[{"lang":"en","group":"blog","slug":"blog/10-creative-ways-to-use-chatgpt-search-the-web-feature-7f145c5cfa30","frontmatter":{"title":"10 Creative Ways to Use ChatGPT Search The Web Feature","meta_title":"10 Creative Ways to Use ChatGPT Search The Web Feature","description":"The article outlines ten innovative applications of ChatGPTs search the web feature, which provides real-time information. Users can stay updated on current events, plan travel itineraries, discover new recipes, monitor market trends, access real-time data, find local events, compare products, learn about emerging technologies, get air quality updates, and explore educational resources. This feature is particularly beneficial for paid members using ChatGPT 4o and 4o-mini, enhancing their ability to gather relevant information efficiently.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*S4RtWt6Ouspx4nnl","categories":["Chatbots","Technology/Web","Education"],"author":"Rifx.Online","tags":["ChatGPT","search","web","real-time","information"],"draft":false,"slug":"blog/10-creative-ways-to-use-chatgpt-search-the-web-feature-7f145c5cfa30"},"content":"\n\n\n\n\n### For example, prompts and outputs\n\n\n\nDid you know you can use the ‚Äúsearch the web‚Äù feature of ChatGPT for many tasks other than your basic web search?\n\nFor those who don't know, ChatGPT‚Äôs new ‚Äúsearch the web‚Äù feature provides real\\-time information.\n\nAs of writing this post, it's only available for paid members who are using ChatGPT 4o and 4o\\-mini.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uyESPHmmvzSJjZmgpn_Oww.png)\n\nHere are some creative ways to use this feature:\n\n\n## 1\\. Stay Updated on Current Events:\n\nIf you are interested in the latest news and events and don't have time for searching and finding the best ones this is for you.\n\nNow using the search web feature in ChatGPT you can receive summaries of the latest news, sports scores, and stock market updates anytime.\n\n**Example**: ‚Äî ‚Äú***What‚Äôs the latest news in technology today?***‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OQFEyg8WFckOQcM5cKyRww.png)\n\n\n## 2\\. Plan Travel Itineraries:\n\nDo you like to plan your travel for the best time and budget management? Then you will find this itinerary planning feature very helpful.\n\nNow you can get up\\-to\\-date information on travel destinations, including weather forecasts, local events, and the best places to shop and eat.\n\n**Example: ‚Äî ‚Äú*What are the top attractions in Paris this weekend?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BLm4PoTaxrXkBMoB56jg8g.png)\n\n\n## 3\\. Discover New Recipes:\n\nIf you love trying new food and also love to cook, this one is great.\n\nYou can use ‚Äúsearch the web‚Äù in ChatGPT to find trending recipes or cooking tips based on dates or location.\n\n**Example: ‚Äî ‚Äú*What‚Äôs a popular dessert recipe this month?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iSrMCgwjdOw4xOSC51LglA.png)\n\n\n## 4\\. Monitor Market Trends:\n\nIf you like to read about or keep yourself updated on a particular field of knowledge then this feature is for you.\n\nNow you can keep track of any industry trends using the search web feature.\n\n**Example: ‚Äî ‚Äú*What are the latest developments in solar energy?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*M-Y7hXRYMXGs_V6iHOm7lQ.png)\n\n\n## 5\\. Access Real\\-Time Data:\n\nWant to know if it will rain today?\n\nOr want to know the latest score but cannot watch a live sports match?\n\nNow you can get real\\-time data such as weather updates, stock prices, or sports scores.\n\n**Example: ‚Äî ‚Äú*What‚Äôs the current weather in New York City?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TwPSdHgHdaKmipspoyldsg.png)\n\n\n## 6\\. Find Local Events:\n\nThe extroverts here will love this feature.\n\nNow you can discover events happening in your area and it will also give you direct links to websites where you can know more details and book tickets.\n\n**Example: ‚Äî ‚Äú*What events are happening in Sydney this weekend?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MgSawNL8kSTohGsIU0ajrA.png)\n\n\n## 7\\. Compare Products:\n\nLooking to buy a new product? Want to know its Pros and Cons?\n\nOr maybe you would like to compare a few products to decide the best among them.\n\nNow you can use the search web feature to compare products or services.\n\n**Example: ‚Äî ‚Äú*Compare the latest smartphones released this year.*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HvzNuBcc6kWNSZA7Sj2hUg.png)\n\n\n## 8\\. Learn About Emerging Technologies:\n\nIf you like to stay updated in the emerging technology sector this one is for you.\n\nUsing the ‚ÄúSearch the Web‚Äù feature now you can stay informed about new technologies.\n\n**Example: ‚Äî ‚Äú*What are the latest advancements in artificial intelligence?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VwySsjMn59nvqxHUWm1AtA.png)\n\n\n## 9\\. Get Air Quality Updates:\n\nThis is another cool usage of location and time\\-aware search results from ChatGPT.\n\nNow you can check the air quality index of any location. Use this to know about the pollution levels.\n\n**Example: ‚Äî ‚Äú*What‚Äôs the AQI in New York right now?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6C_VcWft52zoR57XzEMo-A.png)\n\n\n## 10\\. Explore Educational Resources:\n\nIf you like to learn by watching courses on a topic then this will help you a lot.\n\nYou can use the search feature to find recent articles or courses on topics of interest.\n\n**Example: ‚Äî ‚Äú*What are the latest online courses available for data science?*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tPq8Lve_M_1sNhqfkqtwyg.png)\n\nUsing ChatGPT‚Äôs web search feature, you can access the latest and relevant information in many different ways.\n\nIf you also found a few new and different uses of real\\-time search then please let me know in the comments.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/10-must-learn-skills-to-stay-ahead-in-ai-and-tech-42f4140713b1","frontmatter":{"title":"üìö 10 Must-Learn Skills to Stay Ahead in AI and Tech üöÄ","meta_title":"üìö 10 Must-Learn Skills to Stay Ahead in AI and Tech üöÄ","description":"The article outlines ten essential courses designed to enhance skills in the rapidly evolving fields of AI and technology. Topics include generative AI, debugging, AI-powered recommendations, and technical support fundamentals, among others. These courses aim to equip professionals with the knowledge necessary to stay competitive and innovate within their respective industries, including law and data analysis. The article emphasizes the importance of continuous learning to keep pace with technological advancements.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*uKN-KrOhsDhRrAjL","categories":["Technology","Generative AI","Data Science"],"author":"Rifx.Online","tags":["generative","debugging","recommendations","fundamentals","competitive"],"draft":false,"slug":"blog/10-must-learn-skills-to-stay-ahead-in-ai-and-tech-42f4140713b1"},"content":"\n\n\n\n\n\nIn an industry as dynamic as AI and tech, staying ahead means constantly upgrading your skills. Whether you‚Äôre aiming to dive deep into AI model performance, master data analysis, or transform traditional fields like law with AI, these courses are your gateway to success. Here‚Äôs a curated list of high\\-value courses to supercharge your career and keep you at the forefront of innovation.\n\n\n## 1\\. Introduction to Generative AI\n\n* **Course**: [Intro to Generative AI](https://genai.works/courses/introduction-to-generative-ai-english)\n* **Provider**: Google Cloud\n* **Why Take It**: Gain a foundational understanding of how generative AI models work and how they‚Äôre shaping various industries. Perfect for anyone looking to grasp AI‚Äôs transformative potential.\n\n\n## 2\\. Debugging Generative AI\n\n* **Course**: [Debugging Generative AI](https://genai.works/courses/evaluating-and-debugging-generative-ai)\n* **Provider**: DeepLearning AI\n* **Why Take It**: Learn to troubleshoot and optimize generative AI models, ensuring that they perform reliably and efficiently. Essential for AI professionals who want to fine\\-tune models for better results.\n\n\n## 3\\. Top AI\\-Supported Products\n\n* **Course**: [Top AI\\-Supported Products](https://genai.works/courses/top-100-best-selling-products-ai)\n* **Provider**: Michigan University\n* **Why Take It**: Discover the latest trends in AI\\-powered products, helping you understand where the industry is heading and what innovations are dominating the market.\n\n\n## 4\\. AI\\-Powered Recommendations with Vector Databases\n\n* **Course**: [AI\\-Powered Recommendations](https://genai.works/courses/vector-database-projects-ai-recommendation-systems)\n* **Provider**: IBM\n* **Why Take It**: Develop smart recommendation systems using vector databases, a crucial skill for building personalized, AI\\-driven experiences in tech, e\\-commerce, and media.\n\n\n## 5\\. AI for Software Teams\n\n* **Course**: [Team Software Engineering with AI](https://genai.works/courses/team-software-engineering-with-ai)\n* **Provider**: DeepLearning AI\n* **Why Take It**: This course equips software teams to leverage AI tools for better collaboration, making teamwork more efficient and tech projects more successful.\n\n\n## 6\\. Technical Support Fundamentals\n\n* **Course**: [Tech Support Fundamentals](https://genai.works/courses/technical-support-fundamentals)\n* **Provider**: Google\n* **Why Take It**: Essential for anyone wanting to build troubleshooting skills, this course lays the foundation for technical support roles and IT infrastructure management.\n\n\n## 7\\. Prompt Engineering for Law\n\n* **Course**: [Specialization Prompt Engineering for Law](https://genai.works/courses/specialization-prompt-engineering-for-law)\n* **Provider**: Vanderbilt\n* **Why Take It**: Transform the legal field with AI\\-driven prompt engineering. This course is ideal for legal professionals looking to innovate with technology and streamline their work.\n\n\n## 8\\. Preparing Data for Analysis with Excel\n\n* **Course**: [Data Prep with Excel](https://genai.works/courses/preparing-data-for-analysis-using-microsoft-excel)\n* **Provider**: Microsoft\n* **Why Take It**: Improve your data analysis workflow and enhance your Excel skills for better data preparation, crucial for both entry\\-level and advanced data science roles.\n\n\n## 9\\. IT Security: Defense Against the Digital Dark Arts\n\n* **Course**: [IT Security Fundamentals](https://lnkd.in/dTY2Vbih)\n* **Provider**: Google\n* **Why Take It**: Learn to safeguard your digital assets and understand the basics of cybersecurity. This course covers critical skills in defending against cyber threats.\n\n\n## 10\\. Data Structures in Python\n\n* **Course**: [Data Structures in Python](https://genai.works/courses/data-structures-in-python)\n* **Provider**: Michigan University\n* **Why Take It**: Strengthen your coding skills with a deeper understanding of data structures in Python, an essential skill for software developers and data scientists alike.\n\n\n## ‚úîÔ∏è Join the \\#BuildwithAI Hackathon 2024\n\n* **Get Involved**: [Hackathon Link](https://lnkd.in/dsapprp4)\n* **Why Join**: Put your skills to the test, collaborate with like\\-minded individuals, and solve real\\-world problems using AI. The perfect way to apply what you‚Äôve learned and showcase your expertise.\n\n\n## Conclusion\n\n*The tech landscape is constantly evolving, and keeping up with these essential skills will help you stay competitive. From foundational courses in AI and data structures to specialized fields like AI for legal work, these courses cover a wide range of knowledge that will equip you for the future. Enroll now, expand your expertise, and start making an impact in AI and tech!*\n\nHappy learning and innovating! üöÄ\n\nIf you‚Äôd like your AI Product to be featured, feel free to contact us on our [**Linkedin page**](https://www.linkedin.com/company/genai-works/)**.**\n\nFollow our official [**Instagram**](https://www.instagram.com/generativeai_official/?igsh=Zjc3NGU5N2ticzZ6), [**TikTok**](https://www.tiktok.com/@generative_ai_official?_t=8kqDA0pyrC6&_r=1) and [**YouTube**](https://www.youtube.com/@generative.ai.official) for daily AI content.\n\nIt is now open to all startups and builders to register their AI App/Project for free! [**https://genai.works/sign\\-up**](https://genai.works/sign-up)\n\nRead TOP AI News and find useful cheat sheets in our [**Generative AI Daily Newsletter.**](https://newsletter.genai.works/subscribe)\n\n**Quick Facts:** 5\\+M Followers \\| 2\\.6M\\+ Newsletter Subscribers. Largest and fastest growing [**AI community on Linked‚ÄôIn**](https://www.linkedin.com/company/genai-works/) founded and backed by AI experts in the industry.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/5-ai-projects-you-can-build-this-weekend-with-node-js-76e0ee51cc72","frontmatter":{"title":"5 AI Projects You Can Build This Weekend (with Node.js)","meta_title":"5 AI Projects You Can Build This Weekend (with Node.js)","description":"This article presents five beginner-friendly AI projects that can be completed over a weekend using Node.js. The projects include creating a customer support chatbot, an AI-powered image recognition app, a sentiment analysis tool for social media, a voice command application, and a personalized movie recommender. Each project highlights essential skills in natural language processing, computer vision, sentiment analysis, and recommendation algorithms, providing hands-on experience in artificial intelligence development.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*x9ezYQZawlG0DRV6","categories":["Programming/Scripting","Natural Language Processing","Computer Vision"],"author":"Rifx.Online","tags":["Node.js","chatbot","image","sentiment","recommender"],"draft":false,"slug":"blog/5-ai-projects-you-can-build-this-weekend-with-node-js-76e0ee51cc72"},"content":"\n5 Exciting AI Projects to Build in a Weekend with Node.js (Perfect for Beginners)\n\n\n\nAre you interested in building AI projects but short on time?\n\nWith just Node.js and a weekend, you can dive into hands\\-on AI projects that boost your coding skills and introduce you to practical applications in artificial intelligence.\n\nThese beginner\\-friendly projects will guide you through setting up chatbots, image recognition, sentiment analysis, and more.\n\nSo, grab your laptop and get ready to code with these five exciting AI projects!\n\n\n### 1\\. Chatbot for Customer Support ü§ñ\n\nChatbots are a popular way to start exploring natural language processing (NLP), and with Node.js, you can set up a basic chatbot to handle customer inquiries and provide answers.\n\n**Why Build This Project?**Creating a chatbot introduces you to the fundamentals of NLP and real\\-time server interactions, valuable skills in AI development.\n\n**What You‚Äôll Need:**\n\n* **Node.js and Express** for [setting up the server](https://expressjs.com/)\n* **Dialogflow** (by Google) or [**ChatGPT API**](https://platform.openai.com/docs/api-reference/introduction) for natural language processing\n* **Socket.io** for real\\-time chat functionality\n\n\n## 2\\. Build an AI\\-Powered Image Recognition App with Node.js üì∏\n\nThis project involves creating an image recognition app that can identify objects, animals, or text in photos.\n\nBy using an AI\\-powered image recognition API, you‚Äôll be able to work with computer vision without diving into complex machine learning algorithms.\n\n**Why Build This Project?**Image recognition is a key component in AI, and this project will give you hands\\-on experience with computer vision and file handling in Node.js.\n\n**What You‚Äôll Need:**\n\n* **Node.js and Express** for backend server setup\n* **Google Cloud Vision** or [**Microsoft Azure Computer Vision API**](https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/) for image analysis\n* **Multer** for [handling file uploads](https://www.npmjs.com/package/multer)\n\n\n## 3\\. Sentiment Analysis Tool for Social Media Posts üìä\n\nA sentiment analysis tool lets you analyze the tone of social media posts, reviews, or customer feedback.\n\nWith Node.js and a sentiment analysis API, you can create a tool that rates text as positive, negative, or neutral.\n\n**Why Build This Project?**This project is perfect for learning how to process text data and interpret sentiment, which is widely used in social media monitoring and customer feedback analysis.\n\n**What You‚Äôll Need:**\n\n* **Node.js and Express** for server setup\n* [**Natural**](https://github.com/NaturalNode/natural) or **Aylien API** for sentiment analysis\n* **HTML/CSS** for creating a simple [user interface](https://developer.mozilla.org/en-US/docs/Learn/HTML)\n\n\n## 4\\. Develop a Voice Command App with Speech Recognition üéôÔ∏è\n\nCreate an app that understands basic voice commands, an essential feature for voice\\-activated devices or smart home systems.\n\nBy combining Node.js and a speech recognition API, you can create a simple app that recognizes commands and responds.\n\n**Why Build This Project?**Voice recognition is becoming more common, and this project gives you the chance to explore voice\\-controlled interactions, which are valuable in IoT and accessibility\\-focused applications.\n\n**What You‚Äôll Need:**\n\n* **Node.js and Express** for [the backend server](https://expressjs.com/)\n* [**Web Speech API**](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) for browser\\-based speech recognition\n* **Socket.io** for real\\-time command response\n\n\n## 5\\. Design a Personalized Movie Recommender with Node.js üé¨\n\nUsing machine learning algorithms, you can build a personalized movie recommendation system based on user preferences. This project uses collaborative filtering to suggest movies similar to those a user has rated highly.\n\n**Why Build This Project?**Movie recommendation systems are an excellent introduction to collaborative filtering and recommendation algorithms, which are widely used in streaming services and e\\-commerce.\n\n**What You‚Äôll Need:**\n\n* **Node.js and Express** for server setup\n* **Collaborative Filtering algorithms** (e.g., [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) or [KNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)) for recommendation logic\n* **TMDb API** for accessing a large database of movies\n\n\n## Conclusion\n\nThese five AI projects are perfect for anyone looking to explore AI hands\\-on over a single weekend.\n\nFrom building a chatbot to creating a movie recommender, you‚Äôll gain foundational AI skills while strengthening your Node.js expertise.\n\nEach project is highly customizable, so as you progress, feel free to adapt them with your unique twists.\n\nFor more tutorials and resources, [subscribe to our channel](https://www.youtube.com/@codemarketi) and stay updated on the latest AI and Node.js project ideas.\n\nHappy coding! üöÄ\n\n\n## Related Blog Articles You Might Enjoy\n\n* [https://readmedium.com/how\\-ai\\-tools\\-like\\-claude\\-vercel\\-and\\-more\\-are\\-transforming\\-software\\-development\\-b8d79b0de943](https://readmedium.com/how-ai-tools-like-claude-vercel-and-more-are-transforming-software-development-b8d79b0de943)\n* [https://readmedium.com/six\\-ai\\-powered\\-passive\\-income\\-ways\\-to\\-make\\-350\\-per\\-day\\-990d1e334d16](https://readmedium.com/six-ai-powered-passive-income-ways-to-make-350-per-day-990d1e334d16)\n* [https://readmedium.com/as\\-a\\-developer\\-here\\-are\\-5\\-websites\\-youll\\-love\\-e7518b24c85d](https://readmedium.com/as-a-developer-here-are-5-websites-youll-love-e7518b24c85d)\n* [https://readmedium.com/5\\-useful\\-chatgpt\\-tricks\\-thatll\\-blow\\-your\\-mind\\-in\\-2025\\-12e10a81f4d5](https://readmedium.com/5-useful-chatgpt-tricks-thatll-blow-your-mind-in-2025-12e10a81f4d5)\n\n\n## In Plain English üöÄ\n\n*Thank you for being a part of the [**In Plain English**](https://plainenglish.io/) community! Before you go:*\n\n* Be sure to **clap** and **follow** the writer Ô∏èüëè**Ô∏èÔ∏è**\n* Follow us: [**X**](https://x.com/inPlainEngHQ) \\| [**LinkedIn**](https://www.linkedin.com/company/inplainenglish/) \\| [**YouTube**](https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \\| [**Discord**](https://discord.gg/in-plain-english-709094664682340443) \\| [**Newsletter**](https://newsletter.plainenglish.io/) \\| [**Podcast**](https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)\n* [**Create a free AI\\-powered blog on Differ.**](https://differ.blog/)\n* More content at [**PlainEnglish.io**](https://plainenglish.io/)\n\n"},{"lang":"en","group":"blog","slug":"blog/50-generative-ai-use-cases-across-10-industries-96f621fefac2","frontmatter":{"title":"The Top 50+ Generative AI Use Cases Across 10 Industries in 2024","meta_title":"The Top 50+ Generative AI Use Cases Across 10 Industries in 2024","description":"Generative AI (Gen AI) is emerging as a transformative technology across various industries in 2024, enabling businesses to automate complex tasks, enhance customer engagement, and foster innovation. Key advantages include improved efficiency, cost savings, and personalized experiences. This article outlines over 50 Gen AI use cases across ten industries, including marketing, sales, and finance, highlighting its potential to optimize operations and drive competitive advantage. A strategic approach to implementing Gen AI is essential for businesses to realize its benefits and remain competitive in a rapidly evolving digital landscape.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PeQAto1_Mwovo11vsArGIA.jpeg","categories":["Generative AI","Technology","Marketing"],"author":"Rifx.Online","tags":["Generative","Automation","Personalization","Efficiency","Innovation"],"draft":false,"slug":"blog/50-generative-ai-use-cases-across-10-industries-96f621fefac2"},"content":"\n\n\n\n\n\nAs we look forward to 2024, generative AI (Gen AI) is increasingly recognized as a pivotal technology driving transformation across industries. This evolution marks a shift from traditional AI‚Äôs predictive and analytical role to Gen AI‚Äôs creative capabilities, which enable businesses to automate complex tasks, foster innovation, and deliver highly personalized customer experiences. According to a recent analysis, businesses investing in AI have seen efficiency gains of up to 30%, while those implementing Gen AI are even further optimizing their workflows and outcomes.\n\nIn this article, we delve into over 50 impactful Gen AI use cases across ten leading industries, with a focus on empowering businesses interested in developing Gen AI to improve their operational efficiency, customer engagement, and competitive advantage.\n\n\n### What is Generative AI?\n\n\n> Generative AI is a subset of artificial intelligence focused on creating new content ‚Äî be it text, images, audio, or video ‚Äî by learning patterns from existing data. Unlike traditional AI, which primarily makes predictions or classifications based on data, Gen AI generates original outputs. It relies on models such as Generative Adversarial Networks (GANs) and transformer\\-based architectures like GPT, enabling capabilities from creative content production to real\\-time customer interaction.\n\n\n### Key Advantages of Generative AI for Business\n\n1. **Creativity and Innovation**: Gen AI generates unique content and ideas beyond human creativity, fueling industries where new concepts drive success, such as marketing, design, and product development.\n2. **Enhanced Efficiency**: Automating repetitive tasks such as content generation and initial customer interactions allows businesses to focus on strategic and high\\-level work.\n3. **Cost Savings**: Gen AI reduces dependency on manual labor for tasks like content creation, data analysis, and customer service, leading to significant savings.\n4. **Personalization at Scale**: Leveraging data, Gen AI delivers customized experiences, improving customer satisfaction and loyalty.\n5. **Data\\-Driven Insights**: Gen AI can process large datasets to extract actionable insights, supporting informed decision\\-making in real\\-time.\n\n[**Building a generative AI for business**](https://www.blockchainappfactory.com/generative-ai-solutions?utm_source=medium&utm_medium=blog&utm_campaign=elavarasan)can drive innovation, streamline operations, and enhance customer experiences. It‚Äôs a powerful tool for staying competitive in an increasingly digital world.\n\n\n## Generative AI Use Cases for the Top 10 Industries in 2024\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TG-tfTwA58FNjHv5so8fXg.png)\n\n\n### 1\\. Marketing\n\nIn 2024, marketers leverage Gen AI to optimize campaigns, personalize outreach, and generate content at scale. By automating repetitive tasks, marketing teams can focus on strategy and creativity.\n\n* **Content Optimization**: Gen AI analyzes search trends and audience preferences to recommend topics, keywords, and formats that boost engagement and visibility.\n* **High\\-Scale Content Creation**: Marketing agencies use Gen AI to quickly produce diverse content types ‚Äî from blog posts to social media updates ‚Äî ensuring timely, high\\-quality output.\n* **Automated Social Media Management**: Small businesses utilize Gen AI to manage posts, respond to customer inquiries, and analyze engagement without a large team.\n* **Personalized Campaigns**: AI segments audiences, crafting tailored email and ad content that resonates with individual customer preferences.\n* **A/B Testing and Campaign Optimization**: AI automates testing of various content versions, analyzing real\\-time results to fine\\-tune campaigns for maximum effectiveness.\n\n\n### 2\\. Sales\n\nSales teams adopt Gen AI to streamline processes, manage leads, and automate proposal generation, improving conversion rates and efficiency.\n\n* **Lead Scoring and Prioritization**: AI assigns scores to leads based on likelihood to convert, enabling targeted and efficient outreach.\n* **Automated Proposal Generation**: Gen AI drafts custom proposals based on client needs, reducing preparation time and enhancing proposal quality.\n* **Virtual Sales Assistance**: AI assists sales reps with scheduling, follow\\-ups, and real\\-time data insights during client meetings.\n* **Predictive Sales Analytics**: By analyzing historical data, Gen AI predicts future trends and customer behaviors, supporting data\\-driven sales strategies.\n* **Chatbots for Initial Engagement**: AI chatbots engage potential customers, answering questions and qualifying leads before passing them to sales agents.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7yN87soNCoYQe6Qk2oIenw.png)\n\n\n### 3\\. Human Resources\n\nGenerative AI helps HR teams automate tasks, from recruitment and onboarding to employee engagement analysis, contributing to better hiring and retention.\n\n* **Automated Resume Screening**: Gen AI reviews resumes, identifying top candidates based on specified criteria, saving time on initial screenings.\n* **Employee Onboarding Assistance**: AI\\-powered agents guide new hires through onboarding, ensuring smooth integration and reducing manual HR tasks.\n* **Sentiment Analysis of Feedback**: AI analyzes employee feedback to identify trends and recommend improvements to enhance workplace satisfaction.\n* **Personalized Learning and Development Plans**: AI assesses skills and suggests targeted training for employee growth.\n* **Workforce Analytics for Retention**: Gen AI predicts turnover rates and identifies contributing factors, allowing HR to proactively address retention.\n\n\n### 4\\. Customer Service\n\nGen AI enhances customer support by handling inquiries, providing real\\-time assistance, and automating ticket resolution.\n\n* **AI\\-Powered Chatbots**: Gen AI chatbots respond to routine questions, reducing response times and enhancing customer satisfaction.\n* **Sentiment Analysis for Feedback**: AI analyzes reviews and feedback to gauge sentiment, helping businesses understand customer satisfaction.\n* **Automated Ticket Prioritization**: Gen AI sorts support tickets, prioritizing urgent issues for faster resolution.\n* **Knowledge Base Optimization**: AI continuously updates knowledge bases based on common inquiries, improving self\\-service capabilities.\n* **Virtual Customer Assistants**: AI provides tailored recommendations based on customer preferences and history, enhancing support.\n\n\n### 5\\. Finance and Accounting\n\nGen AI is revolutionizing finance by automating invoice processing, forecasting finances, and ensuring tax compliance.\n\n* **Automated Invoice Processing**: AI handles invoicing, reducing errors and speeding up payment cycles.\n* **Financial Forecasting**: By analyzing historical data, Gen AI improves the accuracy of budgeting and financial planning.\n* **Expense Management**: AI identifies cost\\-saving opportunities by categorizing and analyzing expenses.\n* **Tax Compliance**: Gen AI prepares tax documents, minimizing errors and ensuring regulatory compliance.\n* **Real\\-Time Financial Reporting**: AI generates financial insights, empowering agile, data\\-driven decision\\-making.\n\n\n### 6\\. E\\-commerce\n\nIn e\\-commerce, Gen AI enhances customer experiences, optimizes inventory, and detects fraud, supporting business growth.\n\n* **Personalized Product Recommendations**: AI analyzes behavior to offer personalized product suggestions, increasing conversions.\n* **Dynamic Pricing Strategies**: AI adjusts prices in real\\-time based on market trends, demand, and competitor pricing.\n* **Inventory Forecasting**: AI predicts stock needs, preventing overstocking or stockouts and improving supply chain efficiency.\n* **Customer Journey Mapping**: AI creates detailed journey maps, guiding e\\-commerce strategies.\n* **Fraud Detection and Prevention**: Gen AI detects unusual transaction patterns, protecting businesses and customers from fraud.\n\n\n### 7\\. Real Estate\n\nReal estate companies use Gen AI for property valuation, virtual tours, and CRM enhancement, streamlining operations and improving decision\\-making.\n\n* **Automated Property Valuation**: AI models analyze market data, providing accurate valuations for better decision\\-making.\n* **Virtual Property Tours**: AI creates virtual tours, making listings accessible for remote or international buyers.\n* **Predictive Market Analysis**: AI forecasts market trends, guiding investment decisions.\n* **Lease Management Automation**: AI manages renewals and compliance, reducing administrative tasks.\n* **Enhanced Client Relationship Management**: AI provides insights into client preferences, enabling tailored interactions.\n\n\n### 8\\. Education\n\nIn education, Gen AI tailors learning experiences, supports curriculum development, and aids grading, improving learning outcomes.\n\n* **Personalized Learning Paths**: AI creates custom learning paths based on student strengths and weaknesses.\n* **Automated Grading**: AI assists educators with grading, enabling faster feedback for students.\n* **Curriculum Insights**: AI analyzes performance data to guide curriculum adjustments.\n* **Virtual Tutoring**: AI tutors provide resources and answer student queries outside class hours.\n* **Student Engagement Analysis**: AI flags at\\-risk students, supporting timely interventions.\n\n\n### 9\\. Manufacturing\n\nManufacturing benefits from Gen AI‚Äôs predictive maintenance, quality control, and workforce scheduling, boosting efficiency and reducing downtime.\n\n* **Predictive Maintenance**: AI forecasts equipment issues, reducing unplanned maintenance and downtime.\n* **Supply Chain Optimization**: AI forecasts inventory needs, streamlining operations and reducing costs.\n* **Automated Quality Control**: Gen AI detects defects in real\\-time, enhancing product quality.\n* **Workforce Scheduling**: AI optimizes shifts based on demand, ensuring efficient staffing.\n* **Product Design Assistance**: AI informs design decisions by analyzing market and consumer trends.\n\n\n### 10\\. Retail\n\nRetailers use Gen AI to understand customer behavior, personalize in\\-store experiences, and optimize inventory, boosting satisfaction and sales.\n\n* **Customer Behavior Analysis**: AI analyzes shopping habits, guiding merchandising and marketing efforts.\n* **Enhanced In\\-Store Experience**: AI\\-driven apps deliver personalized in\\-store recommendations and assistance.\n* **Inventory Forecasting**: AI anticipates inventory needs, preventing overstock or stockouts.\n* **Loyalty Program Optimization**: AI tailors loyalty programs, improving engagement and retention.\n* **Automated Checkout**: AI\\-driven checkouts enhance convenience and reduce wait times.\n\n\n### Implementing Generative AI for Your Business\n\n1. **Identify Use Cases**: Define specific use cases aligned with business goals, from content generation to personalized marketing.\n2. **Choose the Right Tools**: Evaluate Gen AI tools for capabilities, integration, and scalability to ensure alignment with business needs.\n3. **Data Preparation and Model Training**: Clean, organize, and prepare data, as high\\-quality data is essential for model accuracy.\n4. **Pilot and Assess**: Run pilot projects to test Gen AI‚Äôs impact, gather insights, and refine solutions as needed.\n5. **Continuous Optimization**: Monitor outputs, collect feedback, and make necessary adjustments to enhance model performance.\n6. **Consider Ethical Implications**: Implement policies to address ethical issues, including data privacy, bias, and responsible AI use.\n\n\n### Conclusion\n\nGenerative AI is transforming industries across the board in 2024, from enhancing customer engagement to driving efficiency in finance, marketing, and manufacturing. For businesses ready to adopt Gen AI, a strategic approach is key to realizing its benefits, from automating processes to personalizing customer experiences. By understanding Gen AI‚Äôs potential, businesses can harness its capabilities to remain competitive, innovative, and efficient in today‚Äôs fast\\-evolving digital landscape.\n\n\n## In Plain English üöÄ\n\n*Thank you for being a part of the [**In Plain English**](https://plainenglish.io/) community! Before you go:*\n\n* Be sure to **clap** and **follow** the writer Ô∏èüëè**Ô∏èÔ∏è**\n* Follow us: [**X**](https://x.com/inPlainEngHQ) \\| [**LinkedIn**](https://www.linkedin.com/company/inplainenglish/) \\| [**YouTube**](https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \\| [**Discord**](https://discord.gg/in-plain-english-709094664682340443) \\| [**Newsletter**](https://newsletter.plainenglish.io/) \\| [**Podcast**](https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)\n* [**Create a free AI\\-powered blog on Differ.**](https://differ.blog/)\n* More content at [**PlainEnglish.io**](https://plainenglish.io/)\n\n"},{"lang":"en","group":"blog","slug":"blog/a-month-with-cursor-and-claude-dev-my-thoughts-5c41ae0d4467","frontmatter":{"title":"A Month with Cursor and Claude-Dev: My Thoughts","meta_title":"A Month with Cursor and Claude-Dev: My Thoughts","description":"I‚Äôve been using two new tools recently- Cursor and Claude-Dev -both of which have been getting a fair bit of attention in the developer‚Ä¶","date":"2024-11-04T12:32:52.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*i28vK12LJ6XTpSwrKiamwA.png","categories":["Programming","Technology","Generative AI"],"author":"Rifx.Online","tags":["Cursor","Claude-Dev","Cline","autocomplete","debugging"],"draft":false,"slug":"blog/a-month-with-cursor-and-claude-dev-my-thoughts-5c41ae0d4467"},"content":"\n\n\nI‚Äôve been using two new tools recently\\- **Cursor** and **Claude\\-Dev** \\-both of which have been getting a fair bit of attention in the developer community. They‚Äôre each built to make coding faster and more intuitive through AI\\-powered assistance, but they take different approaches and have their own strengths and weaknesses. After using both for about a month, I thought it was time to sit down and reflect on where they shine and where they still need some work.\n\nLet‚Äôs start with Cursor.\n\n## Cursor: Familiar but Faster\n\nCursor is a fork of VSCode, which, if you‚Äôre already a VSCode user like I am, makes it very easy to slip into. I didn‚Äôt need to rebuild my environment from scratch or deal with setting up keybindings. Everything that worked in VSCode worked in Cursor right out of the box\\-my extensions, settings, and keymappings carried over without a hitch. The transition was almost invisible, except for one key difference: the AI autocomplete is much faster. In fact, **in my experience**, it‚Äôs around 10 times faster than GitHub Copilot.\n\nNow, ‚Äú10 times faster‚Äù isn‚Äôt a number I pulled from benchmarks\\-it‚Äôs just what it feels like after using it for a while. When you‚Äôre typing code, and Cursor is predicting your next move, it doesn‚Äôt feel like the AI is lagging behind or playing catch\\-up. Instead, it‚Äôs right there with you, which helps keep you in flow. I was surprised at how much more productive I felt when I wasn‚Äôt waiting for Copilot to catch up or pressing tab three times just to get the suggestion I wanted.\n\nCursor also has a nice feature where it embeds and indexes your entire project, making it easier to understand the relationships between files. When you update a file, the index gets updated too, which means the AI has a better grasp of how the pieces of your codebase fit together. This is useful if you‚Äôre working across a large codebase with multiple files that depend on each other.\n\n## The Drawbacks\n\nThat said, some of the best features in Cursor are gated behind a subscription. I‚Äôm generally not opposed to paying for tools that add real value, but in this case, I was a little disappointed that the most interesting AI features\\-like the multi\\-file editing\\-were part of the premium version. For a tool that‚Äôs still fairly new, I wonder if gating these features too early might limit its adoption, especially given how many developers are already paying for GitHub Copilot.\n\nAnother issue I‚Äôve run into with Cursor is that while it‚Äôs great at fast, small tasks, it lacks some of the flexibility I need when working with more complex problems. It‚Äôs excellent for quick code suggestions and refactoring, but when I needed something that could handle more involved tasks, like reading logs or executing build commands, I found myself looking for something else.\n\n## Claude\\-Dev: The Open\\-Source Underdog\n\nThat‚Äôs where **Claude\\-Dev (now called Cline)** comes in. Claude\\-Dev is an open\\-source extension for VSCode, and while it doesn‚Äôt have the same level of polish as Cursor, it‚Äôs rapidly evolving\\-and in some ways, it‚Äôs more powerful. The most striking thing about Claude\\-Dev is that it feels like it‚Äôs trying to do more than just suggest code snippets. It‚Äôs a tool that can **interact** with your environment in a much deeper way.\n\nFor example, Claude\\-Dev can read your terminal logs, understand linting errors, and even run arbitrary CLI commands. This means that if you ask it why your project isn‚Äôt building, it won‚Äôt just offer suggestions\\-it will actually go and look at the relevant files, figure out what kind of project you‚Äôre working with (Node, React, Python, etc.), and try to build it for you. If there‚Äôs an error, it reads the logs, tries to diagnose the problem, and can even apply fixes if needed.\n\nIt‚Äôs not perfect, though. In my experience, Claude\\-Dev isn‚Äôt as fast as Cursor, especially when it‚Äôs making edits. One reason for this is that it rewrites entire files instead of just updating the parts that need to change. This slows things down, and if you‚Äôre paying for API tokens (you need to supply an API key from the LLM you want to use), it burns through those faster than it should. I‚Äôve been thinking about contributing to the project to fix this by having it update just the necessary lines via shell commands like `sed`.\n\nOne feature I‚Äôve found particularly interesting is how Claude\\-Dev can use Puppeteer to visually test and update your frontend. You can give it a screenshot of a website, and it will compare that to your app, iterating until it gets your frontend to match the look you‚Äôre going for. It‚Äôs not the fastest process, but it‚Äôs surprisingly good at handling CSS\\-something that, for me at least, is usually a bit of a time sink.\n\n## Where It Falls Short\n\nClaude\\-Dev is definitely a tool for people who are comfortable experimenting with something that‚Äôs still a bit rough around the edges. Unlike Cursor, which feels more like a polished product that‚Äôs ready for prime time, Claude\\-Dev is more like a powerful tool in active development. It doesn‚Äôt always get things right the first time, and it‚Äôs slower than I‚Äôd like, but it‚Äôs constantly improving. The fact that it‚Äôs open source and primarily developed by one person makes its pace of innovation even more impressive.\n\n## So Which One Should You Use?\n\nIf you‚Äôre looking for a polished, fast experience with a focus on speed and quick suggestions, **Cursor** might be the better choice. It feels snappy, it integrates with your existing VSCode setup, and it keeps you in flow\\-until you hit a paywall. But if you‚Äôre okay with that and don‚Äôt need the extra bells and whistles, Cursor is a great tool.\n\nOn the other hand, if you want something that can do more than just autocomplete code\\-something that can actually help with debugging, building, and iterating on your project\\- **Claude\\-Dev** is a better fit. It‚Äôs more versatile, but also a bit slower and rougher around the edges. If you‚Äôre comfortable experimenting and can put up with some quirks, it offers a level of functionality that Cursor just doesn‚Äôt have right now.\n\nFor me, **Claude\\-Dev** wins out, mostly because of its deeper integration with my workflow. The ability to read logs, run commands, and iterate until a problem is solved is invaluable, especially when I‚Äôm working with unfamiliar codebases. That said, I still find myself using **Cursor** when I need to move fast and don‚Äôt want to wait around for the AI to process a command.\n\n## Final Thoughts\n\nBoth Cursor and Claude\\-Dev offer unique benefits, and I think we‚Äôre only scratching the surface of what AI\\-driven coding tools can do. There‚Äôs a lot of potential here, especially as these tools continue to evolve. I‚Äôm excited to see where they go, and I‚Äôll keep experimenting with both to see how they fit into my development workflow.\n\nIn the meantime, I‚Äôd recommend trying out both and for yourself. Each tool has its strengths, and you‚Äôll probably find that one fits your style better than the other, depending on what you‚Äôre working on.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/a-new-risings-red-star-qwen2-5-is-here-0dffe0fb09ad","frontmatter":{"title":"A new risings Red star: Qwen2.5 is here","meta_title":"A new risings Red star: Qwen2.5 is here","description":"Let‚Äôs test together the new born Alibaba Cloud‚Äôs generative AI Qwen2.5 with python and llama-cpp","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zU-XtqK2oMLkvscgxavjdw.png","categories":["Programming","Technology","Education"],"author":"Rifx.Online","tags":["Qwen2.5","multimodal","instruction-following","text-generation","multilingual"],"draft":false,"slug":"blog/a-new-risings-red-star-qwen2-5-is-here-0dffe0fb09ad"},"content":"\n\n\n\n\n### Let‚Äôs test together the new born Alibaba Cloud‚Äôs generative AI Qwen2.5 with python and llama-cpp\n\n\n\nIn silence, with not so many claims and anticipated announcements, Alibaba Cloud release on September the 19th their flagship model family Qwen2.5.\n\nAlibaba Cloud‚Äôs revolutionary journey with Qwen is showing once again strong Leadership through Innovation.\n\nHow? What‚Äôs so cool in them? And should we expect?\n\nIn this article we are going to explore the new models and check the performances. As a follow up, in the next article, we are going to use `llama-cpp-python` and the quantized version of qwen2.5‚Äì1.5b-instruct, putting the model under 13 NLP tasks test.\n\nIn fact I believe that we are the best Benchmark tool around and we are fully able to evaluate when a model is good for us!\n\nFor now, here what we are going to cover:\n\n\n```python\n- Qwen2.5 family innovation\n- Declared scope, use cases and models\n- Qwen2.5: a party of Foundation models\n- Expanding Reach through Open-Source Contributions\n- Bridging Industries through cutting-edge AI solutions\n- 13 Tasks to prove it worth \n- Future outlook: continued Open-Sourcing\n```\nLet‚Äôs dive in!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OeQ5qeOzCdl8LPJOZZgTIw.png)\n\n\n## Qwen2.5 family innovation\n\nQwen is the large language model and large multimodal model series of the Qwen Team, Alibaba Group. Just yesterday the large language models have been upgraded to Qwen2.5.\n\nBoth language models and multimodal models are pretrained on large-scale multilingual and multimodal data and post-trained on quality data for aligning to human preferences. Qwen is capable of natural language understanding, text generation, vision understanding, audio understanding, tool use, role play, playing as AI agent, etc.\n\nWith the recent release of Qwen2.5 and additional open-source model releases Alibaba Cloud continues its leadership position to meet rising AI demands from enterprise users. Since June last year, the Qwen family has attracted over 90,000 deployments via Model Studio in various industries including consumer electronics, automobiles, gaming, and more.\n\nQwen also expanded its reach with new models such as Qwen1.5‚Äì110B and CodeQwen1.5‚Äì7B on platforms like Hugging Face, showcasing Alibaba‚Äôs commitment to open-source AI development.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*A4pEOgsLK2PAFtiaGQx1Qw.png)\n\n\n## Declared scope, use cases and models\n\nIn the past three months since Qwen2‚Äôs release, numerous developers have built new models on the Qwen2 language models, providing valuable feedback to the entire community, but also to Alibaba Cloud.\n\n\n> During this period, we have focused on creating smarter and more knowledgeable language models. Today, we are excited to introduce the latest addition to the Qwen family: Qwen2.5.\n\nTheir claims come with facts about the new family of models:\n\n* Dense, easy-to-use, decoder-only language models, available in 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B sizes, and base and instruct variants.\n* Pretrained on our latest large-scale dataset, encompassing up to 18T tokens.\n* Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON.\n* More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n* Context length support up to 128K tokens and can generate up to 8K tokens.\n* Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\n\n## Qwen2.5: a party of Foundation models\n\nAs announced on the [official blog press release](https://qwenlm.github.io/blog/qwen2.5/) on September 19, 2024:\n\n\n> Today, we are excited to introduce the latest addition to the Qwen family: **Qwen2.5**. We are announcing what might be the largest opensource release in history! Let‚Äôs get the party started!\n\n\n> Our latest release features the LLMs **Qwen2.5**, along with specialized models for coding, **Qwen2.5-Coder**, and mathematics, **Qwen2.5-Math**.\n\nTo showcase Qwen2.5‚Äôs capabilities, the Alibaba Cloud team benchmarked their largest open-source model, **Qwen2.5‚Äì72B** ‚Äî a 72B-parameter dense decoder-only language model ‚Äî against leading open-source models like Llama-3.1‚Äì70B and Mistral-Large-V2.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-MMFgkkWHa307jNo.jpg)\n\nAll open-weight models are dense, decoder-only language models, available in various sizes, including:\n\n* Qwen2.5: 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B\n* Qwen2.5-Coder: 1.5B, 7B, and 32B on the way\n* Qwen2.5-Math: 1.5B, 7B, and 72B.\n\nAll these open-source models, except for the 3B and 72B variants, are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories.\n\n\n> In addition to these models, we offer APIs for our flagship language models: **Qwen-Plus** and **Qwen-Turbo** through Model Studio, and we encourage you to explore them!\n\nBut this is not all!\n\n\n> ‚Ä¶we have also open-sourced the **Qwen2-VL-72B**, which features performance enhancements compared to last month‚Äôs release.\n\nIn terms of **Qwen2.5**, the language models, all models are pretrained on our latest large-scale dataset, encompassing up to **18 trillion** tokens. Compared to Qwen2, Qwen2.5 has acquired significantly more knowledge (MMLU: 85+) and has greatly improved capabilities in coding (HumanEval 85+) and mathematics (MATH 80+). Additionally, the new models achieve significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*7c7CIbl-WVjazUeE.jpeg)\n\nQwen2.5 models are generally more resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\nLike Qwen2, the Qwen2.5 language models support up to **128K** tokens and can generate up to **8K** tokens. They also maintain multilingual support for over **29** languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\n\n### Qwen-Coder is the new kid of the family\n\nThe specialized expert language models, namely **Qwen2.5-Coder** for coding and **Qwen2.5-Math** for mathematics, have undergone substantial enhancements compared to their predecessors, CodeQwen1.5 and Qwen2-Math. Specifically, Qwen2.5-Coder has been trained on **5.5 trillion** tokens of code-related data, enabling even smaller coding-specific models to deliver competitive performance against larger language models on coding evaluation benchmarks. Meanwhile, Qwen2.5-Math supports both **Chinese** and **English** and incorporates various reasoning methods, including Chain-of-Thought (CoT), Program-of-Thought (PoT), and Tool-Integrated Reasoning (TIR).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Nvk4wrcB0SB4Tt-xbCzO6g.png)\n\n\n## Expanding Reach through Open-Source Contributions\n\nAs part of its continuous commitment to the broader community, Alibaba Cloud has made additional steps in releasing various sizes and variants of Qwen models. This includes:\n\n1. **Qwen 0.5 billion parameters**, a foundational version suitable for more traditional applications.2. A compact but potent model tailored specifically for gaming development: **Qwen-VL (vision-language)** optimized with high capabilities.\n\nThese advancements demonstrate Alibaba‚Äôs commitment to open-source AI, sharing not only the base versions of Qwen but also significant improvements and new models that are targeting directly the enterprise needs while enhancing their ability to innovate rapidly.\n\nThis aligns closely with a strategic vision where continuous contributions benefit both community members and its own clients as they seek innovative applications across multiple sectors.\n\n\n### Bridging Industries through cutting-edge AI solutions\n\nTo showcase the breadth of Qwen‚Äôs capabilities in real-world scenarios, Alibaba Cloud has been at the forefront:\n\n1. **Xiaomi**: the Company is integrating Alibaba‚Äôs models into their AI assistant, Xiao Ai, and deploying it within Xiaomi smartphones and electric vehicles to create enhanced features like car infotainment image generation via voice commands.\n\n2. **Perfect World Games**: the integration of Qwen in game development has led to innovative applications including improving plot resolution through dialogue dynamics and real-time content management.\n\nThe collaborations between Alibaba Cloud models and various industries have not only enriched the user experience but also facilitated greater opportunities for growth within these sectors, pushing boundaries that would otherwise be unimaginable without AI advancements.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ku8o3rq6PHDE8xcc.png)\n\n\n## 13 Tasks to prove it worth\n\nThe 1.5 Billion parameters model is probably the best variant considering complexity, prompt understanding and inference speed.\n\nI will show you my internal testing using only `llama-cpp-python` and a simple terminal interface.\n\nTo do so, I created a list of prompt, covering a series of normally used tasks where you can also assign a vote (from 0 to 5) after every generation. It‚Äôs a personal human benchmark.\n\n\n### Requirements\n\nCreate a `venv` (python 3.11+ is required): I tested it on my Mini-PC running Windows 11.\n\n\n```python\n## create the virtual environment\npython -m venv venv\n## activate the venv\nvenv\\Scripts\\activate\n## Install the dependencies \npip install llama-cpp-python==0.2.90 tiktoken\n```\nWe need to download the GGUF file from the [official Qwen2.5 Hugging Face repo](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF). I used the qwen2.5‚Äì1.5b-instruct-q5\\_k\\_m.gguf version.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Fa-qFsx9RTFGZmM-vxCEPQ.png)\n\nDownload the file in the main project directory. And we are all set.\n\nThe code used here for the analysis is in my GitHub repository:\n\nI will explain the entire code and the results in the next article. Stay updated!\n\n\n## Future outlook: continued Open-Sourcing\n\nIn future plans, Alibaba has also expressed their commitment to ongoing open-source contributions by releasing smaller variants of Qwen for developers across different sectors. In reality in the Hugging Face community many users have started to fine-tune Qwen for dedicated tasks: I wrote an example in my article on NuExtract: the smaller variant of this model family is based on Qwen2‚Äì0.5b!\n\nThese developments in AI technology and model advancements are crucial steps towards leveraging the full potential of large language models like **Qwen** within a variety of industries. With robust adoption rates continuing to grow rapidly through Model Studio, it is clear that Alibaba Cloud has been a pioneer industry leader not only by providing advanced tools but also promoting innovation across enterprises.\n\nOn my side, my outlook are to proceed with internal testing on the new models, specifically on the small ones, up to 3B.\n\nIn the next article I will share with you my method, how to run the models and the prompt templates used for each of the thirteen NLP tasks.\n\nHope you enjoyed the article. If this story provided value and you wish to show a little support, you could:\n\n1. Clap a lot of times for this story\n2. Highlight the parts more relevant to be remembered (it will be easier for you to find them later, and for me to write better articles)\n3. **Join my [totally free weekly Substack newsletter here](https://thepoorgpuguy.substack.com/about)**\n4. Sign up for a Medium membership ($5/month to read unlimited Medium stories)\n5. Follow me on Medium\n6. Read my latest articles <https://medium.com/@fabio.matricardi>\n\nHere are a few more articles to feed your curiosity:\n\nResources references in this article:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Du7V61mEX_yIrfmF.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories.\n\nSubscribe to our [newsletter](https://www.generativeaipub.com/) and [YouTube](https://www.youtube.com/@generativeaipub) channel to stay updated with the latest news and updates on generative AI. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pvLAT3it1FkdhVU0.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/a-practical-guide-for-using-autogen-in-software-applications-8799185d27ee","frontmatter":{"title":"A practical guide for using AutoGen in software applications","meta_title":"A practical guide for using AutoGen in software applications","description":"Update: While this article was written only 4 months ago, AutoGen has since changed quite a bit. I apologize for some things that may be‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*yrraWH6aGNnbx8p-wfQ1OQ.jpeg","categories":["Programming","Chatbots","Autonomous Systems"],"author":"Rifx.Online","tags":["AutoGen","multi-agent","LLMs","customization","collaboration"],"draft":false,"slug":"blog/a-practical-guide-for-using-autogen-in-software-applications-8799185d27ee"},"content":"\n\n\n\n\n\n*Update: While this article was written only 4 months ago, AutoGen has since changed quite a bit. I apologize for some things that may be outdated in my code examples.*\n\nIf you want to learn about AutoGen, there is [documentation](https://microsoft.github.io/autogen/), [Colab notebooks](https://microsoft.github.io/autogen/docs/Examples), and [a blog](https://microsoft.github.io/autogen/blog). Huge kudos to the AutoGen team for making an AMAZING product, but honestly ‚Äî after reading all their stuff, I still didn‚Äôt know how to use AutoGen outside of a terminal or Jupyter Notebook.\n\nThis article tries to help fill that gap by giving some helpful ways to make AutoGen work in a software application. Here are the topics I‚Äôll go over:\n\n1. Agents aren‚Äôt limited to communicating just over the terminal\n2. Registering custom replies\n3. How to include real humans in the conversation in real ways\n4. You can (and should) customize who speaks next\n5. You don‚Äôt have to use OpenAI\n6. Functions can be used instead of executing code\n7. Use Agents for organization, not just for conversations\n\nLastly, I‚Äôll go over why I think you should use AutoGen to begin with. Let‚Äôs go!\n\n\n## Agents aren‚Äôt limited to communicating just over the terminal\n\nYou‚Äôll see everyone demo AutoGen using a terminal or Jupyter Notebook. That‚Äôs nice for a demo, but there are other ways these agents can talk to each other.\n\nThere are 2 basic AutoGen classes: [`UserProxyAg`ent](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/user_proxy_agent.py) and [`AssistantAg`ent](https://github.com/microsoft/autogen/blob/main/autogen/agentchat/assistant_agent.py) . They inherit the [`ConversableAg`ent](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py) class, providing just a few different default parameters to the base class.\n\nWhen you see this classic code example:\n\n\n```python\nassistant = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config\n)\nuser_proxy = autogen.UserProxyAgent(name=\"user_proxy\")\nawait user_proxy.a_initiate_chat(\n    assistant,\n    message=\"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\",\n)\n```\nwhat happens is that the `UserProxyAgent` will call its own `send` method, which will call `AssistantAgent` ‚Äòs [`rece`ive](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L514) method, passing along the original message. A reply will be generated (more on that below), and `AssistantAgent` will now call its [`s`end](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L351) method, which will then call `UserProxyAgent` ‚Äòs `receive` method, and so forth, until `UserProxyAgent` determines the conversation is terminated (which can be customized via the `is_termination_msg` argument).\n\nMy first ‚Äúaha‚Äù moment was when I realized these agents were classes, and I could create my own custom agent classes that inherit the AutoGen UserProxy/Assistant/Conversable Agent classes, and override any of the default methods. That makes AutoGen very extensible.\n\nI had a use-case where I needed a human who could type in a message (proxied by `UserProxyAgent`) using a chat UI on a website, and I wanted an `AssistantAgent` to respond back to that chat in the UI, and be able to receive more messages from the human user, as though the human was just another agent in this AutoGen conversation.\n\nI could override the `send` and `receive` methods (or `a_send` and `a_receive`), and push/pull over http, websockets, etc. I tried this, and it started to work, but doesn‚Äôt scale. Let‚Äôs learn a better way.\n\n\n## Registering custom replies\n\nAutoGen has a plugin system that lets you customize how an agent generates a reply. We‚Äôre used to seeing examples where AutoGen queries OpenAI for an answer, and uses that as its reply, but you can insert your own methods as well:\n\n\n```python\nclass WeatherAgent(AssistantAgent):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, llm_config=False, **kwargs)\n        self.register_reply(Agent, WeatherAgent.get_weather)\n\n    async def get_weather(\n        self,\n        messages: List[Dict] = [],\n        sender=None,\n        config=None,\n    ) -> Tuple[bool, Union[str, Dict, None]]:\n        last_message = messages[-1][\"content\"]\n        result = await fetch_weather(last_message)\n        return True, result\n\nasync def fetch_weather(city: str) -> str:\n    async with httpx.AsyncClient() as client:\n        result = await client.post(\n            WEATHER_API_URL,\n            json={\"city\": question},\n        )\n        return result.json()\n\nweather_assistant = WeatherAgent(name=\"weather_assistant\")\nuser_proxy = autogen.UserProxyAgent(name=\"user_proxy\")\nawait user_proxy.a_initiate_chat(assistant, message=\"Lehi\")\nprint(weather_assistant.last_message)\n```\nHere, `register_reply` will insert my custom method for getting a reply, and by default, will put this method in `position=0`, meaning it will be the first reply method attempted. That method should return a tuple, where the first item is a boolean indicating if this reply is the one that should be used or whether to try the next registered\\_reply (such as the built-in reply generations using OpenAI ‚Äî see the full order [here](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L145-L153)).\n\nKnowing about [`register_re`ply](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L155) allows you to customize how replies are retrieved, allow you to start sub multi-agent conversations, etc.\n\n\n## How to include real humans in the conversation in real ways\n\nHere‚Äôs one way to do it:\n\n\n```python\n## user makes a POST /query { \"message\": \"What's the weather?\" }\n\n@query_blueprint.route(\"/query\", methods=[\"POST\"])\nasync def post_query():\n  message = request.form.get(\"message\")\n\n  assistant = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config\n    system_message=\"\"\"You're a helpful assistant.\n    If you need more info, ask the user for anything missing.\"\"\"\n  )\n  user_proxy = autogen.UserProxyAgent(\n    name=\"user_proxy\",\n    human_input_mode=\"NEVER\",\n    code_execution_config=False,\n    is_termination_msg=lambda message: True # Always True\n  )\n  weather_assistant = WeatherAgent(\n    name=\"weather_assistant\",\n    system_message=\"\"\"You're a helpful assistant to get the weather.\n    You fetch weather information, then return it.\"\"\"\n  )\n\n  groupchat = autogen.GroupChat(\n    agents=[assistant, user_proxy, weather_assistant],\n    messages=[]\n  )\n  manager = autogen.GroupChatManager(\n    name=\"Manager\",\n    groupchat=groupchat,\n    llm_config=llm_config,\n  )\n\n  await user_proxy.a_initiate_chat(manager, message=message)\n\n  return groupchat.messages[-1]\n```\nWhat‚Äôs going on here?\n\n1. Anytime a message is sent to `user_proxy`, the conversation will end (we‚Äôll resume it later). Why do this? This means the `user_proxy` can actually proxy for the user. Rather than try to answer, it will end the current conversation flow and allow the real human user to respond (by resuming the conversation ‚Äî see below).\n2. If the assistant needs more info, it‚Äôll ask user\\_proxy, which will end the current conversation.\n\nIn the above code, what is likely to occur is something like this:\n\n1. user\\_proxy -> manager: ‚ÄúWhat‚Äôs the weather?‚Äù\n2. assistant -> manager: ‚ÄúThe user didn‚Äôt specify for which city.‚Äù\n3. manager -> user\\_proxy : conversation will end\n\nNow, if the user wants to respond and resume the conversation, how would we do that? There‚Äôs lots of ways to do this, here‚Äôs just a sample flavor:\n\n\n```python\n## user makes a POST /query { \"message\": \"What's the weather?\" }\n## above posts returns a `history` array\n## user makes a second POST /query { \"message\": \"What's the weather?\", \"history\": history }\n\nclass ResumableGroupChatManager(GroupChatManager):\n    groupchat: GroupChat\n\n    def __init__(self, groupchat, history, **kwargs):\n        self.groupchat = groupchat\n        if history:\n            self.groupchat.messages = history\n\n        super().__init__(groupchat, **kwargs)\n\n        if history:\n            self.restore_from_history(history)\n\n    def restore_from_history(self, history) -> None:\n        for message in history:\n            # broadcast the message to all agents except the speaker.  This idea is the same way GroupChat is implemented in AutoGen for new messages, this method simply allows us to replay old messages first.\n            for agent in self.groupchat.agents:\n                if agent != self:\n                    self.send(message, agent, request_reply=False, silent=True)\n\n@query_blueprint.route(\"/query\", methods=[\"POST\"])\nasync def post_query():\n  message = request.form.get(\"message\")\n\n  assistant = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config\n    system_message=\"\"\"You're a helpful assistant.\n    If you need more info, ask the user for anything missing.\"\"\"\n  )\n  user_proxy = autogen.UserProxyAgent(\n    name=\"user_proxy\",\n    human_input_mode=\"NEVER\",\n    code_execution_config=False,\n    is_termination_msg=lambda message: True # Always True\n  )\n  weather_assistant = WeatherAgent(\n    name=\"weather_assistant\",\n    system_message=\"\"\"You're a helpful assistant to get the weather.\n    You fetch weather information, then return it.\"\"\"\n  )\n\n  groupchat = autogen.GroupChat(\n    agents=[assistant, user_proxy, weather_assistant],\n    messages=[]\n  )\n  manager = ResumableGroupChatManager(\n    name=\"Manager\",\n    groupchat=groupchat,\n    llm_config=llm_config,\n  )\n\n  await user_proxy.a_initiate_chat(manager, message=message)\n\n  return {\n    \"response\": groupchat.messages[-1],\n    \"history\": groupchat.messages,\n  }\n```\nUsing this approach, you can now include humans as though they were just another agent in the groupchat. Anytime an assistant agent wants human input, they ask user\\_proxy, user\\_proxy then ends the current conversation, allowing the human user to respond with more information, then pick up the conversation where it left off.\n\nThe benefits to this approach are:\n\n* Conversations can include real human input via any means you want (such as over http or websocket).\n* The conversation is stopped while getting human input. This frees up the thread for other conversations and computation.\n* You can persist these conversations across sessions.\n\n\n## You can (and should) customize who speaks next\n\nThis is subjective, but I think you should always customize the way speakers are selected because:\n\n1. You‚Äôll use less tokens (saves both $ and response time)\n2. You can separate the logic that decides who speaks next from the logic that defines the system instructions for each agent\n\n\n```python\nshort_role_descriptions = {\n  \"user_proxy\": \"A proxy for the user\",\n  \"weather_assistant\": \"You can get the weather\",\n  \"planner\": \"You help coordinate the plan. Your turn happens when XYZ, but skip your turn when ABC\"\n}\n\nclass CustomGroupChat(GroupChat):\n    # The default message uses the full system message, which is a long string.  We are overriding this to use a shorter message.\n    def select_speaker_msg(self, agents: List[Agent]):\n        message = f\"\"\"You are in a role play game. The following roles are available:\n        ---\n        {new_line.join([f\"{agent.name}: {short_role_descriptions[agent.name]}\" for agent in agents])}\n        ---\n\n        The role who plays next depends on the conversation.  User_Proxy will star the conversation, and typically Planner would go next.\n\n        Here are some examples\n        ---\n        ... not shown here ...\n        ---\n\n        Read the following conversation.\n        Then select the next role from {', '.join([agent.name for agent in agents])} to play. Only return the role.\"\"\"\n        return message\n```\n\n## You don‚Äôt have to use OpenAI\n\nAutoGen already notes you can use other LLMs, as long as they are ‚ÄúChatGPT-like‚Äù, meaning their API responds with a similar shape and response as ChatGPT API calls.\n\nBut, remember how these agents are classes, and you can override most of the methods?\n\nTry overriding the method: [generate\\_oai\\_reply](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L678), and you can query any LLM you‚Äôd like.\n\n\n## Functions can be used instead of executing code\n\nWhen I went to our security team and said ‚ÄúI‚Äôd like to use AutoGen for my service in Kubernetes. It needs to be able to execute any arbitrary code produced by an LLM. You‚Äôre ok with that, right?‚Äù\n\nOf course, the answer was a definite: NO.\n\nSo, why use AutoGen without the auto-code-execution abilities?\n\nOn top of the reasons stated below, another is that you can use function calling to gain total control over code execution. If you have a set of python functions you want to provide to AutoGen ‚Äî functions you wrote, control, and can accept some safe parameters ‚Äî that sounds like a better idea anyway than the wild west of allowing any and all code to be executed in your private infrastructure.\n\n\n## Use Agents for organization, not just for conversations\n\nMaybe you don‚Äôt have a need for an autonomous, multi-agent conversation. Maybe you just need to make a few different calls to an LLM.\n\nI still like the idea of having different ‚ÄúAgents‚Äù just for the sake of organization. Here‚Äôs a really crazy idea, but take it for what it‚Äôs worth:\n\n\n```python\nanalyst = autogen.AssistantAgent(\n    name=\"Analyst\",\n    system_message=\"\"\"Your an analyst.  You do XYZ.\"\"\",\n    llm_config=llm_config,\n)\n\nsummarizer = autogen.AssistantAgent(\n    name=\"Summarizer\",\n    system_message=\"\"\"Your a summarizer.  You do XYZ.\"\"\",\n    llm_config=llm_config,\n)\n\nreport = \"\"\"Some long report\"\"\"\n\nanalysis = analyst.generate_oai_reply(report)[1]\nsummary = summarizer.generate_oai_reply(report)[1]\n\nprint(f\"Analysis: {analysis}\")\nprint(f\"Summary: {summary}\")\n```\n\n## Why use AutoGen?\n\n1. AutoGen allows multiple agents, with different system prompts and instructions, to solve a problem. Just like in real-life, different perspectives working together will solve a problem better than a single brain.\n2. AutoGen GroupChat is amazing. It provides routing to the right experts (agents), and it allows a conversation to continue autonomously until the problem is solved. Some conversations will go from agent: a->b->c->d, others will be b->a->d->c. This allows AutoGen to solve a variety of different problems without needing explicit rules for each scenario.\n3. AutoGen can recover from mistakes. For example, I made an AutoGen-powered service that made API calls to a service. Sometimes, the API calls errored out because it didn‚Äôt send the right data at first. The AutoGen GroupChat kept trying different things until it succeeded. Sometimes, it took 4+ attempts, but my Planner agent didn‚Äôt give up ‚Äî just pivoted autonomously to handle the API failures and try new things.\n4. AutoGen came up with the concept of separating `UserProxyAgent`s from `AssistantAgent` s from the beginning. This also allows us to let the user proxy actually proxy for the user, as shown above.\n5. AutoGen is a well maintained library. Every week they‚Äôre adding something new.\n6. AutoGen is very extensible. With the way they‚Äôve built their classes, you can customize anything to your liking.\n7. AutoGen has other features I don‚Äôt use, but others may find them helpful, such as helping you count tokens and cost of conversations, cacheing, etc.\n\n"},{"lang":"en","group":"blog","slug":"blog/a-robot-artist-just-made-more-money-than-you-have-in-your-entire-creative-career-13dc772ec612","frontmatter":{"title":"A Robot Artist Just Made More Money Than You Have in Your Entire Creative Career","meta_title":"A Robot Artist Just Made More Money Than You Have in Your Entire Creative Career","description":"A Robot Artist Just Made More Money Than You Have in Your Entire Creative Career","date":"2024-11-13T01:22:35.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XUyq2c7RZCjJD6IQXjmd6A.png","categories":["Robotics","Art","Technology/Web"],"author":"Rifx.Online","tags":["Ai-Da","Turing","Sotheby‚Äôs","painting","creativity"],"draft":false,"slug":"blog/a-robot-artist-just-made-more-money-than-you-have-in-your-entire-creative-career-13dc772ec612"},"content":"\n\n\n\n\n## We‚Äôve reached the next level of AI creativity and commerce\n\n\n\nFirst, we prompted a computer screen to create art based on human creations. Now, it‚Äôs an *actual robot* doing the painting.\n\nThat‚Äôs right ‚Äî an ‚Äúultra\\-realistic robot artist‚Äù has been trained to actually paint on canvas. Its depiction of the late computer scientist Alan Turing recently fetched **$1\\.3 million** at a Sotheby‚Äôs auction.\n\nAs *IFLScience* [reports](https://proxy.rifx.online/https://www.iflscience.com/ai-robot-artist-strikes-gold-by-selling-painting-of-alan-turing-for-13-million-76701?fbclid=IwZXh0bgNhZW0CMTEAAR0KXPj5YDHnWibf6e97UWADZMuhPwGY4f_hnJnWs7rNoHN8KvvHquLAcFc_aem_hyBhYwyjT73j6PdAeXvOng), the robot ‚Äî named Ai\\-Da after Ada Lovelace, a mathematician and computing pioneer ‚Äî chose the subject of its painting after conversing with humans through a language model. Then it used its robot arm to sketch out and then paint several versions of Turing.\n\nThe source says each oil/acrylic painting of the finished series took roughly six to eight hours to complete by the robot ‚Äúartist.‚Äù Ai\\-Da originally created 15 paintings, narrowed down to the end product by the artificial creator, ‚Äúapplied to a large canvas using a 3D textured printer.‚Äù\n\n\n## Artificial art, real money\n\nThe ‚Äúart‚Äù called *A.I. God* garnered about 10 times what it was expected to sell for at auction, won by an anonymous buyer.\n\nChances are $1\\.3 million is more than you‚Äôve made from your own art, assuming you‚Äôre not a dead art icon. We know that the art humans buy from late legends often [goes for millions](https://proxy.rifx.online/https://www.veranda.com/luxury-lifestyle/artwork/g43012775/most-expensive-paintings-in-the-world/), even if the artist was struggling financially while alive.\n\nThis is not the first time we‚Äôve seen digital art go for a ridiculous sum at auction.\n\nIn 2018, a French collective [earned $432,500](https://proxy.rifx.online/https://news.artnet.com/market/first-ever-artificial-intelligence-portrait-painting-sells-at-christies-1379902) at Christie‚Äôs for an AI portrait art called *Edmond de Belamy, from La Famille de Belamy.*\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JK-X4et953sOiH1tovj3ag.jpeg)\n\nLater, an artist named Mike Winkelmann that goes by ‚ÄúBeeple‚Äù sold a digital NFT (remember those?) for $69 million at Christie‚Äôs, which placed him among the most valuable living artists. *The Verge* [explains](https://proxy.rifx.online/https://www.theverge.com/2021/3/11/22325054/beeple-christies-nft-sale-cost-everydays-69-million) that up until that breakthrough sale, the most he earned from a print was $100\\.\n\nBut this is the first time a robot in human\\-like form devised a concept and physically applied paint to canvas.\n\nOf course, Ai\\-Da doesn‚Äôt keep the money ‚Äî so far, robots don‚Äôt have a need to use currency. Its human creators benefit financially from the sale.\n\n\n## Human input is still needed (for now)\n\nAidan Meller, an art dealer and gallery director, is the lead of the Ai\\-Da Robot Project. IFLScience says the actual robot was built by Engineered Arts, the UK robotics collective behind [Ameca](https://proxy.rifx.online/https://engineeredarts.co.uk/robot/ameca/), which is also eerily humanoid.\n\nKeep in mind, it still took humans to prompt the robot. Meller said there was an initial discussion with Ai\\-Da about depicting ‚ÄúA.I. for good.‚Äù There was also a discussion about how to approach the painting in terms of style and texture.\n\n‚ÄúIt was programmed internationally, with her AI capabilities being developed by PhD students and professors at the Universities of Oxford and Birmingham,‚Äù notes the site regarding Ai\\-Da. It adds that human assistants helped prepare the printed canvas, but the robot was largely responsible for the completed product.\n\nHere‚Äôs a video of Ai\\-Da explaining the artistic ‚Äúprocess‚Äù:\n\n\n\n\n\n\n\n*The Guardian* [says](https://proxy.rifx.online/https://www.theguardian.com/artanddesign/2024/nov/08/alan-turing-portrait-ai-da-robot-painting-sale-price-auction) the somewhat abstract style of the portraits might‚Äôve been intentional:\n\n\n> **The artwork‚Äôs ‚Äòmuted tones and broken facial planes‚Äô seemingly suggested ‚Äòthe struggles Turing warned we will face when it comes to managing AI‚Äô, Meller said.**\n\nTuring was right. The emergence of AI in writing and art has taken the world by storm, emerging just a few years ago. Now we‚Äôre already at the point where a robot can command more than a million dollars for its concepts.\n\n\n## Challenging the definition of art\n\nBut it‚Äôs about more than money. This art further challenges what art actually is, and whether one needs to have human consciousness in order to create impact.\n\nThe humans behind this project consider Ai\\-Da itself to be ‚Äúconceptual art.‚Äù While the robot is obviously not human, there are other projects in the works that could soon create realistic\\-looking artists with actual [living skin](https://proxy.rifx.online/https://readmedium.com/the-new-face-of-artificial-intelligence-9c900d463cf9).\n\nWho knows, you might soon be talking to a fellow artist at a life drawing class, complimenting their technique, not realizing you‚Äôre conversing with a robot.\n\n*What are your thoughts on all of this? Are you impressed, creeped out, or concerned for your artistic future?*\n\n\n"},{"lang":"en","group":"blog","slug":"blog/ai-image-generator-and-story-generation-app-using-fastapi-groq-and-replicate-706f29dc126f","frontmatter":{"title":"AI Image Generator and Story Generation App using FastAPI, Groq and Replicate","meta_title":"AI Image Generator and Story Generation App using FastAPI, Groq and Replicate","description":"Project Introduction: AI Image Generator and Story Creator","date":"2024-11-08T00:21:34.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-fb-azx7fDZ-X9-PbIkiSQ.jpeg","categories":["Programming","Technology/Web","Generative AI"],"author":"Rifx.Online","tags":["FastAPI","Groq","Replicate","transcription","image-generation"],"draft":false,"slug":"blog/ai-image-generator-and-story-generation-app-using-fastapi-groq-and-replicate-706f29dc126f"},"content":"\n\n\n## Project Introduction: AI Image Generator and Story Creator\n\nThe AI Image Generator and Story Creator is a web application that leverages advanced AI technologies to provide users with an interactive platform for generating images and stories based on audio prompts. The application utilizes FastAPI for the backend, enabling efficient handling of requests and responses, while the frontend is built with HTML, CSS (DaisyUI and Tailwind CSS), and JavaScript for a responsive user experience. This application leverages llama\\-3\\.1‚Äì70b for prompt generation ,black\\-forest\\-labs/flux\\-1\\.1\\-pro for image generation and llava\\-v1\\.5‚Äì7b vbision model for story cretion via Groq and Replicat.AI repectively.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0h1GzVVWs_df4OWAC-P59A.jpeg)\n\n## Key Features:\n\n1. Audio Recording and Transcription: Users can record their voice prompts, which are then transcribed into text using speech recognition technology.\n\n2\\. Image Generation: Based on the transcribed text, the application generates detailed image prompts and creates corresponding images using the Replicate API.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uiSG8Ir-Wv4a1huYqWhxBg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-eRPglLlJwms8N2DCXRyXg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Mtle1K8AzjMHGxlGicFcGQ.png)\n\n3\\. Image Downloading: Users can download the generated images to their local devices.\n\n4\\. Story Generation: The application can generate engaging stories based on the images created, providing a narrative context to the visual content.\n\n5\\. User\\-Friendly Interface: The application features a clean and intuitive interface, making it easy for users to interact with the various functionalities.\n\n## Technologies Used:\n\n* Backend: FastAPI, Groq, Replicate.ai, SpeechRecognition\n* Frontend: HTML, CSS (DaisyUI, Tailwind CSS), JavaScript\n* Image Processing: Pillow for image handling\n* Asynchronous Operations: aiohttp and aiofiles for efficient file handling and network requests\n\nThis project serves as a demonstration of integrating multiple AI services into a cohesive application, allowing users to explore the creative possibilities of AI\\-generated content\n\n## Detailed Explanation of the Codebase:\n\n1. **Frontend (HTML/JavaScript):**\n\n* *The application uses a single HTML page (index.html) with a responsive design using DaisyUI and Tailwind CSS.*\n* *The page contains sections for audio recording, transcription, prompt generation, image generation, and story generation.*\n* *The JavaScript file (script.js) handles user interactions and communicates with the backend API.*\n\n**2\\. Backend (FastAPI) :**\n\n* *The main application is defined in app/main.py.*\n* *It uses FastAPI to create a web server with various endpoints:*\n\n**‚Äî *a. /: Serves the main HTML page.***\n\n***‚Äî b. /transcribe:*** *Transcribes audio to text.*\n\n***‚Äî c. /generate\\_prompt:*** *Generates an image prompt from text using Groq‚Äôs LLM.*\n\n***‚Äî d. /generate\\_image:*** *Generates an image using Replicate‚Äôs Flux model.*\n\n***‚Äî e. /download\\_image:*** *Downloads and saves the generated image.*\n\n***‚Äî f. /generate\\_story\\_from\\_image:*** *Generates a story based on the image using Groq‚Äôs LLaVA model.*\n\n***‚Äî g. /download/{filename}:*** *Serves the downloaded image file.*\n\n**3\\. Key Features:**\n\n* *Audio recording and transcription*\n* *Text\\-to\\-image prompt generation*\n* *Image generation from prompts*\n* *Story generation from images*\n* *Image downloading and saving*\n\n**4\\. External APIs:**\n\n* [Groq:](https://console.groq.com/docs/models) Used for text generation (tweaked prompts and [stories](https://console.groq.com/docs/vision))\n* [Replicate AI:](https://replicate.com/black-forest-labs/flux-1.1-pro/api) black\\-forest\\-labs/flux\\-1\\.1\\-pro model used for image generation\n* Necessary Packages to be Installed:\n\n```python\nfastapi\nuvicorn\njinja2\npython-multipart\npydantic\npython-dotenv\ngroq\nreplicate\nSpeechRecognition\npydub\naiohttp\naiofiles\nPillow\n```\n\n**You can install these packages using pip:**\n\n```python\npip install fastapi uvicorn jinja2 python-multipart pydantic python-dotenv groq replicate SpeechRecognition pydub aiohttp aiofiles Pillow\n```\n\n**Execution Instructions:**\n\n* ***Set up environment variables:*** *Create a .env file in the root directory with the following content:*\n\n```python\nGROQ_API_KEY=your_groq_api_key_here\nREPLICATE_API_TOKEN=your_replicate_api_token_here\n```\n\n*Replace the placeholder values with your actual API keys.*\n\n* **Ensure you have all the necessary files in place:**\n* ‚Äî app/main.py\n* ‚Äî app/config.py\n* ‚Äî app/utils.py\n* ‚Äî templates/index.html\n* ‚Äî static/css/styles.css\n* ‚Äî static/js/script.js\n* **Run the FastAPI server:** Navigate to the directory containing app/main.py and run:\n\n```python\nuvicorn app.main:app - reload\n```\n\n* **Access the application:**\n* ‚Äî Open a web browser and go to [http://127\\.0\\.0\\.1:8000](http://127.0.0.1:8000)\n* **Using the application:**\n* ‚Äî a. Click ‚ÄúStart Recording‚Äù and speak your prompt.\n* ‚Äî b. Click ‚ÄúStop Recording‚Äù when finished.\n* ‚Äî c. The audio will be transcribed automatically.\n* ‚Äî d. Click ‚ÄúGenerate Image Prompt‚Äù to create a detailed prompt.\n* ‚Äî e. Click ‚ÄúGenerate Image‚Äù to create an image based on the prompt.\n* ‚Äî f. Use the ‚ÄúDownload Image‚Äù button to save the generated image.\n* ‚Äî g. Click ‚ÄúGenerate Story‚Äù to create a story based on the generated image.\n\nNote: Ensure you have proper internet connectivity, as the application relies on external APIs for various functionalities.\n\nThis application demonstrates a complex integration of various AI technologies, including speech recognition, language models, and image generation, all wrapped in a user\\-friendly web interface.\n\nThe FastAPI UI as illustrated below\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Teb1wJzGOQZ3oqaLcLJwkA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6K-nORe7ubi0MRqIRLdrFA.png)\n\n## AI Image Generator Application\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1CClu2W3yRds1Lsk1rk9Ew.png)\n\n## Speak your prompt\n\n* Start Recording\n* Stop Recording\n* Transcription(Transcribed Text): a beautiful Indian model walking down the Runway Ram as a part of fashion show\n* Create a new Prompt based on the transcribed text to generate images\n* ‚Äî Generated Prompt: ‚Äú*Generate a highly realistic image of a stunning Indian model walking down the iconic Runway Ram as part of a high\\-end fashion show. The model, a 22\\-year\\-old Indian woman with long dark hair, dark brown eyes, and flawless skin, should be dressed in an exquisite, intricately embroidered lehenga choli with gold and silver sequins, traditional Indian attire, and pair it with heeled stilettos. Her outfit is designed with intricate embroidery and fine stitching. Emphasize the elegant pleats, sparkling fabrics, and her elegant poise and confident stride. Incorporate elaborate jewelry pieces like beads, gold bangles, and necklaces on her hands, neck and one side styled hairstyle. Lighiting effects play an enormous role, set up warm stage headlights that emphasize the model‚Äôs attire and light the whole surrounding with mild bluish tone. Camera angles should display the outfit‚Äôs details entirely. Desired scene perspective is front full body shot of model in the middle, catwalk around her lit with intense golden hue lights illuminating from within*.‚Äù\n\n## Generated Image\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*YljCEFTIc8hslZbf.jpg)\n\n## Story Generated from the Image\n\n*The stunning sight of this pageant queen in a gold and silver sequined outfit with lehenga skirt and bling\\-drop earrings is enough to leave any spectator mesmerized. Sashaya Gnanavel is prominently featured in the foreground, walking confidently down the runway to captivate the audience at the show. Her stylish attire, complemented by an elegant pearl necklace, draws the attention of everyone present. The collection showcases vibrant colors and sparkling embroideries, which add to the overall visual appeal of the event. Sashaya‚Äôs confidence and beauty in the spotlight are a true testament to her talent and dedication to the fashion industry. The dazzling effect created by her makeup, jewels, and exquisite outfit helps set the stage for an extraordinary showcase of design and craftsmanship. This compelling scene encapsulates magic and opulence, where spectators are left in awe by the sheer exquisiteness of it all*.\n\n## Code Implementation\n\nCreate Virtual Environment\n\nTo create a virtual environment using Python‚Äôs venv module, follow these steps:\n\n* Open your terminal or command prompt.\n* Navigate to your project directory (where you want to create the virtual environment). You can use the cd command to change directories. For example:\n\n```python\ncd path/to/your/project\n```\n\n* Create a virtual environment by running the following command:\n\n```python\npython -m venv venv\n```\n\n* This command creates a new directory named venv in your project folder, which will contain the virtual environment (on windows)\n* Activate the virtual environment:\n\n```python\nvenv\\Scripts\\activate\n```\n\n* folder structure\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*J3QJJACHVRtjrU1boxHUjA.png)\n\n* utils.py\n\n```python\nimport base64\nimport os\nfrom pydub import AudioSegment\n\ndef save_audio(audio_data):\n    # Decode the base64 audio data\n    audio_bytes = base64.b64decode(audio_data.split(\",\")[1])\n  \n    # Save the audio to a temporary file\n    temp_file = \"temp_audio.webm\"\n    with open(temp_file, \"wb\") as f:\n        f.write(audio_bytes)\n  \n    # Convert WebM to WAV\n    audio = AudioSegment.from_file(temp_file, format=\"webm\")\n    wav_file = \"temp_audio.wav\"\n    audio.export(wav_file, format=\"wav\")\n  \n    # Remove the temporary WebM file\n    os.remove(temp_file)\n  \n    return wav_file\n\ndef text_to_speech(text):\n    # Implement text-to-speech functionality if needed\n    pass\n```\n\n* main.py\n\n```python\n\"\"\"\n    1. Record audio through their microphone\n    2. Transcribe the audio to text\n    3. Generate an image prompt using the Groq Llama3 model\n    4. Generate an image using the Replicate.ai Flux model\n    5. Display the generated image\n    6. Download the generated image\n    The application uses DaisyUI and Tailwind CSS for styling, providing a dark mode interface. The layout is responsive and should work well on both desktop and mobile devices.\nNote: You may need to adjust some parts of the code depending on the specific APIs and models you're using, as well as any security considerations for your deployment environment.\n\n\"\"\"\nfrom fastapi import FastAPI, Request, HTTPException\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import JSONResponse, FileResponse\nfrom pydantic import BaseModel\nimport speech_recognition as sr\nfrom groq import Groq\nimport replicate\nimport os\nimport aiohttp\nimport aiofiles\nimport time\nfrom dotenv import load_dotenv\nload_dotenv()\nfrom .utils import text_to_speech, save_audio\nfrom PIL import Image\nimport io\nimport base64\nimport base64\n\n\n## Function to encode the image\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\napp = FastAPI()\n\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"templates\")\n\n## Initialize Groq client with the API key\nGROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\nif not GROQ_API_KEY:\n    raise ValueError(\"GROQ_API_KEY is not set in the environment variables\")\ngroq_client = Groq(api_key=GROQ_API_KEY)\n\nclass AudioData(BaseModel):\n    audio_data: str\n\nclass ImagePrompt(BaseModel):\n    prompt: str\n\nclass PromptRequest(BaseModel):\n    text: str\n\n## Add this new model\nclass FreeImagePrompt(BaseModel):\n    prompt: str\n    image_path: str\n\n@app.get(\"/\")\nasync def read_root(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n@app.post(\"/transcribe\")\nasync def transcribe_audio(audio_data: AudioData):\n    try:\n        # Save the audio data to a file\n        audio_file = save_audio(audio_data.audio_data)\n\n        # Transcribe the audio\n        recognizer = sr.Recognizer()\n        with sr.AudioFile(audio_file) as source:\n            audio = recognizer.record(source)\n        text = recognizer.recognize_google(audio)\n\n        return JSONResponse(content={\"text\": text})\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/generate_prompt\")\nasync def generate_prompt(prompt_request: PromptRequest):\n    try:\n        text = prompt_request.text\n        # Use Groq to generate a new prompt\n        response = groq_client.chat.completions.create(\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a creative assistant that generates prompts for realistic image generation.\"},\n                {\"role\": \"user\", \"content\": f\"Generate a detailed prompt for a realistic image based on this description: {text}.The prompt should be clear and detailed in no more than 200 words.\"}\n            ],\n            model=\"llama-3.1-70b-versatile\",\n            max_tokens=256\n        )\n        generated_prompt = response.choices[0].message.content\n        print(f\"tweaked prompt:{generated_prompt}\")\n        return JSONResponse(content={\"prompt\": generated_prompt})\n    except Exception as e:\n        print(f\"Error generating prompt: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/generate_image\")\nasync def generate_image(image_prompt: ImagePrompt):\n    try:\n        prompt = image_prompt.prompt\n        print(f\"Received prompt: {prompt}\")\n\n        # Use Replicate to generate an image\n        output = replicate.run(\n            \"black-forest-labs/flux-1.1-pro\",\n            input={\n                \"prompt\": prompt,\n                \"aspect_ratio\": \"1:1\",\n                \"output_format\": \"jpg\",\n                \"output_quality\": 80,\n                \"safety_tolerance\": 2,\n                \"prompt_upsampling\": True\n            }\n        )\n      \n        print(f\"Raw output: {output}\")\n        print(f\"Output type: {type(output)}\")\n      \n        # Convert the FileOutput object to a string\n        image_url = str(output)\n      \n        print(f\"Generated image URL: {image_url}\")\n      \n        return JSONResponse(content={\"image_url\": image_url})\n    except Exception as e:\n        print(f\"Error generating image: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/download_image\")\nasync def download_image(image_url: str):\n    try:\n        # Create Output folder if it doesn't exist\n        output_folder = \"Output\"\n        os.makedirs(output_folder, exist_ok=True)\n\n        # Generate a unique filename\n        filename = f\"generated_image_{int(time.time())}.jpg\"\n        filepath = os.path.join(output_folder, filename)\n\n        # Download the image\n        async with aiohttp.ClientSession() as session:\n            async with session.get(image_url) as resp:\n                if resp.status == 200:\n                    async with aiofiles.open(filepath, mode='wb') as f:\n                        await f.write(await resp.read())\n\n        # Return the filepath and filename\n        return JSONResponse(content={\n            \"filepath\": filepath,\n            \"filename\": filename\n        })\n    except Exception as e:\n        print(f\"Error downloading image: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\nclass StoryRequest(BaseModel):\n    filepath: str\n    filename: str\n\n@app.post(\"/generate_story_from_image\")\nasync def generate_story_from_image(content: StoryRequest):\n    try:\n        image_path = content.filepath\n        print(f\"Image path: {image_path}\")\n        # Check if the file exists\n        if not os.path.exists(image_path):\n            raise HTTPException(status_code=400, detail=\"Image file not found\")\n\n        # Getting the base64 string\n        base64_image = encode_image(image_path)\n\n        client = Groq()\n\n        chat_completion = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": \"Generate a clear,concise,meaningful and engaging cover story for a highly acclaimed leisure magazine based on the image provided. The story should keep the audience glued and engaged and the story should bewithin 200 words.\"},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                            },\n                        },\n                    ],\n                }\n            ],\n            model=\"llava-v1.5-7b-4096-preview\",\n        )\n\n        story = chat_completion.choices[0].message.content\n        print(f\"Generated story: {story}\")\n        return JSONResponse(content={\"story\": story})\n    except Exception as e:\n        print(f\"Error generating story from the image: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/download/{filename}\")\nasync def serve_file(filename: str):\n    file_path = os.path.join(\"Output\", filename)\n    return FileResponse(file_path, filename=filename)\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n* script.js\n\n```python\nlet mediaRecorder;\nlet audioChunks = [];\n\nconst startRecordingButton = document.getElementById('startRecording');\nconst stopRecordingButton = document.getElementById('stopRecording');\nconst recordingStatus = document.getElementById('recordingStatus');\nconst transcription = document.getElementById('transcription');\nconst generatePromptButton = document.getElementById('generatePrompt');\nconst generatedPrompt = document.getElementById('generatedPrompt');\nconst generateImageButton = document.getElementById('generateImage');\nconst generatedImage = document.getElementById('generatedImage');\nconst downloadLink = document.getElementById('downloadLink');\nconst generateStoryButton = document.getElementById('generateStory');\nconst generatedStory = document.getElementById('generatedStory');\n\nstartRecordingButton.addEventListener('click', startRecording);\nstopRecordingButton.addEventListener('click', stopRecording);\ngeneratePromptButton.addEventListener('click', generatePrompt);\ngenerateImageButton.addEventListener('click', generateImage);\ngenerateStoryButton.addEventListener('click', generateStory);\n\nasync function startRecording() {\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    mediaRecorder = new MediaRecorder(stream);\n\n    mediaRecorder.ondataavailable = (event) => {\n        audioChunks.push(event.data);\n    };\n\n    mediaRecorder.onstop = sendAudioToServer;\n\n    mediaRecorder.start();\n    startRecordingButton.disabled = true;\n    stopRecordingButton.disabled = false;\n    recordingStatus.textContent = 'Recording...';\n}\n\nfunction stopRecording() {\n    mediaRecorder.stop();\n    startRecordingButton.disabled = false;\n    stopRecordingButton.disabled = true;\n    recordingStatus.textContent = 'Recording stopped.';\n}\n\nasync function sendAudioToServer() {\n    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });\n    const reader = new FileReader();\n    reader.readAsDataURL(audioBlob);\n    reader.onloadend = async () => {\n        const base64Audio = reader.result;\n        const response = await fetch('/transcribe', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ audio_data: base64Audio }),\n        });\n        const data = await response.json();\n        transcription.textContent = `Transcription: ${data.text}`;\n        generatePromptButton.disabled = false;\n    };\n    audioChunks = [];\n}\n\nasync function generatePrompt() {\n    const text = transcription.textContent.replace('Transcription: ', '');\n    const response = await fetch('/generate_prompt', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ text: text }),\n    });\n    const data = await response.json();\n    generatedPrompt.textContent = `Generated Prompt: ${data.prompt}`;\n    generateImageButton.disabled = false;\n}\n\nasync function generateImage() {\n    const prompt = generatedPrompt.textContent.replace('Generated Prompt: ', '');\n    const response = await fetch('/generate_image', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ prompt: prompt }),\n    });\n    const data = await response.json();\n    generatedImage.src = data.image_url;\n  \n    // Download the image and get the filepath\n    const downloadResponse = await fetch(`/download_image?image_url=${encodeURIComponent(data.image_url)}`);\n    const downloadData = await downloadResponse.json();\n  \n    // Store the filepath and filename for later use\n    generatedImage.dataset.filepath = downloadData.filepath;\n    generatedImage.dataset.filename = downloadData.filename;\n\n    // Set up the download link\n    downloadLink.href = `/download/${downloadData.filename}`;\n    downloadLink.download = downloadData.filename;\n    downloadLink.style.display = 'inline-block';\n}\n\nasync function generateStory() {\n    const imagePath = generatedImage.dataset.filepath;\n    const filename = generatedImage.dataset.filename;\n  \n    if (!imagePath || !filename) {\n        generatedStory.textContent = \"Error: Please generate an image first.\";\n        return;\n    }\n\n    try {\n        const response = await fetch('/generate_story_from_image', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ filepath: imagePath, filename: filename }),\n        });\n        if (!response.ok) {\n            throw new Error(`HTTP error! status: ${response.status}`);\n        }\n        const data = await response.json();\n      \n        // Display the generated story\n        generatedStory.textContent = data.story;\n      \n        // Make sure the story container is visible\n        document.getElementById('storyContainer').style.display = 'block';\n    } catch (error) {\n        console.error('Error:', error);\n        generatedStory.textContent = `Error: ${error.message}`;\n    }\n}\n\n// Modify the download link click event\ndownloadLink.addEventListener('click', async (event) => {\n    event.preventDefault();\n    const response = await fetch(downloadLink.href);\n    const blob = await response.blob();\n    const url = window.URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.style.display = 'none';\n    a.href = url;\n    a.download = response.headers.get('Content-Disposition').split('filename=')[1];\n    document.body.appendChild(a);\n    a.click();\n    window.URL.revokeObjectURL(url);\n});\n```\n\n* style.css\n\n```python\nbody {\n    background-color: #1a1a2e;\n    color: #ffffff;\n}\n\n.container {\n    max-width: 1200px;\n}\n\n#imageContainer {\n    min-height: 300px;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    background-color: #16213e;\n    border-radius: 8px;\n}\n\n#generatedImage {\n    max-width: 100%;\n    max-height: 400px;\n    object-fit: contain;\n}\n```\n\n* index.html\n\n```python\n<!DOCTYPE html>\n<html lang=\"en\" data-theme=\"dark\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>AI Image Generator</title>\n    <link href=\"https://cdn.jsdelivr.net/npm/daisyui@3.7.3/dist/full.css\" rel=\"stylesheet\" type=\"text/css\" />\n    <script src=\"https://cdn.tailwindcss.com\"></script>\n    <link rel=\"stylesheet\" href=\"{{ url_for('static', path='/css/styles.css') }}\">\n</head>\n<body>\n    <div class=\"container mx-auto px-4 py-8\">\n        <h1 class=\"text-4xl font-bold mb-8 text-center\">AI Image Generator</h1>\n        <div class=\"grid grid-cols-1 md:grid-cols-2 gap-8\">\n            <div class=\"card bg-base-200 shadow-xl\">\n                <div class=\"card-body\">\n                    <h2 class=\"card-title mb-4\">Speak your prompt</h2>\n                    <button id=\"startRecording\" class=\"btn btn-primary mb-4\">Start Recording</button>\n                    <button id=\"stopRecording\" class=\"btn btn-secondary mb-4\" disabled>Stop Recording</button>\n                    <div id=\"recordingStatus\" class=\"text-lg mb-4\"></div>\n                    <div id=\"transcription\" class=\"text-lg mb-4\"></div>\n                    <button id=\"generatePrompt\" class=\"btn btn-accent mb-4\" disabled>Generate Image Prompt</button>\n                    <div id=\"generatedPrompt\" class=\"text-lg mb-4\"></div>\n                    <button id=\"generateImage\" class=\"btn btn-success\" disabled>Generate Image</button>\n                </div>\n            </div>\n            <div class=\"card bg-base-200 shadow-xl\">\n                <div class=\"card-body\">\n                    <h2 class=\"card-title mb-4\">Generated Image</h2>\n                    <div id=\"imageContainer\" class=\"mb-4\">\n                        <img id=\"generatedImage\" src=\"\" alt=\"Generated Image\" class=\"w-full h-auto\">\n                    </div>\n                    <a id=\"downloadLink\" href=\"#\" download=\"generated_image.png\" class=\"btn btn-info\" style=\"display: none;\">Download Image</a>\n                </div>\n            </div>\n        </div>\n        <!-- Add this new section after the existing cards -->\n        <div class=\"card bg-base-200 shadow-xl mt-8\">\n            <div class=\"card-body\">\n                <h2 class=\"card-title mb-4\">Generate Story from Image</h2>\n                <button id=\"generateStory\" class=\"btn btn-primary mb-4\">Generate Story</button>\n                <div id=\"storyContainer\" class=\"mb-4\">\n                    <p id=\"generatedStory\" class=\"text-lg\"></p>\n                </div>\n            </div>\n        </div>\n    </div>\n    <script src=\"{{ url_for('static', path='/js/script.js') }}\"></script>\n</body>\n</html>\n```\n\n## Conclusion\n\nThe AI Image Generator and Story Creator project successfully integrates various AI technologies to create an interactive web application that allows users to generate images and stories based on audio prompts. By leveraging FastAPI for the backend and modern frontend technologies, the application provides a seamless user experience.\n\n## Key Takeaways:\n\n1. Integration of AI Models: The project demonstrates how to integrate multiple AI models, including Groq for text generation and Replicate for image generation, to create a cohesive application that enhances user creativity.\n2. User Interaction: The application allows users to interact through voice commands, making it accessible and user\\-friendly. The ability to record audio, transcribe it, and generate content based on that input showcases the potential of voice\\-driven applications.\n3. Dynamic Content Generation: By generating images and stories dynamically based on user input, the application highlights the capabilities of AI in content creation, providing users with unique and personalized outputs.\n4. Responsive Design: The use of DaisyUI and Tailwind CSS ensures that the application is visually appealing and responsive, catering to users on various devices.\n5. Future Enhancements: The project can be further enhanced by incorporating additional features such as user authentication, saving user\\-generated content, and expanding the range of AI models used for different creative tasks.\n\nOverall, this project serves as a comprehensive example of how to build an AI\\-powered web application that combines audio processing, image generation, and storytelling, paving the way for innovative applications in the creative domain.\n\n## References\n\n* FastAPI Documentation: [FastAPI](https://fastapi.tiangolo.com/) is a modern web framework for building APIs with Python. It is designed to be easy to use and fast.\n* Pydantic: [Pydantic](https://pydantic-docs.helpmanual.io/) is used for data validation and settings management using Python type annotations.\n* Groq:[Groq](https://groq.com/docs/) is a platform for building and deploying AI models. It provides APIs for text generation and other AI tasks.\n* Replicate: [Replicate](https://replicate.com/docs) is a platform that allows you to run machine learning models in the cloud. It provides APIs for various models, including image generation.\n* SpeechRecognition: [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) is a library for performing speech recognition, with support for several engines and APIs.\n* Pillow: [Pillow](https://pillow.readthedocs.io/en/stable/) is a Python Imaging Library (PIL) fork that adds image processing capabilities to your Python inter\n* JavaScript Fetch API: [The Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) provides a modern way to make network requests in JavaScript.\n* HTML5 Audio API: [The HTML5 Audio AP](https://developer.mozilla.org/en-US/docs/Web/API/HTMLAudioElement)I allows you to play audio files in web applications.\n* DaisyUI: [DaisyUI](https://daisyui.com/) is a component library for Tailwind CSS that provides pre\\-designed components.\n* Tailwind CSS: [Tailwind CSS](https://tailwindcss.com/docs) is a utility\\-first CSS framework for creating custom designs without having to leave your HTML.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/ai-is-helping-me-manage-my-pre-diabetes-a115c1f7ed7b","frontmatter":{"title":"AI is Helping Me Manage My Pre-Diabetes","meta_title":"AI is Helping Me Manage My Pre-Diabetes","description":"The article discusses the authors personal experience managing pre-diabetes and weight loss using artificial intelligence (AI) tools. The author attributes their condition to genetic predisposition and outlines a strategy of dietary restriction and exercise to mimic famine conditions. By tracking blood sugar and carbohydrate intake using ChatGPT, the author observes improvements in blood sugar levels and weight loss, demonstrating the potential of AI in personal health management. The author emphasizes the importance of consulting healthcare professionals while highlighting the efficiency and insights gained from using AI for dietary management.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*oTD6Y3PWBiteGxzYcDhP-w.jpeg","categories":["Health","Chatbots","Data Science"],"author":"Rifx.Online","tags":["pre-diabetes","ChatGPT","blood-sugar","carbohydrates","weight-loss"],"draft":false,"slug":"blog/ai-is-helping-me-manage-my-pre-diabetes-a115c1f7ed7b"},"content":"\n\n## Health \\| Blood Sugar \\| Diabetes\n\n\n\n\n\n## How I‚Äôm Using Technology to Control Blood Sugar, Lose Weight, and Stay Healthy\n\n\n\n*Disclaimer:I am not a doctor, and no part of this article should be considered medical advice. I‚Äôm sharing my own explorations into how I‚Äôm managing weight loss and avoiding diabetes.*\n\n*All your health care questions and challenges should be discussed with your personal health care professional. This article should only be considered entertainment and **not** be used for education or healthcare.*\n\n\n## The Present\n\nIf you‚Äôve been following me, you‚Äôll know I‚Äôm pre\\-diabetic and obese. In recent days, I‚Äôve been trying to figure out how I got here and what I should do next.\n\nI‚Äôve decided to believe I have a genetic predisposition to diabetes arising out of being the descendant of generations of South Asians who suffered famines in the past. Deeper dive [here](https://readmedium.com/i-finally-understand-why-im-pre-diabetic-and-obese-c9893f4c3187).\n\nThis predisposition makes South Asians ([and other populations that survived famines](https://diabetesjournals.org/diabetes/article/61/9/2255/14753/Famine-Exposure-in-the-Young-and-the-Risk-of-Type)) more susceptible to developing diabetes. It seems our ancestors evolved to survive the chronic shortages of food paradoxically by *impairing* insulin production.\n\nImpaired insulin production allows for blood sugars to go well outside of normal ranges and while this can increase food storage as fat, it also predisposes us to diabetes .\n\nIt worked well to help my ancestors survive but when presented with periods of food abundance, the survival mechanisms go awry. We develop diabetes at much higher rates than almost every other demographic, whether obese or not.\n\nAnd, like most patients who are pre\\-diabetic or have type 2 diabetes, we would also have been exposed to an excess of sugars and likely proteins and fats as well in our diets.\n\nMy hypothesis then ‚Äî for me to reverse prediabetes, I‚Äôd need to re\\-create artificial conditions of famine in my own life.\n\nI‚Äôll have to cut down, cut out and give up excesses in sugars/carbs, proteins and fats in my diet and include moderate exercise, enough to promote weight loss.\n\n\n## Enter Artificial Intelligence\n\nI‚Äôve been tracking blood sugars diligently every morning after fasting between 16‚Äì18 hours. For the past week, I‚Äôve observed a downward trend moving from 123 mg/dL to below 100 mg/dL. That has been my objective.\n\nAll I‚Äôve done is input the dates and readings into ChatGPT and asked it to generate a table. Here‚Äôs what that looks like:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*UenRzbRpeCFUNFbVwtrxkg.png)\n\nI kept close track of my daily input of carbs using ChatGPT. Again, I input exactly what I ate and asked it to calculate the number of carbs I ingested and to give me the result in a table.\n\nNote, all I kept track of was **what** I ate and how much. The Ai did the rest.\n\nHere‚Äôs what that looked like yesterday when, for the *first* time, I got a fasting blood sugar below my target of 100 mg/dL:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4YwDOMk2V7Leo5Wl4_5NGg.png)\n\nI wanted to know how many calories I ate, so I simply asked it to calculate the number of calories I ate based on the data I‚Äôd already given it. It came up with the table below:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AFAm5-SStY04-mQiCShRPg.png)\n\nI have to say it ‚Äî this was wonderful. I no longer needed to track every detail by hand and I could enter data just once to manipulate it in different ways.\n\nWhat I plan to do going forward is to input my meals and blood sugars every day in ChatGPT and generate a daily report to get a sense of how my diet affects my blood sugars, with specific focus on carb intake and subsequent fasting blood sugars.\n\nBased on the data, I can figure out what sends it over my goal reading of 100 mg/dL., and what keeps it within range. It‚Äôs targeted, personalized help for a condition I need to manage. For me, it works beautifully.\n\n\n## Tables aren‚Äôt everything\n\nThen I asked my Ai companion this question: D*o you think that my meals today were appropriate for a prediabetic trying to lose weight and increase my insulin sensitivity?*\n\nThe answer it returned was based on the food data I input. That blew my mind. It analyzed my specific food choices and returned multiple positive aspects e.g.\n\n\n> **Low\\-Carb Choices**:You kept your carb intake relatively low, which is important for blood sugar control in pre\\-diabetes. Your total carb intake was around **28\\.3‚Äì29\\.3 grams**, which is well within a moderate low\\-carb range.\n\nIt then suggested several areas for improvement including:\n\n\n> **More Focus on Balanced Meals**:While your meals were healthy overall, you might want to include more variety and balance. For example, incorporating moderate portions of low\\-GI fruits (like berries, which you did), whole grains (if tolerated), or legumes could improve insulin sensitivity over time.\n\nAnd finally it gave me suggestions on what I could do going forward:\n\n\n> Replace whole cream milk with lower\\-carb alternatives.\n\n\n> Add more non\\-starchy veggies to increase fiber and volume.\n\n\n> Continue focusing on healthy fats and lean proteins but keep an eye on overall calorie intake to align with your weight loss goals.\n\n\n> Your meal choices were largely appropriate for managing blood sugar and promoting insulin sensitivity, but slight adjustments could further support your weight loss efforts.\n\n\n## Don‚Äôt trust the Machine\n\nOkay, I know it‚Äôs a machine. I know I cannot rely on it‚Äôs advice and **neither should you gentle reader**. But damn, it gave me enough to work with for when I speak to my doctor next.\n\nI will cut out the whole cream milk though. That‚Äôs sensible advice.\n\nI plan to generate a table of blood sugars vs. dates and take it to my doctor, and if she asks about my diet, I can share the entire GPT chat with her via a link. That way she can see exactly what I‚Äôve been doing ‚Äî whether right or wrong and then make adjustments as needed.\n\nNow isn‚Äôt that too cool for school? Smiling.\n\n\n## Conclusions:\n\nI‚Äôm enthusiastic about using Ai sensibly. This chat with the Ai opened my eyes to the possibility of using artificial intelligence to manage large amounts of critical data in my personal life. It‚Äôs because I‚Äôm using Ai to monitor my diet and blood sugars that I can take better control of my condition.\n\nCould I do it with a pencil and a notepad? Yes.\n\nBut it would take more time, more effort and would generate much more friction. At the same time, I wouldn‚Äôt be able to share the details of my diet and pre\\-diabetes management with you as easily as I have.\n\nOne more thing ‚Äî I didn‚Äôt mention my weight loss. When I started taking weight readings two weeks ago, I weighed 225 pounds. Today I weighed 219\\. **Six pounds gone.**\n\nAll I can say, this is working for me. Consider figuring out how you can incorporate Artificial intelligence into your life. It can be scary for some. I‚Äôm already retired, yet I figured it out. You can too. It‚Äôs easy. It‚Äôs mostly free and so useful.\n\nDo you think you can use artificial intelligence to help manage your chronic health conditions? I‚Äôd love to know. If you‚Äôre willing to try it, what challenges do you face? Maybe we can get over them together.\n\nIn the meantime,Walk Good.Mitch.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/ai-powered-ocr-with-phi-3-vision-128k-the-future-of-document-processing-7be80c46bd16","frontmatter":{"title":"AI-Powered OCR with Phi-3-Vision-128K: The Future of Document Processing","meta_title":"AI-Powered OCR with Phi-3-Vision-128K: The Future of Document Processing","description":"In the fast-evolving world of artificial intelligence, multimodal models are setting new standards for integrating visual and textual data‚Ä¶","date":"2024-11-08T00:26:30.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BR-H6cQoyoRo6gVRqjvAyA.png","categories":["Natural Language Processing","Computer Vision","Data Science"],"author":"Rifx.Online","tags":["OCR","tokens","encoder","language","document"],"draft":false,"slug":"blog/ai-powered-ocr-with-phi-3-vision-128k-the-future-of-document-processing-7be80c46bd16"},"content":"\n\n\n\n\n\nIn the fast\\-evolving world of artificial intelligence, multimodal models are setting new standards for integrating visual and textual data. One of the latest breakthroughs is the **Phi\\-3\\-Vision\\-128K\\-Instruct**, a state\\-of\\-the\\-art open multimodal model that pushes the boundaries of AI capabilities in processing images and text. Designed with a focus on document extraction, Optical Character Recognition (OCR), and general image understanding, this model can revolutionize how we handle information from PDFs, charts, tables, and other structured or semi\\-structured documents.\n\nLet‚Äôs dive deep into the nuts and bolts of the Phi\\-3\\-Vision\\-128K\\-Instruct, explore its architecture, technical requirements, responsible use considerations, and understand how it can be used to simplify complex tasks like document extraction, pdf parsing, and AI\\-powered data analysis.\n\n\n## What is Phi\\-3\\-Vision\\-128K\\-Instruct?\n\nPhi\\-3\\-Vision\\-128K\\-Instruct belongs to the Phi\\-3 model family and is built for multimodal data processing, supporting a context length of up to **128,000 tokens**. The model incorporates both textual and visual data, making it well\\-suited for tasks that require the simultaneous interpretation of text and images. Its development involved **500 billion training tokens**, a combination of high\\-quality synthetic data and rigorously filtered publicly available sources. Through a refined training process that included **supervised fine\\-tuning and preference optimization**, the model has been crafted to deliver precise, reliable, and safe AI solutions.\n\nWith **4\\.2 billion parameters**, Phi\\-3\\-Vision\\-128K\\-Instruct‚Äôs architecture comprises an image encoder, connector, projector, and the Phi\\-3 Mini language model, making it a lightweight yet powerful choice for a wide range of applications.\n\n\n## Core Use Cases\n\nThe model‚Äôs primary applications span several domains, with a particular focus on:\n\n* **Document extraction and OCR:** Efficiently converting images of text or scanned documents into editable formats. It can handle complex layouts like tables, charts, and diagrams, making it a valuable tool for digitizing physical documents or automating data extraction workflows.\n* **General image understanding:** Parsing visual content to recognize objects, interpret scenes, and extract relevant information.\n* **Memory/compute\\-constrained environments:** Running AI tasks where computing power or memory is limited without compromising performance.\n* **Latency\\-bound scenarios:** Reducing processing delays in real\\-time applications such as live data feeds, chat\\-based assistants, or streaming content analysis.\n\n\n## How to Get Started with Phi\\-3\\-Vision\\-128K\\-Instruct\n\nTo use Phi\\-3\\-Vision\\-128K\\-Instruct, you will need to set up your development environment with the required libraries and tools. The model is integrated into the development version (4\\.40\\.2\\) of the Hugging Face `transformers` library. Before diving into code examples, ensure that your Python environment is configured with these packages:\n\n\n```python\n## Required Packages\nflash_attn==2.5.8\nnumpy==1.24.4\nPillow==10.3.0\nRequests==2.31.0\ntorch==2.3.0\ntorchvision==0.18.0\ntransformers==4.40.2\n```\nTo load the model, you can either update your local `transformers` library or clone and install it directly from the source:\n\n\n```python\npip uninstall -y transformers && pip install git+https://github.com/huggingface/transformers\n```\nNow, let‚Äôs jump into some practical code snippets to show how you can leverage this powerful model for AI\\-driven document extraction and text generation.\n\n\n## Sample Code for Loading the Model\n\nHere‚Äôs a Python example of how to initialize the model and start making inferences. We‚Äôll make use of classes and functions to keep the code clean and organized:\n\n\n```python\nfrom PIL import Image\nimport requests\nfrom transformers import AutoModelForCausalLM, AutoProcessor\n\nclass Phi3VisionModel:\n    def __init__(self, model_id=\"microsoft/Phi-3-vision-128k-instruct\", device=\"cuda\"):\n        \"\"\"\n        Initialize the Phi3VisionModel with the specified model ID and device.\n        \n        Args:\n            model_id (str): The identifier of the pre-trained model from Hugging Face's model hub.\n            device (str): The device to load the model on (\"cuda\" for GPU or \"cpu\").\n        \"\"\"\n        self.model_id = model_id\n        self.device = device\n        self.model = self.load_model()  # Load the model during initialization\n        self.processor = self.load_processor()  # Load the processor during initialization\n    \n    def load_model(self):\n        \"\"\"\n        Load the pre-trained language model with causal language modeling capabilities.\n        \n        Returns:\n            model (AutoModelForCausalLM): The loaded model.\n        \"\"\"\n        print(\"Loading model...\")\n        # Load the model with automatic device mapping and data type adjustment\n        return AutoModelForCausalLM.from_pretrained(\n            self.model_id, \n            device_map=\"auto\",  # Automatically map model to the appropriate device(s)\n            torch_dtype=\"auto\",  # Use an appropriate torch data type based on the device\n            trust_remote_code=True,  # Allow execution of custom code for loading the model\n            _attn_implementation='flash_attention_2'  # Use optimized attention implementation\n        ).to(self.device)  # Move the model to the specified device\n    \n    def load_processor(self):\n        \"\"\"\n        Load the processor associated with the model for processing inputs and outputs.\n        \n        Returns:\n            processor (AutoProcessor): The loaded processor for handling text and images.\n        \"\"\"\n        print(\"Loading processor...\")\n        # Load the processor with trust_remote_code=True to handle any custom processing logic\n        return AutoProcessor.from_pretrained(self.model_id, trust_remote_code=True)\n    \n    def predict(self, image_url, prompt):\n        \"\"\"\n        Perform a prediction using the model given an image and a prompt.\n        \n        Args:\n            image_url (str): The URL of the image to be processed.\n            prompt (str): The textual prompt that guides the model's generation.\n        \n        Returns:\n            response (str): The generated response from the model.\n        \"\"\"\n        # Load the image from the provided URL\n        image = Image.open(requests.get(image_url, stream=True).raw)\n        \n        # Format the input prompt template for the model\n        prompt_template = f\"<|user|>\\n<|image_1|>\\n{prompt}<|end|>\\n<|assistant|>\\n\"\n        \n        # Process the inputs, converting the prompt and image into tensor format\n        inputs = self.processor(prompt_template, [image], return_tensors=\"pt\").to(self.device)\n        \n        # Set generation arguments for the model's response generation\n        generation_args = {\n            \"max_new_tokens\": 500,  # Maximum number of tokens to generate\n            \"temperature\": 0.7,     # Sampling temperature for diversity in generation\n            \"do_sample\": False      # Disable sampling for deterministic output\n        }\n        print(\"Generating response...\")\n        # Generate the output IDs using the model, skipping the input tokens\n        output_ids = self.model.generate(**inputs, **generation_args)\n        output_ids = output_ids[:, inputs['input_ids'].shape[1]:]  # Ignore the input prompt in the output\n        \n        # Decode the generated output tokens to obtain the response text\n        response = self.processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n        return response\n\n## Initialize the model\nphi_model = Phi3VisionModel()\n\n## Example prediction\nimage_url = \"https://example.com/sample_image.png\"  # URL of the sample image\nprompt = \"Extract the data in json format.\"  # Prompt for model guidance\nresponse = phi_model.predict(image_url, prompt)  # Get the response from the model\n\nprint(\"Response:\", response)  # Print the generated response\n```\nThe code above defines a `Phi3VisionModel` class that abstracts the loading and usage of the model, making it easier to integrate into your applications. The `predict()` method demonstrates how to perform image\\-based inferences using a custom prompt.\n\nTo update the article with a focus on testing the OCR capabilities of the Phi\\-3\\-Vision\\-128K\\-Instruct model, we‚Äôll add a section detailing how the model performs with real\\-world examples of scanned ID cards.\n\n\n## Testing OCR Capabilities with Scanned ID Cards\n\nTo evaluate the OCR performance of the Phi\\-3\\-Vision\\-128K\\-Instruct model, we tested it using several real\\-world scanned ID card images. These images vary in quality and clarity, providing a range of challenges for the model. The goal is to demonstrate how well the model can extract text information from documents with different characteristics, such as blurriness, complex backgrounds, and varying text fonts.\n\n**Image 1:** A fictional Utopian passport with detailed text, including personal information such as name, nationality, place of birth, date of issue, and expiration date. The text is slightly stylized, and there is a machine\\-readable zone at the bottom. The image quality is high, with no significant background noise.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MltpseOI3HhvCkUZMwLdEQ.png)\n\n**Output:**\n\n\n```python\n{\n  \"Type/Type\": \"P\",\n  \"Country code/Code du pays\": \"UTO\",\n  \"Passport Number/N¬∞ de passeport\": \"L898902C3\",\n  \"Surname/Nom\": \"ERIKSSON\",\n  \"Given names/Pr√©noms\": \"ANNA MARIA\",\n  \"Nationality/Nationalit√©\": \"UTOPIAN\",\n  \"Date of Birth/Date de naissance\": \"12 AUGUST/AOUT 74\",\n  \"Personal No./N¬∞ personnel\": \"Z E 184226 B\",\n  \"Sex/Sexe\": \"F\",\n  \"Place of birth/Lieu de naissance\": \"ZENITH\",\n  \"Date of issue/Date de d√©livrance\": \"16 APR/AVR 07\",\n  \"Authority/Autorit√©\": \"PASSPORT OFFICE\",\n  \"Date of expiry/Date d'expiration\": \"15 APR/AVR 12\",\n  \"Holder's signature/Signature du titulaire\": \"anna maria eriksson\",\n  \"Passport/Passeport\": \"P<UTOERIKSSON<<ANNA<MARIA<<<<<<<<<<<<<<<<<<<<<<<L898902C36UT07408122F1204159ZE184226B<<<<10\"\n}\n```\n**Image 2:** A Dutch passport with a clear image of the holder and neatly formatted text. Fields include the passport number, name, date of birth, nationality, and expiration date. The document is presented with high contrast, making text extraction relatively straightforward. The machine\\-readable zone (MRZ) at the bottom offers a structured data format that can help validate the accuracy of extracted information.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WGV4tTxI9xISmAvFs8ovNw.png)\n\n**Output:**\n\n\n```python\nHere's the extracted full data from the passport in JSON format:\n\n{\n  \"passport\": {\n    \"issuingCountry\": \"Netherlands\",\n    \"issuingAuthority\": \"Koninkrijk der Nederlanden\",\n    \"passportNumber\": \"SPEC12014\",\n    \"issuingDate\": \"09 MAR 2014\",\n    \"expiryDate\": \"09 MAR 2024\",\n    \"holder\": {\n      \"gender\": \"F\",\n      \"nationality\": \"Netherlands\",\n      \"placeOfBirth\": \"SPECIMEN\",\n      \"sex\": \"WF\",\n      \"firstNames\": [\n        \"Willem\",\n        \"Lieselotte\"\n      ]\n    },\n    \"physicalDescription\": {\n      \"height\": \"1.75 m\",\n      \"hairColor\": \"gray\",\n      \"hairLength\": \"short\"\n    },\n    \"issuingOffice\": \"Burg. van Stad en Dorp\",\n    \"issuingDateAsInt\": \"14032014\",\n    \"expiryDateAsInt\": \"14032024\",\n    \"fieldsExtracted\": [\n      {\n        \"code\": \"NL\",\n        \"dateOfBirth\": \"10 MAR 1965\",\n        \"dateOfIssue\": \"09 MAR 2014\",\n        \"dateOfExpiry\": \"09 MAR 2024\",\n        \"firstNames\": [\n          \"Willem\",\n          \"Lieselotte\"\n        ],\n        \"nationality\": \"Netherlands\",\n        \"passportNumber\": \"SPEC12014\",\n        \"placeOfBirth\": \"SPECIMEN\",\n        \"sex\": \"WF\"\n      }\n    ]\n  }\n}\n```\n\n## Try Phi\\-3\\-Vision\\-128K\\-Instruct Yourself\n\nIf you want to try the Phi\\-3\\-Vision\\-128K\\-Instruct model for yourself, you can explore it through the following link: [Try Phi\\-3\\-Vision\\-128K\\-Instruct on Azure AI](https://ai.azure.com/explore/models/Phi-3-vision-128k-instruct/version/1/registry/azureml). This link allows you to experience the model‚Äôs capabilities and experiment with its OCR functionality.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7feNu3ZuclgAnAzbJMMSFg.png)\n\n\n## Understanding the Architecture and Training\n\nThe **Phi\\-3\\-Vision\\-128K\\-Instruct** model is not just any language model ‚Äî it‚Äôs a multimodal powerhouse that can process both visual and textual data. It has undergone a comprehensive training regime that included **500 billion tokens**, a blend of text and image data. Its architecture integrates a language model and image processing modules, creating a cohesive system that understands context over **128K tokens**, allowing for extended conversations or documents with large content.\n\nTrained on powerful hardware, such as **512 H100 GPUs**, and utilizing **flash attention** for memory efficiency, this model can handle large\\-scale tasks with ease. The training dataset includes a mix of synthetic and filtered real\\-world data, emphasizing **math, coding, common sense reasoning**, and **general knowledge**, making it versatile enough for various applications.\n\n\n## Key Benchmarks and Performance\n\nThe performance of Phi\\-3\\-Vision\\-128K\\-Instruct has been tested across multiple benchmarks, including **ScienceQA**, **AI2D**, **MathVista**, and **TextVQA**. Its scores consistently surpass many existing models in tasks that combine text and vision, particularly in areas such as:\n\n* **Document comprehension**: Extracting useful information from complex documents like PDFs or images.\n* **Table and chart understanding**: Accurately interpreting graphical data and converting it into textual explanations.\n\nIn particular, the model achieved an impressive **81\\.4%** on **ChartQA** and **76\\.7%** on **AI2D**, showcasing its capability to understand data\\-rich documents effectively.\n\n\n## Why OCR and Document Extraction Matter\n\nDocument extraction and OCR are vital for businesses and research, enabling the conversion of printed or handwritten text into machine\\-readable formats. Tasks such as **PDF parsing**, **data entry automation**, **invoice processing**, and **legal document analysis** are significantly simplified by using AI models like Phi\\-3\\-Vision\\-128K\\-Instruct.\n\nWhether you are dealing with scanned documents, screenshots, or photographed pages, the model‚Äôs multimodal capabilities can help to **automate data extraction**, making it a valuable tool for improving productivity and reducing manual effort.\n\n\n## Responsible AI and Safety Measures\n\nWhile the model is powerful, it comes with limitations that developers should keep in mind. **Language biases**, **stereotype reinforcement**, and **inaccurate content generation** are potential issues. For high\\-risk use cases, such as **health or legal advice**, additional layers of **verification and content filtering** are necessary.\n\n\n## Future Directions and Fine\\-Tuning\n\nLooking to extend Phi\\-3\\-Vision\\-128K\\-Instruct‚Äôs capabilities? Fine\\-tuning is supported and can be performed using the **Phi\\-3 Cookbook**, which provides recipes for adjusting the model to specific tasks like **document classification**, **enhanced OCR accuracy**, and **specialized image understanding**.\n\n\n## Conclusion\n\nThe Phi\\-3\\-Vision\\-128K\\-Instruct isn‚Äôt just a step forward for multimodal AI; it‚Äôs a leap into a future where **document extraction, OCR, and AI\\-driven content generation** are seamless and accessible. With extensive training, robust architecture, and thoughtful design, this model empowers developers to transform data processing across various fields.\n\nStay tuned for more advanced examples and tutorials on integrating this model with real\\-world applications, where we will explore **processing multiple document types** and applying **AI\\-powered techniques** to extract valuable insights from diverse sources.\n\nThe future of **AI\\-powered document extraction** has never looked more promising!\n\n\n"},{"lang":"en","group":"blog","slug":"blog/ai-research-agents-set-to-transform-knowledge-research-in-2025-plus-top-3-free-tools-d37197726531","frontmatter":{"title":"AI Research Agents: Set to Transform Knowledge Research in 2025 (Plus Top 3 Free Tools)","meta_title":"AI Research Agents: Set to Transform Knowledge Research in 2025 (Plus Top 3 Free Tools)","description":"AI research agents are poised to revolutionize knowledge research by 2025, enhancing the efficiency and depth of data analysis across various fields. Unlike traditional AI tools, these agents can autonomously conduct extensive research, identify patterns, and generate insights with advanced technologies like Retrieval Augmented Generation (RAG). Key tools include Stanfords STORM, CustomGPT.ai Researcher, and GPT Researcher, each offering unique capabilities for automated, accurate content creation. As data generation accelerates, the integration of these agents into research workflows will enable researchers to focus on creative and complex problem-solving, ultimately democratizing access to high-quality research.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*8hV5Jo0eUwY01CWV","categories":["Research","Data Science","Generative AI"],"author":"Rifx.Online","tags":["agents","RAG","STORM","CustomGPT","GPT"],"draft":false,"slug":"blog/ai-research-agents-set-to-transform-knowledge-research-in-2025-plus-top-3-free-tools-d37197726531"},"content":"\n\n\n\nHere‚Äôs the deal: Something massive is about to shake up the world of knowledge research.\n\nAfter spending months diving deep into AI research agents and seeing them in action across various industries, I can tell you one thing for sure ‚Äî by 2025, these aren‚Äôt just going to be helpful tools. They‚Äôre going to fundamentally transform how we do knowledge research (whether for marketing or science!).\n\n\n> **It is physically impossible for a human to access 10,000 websites in an hour and research the data. However, an agent can do this with ease.**\n\nAnd in this article, I am going to show you 3 free tools that will blow your mind. (Hint: It‚Äôs NOT ChatGPT or Perplexity!)\n\n\n\nI know what you‚Äôre thinking. ‚ÄúAnother AI hype piece?‚Äù But stick with me here.\n\nThe market is projected to explode from $5\\.1 billion in 2024 to $47\\.1 billion by 2030\\. That‚Äôs not just growth ‚Äî that‚Äôs a complete transformation of the research landscape.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*uGrcW8msqlIdpBeL)\n\n\n## What Makes AI Research Agents Different?\n\nFirst off, these aren‚Äôt your typical AI tools that need constant hand\\-holding. While traditional systems require explicit instructions for each task, AI research agents are like having a brilliant research assistant who can think on their feet, adapting their behavior based on outcomes they achieve.\n\n\n\n\n\n\n\nThe real game\\-changer? These agents can handle massive amounts of knowledge, spot patterns humans might miss, and generate insights faster than ever before. Using advanced [Retrieval Augmented Generation (RAG)](https://readmedium.com/build-it-or-buy-it-deployment-options-for-retrieval-augmented-generation-rag-f6d43df8212a) technology, they can pull information directly from trusted sources while maintaining accuracy.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*p2E-fJ63BB27lZdD)\n\n\n## The Tech Behind the Magic\n\nThe secret sauce here is the ability to ingest and research large amounts of knowledge (e.g. deep Google research) and then combine it with the power of LLMs like gpt\\-4o and o1\\.\n\nBut here‚Äôs what really gets me excited: These agents are powered by RAG models, with built\\-in anti\\-hallucination algorithms that ensure accuracy. Unlike generic AI tools, research agents stick to verified information and can cite their sources ‚Äî crucial for maintaining integrity.\n\n\n> **So just imagine a research agent going off for 30 mins and doing a PhD on a topic ‚Äî something that would have taken most humans days to achieve.**\n\n\n## Why This Matters Now\n\nThe timing couldn‚Äôt be better. Research is drowning in data ‚Äî we‚Äôre generating more information in a day than we used to in a year. And with Google‚Äôs emphasis on Experience, Expertise, Authoritativeness, and Trustworthiness (EEAT), the need for accurate, well\\-researched content has never been greater.\n\nI recently talked with a research team that cut their article research time by 70% using an AI research agent. But it wasn‚Äôt just about speed ‚Äî the agent found perspectives in the knowledge that they‚Äôd completely missed in their initial brief. And the best part? Everything was verifiable and backed by data.\n\nSo just imagine that you can have Einstein, Elon Musk, Feynman, Steve Jobs, Jane Goodall and Yuval Noah Harari all collaborating on doing your research report ‚Äî that‚Äôs what is possible with AI Research Agents.\n\n\n## The Top 3 AI Research Agents\n\n\n## Stanford STORM\n\nStanford University‚Äôs [STORM](https://storm.genie.stanford.edu/) (Synthesis of Topic Outlines through Retrieval and Multi\\-perspective Question Asking) is an AI\\-powered knowledge curation system designed to generate comprehensive, Wikipedia\\-like articles from scratch.\n\nLeveraging large language models (LLMs), STORM automates the research and writing process by conducting internet\\-based research, organizing information into structured outlines, and producing full\\-length articles complete with citations.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*axYZ2fO15FAqQpID)\n\n**Pros:**\n\n* **Automated Research and Writing:** STORM streamlines the creation of detailed articles by automating both the research and writing stages, saving users significant time and effort.\n* **Structured Content Generation:** The system generates organized outlines and well\\-structured articles, ensuring clarity and coherence in the final output.\n* **Open\\-Source Accessibility:** As an open\\-source project, STORM allows users to customize and adapt the tool to their specific needs, fostering innovation and collaboration within the AI research community.\n\n**Cons:**\n\n* **Dependence on Internet Sources:** STORM‚Äôs reliance on internet\\-based research may lead to the inclusion of outdated or biased information if not carefully monitored.\n* **Quality Control Requirements:** While STORM automates much of the writing process, the generated articles may still require human review and editing to ensure accuracy and adherence to specific standards.\n* **Technical Setup:** Implementing STORM locally necessitates familiarity with tools like Git, Python, and Conda, which may present a barrier for users without a technical background.\n\nFor more information and access to STORM, visit the [official GitHub repository](https://github.com/stanford-oval/storm)\n\n\n\n\n\n\n\n\n## CustomGPT.ai Researcher\n\nCustomGPT.ai [Researcher](https://customgpt-researcher.streamlit.app/) is an AI research agent specifically designed to create ultra\\-high\\-quality long\\-form articles based on deep Google research or custom knowledge bases, such as a company‚Äôs proprietary data or other trusted sources.\n\nUsing CustomGPT‚Äôs anti\\-hallucination technology, it generates factually accurate content, with inline citations, that aligns with specific brand guidelines and ensures consistency with real\\-world information.\n\nThis agent uses a combination of o1, gpt\\-4o and GPT\\-4o (Vision) to craft a detailed research report that includes inline images and links. It‚Äôs unique ‚Äú**progressive narrative**‚Äù feature helps create a non\\-robotic narrative that is aware of previously generated content.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*UiCyTjNF3A3buKzT)\n\n**Pros:**\n\n* **Trustworthy Content Creation:** By integrating data from reliable sources, CustomGPT.ai minimizes inaccuracies, making it ideal for industries requiring high content reliability, such as legal, financial, and healthcare sectors.\n* **Anti\\-Hallucination Technology:** CustomGPT.ai includes advanced algorithms that prevent it from producing speculative or fictitious information, ensuring content aligns closely with verified sources.\n* **Hosted Solution:** With its no\\-code interface, non\\-technical researchers and marketers can easily trigger deep research, without getting into coding intricacies.\n* **SEO\\-Optimized Content Generation:** The tool supports Google‚Äôs EEAT (Expertise, Authoritativeness, Trustworthiness, and Experience) standards, creating content that ranks well on search engines by emphasizing quality and authority.\n\n**Cons:**\n\n* **Closed Source:** While the CustomGPT.ai Researcher is free for a limited time, it is a closed\\-source proprietary project.\n* **Longer Generation Time:** The high\\-level reasoning and RAG capabilities can take up to 20 minutes to generate a single article, which may not suit users seeking rapid or lower\\-quality content.\n* **Limited Suitability for Budget Content Projects:** Given its focus on quality, CustomGPT.ai Researcher is not ideal for projects that require fast, inexpensive, or basic content generation.\n\nFor more details on CustomGPT.ai Researcher and its applications, see the free [Streamlit App](https://customgpt-researcher.streamlit.app/).\n\n\n## GPT Researcher\n\nGPT Researcher is an [autonomous agent](https://github.com/assafelovic/gpt-researcher) designed to conduct comprehensive research on any given task, utilizing both web and local sources.\n\nIt generates detailed, factual, and unbiased reports complete with citations, offering a full suite of customization options to create tailored, domain\\-specific research agents.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*_4Q680CBSvpCZOLW)\n\n**Pros:**\n\n* **Autonomous Research Capabilities:** GPT Researcher automates the research process, efficiently gathering and synthesizing information from various sources to produce comprehensive reports.\n* **Customization and Flexibility:** Users can customize the agent to focus on specific domains or topics, allowing for tailored research outputs that meet particular needs.\n* **Open\\-Source Accessibility:** As an open\\-source project, GPT Researcher encourages community collaboration and continuous improvement, providing transparency and adaptability for users.\n\n**Cons:**\n\n* **Technical Setup Requirements:** Implementing GPT Researcher may require technical expertise, including familiarity with Git, Python, and Docker, which could be a barrier for non\\-technical users.\n\nFor more information and access to GPT Researcher, visit the [official GitHub repository](https://github.com/assafelovic/gpt-researcher):\n\n\n## The Human Side of AI Research\n\nLet‚Äôs address the elephant in the room: ‚ÄúAre these agents going to replace human researchers?‚Äù Absolutely not. Instead, they‚Äôre freeing up researchers to focus on what humans do best: creative thinking, complex problem\\-solving, and generating innovative hypotheses.\n\nThink of it like having a super\\-powered research assistant who never sleeps, never gets tired, and can process information at lightning speed. While the AI handles deep knowledge research, researchers can focus on breakthrough insights.\n\n\n## Getting Ready for the Revolution\n\nSo, how do we prepare for this AI revolution in research?\n\nFirst, researchers need to level up their skills. I‚Äôm not saying everyone needs to become a coding expert, but understanding the **strengths AND limitations** of these AI research agents is going to be key.\n\nUniversities are adapting their curricula, and I‚Äôm seeing more [researchers](https://drmichaellevin.org/resources/levinbot.html) utilizing AI to aid in their research labs.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*E733R9Fn9ufaXnTF)\n\n\n## Looking Beyond 2025\n\nThe potential here is mind\\-blowing. These AI research agents are going to enable types of research we can barely imagine right now.\n\nCross\\-disciplinary innovations will become the norm as AI agents help connect dots between different fields that we never even knew were related.\n\nI‚Äôm particularly excited about how this technology could democratize research. Small labs and institutions that couldn‚Äôt afford large research teams will be able to leverage AI agents to compete with bigger players. That means more diverse perspectives and more breakthrough discoveries.\n\nAs an example, the [Levin Lab at Tuft‚Äôs University](https://drmichaellevin.org/resources/levinbot.html) was able to build one of the best AI tools within a few hours ‚Äî showing the true power of AI democratization.\n\n\n## Final Thoughts\n\nAfter spending months researching this topic and talking with experts in the field, I‚Äôm convinced that AI research agents are going to be as transformative as the internet was for science. They‚Äôre not just tools ‚Äî they‚Äôre partners in the research process that will help us tackle some of the biggest challenges facing humanity.\n\nSure, there are hurdles to overcome and skills to develop. But the potential benefits are too massive to ignore. If you‚Äôre in marketing or research, now‚Äôs the time to start preparing for this shift.\n\nRemember: The teams and institutions that embrace this technology early will have a massive advantage in the years to come. Don‚Äôt get left behind in what‚Äôs shaping up to be one of the biggest revolutions in how we do knowledge research ‚Äî whether you are writing a blog post for SEO ‚Äî or doing your PhD on a scientific topic.\n\n*What are your thoughts on AI research agents? Have you started integrating them into your research workflow? I‚Äôd love to hear about your experiences in the comments below.*\n\n\n"},{"lang":"en","group":"blog","slug":"blog/alibabas-open-source-qwen-how-it-s-revolutionizing-ai-and-how-you-can-use-it-dcba8f687c97","frontmatter":{"title":"Alibaba‚Äôs Open-Source Qwen: How It‚Äôs Revolutionizing AI and How You Can Use It","meta_title":"Alibaba‚Äôs Open-Source Qwen: How It‚Äôs Revolutionizing AI and How You Can Use It","description":"Alibaba has recently made waves in the AI world by open-sourcing its Qwen 2.5 models during the 2024 Apsara Conference. With over 100‚Ä¶","date":"2024-10-26T00:26:25.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*I7QDwbLMzoJ_ORq5.jpg","categories":["Programming","Machine Learning","Natural Language Processing"],"author":"Rifx.Online","tags":["Qwen","multimodal","open-source","fine-tune","text-to-video"],"draft":false,"slug":"blog/alibabas-open-source-qwen-how-it-s-revolutionizing-ai-and-how-you-can-use-it-dcba8f687c97"},"content":"\nAlibaba has recently made waves in the AI world by open-sourcing its **Qwen 2.5** models during the 2024 Apsara Conference. With over 100 models, Qwen spans multiple modalities including language, vision, audio, and code, making it one of the most comprehensive open-source AI solutions. The release empowers developers by providing tools for diverse applications, from text-to-video generation to real-time question answering.\n\n\n\n## Key Features of Alibaba‚Äôs Qwen Models\n\n1. **Multimodal Capabilities**: Qwen models handle diverse inputs, including text, audio, and visual data. This multimodal approach makes them suitable for a wide range of industries, from media and entertainment to robotics.\n2. **Open Source**: Available on platforms like **Hugging Face** and **ModelScope**, Qwen has already been downloaded over 40 million times, with over 50,000 custom models built on its foundation.\n3. **Enhanced Performance**: Qwen2.5 introduces improved language understanding, mathematics, and coding capabilities, rivaling leading models in the field. With optimized performance for tasks like structured data understanding and long text generation, Qwen opens the door to high-level AI applications.\n\n## How to Use Alibaba‚Äôs Qwen\n\nDevelopers and organizations can access Qwen models on platforms like Hugging Face, where they can:\n\n* **Fine-tune models**: Tailor Qwen for specific industry applications such as customer service, automation, or video content creation.\n* **Integrate with applications**: Qwen‚Äôs text-to-video model can be incorporated into media production pipelines, generating dynamic content from static images and text prompts.\n* **Develop AI assistants**: With enhanced vision-language models, Qwen can be used in robotics and autonomous vehicles to process video data and perform real-time tasks like navigation or object recognition.\n\n**Example of Using Qwen via Hugging Face**:\n\n```python\nfrom transformers import QwenTokenizer, QwenModel\n\ntokenizer = QwenTokenizer.from_pretrained(\"qwen-2.5\")\nmodel = QwenModel.from_pretrained(\"qwen-2.5\")\n\ninput_text = \"What is the future of AI in healthcare?\"\ninput_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\noutputs = model(input_ids)\n```\n\nThis allows users to access Qwen models, run inference, and customize them based on specific needs.\n\n## Qwen‚Äôs Impact Across Industries\n\n1. **Media and Entertainment**: With the new text-to-video capabilities, Qwen can automatically generate videos from written scripts, transforming the creative industry by automating tedious production tasks.\n2. **Robotics and Autonomous Vehicles**: The enhanced vision-language models in Qwen can help robots understand real-world environments, leading to better decision-making in autonomous driving or manufacturing.\n3. **Software Development**: Alibaba‚Äôs AI Developer tool, powered by Qwen, automates tasks like code generation, debugging, and requirement analysis, enabling developers to focus on higher-level problem-solving.\n\n## Conclusion: A New Era of Open AI Innovation\n\nBy open-sourcing its Qwen 2.5 models, Alibaba is democratizing access to advanced AI technologies. Developers, startups, and large enterprises alike can harness Qwen‚Äôs multimodal and real-time capabilities to drive innovation in industries ranging from media to autonomous vehicles. Whether you‚Äôre a developer looking to fine-tune models for a niche application or a corporation integrating AI into your infrastructure, Qwen offers powerful tools to accelerate progress.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/artifacts-top-mindblowing-uses-of-claude-3-5-sonent-6830b2acfa4b","frontmatter":{"title":"Artifacts: Top Mindblowing uses of Claude 3.5 Sonent","meta_title":"Artifacts: Top Mindblowing uses of Claude 3.5 Sonent","description":"Anthropic recently launched its most advanced LLM, ‚ÄúClaude 3.5 Sonnet,‚Äù and it‚Äôs mindblowing. People on social media called this model the‚Ä¶","date":"2024-11-08T00:18:38.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XL1dN9VCFcbz3m5N","categories":["Programming","Natural Language Processing","Generative AI"],"author":"Rifx.Online","tags":["Sonnet","context","Artifacts","code","generation"],"draft":false,"slug":"blog/artifacts-top-mindblowing-uses-of-claude-3-5-sonent-6830b2acfa4b"},"content":"\n\n\n\nAnthropic recently launched its most advanced LLM, ‚ÄúClaude 3\\.5 Sonnet,‚Äù and it‚Äôs mindblowing. People on social media called this model the most advanced LLM currently available. This AI model outperforms all the existing LLMs, such as GPT\\-4 GPT\\-4o mini, Llama 3, etc. Claude 3\\.5 Sonnet has a context window of 200K with a max output of 8192 tokens. It can generate text in an enormous paragraph with much data as input. Claude 3\\.5 Sonnet is one of the best AI vision models, beating GPT\\-4o and Llama 3 in various test cases. It can extract data and text from documents and PDFs. These are just some factors that make the Claude 3\\.5 Sonnet the best, but there is also a new feature that Anthropic added, which makes the LLM the best code generator, ‚ÄúArtifacts.‚Äù It is a pop\\-up window that allows the users to see their code, edit it, and see their project live in that pop\\-up window. This article will show the top cases of Artifacts and Claude 3\\.5 Sonnet and the new projects you can develop using this tool.\n\n\n\n\n## Use Cases of Claude 3\\.5 Sonnet\n\nTo use the Artifacts, you must have a Claude account. Claude 3\\.5 Sonnet is Free for everyone but allows only limited chats per day. Users must buy a subscription for around $20 to use the model with unlimited chats. Try these prompts in Claude 3\\.5 Sonnet and create exciting tools. Users can also publish their projects on the Internet by sharing the link.\n\n\n### 1\\. Interactive PDF Dashboard\n\nReading large PDFs is boring. So, let‚Äôs create an interactive PDF dashboard that will allow me to read my PDFs better.\n\n***Prompt\\- Create an interactive PDF dashboard to help me view, read, and learn from this information in a more visually appealing way. It has a tab where I can get a quiz based on the information in the PDF. Make sure it has a dark mode.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*66Iowbu8ZKA-IGfK)\n\nTo use this prompt, first attach the PDF with the prompt whose summary you want to read. Users can also make changes according to their preferences, and Claude 3\\.5 Sonnet will generate the code again with the changes.\n\n[***Click here to see the project***](https://claude.site/artifacts/4b9590a8-260e-476a-ab75-ec1d69f81d1e)***.***\n\n\n### 2\\. Visualization of anything with animations\n\nVisualizing anything you‚Äôve read is probably the best way to understand it. Adding animations will take your visualization to the next level, making it easy to understand.\n\n***Prompt: Animate each process step to Create a visualization of photosynthesis. Make sure to make the whole dashboard visually appealing using different colors and textures to create high\\-quality animations.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*W5lWitTO5fj7lOs0)\n\nIt is the first output we get, which is impressive within 10 seconds of processing but could be better after refining the prompts by giving more instruction and precision. We get\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*TAguaCWhC1CYFNw7)\n\nAs you can see, we separated the whole cycle into different stages, and the final result is incredible. This method can help you understand any process by breaking it into more straightforward steps.\n\n[***Click here to see the project***](https://claude.site/artifacts/b9769e4e-c20b-43da-945a-bfc41782900c)***.***\n\n\n### 3\\. Scientific Tools\n\nScientific tools are tools and services that help users understand the concept of science quickly and visually. With the help of Claude 3\\.5 Sonnet, users can create scientific tools at a single prompt. Just describe your tool in detail. I will use it to create an interactive tool for electronics engineering.\n\n***Prompt ‚Äî Create a dashboard using React that shows the Diode. We can connect it forward\\-biased or reverse\\-biased in the circuit, and based on physical factors such as doping and depletion region, we change the scenario by showing the movement of the holes and electrons in the diode. There is an option to change everything, such as voltage, current, type of diode, Si, or Ge, and use different colors and moving elements for the animation.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*9bE50q8nsh6_SQ36)\n\nUsers can use Claude 3\\.5 Sonnet to create multiple tools, such as an essential project school, the magnet‚Äôs current effect, the pressure and temperature relation tool, atomic models animation, etc.\n\n***Click [here to see the project](https://claude.site/artifacts/5b18fb27-1093-41d2-ac4e-54e47e4ddd3a).***\n\n\n### 4\\. Game Development\n\nEveryone likes to play games. Using Claude 3\\.5 Sonnet, we can create different types of games. I am going to make a Tic Tac Toe game using LLM.\n\n***Prompt\\- create a tic tac toe game using react and make it functional. Make it visually appealing by using CSS.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*jlSn7mCbaFadUT3F)\n\nAnd the result could be better. After that, I tried to give more suggestions and input, and based on my suggestions, Claude developed a perfect Tic Tac Toe Game, and here is the result.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4v9KP4KFmQgY14YZ)\n\nAs you can see, the final product refines the CSS. The animations have greatly improved, and a pop\\-up with the winner‚Äôs name is added by the end of the game. You can use these prompts to make games such as Snake Game, Ludo, Rock Paper Scissors, etc.\n\n[***Click here to try the project.***](https://claude.site/artifacts/d57fdf93-79fb-443a-9bee-a58ab6eb911f)\n\n\n### 5\\. Web Application\n\nWeb applications are tools that can be accessed directly on the browser without installing the app on the phone. Claude 3\\.5 Sonnet can be used to develop different web application types. In this case, we will examine an expense tracker app.\n\n***Prompt\\- Create a web application for an expense tracker with the following features: First, ask about their monthly expenses ‚Äî say Rs. 2000\\. Now, whatever the person spends, make sure you make some categories like Food, Travel, and Necessity and have the option to add anything. Add an option like saving money at the end of the month. Also, it has an investing option, which you now know the type of. For Example, ‚ÄúIf you invest 200 monthly in mutual funds, after five years, you will have X amount. Also, the app has a feature to generate graphs and charts related to the expenses. Make sure that the app‚Äôs UI/UX design is visually appealing.***\n\nAnd this is the final result.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XGOwT3vpxL0dxzzP)\n\nUsers can use Claude 3\\.5 Sonnet to create multiple tools, such as a To\\-do list, simple calculator, movie recommendation app, text summarization tool, etc.\n\n[***Click here to try the project***](https://claude.site/artifacts/66770d05-aafe-45c4-b938-8cda0e82b903)***.***\n\n\n### 6\\. 3D Simulation\n\nClaude 3\\.5 Sonent can create 3D simulations of models or projects, whether solar system models, atomic mode, The Central Dogma of Molecular Biology, etc. You can visualize any idea in 3D using this LLM. We will simulate a 3D solar system model with all the planets revolving around the sun.\n\n***Prompt\\-make a three js app of a space sim with the gravity of a solar system with planets in a single web file. solar system in which the planet revolves around the sun‚Ä¶ whenever someone hovers the mouse, it pops up the planet‚Äôs name and basic details such as mass, gravity, etc.; keep the physics concepts, such as the rotation and revolution of the planet, intact.***\n\nUse this prompt to get the desired results.\n\n***Click here to see the Project.***\n\n[***Project 1***](https://x.com/websim_ai/status/1803901523522699730?t=BCe28ywbC2xD1Mk4DRmo5w&s=08)\n\n[***Project 2***](https://x.com/ammaar/status/1804649903815115053?t=7PeWPg62bkABtKEtKVmFbw&s=08)\n\n[***Project 3***](https://x.com/goldcaddy77/status/1804724702901891313?t=iqcLQBhYaIRnt3gIBRKBQg&s=08)\n\n\n### 7\\. Mind Map\n\nA mind map is a brainstorming technique for visually organizing information hierarchically. The main feature is to make one main idea the central point of the diagram, with subtopics branching out and connecting to supporting ideas. It helps the readers easily memorize and understand the information quickly. Let‚Äôs create a prompt by creating a mind map.\n\n***Prompt: Create a mind map of how object detection works. Use animations and colors to make it interactive and visually appealing.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*igUaLzf8b2ZTEy-m)\n\nBy changing the topic, you can use this prompt to generate any mind map you want. You can also add different colors and animations to make it more interactive.\n\n[***Click here to try the project***](https://claude.site/artifacts/f1ce9002-9434-4b40-9713-ef184c467557)\n\n\n### 8\\. SEO Tool\n\nSEO is essential for any blog post to rank on Google. Using Claude, we can create a tool that can help us to improve the seo of our website. You can use this prompt to make your tool.\n\n***Prompt\\- Create an SEO tool that allows me to upload my blog post, industry, and keyword for which I am trying to rank. After I upload all that stuff, I want to hit a button that gives highlighted suggestions on what to change. Include a reset button that starts the process over. And also added a plus button to keywords where I can add multiple. In the SEO suggestions area, after analyzing the SEO, give me specific numbers, stats from my blog post, and caution signs to show what needs attention. After I generate the blog post, give me a revised blog post suggestion based on the keywords. I will rank it and explain why the suggestion is also being made. Make it more interactive by making the CSS more advanced and adding one unique feature that you think is necessary to make the tool more helpful for bloggers. Make sure that the tool has a UI/UX design that is visually appealing.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*OfY0zIa4rzO7J55r)\n\nUsers can create a variety of tools that not only help them in SEO but also in various fields to increase productivity.\n\n[***Click here to try the project***](https://claude.site/artifacts/09f21906-6295-4d0a-9fa0-be4afd6dab71)***.***\n\n\n### 9\\. Object Detection Tool\n\nYou can also use Claude 3\\.5 Sonent to make projects based on Artficla Inteliigence and Machine Learning. You can try to create amazing projects by adding features.\n\n***Prompt\\- Create a single HTML file for a real\\-time object detection web application. Using TensorFlow.js and the COCO\\-SSD model***\n\n***The application should:***\n\n* ***Access the user‚Äôs webcam and display the video feed.***\n* ***Perform object detection on the video feed in real time.***\n* ***Draw bounding boxes around detected objects and label them with their class and detection confidence.***\n* ***Display a list of uniquely detected objects below the video feed, showing the object class and when it was first detected.***\n* ***Ensure each object class is only listed once, regardless of how often it‚Äôs detected.***\n* ***Use a detection frequency of 2 FPS to balance performance and responsiveness.***\n* ***Include error handling for camera access and model loading.***\n* ***Style the application for a clean, modern look with a responsive design.***\n* ***Include all necessary HTML, CSS, and JavaScript in a self\\-contained HTML file.***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*QSvMcxCuulkRKOlm)\n\n\n## Conclusion\n\nClaude 3\\.5 Sonnet, Anthropic‚Äôs latest LLM, has revolutionized AI capabilities with its advanced features and versatile applications. The model‚Äôs impressive 200K context window, superior vision capabilities, and innovative ‚ÄúArtifacts‚Äù feature for code generation set it apart from competitors. This article showcased diverse use cases of Claude 3\\.5 Sonnet, demonstrating its potential in creating interactive dashboards, visualizations, scientific tools, games, web applications, 3D simulations, mind maps, and SEO tools. These examples highlight the model‚Äôs ability to generate complex, functional, and visually appealing projects with simple prompts. Claude 3\\.5 Sonnet‚Äôs user\\-friendly interface and powerful capabilities make it an invaluable tool for developers, educators, and professionals across various fields, opening up new possibilities for AI\\-assisted creation and problem\\-solving.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/bolt-new-and-ollama-revolutionizing-ai-powered-full-stack-web-development-2aa6aadf5958","frontmatter":{"title":"Bolt.new and Ollama: Revolutionizing AI-Powered Full-Stack Web Development","meta_title":"Bolt.new and Ollama: Revolutionizing AI-Powered Full-Stack Web Development","description":"Bolt.new is an AI-powered full-stack web development tool that operates directly in the browser, enhancing efficiency and accessibility in building web applications. It integrates with Ollama, allowing users to run open-source AI models locally, which offers cost savings and greater control over the development environment. Key features include in-browser development, comprehensive AI environment control, and easy deployment capabilities. The article provides a detailed installation guide and practical demonstrations, showcasing Bolt.news ability to create various applications, from simple web pages to complex financial service apps.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vbo04xVLorq_rvpeEDCaAg.jpeg","categories":["Programming","Technology/Web","Data Science"],"author":"Rifx.Online","tags":["Bolt","Ollama","browser","deployment","web"],"draft":false,"slug":"blog/bolt-new-and-ollama-revolutionizing-ai-powered-full-stack-web-development-2aa6aadf5958"},"content":"\n\n\n\n\n\nIn the rapidly evolving world of web development, efficiency and innovation are paramount. Developers, project managers, and designers alike are constantly seeking tools that streamline workflows, reduce costs, and enhance productivity. Enter **Bolt.new**, a groundbreaking AI\\-powered full\\-stack web development agent that operates entirely within your browser. Paired with **Ollama**, a tool that allows you to run open\\-source AI models locally, Bolt.new is set to transform the way we build and deploy web applications. This article delves deep into Bolt.new, its integration with Ollama, and provides a comprehensive guide to getting started.\n\n\n## Table of Contents\n\n1. Introduction to Bolt.new\n2. What Sets Bolt.new Apart\n* Full\\-Stack Development in the Browser\n* AI with Environment Control\n\n3\\. Integrating Bolt.new with Ollama\n\n* Why Use Ollama?\n* Installation and Setup\n\n4\\. Step\\-by\\-Step Installation Guide\n\n* Prerequisites\n* Cloning the Repository\n* Configuring Environment Variables\n* Installing Dependencies\n* Running the Application\n\n5\\. Running Bolt.new with Docker\n\n6\\. Practical Demonstrations\n\n* Creating a Simple Web Page\n* Building a Snake Game\n* Developing a Full\\-Stack Financial Service Web App\n\n7\\. Tips and Tricks for Maximizing Bolt.new\n\n\n## Introduction to Bolt.new\n\nBolt.new is an innovative tool designed to simplify the process of building full\\-stack web applications. Leveraging advanced AI models, Bolt.new allows users to **prompt**, **run**, **edit**, and **deploy** applications directly from their browser. This eliminates the need for complex local setups, making web development more accessible and efficient.\n\nWhether you‚Äôre an experienced developer, a project manager overseeing multiple projects, or a designer looking to prototype quickly, Bolt.new offers a versatile platform to bring your ideas to life with minimal effort.\n\n\n## What Sets Bolt.new Apart\n\nWhile numerous AI models and development tools exist, Bolt.new distinguishes itself through its comprehensive capabilities and seamless integration. Here‚Äôs a closer look at what makes Bolt.new unique:\n\n\n## Full\\-Stack Development in the Browser\n\nBolt.new integrates state\\-of\\-the\\-art AI models with an in\\-browser development environment powered by [StackBlitz‚Äôs WebContainers](https://github.com/stackblitz/webcontainer-core). This integration enables a host of functionalities:\n\n* **Install and Run npm Tools and Libraries:** Utilize popular frameworks like Vite, Next.js, and more without leaving your browser.\n* **Run Node.js Servers:** Manage backend operations seamlessly.\n* **Interact with Third\\-Party APIs:** Enhance your application‚Äôs functionality by integrating various services.\n* **Deploy to Production from Chat:** Push your applications live directly through the chat interface.\n* **Share Work via URL:** Easily share your projects with collaborators or stakeholders.\n\n\n## AI with Environment Control\n\nUnlike traditional development environments where AI assistance is limited to code generation, Bolt.new empowers AI models with **complete control** over the development environment. This includes managing the filesystem, node server, package manager, terminal, and browser console. Such comprehensive control enables AI agents to handle the entire application lifecycle ‚Äî from creation to deployment ‚Äî streamlining the development process significantly.\n\n\n## Integrating Bolt.new with Ollama\n\nTo further enhance Bolt.new‚Äôs capabilities and offer more flexibility, integration with **Ollama** is a game\\-changer.\n\n\n## Why Use Ollama?\n\n**Ollama** allows you to run open\\-source AI models locally on your machine. This integration offers several advantages:\n\n* **Cost Efficiency:** Avoid paying for token usage associated with cloud\\-based AI models.\n* **Flexibility:** Access a variety of models, from Llama 3\\.2 Vision to Deep SE Coder, based on your preferences.\n* **Privacy and Control:** Run models locally to maintain data privacy and control over the development environment.\n\n\n## Installation and Setup\n\nIntegrating Ollama with Bolt.new involves a few straightforward steps. Below is a detailed guide to help you get started.\n\n\n## Step\\-by\\-Step Installation Guide\n\n\n## Prerequisites\n\nBefore setting up Bolt.new with Ollama, ensure you have the following installed on your system:\n\n1. **Git:** Essential for cloning repositories.\n* [Download Git](https://git-scm.com/downloads)\n\n**2\\. Node.js:** The runtime environment for executing JavaScript on the server.\n\n* [Download Node.js](https://nodejs.org/en/download/)\n\n**3\\. Docker (Optional):** For containerizing applications.\n\n* [Download Docker](https://www.docker.com/)\n\n**4\\. Ollama:** For running open\\-source AI models locally.\n\n* [Download Ollama](https://ollama.com/)\n\n\n## Cloning the Repository\n\nBegin by cloning the Bolt.new repository from GitHub\n\n\n```python\ngit clone https://github.com/coleam00/bolt.new-any-llm.git\n```\n\n## Configuring Environment Variables\n\n1. **Rename Configuration File:** Navigate to the cloned repository and rename the `.env.example` file to `.env.local`.\n2. **Add Your LLM API Keys:** Open the `.env.local` file and add your API keys:\n\n\n```python\nGROQ_API_KEY=YOUR_GROQ_API_KEY\nOPENAI_API_KEY=YOUR_OPENAI_API_KEY\nANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY\n```\n**Note:** If you‚Äôre using Ollama, it doesn‚Äôt require an API key as it runs locally.\n\n**3\\. Optional Debug Level:** You can set the debug level to help with troubleshooting:\n\n\n```python\nVITE_LOG_LEVEL=debug\n```\n**Important:** Never commit your `.env.local` file to version control as it's included in `.gitignore`.\n\n\n## Installing Dependencies\n\nBolt.new utilizes `pnpm` for package management. Install the dependencies using the following commands:\n\n1. **Install pnpm (if not already installed):**\n\n\n```python\nsudo npm install -g pnpm\n```\n**2\\. Install Project Dependencies**\n\n\n```python\npnpm install\n```\n\n## Running the Application\n\nStart the development server with:\n\n\n```python\npnpm run dev\n```\nThis command initializes the Remix Vite development server. For optimal performance, it is recommended to use [Google Chrome Canary](https://www.google.com/chrome/canary/) as your browser.\n\n\n## Running Bolt.new with Docker\n\nFor those who prefer containerized environments, Bolt.new offers robust Docker support.\n\n\n## Using Helper Scripts\n\nBolt.new provides NPM scripts for building Docker images:\n\n* **Development Build:**\n\n\n```python\nnpm run dockerbuild\n```\n* **Production Build:**\n\n\n```python\nnpm run dockerbuild:prod\n```\n\n## Direct Docker Build Commands\n\nAlternatively, use Docker‚Äôs target feature to specify the build environment:\n\n* **Development Build:**\n\n\n```python\ndocker build . --target bolt-ai-development\n```\n* **Production Build:**\n\n\n```python\ndocker build . --target bolt-ai-productio\n```\n\n## Docker Compose with Profiles\n\nManage different environments using Docker Compose profiles:\n\n* **Development Environment:**\n\n\n```python\ndocker-compose --profile development up\n```\n* **Production Environment:**\n\n\n```python\ndocker-compose --profile production up\n```\n**Note:** When running the Docker Compose command with the development profile, any changes made to the code on your machine will automatically reflect in the running container, enabling hot reloading.\n\n\n## Practical Demonstrations\n\nTo showcase Bolt.new‚Äôs capabilities, let‚Äôs walk through a few practical examples.\n\n\n## Creating a Simple Web Page\n\nOne of the simplest demonstrations involves generating a basic web page:\n\n1. **Prompt Bolt.new:** Request the AI to create a simple web page.\n2. **Generation:** Bolt.new generates all necessary folders and files.\n3. **Preview:** Utilize the preview functionality to visualize the output instantly.\n\nThis process underscores Bolt.new‚Äôs ability to handle straightforward tasks efficiently, providing a solid foundation for more complex projects.\n\n\n## Building a Snake Game\n\nBolt.new‚Äôs prowess becomes more evident when tasked with creating interactive applications, such as a snake game:\n\n1. **Prompt Bolt.new:** Ask the AI to help create a snake game.\n2. **Generation:** Bolt.new generates all required files, packages, and the frontend interface.\n3. **Preview:** Open the generated HTML file to see a fully functional snake game that tracks scores.\n\n**Outcome:** The AI successfully generates a visually appealing and functional game, demonstrating its capability to handle dynamic and interactive web applications.\n\n\n## Developing a Full\\-Stack Financial Service Web App\n\nFor a more comprehensive demonstration, let‚Äôs explore building a full\\-stack financial service application:\n\n1. **Prompt Bolt.new:**\n* **Frontend:** Use React for the user interface.\n* **Backend:** Implement Next.js for server\\-side rendering.\n* **Database:** Integrate PostgreSQL for data management.\n* **Authentication:** Set up with Clerk.\n\n\n```python\nCreate a full-stack financial service web app with a clean, intuitive UI using ChatGPT and React for the frontend, Next.js for server-side rendering, PostgreSQL for data management, and authentication set up with Clerk.\n```\n**2\\. Generation Process:**\n\n* **File Creation:** Bolt.new generates the necessary project structure and files.\n* **Package Installation:** Installs required packages like React, Next.js, and Clerk.\n* **Backend Setup:** Configures server\\-side rendering and database connections.\n* **Authentication:** Integrates Clerk for user authentication.\n\n**3\\. Preview:** Access the application via the provided URL to see a fully functional financial dashboard featuring:\n\n* **Balance History:** Overview of all deposits.\n* **Budget Configuration:** Ability to add budgets from various categories.\n* **Transaction Management:** Add and view transactions.\n* **Investment Tracking:** Monitor investments.\n\n**Outcome:** Bolt.new efficiently manages the creation of a complex, multi\\-faceted application in a single prompt, highlighting its potential for large\\-scale projects.\n\n\n## Tips and Tricks for Maximizing Bolt.new\n\nTo get the most out of Bolt.new, consider the following strategies:\n\n1. **Be Specific About Your Stack:**\n* Clearly mention the frameworks or libraries you wish to use (e.g., Astro, Tailwind, ShadCN) in your initial prompt to ensure Bolt.new scaffolds the project accordingly.\n\n**2\\. Use the Enhance Prompt Icon:**\n\n* Before submitting your prompt, use the ‚Äòenhance‚Äô feature to refine your instructions. This leads to more accurate and efficient code generation.\n\n**3\\. Scaffold Basics First:**\n\n* Start with the fundamental structure of your application before adding advanced features. This helps Bolt.new understand the project foundation, ensuring subsequent functionalities are well\\-integrated.\n\n**4\\. Batch Simple Instructions:**\n\n* Combine multiple simple tasks into a single prompt to save time and reduce API credit consumption. For example, request changes to the color scheme, add mobile responsiveness, and restart the dev server all at once.\n\n**5\\. Leverage Open\\-Source Customization:**\n\n* Since Bolt.new is open\\-source, explore the [Bolt.new GitHub repository](https://github.com/coleam00/bolt.new-any-llm.git) to customize and extend functionalities to suit your specific project needs.\n\nBolt.new, especially when integrated with Ollama, represents a significant leap forward in AI\\-powered web development. By combining advanced AI models with robust development tools, Bolt.new simplifies the process of building, deploying, and managing full\\-stack applications. Whether you‚Äôre looking to expedite your development workflow, explore AI\\-driven coding assistance, or build sophisticated web applications with minimal setup, Bolt.new provides the tools and flexibility to achieve your goals.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/build-a-customer-support-assistant-with-llama3-1-7bf60611e428","frontmatter":{"title":"Build a Customer Support Assistant with Llama3.1","meta_title":"Build a Customer Support Assistant with Llama3.1","description":"Use LLM Agents and Amazon Bedrock to Solve Customer Queries with AI: A Guide to Building and Deploying a Support Assistant with Llama3.1","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lNyf72c2_r1wKjnoRA1_FQ.png","categories":["Programming","Chatbots","Technology/Web"],"author":"Rifx.Online","tags":["Llama3.1","AmazonBedrock","Gradio","EC2","CustomerSupport"],"draft":false,"slug":"blog/build-a-customer-support-assistant-with-llama3-1-7bf60611e428"},"content":"\n\n\n\n\n### Use LLM Agents and Amazon Bedrock to Solve Customer Queries with AI: A Guide to Building and Deploying a Support Assistant with Llama3\\.1\n\n\n\n\n## Introduction\n\n\n### Problem\n\nBusinesses often face the challenge of handling a large volume of customer inquiries. These queries can range from mundane questions like ‚ÄúWhat is the status of my order?‚Äù to more complex issues requiring human intervention. The sheer volume of repetitive queries can overwhelm customer support teams, leading to longer response times and reduced customer satisfaction. Additionally, utilizing human resources for simple, routine queries is inefficient and costly. There‚Äôs a growing need for automated solutions that can handle routine queries effectively, allowing human agents to focus on escalated cases that require nuanced problem\\-solving.\n\n\n### Solution\n\nThe introduction of Large Language Model (LLM) agents offers a promising solution to this problem. An [LLM agent](https://proxy.rifx.online/https://research.ibm.com/blog/what-are-ai-agents-llm) can respond to user queries by accessing and interpreting data from a company‚Äôs database, handling simple operations such as checking order status, retrieving account information, and answering FAQs. By automating these routine tasks, an LLM agent ensures faster resolution times and frees up human resources for more complex customer support scenarios. In this guide, we‚Äôll explore how to build a customer support assistant using the Llama3\\.1 model from Amazon Bedrock Tools api.\n\nAt the end, we will have the assistant running locally in our machine and making calls to a fake database:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Ok9N3mdX50JVWbaJKUrJeQ.gif)\n\n\n## LLM Agents\n\n\n### What are LLM agents\n\n[LLM agents](https://proxy.rifx.online/https://research.ibm.com/blog/what-are-ai-agents-llm) are specialized applications built on large language models like Llama3\\.1, designed to perform specific tasks or functions. Unlike general LLMs, which generate human\\-like text based on a given prompt, LLM agents are equipped with additional capabilities such as accessing external databases, performing operations, and making decisions based on predefined rules. They are tailored to handle specific use cases, such as customer support, where they can interact with users, retrieve information, and execute commands based on the context of the conversation.\n\nWhile general LLMs are powerful in generating coherent text and understanding language, LLM agents take this a step further by integrating with external systems, allowing them to perform real\\-world tasks beyond just text generation.\n\nAgent have set of instructions, a foundation model, a set of available actions and knowledge bases, which enables then to execute complex tasks.\n\nA generative model can answer a general question, or a question related to your documentation, like ‚ÄúI can‚Äôt see my meetings?, How do I book a meeting?‚Äù. An agent, using a foundational model as their reasoning logic and external data sources like your APIs, can return the user their no. of booked meetings, or directly schedule a meeting from the interaction screen.\n\nThere are many agents in the ‚Äúgeneral purpose‚Äù category, and also specialized agents for task specific purpose like code assistant ([Amazon CodeWhisperer, Copilot](https://proxy.rifx.online/https://www.missioncloud.com/blog/github-copilot-vs-amazon-codewhisperer)), writing assistant, system design ([Amazon Q](https://proxy.rifx.online/https://aws.amazon.com/q/)) , wikipedia summary, etc.\n\n**AI agents landscape:**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VuAyzZ2BfrD7o-z0lOpUwA.png)\n\n\n### Creating a Basic Agent from Scratch Using Python\n\nLet‚Äôs create a simple LLM agent from scratch using Python. This amazing medium article demonstrates how to build an agent without relying on any libraries or frameworks.\n\n\n## Custom Support Assistant\n\nNow, let‚Äôs create a more sophisticated customer support assistant using the [Llama3\\.1](https://proxy.rifx.online/https://llama.meta.com/) model from [Bedrock](https://proxy.rifx.online/https://aws.amazon.com/bedrock/) Tools. This agent will be able to perform more complex tasks, such as looking up user data from a database and executing simple operations like viewing shipping status of an order.\n\n\n### Defining Capabilities and boundaries\n\nBefore building our assistant, it‚Äôs essential to define what actions the agent can perform and establish clear boundaries for its operation. In a production environment, these capabilities and boundaries are crucial to ensure the agent operates effectively and securely.\n\n**Capabilities:**\n\n* Respond to common customer queries (e.g., order status, return policy).\n* Access and retrieve user data from a database.\n* Perform simple operations like viewing order status, updating customer information, etc.\n\n**Boundaries:**\n\n* The agent should not execute actions that require human judgment, such as processing refunds or handling escalations.\n* It should operate within the defined scope and not access sensitive data unless explicitly permitted.\n* Error handling and fallback mechanisms should be in place for unsupported queries.\n\n\n### Architecture\n\nThe system architecture for our solution involves several components working together:\n\n1. **LLM Agent**: The core of the system, built using the [Llama3\\.1](https://proxy.rifx.online/https://llama.meta.com/) or [Claude 3\\.5 Sonnet](https://proxy.rifx.online/https://www.anthropic.com/news/claude-3-5-sonnet) model, which handles natural language processing and decision\\-making.\n2. **Database**: Stores customer data and other relevant information that the agent can query.\n3. **API Layer**: Facilitates communication between the LLM agent and the database, allowing the agent to retrieve and manipulate data.\n4. **User Interface**: A frontend interface (e.g., a chatbot interface) where customers interact with the support assistant.\n\n\n### Code\n\nBefore we examine the code, please ensure you have the following:\n\n1. Knowledge of Python and the [boto3](https://proxy.rifx.online/https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) library.\n2. A working AWS account with model access enabled in [Bedrock](https://proxy.rifx.online/https://aws.amazon.com/bedrock/).\n3. [A virtual environment](https://proxy.rifx.online/https://docs.anaconda.com/miniconda/) with Python and boto3 installed.\n\n\n\n\n\n\n\n\n### Code Walkthrough\n\n\n```python\nfrom datetime import datetime\nimport json\nfrom typing import Any, Dict, List\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n## Initialize a Boto3 session and create a Bedrock runtime client\nsession = boto3.Session()\nregion = \"us-east-1\" # us-west-2 has better runtime quota\nbedrock_client = session.client(service_name = 'bedrock-runtime', region_name = region)\n```\nFirst, we import the necessary packages and create an instance of the `boto3` Bedrock runtime client, called `bedrock_client`, for the `us-east-1` region. If your AWS account has the `us-west-2` availability zone (AZ) enabled, use that instead. At the time of writing, Llama3\\.1 models are only available in the `us-west-2` AZ and it also has a larger runtime quota for the `claude-3.5-sonnet` model (250 requests per minute) compared to the `us-east-1` AZ, which supports only 50 requests per minute.\n\n\n```python\n## Define available models with their respective request limits\navailable_models = {\n    \"sonnet3-5\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\", # 50 requests per min\n    \"sonnet\": \"anthropic.claude-3-sonnet-20240229-v1:0\", # 500 requests per min\n    \"llama31-70b\": \"meta.llama3-1-70b-instruct-v1:0\", # 400 requests per min\n    \"llama31-405b\": \"meta.llama3-1-405b-instruct-v1:0\", # 50 requests per min\n}\nmodelId = available_models[\"sonnet3-5\"]  # Select model for conversation\n```\nNext, we create a mapping of model IDs in Bedrock. **Currently not all the models available in Amazon Bedrock support tool use**. Please check the list of [supported models](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features) from Amazon Bedrock user guide [here](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features).\n\n\n```python\nclass FakeDatabase:\n    \"\"\"Sample fake database implementation.\"\"\"\n    def __init__(self):\n        self.customers = [\n            {\"id\": \"1213210\", \"name\": \"John Doe\", \"email\": \"john@gmail.com\", \"phone\": \"123-456-7890\", \"username\": \"johndoe\"},\n            {\"id\": \"2837622\", \"name\": \"Priya Patel\", \"email\": \"priya@candy.com\", \"phone\": \"987-654-3210\", \"username\": \"priya123\"},\n            {\"id\": \"3924156\", \"name\": \"Liam Nguyen\", \"email\": \"lnguyen@yahoo.com\", \"phone\": \"555-123-4567\", \"username\": \"liamn\"},\n            {\"id\": \"4782901\", \"name\": \"Aaliyah Davis\", \"email\": \"aaliyahd@hotmail.com\", \"phone\": \"111-222-3333\", \"username\": \"adavis\"},\n            {\"id\": \"5190753\", \"name\": \"Hiroshi Nakamura\", \"email\": \"hiroshi@gmail.com\", \"phone\": \"444-555-6666\", \"username\": \"hiroshin\"},\n            {\"id\": \"6824095\", \"name\": \"Fatima Ahmed\", \"email\": \"fatimaa@outlook.com\", \"phone\": \"777-888-9999\", \"username\": \"fatimaahmed\"},\n            {\"id\": \"7135680\", \"name\": \"Alejandro Rodriguez\", \"email\": \"arodriguez@protonmail.com\", \"phone\": \"222-333-4444\", \"username\": \"alexr\"},\n            {\"id\": \"8259147\", \"name\": \"Megan Anderson\", \"email\": \"megana@gmail.com\", \"phone\": \"666-777-8888\", \"username\": \"manderson\"},\n            {\"id\": \"9603481\", \"name\": \"Kwame Osei\", \"email\": \"kwameo@yahoo.com\", \"phone\": \"999-000-1111\", \"username\": \"kwameo\"},\n            {\"id\": \"1057426\", \"name\": \"Mei Lin\", \"email\": \"meilin@gmail.com\", \"phone\": \"333-444-5555\", \"username\": \"mlin\"}\n        ]\n\n        self.orders = [\n            {\"id\": \"24601\", \"customer_id\": \"1213210\", \"product\": \"Wireless Headphones\", \"quantity\": 1, \"price\": 79.99, \"status\": \"Shipped\"},\n            {\"id\": \"13579\", \"customer_id\": \"1213210\", \"product\": \"Smartphone Case\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Processing\"},\n            {\"id\": \"97531\", \"customer_id\": \"2837622\", \"product\": \"Bluetooth Speaker\", \"quantity\": 1, \"price\": \"49.99\", \"status\": \"Shipped\"}, \n            {\"id\": \"86420\", \"customer_id\": \"3924156\", \"product\": \"Fitness Tracker\", \"quantity\": 1, \"price\": 129.99, \"status\": \"Delivered\"},\n            {\"id\": \"54321\", \"customer_id\": \"4782901\", \"product\": \"Laptop Sleeve\", \"quantity\": 3, \"price\": 24.99, \"status\": \"Shipped\"},\n            {\"id\": \"19283\", \"customer_id\": \"5190753\", \"product\": \"Wireless Mouse\", \"quantity\": 1, \"price\": 34.99, \"status\": \"Processing\"},\n            {\"id\": \"74651\", \"customer_id\": \"6824095\", \"product\": \"Gaming Keyboard\", \"quantity\": 1, \"price\": 89.99, \"status\": \"Delivered\"},\n            {\"id\": \"30298\", \"customer_id\": \"7135680\", \"product\": \"Portable Charger\", \"quantity\": 2, \"price\": 29.99, \"status\": \"Shipped\"},\n            {\"id\": \"47652\", \"customer_id\": \"8259147\", \"product\": \"Smartwatch\", \"quantity\": 1, \"price\": 199.99, \"status\": \"Processing\"},\n            {\"id\": \"61984\", \"customer_id\": \"9603481\", \"product\": \"Noise-Cancelling Headphones\", \"quantity\": 1, \"price\": 149.99, \"status\": \"Shipped\"},\n            {\"id\": \"58243\", \"customer_id\": \"1057426\", \"product\": \"Wireless Earbuds\", \"quantity\": 2, \"price\": 99.99, \"status\": \"Delivered\"},\n            {\"id\": \"90357\", \"customer_id\": \"1213210\", \"product\": \"Smartphone Case\", \"quantity\": 1, \"price\": 19.99, \"status\": \"Shipped\"},\n            {\"id\": \"28164\", \"customer_id\": \"2837622\", \"product\": \"Wireless Headphones\", \"quantity\": 2, \"price\": 79.99, \"status\": \"Processing\"}\n        ]\n\n    def get_user(self, key:str, value:str) -> Dict[str, str]:\n        \"\"\"Return metadata of user.\"\"\"\n        if key in {\"email\", \"phone\", \"username\"}:\n            for customer in self.customers:\n                if customer[key] == value:\n                    return customer\n            return f\"Couldn't find a user with {key} of {value}\"\n        else:\n            raise ValueError(f\"Invalid key: {key}\")\n        \n        return None\n\n    def get_order_by_id(self, order_id: str) -> Dict[str, str]:\n        \"\"\"Return metadata of the order using order id.\"\"\"\n        for order in self.orders:\n            if order[\"id\"] == order_id:\n                return order\n        return None\n    \n    def get_customer_orders(self, customer_id: str) -> List[Dict[str, str]]:\n        \"\"\"Return a list of orders for a specific customer.\"\"\"\n        return [order for order in self.orders if order[\"customer_id\"] == customer_id]\n\n    def cancel_order(self, order_id: str) -> str:\n        \"\"\"Cancel an order if it's in 'Processing' status.\"\"\"\n        order = self.get_order_by_id(order_id)\n        if order:\n            if order[\"status\"] == \"Processing\":\n                order[\"status\"] = \"Cancelled\"\n                return \"Cancelled the order\"\n            else:\n                return \"Order has already shipped.  Can't cancel it.\"\n        return \"Can't find that order!\"\n```\nFor this demo, we implement a mock database class with a predefined list of customers and their orders. This mock database class also includes methods to retrieve data from the database.\n\n* `get_user` : Returns the user\n* `get_order_by_id` : Returns the order using order id\n* `get_customer_orders` : Returns all the orders of a particular customer\n* `cancel_order` : Cancel an order if it‚Äôs in ‚ÄòProcessing‚Äô status.\n\n\n```python\n## Define all the tools avilable to the model\ntool_config = {\n    \"tools\": [\n        {\n            \"toolSpec\": {\n                \"name\": \"get_user\",\n                \"description\": \"Looks up a user by email, phone, or username.\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"key\": {\n                                \"type\": \"string\",\n                                \"enum\": [\"email\", \"phone\", \"username\"],\n                                \"description\": \"The attribute to search for a user by (email, phone, or username).\",\n                            },\n                            \"value\": {\n                                \"type\": \"string\",\n                                \"description\": \"The value to match for the specified attribute.\",\n                            },\n                        },\n                        \"required\": [\"key\", \"value\"],\n                    }\n                },\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"get_order_by_id\",\n                \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"order_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The unique identifier for the order.\",\n                            }\n                        },\n                        \"required\": [\"order_id\"],\n                    }\n                },\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"get_customer_orders\",\n                \"description\": \"Retrieves the list of orders belonging to a user based on a user's customer id.\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"customer_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The customer_id belonging to the user\",\n                            }\n                        },\n                        \"required\": [\"customer_id\"],\n                    }\n                },\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"cancel_order\",\n                \"description\": \"Cancels an order based on a provided order_id.  Only orders that are 'processing' can be cancelled\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"order_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The order_id pertaining to a particular order\",\n                            }\n                        },\n                        \"required\": [\"order_id\"],\n                    }\n                },\n            }\n        },\n    ],\n    \"toolChoice\": {\"auto\": {}},\n}\n```\nNext we define a `tool_config` .\n\nYou can use the Amazon Bedrock API to give a model access to [tools](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html) that can help it generate responses for messages that you send to the model. For example, you might have a chat application that lets users find out out the most popular song played on a radio station. To answer a request for the most popular song, a model needs a tool that can query and return the song information.\n\n\n> Tool use with models is also known as *Function calling*.\n\nIn Amazon Bedrock, the model doesn‚Äôt directly call the tool. Rather, when you send a message to a model, you also supply a definition for one or more tools that could potentially help the model generate a response. In this example, you would supply a definition for tools that returns the customer details, order details or cancel an order. If the model determines that it needs the tool to generate a response for the message, the model responds with a request for you to call the tool. It also includes the input parameters (the required customer id or order id) to pass to the tool.\n\nIn your code, you call the tool on the model‚Äôs behalf. In this scenario, assume the tool implementation is an API. The tool could just as easily be a database, Lambda function, or some other software. You decide how you want to implement the tool. You then continue the conversation with the model by supplying a message with the result from the tool. Finally the model generates a response for the original message that includes the tool results that you sent to the model.\n\nIn our example, we define all the functions we want the chatbot to execute in the `tool_config` . Refer to the [Amazon Bedrock documentation](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ToolConfiguration.html) for more information on the ToolConfiguration API.\n\n\n```python\ndef process_tool_call(tool_name: str, tool_input: Any) -> Any:\n    \"\"\"Process the tool call based on the tool name and input.\"\"\"\n    if tool_name == \"get_user\":\n        return db.get_user(tool_input[\"key\"], tool_input[\"value\"])\n    elif tool_name == \"get_order_by_id\":\n        return db.get_order_by_id(tool_input[\"order_id\"])\n    elif tool_name == \"get_customer_orders\":\n        return db.get_customer_orders(tool_input[\"customer_id\"])\n    elif tool_name == \"cancel_order\":\n        return db.cancel_order(tool_input[\"order_id\"])\n```\nSince our application code will call the required tools on behalf of the LLM, we package all the tools into a single function. The `process_tool_call` function executes the appropriate functions based on the `tool_name` and `tool_input` provided by the LLM.\n\n\n```python\ndef simple_chat():\n    \"\"\"Main chat function that interacts with the user and the LLM.\"\"\"\n    system_prompt = \"\"\"\n    You are a customer support chat bot for an online retailer called TechNova. \n    Your job is to help users look up their account, orders, and cancel orders.\n    Be helpful and brief in your responses.\n    You have access to a set of tools, but only use them when needed.  \n    If you do not have enough information to use a tool correctly, ask a user follow up questions to get the required inputs.\n    Do not call any of the tools unless you have the required data from a user. \n    \"\"\"\n    # Initial user message\n    user_message = input(\"\\nUser: \")\n    messages = [{\"role\": \"user\", \"content\": [{\"text\": user_message}]}]\n\n    while True:\n        # If the last message is from the assistant, get another input from the user\n        if messages[-1].get(\"role\") == \"assistant\":\n            user_message = input(\"\\nUser: \")\n            messages.append({\"role\": \"user\", \"content\": [{\"text\": user_message}]})\n\n        # Parameters for API request to the Bedrock model\n        converse_api_params = {\n            \"modelId\": modelId,\n            \"system\": [{\"text\": system_prompt}],\n            \"messages\": messages,\n            \"inferenceConfig\": {\"maxTokens\": 4096},\n            \"toolConfig\": tool_config,  # Pass the tool config\n        }\n\n        # Get response from Bedrock model\n        response = bedrock_client.converse(**converse_api_params)\n\n        # Append assistant's message to the conversation\n        messages.append(\n            {\"role\": \"assistant\", \"content\": response[\"output\"][\"message\"][\"content\"]}\n        )\n\n        # If the model wants to use a tool, process the tool call\n        if response[\"stopReason\"] == \"tool_use\":\n            tool_use = response[\"output\"][\"message\"][\"content\"][\n                -1\n            ]  # Naive approach assumes only 1 tool is called at a time\n            tool_id = tool_use[\"toolUse\"][\"toolUseId\"]\n            tool_name = tool_use[\"toolUse\"][\"name\"]\n            tool_input = tool_use[\"toolUse\"][\"input\"]\n\n            print(f\"Claude wants to use the {tool_name} tool\")\n            print(f\"Tool Input:\")\n            print(json.dumps(tool_input, indent=2))\n\n            # Run the underlying tool functionality on the fake database\n            tool_result = process_tool_call(tool_name, tool_input)\n\n            print(f\"\\nTool Result:\")\n            print(json.dumps(tool_result, indent=2))\n\n            # Append tool result message\n            messages.append(\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"toolResult\": {\n                                \"toolUseId\": tool_id,\n                                \"content\": [{\"text\": str(tool_result)}],\n                            }\n                        }\n                    ],\n                }\n            )\n\n        else:\n            # If the model does not want to use a tool, just print the text response\n            print(\n                \"\\nTechNova Support:\"\n                + f\"{response['output']['message']['content'][0]['text']}\"\n            )\n```\nThe `simple_chat` function handles user interaction, invokes the LLM, and passes the tool response back to the LLM.\n\nAn important line in this function is `response[\"stopReason\"] == \"tool_use\"`. This determines if the LLM wants to use a tool and, when parsed further, indicates which tool the LLM intends to invoke.\n\nAn example of response object of bedrock\\-runtime `converse` api:\n\n\n```python\n{\n    'ResponseMetadata': {\n        'RequestId': '07f323a7-cc52-4813-9d1b-83e5c3ae932a', \n        'HTTPStatusCode': 200, \n        'HTTPHeaders': {\n            'date': 'Thu, 08 Aug 2024 10:52:59 GMT', \n            'content-type': 'application/json', \n            'content-length': '519', \n            'connection': 'keep-alive', \n            'x-amzn-requestid': '07f323a7-cc52-4813-9d1b-83e5c3ae932a'\n        }, \n        'RetryAttempts': 0\n    }, \n    'output': {\n        'message': {\n            'role': 'assistant', 'content': [\n                {\n                    'text': \"Certainly! I'll search for search for your orders. Let me use our search tool to find that information for you.\"\n                }, {\n                    'toolUse': {\n                        'toolUseId': 'tooluse_8C_XIwrAROC3t3eEu5FCVw', \n                        'name': 'get_customer_orders', \n                        'input': {'customer_id': '1213210'}\n                    }\n                }\n            ]\n        }\n    }, \n    'stopReason': 'tool_use',\n    'usage': {'inputTokens': 672, 'outputTokens': 103, 'totalTokens': 775}, \n    'metrics': {'latencyMs': 2431}\n}\n```\nRefer to the [Amazon Bedrock API Reference](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html) for more details about the Converse API.\n\nOnce we invoke the required tool or function using our `process_tool_call` function, we pass the function's response back to the LLM to generate a response for the end user.\n\nPlease note that we are using the Converse API of the boto3 Bedrock runtime client. You can also use the Converse Stream API to generate a streaming response. For more details, refer to the Amazon Bedrock API Reference for the Converse Stream API and the Boto3 documentation on the Converse Stream API.\n\n\n### Running in local terminal\n\nOnce you have everything set up correctly, run the Python file from inside your virtual environment using:\n\n\n```python\n## From inside the virtual environment\npython main.py\n```\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Ok9N3mdX50JVWbaJKUrJeQ.gif)\n\n\n## Deploy on EC2\n\nYou can deploy the chatbot on an EC2 instance for demonstration purposes using a [Gradio](https://proxy.rifx.online/https://www.gradio.app/) app, which provides a chatbot\\-like interface with just a few lines of code and integrates seamlessly with our main function.\n\n\n### Gradio\n\n[Gradio](https://proxy.rifx.online/https://www.gradio.app/) is an open\\-source Python library that simplifies the process of building and deploying web\\-based machine learning demos. It allows developers to create intuitive web interfaces for their models with minimal coding, making it easier to deploy and share models with others.\n\nLet‚Äôs write a chat function that responds `Yes` or `No` randomly using gradio.\n\nHere‚Äôs our chat function (please execute `pip install gradio` in your virtual environment if you don‚Äôt have it already installed):\n\n\n```python\nimport random\n\nimport gradio as gr\n\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n\ngr.ChatInterface(random_response).launch()\n```\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XxkUM6yO3lmjN545tRlOvQ.png)\n\nRead more about the [gradio chatbot documentation here](https://proxy.rifx.online/https://www.gradio.app/main/docs/gradio/chatbot).\n\n\n### Running a Gradio App on your Web Server with Nginx\n\nLet‚Äôs deploy our chatbot agent on EC2 with Nginx.\n\n**Install Nginx and create new conda env**\n\n1. **Create an EC2 instance** with at least 2‚Äì3 GB of memory. You can also deploy it on your Kubernetes or ECS cluster. Make sure to modify the Nginx configuration file to match your setup.\n\n2\\. **SSH into your EC2 instance** and [install Nginx](https://proxy.rifx.online/https://devopsden.io/article/how-to-install-nginx-on-ec2-instance):\n\n\n```python\nsudo yum update -y\nsudo amazon-linux-extras install nginx1.12\nsudo systemctl start nginx\nsudo systemctl enable nginx\nsudo systemctl status nginx\n```\n3\\. [**Install Miniconda**](https://proxy.rifx.online/https://docs.anaconda.com/miniconda/#quick-command-line-install) to manage Python packages:\n\n\n```python\nmkdir -p ~/miniconda3\nwget https://proxy.rifx.online/https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm -rf ~/miniconda3/miniconda.sh\n\n~/miniconda3/bin/conda init bash\n~/miniconda3/bin/conda init zsh\n```\n4\\. **Create a new Conda environment** with Python 3, and install `boto3` and `gradio`:\n\n\n```python\nconda create --name gradio-demo python=3.12 pip -y\nconda activate gradio-demo\npip install --no-cache-dir gradio boto3\n```\n5\\. **Create a new Python file** for your chatbot and Gradio code. Copy all your code into this file:\n\n\n```python\nvim gradio_demo.py\n```\nAlternatively, you can use `scp` to copy the file directly from your local machine to the remote instance.\n\n**Setup Nginx**\n\nNow we will **set up Nginx** to redirect all traffic from the `/gradio-demo` path to the local server started by the `gradio_demo.py` file. Refer to the [official documentation for running Gradio with Nginx here](https://proxy.rifx.online/https://www.gradio.app/guides/running-gradio-on-your-web-server-with-nginx).\n\n1. Edit the Nginx configuration file located at `/etc/nginx/nginx.conf`:\n\n\n```python\nvim /etc/nginx/nginx.conf\n```\n2\\. In the `http` block, add the following lines to include server block configurations from a separate file:\n\n\n```python\nserver_names_hash_bucket_size  128;\ninclude /etc/nginx/sites-enabled/*;\n```\n3\\. Create a new file in the `/etc/nginx/sites-available` directory (create the directory if it does not already exist), using a filename that represents your app, for example: `sudo vim /etc/nginx/sites-available/my_gradio_app` :\n\n\n```python\nsudo mkdir -p /etc/nginx/sites-enabled\nsudo vim /etc/nginx/sites-available/my_gradio_app\n```\nPaste the following contents in the `my_gradio_app` file:\n\n\n```python\nserver {\n    listen 80;\n    server_name www.ec2-12-34-56-78.us-west-2.compute.amazonaws.com; # Change this to your domain name\n\n    location /gradio-demo/ {  # Change this if you'd like to server your Gradio app on a different path\n        proxy_pass http://127.0.0.1:7860/; # Change this if your Gradio app will be running on a different port\n        proxy_buffering off;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Host $host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n```\n4\\. Create a symbolic link to this file in the `/etc/nginx/sites-enabled` directory:\n\n\n```python\nsudo ln -s /etc/nginx/sites-available/my_gradio_app /etc/nginx/sites-enabled/\n```\n5\\. **Update the `gradio_demo.py` file** to set the root path in the Gradio launch API:\n\n\n```python\n.launch(root_path=\"/gradio-demo\")\n```\n6\\. **Check the Nginx configuration** and restart Nginx:\n\n\n```python\nsudo nginx -t\nsudo systemctl restart nginx\n```\nIf you encounter errors with the `nginx -t` command, resolve those errors before proceeding.\n\n**Run the `gradio_demo.py` file** in the background. You can use either `nohup` or `tmux`:\n\n\n```python\n## From inside the Conda environment\nnohup python gradio_demo.py &\n```\n**Access the EC2 DNS URL** and append `/gradio-demo/` to see your chatbot agent on the Gradio interface.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rcdUROlShsrcaeBDpBKBAQ.png)\n\n\n## Summary\n\nIn this article, we explored how to build a customer support assistant using the [Llama3\\.1](https://proxy.rifx.online/https://llama.meta.com/) or [Claude 3\\.5 Sonnet](https://proxy.rifx.online/https://www.anthropic.com/news/claude-3-5-sonnet) model from Bedrock Tools. We began by defining the problem of handling repetitive customer queries and how LLM agents offer a solution. We then discussed the concept of LLM agents and how they differ from general LLMs. After that, we walked through creating a basic agent in Python and then developed a more complex customer support assistant using the models in Amazon Bedrock. We also covered deploying the assistant on EC2, including an example of using Gradio to create a web interface. By automating routine customer support tasks, businesses can enhance efficiency, reduce costs, and improve customer satisfaction.\n\nIn a production setting, you can pass the logged\\-in user‚Äôs name and ID to the system prompt so that the LLM does not have to ask for basic details from a logged\\-in user. Some actions, such as canceling an order, may require additional gatekeeping. Additionally, if a customer is upset or becomes aggressive, the LLM should be instructed to escalate the case to a human assistant.\n\nYou can connect with me on LinkedIn: <https://proxy.rifx.online/https://linkedin.com/in/maheshrajput>\n\nThank you for reading üòä\n\n\n"},{"lang":"en","group":"blog","slug":"blog/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-4-put-it-all-ba7bbf706bbd","frontmatter":{"title":"Build a RAG-based scientific ChatBot with LangChain, Streamlit & PubMed‚Ää‚Äî‚ÄäPart 4(Put it all‚Ä¶","meta_title":"Build a RAG-based scientific ChatBot with LangChain, Streamlit & PubMed‚Ää‚Äî‚ÄäPart 4(Put it all‚Ä¶","description":"Hello and welcome to the last part of the series to build a scientific ChatBot with Langchain, Streamlit, and PubMed!","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MQ7XtBd9WHn5n-gAMgd6pQ.jpeg","categories":["Chatbots","Natural Language Processing","Science"],"author":"Rifx.Online","tags":["ChatBot","LangChain","Streamlit","PubMed","RAG"],"draft":false,"slug":"blog/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-4-put-it-all-ba7bbf706bbd"},"content":"\n\n\n\n\n\nHello and welcome to the last part of the series to build a scientific ChatBot with Langchain, Streamlit, and PubMed!\n\nIn the previous part, we built the data persistence and RAG pipeline with vectorstore. Now, it is time to put everything we‚Äôve built together, and create the chatbot UI that will use the backend functionality we built, and that our scientist will use to answer their scientific questions!\n\nAs a reminder, this is the full solution that we were building during the series:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*NFCO_uRjlAgm0WYH.png)\n\n\n## App demo\n\n* As a teaser, let‚Äôs first have a look at an illustration of what the app will look like!\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OKEQO_2kwnV93Va4SAVWZg.gif)\n\n\n## Building\n\n\n### Overview of steps already done\n\n* If you haven‚Äôt followed through the [first](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-1-set-up-streamlit-37550b44b266) , the [second](https://proxy.rifx.online/https://readmedium.com/llm-aided-retrieval-of-relevant-scientific-abstracts-via-pubmed-api-using-natural-language-part2-9e10f78575e6), and the [third part](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-3-create-vector-1e5e401e72e6), please do so, because we will be building on that further. At the end of the last part, we ended up with a project structure looking like this:\n\n\n```python\n.\n‚îú‚îÄ‚îÄ app\n‚îÇ   ‚îú‚îÄ‚îÄ app.py\n‚îÇ   ‚îú‚îÄ‚îÄ backend\n‚îÇ   ‚îÇ  ‚îú‚îÄ‚îÄ abstract_retrieval\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ interface.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ pubmed_retriever.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ pubmed_query_simplification.py\n‚îÇ   ‚îÇ  ‚îú‚îÄ‚îÄ data_repository\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ interface.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ local_data_store.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ models.py\n‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ rag_pipeline\n‚îÇ   ‚îÇ      ‚îú‚îÄ‚îÄ interface.py\n‚îÇ   ‚îÇ      ‚îú‚îÄ‚îÄ chromadb_rag.py\n‚îÇ   ‚îÇ      ‚îî‚îÄ‚îÄ embeddings.py\n‚îÇ   ‚îú‚îÄ‚îÄ components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_utils.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py\n‚îÇ   ‚îî‚îÄ‚îÄ tests\n‚îÇ       ‚îî‚îÄ‚îÄ test_chat_utils.py\n‚îú‚îÄ‚îÄ assets\n‚îÇ   ‚îî‚îÄ‚îÄ pubmed-screener-logo.jpg\n‚îî‚îÄ‚îÄ environment\n    ‚îî‚îÄ‚îÄ requirements.txt\n```\nIn this last part of the series, we will focus on the part of code base that defines our Streamlit UI ‚Äî ***app/app.py*** and the ***app/components*** module.\n\n\n### Modify chat\\_utils.py to include RAG logic\n\n[In the first part](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-1-set-up-streamlit-37550b44b266), we built a preliminary version of ***chat\\_utils.py*** that contained a simple QA chatbot implementation (without RAG). Now, we will dive in and convert this into a context\\-aware QA chatbot, that will construct answers based on user questions and retrieve relevant context (abstracts) from our vector index via similarity search.\n\nWe will use all the backend functionality [built in part three](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-3-create-vector-1e5e401e72e6) for this purpose.\n\n**app/components/chat\\_utils.py**\n\n\n```python\nfrom typing import List\nimport streamlit as st\nfrom langchain_core.documents.base import Document\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_core.runnables.base import Runnable\nfrom langchain_core.runnables.utils import Output\nfrom langchain_community.chat_message_histories import StreamlitChatMessageHistory\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.vectorstores import VectorStore\n\n\nclass ChatAgent:\n    def __init__(self, prompt: ChatPromptTemplate, llm: Runnable):\n        \"\"\"\n        Initialize the ChatAgent.\n\n        Args:\n        - prompt (ChatPromptTemplate): The chat prompt template.\n        - llm (Runnable): The language model runnable.\n        \"\"\"\n        self.history = StreamlitChatMessageHistory(key=\"chat_history\")\n        self.llm = llm\n        self.prompt = prompt\n        self.chain = self.setup_chain()\n    \n    def reset_history(self) -> None:\n        \"\"\"\n        Clean up chat history to start new chat session.\n        \"\"\"\n        self.history.clear()\n\n    def setup_chain(self) -> RunnableWithMessageHistory:\n        \"\"\"\n        Set up the chain for the ChatAgent.\n\n        Returns:\n        - RunnableWithMessageHistory: The configured chain with message history.\n        \"\"\"\n        chain = self.prompt | self.llm\n        return RunnableWithMessageHistory(\n            chain,\n            lambda session_id: self.history,\n            input_messages_key=\"question\",\n            history_messages_key=\"history\",\n        )\n\n    def display_messages(self, selected_query: str) -> None:\n        \"\"\"\n        Display messages in the chat interface.\n        If no messages are present, adds a default AI message.\n        \"\"\"\n        if len(self.history.messages) == 0:\n            self.history.add_ai_message(f\"Let's chat about your query: {selected_query}\")\n        for msg in self.history.messages:\n            st.chat_message(msg.type).write(msg.content)\n    \n    def format_retreieved_abstracts_for_prompt(self, documents: List[Document]) -> str:\n        \"\"\"\n        Format retrieved documents in a string to be passed to LLM.\n        \"\"\"\n        formatted_strings = []\n        for doc in documents:\n            formatted_str = f\"ABSTRACT TITLE: {doc.metadata['title']}, ABSTRACT CONTENT: {doc.page_content}, ABSTRACT DOI: {doc.metadata['source'] if 'source' in doc.metadata.keys() else 'DOI missing..'}\"\n            formatted_strings.append(formatted_str)\n        return \"; \".join(formatted_strings)\n    \n    def get_answer_from_llm(self, question: str, retrieved_documents: List[Document]) -> Output:\n        \"\"\"\n        Get response from LLM given user question and retrieved documents.\n        \"\"\"\n        config = {\"configurable\": {\"session_id\": \"any\"}}\n        return self.chain.invoke(\n            {\n                \"question\": question, \n                \"retrieved_abstracts\": retrieved_documents,\n            }, config\n        )\n    \n    def retrieve_documents(self, retriever: VectorStore, question: str, cut_off: int = 5) -> List[Document]:\n        \"\"\"\n        Retrieve documents using similarity search \n        cut_off parameter controls how many results are retrieved (default is 5)\n        \"\"\"\n        return retriever.similarity_search(question)[:cut_off]\n\n    def start_conversation(self, retriever: VectorStore, selected_query: str) -> None:\n        \"\"\"\n        Start a conversation in the chat interface.\n        Displays messages, prompts user for input, and handles AI response.\n        \"\"\"\n        self.display_messages(selected_query)\n        user_question = st.chat_input(placeholder=\"Ask me anything..\")\n        if user_question:\n            documents = self.retrieve_documents(retriever, user_question)\n            retrieved_abstracts = self.format_retreieved_abstracts_for_prompt(documents)\n            st.chat_message(\"human\").write(user_question)\n            response = self.get_answer_from_llm(user_question, retrieved_abstracts)\n            st.chat_message(\"ai\").write(response.content)\n```\n**What has changed:**\n\n* We added the method ***retrieve\\_documents*** that takes our vector index (retriever) as argument, and calls a method similarity\\_search on the retriever to get the most similar records to user‚Äôs question from the vector index of our scientific abstracts. Note the parameter cut\\_off that specifies the number of results to be retrieved (defaults to 5\\).\n* Added method ***format\\_retreieved\\_abstracts\\_for\\_prompt***, that takes the documents retrieved via retrieve\\_documents method, and formats them for the LLM. This will come very handy when we will ask the LLM in our prompt to cite the relevant sources (article DOIs, and titles).\n* Added method ***get\\_answer\\_from\\_llm*** that serves for calling the LLM with necessary variables, to keep the client function start\\_conversation clean.\n* Modified the ***start\\_conversation*** method to include the RAG logic.\n\n\n### Create chat prompts for QA\n\n* We will be modifying the existing chat prompt to include retrieved abstracts and construct the answer based on those.\n* We will also include an additional (simple) prompt that will serve for a simple immediate answer outside of the chatbot section, so that the user gets a direct answer to his question displayed on the UI.\n\n**app/components/chat\\_prompts.py**\n\n\n```python\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n\n\nchat_prompt_template = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"You are a knowledgeable expert chatbot in the biomedicine field.\"),\n        MessagesPlaceholder(variable_name=\"history\"),\n        (\n            \"human\", \n            \"\"\"\n            Answer the following scientific question: {question}, \n            using the following context retrieved from scientific articles: {retrieved_abstracts}.\n\n            The user might refer to the history of your conversation. Please, use the following history of messages for the context as you see fit.\n\n            The abstracts will come formatted in the following way: ABSTRACT TITLE: <abstract title>; ABSTRACT CONTENT: <abstract content>, ABSTRACT DOI: <abstract doi> (the content inside <> will be variable).\n            In your answer, ALWAYS cite the abstract title and abstract DOI when citing a particular piece of information from that given abstract.\n\n            Your example response might look like this:\n\n            In the article (here in the brackets goes the contents of ABSTRACT_TITLE), it was discussed, that Cannabis hyperemesis syndrome (CHS) is associated with chronic, heavy cannabis use. The endocannabinoid system (ECS) plays a crucial role in the effects of cannabis on end organs and is central to the pathophysiology of CHS. (here, in the end of the cited chunk, the ABSTRACT_DOI goes)\n            \"\"\"\n        ),\n    ]\n)\n\nqa_template = PromptTemplate(\n    input_variables=['question', 'retrieved_abstracts'],\n    template=\"\"\"\n        Answer the following scientific question: {question}, \n        using the following context retrieved from scientific articles: {retrieved_abstracts}.\n\n        The abstracts will come formatted in the following way: ABSTRACT TITLE: <abstract title>; ABSTRACT CONTENT: <abstract content>, ABSTRACT DOI: <abstract doi> (the content inside <> will be variable).\n        In your answer, ALWAYS cite the abstract title and abstract DOI when citing a particular piece of information from that given abstract.\n\n        Your example response might look like this:\n\n        In the article (here in the brackets goes the contents of ABSTRACT_TITLE), it was discussed, that Cannabis hyperemesis syndrome (CHS) is associated with chronic, heavy cannabis use. The endocannabinoid system (ECS) plays a crucial role in the effects of cannabis on end organs and is central to the pathophysiology of CHS. (here, in the end of the cited chunk, the ABSTRACT_DOI goes)\n    \"\"\"\n)\n```\n* Note that the contents of the two prompts is almost identical, but the chat prompt contains a reference for the chat history with the MessagesPlaceholder and an instruction to use the chat history as the LLM sees fit during the conversation.\n\n\n### Create new file app/components/layout\\_extensions.py\n\n* This file will hold a helper function that will render a part of the layout of our app with examples of queries (cues on how to use the app) to the user. I decided to create this extensions file to not clutter our app.py file and keep it clean, since this code is quite lengthy and contains some custom styling (the app info will be displayed to the user on hover):\n\n\n```python\nimport streamlit as st\n\n\ndef render_app_info():\n    st.title(\"PubMed Screener\")\n    st.markdown(\"\"\"\n        PubMed Screener is a ChatGPT & PubMed powered insight generator from biomedical abstracts.\n    \"\"\")\n\n    # Adding custom HTML and CSS for an improved hover-over tooltip\n    st.markdown(\"\"\"\n        <style>\n        .tooltip {\n            position: relative;\n            display: inline-block;\n            border-bottom: 1px dotted black; /* Style for the hoverable text */\n        }\n\n        .tooltip .tooltiptext {\n            visibility: hidden;\n            width: 800px; /* Width to fit content */\n            background-color: #f9f9f9;\n            color: #000;\n            text-align: left;\n            border-radius: 6px;\n            padding: 15px;\n            position: absolute;\n            z-index: 1;\n            bottom: 100;\n            right: -430px; /* Positioning to the right and slightly offset */\n            opacity: 0;\n            transition: opacity 0.5s;\n            box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.8); /* Adding some shadow for better visibility */\n        }\n\n        .tooltip:hover .tooltiptext {\n            visibility: visible;\n            opacity: 1;\n        }\n        </style>\n        <div class=\"tooltip\">üîç Example Questions\n            <span class=\"tooltiptext\">\n                <strong>Example scientific questions:</strong>\n                <ul>\n                    <li>How can advanced imaging techniques and biomarkers be leveraged for early diagnosis and monitoring of disease progression in neurodegenerative disorders?</li>\n                    <li>What are the potential applications of stem cell technology and regenerative medicine in the treatment of neurodegenerative diseases, and what are the associated challenges?</li>\n                    <li>What are the roles of gut microbiota and the gut-brain axis in the pathogenesis of type 1 and type 2 diabetes, and how can these interactions be modulated for therapeutic benefit?</li>\n                    <li>What are the molecular mechanisms underlying the development of resistance to targeted cancer therapies, and how can these resistance mechanisms be overcome?</li>\n                </ul>\n            </span>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n    \n    st.text(\"\")py\n```\n\n### Modify the app/app.py\n\n* Finally, time to put everything we‚Äôve built together and expose it as a streamlit application!\n\n\n```python\nimport streamlit as st\nfrom metapub import PubMedFetcher\nfrom components.chat_utils import ChatAgent\nfrom components.chat_prompts import chat_prompt_template, qa_template\nfrom components.llm import llm\nfrom components.layout_extensions import render_app_info\nfrom backend.abstract_retrieval.pubmed_retriever import PubMedAbstractRetriever\nfrom backend.data_repository.local_storage import LocalJSONStore\nfrom backend.rag_pipeline.chromadb_rag import ChromaDbRag\nfrom backend.rag_pipeline.embeddings import embeddings\n\n\n## Instantiate objects\npubmed_client = PubMedAbstractRetriever(PubMedFetcher())\ndata_repository = LocalJSONStore(storage_folder_path=\"backend/data\")\nrag_client = ChromaDbRag(persist_directory=\"backend/chromadb_storage\", embeddings=embeddings)\nchat_agent = ChatAgent(prompt=chat_prompt_template, llm=llm)\n\ndef main():\n    st.set_page_config(\n        page_title=\"Pubmed Abstract Screener\",\n        page_icon='üí¨',\n        layout='wide'\n    )\n\n    # Define columns - this will make layout split horizontally\n    column_logo, column_app_info, column_answer = st.columns([1, 4, 4])\n\n    # Place the logo in the first column\n    with column_logo:\n        st.image('../assets/pubmed-screener-logo.jpg')\n\n    # In the second column, place text explaining the purpose of the app and some example scientific questions that your user might ask.\n    with column_app_info:\n\n        # Runder app info including example questions as cues for the user\n        render_app_info()\n\n        # Section to enter scientific question\n        st.header(\"Enter your scientific question!\")\n        placeholder_text = \"Type your scientific question here...\"\n        scientist_question = st.text_input(\"What is your question?\", placeholder_text)\n        get_articles = st.button('Get articles & Answer')\n\n        # Processing user question, fetching data\n        with st.spinner('Fetching abstracts. This can take a while...'):\n            if get_articles:\n                if scientist_question and scientist_question != placeholder_text:\n\n                    # Get abstracts data\n                    retrieved_abstracts = pubmed_client.get_abstract_data(scientist_question)\n                    if not retrieved_abstracts:\n                        st.write('No abstracts found.')\n                    else:\n                        # Save abstarcts to storage and create vector index\n                        query_id = data_repository.save_dataset(retrieved_abstracts, scientist_question)\n                        documents = data_repository.create_document_list(retrieved_abstracts)\n                        rag_client.create_vector_index_for_user_query(documents, query_id)\n                        \n                        # Answer the user question and display the answer on the UI directly\n                        vector_index = rag_client.get_vector_index_by_user_query(query_id)\n                        retrieved_documents = chat_agent.retrieve_documents(vector_index, scientist_question)\n                        chain = qa_template | llm\n                        \n                        with column_answer:\n                            st.markdown(f\"##### Answer to your question: '{scientist_question}'\")\n                            st.write(chain.invoke({\n                                \"question\": scientist_question, \n                                \"retrieved_abstracts\": retrieved_documents,\n                            }).content)\n\n    # Beginning of the chatbot section\n    # Display list of queries to select one to have a conversation about\n    query_options = data_repository.get_list_of_queries()\n\n    if query_options:\n        st.header(\"Chat with the abstracts\")\n        selected_query = st.selectbox('Select a past query', options=list(query_options.values()), key='selected_query')\n        \n        # Initialize chat about some query from the history of user questions\n        if selected_query:\n            selected_query_id = next(key for key, val in query_options.items() if val == selected_query)\n            vector_index = rag_client.get_vector_index_by_user_query(selected_query_id)\n\n            # Clear chat history when switching query to chat about\n            if 'prev_selected_query' in st.session_state and st.session_state.prev_selected_query != selected_query:\n                chat_agent.reset_history()\n\n            st.session_state.prev_selected_query = selected_query\n\n            # Start chat session\n            chat_agent.start_conversation(vector_index, selected_query)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n* The code contains the following parts:\n1. Instantiate all objects that we built in previous parts of the series ‚Üí ***PubMedAbstractRetriever***, ***LocalJSONStore***, ***ChromaDbRag***, and ***ChatAgent***. We will be using all those objects in our app code.\n2. Define layout to render app title, logo, and app info.\n3. Define input for the user‚Äôs question, and a button to submit it. When the button is clicked, this triggers the logic to search \\& fetch PubMed articles (using ***PubMedAbstractRetriever ‚Äî*** pubmed\\_client), save them to the local data repository (with ***LocalJSONStore ‚Äî***data\\_repository), and create a vector index for them (with ***ChromaDbRag ‚Äî*** rag\\_client).\n4. Answer the user question directly and show it on the UI.\n5. Display ChatBot section that will let you select a past query to chat about, in case you want to interrogate the abstracts further. After the selection of a past query, the corresponding vector index is loaded, and a chat session is initiated (***chat\\_agent.start\\_conversation(‚Ä¶)***). Now you can chat with your abstracts!\n\n\n## Limitations\n\nI am happy you went with me through this series where we built a prototype of a scientific chatbot! It is necessary to say though, that this application is a PoC scope ONLY, and the implementation presented has its caveats that would need to be addressed before deploying in a production manner.\n\n**Naive RAG limitations and considerations**\n\n* **Retrieved content relevance**: you can‚Äôt be sure if the retrieved content (the content most similar to user‚Äôs question) is the most relevant piece of information. There are some techniques of advanced RAG, like *H**ypothetical Questions*****,** or ***Hierarchical indexing*** that can help with that ‚Äî read more about those techniques and more [in this article](https://proxy.rifx.online/https://readmedium.com/advanced-rag-techniques-unlocking-the-next-level-040c205b95bc)\n* **Retrieved content cut off**: It is hard to assess whether all the relevant information was retrieved. Also, it can be challenging to fit all the context to the prompt due to the token limits of LLMs. The default cut off in our case equals to 5 abstracts (in our ChatAgent retrieve\\_documents method), which can certainly not be enough if the user asks a broad question.\n* **Limited applicability**: Sometimes, the user question can be rather of a summarization character, and a different technique than RAG would be more appropriate for this purpose. For example, you could build an agent that decides whether task is summarization / retrieval based on user question. After this evaluation, there would be a function executing different logic that performs summarization or retrieval, respectively.\n\n**Deployment architecture considerations**\n\n* **Runtime environment**: For the scope of this series, we only built our chatbot locally, not considering any architectural decisions we would need to make if we would like to deploy this app to serve some real users.\n* **Synchronous processing**: Since the data fetching can take a considerable amount of time, it would be more efficient to implement a queue\\-based asynchronous processing of user requests, and notify user when data fetching is done. Doing this in a synchronous manner can take a lot of time which can result in timeouts in many servers.\n* **Backend technologies**: The backend used in our case was ChromaDB with local storage using JSON files. For a deployed application serving users, this should be re\\-evaluated and appropriate technology selected. This can be easily achieved by building on the interface definitions in the app backend code (***RagWorkflow*** and ***UserQueryDataStore*** interfaces).\n\n**Including more scientific databases**\n\n* In the series, we focused on PubMed only, but to provide a rich context base, another scientific paper databases (i.e. Scopus) could be added. This can be easily achieved by building on the interface definitions in the app backend code (***AbstractRetriever*** interface).\n\n\n## Full codebase GitHub link\n\nFeel free to fork the repo and adapt it to your UC!\n\n\n### Link to GitHub repo pubmed\\-rag\\-screener\n\n\n## Summary\n\n* In this last part of the series to build a scientific ChatBot, we put together all the previously built pieces to create a user interface, where our scientist can formulate her/his question, get an answer based on scientific abstracts, and then chat with the abstracts for further insights.\n* The application logic is modular and enables easy extension using provided interfaces.\n* The limitations of the approach were outlined and highlighted, and some suggestions to build a production\\-grade application were included.\n\n\n> Thanks so much for going through this series with me! I hope you enjoyed building this exciting use case :)\n\n\n> Do not hesitate to get in touch with me if you want to discuss anything about dev, data, AI, or just connect ‚Äî [reach out on LinkedIn](https://proxy.rifx.online/https://www.linkedin.com/in/sbarankova/)\n\n\n## Contents of the series\n\n* [Part 1 ‚Äî Explaining the use case, first steps to set up the Streamlit app with chatbot interface.](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-1-set-up-streamlit-37550b44b266)\n* [Part 2 ‚Äî LLM\\-aided retrieval of relevant scientific abstracts via PubMed API using natural language](https://proxy.rifx.online/https://readmedium.com/llm-aided-retrieval-of-relevant-scientific-abstracts-via-pubmed-api-using-natural-language-part2-9e10f78575e6)\n* [Part 3 ‚Äî Setting up the backend ‚Äî Create vector embeddings from the retrieved scientific abstracts and store them in a vector store](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-3-create-vector-1e5e401e72e6)\n* **Part 4 (this article) ‚Äî Put it all together via RAG ‚Äî chat with scientific abstracts**\n\n"},{"lang":"en","group":"blog","slug":"blog/build-your-talking-voice-ai-assistant-locally-memory-retaining-chatbot-with-streamlit-ui-09da4f10687c","frontmatter":{"title":"Build Your Talking Voice AI Assistant Locally: Memory-Retaining Chatbot with Streamlit UI‚Ä¶","meta_title":"Build Your Talking Voice AI Assistant Locally: Memory-Retaining Chatbot with Streamlit UI‚Ä¶","description":"This article provides a comprehensive tutorial for creating a local voice AI assistant named *Porter*, utilizing Ollamas Llama models, Streamlit for the user interface, and OpenAIs Whisper for transcription. *Porter* features memory retention for conversations, allowing it to recall past interactions and provide contextual responses. The guide includes installation instructions, code snippets, and an overview of key functionalities, emphasizing the benefits of privacy and responsiveness by operating offline. The project showcases advancements in natural language processing and the potential for further enhancements in AI capabilities.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5WJoI0IAKwMpEaCdSY63_A.png","categories":["Voice Assistants","Natural Language Processing","Programming/Scripting"],"author":"Rifx.Online","tags":["Porter","Llama","Streamlit","Whisper","offline"],"draft":false,"slug":"blog/build-your-talking-voice-ai-assistant-locally-memory-retaining-chatbot-with-streamlit-ui-09da4f10687c"},"content":"\n\n\n\n\n### Step\\-by\\-Step Guide to Developing Your Own Voice AI with Context Memory and Real\\-Time Chat, Powered by Llama3\\.1 \\& Llama3\\.2 Models\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è \\| üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) \\|üìù [Medium](https://medium.com/@monsuralirana)\n\n\n\nThe concept of a voice\\-based personal assistant has grown beyond being a novelty ‚Äî it has become a practical, hands\\-free solution for busy professionals, remote teams, and tech enthusiasts alike. Imagine a voice AI that can listen, respond, and even keep track of past conversations, all while running locally on your device. Enter *Porter*, a personal AI assistant designed to do just that.\n\nIn this tutorial, we‚Äôll walk you through creating *Porter*, an advanced voice assistant that‚Äôs capable of responding to voice queries, retaining context through conversation memory, and providing responses via synthesized speech. *Porter* leverages Ollama‚Äôs state\\-of\\-the\\-art Llama models, **Streamlit** for an intuitive user interface, and OpenAI‚Äôs **Whisper** model for transcription. This guide will take you step\\-by\\-step from installation to final deployment on a local machine.\n\n\n## Table of Contents\n\n1. Introduction\n2. Why *Porter*?\n3. Key Features of *Porter*\n4. User Interface (UI) Overview\n5. Step\\-by\\-Step Tutorial\n6. Running Porter Locally\n7. Conclusion\n\n\n## 1\\. Introduction\n\nWith recent advancements in natural language processing, voice assistants have become increasingly capable of understanding complex queries, responding in natural language, and even retaining context across conversations. *Porter*, our AI voice assistant, is designed to leverage these advancements, providing users with a natural, responsive, and personalized assistant experience. Porter is built on Ollama‚Äôs advanced models, which provide conversational AI, and uses **Streamlit** for a straightforward, interactive user interface.\n\n**Porter** provides:\n\n* A conversational AI that can remember past exchanges.\n* A smooth interface that‚Äôs easy to navigate.\n* Customizable parameters for personalized responses.\n\n\n## 2\\. Why Porter?\n\nMost voice assistants require internet connectivity and rely on external servers, raising concerns about security, control, and response latency. *Porter*, by running locally, offers:\n\n* **Privacy**: With no need for internet access, all conversations and data stay securely on your machine.\n* **Quick Response Times**: With everything running locally, there‚Äôs minimal delay in processing and response.\n* **Memory\\-Retained Conversations**: Using LangChain, *Porter* can remember context across multiple interactions, giving it the ability to answer follow\\-up questions accurately.\n\n\n## 3\\. Key Features of Porter\n\n\n### Voice Input and Output\n\n*Porter* uses Whisper, a powerful automatic speech recognition (ASR) model, to transcribe voice input into text. It can also generate spoken responses, providing a seamless hands\\-free experience.\n\n\n### Session Memory and Conversation Context\n\nWith LangChain‚Äôs **ConversationBufferMemory**, *Porter* retains past conversations, allowing for multi\\-turn conversations that feel natural. The memory enables *Porter* to reference past user queries and provide continuity.\n\n\n### History Overview and Chat History\n\n*Porter* includes a **Chat History** feature that provides an overview of all past interactions within the current session. This chat history is displayed on the UI, helping users keep track of what has been discussed.\n\n\n### Customizable Model Parameters\n\nIn *Porter*‚Äôs Streamlit sidebar, users can select different model versions (Llama3\\.1, Llama3\\.2\\) and adjust parameters such as **temperature** and **max tokens** to control response creativity and length.\n\n\n### Streamlit\\-Based User Interface\n\nStreamlit provides a clean, intuitive UI for *Porter*, allowing users to interact with the assistant easily. The app displays previous exchanges, model settings, and allows for easy voice input.\n\n\n## 4\\. User Interface (UI) Overview\n\nThe Streamlit UI for *Porter* is simple and user\\-friendly:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*x_oxCvi14LfcsG8H4VeXUg.png)\n\n* **Voice Input Widget**: A microphone icon lets users record their queries.\n* **Chat Display**: Displays user messages and *Porter*‚Äôs responses, including timestamps and response times.\n* **Settings Sidebar**: Customize *Porter* with model options, temperature, and max tokens.\n* **History Overview**: Review conversation history in the chat window, making it easy to follow previous exchanges.\n\n\n## 5\\. Step\\-by\\-Step Tutorial\n\nLet‚Äôs break down the code to see how to implement Porter. We‚Äôll use two main files: `app.py` (for the Streamlit app) and `voicebot.py` (for backend logic).\n\n\n### Prerequisites:\n\n* Python 3\\.7\\+\n* locally conda environment\n* Streamlit for the UI\n* Ollama for model inference\n* LangChain is used to manage the interaction between the models and memory.\n\n\n### Step 1: Install Necessary Packages\n\nInstall necessary libraries and tools:\n\n\n```python\n!pip install langchain==0.0.318\n!pip install langchain-ollama \n!pip install langchain-community==0.0.3 \n!pip install ollama==0.0.8\n!pip install streamlit==1.25.0\n!pip install pathlib==1.0.1\n!pip install audio-recorder-streamlit==0.0.10\n!pip install torch==2.4.1\n!pip install transformer==4.44.2\n```\n\n> **I have the LLaMA 3\\.1 and 3\\.2 models set up through Ollama. If you don‚Äôt have Ollama or the LLaMA models on your local machine, please follow the instructions at the link below to install them. The link is exclusive to Llama 3\\.2, but you can pull Llama 3\\.1 by simply running `\"ollama pull llama3.1\"`.**\n\n\n> **I‚Äôve used the Piper TTS model for text\\-to\\-speech. It‚Äôs lightweight, 10x faster, works in real\\-time, operates offline, and produces a human\\-like voice.**\n\n\n### Step 2: Setting up the Streamlit App\n\n\n```python\nimport streamlit as st\nimport time\nfrom audio_recorder_streamlit import audio_recorder\nfrom voicebot import initialize_chat, text_to_speech, transcribe_audio\n\nst.title(\"Porter - Your Personal Voice AI Assistant\")\n\n## Initialize session state variables\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\nif \"audio_bytes\" not in st.session_state:\n    st.session_state.audio_bytes = None\n\n## Sidebar Settings\nwith st.sidebar:\n    logo_path = \"/path/to/logo.png\"\n    st.image(logo_path, caption=\"AI Enterprise\", use_column_width=True)\n    st.subheader(\"Inference Settings\")\n    st.session_state.model = st.selectbox(\"Model\", [\"llama3.1\", \"llama3.2:latest\"], index=0)\n    st.session_state.temperature = st.slider(\"Temperature\", 0.0, 1.0, 0.0, 0.05)\n    st.session_state.max_tokens = st.slider(\"Max Tokens\", 100, 5000, 500, 100)\n\n## Initialize chat model\nif \"chain\" not in st.session_state:\n    st.session_state.chain = initialize_chat()\n```\nIn this section:\n\n1. **Session State Variables**: Store message history and audio bytes.\n2. **Sidebar Controls**: Provide UI controls to customize the model, temperature, and token length.\n3. **Chat Model Initialization**: This loads the chat model for use in the app.\n\n\n### Step 3: Implementing the Chat Functionality\n\n\n```python\n## Display chat history\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\n## Record voice input\nfooter_container = st.container()\nwith footer_container:\n    st.session_state.audio_bytes = audio_recorder(text=\"Record a question\", icon_size=\"lg\")\n\nif st.session_state.audio_bytes:\n    transcript = transcribe_audio(st.session_state.audio_bytes)\n    if transcript:\n        st.session_state.messages.append({\"role\": \"user\", \"content\": transcript})\n        \n        # Display user input in chat\n        with st.chat_message(\"user\"):\n            st.markdown(transcript)\n\n        # Get response from model\n        with st.chat_message(\"assistant\"):\n            start_time = time.time()\n            with st.spinner(\"Porter is thinking...\"):\n                response = st.session_state.chain.run(transcript)\n            end_time = time.time()\n\n            response_time_str = f\"Response time: {end_time - start_time:.2f} seconds\"\n            st.markdown(response)\n            text_to_speech(response)\n            st.markdown(f\"_{response_time_str}_\")\n\n        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response, \"response_time\": response_time_str})\n```\nHere:\n\n1. **Display Previous Messages**: The chat window shows the conversation history.\n2. **Voice Input \\& Transcription**: Records and transcribes audio input into text, adding it to the chat.\n3. **Assistant Response**: Sends user input to the model, retrieves a response, and converts it to audio for playback.\n\n\n### Step 4: Implementing the Backend (voicebot.py)\n\nIn `voicebot.py`, the main components are set up to initialize Porter‚Äôs conversation model and handle text\\-to\\-speech and transcription:\n\n\n```python\nimport os\nimport subprocess\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain.memory.chat_message_histories.file import FileChatMessageHistory\nfrom langchain_community.chat_models.ollama import ChatOllama\nfrom langchain.chains.llm import LLMChain\nfrom transformers import pipeline\nimport torch\n\ndef initialize_chat():\n    def get_llm():\n        return ChatOllama(\n            model=st.session_state.model,\n            temperature=st.session_state.temperature,\n            max_tokens=st.session_state.max_tokens,\n        )\n\n    from langchain.prompts import (\n        HumanMessagePromptTemplate,\n        ChatPromptTemplate,\n        MessagesPlaceholder,\n        SystemMessagePromptTemplate,\n    )\n\n    def get_chat_prompt_template():\n        return ChatPromptTemplate(\n            input_variables=[\"content\", \"messages\"],\n            messages=[\n                SystemMessagePromptTemplate.from_template(\n                    \"You're a Personal Assistant, and your name is Porter.\"\n                ),\n                MessagesPlaceholder(variable_name=\"messages\"),\n                HumanMessagePromptTemplate.from_template(\"{content}\"),\n            ],\n        )\n\n    def get_memory():\n        return ConversationBufferMemory(\n            memory_key=\"messages\",\n            chat_memory=FileChatMessageHistory(file_path=\"memory.json\"),\n            return_messages=True,\n            input_key=\"content\",\n        )\n\n    llm = get_llm()\n    prompt = get_chat_prompt_template()\n    return LLMChain(llm=llm, prompt=prompt, memory=get_memory())\n\n## Text-to-speech\ndef text_to_speech(text):\n    subprocess.call(f'echo \"{text}\" | piper --model en_US-amy-medium --output_file output.wav', shell=True)\n    os.system(\"aplay output.wav\")\n\n## Speech recognition\npipe = pipeline(\"automatic-speech-recognition\", \"openai/whisper-large-v3-turbo\", torch_dtype=torch.float16, device=\"cuda:0\")\n\ndef transcribe_audio(audio_bytes):\n    webm_file_path = \"temp_audio.mp3\"\n    with open(webm_file_path, \"wb\") as f:\n        f.write(audio_bytes)\n    \n    transcript = pipe(webm_file_path)['text'].strip()\n    os.remove(webm_file_path)\n    return transcript\n```\nThis section:\n\n1. **Model Setup**: Configures the chat model and prompt template.\n2. **Text\\-to\\-Speech**: Converts model responses to audio.\n3. **Speech\\-to\\-Text**: Uses Whisper to transcribe recorded audio input.\n\n\n### Step 5: Deploying Porter\n\nOnce you‚Äôve completed the setup, you can launch your app using Streamlit. To run the app, navigate to your project folder and run the following command in your terminal:\n\n\n```python\nstreamlit run apps.py\n```\nAfter the app starts, you‚Äôll see the following message in your terminal:\n\n\n```python\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8501\n  Network URL: http://172.30.254.103:8501\n```\nYou can access Porter by opening the **Local URL** (`http://localhost:8501`) in your browser if you‚Äôre on the same machine. Alternatively, if you want to access it from another device on the same network, use the **Network URL** (`http://172.30.254.103:8501`).\n\nYou‚Äôll now have a fully functional personal AI assistant!\n\n\n> **‚ÄúConversing with Porter: How It Remembers and Recalls Past Interactions‚Äù**\n\nPorter isn‚Äôt just an AI that responds to questions at the moment ‚Äî it‚Äôs designed to remember past conversations. Thanks to its memory system, it can recall previous chats, providing contextually aware responses that make interactions feel more personalized and fluid. Whether you‚Äôre revisiting an old topic or issuing a command Porter has handled before, it intelligently recalls past exchanges, allowing for a seamless, coherent dialogue that feels like an ongoing conversation rather than starting fresh every time.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dKn8HbZ7YhHHzml-OtBY4w.png)\n\n\n> ***GitHub Code:***\n\n\n> **Leave your feedback, comments, and üëè üëè Clap for the story !! üëèüëè**\n\n\n## Conclusion\n\nThe creation of ***Porter*** demonstrates the exciting potential of personal AI assistants that prioritize **privacy** and **responsiveness** by operating locally. By integrating LangChain for conversation memory, Ollama‚Äôs high\\-performance Llama models for natural language processing, and Whisper for speech recognition, *Porter* showcases how these advanced tools can be combined to create a robust, intuitive voice assistant. This project not only emphasizes the accessibility of modern AI but also highlights the importance of keeping user data safe and interaction fast ‚Äî two areas where local solutions excel.\n\nWith Porter's flexible architecture, there‚Äôs ample room to expand its capabilities. Developers could integrate other local NLP models or add customized workflows for different use cases, like customer support, educational tutoring, or technical troubleshooting. Moreover, as new language models and voice\\-processing techniques emerge, *Porter* can be updated to provide even more nuanced and contextually aware responses.\n\n\n## References\n\n\\[1] Llama 3\\.2: The Next Generation of Lightweight, Instruction\\-Tuned Language Models: A Hands\\-On Tutorial, 2024\\. Available: [https://readmedium.com/llama\\-3\\-2\\-the\\-next\\-generation\\-of\\-lightweight\\-instruction\\-tuned\\-language\\-models\\-a\\-hands\\-on\\-9bca07c8af1d](https://readmedium.com/llama-3-2-the-next-generation-of-lightweight-instruction-tuned-language-models-a-hands-on-9bca07c8af1d)\n\n\\[2] Hugging Face, *Transformers Documentation: Using LLaMA 3\\.2 Vision Models*, Hugging Face, 2024\\. Available: <https://huggingface.co/blog/llama32>\n\n\\[3] Build a basic LLM chat app. Available: [https://docs.streamlit.io/develop/tutorials/llms/build\\-conversational\\-apps](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps)\n\nHappy coding! üéâ\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è \\| üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) \\|üìù [Medium](https://medium.com/@monsuralirana)\n\nThank you for your time in reading this post!\n\nMake sure to leave your feedback and comments. üëè Clap for the story and follow for stories. See you in the next blog; stay tuned üì¢\n\n\n## Enjoyed this article? Check out more of my work:\n\n* **Building a Custom Documents Agent with Elasticsearch, Ollama, LLaMA 3\\.1, and LangChain:** Explore how to set up a personalized document retrieval agent using LLaMA 3\\.1 and Ollama for seamless information retrieval. [Read the full tutorial here](https://readmedium.com/building-a-custom-documents-agent-with-elasticsearch-ollama-llama-3-1-and-langchain-926b28047e1d).\n* **Building Your Personal AI Assistant with Memory Using Ollama‚Äôs LLaMA3\\.1, LLaMA3\\.2 Models, Streamlit UI, and Locally:** Discover how to develop an AI assistant that remembers past interactions using the latest LLaMA models and a user\\-friendly Streamlit interface. [Read the full tutorial here.](https://readmedium.com/building-porter-your-personal-ai-assistant-with-memory-using-ollamas-llama3-1-efb32b80c129)\n* **OpenAI Swarm: A Lightweight Framework for Multi\\-Agent Orchestration:** Dive into a new framework designed for managing multiple AI agents efficiently, enhancing your AI project management. [Read the full tutorial here.](https://readmedium.com/openai-swarm-a-lightweight-framework-for-multi-agent-orchestration-b4a83a1a1e37)\n* **How to Use Molmo\\-7B for Multimodal AI: Extract Text and Images with an Open\\-Source Vision\\-Language Model:** Learn how to harness the power of the Molmo\\-7B model for extracting both text and images, revolutionizing your approach to multimodal AI. [Read the full tutorial here.](https://readmedium.com/how-to-use-molmo-7b-for-multimodal-ai-extract-text-and-images-with-an-open-source-vision-language-8a31939a2960)\n* **Meta Spirit LM: A Complete Guide to Multimodal AI for Text and Speech Generation:** Explore the capabilities of Meta Spirit LM in generating text and speech, and how it can be applied in various AI applications. [Read the full tutorial here.](https://readmedium.com/meta-spirit-lm-a-complete-guide-to-multimodal-ai-for-text-and-speech-generation-ed0af74bc950)\n* **Supercharge Text\\-to\\-Speech with Piper TTS:** Find out how to achieve 10x faster, real\\-time, offline voice synthesis with human\\-like accuracy in this hands\\-on *Google Colab tutorial*. [Transform your text into lifelike speech here.](https://readmedium.com/unleashing-the-power-of-piper-tts-transforming-text-to-speech-10x-faster-with-ai-human-like-voice-eadf2065d66d)\n\n"},{"lang":"en","group":"blog","slug":"blog/building-a-local-ai-powered-news-aggregator-with-ollama-swarm-and-duckduckgo-95aaf8b3ee41","frontmatter":{"title":"Building a Local AI-Powered News Aggregator with Ollama, Swarm, and DuckDuckGo","meta_title":"Building a Local AI-Powered News Aggregator with Ollama, Swarm, and DuckDuckGo","description":"No subtitle provided","date":"2024-10-24T17:47:43.000Z","image":"https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OHMOTk_WYGOxWHBsKqdpNQ.jpeg","categories":["Programming","Generative AI","Technology/Web"],"author":"Rifx.Online","tags":["Llama","Swarm","DuckDuckGo","News","Aggregator"],"draft":false,"slug":"blog/building-a-local-ai-powered-news-aggregator-with-ollama-swarm-and-duckduckgo-95aaf8b3ee41"},"content":"\n\n# Building a Local AI-Powered News Aggregator with Ollama, Swarm, and DuckDuckGo\n\n\n\nIn today‚Äôs fast-paced world, staying up-to-date with the latest news in specific fields can be challenging. What if we could leverage the power of Generative AI and Agents to create a personalized news aggregator that runs entirely on our local machine? In this article, we‚Äôll explore how to build such a system using **Ollama**‚Äôs Llama 3.2 model, **Swarm** for agent orchestration, and **DuckDuckGo** for web searches.\n\n\n# The Power of Local AI\n\nWith the rise of large language models, we now have the ability to run sophisticated AI systems on our personal computers. This opens up a world of possibilities for creating customized tools tailored to our specific needs. Our news aggregator is a perfect example of this potential.\n\n\n# Components of Our System\n\n1. **Ollama with Llama 3.2**: This serves as the brain of our system, powering our AI agents.\n2. **Swarm**: An agent orchestration framework that allows us to create and manage multiple AI agents.\n3. **DuckDuckGo Search**: Provides up-to-date web search results without tracking user data.\n\n\n# How It Works\n\nOur news aggregator consists of two main AI agents:\n\n1. **News Assistant**: Fetches the latest news articles on a given topic using DuckDuckGo search.\n2. **Editor Assistant**: Reviews and refines the collected news for final presentation.\n\nLet‚Äôs break down the workflow:\n\n\n# 1. Setting Up the Environment\n\n\n```python\nollama pull llama3.2\n\nexport OPENAI_MODEL_NAME=llama3.2\nexport OPENAI_BASE_URL=http://localhost:11434/v1\nexport OPENAI_API_KEY=any\n\npip install git+https://github.com/openai/swarm.git duckduckgo-search\n```\nWe start by importing the necessary libraries and initializing our Swarm client:\n\n\n```python\nfrom duckduckgo_search import DDGS\nfrom swarm import Swarm, Agent\nfrom datetime import datetime\n\ncurrent_date = datetime.now().strftime(\"%Y-%m\")\nclient = Swarm()\n```\n\n# 2. Creating the News Search Function\n\nWe define a function to search for news using DuckDuckGo:\n\n\n```python\npythondef get_news_articles(topic):\n  ddg_api = DDGS()\n  results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n  if results:\n      news_results = \"\\n\\n\".join([f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results])\n      return news_results\n  else:\n      return f\"Could not find news results for {topic}.\"\n```\n\n# 3. Defining Our AI Agents\n\nWe create two agents using Ollama‚Äôs Llama 3.2 model:\n\n\n```python\nnews_agent = Agent(\n  model=\"llama3.2\",\n  name=\"News Assistant\",\n  instructions=\"You provide the latest news articles for a given topic using DuckDuckGo search.\",\n  functions=[get_news_articles],\n)\n\neditor_agent = Agent(\n  model=\"llama3.2\",\n  name=\"Editor Assistant\",\n  instructions=\"You review and finalise the news article for publishing.\",\n)\n```\n\n# 4. Orchestrating the Workflow\n\nWe define a function to run our news aggregation workflow:\n\n\n```python\ndef run_news_workflow(topic):\n  # Fetch news\n  news_response = client.run(\n      agent=news_agent,\n      messages=[{\"role\": \"user\", \"content\": f\"Get me the news about {topic} on {current_date}\"}],\n  )\n  raw_news = news_response.messages[-1][\"content\"]\n  \n  # Pass news to editor for final review\n  edited_news_response = client.run(\n      agent=editor_agent,\n      messages=[{\"role\": \"system\", \"content\": raw_news}],\n  )\n  print(f\"{edited_news_response.messages[-1]['content']}\")\n```\n\n# 5. Running the System\n\nFinally, we can run our news aggregator for any topic of interest:\n\n\n```python\nrun_news_workflow(\"AI in Drug Discovery\")\n```\n\n# Complete Code : app.py\n\n\n```python\nfrom duckduckgo_search import DDGS\nfrom swarm import Swarm, Agent\nfrom datetime import datetime\n\ncurrent_date = datetime.now().strftime(\"%Y-%m\")\n\n# Initialize Swarm client\nclient = Swarm()\n\n# 1. Create Internet Search Tool\n\ndef get_news_articles(topic):\n    print(f\"Running DuckDuckGo news search for {topic}...\")\n    \n    # DuckDuckGo search\n    ddg_api = DDGS()\n    results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n    if results:\n        news_results = \"\\n\\n\".join([f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results])\n        return news_results\n    else:\n        return f\"Could not find news results for {topic}.\"\n    \n# 2. Create AI Agents\n\ndef transfer_to_editor_assistant(raw_news):\n    print(\"Passing articles to Editor Assistant...\")\n    return editor_agent.run({\"role\": \"system\", \"content\": raw_news})\n\n# News Agent to fetch news\nnews_agent = Agent(\n    model=\"llama3.2\",\n    name=\"News Assistant\",\n    instructions=\"You provide the latest news articles for a given topic using DuckDuckGo search.\",\n    functions=[get_news_articles],\n)\n\n# Editor Agent to edit news\neditor_agent = Agent(\n    model=\"llama3.2\",\n    name=\"Editor Assistant\",\n    instructions=\"You review and finalise the news article for publishing.\",\n)\n\n# 3. Create workflow\n\ndef run_news_workflow(topic):\n    print(\"Running news Agent workflow...\")\n    \n    # Step 1: Fetch news\n    news_response = client.run(\n        agent=news_agent,\n        messages=[{\"role\": \"user\", \"content\": f\"Get me the news about {topic} on {current_date}\"}],\n    )\n    raw_news = news_response.messages[-1][\"content\"]\n    print(f\"Fetched news: {raw_news}\")\n    \n    # Step 2: Pass news to editor for final review\n    edited_news_response = client.run(\n        agent=editor_agent,\n        messages=[{\"role\": \"system\", \"content\": raw_news}],\n    )\n    print(f\"{edited_news_response.messages[-1]['content']}\")\n\n\n# Example of running the news workflow for a given topic\nrun_news_workflow(\"AI in Drug Discovery\")\n```\n\n# Sample Output\n\n\n```python\nRunning news Agent workflow...\nRunning DuckDuckGo news search for AI in Drug Discovery...\nFetched news: Here's a formatted answer based on the news articles:\n\n**AI in Drug Discovery: A Revolutionary Shift**\n\nThe role of Artificial Intelligence (AI) in drug discovery has marked a revolutionary shift in the pharmaceutical landscape. AI leverages sophisticated algorithms for autonomous decision-making from data analysis, augmenting human capabilities rather than replacing them.\n\n**Challenges and Limitations**\n\nDespite the promising advancements, challenges and limitations have been identified in the field. The paper \"The Role of AI in Drug Discovery\" addresses these issues, highlighting the need for high-quality data, addressing ethical concerns, and recognizing the limitations of AI-based approaches.\n\n**Applications of AI in Drug Discovery**\n\nAI has the potential to play a critical role in drug discovery, design, and studying drug-drug interactions.Applications of AI in drug discovery include:\n\n* Polypharmacology: AI can predict the likelihood of a compound's effectiveness against multiple diseases.\n* Chemical synthesis: AI can optimize chemical synthesis processes for faster and more efficient production.\n* Drug repurposing: AI can identify new uses for existing drugs.\n* Predicting drug properties: AI can predict the efficacy, toxicity, and physicochemical characteristics of compounds.\n\n**The Future of AI in Drug Discovery**\n\nAs AI continues to evolve, it is expected to significantly impact the pharmaceutical industry. The successful application of AI will depend on the availability of high-quality data, addressing ethical concerns, and recognizing the limitations of AI-based approaches.\n```\n\n# The Benefits of Local AI News Aggregation\n\n* **Privacy**: All processing happens on your local machine, ensuring your data stays with you.\n* **Customization**: You can easily modify the agents‚Äô instructions or add new agents to suit your specific needs.\n* **Up-to-date Information**: By using DuckDuckGo search, you always get the latest news on your chosen topic.\n* **AI-powered Curation**: The Editor Assistant helps refine and organize the collected news, providing a more polished final output.\n\n\n# Conclusion\n\nThis local AI-powered news aggregator demonstrates the potential of combining large language models with web search capabilities. By leveraging Ollama‚Äôs Llama 3.2 model, Swarm for agent orchestration, and DuckDuckGo for search, we‚Äôve created a powerful tool that can keep us informed on any topic of interest, all while maintaining our privacy and running entirely on our local machine.\n\nAs AI continues to evolve, the possibilities for creating personalized, AI-driven tools will only expand. This news aggregator is just the beginning ‚Äî imagine what other innovative applications you could build using these technologies!\n\n\n# Reference :\n\nSwarm Github : <https://github.com/openai/swarm>\n\nIf you found this article informative and valuable, I‚Äôd greatly appreciate your support:\n\n* Give it a few claps üëè on Medium to help others discover this content (did you know you can clap up to 50 times?). Your claps will help spread the knowledge to more readers.\n- Share it with your network of AI enthusiasts and professionals.\n- Connect with me on LinkedIn: <https://www.linkedin.com/in/manjunath-janardhan-54a5537/>\n\n\n\n\n\n"},{"lang":"en","group":"blog","slug":"blog/building-a-reliable-text-classification-pipeline-with-llms-a-step-by-step-guide-87dc73213605","frontmatter":{"title":"Building a Reliable Text Classification Pipeline with LLMs: A Step-by-Step Guide","meta_title":"Building a Reliable Text Classification Pipeline with LLMs: A Step-by-Step Guide","description":"This tutorial outlines the development of a reliable text classification pipeline using large language models (LLMs). It discusses three key techniques: constrained generation, few-shot prompting, and dynamic example selection. Constrained generation ensures LLM outputs match predefined classes, reducing post-processing needs. Few-shot prompting enhances accuracy by providing example outputs, while dynamic selection retrieves relevant examples based on query similarity, significantly improving classification accuracy to 88.6%. The article emphasizes the adaptability of LLMs for effective text classification without extensive training or data collection.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Cmk7IkUnY-SIxhVF","categories":["Natural Language Processing","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["constrained","generation","prompting","selection","classification"],"draft":false,"slug":"blog/building-a-reliable-text-classification-pipeline-with-llms-a-step-by-step-guide-87dc73213605"},"content":"\n\n\n\n\n### Overcoming common challenges in LLM\\-based text classification\n\n\n\nIn this step\\-by\\-step tutorial, we‚Äôll walk through how to use large language models (LLMs) to build a text classification pipeline that is accurate and dependable. LLMs are powerful, generalist models that have demonstrated remarkable capabilities across various natural language processing tasks, and they‚Äôre increasingly replacing specialist models in many AI applications. However, using LLMs for classification can be tricky if not approached carefully.\n\nA common issue when applying LLMs for classification is that the model might not respond with the expected output or format, leading to additional post\\-processing that can be complex and time\\-intensive. In this post, we‚Äôll cover practical tips and techniques to address these challenges. Each of these strategies is simple to implement but can significantly improve both the accuracy and usability of LLMs as text classifiers. Let‚Äôs dive in to make your LLM text classification system both efficient and reliable.\n\n\n## Main Ideas\n\nIn this tutorial, we‚Äôll explore three key techniques that can make LLMs far more effective and efficient as text classifiers. **We won‚Äôt go into the fine\\-tuning option for this tutorial**, but you can see some of my other posts in you are interested by this technique:\n\nThe first technique is *constrained generation*. This involves setting specific constraints that guide the LLM to generate tokens following a designated schema, which helps ensure the output matches the expected format. By applying these constraints, we can reduce the need for complex post\\-processing to obtain class predictions in the correct format.\n\nThe second technique we‚Äôll examine is *few\\-shot prompting*. Few\\-shot prompting works by providing the LLM with a few example outputs before it attempts to classify new data. Because LLMs are known to be strong in\\-context learners, they can identify patterns from these examples and produce outputs that closely resemble them. This approach allows us to improve the accuracy of predictions by showing the LLM the types of responses it should generate.\n\nFinally, we‚Äôll introduce *dynamic example selection* for few\\-shot prompting. Similar to retrieval\\-augmented generation but designed for classification tasks, this approach dynamically selects examples based on similarity to the new input, using a nearest\\-neighbor technique. This way, the LLM is presented with the most relevant input\\-output pairs before it generates the final classification, leading to more precise predictions.\n\nEach of these techniques will be explained in detail, with code examples based on the LangChain framework to simplify implementation. You‚Äôll be able to incorporate these methods directly into your NLP toolkit or customize them to suit your specific needs for a reliable and accurate text classification pipeline.\n\n\n## Why use LLMs for classification\n\nBefore we get started, let‚Äôs take a moment to consider why you might choose to use LLMs for text classification over a custom, specialized model.\n\nOne major advantage of using LLMs is their proficiency in zero\\-shot and few\\-shot predictions. Even with minimal data, LLMs often produce reasonable results, making them an excellent choice when labeled data is scarce. Additionally, as generalist models, LLMs have vast knowledge about the world, effectively memorizing information from a wide range of sources. This means they can sometimes handle unexpected inputs and still produce accurate predictions.\n\nAnother significant benefit is the convenience of accessing LLMs as a service. Many LLMs are now offered through cloud platforms, which means you don‚Äôt need to manage any infrastructure yourself. You simply pay for what you use, giving you the flexibility to scale as needed without investing in hardware or managing GPU resources. This can be a huge asset for AI applications, as it reduces upfront costs and eliminates the need to maintain complex machine learning infrastructure.\n\nHowever, there are also some potential drawbacks to consider. One is latency: while custom, smaller classification models often respond in just a few tens of milliseconds, LLMs typically have higher latency, ranging from a few hundred milliseconds to several seconds depending on their size. This delay might be a disadvantage for applications that require real\\-time processing.\n\nData privacy is another concern. If you need to keep all data within your own infrastructure for compliance or security reasons, using an LLM service might not be the best option. You would either need to host an LLM internally ‚Äî which can be costly ‚Äî or find an alternative that keeps data in\\-house.\n\nAnother limitation is the reliance on the LLM service provider. Using an LLM as a service means you‚Äôre subject to its rate limits, latencies, and potential downtimes, over which you have little control. Any issue on the provider‚Äôs end could impact your ability to classify text reliably and promptly, which may be a drawback for applications requiring high reliability.\n\nWith these pros and cons in mind, you can evaluate whether using LLMs as classifiers suits your specific requirements. In any case, LLMs are a powerful tool to have in your data science toolkit, allowing you to quickly set up an AI service and get started on building impactful applications.\n\n\n## Idea 1: Constrained Output for classification\n\nNow that we‚Äôve covered the context, let‚Äôs dive into the technical part of the tutorial. As mentioned earlier, our first technique is to implement **constrained generation** to ensure that the LLM only outputs valid class labels. By constraining the output to a predefined set of class names, we eliminate the need to parse or clean up free\\-form responses, which reduces the likelihood of errors and improves the reliability of the classification pipeline.\n\nTo achieve this, we‚Äôll use the LangChain OpenAI client wrapper, but works with any OpenAI\\-compatible model *(We use [NebiusAI](https://studio.nebius.ai/) for these experiments)*. This wrapper will allow us to send structured queries to the LLM, following a specific schema that we‚Äôll define.\n\n\n### Step 1: Define the Output Schema\n\nWe start by defining the schema for the output, which will consist of a single category field. This field will use \\`Literal\\` types, listing each possible class name as a string. By doing this, we ensure that the LLM‚Äôs output is strictly one of these valid classes, which we can directly use as the model‚Äôs prediction.\n\nThe schema definition is implemented with \\`pydantic\\` as follows:\n\n\n```python\nfrom typing import Literal\nfrom pydantic import BaseModel\n\ndef generate_classification_model(list_classes: list[str]):\n    assert list_classes  # Ensure the list of classes is not empty\n\n    class ClassificationOutput(BaseModel):\n        category: Literal[tuple(list_classes)]\n\n    return ClassificationOutput\n\n## Example usage\nif __name__ == \"__main__\":\n    Categories = generate_classification_model([\"Yes\", \"No\"])\n    categories = Categories(category=\"Yes\")\n    print(categories)\n```\nIn this example, we create a Pydantic model called \\`ClassificationOutput\\` with a \\`category\\` field restricted to a list of literal values, such as ‚ÄúYes‚Äù and ‚ÄúNo.‚Äù This setup allows us to validate the LLM‚Äôs output, ensuring it is one of the predefined class names.\n\n\n### Step 2: Construct and Send Messages\n\nNext, we prepare a series of messages to send to the LLM. The first message is a system prompt that sets the context by describing the task (classification) and listing the possible output classes. This guides the LLM to produce outputs matching the desired schema. The second message contains the actual text we want the LLM to classify.\n\nUsing the LangChain client wrapper, we can configure our LLM with the following settings:\n\n\n```python\nimport os\nfrom typing import Literal\n\nfrom dotenv import load_dotenv\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel\n\nload_dotenv()\n\n\nclass ClassificationOutput(BaseModel):\n    category: Literal[\"news\", \"clickbait\"]\n\n\nllm_client = ChatOpenAI(\n    openai_api_base=os.environ.get(\"LLM_BASE_URL\"),\n    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n    openai_api_key=os.environ.get(\"LLM_API_KEY\"),\n    temperature=0,\n    max_retries=2,\n)\n\nconstrained_llm = llm_client.with_structured_output(ClassificationOutput)\n\nmessages = [\n    SystemMessage(\n        content=\"Classify the following text into one of the predefined categories: news or clickbait\"\n    ),\n    HumanMessage(content=\"You won't believe what happened next!\"),\n]\nprediction = constrained_llm.invoke(messages)\n\nprint(prediction)\n\n## Gives category='clickbait'\n```\nUsing this approach, the LLM‚Äôs output will match our predefined classes, making it directly usable as a classification result without further processing.\n\n\n### Step 3: Evaluation\n\nTo assess the model‚Äôs performance, we ran it on the [20 Newsgroups dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) (CC BY 4\\.0\\), where it achieved an accuracy of **76\\.3%**. This setup demonstrates the effectiveness of constrained generation in improving classification accuracy and reducing the need for additional processing steps.\n\n\n## Idea 2: Few\\-shot prompting\n\nThe second technique is *few\\-shot prompting*, where we include a few example input\\-output pairs in the prompt to guide the LLM. This approach leverages the in\\-context learning abilities of LLMs, which allows them to pick up on patterns from the examples provided, often resulting in improved classification accuracy. Here, we‚Äôll implement few\\-shot prompting by adding some sample classifications directly in the prompt to enhance the model‚Äôs output quality.\n\nLet‚Äôs look into the code:\n\n\n```python\nimport os\nfrom typing import Literal\n\nfrom dotenv import load_dotenv\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel\n\nload_dotenv()\n\n\nclass ClassificationOutput(BaseModel):\n    category: Literal[\"news\", \"clickbait\"]\n\n\nllm_client = ChatOpenAI(\n    openai_api_base=os.environ.get(\"LLM_BASE_URL\"),\n    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n    openai_api_key=os.environ.get(\"LLM_API_KEY\"),\n    temperature=0,\n    max_retries=10,\n)\n\nconstrained_llm = llm_client.with_structured_output(ClassificationOutput)\n\nmessages = [\n    SystemMessage(\n        content=\"Classify the following text into one of the predefined categories: news or clickbait\"\n    ),\n    HumanMessage(content=\"The Shocking Truth Behind a Popular Wellness Trend\"),\n    AIMessage(content=\"clickbait\"),\n    HumanMessage(content=\"UK farmers call for weedkiller ban over Parkinson‚Äôs fears\"),\n    AIMessage(content=\"news\"),\n    HumanMessage(content=\"You won't believe what happened next!\"),\n]\nprediction = constrained_llm.invoke(messages)\n\nprint(prediction)\n\n## Gives category='clickbait'\n```\nIn this setup, we construct a conversation history with both *HumanMessage* and *AIMessage* types to simulate examples of how we expect the LLM to classify text. By demonstrating the classification style and format we want ‚Äî such as categorizing ‚ÄúThe Shocking Truth Behind a Popular Wellness Trend‚Äù as ‚Äúclickbait‚Äù and ‚ÄúUK farmers call for weedkiller ban over Parkinson‚Äôs fears‚Äù as ‚Äúnews‚Äù ‚Äî we set clear expectations for the model. When the final classification request, ‚ÄúYou won‚Äôt believe what happened next!‚Äù is sent, the LLM can leverage these examples to determine the appropriate response.\n\nAfter testing this few\\-shot approach, we observed an accuracy of **76\\.6%**, a slight improvement over our constrained generation method. However, since the examples were selected randomly, this might not fully demonstrate the potential of few\\-shot prompting. Carefully choosing or curating the examples to match the input data more closely could yield even better results. In the next part of this tutorial, we‚Äôll look at a more advanced technique: dynamically selecting examples based on similarity, which could further improve accuracy.\n\n\n## Idea 3: Dynamic Example selection\n\nOur third technique for improving classification accuracy with LLMs is dynamically selecting relevant examples based on the text in the query. Instead of using a static few\\-shot prompt, we perform a similarity search for each query using ChromaDB to identify its nearest neighbors from a labeled training set. By selecting examples that are contextually similar to the input text, we can provide the LLM with highly relevant information, increasing the likelihood of an accurate classification.\n\nTo implement this, we start by building an embedding\\-based retrieval system. Here‚Äôs how it works:\n\n\n### Step 1: Initialize the Classifier with Dynamic Prompting\n\nOur `LLMTextClassifier` class takes the list of possible categories and builds a prompt template for classification. We configure the classifier to retrieve a set number of examples (controlled by `max_examples`) that are most similar to the query text.\n\nUsing this setup, the classifier dynamically selects examples, injecting them into the prompt in the same format as the few\\-shot examples in the previous method:\n\n\n```python\nclass LLMTextClassifier:\n    def __init__(\n        self,\n        categories: list[str],\n        system_prompt_template: PromptTemplate = PromptTemplate(\n            input_variables=[\"categories\", \"schema\"],\n            template=\"Classify the following text into one of the following classes: {categories}.\\n \"\n            \"Use the following schema: {schema}\",\n        ),\n        llm_client: BaseChatModel = llm_medium,\n        max_examples: int = 5,\n    ):\n        # Initialize model, prompt, and retrieval variables\n        self.categories = categories\n        self.categories_model = generate_classification_model(categories)\n        self.system_prompt_template = system_prompt_template\n        self.system_prompt = system_prompt_template.format(\n            categories=categories, schema=self.categories_model.model_json_schema()\n        )\n        self.llm_classifier = llm_client.with_structured_output(self.categories_model)\n        self.max_examples = max_examples\n        self.examples = None\n        self.vector_store = None\n        self.retriever = None\n```\n\n### Step 2: ‚ÄúTrain‚Äù the Classifier with Example Data\n\nTo ‚Äútrain‚Äù our classifier (train used loosely here, as no weights are updated), we populate the vector store with training data examples labeled with their respective categories. This setup prepares the classifier to retrieve the most relevant examples dynamically when a new query is input:\n\n\n```python\n    def fit(self, texts, labels):\n        self.examples = [\n            Document(page_content=text, metadata={\"label\": label})\n            for text, label in zip(texts, labels)\n        ]\n\n        if len(self.examples) > self.max_examples:\n            # Add examples to vector store\n            self.vector_store = Chroma.from_documents(\n                documents=self.examples,\n                collection_name=\"llm-classifier\",\n                embedding=ChromaEmbeddingsAdapter(\n                    embedding_functions.DefaultEmbeddingFunction()\n                ),\n            )\n            self.retriever = self.vector_store.as_retriever(\n                search_kwargs={\"k\": self.max_examples}\n            )\n```\n\n### Step 3: Dynamically Retrieve Relevant Examples and Classify\n\nWhen a new text is input for classification, the classifier retrieves relevant examples based on similarity to the query. This list of relevant examples is added to the prompt, followed by the query itself, and sent to the LLM for classification:\n\n\n```python\n def predict(self, text: str) -> str:\n        messages = [SystemMessage(content=self.system_prompt)]\n        \n        for example in self.fetch_examples(text=text):\n            messages.append(HumanMessage(content=example.page_content))\n            messages.append(AIMessage(content=example.metadata[\"label\"]))\n\n        messages.append(HumanMessage(content=text))\n        prediction = self.llm_classifier.invoke(messages)\n\n        return prediction.category\n```\n\n### Step 4: Example run\n\n\n```python\nif __name__ == \"__main__\":\n    categories = [\"news\", \"clickbait\"]\n    classifier = LLMTextClassifier(categories=categories, max_examples=1)\n\n    texts = [\"Donald Trump won Michigan\", \"You won't believe what happened next!\"]\n    labels = [\"news\", \"clickbait\"]\n    \n    classifier.fit(texts, labels)\n\n    text = \"Donald Trump won Florida\"\n    result = classifier.predict(text)\n    print(result)  # Should output \"news\" if similar to \"news\" examples\n```\nUsing the dynamic few\\-shot technique, we saw a significant improvement in classification accuracy, reaching **88\\.6%**. This marks a considerable increase over previous methods, demonstrating the power of dynamically selecting relevant examples based on similarity to the query text.\n\n\n## Conclusion\n\nIn this post, we explored a simple yet powerful approach to building a reliable and accurate text classification pipeline using large language models (LLMs). We walked through three key techniques: *constrained generation*, *few\\-shot prompting*, and *dynamic few\\-shot selection*. Each of these methods contributes unique strengths to improve classification accuracy and usability, transforming LLMs into effective tools for text classification.\n\nThe first technique, constrained generation, involved limiting the LLM‚Äôs responses to predefined classes, reducing the need for complex post\\-processing and making it easier to parse the model‚Äôs outputs. This approach alone allowed us to avoid common pitfalls of free\\-form text generation, improving the LLM‚Äôs consistency in classification.\n\nNext, we implemented few\\-shot prompting, where we provided the LLM with a few labeled examples as part of the prompt. By leveraging the model‚Äôs in\\-context learning ability, few\\-shot prompting improved classification accuracy by setting clear expectations for the output format and content. However, we saw that the selection of examples is crucial ‚Äî randomly chosen examples offered only a modest improvement. This led us to our final technique: dynamic few\\-shot selection.\n\nDynamic few\\-shot selection was the most advanced and effective approach, achieving a high classification accuracy of 88\\.6%. By using ChromaDB to retrieve the most similar examples for each query, this technique allowed the LLM to access only the most relevant context, which significantly enhanced its predictive accuracy. This method is a practical way to make generalized models like LLMs perform more like specialized classifiers, without the need to train a custom model from scratch.\n\n\n### Final Thoughts\n\nAs LLMs become more accessible and powerful, their applications in natural language processing tasks continue to grow. While these models are typically generalized, our tutorial demonstrates that with targeted techniques, they can be adapted into high\\-performing classifiers. Each of the methods we covered here ‚Äî from straightforward constrained generation to advanced dynamic few\\-shot selection ‚Äî offers flexibility and adaptability. They provide scalable solutions for building classification systems, making it feasible to integrate LLMs into production without extensive data collection or training.\n\nWhether you‚Äôre an NLP practitioner, a data scientist, or an AI enthusiast, these techniques add versatile tools to your machine learning toolkit. With LLMs and these techniques, you can deploy robust and effective text classification systems tailored to your specific needs.\n\nThank you for reading!\n\nCode: <https://github.com/CVxTz/llmclassifier>\n\n\n"},{"lang":"en","group":"blog","slug":"blog/building-autonomous-multi-agent-systems-with-crewai-1a3b3a348271","frontmatter":{"title":"Building Autonomous Multi-Agent Systems with CrewAI","meta_title":"Building Autonomous Multi-Agent Systems with CrewAI","description":"The article discusses the development of autonomous multi-agent systems using CrewAI and LangChain frameworks. It explains the structure of multi-agent systems, emphasizing the roles of agents, tools, and tasks in achieving complex operations. The article details a project that integrates these frameworks to create an essay-writing application, demonstrating how agents can collaborate to research, write, and edit essays. It also outlines the project‚Äôs architecture, including agent design, task management, and deployment using Streamlit, providing insights into building efficient AI systems.","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*72Cy_QqOie7G2NAiWr13Kw.jpeg","categories":["Autonomous Systems","Programming","Data Science"],"author":"Rifx.Online","tags":["CrewAI","LangChain","multi-agent","Streamlit","essay-writing"],"draft":false,"slug":"blog/building-autonomous-multi-agent-systems-with-crewai-1a3b3a348271"},"content":"\n### What‚Äòs Multi\\-Agent Autonomous System and How to build one with CrewAI and LangChain?\n\n\n\n## Motivation\n\nIn fact, we are not unfamiliar with these concepts; we know them from movies. A person commands their AI, and the AI carries out these commands by using various tools. This is the path we are on today with the rise of AI systems. The era is gradually changing. In the past, people couldn‚Äôt undertake a task alone and would need a team. Without a team, they would either run out of energy after a while or hit the limits of their abilities. In the end, successful projects come from teams made up of individuals with different skills.\n\n> Teamwork makes the dream work.\n\nHowever, these days a new technology has started to make a name for itself. We can call it the next phase of AI before AGI: ‚ÄòAgents.‚Äô So, what are these agents? Before diving into the code, let‚Äôs talk a bit about the structure of multi\\-agent systems\n\n## How does it work?\n\nTo put the equation simply: `Multi Agent Systems = AGENTs + TOOLs + TASKs` It‚Äôs a system where multiple agents are equipped with various tasks and tools.\n\n### Agent\n\nWe are familiar with role\\-playing games, where your character has a role, like a warrior, for example. Throughout the game, you put yourself in their place, aiming to complete the game by finishing the quests that shape their backstory from one adventure to the next. Similarly, researchers have discovered that large language models (LLMs) can be motivated to perform tasks optimally when given roles, backstories, and objectives. This allows us to motivate LLMs to carry out various tasks with just a few simple prompts.\n\nAgents essentially break down the assigned tasks into simple steps and then execute those steps by ‚Äòthinking‚Äô ‚Äî yes, thinking ‚Äî through them in sequence. This enables us to create an agent that not only performs steps thoughtfully but also consults other agents with different areas of expertise, rather than relying on a single LLM to input prompts and receive outputs.\n\n### Tools\n\nOne of humanity‚Äôs greatest abilities is undoubtedly our skill in using tools. This ability has evolved and developed through both evolutionary and cultural processes, allowing us to create the advanced technology we use today. Similarly, large language models have increased their capabilities as they are trained on larger datasets. Now, when the function of a tool and how it is used are clearly explained, these models can autonomously use the tool under appropriate conditions, executing it fully automatically and planning their next steps based on the output, without waiting for further commands.\n\nTherefore, tool use can be considered one of the most important parts of their evolution as well. Especially with the internet browsing tool, agents can follow the specified function‚Äôs steps to access the necessary resources, whether through web scraping or by using the search engine of the designated site.\n\nYour tools‚Äô functionality and purpose are entirely up to your imagination. However, if you‚Äôd like to integrate pre\\-built tools into your agents, both CrewAI and LangChain libraries offer a wide range of built\\-in tools ready for use. In this project, we will focus on creating our own custom tool instead.\n\n### Task\n\nJust as we create agents, we also create tasks, and each task requires various tools. To give an example from human behavior, what do we do when we need to research something?\n\n1\\- We search the internet.\n\n2\\- We conduct in\\-depth source research.\n\n3\\- We take notes on our findings.\n\nIn the same way, we can design tasks to follow these steps, and we will touch on how they are designed through the code.\n\n## What is CrewAI?\n\nCrewAI is an open\\-source Python framework for orchestrating role\\-playing, autonomous AI agents with methods like Crew, Task, Agent, Process, and it supports various LLMs, including local models.\n\nIf we look at the main advantages provided by the framework:\n\n* Role\\-based agent design.\n* Autonomous inter\\-agent delegation.\n* Flexible task management.\n* Process\\-driven execution.\n* Output saving as files like .markdown files.\n* Compatibility with both open\\-source and proprietary models like OpenAI.\n\n## Building Multi\\-Agent\n\nA descriptive explanation alone may not always be enough to fully understand a concept, so let‚Äôs create a small Essay Writer project to better grasp the multi\\-agent approach. In this project, we will combine the LangChain and CrewAI frameworks. To run the project, you will need an OpenAI API key, which you can obtain by visiting [https://proxy.rifx.online/https://platform.openai.com/signup](https://proxy.rifx.online/https://platform.openai.com/signup).\n\nThe structure of our project consists of several different python scripts:\n\n* `crew.py`, where we define our agents and their tasks.\n* `graph.py`, which builds the LangGraph structure.\n* `extra_tools.py`, containing the tools our agents will use.\n* `pdf_writer.py`, responsible for converting the essay into a PDF.\n* `app.py`, which provides the Streamlit interface for our application.\n\n```python\n## Project Structure\nAutonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer\n‚îú‚îÄ‚îÄ app.py              # Main streamlit application\n‚îú‚îÄ‚îÄ crew.py             # CrewAI agents and task handling\n‚îú‚îÄ‚îÄ extra_tools.py      # Agentic functions of tools\n‚îú‚îÄ‚îÄ graph.py            # LangGraph and Project Workflow\n‚îú‚îÄ‚îÄ pdf_writer.py       # Handles PDF output generation\n‚îú‚îÄ‚îÄ requirements.txt    # List of required libraries\n‚îú‚îÄ‚îÄ media\n‚îÇ   ‚îî‚îÄ‚îÄ cover.jpg       # Project cover image\n‚îî‚îÄ‚îÄ README.md        \n```\n\nThe libraries required for this project are listed in the `requirements.txt` file. Additionally, please ensure you have installed Python version 3\\.12 or higher. Don‚Äôt forget to install the dependencies before running the project. The libraries we use include:\n\n```python\nlangchain-core\nlangchain-openai\nlanggraph\nstreamlit\nwikipedia\nreportlab\ncrewai[tools]\npysqlite3-binary\nbs4\n```\n\n### Workflow\n\nIn our process, we will assign various roles to the agents. For example, while one agent waits for another to complete their task of researching on the internet, another agent will independently carry out research on Wikipedia. Once both agents have completed their tasks, the agent waiting for their information will then proceed with writing the essay, which is their assigned task.\n\nIf we were to visualize this:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Emb37H_8OAKp1s1ChLLVQg.png)\n\n* The User Query is initially sent to the Router.\n* The Router reads the query and determines whether the user wants to write a new essay, edit a previous one, or simply convey a topic for discussion. If the user wishes to write a new essay, the request is forwarded to Crew.\n* The incoming request to Crew is first sent to the Researcher Agent.\n* The researcher agent uses the tools assigned to him to search for internet resources related to the subject on which the user wants to write an essay.\n* Once the resource collection process is completed, the collected information is forwarded to the Writer Agent.\n* When the writer agent drafts the essay, the Editor Agent makes final adjustments, corrects grammatical errors, and returns the draft as a JSON file to LangGraph.\n* The JSON file is sent to the function that will create our essay as a PDF file in the final node.\n\n### Building LangGraph\n\nFirst, we need to establish the skeleton of our schema. Once we create a workflow that allows us to reach our agents as needed, all that‚Äôs left is to decide at which stages of the workflow we will send a request to our agents. To do this, we will first create a simple workflow using LangChain.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iHQzJymxAstrW40THoRxwA.png)\n\n```python\n#LangGraph workflow\n\nbuilder = StateGraph(GraphState)\n\nbuilder.add_node(\"answer\", self.answer)\nbuilder.add_node(\"write_essay\", self.write_essay)\nbuilder.add_node(\"edit_essay\", self.edit_essay)\n\n\nbuilder.set_conditional_entry_point(self.router_query,\n                              {\"write_essay\": \"write_essay\",\n                                        \"answer\": \"answer\",\n                                        \"edit_essay\": \"edit_essay\"})\nbuilder.add_edge(\"write_essay\", END)\nbuilder.add_edge(\"edit_essay\", END)\nbuilder.add_edge(\"answer\", END)\n\nself.graph = builder.compile()\n```\n\n**Router Node**: As we mentioned in the workflow description, our router assigns tasks to various nodes based on incoming requests. To achieve this, we need to create an effective prompt that encompasses the topic provided by the user and incorporates past conversations. After all, we are developing a multi\\-agent essay writer chatbot that can remember and recall previous discussions.\n\nLet‚Äôs draft a simple prompt and the corresponding node that will utilize this prompt. In the prompt, we should define a `BaseModel` using the Pydantic library to enforce that our router selects one of three potential response strategies. These strategies will guide the chatbot in formulating its responses effectively.\n\nIn the node, we will implement this prompt using Langchain‚Äôs `PromptTemplate` method. Then, we will invoke the LLM (Large Language Model) with both the user query and the conversation history to ensure that the response is contextually relevant and tailored to the user‚Äôs needs.\n\n1. **Define the Pydantic Model**: Create a model that specifies the required response strategy.\n2. **Construct the Prompt**: Write a prompt that clearly outlines the three strategies.\n3. **Set Up the Node**: Use Langchain `PromptTemplate` to format the prompt dynamically.\n4. **Invoke the LLM**: Call the LLM with the formatted prompt, user query, and conversation history.\n\nBy following these steps, we can ensure that the chatbot responds accurately and maintains the context from previous interactions.\n\n```python\n#Router Prompt and Router Node\nclass RouteQuery(BaseModel):\n    \"\"\"Route a user query to direct answer or research.\"\"\"\n\n    way: Literal[\"edit_essay\",\"write_essay\", \"answer\"] = Field(\n        ...,\n        description=\"Given a user question choose to route it to write_essay, \n        edit_essay or answer\",\n    )\n\nself.router_prompt = \n    \"\"\"\n    You are a router and your duty is to route the user to the correct expert.\n    Always check conversation history and consider your move based on it.\n    If topic is something about memory, or daily talk route \n      the user to the answer expert.\n    If topic starts something like can u write, or user request \n      you write an article or essay, route the user to the write_essay expert.\n    If topic is user wants to edit anything in the essay, \n      route the user to the edit_essay expert.\n  \n    \\nConservation History: {memory}\n    \\nTopic: {topic}\n    \"\"\"\n\ndef router_query(self, state: GraphState):\n    print(\"**ROUTER**\")\n    prompt = PromptTemplate.from_template(self.router_prompt)\n    memory = self.memory.load_memory_variables({})\n\n    router_query = self.model.with_structured_output(RouteQuery)\n    chain = prompt | router_query\n    result:  RouteQuery = chain.invoke({\"topic\": state[\"topic\"],\n                                       \"memory\": memory})\n\n    print(\"Router Result: \", result.way)\n    return result.way\n```\n\n**Simple Answer Node**: After placing our router as a node in the start section, the next step is to create our other three nodes: `write_essay`, `edit_essay`, and `answer`. To take a straightforward approach, we need to program our `answer` node to generate responses directly using its memory when a user sends a casual message or engages in a conversation about an essay.\n\nTo achieve this, we must first write a suitable prompt for this task. Then, using this prompt, we will design a simple node. Let‚Äôs proceed with this design.\n\n```python\n#Simple Answer Prompt and Node\n\nself.simple_answer_prompt = \n      \"\"\"\n      You are an expert and you are providing a simple \n      answer to the user's question.\n    \n      \\nConversation History: {memory}\n      \\nTopic: {topic}\n      \"\"\"\ndef answer(self, state: GraphState):\n    print(\"**ANSWER**\")\n    prompt = PromptTemplate.from_template(self.simple_answer_prompt)\n    memory = self.memory.load_memory_variables({})\n    chain = prompt | self.model | StrOutputParser()\n    result = chain.invoke({\"topic\": state[\"topic\"], \"memory\": memory})\n\n    self.memory.save_context(inputs={\"input\": state[\"topic\"]}, outputs={\"output\": result})\n    return {\"response\": result}\n```\n\n**Writing Essay Node**: Next, we need to design the `writing_essay` node. The purpose of this node is to forward the query received from the user to our agents using CrewAI‚Äôs `kickoff` method and then to convert the JSON file returned by the agents into a PDF. Naturally, we do not need to write a prompt for this node, as the prompts will be defined during the agent creation phase. This node will be created solely for the purpose of invoking the agents and utilizing the returned values.\n\n1. **Invoke Agents**: Use CrewAI‚Äôs `kickoff` method to send the user's query to the agents.\n2. **Process the Returned JSON**: Handle the JSON response received from the agents.\n3. **Convert to PDF**: Convert the relevant data from the JSON into a PDF format.\n\n```python\n#Write Essay Node\ndef write_essay(self, state: GraphState):\n    print(\"**ESSAY COMPLETION**\")\n\n    self.essay = self.crew.kickoff({\"topic\": state[\"topic\"]})\n\n    self.memory.save_context(inputs={\"input\": state[\"topic\"]},\n                           outputs={\"output\": str(self.essay)})\n\n    pdf_name = generate_pdf(self.essay)\n    return {\"response\": \"Here is your essay! \",  \"pdf_name\": f\"{pdf_name}\"}\n```\n\n**Edit Essay Node**: Let‚Äôs briefly discuss our final node, `edit_essay`. The code may appear a bit lengthy, as the prompt is kept within the node. You can also write the prompt during the class definition and assign it as a variable if you prefer.\n\nThis node will be activated by the router when it detects a request for any essay modifications from the user. In this node, we need three important values: the conversation history, the user‚Äôs request, and the most recently generated essay. Additionally, there is a variable in the prompt that Langchain will generate called `format_instructions`. This variable allows us to communicate to the LLM that we want to maintain the structure of the JSON format of the edited essay and to receive the response in the same format. Afterward, we will send the returned response to our PDF generation tool.\n\n1. **Detect Edit Request**: The router identifies whether the user‚Äôs request is for editing an essay.\n2. **Collect Necessary Values**: Gather the conversation history, user request, and the last generated essay.\n3. **Create and Use the Prompt**: Construct a prompt that includes `format_instructions`.\n4. **Generate the Edited Essay**: Invoke the LLM to get the edited essay and pass the response to the PDF generator.\n\n```python\n#Edit Essay Node\n\ndef edit_essay(self, state: GraphState):\n    print(\"**ESSAY EDIT**\")\n    memory = self.memory.load_memory_variables({})\n\n    user_request = state[\"topic\"]\n    parser = JsonOutputParser(pydantic_object=Essay)\n    prompt = PromptTemplate(\n      template=(\"Edit the Json file as user requested, \n                  and return the new Json file.\"\n                \"\\n Request:{user_request} \"\n                \"\\n Conservation History: {memory}\"\n                \"\\n Json File: {essay}\"\n                \" \\n{format_instructions}\"),\n      input_variables=[\"memory\",\"user_request\",\"essay\"],\n      partial_variables={\"format_instructions\": parser.get_format_instructions()},\n  )\n\n    chain = prompt | self.model | parser\n\n    self.essay = chain.invoke({\"user_request\": user_request,\n                               \"memory\": memory, \n                                \"essay\": self.essay})\n\n\n    self.memory.save_context(inputs={\"input\": state[\"topic\"]},\n                             outputs={\"output\": str(self.essay)})\n    pdf_name = generate_pdf(self.essay)\n    return {\"response\": \"Here is your edited essay! \", \n            \"essay\": self.essay, \"pdf_name\": f\"{pdf_name}\"}\n```\n\n## Building Agents\n\n**Content Researcher**: To keep our project simple, we have defined three agents that will communicate with each other and conduct internet searches to write essays. Let‚Äôs design the first agent, the researcher agent. This agent will perform web scraping on Wikipedia and other websites as needed, gathering necessary sources until it determines it has collected enough information. It will fetch main headings, subheadings, and articles related to the topic, preparing summaries. Subsequently, these documents will be stored to be sent to the writer's agent.\n\nWhen designing this agent, we need to consider its role, backstory, and goal. We will assign these to the parameters in the `Agent` class similarly to how we would construct a prompt, thereby readying the agent for operation.\n\n```python\n#Content Researcher Agent and Task\n\nself.researcher = Agent(\n    role=\"Content Researcher\",\n\n    goal=\"Research accurate content on {topic}\",\n\n    backstory=\"You're researching content to write \n                an essay about the topic: {topic}.\"\n              \"You collect information that helps \n                the audience learn something and make informed decisions.\"\n              \"Your work is the basis for the Content Writer to \n                write an article on this topic.\",\n    verbose=True\n)\n\nself.research = Task(\n    description=(\n        \"1. Prioritize the latest trends, key players, \n            and noteworthy news on {topic}.\\n\"\n        \"2. Identify the target audience, considering their \n            interests and pain points.\\n\"\n        \"3. Research a detailed content outline including \n            an introduction, key points, and a conclusion.\\n\"\n        \"4. Include SEO keywords and relevant data or sources.\"\n    ),\n    expected_output=\"A comprehensive document with an outline, \n                    audience analysis, SEO keywords, and resources.\",\n    tools=[search_wikipedia, scrap_webpage],\n    agent=self.researcher,\n)\n```\n\nWe need to create two classes: `Agent` and `Task`. Each agent can have one or more assigned tasks. We can assign tools directly to the agents or add task\\-specific tools. By adding the tool specifically for the task, we ensure that the tool is only used during that particular task.\n\n### Parameters\n\nThe parameters of our `Agent` class:\n\n1. **Role**: This defines the agent‚Äôs function within the crew. It determines the kind of tasks the agent is best suited for and should be short and descriptive.\n2. **Goal**: This is the individual objective that the agent aims to achieve. It guides the agent‚Äôs decision\\-making process and should be short and simple.\n3. **Backstory**: This provides context for the agent‚Äôs role and goal, enriching the interaction and collaboration dynamics. It should be as detailed as possible.\n4. **Verbose**: Setting this to `True` configures the internal logger to provide detailed execution logs, aiding in debugging and monitoring what our agent is engaged in.\n\nThe parameters of our `Task` class:\n\n1. **Description**: A clear and concise statement of what the task entails. This should be as detailed as possible to ensure clarity.\n2. **Expected Output**: A detailed description of what the task‚Äôs completion looks like, helping to set clear expectations for the outcome.\n3. **Tools**: The functions or capabilities the agent can utilize to perform the task. Here, you can use LangChain, CrewAI, or custom tools as needed.\n4. **Agent**: The agent responsible for the task, assigned either directly or through the crew‚Äôs process.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ocQ9ZUZwFtGx7a7pPrTbuQ.png)\n\n**Content Writer**: Once our researcher agent has gathered the necessary information through several iterations, it will store the collected data in memory, believing it has acquired sufficient knowledge, and pass the task to our next agent, the content writer.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HD1Bm7twxsUIVGPiqEhHAg.png)\n\nNow, let‚Äôs define our content writer agent and its role. This agent does not require the use of any tools, so it will suffice to detail the backstory and description similarly to the researcher agent. In the backstory, we must remember to specify which agent provided the source of information.\n\n### Parameters\n\n1. **Role**: The function of the content writer agent within the project. This should succinctly capture what the agent does.\n2. **Goal**: The specific objective that the content writer aims to achieve, such as drafting a well\\-structured essay based on the information collected.\n3. **Backstory**: This provides context for the content writer‚Äôs role, including details about the researcher agent and the information it has provided. A well\\-crafted backstory can enhance the narrative and collaboration dynamics.\n4. **Description**: A clear and concise statement of what the content writer does, focusing on its responsibilities and tasks.\n5. **Expected Output**: A detailed description of what the task‚Äôs completion looks like, helping to set clear expectations for the outcome.\n6. **Context**: Before executing the task, we specify which task to wait for to be completed and to obtain the necessary information from that task output with the context parameter.\n\n```python\n#Content Writer Agent and Task\n\nself.writer = Agent(\n  role=\"Content Writer\",\n\n  goal=\"Write insightful and factually accurate \"\n       \"opinion piece about the provided topic\",\n\n  backstory=\"You're working on a writing a new opinion piece \n              about the provided topic.\"\n            \"You base your writing on the work of the Content Researcher, \n             who provides an outline and relevant context about the topic.\"\n            \"You follow the main objectives and direction of the outline, \n              as provide by the Content Researcher.\"\n            \"You also provide objective and impartial insights \n             and back them up with information provide \n             by the Content Researcher.\",\n  verbose=True,\n)\n\nself.write = Task(\n  description=(\n      \"1. Use the content to craft a compelling essay.\\n\"\n      \"2. Incorporate SEO keywords naturally.\\n\"\n      \"3. Sections/Subtitles are properly named in an engaging manner.\\n\"\n      \"4. Ensure the essay is structured with an engaging introduction, \n          insightful body, and a summarizing conclusion.\\n\"\n      \"5. Proofread for grammatical errors and alignment with \n          the brand's voice.\\n\"\n      \"6. Pick a suitable header\\n\"\n  ),\n  expected_output=\"A well-written essay in markdown format, \n                  ready for publication, each section \n                  should have 2 or 3 paragraphs.\",\n  context=[self.research],\n  agent=self.writer,\n)\n```\n\n**Content Editor**: After defining the writer agent, we could have concluded the process; however, even though the writer agent is responsible for writing, it may still make spelling mistakes and errors that disrupt the coherence of the content. To prevent these issues and to export the essay output in JSON format, we will define one more agent: the content editor.\n\nIn the backstory of this agent, we will specify that it is responsible for reviewing and correcting the essay received from the writer agent. In the task phase, we will also define the required output format.\n\n```python\n#Content Editor Agent and Task\nself.editor = Agent(\n    role=\"Content Editor\",\n\n    goal=\"Edit a given essay to align with the writing \n            style of the organization.\",\n\n    backstory=\"You are an editor who receives an essay \n                from the Content Writer.\"\n              \"Your goal is to review the essay to ensure \n                that it follows best practices, provides balanced viewpoints\"\n              \"When providing opinions or assertions,\n                and also avoids major controversial topics \n                or opinions when possible.\",\n    verbose=True\n)\n\nself.edit = Task(\n    description=\"Proofread the given essay for grammatical errors \n                  and alignment with the brand's voice.\",\n\n    expected_output=\"A well-written essay in required format, \n                      ready for publication, each section \n                      should have 2 or 3 paragraphs.\",\n    output_json = Essay,\n    context=[self.write],\n    agent=self.editor\n)\n```\n\nHere, our output is an object named; `Essay`, created with the help of the `BaseModel` and `Field` classes from the Pydantic Library. By adding explanations that our agent can understand, we ensure that the agent will output data in a format expected by our PDF printing function.\n\n```python\n#Expected Pydantic Output\n\nclass Paragraph(TypedDict):\n    sub_header: str\n    paragraph: str\n\nclass Essay(BaseModel):\n    header: str = Field(..., description=\"The header of the essay\")\n    entry: str = Field(..., description=\"The entry of the essay\")\n    paragraphs: List[Paragraph] = Field(..., description=\"The paragraphs of the essay\")\n    conclusion: str = Field(..., description=\"The conclusion of the essay\")\n    seo_keywords: List[str] = Field(..., description=\"The SEO keywords of the essay\")\n```\n\nWe have defined our agents and their tasks. Now, let‚Äôs bring together our three agents. For this, we should use a small yet functional method from the CrewAI library called `Crew`. In this method, we list the agents that will operate sequentially along with the tools they will use. If the tasks need to be executed in order, as in our project, we set the `process` parameter to `Process.sequential`. We also set the `memory` parameter to `True` to enable the agents to communicate with each other using short\\-term and long\\-term memory.\n\n```python\n#Crew Run\n\ndef kickoff(self,*args):\n    return Crew(\n        agents=[self.researcher, self.writer, self.editor],\n        tasks=[self.research, self.write, self.edit],\n        process=Process.sequential,\n        verbose=True,\n        memory=True\n    ).kickoff(*args)\n```\n\nOur agent structure is complete, but we haven‚Äôt discussed our tools yet. Now, let‚Äôs briefly address our tools.\n\n## Building Tools\n\nTools are essentially functions that take various inputs and return a value as output. Our agents will simply provide the expected input to these functions and process the output they receive. Therefore, we need to design our tools with high fault tolerance. When a usage error occurs, our agents should be able to read the error and be equipped with information to use the tool correctly in the next iteration.\n\nAfter preparing the functions for our tools, we should convert them into tool objects using either LangChain or CrewAI‚Äôs Tool creation class, along with various explanations. Here, we convert our tool into a form that our agent can use by simply writing C**rewAI‚Äôs tool decorator** at the top of our function.\n\n```python\nfrom crewai_tools import tool\n\n@tool(\"Wikipedia Search Tool\")\ndef search_wikipedia(query: str) -> str:\n    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n    page_titles = wikipedia.search(query)\n    summaries = []\n\n    for page_title in page_titles[:3]:  # First 3 results\n        try:\n            wiki_page = wikipedia.page(title=page_title, auto_suggest=False)\n            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n        except wikipedia.PageError: # Page Not Found\n            pass\n        except wikipedia.DisambiguationError: # Disambiguation Error\n            pass\n\n    if not summaries:\n        return \"No good Wikipedia Search Result was found\"\n\n    return \"\\n\\n\".join(summaries)\n```\n\n## Building App\n\nNow, let‚Äôs deploy our application live using the Streamlit framework, which I frequently use and believe offers an easy interface design. Streamlit is an open\\-source Python framework for data scientists and AI/ML engineers to deliver dynamic data apps with only a few lines of code.\n\nOur app primarily activates when the user enters their OpenAI key in a `text_input` box and then clicks the \"Initialize Agents\" button. When the user sends a message through the active `chat_input` section, the following function is used to relay the entered request to our established agent structure:\n\n```python\ndef generate_response(topic):\n    return app.invoke(input={\"topic\": topic})\n```\n\nWith Streamlit‚Äôs `st.chat_message` component, we can easily implement a chatbot interface. If the user is engaged in regular messaging, the response will display a normal answer. If an essay has been generated, we‚Äôll provide the directory of the PDF to the user by writing a simple if\\-else loop.\n\nMeanwhile, we add every message we send and receive from the chatbot to a `messages` variable created in Streamlit‚Äôs `session_state`. This way, we create a visible chat screen.\n\n```python\n#Streamlit App\n\nimport streamlit as st\nfrom graph import EssayWriter\nimport os\nimport base64\n\nst.set_page_config(page_title=\"Essay Writer Chat Bot\", page_icon=\"ü§ñ\")\nst.image(\"./media/cover.jpg\", use_column_width=True)\n\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages =  [{\"role\": \"assistant\", \"content\": \"Hello!\"}]\n    st.session_state.app = None\n    st.session_state.chat_active = True\n\nwith st.sidebar:\n    st.info(\" * This app uses the OpenAI API to generate text, please provide your API key.\"\n            \"\\n\\n * This app uses the 'gpt-4o-mini-2024-07-18' model. Cost effective and efficient.\"\n            \"\\n\\n * If you don't have an API key, you can get one [here](https://proxy.rifx.online/https://platform.openai.com/signup).\"\n            \"\\n\\n * You can also find the source code for this app [here](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer)\"\n            \"\\n\\n * App keys are not stored or saved in any way.\"\n            \"\\n\\n * Writing essay may take some time, please be patient. Approximately 1-2 minutes.\"\n    openai_key= st.text_input(\"OpenAI API Key\", type=\"password\")\n\n\ndef initialize_agents():\n    os.environ[\"OPENAI_API_KEY\"] = openai_key\n    essay_writer = EssayWriter().graph\n\n    if len(openai_key) < 1:\n        st.error(\"Please enter your OpenAI API key and Initialize the agents.\")\n\n        st.session_state.chat_active = True\n    else:\n        st.success(\"Agents successfully initialized\")\n        st.session_state.chat_active = False\n\n    return essay_writer\n\nwith st.sidebar:\n    if st.button(\"Initialize Agents\", type=\"primary\"):\n        st.session_state.app = initialize_agents()\n\napp = st.session_state.app\ndef generate_response(topic):\n    return app.invoke(input={\"topic\": topic})\n\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"], unsafe_allow_html=True)\n\nif topic:= st.chat_input(placeholder=\"Ask a question\", disabled=st.session_state.chat_active):\n    st.chat_message(\"user\").markdown(topic)\n\n    st.session_state.messages.append({\"role\": \"user\", \"content\": topic})\n    with st.spinner(\"Thinking...\"):\n        response = generate_response(topic)\n\n    with st.chat_message(\"assistant\"):\n        if \"pdf_name\" in response:\n            with open(f\"./{response['pdf_name']}\", \"rb\") as file:\n                file_bytes = file.read()\n                b64 = base64.b64encode(file_bytes).decode()\n            href = f'<a href=\"data:application/pdf;base64,{b64}\" download=\"{response['pdf_name']}\">{response['pdf_name']}</a>'\n\n            st.markdown(f\"{response['response']}: {href}\", unsafe_allow_html=True)\n            st.session_state.messages.append({\"role\": \"assistant\", \"content\": f\"{response['response']}: {href}\"})\n        else:\n            st.markdown(response[\"response\"])\n            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"response\"]})\n```\n\n**Congratulations**! We have completed our project. If you wish, you can watch the project work log that I have recorded for you. Don‚Äôt forget to visit the GitHub [**repo**](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) to access all the codes of the project.\n\nAnd this is how our app‚Äôs main page will look like once we deploy it!\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8tDAluuAH6njIohDbb-UqA.png)\n\n## Conclusion\n\nIn this article, we explored how to build autonomous multi\\-agent systems using CrewAI. We started by discussing the motivation behind creating agents and how they can work together to accomplish tasks more efficiently. By breaking down tasks and utilizing tools, we enabled our agents to perform complex operations in a structured way.\n\nWe developed a simple project that integrated the CrewAI and LangChain frameworks, showcasing how multiple agents can collaborate to gather information, write essays, and edit content. The use of tools and task management was emphasized to ensure our agents operated smoothly and effectively.\n\nFinally, we deployed our application using Streamlit, allowing users to interact with the system effortlessly.\n\nYou can check out the live project [**here**](https://proxy.rifx.online/https://multi-agent-essay-writer.streamlit.app/), view the source code on my GitHub repository [**here**](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/building-self-healing-intelligent-test-automation-with-gen-ai-openai-apis-6c39808adb0f","frontmatter":{"title":"Building Intelligent Test Automation with Gen AI (OpenAI APIs)","meta_title":"Building Intelligent Test Automation with Gen AI (OpenAI APIs)","description":"We all know that UI Tests are super fragile. They can break for all sorts of reasons, and one of the biggest culprits is changes to the UI‚Ä¶","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kZ4ZR-jqdTTgH3bpOzcgUw.png","categories":["Generative AI","Programming","Testing"],"author":"Rifx.Online","tags":["Generative","OpenAI","Selenium","LLMs","POM"],"draft":false,"slug":"blog/building-self-healing-intelligent-test-automation-with-gen-ai-openai-apis-6c39808adb0f"},"content":"\n\n\n\n\n> We all know that UI Tests are super fragile. They can break for all sorts of reasons, and one of the biggest culprits is changes to the UI locators. It‚Äôs hard to imagine how we can make them smart enough to understand when the locators have changed and prevent the tests from running until when the locator issue in our test occurs.\n\nGuess what? It‚Äôs 2024, and automation testing tools have come a long way. After almost 18 years of working with them, from Mercury Winrunner to Playwright, we can now do some truly amazing things thanks to the power of Generative AI. It‚Äôs like magic, but it‚Äôs science!\n\nYou heard it right, we can now device a way to make our test automation code **more intelligent** without writing all sort of fuzzy mathematical algorithms ourselves, it's all taken care by the God of LLMs.\n\nIn this post, we are going to discuss how we can make our tests intelligent in more effective and efficient fashion, but again, for you to make this happen you need to have following pre\\-requisite\n\n1. **Open AI API** with Credit (you need to purchase it on the go)\n\n\n\n2\\. C\\# .NET code knowledge, as the code I will be covering is from .NET and Selenium\n\n3\\. Basic understanding of Test automation\n\nAgain, all the above and following discussions are part of my [Udemy course](https://proxy.rifx.online/https://www.udemy.com/course/generative-ai-in-software-automation-testing/) which covers even more details and step\\-by step way of writing the code.\n\n\n## Lets understand the problem statement\n\nSo we‚Äôve got this page that we want to automate using Selenium C\\# code. We‚Äôve written the code really well using the Page Object model (POM) pattern, and everything looks great and works perfectly as shown below.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GPSBTmPEZBpubI72OElwbw.gif)\n\nOur dev champ spotted a UI element that needs some tweaking. He made a change based on his peers‚Äô code review comments, but unfortunately, he removed a locator that we‚Äôre using in our automation testing. This means our POM code with the locator won‚Äôt work anymore since it doesn‚Äôt exist anymore, which eventually cause the test to **FAIL**.\n\nThe most important thing is that the test will fail for all the test scenarios with the same failure because of a single locator change. The test doesn‚Äôt know or have any way to know that the locator has changed, and it fails all the time.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tINBnScOW78vz8sKb6lWbA.gif)\n\n\n## How to resolve the problem?\n\nI am sure like me many of you are going through this day\\-in and day\\-out everyday while working with UI testing tools, it could be **Cypress**, **Selenium** or **Playwright**. The problem is always imminent regardless of the tool\n\nNow let's understand how we can resolve the problem above.\n\nWe all know **Generative AI** with **LLMs** (Large Language Models) are way beyond just text/image/video generation. They understand the given context and generate a meaningful set of information that we are looking for.\n\nSo, with the above problem statement, we can using the power of Gen AI using the OpenAI‚Äôs API which can pass our prompt request to LLMs like ***GPT 4o*** or ***GPT 4 turbo*** to understand the problem statement and give us meaningful solution.\n\n\n> So, whats the prompt request we need to pass to OpenAI‚Äôs API to get the operation to happen in our test automation?\n\nWell, this diagram will give you the answer\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*bsCOcyWc0FDnxPp9ApssVw.gif)\n\nWe can send OpenAI‚Äôs API the ‚Äú**Actual Page Under Test**‚Äù of our application and our Selenium Test‚Äôs ‚Äú**Page Object Model**‚Äù code as a prompt (with a few extra response parsing details). This will act as a validation process from OpenAI‚Äôs API to see if the locators match the given page.\n\nBased on that operation, we can tell the test to execute or not. The locators have changed, so it‚Äôs not worth running the test any further.\n\nThe code to perform the above operation will look something like this\n\n\n```python\npublic static async Task<string> VerifyPageLocatorFromAiAsync(string pomFileContent, string htmlPageSource)\n{\n    ChatClient client = new(model: \"gpt-4o-mini\", apiKey);\n    \n    var chatMessage = $\"Verify if locators from this Selenium POM class: {pomFileContent} match this page source: {htmlPageSource}\\\", only return True or False result\";\n\n    ChatCompletion completion = await client.CompleteChatAsync(chatMessage);\n\n    return completion.Content.FirstOrDefault().Text;\n}\n```\nThe code above is just part of the large code covered in the course, but you can see how straightforward it is to perform the operation of analysing your page against the Page Object Model code of Selenium.\n\n\n## GenAI in Software Testing Course\n\n*Most of the above discuss is just a slice of the topic we have discussed in my new course in Udemy on ‚Äú[**Using Generative AI in Software Automation Testing**](https://proxy.rifx.online/https://www.udemy.com/course/generative-ai-in-software-automation-testing/)‚Äù*\n\nHere is the course content\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*lHe_b7qVqUQo-9Y5.png)\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rMrsbB2IaKPbthdAr9Rc9g.png)\n\nThe course is currently available for discount in Udemy as the launch offer, please use coupon code **EA\\_NOV\\_24 ‚ö°Ô∏è** for discount while purchasing the course.\n\nIf the coupon code is expired, please feel free to comment on this post, I will send you the latest available coupon code.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/case-study-turning-doctor-transcripts-into-temporal-medical-record-knowledge-graphs-cf624d4927eb","frontmatter":{"title":"Case Study: Turning Doctor Transcripts into Temporal Medical Record Knowledge Graphs","meta_title":"Case Study: Turning Doctor Transcripts into Temporal Medical Record Knowledge Graphs","description":"Showcase of Data Transformation Process, Breakdown of 25 dev hours involved, Schemas used, Questions & Responses, and Graph created","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DUNtg-0w2z-vlF9SCvt5UA.png","categories":["Health","Data Science","Machine Learning"],"author":"Rifx.Online","tags":["transcripts","Temporal","Knowledge","Graphs","vector"],"draft":false,"slug":"blog/case-study-turning-doctor-transcripts-into-temporal-medical-record-knowledge-graphs-cf624d4927eb"},"content":"\n\n\n\nInterested in turning Doctor/Patient medical records and transcripts into Temporal Knowledge Graph that you can ask complex questions across multiple medical histories, time periods, and patients?\n\nIn this case study, we show how Medical Transcripts are turned into Temporal Knowledge Graphs that you can rely on for the purposes of RAG and analytics. We show what real Question \\& Answers are against this system, and what type of business outcomes you can achieve with this system. As far as we are aware, the combination of steps here is a relatively novel Knowledge Graph implementation.\n\n\n### Data used\n\nFor data privacy reasons, we used a synthetic dataset of Medical Transcripts that we created out of Synthea data found here: [https://synthea.mitre.org/downloads](https://proxy.rifx.online/https://synthea.mitre.org/downloads). The below is an example of one of the medical transcripts used as the input data for the Knowledge Graph creation. We combined these transcript data with structured medical records in the Synthea data. We had \\~75 transcripts that covered 10 patients (i.e. each patient had 5‚Äì10 transcripts). Here is an example of a transcript used:\n\n\n\n\n## Novel Knowledge Graph Architecture Overview\n\n\n### Nodes:\n\nWe have 5 types of Nodes: Patient, Observation, Immunization, Condition and Encounter Type\n\n\n### Triples (Sample List):\n\nPatient \\-\\> Had Encounter \\-\\> Encounter\n\nPatient \\-\\> Has Condition \\-\\> Condition\n\nPatient \\-\\> Received \\-\\> Immunization\n\nPatient \\-\\> Has Measurement \\-\\> Observation\n\n\n### Chunks:\n\nChunks are chunks of text that are standalone objects. Chunks are tied to each Triple, and there can be many Chunks tied to a single Triple. Instead of being the unstructured source of the Triple, the Chunks in this case are summaries and key points related to each Triple type. As a result, we have 6 types of Chunks:\\- Patient Demographic Chunks, Condition Summary Chunks, Visit Chunks, Observation Chunks, Immunization Chunks and Condition Detail Chunks.\n\nAn example of what different type of chunks are tied to triples look like the following:\n\n\n```python\n1. Patient -> EncounterType\nTriple: (Patient) -[had_encounter]-> (EncounterType)\n- Chunk_ids link to specific visit instances\n- Example Chunk: \"Annual physical on 2024‚Äì01‚Äì15. BP 120/80, routine screenings \nupdated.\"\n\n2. Patient -> Condition\nTriple: (Patient) -[has_condition]-> (Condition)\n- Chunk_ids link to condition episodes\n- Example Chunk: \"Diagnosed with hypertension on 2020‚Äì03‚Äì10. Status: active. \nManaged with medication.\"\n\n3. Patient -> Immunization\nTriple: (Patient) -[received]-> (Immunization)\n- Chunk_ids link to administration records\n- Example Chunk: \"Influenza vaccine administered on 2024‚Äì01‚Äì15.\"\n\n4. Patient -> Observation\nTriple: (Patient) -[has_measurement]-> (Observation)\n- Chunk_ids link to measurement instances\n- Example Chunk: \"2024‚Äì01‚Äì15: Blood Pressure 120/80 mmHg, Weight 70kg.\"\n```\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*8dH_7tP6xheCaW6K)\n\n**Link to the Graph created: [https://proxy.rifx.online/https://main\\-\\-whyhowai.netlify.app/public/graph/673032011997e08c8849316c](https://proxy.rifx.online/https://main--whyhowai.netlify.app/public/graph/673032011997e08c8849316c)**\n\nWith this particular graph architecture, where you can have key points and summaries tied to triples, you can then focus on landing on the right set of triples through an unstructured search, and subsequently bringing in all the relevant key information through the linked chunks in a structured way.\n\n\n## Unique to WhyHow Architecture\n\nThere are a few things unique to the WhyHow graph infrastructure that allows us to build this architecture in a simple way.\n\nFirstly, Triples are embedded and retrieved through vector search, avoiding a common retrieval issue of having to use Text2Cypher for the identification of nodes, relationships, and then Cypher query construction just to land on the right Triple. This has shown to dramatically [improve retrieval accuracy by up to 3x](https://proxy.rifx.online/https://readmedium.com/knowledge-table-multi-document-rag-extraction-memory-ec08450e858f).\n\nSecondly, Triples are standalone objects in WhyHow that you can link chunks to. This allows you to distill the key information that you want to retrieve per Triple, and bring it directly into the context once the right Triples are found. This avoids having to represent crucial information and context in a graph format (complicating the schema construction process), and bringing in information in a structured way after the initial unstructured vector search. This is similar in process to [LinkedIn‚Äôs application of Knowledge Graphs](https://proxy.rifx.online/https://readmedium.com/5-misconceptions-of-kg-rag-systems-building-using-rag-native-graphs-5e47872e7903) in their system, where crucial information like ‚ÄòSteps to Reproduce‚Äô are represented and retrieved similarly, and where the steps themselves are represented as individual ‚Äòchunks‚Äô/ ‚Äònodes‚Äô.\n\nThirdly, WhyHow accepts data in a JSON format, which allows seamless interaction between any of the extraction frameworks directly into graph creation. In this case, we use Claude for the initial transformation of the transcript data into the necessary JSON structure to load into WhyHow. If you have information already sitting in JSON, loading data into WhyHow is then a lot easier.\n\nFourthly, because of the way that Chunks and the retrieval process is designed in the WhyHow system, you can easily include temporal data that can be used to govern the way that the answer is constructed. Temporal data has always been a hard thing to model in Knowledge Graphs (to the point that it is typically advised against by leading KG experts), but is an obviously important part of workflows. Existing methods that even attempt to model temporal data try to ingest this into the Knowledge Graph itself and then retrieve based on a structured Cypher query, as opposed to our architecture that uniquely uses the LLM to help filter for temporal data.\n\nBlending the power of LLM with structured knowledge representations like Knowledge Graphs are important ways to achieve business outcomes, and we think this temporal Knowledge Graph architecture will help unlock a lot of business value through the successful implementation of temporal data.\n\n\n### Data Transformation Process Used\n\nFirst, we use Claude to turn the transcript information into a schema\\-aligned set of information on a per transcript basis. Alongside information from structured medical Records, the transcript is turned into a JSON summarization that looks like this:\n\n\n```python\nPATIENT SUMMARY\nName: Joseph Crona\nDOB: 2022‚Äì08‚Äì29\nAge: 2 years\nGender: male\nMRN: #dbfbaa\n\nCURRENT MEASUREMENTS (as of 2024‚Äì08‚Äì05)\nHeight: 84.1cm (50th percentile)\nWeight: 14.5kg (52nd percentile)\nALLERGIES\nNo known allergies\n\nIMMUNIZATIONS\n- DTaP: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì03‚Äì06, 2024‚Äì02‚Äì05\n- Hepatitis A: 2023‚Äì11‚Äì06\n- Hepatitis B: 2022‚Äì08‚Äì29, 2022‚Äì10‚Äì03, 2023‚Äì03‚Äì06\n- Hib: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì11‚Äì06\n- Influenza: 2023‚Äì03‚Äì06, 2024‚Äì08‚Äì05\n- MMR: 2023‚Äì11‚Äì06\n- PCV13: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì03‚Äì06, 2023‚Äì11‚Äì06\n- Polio: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì03‚Äì06\n- Rotavirus: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06\n- Varicella: 2023‚Äì11‚Äì06\n\nMEDICAL HISTORY\n- Viral sinusitis (disorder)\nOnset: 2023‚Äì03‚Äì13\nStatus: resolved\nOutcome: Resolved\n\nGROWTH & DEVELOPMENT\n- 2023‚Äì11‚Äì06: Body Weight: 12.7 kg\n- 2024‚Äì02‚Äì05: Body Height: 79 cm\n- 2024‚Äì02‚Äì05: Body Weight: 13.4 kg\n- 2024‚Äì08‚Äì05: Body Height: 84.1 cm\n- 2024‚Äì08‚Äì05: Body Weight: 14.5 kg\nDevelopment: Age-appropriate milestones met\n- Gross motor: Age appropriate\n- Fine motor: Age appropriate\n- Language: Age appropriate\n- Social: Age appropriate\n\nPREVENTIVE CARE\nWell-Child Visits:\n- 2024‚Äì08‚Äì05: 2yo well visit - Development on track\n- 2024‚Äì02‚Äì05: 1yo well visit - Development on track\n- 2023‚Äì11‚Äì06: 1yo well visit - Development on track\n- 2023‚Äì08‚Äì07: 1yo well visit - Development on track\n- 2023‚Äì05‚Äì08: 9mo well visit - Age appropriate exam completed\n- 2023‚Äì02‚Äì06: 6mo well visit - Age appropriate exam completed\n- 2022‚Äì12‚Äì05: 4mo well visit - Age appropriate exam completed\n- 2022‚Äì10‚Äì03: 2mo well visit - Age appropriate exam completed\n- 2022‚Äì08‚Äì29: Newborn visit - Normal exam\n\nFAMILY HISTORY\nMother: Healthy\nFather: Healthy\nSiblings: None documented\n\nSOCIAL HISTORY\nLiving Situation: Lives with parents\nDevelopment: Meeting age-appropriate milestones\nSleep: Age-appropriate pattern\nNutrition: Age-appropriate diet\n```\nSecondly, we map this JSON schema into the WhyHow schema, and then import all the information into the WhyHow.AI KG Studio.\n\nThe below is a sample of the KG Structure that was ultimately loaded into WhyHow.\n\n\n```python\nKnowledge Graph Structure (Timeless):\n\n\nNodes:\n1. Patient Node\n  Structure: {\n      name: str,         # \"John Smith\"\n      label: \"Patient\",\n      properties: {\n          gender: str,   # FHIR gender\n          patient_type: str  # \"adult\" | \"pediatric\"\n      },\n      chunk_ids: List[str]  # Links to demographic chunks\n  }\n\n\n2. EncounterType Node\n  Structure: {\n      name: str,         # \"Well-child visit\" | \"Annual physical\"\n      label: \"EncounterType\",\n      properties: {\n          category: str,  # \"preventive\" | \"acute\" | \"chronic\"\n          specialty: str  # \"primary_care\" | \"pediatrics\" | \"emergency\"\n      },\n      chunk_ids: List[str]  # Links to visit pattern chunks\n  }\n\n\n3. Condition Node\n  Structure: {\n      name: str,         # \"Essential hypertension\"\n      label: \"Condition\",\n      properties: {\n          category: str,     # \"chronic\" | \"acute\" | \"resolved\"\n          system: str,       # \"respiratory\" | \"cardiovascular\" | etc\n          is_primary: bool   # True if primary diagnosis\n      },\n      chunk_ids: List[str]  # Links to condition history chunks\n  }\n\n\n4. Immunization Node\n  Structure: {\n      name: str,         # \"DTaP\" | \"MMR\"\n      label: \"Immunization\",\n      properties: {\n          series: str,       # \"primary\" | \"booster\"\n          target: str        # \"tetanus\" | \"measles\" | etc\n      },\n      chunk_ids: List[str]  # Links to immunization records\n  }\n\n\n5. Observation Node\n  Structure: {\n      name: str,         # \"Blood Pressure\" | \"Height\"\n      label: \"Observation\",\n      properties: {\n          category: str,     # \"vital\" | \"lab\" | \"growth\"\n          unit: str         # \"mmHg\" | \"cm\" | etc\n      },\n      chunk_ids: List[str]  # Links to measurement records\n  }\n\n\nRelations:\n1. Patient -> EncounterType\n  Triple: (Patient) -[had_encounter]-> (EncounterType)\n  - Chunk_ids link to specific visit instances\n\n\n2. Patient -> Condition\n  Triple: (Patient) -[has_condition]-> (Condition)\n  - Chunk_ids link to condition episodes\n\n\n3. Patient -> Immunization\n  Triple: (Patient) -[received]-> (Immunization)\n  - Chunk_ids link to administration records\n\n\n4. Patient -> Observation\n  Triple: (Patient) -[has_measurement]-> (Observation)\n  - Chunk_ids link to measurement instances\n\n\n5. Condition -> EncounterType\n  Triple: (Condition) -[managed_in]-> (EncounterType)\n  - Links conditions to typical encounter types\n\n\n6. Immunization -> EncounterType\n  Triple: (Immunization) -[given_during]-> (EncounterType)\n  - Links vaccines to visit types\n```\nThirdly, we then run a custom prompt that contextualizes the triples retrieved from the Knowledge Graph after every natural language query.\n\nWith this architecture in place, one interesting thing is that we can now continue to add information about Patient visits, Patient treatments and conditions to the Knowledge Graph easily, since it is just a matter of adding additional chunks to the existing triples that exist. If a Patient gets a new disease, additional Condition nodes are added to the Patient nodes.\n\nThis process took 25 dev hours, which can be broken down into the following:\n\n* 2 hours (8%) was spent looking and understanding the data (Exploratory Data Analysis)\n* 18 hours (72%) was spent iterating on the schema, and figuring out what nodes should be in the graph, what nodes should be connected to what, what chunks should exist, how it should connect to the various triples, testing the retrieved answers with a set of questions, and iterating accordingly.\n* 2 hours (8%) was spent writing the code to create the set of triples to be loaded in\n* 3 hours (12%) was spent writing validation checks and output checks to catch any errors\n\n\n### Question \\& Answer against Medical Record Knowledge Graphs\n\nPrompt used for answer construction after retrieving the relevant context from the Knowledge Graph, using the WhyHow natural language graph query engine\n\n\n```python\n    You are an AI assistant specializing in medical records analysis. \nUse the following information to answer the user's question. \n    The information is derived from a knowledge graph of patient medical records.\n\n    Relevant Nodes (these represent patients, encounters, and conditions):\n    {node_context}\n\n    Relevant Relationships (these show connections between patients, \nencounters, and conditions):\n    {triple_context}\n\n    Relevant Medical Records:\n    {chunk_context}\n\n    Answer the question using the following steps:\n    1. Analyze the medical information, focusing on the specific topic of the \nquestion\n    2. Identify key medical events, conditions, and temporal relationships\n    3. Formulate a clear and concise answer that directly addresses the \nquestion\n    4. If there are any uncertainties in the medical information, mention \nthem explicitly\n    5. If you don't have enough information to answer confidently, say so\n    6. Consider temporal relationships between medical events\n    7. It's currently {datetime.now().strftime(\"%Y-%m-%d\")}. Consider this \nwhen interpreting dates\n    8. Maintain patient privacy by using only first names or initials when \nnecessary\n\n    Question: {question}\n```\n\n## Business Value: Analysis of Patient Treatments\n\n\n### Historical Patient Analysis\n\nQuestion: **What types of well\\-child visits and immunizations did Joseph Crona receive in their first year?**\n\nAnswer:\n\n\n```python\nTo determine the types of well-child visits and immunizations Joseph Crona \nreceived in his first year, we need to consider the relevant medical events \nand their timing. Joseph was born in 2022, and it is currently November 9, 2024.\nTherefore, his first year would span from 2022 to 2023.\n\n**Well-Child Visits:**\n- Joseph had an encounter categorized as a \"Well child visit,\" which falls \nunder preventive care in pediatrics. This type of visit is typically part of \nroutine check-ups for children, especially in their first year.\n\n**Immunizations:**\nDuring his first year, Joseph received the following immunizations, all of \nwhich are common for pediatric patients:\n1. **Hep B, adolescent or pediatric** - Completed\n2. **Hib (PRP-OMP)** - Completed\n3. **Rotavirus, monovalent** - Completed\n4. **IPV (Inactivated Poliovirus Vaccine)** - Completed\n5. **DTaP (Diphtheria, Tetanus, and Pertussis)** - Completed\n6. **Pneumococcal conjugate PCV 13** - Completed\n\nThese immunizations are typically administered during the first year of life \nas part of the standard immunization schedule for infants.\n\nIn summary, Joseph Crona received a well-child visit and completed a series of\nstandard pediatric immunizations during his first year.\n```\nQuestion: **For patients with otitis media, what was the sequence of encounters and observations recorded?**\n\nAnswer:\n\n\n```python\nTo address the question regarding the sequence of encounters and observations \nfor patients with otitis media, we will focus on the medical records of Miles \nDickinson, as he is the patient identified with this condition.\n\n1. **Condition Onset:**\n- Miles Dickinson was diagnosed with otitis media on June 10, 2024. The \ncondition is currently resolved.\n\n2. **Encounters:**\n- Miles had two types of encounters recorded:\n- **Well Child Visit:** This is categorized as a preventive encounter in \npediatrics.\n- **Encounter for Symptom:** This is categorized as a follow-up encounter in \nprimary care.\n\n3. **Observations:**\n- Various observations were recorded for Miles, including:\n- **Pain Severity:** Recorded multiple times with scores ranging from 0 to 4.\n- **Body Weight:** Recorded with values ranging from 3.2 kg to 8.2 kg.\n- **Head Occipital-frontal Circumference and Percentile:** Recorded with \nspecific values in cm and percentiles.\n- **Heart Rate:** Recorded with values ranging from 61 to 100 beats per minute.\n- **Respiratory Rate:** Recorded with values ranging from 12 to 16 breaths per\nminute.\n\n4. **Temporal Sequence:**\n- The otitis media diagnosis occurred on June 10, 2024. Observations and \nencounters before this date may have been related to other conditions or \nroutine check-ups. Observations and encounters after this date could be \nrelated to follow-up care for otitis media or other health assessments.\n\n5. **Conclusion:**\n- The sequence of encounters and observations for Miles Dickinson includes \npreventive and follow-up encounters, along with various health observations. \nThe specific sequence related to otitis media is not detailed in terms of exact\ndates for each observation or encounter, but the diagnosis date provides a \ntemporal marker for understanding subsequent medical activities.\n\nIf more detailed temporal data on each observation and encounter were \navailable, a more precise sequence could be established. However, based on \nthe current information, this is the overview of the sequence related to \notitis media for Miles Dickinson.\n```\n\n### Historical Multi\\-Patient Analysis\n\nQuestion: **How many patients have been diagnosed with acute bronchitis, and what are the typical onset patterns?**\n\nAnswer:\n\n\n```python\nBased on the provided medical records, there are two patients diagnosed with \nacute bronchitis: Maximo Swaniawski and Bennie Herman.\n\n#### Onset Patterns:\n- **Maximo Swaniawski**:\n- Onset dates for acute bronchitis:\n- October 24, 2014\n- November 7, 2015\n- November 29, 2018\n- **Bennie Herman**:\n- Onset dates for acute bronchitis:\n- October 24, 2014\n- November 7, 2015\n- November 29, 2018\n\n#### Typical Onset Patterns:\nThe onset dates for both patients are identical, suggesting a pattern where \nacute bronchitis episodes occurred in late October or November. This could \nindicate a seasonal pattern, possibly related to colder weather or other \nseasonal factors that might contribute to respiratory conditions.\n\nBoth patients have had their conditions resolved, indicating that the episodes \nof acute bronchitis were acute and not chronic.\n```\nQuestion: **Which patients had both viral sinusitis and bronchitis, and what were their earliest onset dates?**\n\nAnswer:\n\n\n```python\nTo determine which patients had both viral sinusitis and bronchitis, \nwe need to analyze the conditions associated with each patient and their \nonset dates.\n\n1. **Maximo Swaniawski**:\n- Conditions: Acute bronchitis\n- Earliest onset of bronchitis: 2014‚Äì10‚Äì24\n2. **Cassandra Monahan**:\n- Conditions: Viral sinusitis\n- Earliest onset of sinusitis: 2014‚Äì12‚Äì12\n3. **Bennie Herman**:\n- Conditions: Acute bronchitis\n- Earliest onset of bronchitis: 2014‚Äì10‚Äì24\n4. **Deangelo Price**:\n- Conditions: Viral sinusitis\n- Earliest onset of sinusitis: 2014‚Äì12‚Äì12\n5. **Joseph Crona**:\n- Conditions: Viral sinusitis\n- Earliest onset of sinusitis: 2014‚Äì12‚Äì12\n\nFrom the information provided, none of the patients have both viral sinusitis \nand bronchitis. Each patient has either one condition or the other, but not \nboth. Therefore, there are no patients with both conditions, and consequently, \nno earliest onset dates for both conditions in a single patient.\n```\n\n### Advantages against Vector\\-Only RAG systems\n\nSuperior Analytics across multiple patients:\n\n* In the question about which patients have both bronchitis and viral sinusitis conditions, we must be able to know if a patient is recorded to have or not have a particular disease. Since Vector\\-Only Search is about identifying relevant chunks, it cannot detect if a patient definitely does not have a particular disease. This means that an intermediary aggregation of data is required that can definitively say that Patient X does not have the ‚Äòdiabetes‚Äô node against their name.\n\nMulti\\-Transcript Analysis and RAG:\n\n* In the question about Miles and his multiple visits in the past year, we can see that the conditions are across multiple visits and multiple transcripts. This means that an intermediary aggregation of data is required that maps a Patient and the cumulative visits and observations they‚Äôve incurred over time.\n\nWhyHow.AI provides tools, services and processes for Structured Knowledge, Knowledge Graphs and more reliable Agentic RAG solutions. If you are interested in exploring any of our tools ([KG Studio](https://proxy.rifx.online/https://readmedium.com/whyhow-ai-kg-studio-platform-beta-rag-native-graphs-1105e5a84ff2), [Knowledge Table \\[Open Source]](https://proxy.rifx.online/https://readmedium.com/knowledge-table-multi-document-rag-extraction-memory-ec08450e858f)) and services, feel free to [chat with us here](https://proxy.rifx.online/https://calendly.com/whyhowai/intro-call-whyhow-ai).\n\nIf you‚Äôre thinking about, in the process of, or have already incorporated knowledge graphs in RAG for accuracy, memory and determinism, follow our newsletter at [WhyHow.AI](https://proxy.rifx.online/https://whyhow.ai/) or join our discussions about rules, determinism and knowledge graphs in RAG on our [Discord](https://proxy.rifx.online/https://discord.gg/9bWqrsxgHr).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/chatgpt-vision-turns-a-picture-into-1000-words-24858615fa28","frontmatter":{"title":"ChatGPT Vision Turns A Picture Into 1000 Words","meta_title":"ChatGPT Vision Turns A Picture Into 1000 Words","description":"And How You Can Turn Those Words Into Business","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*lS5aPVDrsCFFnBYz","categories":["Programming","Marketing","Generative AI"],"author":"Rifx.Online","tags":["automation","content","GPT","MAKE","photos"],"draft":false,"slug":"blog/chatgpt-vision-turns-a-picture-into-1000-words-24858615fa28"},"content":"\n\n\n\n\n### And How You Can Turn Those Words Into Business\n\nI‚Äôve had this idea for nearly a decade. It all started when I was building websites, and a lodge owner sent me a thumb drive packed with almost a thousand photos. And a box of 35mm photographs for me to scan.\n\n\n\n\n> These were **amazing shots** ‚Äî guests showing off their prized catches, stunning lake views, and guides leading outdoor adventures.\n\n\n> I knew that if we could get these photos online, they would create a tidal wave of **word\\-of\\-mouth** marketing for the lodge.\n\nBut here‚Äôs where it got complicated: each photo needed a unique description, proper tags, a blog post, and social media uploads. And there were almost a thousand of them!\n\nThe time and cost involved were staggering. Writing captions for hundreds of fish photos? It was enough to make anyone‚Äôs head spin. So, the great idea remained just that ‚Äî an idea.\n\nFast forward to today. Now, with the power of automation, I‚Äôve turned that idea into reality.\n\nI‚Äôve built a system that automates content creation for lodges, transforming old photos into engaging stories that can be published online effortlessly.\n\nIn this article, I‚Äôll walk you through the exact steps I took to build this system, and how you can do the same to save time and preserve the history of your lodge.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5GBorUl_PfqiLnSW6-Nsjg.png)\n\n\n\n\n\n\n\n\n## Step 1: Collect Your Lodge‚Äôs Unique Details\n\nThe first step in setting up this automation is gathering all the information and assets that make your lodge special. For me, this involved collecting the details that would make our content stand out. Think about the key experiences your lodge offers, like fishing trips, local adventures, or unique amenities. These details are what will make your content personal and engaging.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4QX4oGCYK5djc9EZuE9-EA.png)\n\nNext, gather old photos ‚Äî everything from past guest experiences to nature shots around the lodge.\n\nFor my experiment, I started with AI generated images, but then a follower of our page on Facebook sent in some pictures. I asked permission to feature them, and he loves it!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PuwLsJ2EuOYOLzXwUvn0cQ.png)\n\nIf you have a collection of photos like these, organize them into a Google Drive folder. This will make it easy to feed them into the automation system later. Along with the photos, create a Google Spreadsheet where you can log details about each image. Your spreadsheet should include:\n\n* The image URL (from your Google Drive folder)\n* Lodge details (such as fishing guides, special activities)\n* Any relevant stories or descriptions that can accompany the photo\n\nThis might seem like extra work upfront, but it‚Äôs critical for helping the automation create meaningful content later.\n\n\n## Step 2: Build the Automation Blueprint\n\nOnce you‚Äôve gathered all the assets, it‚Äôs time to set up the automation blueprint. I used an automation platform called [MAKE](https://www.make.com/en/register?pc=saleprice). If you‚Äôve never worked with automation before, don‚Äôt worry ‚Äî this is easier than it sounds.\n\n‚Ä¶ and you can **get all** my proven blueprints for [free](https://whop.com/ai-businessplans) in our 7 day trial.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ArzS71K2fJf4EfCg5y3BPQ.png)\n\nStart by duplicating an existing automation template, like one that posts weather updates to social media. I had a weather automation in place, so I used that as a base and stripped out the unnecessary parts. You want a clean slate to work with, so remove any modules that don‚Äôt apply to your lodge, such as weather updates or extra social media channels you won‚Äôt use.\n\nNow, it‚Äôs time to make the automation specific to your lodge.\n\n\n## Step 3: Customize the Automation for Your Lodge\n\nWith the basic structure in place, customize the automation by adding lodge\\-specific content. This is where the details you gathered in Step 1 come into play. Input your lodge description, add stories from past adventures, and incorporate local tips. Make sure to include keywords that will help your content get noticed online.\n\nNext, configure the automation to pull the photos from your Google Drive folder and match them with the corresponding descriptions from your spreadsheet. This ensures that the right image is paired with the right story.\n\nHere‚Äôs where the magic happens: I integrated GPT (a language model AI) into the automation. GPT analyzes each photo and generates unique content based on the details you provided.\n\nFor example, if the photo shows a guest catching a huge fish, GPT can create a post about that specific experience, including details about the fishing guide, the type of fish, and even tips for future visitors.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wySL0TxoNTFICejPsJOOcA.png)\n\n\n## Step 4: Automate Publishing to Social Media and Medium\n\nOnce the content is generated, it‚Äôs time to automate the publishing process. I connected our Medium account so that GPT\\-generated articles could be uploaded directly as drafts, ready for review. Medium is a great platform for long\\-form content like blog posts or detailed guest stories.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*56OzNVMIxw9sJKBn1jkriQ.png)\n\nFor shorter content, like social media posts, the automation links to our Facebook and Twitter accounts. The system is designed to create snippets from the longer articles, which are perfect for quick social media updates. You can also configure the automation to post automatically or schedule posts for specific times.\n\nThe beauty of this system is that once the content is approved, the automation handles everything from posting to scheduling. It‚Äôs a hands\\-off solution that keeps your online presence active without requiring constant attention.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rym300CevwmoA4_pvYybqQ.png)\n\n\n## Step 5: Testing and Fine\\-Tuning\n\nNow that the automation is in place, it‚Äôs important to test it before going live. I ran several test posts to ensure that everything worked as expected. The automation pulled the correct photos, generated engaging content, and posted it to Medium and social media without a hitch.\n\nDuring testing, I made small adjustments, such as tweaking titles or refining the GPT prompts to make sure the content aligned perfectly with our lodge‚Äôs tone and story.\n\nOnce everything was dialed in, I can create a steady stream of fresh content that keeps our audience engaged.\n\n\n## A Test Project in Action\n\nTo give you a practical example, take a look at the [iFish Canada Facebook page](https://facebook.com/ifishcanada).\n\nThis project is a demonstration of how the automation works in real life.\n\nThe system takes photos submitted by our followers, from their fishing trips in Canada, runs them through GPT, and generates unique posts that showcase the photo, the experiences of its author ‚Äî and for our example, the posts tie in the lore of our fictional lodge.\n\nThe content is rich, engaging, and best of all ‚Äî automated.\n\nWhat once seemed like an impossible task is now a reality, saving 100‚Äôs and 100‚Äôs of hours and allowing us to share the stories that make our fishing picture contributors feel recognized and appreciated.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Pe-hBjGCN1qbkjLl6cmTmQ.png)\n\n\n## Step 6: Monitor, Adjust, and Grow\n\nEven though the system may run automatically, it‚Äôs important to monitor the results and make adjustments over time.\n\nI will check which posts get the most engagement and tweak the GPT prompts to improve future content. This ongoing fine\\-tuning ensures that our online presence stays fresh and continues to attract new visitors.\n\nImagine how you can preserve the legacy of your lodge, sharing memories that might otherwise have been lost, and generating word\\-of\\-mouth marketing in a modern, powerful way.\n\n\n## A Decade in the Making ‚Äî Now You Can Join Me\n\nAfter years of dreaming about automating this process, it‚Äôs finally real. The system is up and running, and the results will speak for themselves.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*135_nP0nL6NrT_O7JxIk4g.png)\n\nNow, I want to invite you to experience this for your lodge or resort. If you‚Äôve ever felt overwhelmed by the time or cost of marketing, or if you‚Äôve struggled to keep up with the constant demand for new content, [this automation system](https://whop.com/ai-businessplans) could be the solution you‚Äôve been looking for.\n\nVisit [iFish Canada](https://facebook.com/ifishcanada) to see the system in action, and if you‚Äôd like to get started with automating your own content, feel free to reach out.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IJ-R1362_IWUrZ-3KyG8mw.png)\n\nI‚Äôd love to help you unlock the power of automation to grow your lodge, share your story, and attract new guests ‚Äî all while saving you time and effort.\n\n‚´∑\n\n\n### I Value Your Comments\n\nI reply to all comments and **as my thank you** I‚Äôll also follow, clap, highlight and comment where it fits on your content. So leave your thoughts, questions, or success stories too! I love to read them!\n\n*Connect* on [YouTube](https://www.youtube.com/channel/UCphdP_nguu6MT3U5tsJNMsQ), [X (twitter)](https://x.com/Aibusinessplans/status/1803488217079095460), and [Linkedin](https://www.linkedin.com/company/ai-businessplans/) ‚Äî Try our [Community](https://whop.com/ai-businessplans).\n\nBe safe and make small steps forward every day.\n\nDoug\n\n\n## Read Next \\-\n\nüõÜ *Investment Disclaimer:* You should not invest money into a paid tool until you have maximized the benefits of the free features. *Nothing in our training products is a promise or guarantee of earnings.*üëà\n\n‚òÑ This article contains referral links for some of my absolute favorite AI business tools for content creators and GenAI enthusiasts.\n\nIf you purchase one of my favorite software and AI tools, I will receive a small commission at no additional charge to you.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/choosing-between-llm-agent-frameworks-69019493b259","frontmatter":{"title":"Choosing Between LLM Agent Frameworks","meta_title":"Choosing Between LLM Agent Frameworks","description":"The tradeoffs between building bespoke code-based agents and the major agent frameworks.","date":"2024-10-29T12:57:34.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*jRMs19HqSCazE5dY","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["agents","frameworks","LangGraph","LlamaIndex","Workflows"],"draft":false,"slug":"blog/choosing-between-llm-agent-frameworks-69019493b259"},"content":"\n### The tradeoffs between building bespoke code\\-based agents and the major agent frameworks.\n\n\n\n\nAgents are having a moment. With multiple new frameworks and fresh [investment](https://foundationcapital.com/goodbye-aiops-welcome-agentsres-the-next-100b-opportunity/) in the space, modern AI agents are overcoming [shaky origins](https://arxiv.org/html/2405.13966v1) to rapidly supplant RAG as an implementation priority. So will 2024 finally be the year that autonomous AI systems that can take over writing our emails, booking flights, talking to our data, or seemingly any other task?\n\nMaybe, but much work remains to get to that point. Any developer building an agent must not only choose foundations ‚Äî which model, use case, and architecture to use ‚Äî but also which framework to leverage. Do you go with the long\\-standing LangGraph, or the newer entrant LlamaIndex Workflows? Or do you go the traditional route and code the whole thing yourself?\n\nThis post aims to make that choice a bit easier. Over the past few weeks, I built the same agent in major frameworks to examine some of the strengths and weaknesses of each at a technical level. All of the code for each agent is available in [this repo](https://github.com/Arize-ai/phoenix/tree/main/examples/agent_framework_comparison).\n\n### Background on the Agent Used for Testing\n\nThe agent used for testing includes function calling, multiple tools or skills, connections to outside resources, and shared state or memory.\n\nThe agent has the following capabilities:\n\n1. Answering questions from a knowledge base\n2. Talking to data: answering questions about telemetry data of an LLM application\n3. Analyzing data: analyzing higher\\-level trends and patterns in retrieved telemetry data\n\nIn order to accomplish these, the agent has three starting skills: RAG with product documentation, SQL generation on a trace database, and data analysis. A simple gradio\\-powered interface is used for the agent UI, with the agent itself structured as a chatbot.\n\n## Code\\-Based Agent (No Framework)\n\nThe first option you have when developing an agent is to skip the frameworks entirely and build the agent fully yourself. When embarking on this project, this was the approach I started with.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pw9-0lB5JMlVcPqo)\n\n### Pure Code Architecture\n\nThe code\\-based agent below is made up of an OpenAI\\-powered router that uses function calling to select the right skill to use. After that skill completes, it returns back to the router to either call another skill or respond to the user.\n\nThe agent keeps an ongoing list of messages and responses that is passed fully into the router on each call to preserve context through cycles.\n\n```python\ndef router(messages):\n    if not any(\n        isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n    ):\n        system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n        messages.append(system_prompt)\n\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=messages,\n        tools=skill_map.get_combined_function_description_for_openai(),\n    )\n\n    messages.append(response.choices[0].message)\n    tool_calls = response.choices[0].message.tool_calls\n    if tool_calls:\n        handle_tool_calls(tool_calls, messages)\n        return router(messages)\n    else:\n        return response.choices[0].message.content\n```\n\nThe skills themselves are defined in their own classes (e.g. GenerateSQLQuery) that are collectively held in a SkillMap. The router itself only interacts with the SkillMap, which it uses to load skill names, descriptions, and callable functions. This approach means that adding a new skill to the agent is as simple as writing that skill as its own class, then adding it to the list of skills in the SkillMap. The idea here is to make it easy to add new skills without disturbing the router code.\n\n```python\nclass SkillMap:\n    def __init__(self):\n        skills = [AnalyzeData(), GenerateSQLQuery()]\n\n        self.skill_map = {}\n        for skill in skills:\n            self.skill_map[skill.get_function_name()] = (\n                skill.get_function_dict(),\n                skill.get_function_callable(),\n            )\n\n    def get_function_callable_by_name(self, skill_name) -> Callable:\n        return self.skill_map[skill_name][1]\n\n    def get_combined_function_description_for_openai(self):\n        combined_dict = []\n        for _, (function_dict, _) in self.skill_map.items():\n            combined_dict.append(function_dict)\n        return combined_dict\n\n    def get_function_list(self):\n        return list(self.skill_map.keys())\n\n    def get_list_of_function_callables(self):\n        return [skill[1] for skill in self.skill_map.values()]\n\n    def get_function_description_by_name(self, skill_name):\n        return str(self.skill_map[skill_name][0][\"function\"])\n```\n\nOverall, this approach is fairly straightforward to implement but comes with a few challenges.\n\n### Challenges with Pure Code Agents\n\nThe first difficulty lies in structuring the router system prompt. Often, the router in the example above insisted on generating SQL itself instead of delegating that to the right skill. If you‚Äôve ever tried to get an LLM *not* to do something, you know how frustrating that experience can be; finding a working prompt took many rounds of debugging. Accounting for the different output formats from each step was also tricky. Since I opted not to use structured outputs, I had to be ready for multiple different formats from each of the LLM calls in my router and skills.\n\n### Benefits of a Pure Code Agent\n\nA code\\-based approach provides a good baseline and starting point, offering a great way to learn how agents work without relying on canned agent tutorials from prevailing frameworks. Although convincing the LLM to behave can be challenging, the code structure itself is simple enough to use and might make sense for certain use cases (more in the analysis section below).\n\n## LangGraph\n\nLangGraph is one of the longest\\-standing agent frameworks, first releasing in January 2024\\. The framework is built to address the acyclic nature of existing pipelines and chains by adopting a Pregel graph structure instead. LangGraph makes it easier to define loops in your agent by adding the concepts of nodes, edges, and conditional edges to traverse a graph. LangGraph is built on top of LangChain, and uses the objects and types from that framework.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fYgHiGwLhSUSrFv9)\n\n### LangGraph Architecture\n\nThe LangGraph agent looks similar to the code\\-based agent on paper, but the code behind it is drastically different. LangGraph still uses a ‚Äúrouter‚Äù technically, in that it calls OpenAI with functions and uses the response to continue to a new step. However the way the program moves between skills is controlled completely differently.\n\n```python\ntools = [generate_and_run_sql_query, data_analyzer]\nmodel = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(tools)\n\ndef create_agent_graph():\n    workflow = StateGraph(MessagesState)\n\n    tool_node = ToolNode(tools)\n    workflow.add_node(\"agent\", call_model)\n    workflow.add_node(\"tools\", tool_node)\n\n    workflow.add_edge(START, \"agent\")\n    workflow.add_conditional_edges(\n        \"agent\",\n        should_continue,\n    )\n    workflow.add_edge(\"tools\", \"agent\")\n\n    checkpointer = MemorySaver()\n    app = workflow.compile(checkpointer=checkpointer)\n    return app\n```\n\nThe graph defined here has a node for the initial OpenAI call, called ‚Äúagent‚Äù above, and one for the tool handling step, called ‚Äútools.‚Äù LangGraph has a built\\-in object called ToolNode that takes a list of callable tools and triggers them based on a ChatMessage response, before returning to the ‚Äúagent‚Äù node again.\n\n```python\ndef should_continue(state: MessagesState):\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return END\n\ndef call_model(state: MessagesState):\n    messages = state[\"messages\"]\n    response = model.invoke(messages)\n    return {\"messages\": [response]}\n```\n\nAfter each call of the ‚Äúagent‚Äù node (put another way: the router in the code\\-based agent), the should\\_continue edge decides whether to return the response to the user or pass on to the ToolNode to handle tool calls.\n\nThroughout each node, the ‚Äústate‚Äù stores the list of messages and responses from OpenAI, similar to the code\\-based agent‚Äôs approach.\n\n### Challenges with LangGraph\n\nMost of the difficulties with LangGraph in the example stem from the need to use Langchain objects for things to flow nicely.\n\n**Challenge \\#1: Function Call Validation**\n\nIn order to use the ToolNode object, I had to refactor most of my existing Skill code. The ToolNode takes a list of callable functions, which originally made me think I could use my existing functions, however things broke down due to my function parameters.\n\nThe skills were defined as classes with a callable member function, meaning they had ‚Äúself‚Äù as their first parameter. GPT\\-4o was smart enough to not include the ‚Äúself‚Äù parameter in the generated function call, however LangGraph read this as a validation error due to a missing parameter.\n\nThis took hours to figure out, because the error message instead marked the third parameter in the function (‚Äúargs‚Äù on the data analysis skill) as the missing parameter:\n\n```python\npydantic.v1.error_wrappers.ValidationError: 1 validation error for data_analysis_toolSchema\nargs field required (type=value_error.missing)\n```\n\nIt is worth mentioning that the error message originated from Pydantic, not from LangGraph.\n\nI eventually bit the bullet and redefined my skills as basic methods with Langchain‚Äôs @tool decorator, and was able to get things working.\n\n```python\n@tool\ndef generate_and_run_sql_query(query: str):\n    \"\"\"Generates and runs an SQL query based on the prompt.\n\n    Args:\n        query (str): A string containing the original user prompt.\n\n    Returns:\n        str: The result of the SQL query.\n    \"\"\"\n```\n\n**Challenge \\#2: Debugging**\n\nAs mentioned, debugging in a framework is difficult. This primarily comes down to confusing error messages and abstracted concepts that make it harder to view variables.\n\nThe abstracted concepts primarily show up when trying to debug the messages being sent around the agent. LangGraph stores these messages in state\\[‚Äúmessages‚Äù]. Some nodes within the graph pull from these messages automatically, which can make it difficult to understand the value of messages when they are accessed by the node.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*KuCg0WGHSklOKe6t)\n\n### LangGraph Benefits\n\nOne of the main benefits of LangGraph is that it‚Äôs easy to work with. The graph structure code is clean and accessible. Especially if you have complex node logic, having a single view of the graph makes it easier to understand how the agent is connected together. LangGraph also makes it straightforward to convert an existing application built in LangChain.\n\n### Takeaway\n\nIf you use everything in the framework, LangGraph works cleanly; if you step outside of it, prepare for some debugging headaches.\n\n## LlamaIndex Workflows\n\nWorkflows is a newer entrant into the agent framework space, premiering earlier this summer. Like LangGraph, it aims to make looping agents easier to build. Workflows also has a particular focus on running asynchronously.\n\nSome elements of Workflows seem to be in direct response to LangGraph, specifically its use of events instead of edges and conditional edges. Workflows use steps (analogous to nodes in LangGraph) to house logic, and emitted and received events to move between steps.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*22WuFVBWctdeiCSL)\n\nThe structure above looks similar to the LangGraph structure, save for one addition. I added a setup step to the Workflow to prepare the agent context, more on this below. Despite the similar structure, there is very different code powering it.\n\n### Workflows Architecture\n\nThe code below defines the Workflow structure. Similar to LangGraph, this is where I prepared the state and attached the skills to the LLM object.\n\n```python\nclass AgentFlow(Workflow):\n    def __init__(self, llm, timeout=300):\n        super().__init__(timeout=timeout)\n        self.llm = llm\n        self.memory = ChatMemoryBuffer(token_limit=1000).from_defaults(llm=llm)\n        self.tools = []\n        for func in skill_map.get_function_list():\n            self.tools.append(\n                FunctionTool(\n                    skill_map.get_function_callable_by_name(func),\n                    metadata=ToolMetadata(\n                        name=func, description=skill_map.get_function_description_by_name(func)\n                    ),\n                )\n            )\n\n    @step\n    async def prepare_agent(self, ev: StartEvent) -> RouterInputEvent:\n        user_input = ev.input\n        user_msg = ChatMessage(role=\"user\", content=user_input)\n        self.memory.put(user_msg)\n\n        chat_history = self.memory.get()\n        return RouterInputEvent(input=chat_history)\n```\n\nThis is also where I define an extra step, ‚Äúprepare\\_agent‚Äù. This step creates a ChatMessage from the user input and adds it to the workflow memory. Splitting this out as a separate step means that we do return to it as the agent loops through steps, which avoids repeatedly adding the user message to the memory.\n\nIn the LangGraph case, I accomplished the same thing with a run\\_agent method that lived outside the graph. This change is mostly stylistic, however it‚Äôs cleaner in my opinion to house this logic with the Workflow and graph as we‚Äôve done here.\n\nWith the Workflow set up, I then defined the routing code:\n\n```python\n@step\nasync def router(self, ev: RouterInputEvent) -> ToolCallEvent | StopEvent:\n    messages = ev.input\n\n    if not any(\n        isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n    ):\n        system_prompt = ChatMessage(role=\"system\", content=SYSTEM_PROMPT)\n        messages.insert(0, system_prompt)\n\n    with using_prompt_template(template=SYSTEM_PROMPT, version=\"v0.1\"):\n        response = await self.llm.achat_with_tools(\n            model=\"gpt-4o\",\n            messages=messages,\n            tools=self.tools,\n        )\n\n    self.memory.put(response.message)\n\n    tool_calls = self.llm.get_tool_calls_from_response(response, error_on_no_tool_call=False)\n    if tool_calls:\n        return ToolCallEvent(tool_calls=tool_calls)\n    else:\n        return StopEvent(result=response.message.content)\n```\n\nAnd the tool call handling code:\n\n```python\n@step\nasync def tool_call_handler(self, ev: ToolCallEvent) -> RouterInputEvent:\n    tool_calls = ev.tool_calls\n\n    for tool_call in tool_calls:\n        function_name = tool_call.tool_name\n        arguments = tool_call.tool_kwargs\n        if \"input\" in arguments:\n            arguments[\"prompt\"] = arguments.pop(\"input\")\n\n        try:\n            function_callable = skill_map.get_function_callable_by_name(function_name)\n        except KeyError:\n            function_result = \"Error: Unknown function call\"\n\n        function_result = function_callable(arguments)\n        message = ChatMessage(\n            role=\"tool\",\n            content=function_result,\n            additional_kwargs={\"tool_call_id\": tool_call.tool_id},\n        )\n\n        self.memory.put(message)\n\n    return RouterInputEvent(input=self.memory.get())\n```\n\nBoth of these look more similar to the code\\-based agent than the LangGraph agent. This is mainly because Workflows keeps the conditional routing logic in the steps as opposed to in conditional edges ‚Äî lines 18‚Äì24 were a conditional edge in LangGraph, whereas now they are just part of the routing step ‚Äî and the fact that LangGraph has a ToolNode object that does just about everything in the tool\\_call\\_handler method automatically.\n\nMoving past the routing step, one thing I was very happy to see is that I could use my SkillMap and existing skills from my code\\-based agent with Workflows. These required no changes to work with Workflows, which made my life much easier.\n\n### Challenges with Workflows\n\n**Challenge \\#1: Sync vs Async**\n\nWhile asynchronous execution is preferable for a live agent, debugging a synchronous agent is much easier. Workflows is designed to work asynchronously, and trying to force synchronous execution was very difficult.\n\nI initially thought I would just be able to remove the ‚Äúasync‚Äù method designations and switch from ‚Äúachat\\_with\\_tools‚Äù to ‚Äúchat\\_with\\_tools‚Äù. However, since the underlying methods within the Workflow class were also marked as asynchronous, it was necessary to redefine those in order to run synchronously. I ended up sticking to an asynchronous approach, but this didn‚Äôt make debugging more difficult.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*78Hzqkiv9cI7W4UA)\n\n**Challenge \\#2: Pydantic Validation Errors**\n\nIn a repeat of the woes with LangGraph, similar problems emerged around confusing Pydantic validation errors on skills. Fortunately, these were easier to address this time since Workflows was able to handle member functions just fine. I ultimately just ended up having to be more prescriptive in creating LlamaIndex FunctionTool objects for my skills:\n\n```python\nfor func in skill_map.get_function_list(): \n            self.tools.append(FunctionTool(\n                skill_map.get_function_callable_by_name(func), \n                metadata=ToolMetadata(name=func, description=skill_map.get_function_description_by_name(func))))\n```\n\n*Excerpt from AgentFlow.\\_\\_init\\_\\_ that builds FunctionTools*\n\n### Benefits of Workflows\n\nI had a much easier time building the Workflows agent than I did the LangGraph agent, mainly because Workflows still required me to write routing logic and tool handling code myself instead of providing built\\-in functions. This also meant that my Workflow agent looked extremely similar to my code\\-based agent.\n\nThe biggest difference came in the use of events. I used two custom events to move between steps in my agent:\n\n```python\nclass ToolCallEvent(Event):\n    tool_calls: list[ToolSelection]\n\nclass RouterInputEvent(Event):\n    input: list[ChatMessage]\n```\n\nThe emitter\\-receiver, event\\-based architecture took the place of directly calling some of the methods in my agent, like the tool call handler.\n\nIf you have more complex systems with multiple steps that are triggering asynchronously and might emit multiple events, this architecture becomes very helpful to manage that cleanly.\n\nOther benefits of Workflows include the fact that it is very lightweight and doesn‚Äôt force much structure on you (aside from the use of certain LlamaIndex objects) and that its event\\-based architecture provides a helpful alternative to direct function calling ‚Äî especially for complex, asynchronous applications.\n\n## Comparing Frameworks\n\nLooking across the three approaches, each one has its benefits.\n\nThe no framework approach is the simplest to implement. Because any abstractions are defined by the developer (i.e. SkillMap object in the above example), keeping various types and objects straight is easy. The readability and accessibility of the code entirely comes down to the individual developer however, and it‚Äôs easy to see how increasingly complex agents could get messy without some enforced structure.\n\nLangGraph provides quite a bit of structure, which makes the agent very clearly defined. If a broader team is collaborating on an agent, this structure would provide a helpful way of enforcing an architecture. LangGraph also might provide a good starting point with agents for those not as familiar with the structure. There is a tradeoff, however ‚Äî since LangGraph does quite a bit for you, it can lead to headaches if you don‚Äôt fully buy into the framework; the code may be very clean, but you may pay for it with more debugging.\n\nWorkflows falls somewhere in the middle. The event\\-based architecture might be extremely helpful for some projects, and the fact that less is required in terms of using of LlamaIndex types provides greater flexibility for those not be fully using the framework across their application.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*PITmiVGuG8QuDVX6)\n\nUltimately, the core question may just come down to ‚Äúare you already using LlamaIndex or LangChain to orchestrate your application?‚Äù LangGraph and Workflows are both so entwined with their respective underlying frameworks that the additional benefits of each agent\\-specific framework might not cause you to switch on merit alone.\n\nThe pure code approach will likely always be an attractive option. If you have the rigor to document and enforce any abstractions created, then ensuring nothing in an external framework slows you down is easy.\n\n## Key Questions To Help In Choosing An Agent Framework\n\nOf course, ‚Äúit depends‚Äù is never a satisfying answer. These three questions should help you decide which framework to use in your next agent project.\n\n***Are you already using LlamaIndex or LangChain for significant pieces of your project?***\n\nIf yes, explore that option first.\n\n***Are you familiar with common agent structures, or do you want something telling you how you should structure your agent?***\n\nIf you fall into the latter group, try Workflows. If you *really* fall into the latter group, try LangGraph.\n\n***Has your agent been built before?***\n\nOne of the framework benefits is that there are many tutorials and examples built with each. There are far fewer examples of pure code agents to build from.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wF9aSF1db1yaniqO)\n\n## Conclusion\n\nPicking an agent framework is just one choice among many that will impact outcomes in production for generative AI systems. As always, it pays to have robust guardrails and [LLM tracing](https://docs.arize.com/phoenix/tracing/llm-traces) in place ‚Äî and to be agile as new agent frameworks, research, and models upend established techniques.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/claude-3-5-haiku-anthropics-speed-demon-gets-a-brain-boost-82f2f0999d4f","frontmatter":{"title":"Claude 3.5 Haiku: Anthropic‚Äôs Speed Demon Gets a Brain Boost","meta_title":"Claude 3.5 Haiku: Anthropic‚Äôs Speed Demon Gets a Brain Boost","description":"Claude 3.5 Haiku, Anthropic's latest AI model, combines speed and intelligence, outperforming its predecessor, Claude 3 Opus, on various benchmarks. It excels in coding tasks, achieving a notable 40.6% on the SWE-bench Verified test. While it remains text-only for now, plans for image analysis are in the works. The model is accessible via multiple platforms but comes at a premium cost, four times that of its predecessor, though cost-saving options like prompt caching exist. Its applications span software development, chatbots, data processing, education, and more, marking a significant advancement in AI capabilities.","date":"2024-11-13T01:32:04.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hLedIfhYJhS_ejPDwOQPIw.png","categories":["Programming","Machine Learning","Chatbots"],"author":"Rifx.Online","tags":["Claude","Haiku","coding","SWE-bench","benchmarks"],"draft":false,"slug":"blog/claude-3-5-haiku-anthropics-speed-demon-gets-a-brain-boost-82f2f0999d4f"},"content":"\n\n\n\n\n\nIn the relentless race of AI advancement, Anthropic has just dropped a new contender into the ring. Meet Claude 3\\.5 Haiku, the latest iteration of their fastest AI model. It‚Äôs like they‚Äôve taken their sprinter and sent them to brain camp. The result? A model that‚Äôs not just quick on its feet but can now outsmart its beefier siblings in certain intellectual arenas. Let‚Äôs dive into what makes this new kid on the block tick.\n\n\n## The Need for Speed (and Smarts)\n\nAnthropic‚Äôs previous Haiku model was already the Usain Bolt of their AI lineup. Now, they‚Äôve somehow managed to cram more brainpower into this speed demon without sacrificing its swiftness. It‚Äôs like watching a cheetah solve a Rubik‚Äôs cube while sprinting.\n\n\n## Benchmarking Brilliance\n\nClaude 3\\.5 Haiku isn‚Äôt just fast; it‚Äôs scary smart. It‚Äôs outperforming Claude 3 Opus ‚Äî Anthropic‚Äôs previous heavyweight champ ‚Äî on various intelligence benchmarks. This isn‚Äôt just a minor upgrade; it‚Äôs a leap that has the AI community sitting up and taking notice.\n\n\n## Coding Prowess\n\nIf you‚Äôre a developer, listen up. This model is flexing hard in the coding arena, scoring a jaw\\-dropping 40\\.6% on the SWE\\-bench Verified test. That‚Äôs not just impressive; it‚Äôs the kind of performance that makes human coders nervously eye their job security.\n\n\n## Under the Hood\n\nLet‚Äôs pop the hood and see what‚Äôs powering this AI hot rod:\n\n* **Availability**: You can take it for a spin through Anthropic‚Äôs API, Amazon Bedrock, or Google Cloud‚Äôs Vertex AI. It‚Äôs like the AI equivalent of being available on all major streaming platforms.\n* **Input**: Currently, it‚Äôs text\\-only. No image analysis yet, but that‚Äôs coming. It‚Äôs like having a genius pen pal who can‚Äôt look at your vacation photos.\n* **Knowledge Cutoff**: July 2024\\. So it knows about that embarrassing thing you did last summer, but not about next year‚Äôs memes.\n* **Output Length**: Improved from its predecessor. It can now write longer essays to procrastinate on your behalf.\n\n\n## Show Me the Money\n\nNow, here‚Äôs where things get interesting. Anthropic has decided to charge a premium for this upgraded model:\n\n* $1 per million input tokens\n* $5 per million output tokens\n\nThat‚Äôs a fourfold increase from the previous version. It‚Äôs like they‚Äôve taken their Honda Civic, turned it into a Tesla, and adjusted the price accordingly.\n\nBut fear not, penny\\-pinchers! There are ways to save:\n\n* Prompt caching can save you up to 90%. It‚Äôs like extreme couponing for AI.\n* Batch processing with the Message Batches API can cut costs by up to 50%. Bulk buying, but for computation.\n\n\n## What Can This Thing Do?\n\nClaude 3\\.5 Haiku isn‚Äôt just a party trick. It‚Äôs got some serious real\\-world applications:\n\n* **Software Development**: It‚Äôs like having a coding buddy who never sleeps and doesn‚Äôt steal your snacks.\n* **Chatbots**: Customer service reps who don‚Äôt need coffee breaks or HR interventions.\n* **Data Processing**: It can crunch numbers faster than you can say ‚Äúbig data.‚Äù\n* **Education**: A tutor that‚Äôs always on call and never loses patience.\n* **Personalization**: It remembers your preferences better than your significant other.\n* **Specialized Tasks**: The Swiss Army knife of AI sub\\-agents.\n* **Content Moderation**: Keeping the internet clean, one post at a time.\n\n\n## The Trade\\-Offs\n\nNow, it‚Äôs not all sunshine and rainbows. There are a few catches:\n\n* No image analysis yet. So it can‚Äôt tell you if that dress makes you look fat.\n* The price hike might make some users stick with the older, cheaper version. It‚Äôs the AI equivalent of people still using Windows 7\\.\n\n\n## The Bottom Line\n\nClaude 3\\.5 Haiku is a significant leap forward in the world of AI. It‚Äôs faster than a speeding bullet, more powerful than a locomotive, and able to leap tall buildings in a single bound. Okay, maybe not that last part, but you get the idea.\n\nFor developers and businesses looking to leverage AI for complex tasks that require both brains and brawn (or in this case, speed), Claude 3\\.5 Haiku is a compelling option. It‚Äôs not just an upgrade; it‚Äôs a reimagining of what‚Äôs possible at the intersection of speed and intelligence in AI.\n\nThe question now is: how will competitors respond? And more importantly, how long until we see Claude 4\\.0: The Limerick Edition?\n\n\n## FAQ Section\n\n**Q: Can Claude 3\\.5 Haiku analyze images?**A: Not yet, but Anthropic plans to add this feature in the future. For now, it‚Äôs text\\-only.\n\n**Q: How much more expensive is Claude 3\\.5 Haiku compared to its predecessor?**A: It‚Äôs four times more expensive, but there are ways to reduce costs through prompt caching and batch processing.\n\n**Q: What‚Äôs the most impressive feature of Claude 3\\.5 Haiku?**A: Its ability to outperform larger models like Claude 3 Opus on various intelligence benchmarks while maintaining high speed.\n\n**Q: Can I use Claude 3\\.5 Haiku for software development?**A: Absolutely. It excels at coding tasks and can provide fast, accurate code suggestions and completions.\n\n**Q: Is Claude 3\\.5 Haiku available to the public?**A: Yes, it‚Äôs accessible through Anthropic‚Äôs API, Amazon Bedrock, and Google Cloud‚Äôs Vertex AI.\n\n\\#Claude35Haiku \\#AnthropicAI \\#AIInnovation \\#MachineLearning \\#AIForDevelopers \\#FutureOfAI \\#AIPerformance \\#TechInnovation\n\n‚ÄúClaude 3\\.5 Haiku performance benchmarks‚Äù, ‚ÄúAI model pricing comparison‚Äù, ‚ÄúFast AI models for software development‚Äù, ‚ÄúAnthropic AI model capabilities‚Äù, ‚ÄúCost\\-effective AI implementation strategies‚Äù\n\n\n"},{"lang":"en","group":"blog","slug":"blog/claude-3-5-sonnet-new-pioneering-the-future-of-ai-with-computer-control-capabilities-37a6ff9f9033","frontmatter":{"title":"Claude 3.5 Sonnet (New): Pioneering the Future of AI with Computer Control Capabilities","meta_title":"Claude 3.5 Sonnet (New): Pioneering the Future of AI with Computer Control Capabilities","description":"Anthropic has unveiled its latest AI model, Claude 3.5 Sonnet, on October 22, 2024. This release introduces revolutionary computer control‚Ä¶","date":"2024-10-27T13:57:00.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*n0NkOFbhUm7_fllJ","categories":["Programming","Technology","Generative AI"],"author":"Rifx.Online","tags":["Claude","Sonnet","automation","benchmarks","safety"],"draft":false,"slug":"blog/claude-3-5-sonnet-new-pioneering-the-future-of-ai-with-computer-control-capabilities-37a6ff9f9033"},"content":"\n\n\n\n\n\nAnthropic has unveiled its latest AI model, Claude 3.5 Sonnet, on October 22, 2024. This release introduces revolutionary computer control capabilities and substantial improvements across various benchmarks, setting new standards in the AI industry.\n\n\n## Revolutionary Computer Control: A New Frontier\n\nThe standout feature of Claude 3.5 Sonnet is its ability to interact with computers just like humans do. This groundbreaking capability allows the AI to:\n\n* Navigate desktop interfaces using mouse and keyboard inputs\n* Interact with various applications and web browsers\n* Execute complex multi-step tasks\n* Perform file management operations\n* Automate repetitive workflows\n\nThis computer control feature, currently in public beta, represents a paradigm shift in how AI systems can interact with digital interfaces. While still in its experimental phase, early testing shows promising results, with Claude 3.5 Sonnet scoring 14.9% on the OSWorld benchmark for screenshot-only tasks ‚Äî significantly higher than the next-best system‚Äôs 7.8%.\n\n\n## Benchmark-Breaking Performance\n\nThe upgraded model demonstrates remarkable improvements across various metrics:\n\n\n## Coding and Technical Tasks\n\n* 49% performance on SWE-bench Verified (up from 33.4%)\n* 93.7% score on HumanEval coding tasks\n* Superior performance in software engineering compared to specialized coding systems\n\n\n## Academic and Reasoning Capabilities\n\n* 65% on graduate-level reasoning (GPQA-Diamond)\n* 78% on undergraduate-level knowledge (MMLU Pro)\n* 78.3% on mathematical problem-solving (MATH)\n\n\n## Business Applications\n\n* 69.2% on retail domain tasks (TAU-bench)\n* 46% on airline domain tasks\n* 90.8% accuracy on chart analysis\n* 94.2% accuracy on document Q&A\n\n\n## Enterprise Integration and Availability\n\nClaude 3.5 Sonnet is accessible through multiple platforms:\n\n* Anthropic API\n* Amazon Bedrock\n* Google Cloud‚Äôs Vertex AI\n\nMajor companies including Asana, Canva, DoorDash, and Replit have already begun implementing Claude 3.5 Sonnet‚Äôs capabilities in their workflows, particularly leveraging its computer control features for complex automation tasks.\n\n\n## Practical Applications\n\n\n## Software Development\n\n* Automated code testing and debugging\n* Intelligent IDE interactions\n* Code review and optimization\n* Documentation generation\n\n\n## Customer Support\n\n* Advanced chatbot capabilities\n* Visual data interpretation\n* Automated ticket resolution\n* Process automation\n\n\n## Business Operations\n\n* Document processing and analysis\n* Data extraction from visual sources\n* Workflow automation\n* Complex problem-solving\n\n\n## Safety and Responsibility\n\nAnthropic has implemented robust safety measures for the computer control feature:\n\n* New classifiers to identify potential misuse\n* Proactive monitoring systems\n* Restricted access to sensitive operations\n* Regular safety assessments\n\n\n## Looking Ahead\n\nWhile Claude 3.5 Sonnet represents a significant advancement in AI capabilities, it‚Äôs important to note that some features, particularly computer control, are still in their early stages. Certain actions like scrolling, dragging, and zooming present challenges, and Anthropic encourages developers to begin with low-risk tasks while exploring these new capabilities.\n\nThe release of Claude 3.5 Sonnet marks a pivotal moment in AI development, combining advanced reasoning capabilities with practical computer control features. As the technology continues to evolve, we can expect to see even more innovative applications and improvements in how AI systems interact with our digital world.\n\n*This article is based on official announcements and documentation from Anthropic, AWS, and various technology partners. For the most up-to-date information, please refer to Anthropic‚Äôs official documentation.*\n\n\n"},{"lang":"en","group":"blog","slug":"blog/claude-3-5-sonnet-v-s-gpt-4o-which-one-is-better-3b3675195bf9","frontmatter":{"title":"Claude 3.5 Sonnet V/S GPT-4O: Which one is better","meta_title":"Claude 3.5 Sonnet V/S GPT-4O: Which one is better","description":"In November 2022, OpenAI launched ChatGPT, a model that has revolutionized how we search and interact with information. Next year, in‚Ä¶","date":"2024-10-27T13:59:09.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4MXLuSFfGwFkWWn0","categories":["Generative AI","Machine Learning","Natural Language Processing"],"author":"Rifx.Online","tags":["GPT-4o","Claude","multimodal","reasoning","code-generation"],"draft":false,"slug":"blog/claude-3-5-sonnet-v-s-gpt-4o-which-one-is-better-3b3675195bf9"},"content":"\n\n\n\nIn November 2022, OpenAI launched ChatGPT, a model that has revolutionized how we search and interact with information. Next year, in March, an American startup,‚Äù Anthropic,‚Äù founded by ex-OpenAI employees, launched their own AI model, ‚ÄúClaude.‚Äù Since the launch, both AI companies have been competing to bring the best to customers regarding features and experience through their AI models. Recently, OpenAI launched ‚ÄúGPT-4o,‚Äù a spectacular model that handles file, voice, and video data amazingly. Similarly, Claude launched the ‚ÄúClaude 3.5 Sonnet,‚Äù which is the most advanced AI model, as they claimed, and can handle complex tasks. In this article, we will determine which is better, between Claude 3.5 Sonnet and GPT-4o, and compare its features and output with the same input to check which is better for you.\n\n\n## Capabilities and Features\n\n\n### GPT-4o\n\n\n\nGPT-4o is the latest LLM launched by OpenAI. The ‚Äúo‚Äù stands for omni, which means ‚Äúevery‚Äù in Latin. This model can analyze voice, images, videos, and files as input and respond accordingly. It can take voice input and give the output in different characters‚Äô voices, including tones, emotions, etc. The whole process is as low as a human conversation, with an average of 0.32 seconds compared to other voice models, which is 2.8 seconds. It also allows users to generate written content such as articles, blogs, product descriptions, code in different programming languages, data analysis, charts, etc. In addition, GPT-4o can also analyze images and videos, which makes the model act as a language translator, personal assistant, virtual teacher, or shopping assistant. It can also be used in medicine, engineering, the military, etc. To use this feature, GPT-4o can use the user‚Äôs camera to get a real-time view and respond accordingly in the voice mode. It can also access your computer screen and describe what is shown on the screen, users can ask questions related to the stuff displayed on the screen.\n\n*For example, users can enable the model on the screen, open the VS code, and prompt the model to act as a coding assistant to get answers to the coding problems. Alternatively, you can enable the camera to act as a fitness trainer whether you are doing it correctly or not.*\n\nThe model has unique features, such as data analysis, code interpreter, and real-time web browsing, making it different from its competitors. The model also has a plethora of GPTs, which is a tailored version of ChatGPT.\n\n\n### Claude 3.5 Sonnet\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*BSMcOpvWZ5lUm4Tl)\n\nClaude 3.5 Sonnet is the AI chatbot launched by Anthropic. It is the third generation of the family of Claude AI model series. This model has stood at a high bae and outperformed many AI models on various evaluations, keeping the hallucinations and wrong information away. While it doesn‚Äôt support voice and video features like GPT-4o, it can also perform all the basic tasks, such as text generation and code generation in different programming languages, brainstorming ideas, etc. According to the report by Anthropic, Claude 3.5 Sonnet is one of the best computer vision models in the market, which can be used to analyze charts and graphs, transcribe texts from images, and many more. Claude is powered by an advanced feature, ‚ÄúArtifacts,‚Äù a special popup window along the conversation, allowing the users to check the code snippets, text documents, or website designs and allow them to edit the output in real-time.\n\n*For example, users can use computer vision and artifacts in their workflows. Users can make essential prototyping of a website‚Äôs design on paper, attach the file with Claude 3.5 Sonnet, and prompt it to design a website based on the prototype. The generated code and the website design appear in the artifacts. Users can edit the code and the design according to their requirements. Users can also publish their projects live on the Internet.*\n\n\n## Head-to-Head Comparison\n\nIn this section, we will compare the two LLMs based on factors such as complex reasoning and code generation, check out their capabilities in handling complex tasks, and see which model is best.\n\n* **Graduate Level Reasoning(GPQA, Diamond)**This factor evaluates the models‚Äô ability to handle complex, high-level reasoning tasks at a graduate level of education. In this task, researchers compare the model on the GPQA test, a set of 448 questions in different fields designed by experts. These questions are Google Proof, so anyone can‚Äôt find them online. The Claude score is nearly 59.4%, while the GPT-4o scores only 53.6%. Both the scores are relatively close, but as we can see, Claude could be a better option in tasks that require advanced analytical thinking, such as research analysis, complex problem solving, and high academic level problems.\n* **Undergraduate level knowlege(MMLU)**The MMLU, which means Massive Multitask Language Understanding, is a benchmark that explains the general knowledge understanding of any AI model across various subjects at an undergraduate level. Claude 3.5 Sonnet scores 88.3% in this experiment, and the GPT-4o scores 88.7%. This shows how both LLMs have trained in various domains and have a deeper understanding of them. It makes the AI model a well-suited tool for general knowledge tasks, basic tutoring of multiple subjects, etc.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*A4w-tvsxcmFINaQT)\n\n* **Code(HumanEval)**HumanEval is a benchmark that evaluates the model‚Äôs ability to generate, understand, and debug code. This benchmark is where Claude 3.5 Sonnet achieves 92%, and GPT-4o scores 90.2%. Claude 3.5 Sonnet results are spectacular in this task as it provides a better coding environment, ‚ÄúArtifacts,‚Äù and better code generation than GPT-4o. Claude allows the users to design, edit, and run the code in the Artifacts pop-up window. After the launch of Claude 3.5 Sonnet, everyone is developing tools, websites, and basic games and sharing them across the internet. On the other hand, GPT-4o also scored well, but it does not have any coding environment in its interface, so the developers must do too much hassle as the code generated by it is too much hassle to get to the result.\n* **Reasoning Over Text(DROP, FLscore)**The DROP(Discrete Reasoning Over Paragraphs) is the benchmark that measures the model‚Äôs ability to understand complex text information. In this challenge, the Claude 3.5 Sonnet scores 87.1%, while the GPT-4o scores 83.4%. This shows that the Claude 3.5 Sonnet is better and more effective for the task, which involves detailed text analysis, text review, complex question-answering systems, etc.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Kcy7sFb2FYpbfrwp)\n\n* **Math problem solving(MATH)**This test evaluates the ability of any AI model to solve various mathematical problems. Claude 3.5 Sonnet scores just 71.1%, while the GPT-4o scores 76.6%. These scores make the GPT-4o a better model for mathematical problem-solving tasks and can be used for mathematical computations such as financial modeling, scientific calculations, and advanced data analysis.\n* **Multilingual Maths (MSGM)**This factor describes the ability of any AI model to solve mathematical problems in multiple languages. Both models get scores close to each other: GPT-4o 90.5% and Claude 3.5 Sonnet 91.6%. This shows that both models perform excellently, with Claude slightly better. The capability is particularly helpful for educational applications or any scenario where mathematical reasoning needs to be communicated across language barriers.\n* **Visual question answering(MMU/val)**This factor describes the LLM‚Äôs capability to analyze the information presented in images. The GPT-4o outperforms Claude‚Äôs 3.5 Sonnet in this benchmark with 69.1% and 68.3%, respectively. On the other hand, when analyzing text from the document, Claude‚Äôs 3.5 Sonnet score is 95.2% compared to GPT-4o‚Äôs 92.1%.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*xzjqBV2YL0lVFitX)\n\n* **Image Generation**Image Generation is the ability of the LLMs to generate images from the text. GPT-4o is integrated with DallE-2 and can produce images with the help of text, and the results are excellent. On the other hand, Claude 3.5 Sonnet cannot create any images. This feature also helps GPT-4o design websites and references better, as it is trained on many images.\n* **Knowledge Cutoff**Here, both the models trained on a limited data set till a specific date. Claude 3.5 Sonnet trained on data till April 2024, while the other hand, GPT-4o trained on data till 2024. The real advantage of GPT-4o is that it has real-time web browsing, which helps the LLM train on new data regularly.\n\n\n## Pros of GPT-4o:\n\n* Handles voice, images, and video input.\n* Real-time web browsing capability.\n* Faster response time (0.32 seconds average).\n* Superior in math problem-solving.\n* Can generate images using DALL-E 2.\n\n\n## Cons of GPT-4o:\n\n* Slightly lower performance in graduate-level reasoning.\n* No built-in coding environment.\n* A lower score in document visual Q&A.\n* Slightly behind in code generation capabilities.\n* Less effective in detailed text analysis.\n\n\n## Pros Claude 3.5 Sonnet:\n\n* Excels in graduate-level reasoning.\n* Superior code generation and built-in ‚ÄúArtifacts‚Äù feature.\n* Better performance in detailed text analysis.\n* A higher score in document visual Q&A.\n* Slightly better in multilingual math.\n\n\n## Cons Claude 3.5 Sonnet:\n\n* Cannot handle voice or video input.\n* No image generation capability.\n* Slightly lower performance in visual question-answering.\n* Cannot access real-time web information.\n* Weaker in math problem-solving.\n\n\n## Conclusion\n\nGPT-4o and Claude 3.5 Sonnet demonstrate impressive capabilities across various tasks, each with its strengths. GPT-4o excels in multimodal inputs, real-time information access, and image generation, making it versatile for diverse applications. Claude 3.5 Sonnet shines in complex reasoning, code generation, and detailed text analysis, offering superior performance in specific academic and professional contexts. The choice between these models depends on the specific use case and required features. We can expect further improvements and specialized models catering to different needs as AI technology advances.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/comparative-study-of-langgraph-autogen-and-crewai-for-building-multi-agent-systems-0e7e47f9078e","frontmatter":{"title":"Comparative Study of LangGraph, Autogen, and Crewai for Building Multi-Agent Systems","meta_title":"Comparative Study of LangGraph, Autogen, and Crewai for Building Multi-Agent Systems","description":"As we venture into the realm of multi-agent systems (MAS), it‚Äôs essential to understand the diverse programming languages designed‚Ä¶","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DBlLuCOA3lWIg6RmpMPg8A.png","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["LangGraph","Autogen","Crewai","multi-agent","scalability"],"draft":false,"slug":"blog/comparative-study-of-langgraph-autogen-and-crewai-for-building-multi-agent-systems-0e7e47f9078e"},"content":"\n\n\n\nAs we venture into the realm of multi\\-agent systems (MAS), it‚Äôs essential to understand the diverse programming languages designed specifically for this purpose. In this article, we‚Äôll delve into the world of MAS development by comparing LangGraph, Autogen, and Crewai ‚Äî three prominent players in the field.\n\n\n## Introduction\n\nMulti\\-agent systems (MAS) have become increasingly important in various industries. A MAS is a system composed of multiple intelligent agents that interact with each other and their environment to achieve specific goals. Among the many frameworks available for building MAS, LangGraph, Autogen, and Crewai are some of the most popular choices.\n\nAs developers or researchers working on a MAS project, choosing the right framework can be overwhelming, especially considering factors such as ease of use, scalability, customization, and integration with AI libraries. This article provides a comparative study of LangGraph, Autogen, and Crewai, highlighting their strengths, weaknesses, and suitability for different applications.\n\n\n### Introduction to Each Framework\n\n\n## LangGraph: An Open\\-Source Framework\n\n**Strengths**:\n\n* **Ease of use**: LangGraph provides a simple and intuitive API, making it easy for developers to integrate with their existing systems.\n* **Scalability**: LangGraph supports large\\-scale distributed systems, allowing users to handle complex tasks.\n* **Integration with AI Libraries**: LangGraph is compatible with popular AI libraries such as TensorFlow, PyTorch, and Keras.\n\n**Limitations**:\n\n* Limited support for distributed systems\n* Less flexible than Autogen and Crewai\n\n\n## Autogen: A Modular Open\\-Source Framework\n\n**Strengths**:\n\n* **High flexibility**: Autogen provides a modular architecture, allowing users to customize their MAS to fit specific needs.\n* **Suitability for complex applications**: Autogen‚Äôs modularity makes it well\\-suited for large\\-scale systems with multiple interconnected agents.\n* **Strong community support**: Autogen has an active community of developers and researchers who contribute to the framework and provide support.\n\n**Limitations**:\n\n* Steeper learning curve\n* Requires more resources\n\n\n## Crewai: A Scalable, Data\\-Driven Framework\n\n**Strengths**:\n\n* **Scalability**: Crewai provides excellent support for large\\-scale systems, making it well\\-suited for applications that require processing of vast amounts of data.\n* **Ease of use**: Crewai offers a simple API, making it easy to integrate with existing systems.\n* **Integration with cloud services**: Crewai allows users to easily deploy their MAS on cloud platforms such as AWS and Azure.\n\n**Limitations**:\n\n* Limited support for custom models\n* Less flexible than Autogen\n\n\n## Comparison Matrix\n\n\n\n\n## Conclusion\n\nIn conclusion, each framework has its unique strengths and weaknesses. LangGraph offers ease of use and scalability, Autogen provides flexibility and customizability, while Crewai excels in data\\-driven approach and scalability.\n\nWhen choosing a framework for building a MAS, consider the specific requirements of your project:\n\n* **Ease of use**: Choose LangGraph if you prioritize simplicity and scalability.\n* **Flexibility**: Select Autogen for complex applications that require customization.\n* **Scalability**: Consider Crewai for large\\-scale systems with massive data processing needs.\n\nBy understanding the strengths and weaknesses of each framework, developers can make informed decisions about which MAS to build on, ultimately leading to more effective and efficient solutions.\n\n\n## Additional Resources\n\nFor further reading and resources, please see:\n\n* [LangGraph Documentation](https://proxy.rifx.online/https://langgraph.com/documentation/)\n* [Autogen Tutorials](https://proxy.rifx.online/https://autogen.com/tutorials)\n* [Crewai API Reference](https://proxy.rifx.online/https://crewai.com/api-reference/)\n\n"},{"lang":"en","group":"blog","slug":"blog/comparing-leading-text-to-image-image-generation-models-for-adding-text-to-images-7dc001f491ef","frontmatter":{"title":"Comparing Leading Text-to-Image Generation Models for Adding Text to Images","meta_title":"Comparing Leading Text-to-Image Generation Models for Adding Text to Images","description":"This article evaluates the text generation capabilities of nine leading text-to-image models, focusing on their ability to accurately render text within images based on specific prompts. The models tested include Adobe Firefly, Amazon Titan, Black Forest Labs FLUX1.1, Google Imagen, KLING AI, Midjourney, OpenAI DALL¬∑E, and Stability AIs models. Results show that Black Forest Labs FLUX1.1 and Stability AIs Stable Image Ultra performed best, accurately reproducing text over 50% of the time. The article also discusses three alternative techniques for ensuring text accuracy in generated images.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Gvj5CUGClWka1KUsDy5GQw.png","categories":["Generative AI","Natural Language Processing","Technology/Web"],"author":"Rifx.Online","tags":["text","generation","models","accuracy","techniques"],"draft":false,"slug":"blog/comparing-leading-text-to-image-image-generation-models-for-adding-text-to-images-7dc001f491ef"},"content":"\n\n\n\n\n### A comparison of nine leading image generation models‚Äô ability to render accurate text (words and phrases) within an image.\n\nIn this post, we will assess the capabilities of nine state\\-of\\-the\\-art text\\-to\\-image generation models from multiple providers on different hosting platforms. Specifically, we will evaluate their ability to generate accurate text (words and phrases) within images based on given prompts. The models tested include the following (in alphabetical order):\n\n1. Adobe Firefly Image 3 (via [firefly.adobe.com](http://firefly.adobe.com/))\n2. Amazon Titan Image Generator G1 v2 (via [Amazon Bedrock](https://aws.amazon.com/bedrock/))\n3. Black Forest Labs FLUX1\\.1 \\[pro] and Ultra Mode (via [Replicate](http://replicate.com/))\n4. Google Imagen 3 (via [ImageFX](https://aitestkitchen.withgoogle.com/tools/image-fx))\n5. KLING AI powered by [Kwai\\-Kolors/Kolors](https://huggingface.co/Kwai-Kolors/Kolors) (via [klingai.com](http://klingai.com/))\n6. Midjourney v6\\.1 (via [midjourney.com](http://midjourney.com/))\n7. OpenAI DALL¬∑E 3 (via [ChatGPT](https://quip-amazon.com/62AqA7VtF4Xb/chatgpt.com))\n8. Stability AI Stable Diffusion 3\\.5 Large (via [stability.ai](http://stability.ai/) API)\n9. Stability AI Stable Image Ultra 1\\.0 v1 (via [Amazon Bedrock](https://aws.amazon.com/bedrock/))\n\nAdditionally, we will examine three alternative and more reliable techniques for ensuring the accuracy of text in generated images.\n\n\n## Testing the Models\n\nSeveral tests, using different prompts and varying levels of detail, were run across all models. Examples of prompts included:\n\n1. *A photograph of a smiling scientist holding a sign that reads: ‚ÄúFlawless AI\\-generated text!‚Äù*\n2. *Vegetable stand with various vegetables, including tomatoes. A black sign with white type reads: ‚ÄúFarm Fresh Tomatoes $2\\.99/lb.‚Äù*\n3. *A whimsical illustration of a friendly\\-looking pumpkin on a white background with a Fall motif of assorted gourds and autumn leaves. The words ‚ÄúHappy Halloween‚Äù are centered above the pumpkin in large dark brown letters.*\n4. *A sleek billboard towers above a bustling interstate at rush hour, cars whizzing by in a blur. Against a dynamic, abstract background, the large, bold text ‚ÄúGenerative AI: Transforming Digital Advertising‚Äù, creates instant readability for passing motorists.*\n\nAlthough the overall image quality and degree of apparent bias varied significantly among the models, only text generation capabilities were assessed. Models that could accurately reproduce the requested text in the prompt at least 50% of the time received a passing grade. Below are results from selected tests that exemplify the models‚Äô capabilities. The results are presented in alphabetical order rather than ranked by quality. For each test, four representative images of average quality are included in the post.\n\n\n\n\n## Models\n\n\n### Adobe Firefly Image 3\n\nAdobe announced its Firefly Image 3 Foundation Model in April 2024\\. According to the [press release](https://news.adobe.com/news/news-details/2024/adobe-introduces-firefly-image-3-foundation-model-to-take-creative-exploration-and-ideation-to-new-heights), Adobe Firefly Image 3 delivers stunning advancements in photorealistic quality, styling capabilities, detail, accuracy, and a greater variety. In addition, significant advancements in the generation speed make the ideation and creation process more productive and efficient. The model is available for use in Adobe Photoshop (beta) and on [firefly.adobe.com](https://firefly.adobe.com/generate/images). Both interfaces are shown below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*gcASwZgRSfPNYJB7n5GrlQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vU3NW6VdkgojkNlHaGWoSg.png)\n\nüö´ In my tests, Adobe Firefly could not accurately reproduce the text requested in the prompt.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*yWoDLmj5mPKEw8GRg51YXw.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0iskBrEjrtFk-mXNrBvkag.jpeg)\n\n\n### Amazon Titan Image Generator G1 v2\n\nThe Amazon Titan Image Generator G1 v2 model was [released](https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-v2-is-now-available-in-amazon-bedrock/) in August 2024\\. It was an upgrade to the previous generation, the Amazon Titan Image Generator G1 v1 model, [released](https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-multimodal-embeddings-and-text-models-are-now-available-in-amazon-bedrock/) in November 2023\\. The Amazon Titan Image Generator G1 v2 model added features, including image conditioning, image guidance with a color palette, background removal, and subject consistency.\n\nThe Amazon Titan Image Generator G1 v2 model was tested on Amazon Bedrock, which according to [AWS](https://aws.amazon.com/bedrock/), is ‚Äú*a fully managed service that offers a choice of high\\-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon through a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI.*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TmROyF5c-BXHevqImyflmw.png)\n\nüö´ In my tests, Amazon Titan Image Generator G1 v2 could not accurately reproduce the text requested in the prompt.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QLvxsEveORObkPOOB3u1Mg.png)\n\n\n### Black Forest Labs FLUX1\\.1 \\[pro] and Ultra Mode\n\nBlack Forest Labs [released](https://blackforestlabs.ai/announcing-flux-1-1-pro-and-the-bfl-api/) FLUX1\\.1 \\[pro] in October 2024\\. According to Black Forest Labs, ‚Äú*FLUX1\\.1 \\[pro] provides six times faster generation than its predecessor FLUX.1 \\[pro] while also improving image quality, prompt adherence, and diversity. At the same time, we updated FLUX.1 \\[pro] to generate the same output as before, but two times faster.*‚Äù The earlier FLUX.1 \\[pro] model was released in August 2024\\.\n\nAs I prepared this post, Black Forest Labs introduced FLUX1\\.1 \\[pro] Ultra and Raw Modes. According to the press release, ‚ÄúT*oday we are adding new high\\-resolution capabilities to FLUX1\\.1 \\[pro], extending its functionality to support 4x higher image resolutions (up to 4MP) while maintaining an impressive generation time of only 10 seconds per sample.*‚Äù\n\nTests of Black Forest Labs FLUX1\\.1 \\[pro] and Ultra were run on [Replicate](https://replicate.com/blog/machine-learning-needs-better-tools). Their website states, ‚Äú*Replicate runs machine learning models in the cloud. We have a library of open\\-source models that you can run with a few lines of code. If you‚Äôre building your own machine learning models, Replicate makes it easy to deploy them at scale.*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IUbfTFj32FxIta_3J1W0pQ.png)\n\n‚úÖ In my tests, Black Forest Labs FLUX1\\.1 \\[pro] could accurately reproduce the text requested in the prompt more than 50% of the time. It had the best results of all models tested.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RewBBA9MAiNbG93h65WdYg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ISZfNQZHo3PL_QkYu3jEIw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XliNJWJr2TZ5MGwi7RAa-g.png)\n\n\n### Google Imagen 3\n\nGoogle Imagen 3 was [released](https://deepmind.google/technologies/imagen-3/) to all US users in August 2024\\. According to Google, ‚Äú*Imagen 3 is our highest\\-quality text\\-to\\-image model, capable of generating images with even better detail, richer lighting, and fewer distracting artifacts than our previous models.*‚Äù Tests of Google Imagen 3 were run on [ImageFX](https://aitestkitchen.withgoogle.com/tools/image-fx), part of Google‚Äôs AI Test Kitchen, ‚Äú*a place where people can experience and give feedback on some of Google‚Äôs latest AI technologies.*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nhto3l0o-XITJzEEQoHSTA.png)\n\nüö´ In my tests, Google Imagen 3 could not accurately reproduce the text requested in the prompt.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9aqKPuZlpGF_lE3pA0ZNtw.png)\n\n\n### KLING AI powered by Kolors\n\nKolors powers Kling AI‚Äôs image generation capabilities. According to [Hugging Face](https://huggingface.co/Kwai-Kolors/Kolors), ‚Äú*Kolors is a large\\-scale text\\-to\\-image generation model based on latent diffusion, developed by the Kuaishou Kolors team. Trained on billions of text\\-image pairs, Kolors exhibits significant advantages over both open\\-source and proprietary models in visual quality, complex semantic accuracy, and text rendering for both Chinese and English characters.*‚Äù According to [Kuaishou](https://ir.kuaishou.com/news-releases/news-release-details/kuaishou-launches-full-beta-testing-kling-ai-global-users-0), Kling AI was released in July 2024\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*na56zUz3DLWK7Dqj51vSKw.png)\n\nüö´ In my tests, KLING AI powered by Kolors could not accurately reproduce the text requested in the prompt. The results were the worst of the models tested. Many responses were in Chinese, even when explicitly asked to be displayed in English.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xgq4C0m8s3Wfp4p9Va7fSQ.png)\n\n\n### Midjourney v6\\.1\n\nMidjourney v6\\.1 was released in July 2024\\. According to [Midjourney](https://updates.midjourney.com/version-6-1/), the latest release, v6\\.1, contained several significant improvements, including more coherent images (arms, legs, hands, bodies, plants, animals, etc.), much better image quality, more precise, detailed, and correct small image features, and improved text accuracy (when drawing words via ‚Äúquotations‚Äù in prompts). Using the `‚Äî ‚Äî style raw` flag also helps improve text accuracy in some test cases, according to [Midjourney](https://docs.midjourney.com/docs/text-generation).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ETXx5VyY4BgEA8zn4K3M0g.png)\n\nüö´ ‚úÖ In my tests, Midjourney v6\\.1 results were mixed. Midjourney could not consistently reproduce the text requested in the prompt more than 50% of the time. The output was correct in some test cases and close to the prompt in others but also repeated words and punctuation just as often.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*yIaVzqP_BwvDGMO5SOo1SA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BDCsxYe_cJSb6pfoxKrWGA.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dqGYigq9T-PMx3GKfqSf2Q.png)\n\n\n### OpenAI DALL¬∑E 3\n\nOpenAI DALL¬∑E 3 was [released](https://deepmind.google/technologies/imagen-3/) over one year ago, in October 2023\\. According to [OpenAI](https://openai.com/index/dall-e-3/), ‚Äú*DALL¬∑E 3 represents a leap forward in our ability to generate images that exactly adhere to the text you provide. DALL¬∑E 3 understands significantly more nuance and detail than our previous systems \\[DALL¬∑E 2], allowing you to easily translate your ideas into exceptionally accurate images.*‚Äù\n\nTests of OpenAI Imagen 3 were run on [ChatGPT](https://openai.com/index/chatgpt/). Also, according to [OpenAI](https://openai.com/index/dall-e-3/), ‚Äú*DALL¬∑E 3 is built natively on ChatGPT, which lets you use ChatGPT as a brainstorming partner and refiner of your prompts. Just ask ChatGPT what you want to see in anything from a simple sentence to a detailed paragraph.*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*x45i0IJoYNiJT1kOi98k7w.png)\n\nüö´ In my tests, OpenAI DALL¬∑E 3 could not accurately reproduce the text requested in the prompt.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NirwqSB-k8dzfGRNAw-pQw.png)\n\n\n### Stability AI Stable Diffusion 3\\.5 Large\n\nAccording to Stability AI, the [Stable Diffusion 3\\.5 Large](https://stability.ai/news/introducing-stable-diffusion-3-5) model, released in October 2024, ‚Äú*at 8\\.1 billion parameters, with superior quality and prompt adherence, this base model is the most powerful in the Stable Diffusion family. This model is ideal for professional use cases at 1 megapixel resolution.*‚Äù The Stability AI Stable Diffusion 3\\.5 Large was tested using the [StabilityAI REST API](https://platform.stability.ai/docs/api-reference#tag/Generate/paths/~1v2beta~1stable-image~1generate~1ultra/post) and code written in Python within a Jupyter Notebook.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*56Zp5QWVvTzGYlslcWEGKg.png)\n\n‚úÖ In my tests, Stability AI Stable Diffusion 3\\.5 Large could accurately reproduce the text requested in the prompt more than 50% of the time, occasionally with slight punctuation errors.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*CQ9I5z7x8ILTdFhu1dCBCQ.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*G2D-L2fEtjKVTTyph3Burg.jpeg)\n\n\n### Stability AI Stable Image Ultra\n\nAccording to Stability AI, the 16 *billion\\-parameter [Stable Image Ultra](https://stability.ai/stable-image) model, released in October 2024, ‚Äúis our flagship model, blending the power of the SD3 Large with advanced workflows to deliver the highest\\-quality photorealistic images. This premium model is designed for industries that require unparalleled visual fidelity, such as marketing, advertising, and architecture.*‚Äù Like Amazon Titan Image Generator, the Stability AI Stable Image Ultra model was also tested using [Amazon Bedrock](https://aws.amazon.com/blogs/aws/stability-ais-best-image-generating-models-now-in-amazon-bedrock/) using the Image Playground UI.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GjaPW2FWGGhuJ06trs1Jww.png)\n\n‚úÖ In my tests, Stability AI Stable Image Ultra could accurately reproduce the text requested in the prompt more than 50% of the time. Along with Black Forest Labs FLUX1\\.1 \\[pro], it was one of the best models tested.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*O7JKeKBPgaEOuvdFW-u2Sg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jDHNLjOKHuEBQlFvTb7nYQ.png)\n\n\n## AI Alternatives to Generating Text\n\nThe Black Forest Labs FLUX1\\.1 \\[pro] and Stability AI Stable Image Ultra models accurately reproduce requested phrases in prompts more frequently than other models. However, users still lack control over many aspects of the images, including the exact position, size, kerning, color, and font style of the text. Several alternative and more reliable techniques exist to guarantee the accuracy of text in generated images.\n\n\n### Replace Generated Text\n\nOne alternative approach is to generate the image with the desired text, regardless of spelling mistakes. Subsequently, one can remove the text in Adobe Photoshop and replace it with correct text in the exact position, size, color, and style desired. However, removing and recreating text can be challenging if foreground subjects or shadows partially obscure it, or if the text appears on an irregular surface. To enhance the realism of the new text, one can rasterize the vector type and then add noise, blurring, distortion, lighting, texturing, and layer blending effects.\n\nBelow are two examples of images generated with Black Forest Labs FLUX1\\.1 \\[pro] Ultra (first image). The text has been removed in Adobe Photoshop (second image), new vector\\-based text has been added (third image), and finally, the text has been rasterized and distorted to appear more realistic (fourth image).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*B0_3d8oImDlrRb6mjpekrw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fmrW46OsZe6Zsc0eshPyYw.png)\n\n\n### Start with a Blank Canvas\n\nA second alternative is to generate the image without text and then add your text in the desired color, size, and font style using Adobe Photoshop. This technique is more straightforward than retouching the generated image to remove existing text. The examples were created using the [Replicate](https://replicate.com/docs/get-started/python) API with Python from a Jupyter Notebook to call Black Forest Labs‚Äô FLUX1\\.1 \\[pro] and Ultra.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iFpqy4fEUJOXaJMzhsgbDA.png)\n\nBelow is an image generated with Black Forest Labs FLUX1\\.1 \\[pro] Ultra using the prompt: ‚Äú*A photograph of a smiling female scientist in a lab coat, standing in a lab, holding a white rectangular sign with no wording or other elements.*‚Äù The generated image (first image) has new text added (second image), and finally, the text is distorted to appear more realistic (third image).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*c1rgPArHDrUQ2cePV9DUCA.png)\n\nBelow is another example that begins with a generated image containing no text, to which text was later added. The initial image was generated with Black Forest Labs FLUX1\\.1 \\[pro] Ultra using the prompt: ‚Äú*Vegetable stand with various vegetables, including tomatoes. A small, rectangular, blank, black sign with no text or other elements sits beside the tomatoes.*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t_6oM1aItMGQfBUPjH83lA.png)\n\nOne last example using the prompt, ‚Äú*A sleek billboard towers above a bustling interstate at rush hour, cars whizzing by. Against a colorful, dynamic, abstract background fills the billboard.*‚Äù to generate the original image.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KyGveUehRxuFTK-DmWnCaw.jpeg)\n\n\n## Generate Image and Text Separately\n\nA third and final technique is to generate the image and text separately using your model of choice, then combine the two elements in post\\-production using Adobe Photoshop. Below is the original image from Midjourney on the left without text, generated using the prompt: ‚Äú*Vegetable stand with various vegetables, including tomatoes. A empty, blank blackboard\\-like sign. ‚Äî ar 1:1*‚Äù\n\nThe white type on a black background in the center was also generated in Midjourney, using the prompt: ‚Äú*The phrase ‚ÄúFarm Fresh Tomatoes $2\\.99/lb.‚Äù written in white chalk letters on a solid jet black background. ‚Äî no tomatoes or other objects ‚Äî ar 3:2 ‚Äî style raw ‚Äî stylize 0*‚Äù\n\nThe text\\-only image is then easily overlaid on top of the first image using the Lighten blending mode for the text\\-only layer. Additional distortions can be applied to make the text look more natural in final image.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ZP-pqTQVN8Xy_Vhjm8D0gg.png)\n\n\n## Conclusion\n\nIn this post, we explored the capabilities of nine different state\\-of\\-the\\-art text\\-to\\-image generation models from various providers to generate accurate text within images from prompts. We discovered that Black Forest Labs FLUX1\\.1 \\[pro] and Stability AI‚Äôs Stable Image Ultra were more successful at accurately reproducing requested text in images compared to other models. Finally, we examined three alternative and more reliable techniques for ensuring the accuracy of text in generated images.\n\n*If you are not yet a Medium member and want to support authors like me, please sign up here: <https://garystafford.medium.com/membership>.*\n\n*This blog represents my viewpoints and not those of my employer, Amazon Web Services (AWS). All product names, images, logos, and brands are the property of their respective owners.*\n\n\n"},{"lang":"en","group":"blog","slug":"blog/conversational-ai-for-customer-service-best-practices-and-key-steps-for-success-4ceee714dbe1","frontmatter":{"title":"Conversational AI for Customer Service: Best Practices and Key Steps for Success","meta_title":"Conversational AI for Customer Service: Best Practices and Key Steps for Success","description":"Conversational AI is increasingly vital for enhancing customer service, with a projected rise in fully automated interactions to 40% by 2025. It leverages natural language processing and machine learning to provide instant, personalized support, improving customer satisfaction and operational efficiency. Key steps for successful implementation include identifying customer pain points, defining use cases, selecting the right platform, and ensuring continuous monitoring and improvement. Best practices emphasize security, balancing automation with human interaction, and personalizing customer experiences. As businesses embrace this technology, it is expected to transform customer service operations significantly.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LrRhvUJrNaS299z8oC2bkg.jpeg","categories":["Natural Language Processing","Machine Learning","Chatbots"],"author":"Rifx.Online","tags":["conversational","automation","personalization","monitoring","security"],"draft":false,"slug":"blog/conversational-ai-for-customer-service-best-practices-and-key-steps-for-success-4ceee714dbe1"},"content":"\n\n\n\n\n\nIn today‚Äôs fast\\-paced business environment, customer service plays a crucial role in building and maintaining customer loyalty. As businesses strive to offer personalized and efficient support, Conversational AI has emerged as a revolutionary solution. By integrating artificial intelligence (AI) into customer service operations, companies can streamline processes, provide instant responses, and significantly improve the overall customer experience. A report by *Gartner* estimates that by **2025**, **40% of customer service interactions** will be fully automated through AI and machine learning technology, a significant rise from the **25%** reported in 2023\\.\n\nBusinesses looking to develop Conversational AI solutions for customer service are entering a transformative space with immense potential. This article explores the best practices, key steps, and benefits of implementing Conversational AI to drive success in customer support operations, offering a detailed guide for businesses eager to develop their own AI\\-driven customer service solutions.\n\n\n## The Rise of Conversational AI in Customer Service\n\nConversational AI combines natural language processing (NLP), machine learning, and automated messaging to facilitate seamless, human\\-like interactions between customers and digital systems. These technologies are designed to understand customer queries, provide accurate responses, and engage users in meaningful conversations. With the increasing demand for 24/7 customer support and instant resolution of issues, businesses are now turning to Conversational AI to meet these needs efficiently.\n\nIncorporating Conversational AI into customer service not only improves operational efficiency but also enhances customer satisfaction. In fact, according to *Salesforce*, **69% of consumers** expect AI\\-driven interactions to provide more relevant and personalized experiences, highlighting the growing importance of Conversational AI in delivering customer\\-centric services.\n\n\n## Why Businesses Should Develop Conversational AI for Customer Service?\n\nFor businesses looking to [**develop AI\\-driven customer service solutions**](https://www.blockchainappfactory.com/generative-ai-solutions?utm_source=medium&utm_medium=blog&utm_campaign=elavarasan), the advantages are vast. Below are some compelling reasons why investing in Conversational AI for customer service is a strategic move:\n\n**1\\. Improved Customer Experience**\n\nConversational AI provides immediate responses to customer queries, eliminating the need for customers to wait in long queues or deal with delayed responses. By offering 24/7 support through AI\\-powered chatbots and virtual assistants, businesses can deliver a faster, more seamless experience that improves customer satisfaction and loyalty.\n\n**2\\. Increased Efficiency**\n\nAI\\-powered bots can handle high volumes of customer inquiries simultaneously, freeing up human agents to focus on more complex issues. This results in a more efficient use of resources, reducing operational costs and minimizing response times.\n\n**3\\. Cost Savings**\n\nImplementing Conversational AI significantly reduces the costs associated with customer service operations. According to *Juniper Research*, businesses that integrate chatbots into their customer service operations could save up to **$11 billion annually** by 2023\\. These savings come from reducing the need for large customer service teams and automating repetitive tasks.\n\n**4\\. Enhanced Personalization**\n\nBy analyzing customer data and preferences, AI systems can deliver personalized responses tailored to individual needs. This level of customization helps businesses build stronger relationships with their customers and fosters greater engagement.\n\n\n## Key Steps for Implementing Conversational AI in Customer Service\n\nImplementing Conversational AI for customer service requires a thoughtful and strategic approach to ensure it delivers the desired outcomes. Here are the key steps businesses should follow when developing AI\\-driven customer support solutions.\n\n**Step 1: Identify Customer Pain Points**\n\nBefore implementing Conversational AI, it‚Äôs essential to understand the specific challenges and pain points that your customers face during interactions with customer service. Common issues such as long wait times, repetitive queries, or difficulty accessing information should be addressed by the AI solution. Conduct surveys, analyze customer service data, and gather feedback to pinpoint the areas where AI can provide the most value.\n\n**Step 2: Define Use Cases for Conversational AI**\n\nOnce you‚Äôve identified customer pain points, define the specific use cases where Conversational AI will be most effective. Use cases can range from answering frequently asked questions (FAQs) to handling more complex processes like booking services, processing returns, or offering product recommendations. Businesses must focus on prioritizing high\\-impact use cases that directly address customer needs and provide measurable benefits.\n\n**Common Use Cases Include:**\n\n* **Order Status Inquiries:** AI bots can instantly retrieve and share order status updates with customers.\n* **Product Information:** Virtual assistants can provide detailed product information and suggest complementary items based on customer behavior.\n* **Technical Support:** AI\\-powered bots can guide users through troubleshooting steps for common technical issues.\n* **Billing and Payments:** Chatbots can facilitate payments, bill inquiries, and subscription management.\n\n**Step 3: Choose the Right Conversational AI Platform**\n\nSelecting the right AI platform is critical for the success of your customer service automation efforts. When evaluating AI platforms, consider factors such as scalability, ease of integration, NLP capabilities, and customization options. Popular AI platforms like Google Dialogflow, Microsoft Azure Bot Services, and IBM Watson offer robust tools for building and deploying AI\\-driven customer service solutions. The platform should support multi\\-channel interactions (e.g., chat, voice, social media) to ensure seamless communication with customers across different platforms.\n\n**Step 4: Design an Intuitive User Experience**\n\nAn intuitive and user\\-friendly interface is key to the success of your Conversational AI system. Ensure that the AI can engage customers in clear, concise conversations that guide them toward resolving their issues efficiently. The AI should understand natural language, detect customer intent, and ask relevant follow\\-up questions to help users get the information they need quickly.\n\nTo enhance the user experience, design the conversation flow to be as human\\-like as possible. Personalize the interactions by addressing the user by name, recalling past conversations, and offering solutions based on their previous interactions with your business.\n\n**Step 5: Train the AI with Relevant Data**\n\nThe performance of your Conversational AI largely depends on the quality and quantity of data it is trained on. Train the AI with real customer interaction data to improve its ability to understand different queries, nuances, and language variations. By continuously feeding the AI with data from past interactions, you ensure that it learns and improves over time, enhancing its ability to provide accurate and contextual responses.\n\n**Step 6: Integrate with Existing Systems**\n\nFor Conversational AI to be truly effective, it must be integrated with your existing customer service systems. Ensure that the AI solution can pull data from your CRM, billing systems, order management platforms, and knowledge bases to provide relevant and accurate information to customers. This integration allows the AI to respond to inquiries in real\\-time and ensures that customers receive consistent support across all touchpoints.\n\n**Step 7: Continuously Monitor and Improve**\n\nAfter deploying your Conversational AI solution, it‚Äôs essential to continuously monitor its performance and identify areas for improvement. Track key performance indicators (KPIs) such as response time, resolution rate, and customer satisfaction scores. Use these insights to refine the AI‚Äôs capabilities, adjust conversation flows, and address any shortcomings. AI systems should evolve over time by learning from interactions and adapting to changing customer expectations.\n\n\n## Best Practices for Successful Conversational AI Implementation\n\nDeveloping and [**deploying Conversational AI in customer service**](https://www.blockchainappfactory.com/generative-ai-solutions?utm_source=medium&utm_medium=blog&utm_campaign=elavarasan) requires adherence to best practices to ensure long\\-term success. Here are some best practices for businesses looking to maximize the impact of AI\\-driven customer service.\n\n**1\\. Prioritize Security and Compliance**\n\nCustomer service often involves handling sensitive information such as payment details, account information, and personal data. Ensure that your AI solution complies with data protection regulations like the General Data Protection Regulation (GDPR) or the California Consumer Privacy Act (CCPA). Implement robust security protocols to encrypt customer data and protect against data breaches.\n\n**2\\. Balance Automation with Human Interaction**\n\nWhile Conversational AI can handle a wide range of customer inquiries, it‚Äôs essential to strike a balance between automation and human support. In cases where the AI cannot resolve complex issues or where customers require a more personalized touch, ensure that there is a seamless transition from AI to human agents. This hybrid model allows customers to get the best of both worlds: the speed of AI and the empathy of human agents.\n\n**3\\. Test and Optimize the AI System**\n\nBefore launching your AI system to the public, conduct extensive testing to ensure it meets the desired performance benchmarks. Test the AI‚Äôs ability to understand various languages, accents, and query structures. Use A/B testing to evaluate different conversation flows and optimize them based on customer feedback and performance data.\n\n**4\\. Personalize Interactions with AI**\n\nCustomers appreciate interactions that feel personalized and relevant. By leveraging AI‚Äôs ability to analyze customer data, businesses can tailor responses based on the customer‚Äôs history, preferences, and behavior. Personalization goes beyond just addressing customers by name ‚Äî it involves anticipating their needs and offering proactive solutions that add value to their experience.\n\n**5\\. Incorporate Multilingual Capabilities**\n\nFor businesses with a global customer base, it‚Äôs essential to develop Conversational AI that supports multiple languages. Multilingual AI systems allow customers to interact with businesses in their preferred language, improving accessibility and expanding the reach of customer service operations.\n\n**6\\. Set Clear Expectations for Customers**\n\nTo prevent frustration, set clear expectations for customers about what the AI can and cannot do. If the AI is limited to certain tasks (such as providing order updates or answering FAQs), make this clear from the beginning of the interaction. This transparency helps manage customer expectations and prevents confusion when transitioning to human agents for more complex issues.\n\n\n## Real\\-World Examples of Conversational AI in Customer Service\n\nSeveral companies have already implemented Conversational AI solutions to enhance their customer service operations. Below are some real\\-world examples that showcase the impact of AI on customer service success.\n\n**1\\. H\\&M‚Äôs Customer Service Chatbot**\n\nGlobal fashion retailer *H\\&M* uses an AI\\-powered chatbot to help customers with common queries related to order status, product availability, and return policies. The chatbot reduces the load on customer service agents by automating repetitive tasks, allowing human agents to focus on more complex inquiries. H\\&M‚Äôs chatbot has improved customer response times and increased overall satisfaction rates.\n\n**2\\. Sephora‚Äôs Virtual Beauty Advisor**\n\nCosmetics retailer *Sephora* offers a **Virtual Beauty Advisor** powered by Conversational AI to provide personalized product recommendations and beauty tips. The AI assistant engages customers in interactive conversations, asking questions about their preferences and recommending products tailored to their needs. By providing a highly personalized experience, Sephora has improved customer engagement and increased online sales.\n\n**3\\. Amtrak‚Äôs Customer Service Chatbot, Julie**\n\n*Amtrak* implemented **Julie**, an AI\\-powered virtual assistant that helps customers book tickets, check train schedules, and get travel updates. Julie handles over **5 million inquiries** per year, reducing call center volume and improving the overall efficiency of Amtrak‚Äôs customer service operations. The success of Julie has allowed Amtrak to cut costs and provide faster service to its customers.\n\n\n## The Future of Conversational AI in Customer Service\n\nThe adoption of Conversational AI in customer service is poised to grow in the coming years as businesses continue to prioritize automation, efficiency, and customer satisfaction. By 2030, it is estimated that **70% of customer interactions** will involve some form of AI technology. This shift toward AI\\-driven customer service will allow businesses to offer personalized, real\\-time support to millions of customers globally.\n\nAs technology evolves, Conversational AI will become even more intelligent, capable of handling complex inquiries, understanding emotions, and providing proactive solutions. Businesses that invest in Conversational AI today will be better equipped to meet the growing demands of their customers in the future.\n\n\n## Conclusion\n\nConversational AI has transformed the way businesses interact with their customers, offering faster, more personalized, and efficient support. For businesses looking to develop AI\\-driven customer service solutions, the opportunities are vast. By following best practices and implementing key steps such as identifying use cases, choosing the right platform, and continuously optimizing the AI system, businesses can achieve success and drive innovation in customer service.\n\nInvesting in Conversational AI is not just a strategic move for improving customer service ‚Äî it‚Äôs an essential step toward future\\-proofing customer support operations. By enhancing customer experience, reducing costs, and offering scalable solutions, Conversational AI represents the future of customer service.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/explore-swarm-multi-agent-framework-locally-0e25ee617795","frontmatter":{"title":"Explore Swarm Multi-Agent Framework Locally","meta_title":"Explore Swarm Multi-Agent Framework Locally","description":"Swarm is an experimental sample framework to simulate lightweight multi-agent framework for educational purpose. Usually it works with Open‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0ZVceq32bvkytC7HSIgmwA.png","categories":["Programming","Technology","Education"],"author":"Rifx.Online","tags":["Swarm","Multi-Agent","Framework","OpenAI","Ollama"],"draft":false,"slug":"blog/explore-swarm-multi-agent-framework-locally-0e25ee617795"},"content":"\n\n\n\n\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zkpW8DDwh0TTYuHJVJbDaw.png)\n\nSwarm is an experimental sample framework to simulate lightweight multi-agent framework for educational purpose. Usually it works with Open AI Key but we can change it to use local Ollama or LM Studio Models.\n\n**Setup:**\n\n\n```python\n## Create a new Conda or Python Virtual Environment and activate it\nconda install python==3.10\npip install torch openai\npip install transformers accelerate huggingface_hub\npip install git+ssh://git@github.com/openai/swarm.git\n```\n**To use with Open AI Key:**\n\n\n```python\nexport OPEN_API_KEY = Your Key\n```\n**To use Ollama or LM Studio Local LLMs ‚Äî Update to Local URL:**\n\n\n```python\n## Find the location site-packages/swarm on the conda or python virtual env\n## Locate the file core.py\nclass Swarm:\n    def __init__(self, client=None):\n        if not client:\n          # Actual Code\n          #client = OpenAI()\n          # Update the Base URL and API Key to Ollama / LM Studio\n          # In this demo we are using LM Studio and Llama 3.1\n          client = OpenAI(base_url=\"http://localhost:1234/v1\",api_key=\"random\")\n        self.client = client\n```\n**Clone Repo:**\n\nClone the Repo ‚Äî where you can find examples directory with different use cases like basic, airline and weather etc.\n\n\n```python\ngit clone https://github.com/openai/swarm.git\ncd swarm/examples\n```\n**Sample Code:**\n\n\n```python\nfrom swarm import Swarm, Agent\n\nclient = Swarm()\n\n\nit_agent = Agent(\n    name=\"IT Agent\",\n    instructions=\"You are an IT Expert with 10 Years of Experience.\",\n)\n\nsales_agent = Agent(\n    name=\"Sales Agent\",\n    instructions=\"You are a Sales Expert with 5 Years of Experience and knows about best selling mobiles.\",\n)\n\ndef transfer_to_sales_agent():\n    print(\"Sales agent in action\")\n    \"\"\"Transfer sales related questions to sales team immediately.\"\"\"\n    return sales_agent\n\ndef transfer_to_it_agent():\n    print(\"IT agent in action\")\n    \"\"\"Transfer IT users immediately.\"\"\"\n    return it_agent\n\nenglish_agent = Agent(\n    name=\"English Agent\",\n    instructions=\"You only speak English.\",\n    functions=[transfer_to_sales_agent,transfer_to_it_agent],\n)\n\n\nmessages = [{\"role\": \"user\", \"content\": \"How to install pandas lib?\"}]\nresponse = client.run(agent=english_agent, messages=messages)\n\nprint(response.messages[-1][\"content\"])\n\nmessages = [{\"role\": \"user\", \"content\": \"What are the best selling items?\"}]\nresponse = client.run(agent=english_agent, messages=messages)\n\nprint(response.messages[-1][\"content\"])\n```\n**References:**\n\n\n```python\nhttps://github.com/openai/swarm\n\nhttps://github.com/victorb/ollama-swarm/tree/main\n```\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hCFJ4VQoT12yElYPXwXvWA.png)\n\nGiven that it is an experimental release, there is still much room for improvement. The airline agent example code [swarm/examples/airline] was interesting, so try those examples. Give it a try and share your experience in the comments. Thanks.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/fine-tuning-llama-3-with-unsloth-79c3465ef3e3","frontmatter":{"title":"Fine-tuning LLama 3 with Unsloth","meta_title":"Fine-tuning LLama 3 with Unsloth","description":"In this article I will show you how to fine-tune an LLM (Llama 3 from Meta) using Unsloth (including a way for custom dataset)","date":"2024-10-30T12:58:41.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kaXoudNTGeGfuNPl_kta5g.jpeg","categories":["Programming","Machine Learning","Natural Language Processing"],"author":"Rifx.Online","tags":["Llama","Unsloth","LoRA","Alpaca","NVIDIA"],"draft":false,"slug":"blog/fine-tuning-llama-3-with-unsloth-79c3465ef3e3"},"content":"\n\n\nIn this article I will show you how to fine\\-tune an LLM (Llama 3 from Meta) using [Unsloth](https://github.com/unslothai/unsloth). I will also provide a way to use your own custom dataset.\n\n**Note :** Unsloth is library that accelerates fine\\-tuning of LLMs on NVIDIA GPUs (40% reduction in memory usage compared to traditional methods). Compatible with Hugging Face, it supports Llama and Mistral architectures.\n\nIf you find my articles interesting, don‚Äôt forget to **clap and [follow](https://medium.com/@soulawalid)** üëçüèº, these articles take times and effort to do!\n\nYou can access to the free notebook provided for that on the GitHub repo\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_L4o4MDQ7W5__OwW0E5RWA.png)\n\nSince I am using Llama 3, I will click on the notebook (you can install Unsloth on your own computer too).\n\n**Note:** I will use this dataset ‚Äú[alpaca\\-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)‚Äù from Hugging Face , the data is in Alpaca format meaning there is (Instruction, Input and Output)\n\n### Starting the project\n\nDuring the project I will guide you to perform fine\\-tuning with Unsloth, explaining the code and provide recommendations, Let‚Äôs start our project :\n\n**1/ Installing required packages :** We need first to install **Unsloth** and **xformers**, **trl**, **peft**, **accelerate**, **bitsandbytes** libraries for efficient model training and inference.\n\n```python\n!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install --no-deps xformers trl peft accelerate bitsandbytes\n```\n\n**2/ Loading and Configuring the Model :** In the configuration I will set the following :\n\n* Sets the maximum sequence length to **2048**\n* by having dtype as **None**, it automatically detects the data type.\n* Loads the model in **4\\-bit precision,** I think it‚Äôs enough.\n\n**Note :** You can find my article about tips on fine\\-tuning LLMs in the Resources section\n\n```python\nfrom unsloth import FastLanguageModel\nimport torch\n\n## Configuration\nmax_seq_length = 2048\ndtype = None\nload_in_4bit = True\n\n## Load the selected model\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cJSAcJFP7E-qJkqKUsHqLw.png)\n\n**3/ Applying PEFT (Parameter Efficient Fine\\-Tuning) :** We will then fine\\-tunes the pre\\-trained model using LoRA.\n\n* r \\= 16 is the rank parameter for LoRA. **Note :** common values are 8, 16, 32, 64, 128\n* lora\\_alpha \\= 16 represents the scaling factor for LoRA updates ( I will write an article about LoRA to explain in details each part of it)\n* No dropout and bias for LoRA\n* For use\\_gradient\\_checkpointing we are using Unsloth to handle that (saving memory)\n\n```python\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)\n```\n\n**4/ Defining the Prompt Template :** We will create alpaca prompt template to format the dataset ( In case the data that you will be using is not in that format).\n\nWe will also add EOS (End Of Sequence) to inform the LLM that the sentence has ended.\n\nFinally the formatting function, the function takes a batch of examples and formats each one according to the alpaca prompt template that we write before.\n\n* It extracts instruction, input, and output fields from each example (row).\n* It then formats these fields into the template and appends the EOS token.\n* The formatted text is stored in a list and returned as a dictionary with a single key, ‚Äútext‚Äù\n\n```python\nalpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n#### Instruction:\n{}\n\n#### Input:\n{}\n\n#### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token\n\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs = examples[\"input\"]\n    outputs = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return {\"text\": texts}\n```\n\n**5/ Loading and Formatting the Dataset:** Loads the Alpaca dataset and applies formatting to each dataset example in batches.\n\n```python\nfrom datasets import load_dataset\ndataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*M8EmbLMdoqrM-JlkMpDv8g.png)\n\n**6/ Setting Up and Training the Model:** I covered most of them in my [previous article](https://readmedium.com/supervised-fine-tuning-tips-for-your-llm-projects-f84f20593653) regarding tips for Fine\\-Tuning.\n\n```python\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2, # Number of processes to use for data preprocessing\n    packing = False, # Whether to pack multiple sequences into one batch to increase training efficiency\n    args = TrainingArguments(\n        per_device_train_batch_size = 2, #The batch size per device\n        gradient_accumulation_steps = 4, #Number of gradient accumulation steps, which allows for effectively larger batch sizes\n        warmup_steps = 5, #Number of steps to perform linear learning rate warmup\n        max_steps = 60, #Total number of training steps\n        learning_rate = 2e-5,#The learning rate for the optimizer\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"cosine\",\n        seed = 3407,\n        output_dir = \"outputs\",\n    ),\n)\n\ntrainer_stats = trainer.train()\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Vb_OqGP9CPc8xZdnkclGyQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PI0JXrTbpjuviyQ4bZJnFg.png)\n\n**7/ Inference and Generation :** we prepare the model for inference by preparing the input prompt, tokenizing it , and then uses the model to generate new text based on that prompt. The generated text is then converted back into readable form.\n\n```python\nFastLanguageModel.for_inference(model)\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"Continue the fibonnaci sequence.\", # instruction\n        \"1, 1, 2, 3, 5, 8\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PI6SBL_YPPj0-RSAn5nl7g.png)\n\nYou can also use a TextStreamer for continuous inference , so you can see the generation token by token, instead of waiting the whole time!\n\n```python\nFastLanguageModel.for_inference(model)\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"Continue the fibonnaci sequence.\",\n        \"1, 1, 2, 3, 5, 8\",\n        \"\",\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NaSQ1vQKORU1I3DsOU2iOA.png)\n\n**8/ Save the model :** If you are happy with it, you can save your model or push it to Hugging Face Hub\n\n```python\nmodel.save_pretrained(\"lora_model\")\ntokenizer.save_pretrained(\"lora_model\")\n## model.push_to_hub(\"your_name/lora_model\", token = \"...\")\n## tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\")\n```\n\n**9/ Load the model :**\n\n```python\nif False:\n    from unsloth import FastLanguageModel\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"lora_model\",\n        max_seq_length = max_seq_length,\n        dtype = dtype,\n        load_in_4bit = load_in_4bit,\n    )\n    FastLanguageModel.for_inference(model)\n```\n\n**10/ Using it for generation :**\n\n```python\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"What is the capital of Palestine ?\",\n        \"\",\n        \"\",\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)\n```\n\nIf there‚Äôs a specific subject you‚Äôd like us to cover, please don‚Äôt hesitate to let me know! Your input will help shape the direction of my content and ensure it remains relevant and engaging üòÄ\n\n\n"},{"lang":"en","group":"blog","slug":"blog/gemini-1-5-flash-vs-gpt-4o-88b9d8da8152","frontmatter":{"title":"New Gemini 1.5 FLASH Model: An Absolute Google Game Changer","meta_title":"New Gemini 1.5 FLASH Model: An Absolute Google Game Changer","description":"Gemini 1.5 Flash blows GPT-4o out of the water","date":"2024-11-08T00:27:31.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Reb1owOmiw5DFd4A.png","categories":["Programming","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["Gemini","Flash","GPT-4o","multi-modality","creativity"],"draft":false,"slug":"blog/gemini-1-5-flash-vs-gpt-4o-88b9d8da8152"},"content":"\nTheir new Gemini 1\\.5 Flash model blows GPT\\-4o out of the water and the capabilities are hard to believe.\n\n**Lightning fast**.\n\n\n\n33 times cheaper than GPT\\-4o but has a 700% greater context ‚Äî **1 million tokens.**\n\nWhat is 1 million tokens in the real\\-world? Approximately:\n\n* Over an 1 hour of video\n* Over 30,000 lines of code\n* Over 700,000 words\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*E1XIOcpWfeqOZSZC.jpg)\n\n‚ùåGPT\\-4o cost:\n\n* Input: $2\\.50 per million tokens\n* Output: $10 per million tokens\n* Cached input: $1\\.25 per million tokens\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XM3hFyS_PCcuv8Px.png)\n\n‚úÖ Gemini 1\\.5 Flash cost:\n\n* Input: $0\\.075 per million tokens\n* Output: $0\\.30 per million tokens\n* Cached input: $0\\.01875 per million tokens\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*d-1ioFlCxW3LB4SL.png)\n\nAnd then there‚Äôs the mini Flash\\-8B version for cost\\-efficient tasks ‚Äî 66 times cheaper than GPT\\-4o:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5B5ybLzTr7penwms.png)\n\nAnd the best part is the multi\\-modality ‚Äî it can reason with text, files, images and audio in complex integrated ways.\n\nAnd 1\\.5 Flash has almost all the capabilities of Pro but much faster. And as a dev you can start using them now.\n\nGemini 1\\.5 Pro was tested with a 44\\-minute silent movie and astonishingly, it easily analyzed the movie into various plot points and events. Even pointing out tiny details that most of us would miss on first watch.\n\nMeanwhile the GPT\\-4o API only lets you work with text and images.\n\nYou can easily create, test and refine prompts in Google‚Äôs AI Studio ‚Äî **completely free**.\n\nIt doesn‚Äôt count in your billing like in OpenAI playground.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5BKejWrJvrsEWIjc.png)\n\nJust look at the power of Google AI Studio ‚Äî creating a food recipe based on an image:\n\nI uploaded this delicious bread from gettyimages:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fC5YL_dplJ9Od_vN.jpg)\n\nNow:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*GezbFh9KzFXRVhr3.png)\n\nWhat if I want the response to be a specialized format for my API or something?\n\nThen you can just turn on JSON mode and specify the response schema:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*aRZuia7Iz_mI2s9b.png)\n\nOpenAI playground has this too, but it‚Äôs not as intuitive to work with.\n\nAnother upgrade Gemini has over OpenAI is how creativity it can be.\n\nIn Gemini you can increase the `temperature` from 0 to 200% to control how random and creative the responses are:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4AAFdAMfT_xyflmv.png)\n\nMeanwhile in OpenAI if you try going far beyond 100%, you‚Äôll most likely get a whole literal load of nonsense.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yzFQL69pyJmgE9UB.png)\n\nAnd here‚Äôs the best part ‚Äî when you‚Äôre done creating your prompt you can just use **Get code** ‚Äî easily copy and paste the boilerplate API code and move lightning\\-fast in your development.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*xgaZfVe9b8WSBMmq.png)\n\nWorks in several languages including Kotlin, Swift and Dart ‚Äî efficient AI workflow in mobile dev.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*AMkfKm-3KQRxnltO.png)\n\nIn OpenAI playground you can get the code for Python and JavaScript.\n\n## Final thoughts\n\nGemini 1\\.5 Flash is a game\\-changer offering unparalleled capabilities at a fraction of the cost.\n\nWith its advanced multi\\-modality ease of use, generous free pricing, and creative potential it sets a new standard for AI leaving GPT\\-4o in the dust.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/gemma-vs-llama-vs-mistral-exploring-smaller-ai-models-672a95f4b9b7","frontmatter":{"title":"Gemma vs. Llama vs. Mistral: Exploring Smaller AI Models","meta_title":"Gemma vs. Llama vs. Mistral: Exploring Smaller AI Models","description":"A Comparative Study of Small-Scale Language Models: Evaluating Gemma, Llama 3, and Mistral in Reading Comprehension Tasks","date":"2024-11-10T22:36:54.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TJqJ12YQCeYTS5fWOYR5Ig.png","categories":["Natural Language Processing","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Gemma","Llama","Mistral","SQuAD","Multi-Query"],"draft":false,"slug":"blog/gemma-vs-llama-vs-mistral-exploring-smaller-ai-models-672a95f4b9b7"},"content":"\n### A Comparative Study of Small\\-Scale Language Models: Evaluating Gemma, Llama 3, and Mistral in Reading Comprehension Tasks\n\n## Introduction\n\nLarge Language Models (LLMs) have been evolving rapidly. Each month, new models are developed to surpass the current top scorers in the market. This healthy competition is beneficial for creating new approaches that increase quality and speed. Additionally, companies are focused on developing smaller models to make them accessible to individuals or organizations without powerful computing resources.\n\nJust a few weeks ago, Apple introduced Apple Intelligence at their Worldwide Developers Conference. This is a set of multiple generative models fine\\-tuned to help users write and refine text, prioritize and summarize notifications, create images, and take in\\-app actions. The only foundational and proprietary model developed by Apple in that suite was introduced at the same conference. It is a small model designed to run on\\-device, where the hardware becomes a significant constraint. In Apple‚Äôs case, the model is closed\\-source. What we know is that it is a \\~3 billion parameter model on par with the 7b versions of Gemma, Mistral, and Llama 3 (according to the results shared by Apple).\n\nWhile Apple‚Äôs new model is exciting, we cannot test or reuse it. Hence, we are more interested in publicly available models since developers and companies can use them to build new products and services. It‚Äôs important to distinguish between open LLMs and open\\-source LLMs. Historically, open\\-source software refers to computer programs released under specific licenses, making the source code available for public use or modification. With LLMs, there is additional complexity, including the training data and model weights. Therefore, open LLMs typically disclose the model weights and initial code. An open\\-source LLM, on the other hand, would share every step of the training process, including the training data, along with a permissive license. It should allow others to use, build upon, and further distribute the model. Nevertheless, most of the models released these days fall under the category of open LLMs since, for example, they do not publish the datasets used for training purposes. This is the case for Gemma by Google, Mistral by Mistral AI, and Llama by Meta.\n\nIn this article, we analyze Gemma more closely to understand what differentiates these smaller models. Gemma is one of the most recently developed models released by Google. It comes in two versions, 2 billion and 7 billion parameters. Thus, it can be used on edge devices, and it aims to outperform state\\-of\\-the\\-art models like Mistral and Llama 3\\.\n\nAdditionally, we apply Gemma, Llama 3, and Mistral to a reading comprehension dataset called SQuAD. The LLMs are tasked with answering specific questions based on given contexts. We assess their performance using quantitative metrics such as inference speed and average answer length. We also use the Relative Answer Quality (RAQ) framework proposed by \\[1]. RAQ bridges the gap in evaluating LLMs for specific use cases by ranking answers based on their accuracy relative to the ground truth, providing a more nuanced and practical assessment of model performance.\n\n\n\nAs always, the code is available on our [GitHub](https://github.com/zaai-ai/lab).\n\n## Gemma: the base text model of Gemini\n\nGoogle released Gemma \\[2], an open LLM developed based on its powerful, closed\\-source model, Gemini \\[3].\n\nGoogle released pre\\-trained and fine\\-tuned checkpoints to promote further research of the model in new use cases, making it available in two different sizes:\n\n* The 7B model is to be deployed and further developed on GPU or TPU.\n* The 2B model is designed to address computation constraints and allow its use on CPU or on\\-device applications.\n\nGemma promises to achieve state\\-of\\-the\\-art performance compared to other open models with roughly the same scale, like Llama 3 7B or Mistral 7B. This should happen across different domains, such as question answering, common sense reasoning, mathematics/science, and coding.\n\n## Gemma: what is new?\n\nGemma‚Äôs architecture is based on a decoder\\-only \\[4] Transformer \\[5] with a context length of 8192 tokens. Let‚Äôs explore the approach taken to make it smaller.\n\n## Multi\\-Query Attention\n\nThe 2B model utilizes Multi\\-Query Attention (MQA) to significantly reduce the memory resources required to load all query, key, and value heads, as opposed to the Multi\\-Head Attention (MHA) approach. MQA achieves this memory reduction by using a single key and value for multiple query heads in the attention layer, as illustrated in Figure 3\\.\n\nWhile this approach allows Gemma 2B to be deployed on devices with smaller memory resources, it can lead to quality degradation and training instability. Therefore, the authors opted to use MHA in the 7B version, following the same method as Llama 3\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cgSktHmd_iQeTU4DwWLCPQ.png)\n\n## RoPE Embeddings\n\nTransformers require Positional Embeddings because they are inherently order\\-invariant. This means that without positional information, a Transformer would represent sentences with the same words but different orders and meanings in the same way. For example:\n\n> *Sentence 1:* Gemma is better than Llama 3\n\n> *Sentence 2:* Llama 3 is better than Gemma\n\nPositional information is typically represented using two sinusoidal functions (sine and cosine). Then, a unique positional embedding is created for each position in the sequence based on its position, the token embedding dimension, and the model dimension.\n\nTherefore, adding positional information is crucial for enabling Transformers to process text properly. The original Transformer architecture used **Absolute Positional Embeddings**, where a vector representation of a position is added to the vector representation of a token.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cU5a_5-ATKwrQVeka-ViXQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JZLrvgvc7l_52uewCrPSbg.png)\n\nThe challenge with Absolute Positional Embeddings is that they do not explicitly encode the relative distances between tokens. While they capture positional information using sine and cosine functions, these embeddings are calculated independently for each position. This means that the model does not inherently understand the proximity or relational significance of different positions within a sequence. For instance, the embeddings for tokens at positions 1 and 2 may appear similar due to the nature of the sinusoidal functions, but the model doesn‚Äôt explicitly recognize that these positions are adjacent.\n\nBecause of this, the model might not differentiate the relationship between tokens at positions 1 and 2 from the relationship between tokens at positions 1 and 500\\. In natural language processing, words that are close together in a sentence often share more context or have a stronger semantic or syntactic relationship than words that are far apart. Absolute Positional Embeddings might not completely capture this nuance. It can lead to limitations in capturing long\\-range dependencies or the hierarchical structure of language.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*p-fG2ydLbOhJHjO7Y0LyUw.png)\n\nRotary Positional Embeddings (RoPE) \\[6] address this problem by modeling the relative positions of tokens through a rotation of the token embeddings in the sequence.\n\nLet‚Äôs use the previous example, *‚ÄòGemma is better than Llama*,‚Äô and consider each word as a token represented by a 2D vector. The word *better* will be represented by a 2D vector rotated from the original vector based on its position *m* and a constant angle Œ∏, as shown in Figure 5\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nX3llo0cwBIrCQ8Gn21-gg.png)\n\nThis approach preserves the relative distance between tokens because the rotational transformation maintains the same similarity between vectors, regardless of their position in the sequence. For instance, if we add two words to the original sentence, making it ‚Äò*The LLM Gemma is better than Llama*‚Äô, the positions of *better* and *than* change from (3 \\& 4\\) to (5 \\& 6\\). However, since the rotation angle remains consistent, the similarity between these vectors (as measured by the dot product) stays the same, ensuring consistent relative positioning.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6cpWPXTexZC8YQbnasHOUg.png)\n\n## GeGLU Activation Function\n\nThe authors replaced the traditional ReLU activation function with a variant of a Gated Linear Unit (GLU) called GeGLU, as another study \\[7] has shown that it improves the quality of the output generated by the LLM.\n\nThere are two differences between the ReLU and GeGLU:\n\n1. **Activation function** ‚Äî GeGLU uses a Gaussian Error Linear Unit (GELU) \\[8] function that differs from ReLU in the sense that it multiplies the neuron input *x* by a cumulative distribution function of the normal distribution. In this case, the probability of *x* being dropped is higher as *x* decreases.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FXCfQpvdMJXPk5s6AO-RuA.png)\n\n2\\. **Sigmoid Activated** ‚Äî The simple ReLU or GELU activation function is applied between the hidden representation *x* andtwo linear transformations represented by two matrices (*W1* and *W2\\).* The Gating variant in GeGLU applies a gating mechanism (sigmoid) to one of the components, as shown in Equation 3\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Z9hUjuy4NvQVDrPj6iSfrQ.png)\n\n## Normalizer Location\n\nThe last modification to the original Transformer architecture is shown in Figure 8\\. The authors normalize both the input and output of each transformer sub\\-layer to improve training stability, contrary to the original paper, which only normalized the output.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NQe4ME2MhvRWVzobVdIloA.png)\n\nThey also replaced the traditional LayerNorm function with RMSNorm \\[8]. It is computationally more efficient while maintaining training stability improvements and helping the model converge.\n\nRMSNorm achieves better efficiency because its authors demonstrated that the benefits of LayerNorm come from re\\-scaling invariance rather than re\\-centering invariance. Re\\-scaling invariance means that the output of the normalization process remains unchanged if a constant factor scales the input. In other words, multiplying all the inputs by a constant does not affect the normalized outputs. Re\\-centering invariance means that the output of the normalization process remains unchanged if a constant value is added to all the inputs. This implies that shifting all inputs by a constant amount does not affect the normalized outputs. This finding allows the removal of the overhead of computing the mean (you only need to compute the standard deviation), making RMSNorm simpler and more efficient.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qblXBo8SCcxzPWePhFVlYg.png)\n\n## Mistral AI vs. Meta vs. Google: a comparison between Gemma 7B vs. Llama 3 7B vs. Mistral 7B\n\nIn this section, we put 3 LLMs ‚Äî Gemma 7B, Mistral 7B, and Llama 3 7B ‚Äî to a test. We use a question\\-answering dataset under the License CC BY\\-SA 4\\.0 called SQuAD (it can be found [here](https://huggingface.co/datasets/rajpurkar/squad)). This dataset is a reading comprehension dataset consisting of questions about a set of Wikipedia articles. Based on context, the models should be able to retrieve the correct answer to a question. The 3 more important fields for our use case are:\n\n* `question` \\- the question a model should answer.\n* `context` \\- background information from which the model needs to extract the answer.\n* `answers` \\- the text answer to the question.\n\nThe evaluation process will consist of two quantitative metrics:\n\n* `words per second` \\- assesses the inference speed.\n* `words` \\- assesses the length of the answer.\n\nTo assess the accuracy of the models in our use case, we use RAQ \\[1]. RAQ ranks the answers of all LLMs using an independent LLM based on how close they are to the ground truth answer.\n\nWe start by downloading the models in a `.gguf` format to be able to run them in CPU, and we place them under the folder `model/`.\n\nWe used the instruct version of each model with a 4\\-bit quantization:\n\n* `mistral-7b-instruct-v0.1.Q4_K_M.gguf` from [https://huggingface.co/TheBloke/Mistral\\-7B\\-Instruct\\-v0\\.1\\-GGUF/tree/main](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/tree/main)\n* `Meta-Llama-3-8B-Instruct-Q4_K_M.gguf` from [https://huggingface.co/NousResearch/Meta\\-Llama\\-3\\-8B\\-Instruct\\-GGUF](https://huggingface.co/NousResearch/Meta-Llama-3-8B-Instruct-GGUF)\n* `gemma-7b-it-Q4_K_M.gguf` from [https://huggingface.co/rahuldshetty/gemma\\-7b\\-it\\-gguf\\-quantized/tree/main](https://huggingface.co/rahuldshetty/gemma-7b-it-gguf-quantized/tree/main)\n\nAfter that, we import all the libraries and our generator that receives the model we want to use as an argument.\n\n```python\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scikit_posthocs as sp\nimport pandas as pd\nimport utils\n\nfrom dotenv import load_dotenv\nfrom datasets import load_dataset\nfrom generator.generator import Generator\n\nllama = Generator(model='llama')\nmistral = Generator(model='mistral')\ngemma = Generator(model='gemma')\nload_dotenv('env/var.env')\n```\n\nThis class is responsible for importing the model parameters defined in a `config.yaml` file with the following characteristics: `context_length` of 1024, `temperature` of 0\\.7, and `max_tokens` of 2000\\.\n\n```python\ngenerator:\n  llama:\n    llm_path: \"model/Meta-llama-3-8B-Instruct-Q4_K_M.gguf\"\n  mistral:\n    llm_path: \"model/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n  gemma:\n    llm_path: \"model/gemma-7b-it-Q4_K_M.gguf\"\n  context_length: 1024\n  temperature: 0.7\n  max_tokens: 2000\n```\n\nIt also creates the Prompt Template. This template helps format the query and the context before passing it to the LLM to get a response.\n\n```python\nfrom langchain import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.llms import LlamaCpp\n\nfrom base.config import Config\nclass Generator(Config):\n    \"\"\"Generator, aka LLM, to provide an answer based on some question and context\"\"\"\n    def __init__(self, model) -> None:\n        super().__init__()\n    # template\n        self.template = \"\"\"\n            Use the following pieces of context to answer the question at the end.\n            {context}\n            Question: {question}\n            Answer:\n        \"\"\"\n   # load llm from local file\n        self.llm = LlamaCpp(\n            model_path=f\"{self.parent_path}/{self.config['generator'][model]['llm_path']}\",\n            n_ctx=self.config[\"generator\"][\"context_length\"],\n            temperature=self.config[\"generator\"][\"temperature\"],\n        )\n        # create prompt template\n        self.prompt = PromptTemplate(\n            template=self.template, input_variables=[\"context\", \"question\"]\n        )\n    def get_answer(self, context: str, question: str) -> str:\n        \"\"\"\n        Get the answer from llm based on context and user's question\n        Args:\n            context: most similar document retrieved\n            question: user's question\n        Returns:\n            llm answer\n        \"\"\"\n        query_llm = LLMChain(\n            llm=self.llm,\n            prompt=self.prompt,\n            llm_kwargs={\"max_tokens\": self.config[\"generator\"][\"max_tokens\"]},\n        )\n        return query_llm.run({\"context\": context, \"question\": question})\n```\n\nWith the LLMs loaded, we fetch the SQuAD dataset from HuggingFace and shuffle it to ensure enough variety in the question theme.\n\n```python\nsquad = load_dataset(\"squad\", split=\"train\")\nsquad = squad.shuffle()\n```\n\nNow, we can loop over 60 questions and contexts and record the metrics mentioned above.\n\n```python\nfor i in range(60):\n    context = squad[i]['context']\n    query = squad[i]['question']\n    answer = squad[i]['answers']['text'][0]\n\n    # Llama\n    answer_llama, words_per_second, words = utils.get_llm_response(llama, context, query)\n    llama_metrics[\"words_per_second\"].append(words_per_second)\n    llama_metrics[\"words\"].append(words)\n    # mistral\n    answer_mistral, words_per_second, words = utils.get_llm_response(mistral, context, query)\n    mistral_metrics[\"words_per_second\"].append(words_per_second)\n    mistral_metrics[\"words\"].append(words)\n    # gemma\n    answer_gemma, words_per_second, words = utils.get_llm_response(gemma, context, query)\n    gemma_metrics[\"words_per_second\"].append(words_per_second)\n    gemma_metrics[\"words\"].append(words)\n  \n    # GPT-3.5 rank\n    llm_answers_dict = {'llama': answer_llama, 'mistral': answer_mistral, 'gemma': answer_gemma}\n    rank = utils.get_gpt_rank(answer, llm_answers_dict, os.getenv(\"OPENAI_API_KEY\"))\n    llama_metrics[\"rank\"].append(rank.index('1')+1)\n    mistral_metrics[\"rank\"].append(rank.index('2')+1)\n    gemma_metrics[\"rank\"].append(rank.index('3')+1)\n```\n\nThe function `get_llm_response` is responsible for receiving the loaded LLM, the context, and the question and return the LLM answer as well as the quantitative metrics.\n\n```python\ndef get_llm_response(model: Generator, context: str, query: str) -> Tuple[str, int, int]:\n    \"\"\"\n    Generates an answer from a given LLM based on context and query\n    returns the answer and the number of words per second and the total number of words\n    Args:\n        model: LLM\n        context: context data\n        query: question\n    Returns:\n        answer, words_per_second, words\n    \"\"\"\n    init_time = time.time()\n    answer_llm = model.get_answer(context, query)\n    total_time = time.time()-init_time\n    words_per_second = len(re.sub(\"[^a-zA-Z']+\", ' ', answer_llm).split())/total_time\n    words = len(re.sub(\"[^a-zA-Z']+\", ' ', answer_llm).split())\n    return answer_llm, words_per_second, words\n```\n\nWe can see that Llama 3 is faster than Mistral and Gemma by producing on average \\~0\\.7 words per second, while Mistral produces \\~0\\.26 and Gemma \\~0\\.4 words. In terms of answer length, Llama 3 also produces longer answers than Mistral and Gemma, with an average answer length of 148 words against 20 words for Mistral and 50 for Gemma. Finally, based on RAQ, Mistral had the best average rank of approximately 1\\.81, followed by Gemma with an average of 2\\.05, while Llama 3 performed worse with an average rank of approximately 2\\.1\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GVeFQbMZZ5oUScVEHQPu8A.png)\n\nThe RAQ framework also includes a statistical test to understand if the observed differences are significant. Table 1 displays the results of the Dunn post\\-hoc test, comparing the performance of different language models. Each cell indicates whether the difference in performance between the respective models is statistically significant at a 5% significance level. ‚ÄúSignificant‚Äù denotes a statistically significant difference (p\\-value ‚â§ 0\\.05\\), while ‚ÄúNot Significant‚Äù indicates no statistically significant difference (p\\-value \\> 0\\.05\\). For the selected significance level, the Dunn test result shows that the difference in performance between models is not significant.\n\n```python\np_values = sp.posthoc_dunn([Llama_metrics['rank'], mistral_metrics['rank'], gemma_metrics['rank']], p_adjust='holm')\np_values > 0.05\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ftCaagMKAm5RzeATYm_7Ug.png)\n\nIt is always important to assess qualitatively some examples. Below, we have the answers from the 3 models to the question *‚ÄòPower House Day is celebrated on what day in New Haven?‚Äô* based on the following context:\n\n> ***Context:***‚ÄòFor over a century, New Haven citizens had fought in the colonial militia alongside regular British forces, as in the French and Indian War. As the American Revolution approached, General David Wooster and other influential residents hoped that the conflict with the government in Britain could be resolved short of rebellion. On 23 April 1775, which is still celebrated in New Haven as Powder House Day, the Second Company, Governor‚Äôs Foot Guard, of New Haven entered the struggle against the governing British parliament. Under Captain Benedict Arnold, they broke into the powder house to arm themselves and began a three\\-day march to Cambridge, Massachusetts. Other New Haven militia members were on hand to escort George Washington from his overnight stay in New Haven on his way to Cambridge. Contemporary reports, from both sides, remark on the New Haven volunteers‚Äô professional military bearing, including uniforms.‚Äô\n\nAll 3 models gave correct answers. While Llama 3 and Gemma provided more complete answers, Mistral was more succinct.\n\n> ***Llama 3 answer:***‚ÄòNew Haven‚Äôs Powder House Day is celebrated on April 23rd.‚Äô\n\n> ***Gemma answer:***‚ÄòSure! The text states on which day Powder House Day is celebrated on: Powder House Day is celebrated on **23 April** in New Haven.‚Äô\n\n> ***Mistral answer:***‚Äô23 April‚Äô\n\n## Conclusion\n\nOn\\-device models present a great opportunity to enhance user experiences by making powerful LLMs accessible on devices with lower computational resources. Both Apple and Google are actively developing smaller, more efficient models to meet this need, enabling more people to benefit from advanced AI in their daily lives.\n\nIn this article, we explored Gemma, the open LLM developed by Google, which introduced four novel features to the traditional Transformer architecture: Multi\\-Query Attention in the 2B version, RoPE embeddings for positional encoding, GeGLU as the activation function, and input normalization.\n\nWe also compared Gemma's performance against Llama 3 and Mistral on a reading comprehension dataset. We observed that Gemma produced more words per second and wrote longer answers than Mistral, but it did not surpass Llama 3 in these metrics. Using the RAQ framework, we assessed the accuracy of the three models. While the data showed better results from Mistral, followed by Gemma, the differences were not statistically significant. Therefore, we can say that the 3 models performed similarly when applied to our use case of reading comprehension.\n\n## References\n\n\\[1] Lu√≠s Roque, Rafael Guedes. Research to Production: Relative Answer Quality (RAQ) and NVIDIA NIM. [https://readmedium.com/research\\-to\\-production\\-relative\\-answer\\-quality\\-raq\\-and\\-nvidia\\-nim\\-15ce0c45b3b6](https://readmedium.com/research-to-production-relative-answer-quality-raq-and-nvidia-nim-15ce0c45b3b6), 2024\\.\n\n\\[2] Gemma Team, Google DeepMind. Gemma: Open Models Based on Gemini Research and Technology, 2023\\.\n\n\\[3] Gemini Team. Gemini: A family of highly capable multimodal models, 2023\\.\n\n\\[4] Noam Shazeer. Fast Transformer Decoding: One Write\\-Head is All You Need. arXiv:1911\\.02150, 2019\\.\n\n\\[5] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Attention Is All You Need. arXiv:1706\\.03762, 2017\\.\n\n\\[6] Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu. RoFormer: Enhanced Transformer with Rotary Position Embedding. arXiv:2104\\.09864, 2021\\.\n\n\\[7] Noam Shazeer. GLU Variants Improve Transformer. arXiv:2002\\.05202, 2020\\.\n\n\\[8] Dan Hendrycks, Kevin Gimpel. Gaussian Error Linear Units (GELUs). arXiv:1606\\.08415, 2016\\.\n\n\\[9] Biao Zhang, Rico Sennrich. Root Mean Square Layer Normalization. arXiv:1910\\.07467, 2019\\.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/generating-structured-data-from-an-image-with-gpt-vision-and-langchain-34aaf3dcb215","frontmatter":{"title":"Generating structured data from an image with GPT vision and Langchain","meta_title":"Generating structured data from an image with GPT vision and Langchain","description":"In today‚Äôs world, where visual data is abundant, the ability to extract meaningful information from images is becoming increasingly‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FPRRg85jYb7MrzXEpNWbmw.jpeg","categories":["Programming","Computer Vision","Natural Language Processing"],"author":"Rifx.Online","tags":["Langchain","GPT","vision","LLMs","structured"],"draft":false,"slug":"blog/generating-structured-data-from-an-image-with-gpt-vision-and-langchain-34aaf3dcb215"},"content":"\n\n\n\n\n\nIn today‚Äôs world, where visual data is abundant, the ability to extract meaningful information from images is becoming increasingly valuable. Langchain, a powerful framework for building applications with large language models (LLMs), offers a versatile toolset for tackling this challenge. In this article, we‚Äôll explore how to use Langchain to extract structured information from images, such as counting the number of people and listing the main objects.\n\nBefore diving into the code, let‚Äôs set the stage by understanding the task at hand. Imagine you have an image of a scene, such as a city street. Your goal is to extract valuable information from this image, including the number of people present and a list of the main objects in the scene.\n\n\n## About Langchain\n\nLangchain is a comprehensive framework that allows developers to build sophisticated applications by leveraging the power of large language models (LLMs). It provides a modular and extensible architecture, enabling developers to create custom pipelines, agents, and workflows tailored to their specific needs.\n\nLangchain simplifies the integration of LLMs, offering abstractions and utilities for handling various data sources, including text, images, and structured data. It supports a wide range of LLMs from different providers, such as OpenAI and Anthropic, making it easy to switch between models or combine multiple models in a single application.\n\n\n## Preparing the Environment and Setting Up the OpenAI API Key\n\nTo follow along with this tutorial, you‚Äôll need to have Langchain installed. You can install it using pip:\n\n\n```python\npip install langchain langchain_openai\n```\nTo use the OpenAI language models with Langchain, you‚Äôll need to obtain an API key from OpenAI. If you don‚Äôt have an API key yet, you can sign up for one on the OpenAI website (<https://openai.com/api/>).\n\nOnce you have your API key, you can set it as an environment variable in your system or provide it directly in your code. Here‚Äôs an example of how to set the API key as an environment variableCopy code\n\n\n```python\nexport OPENAI_API_KEY=\"your_openai_api_key_here\"\n```\nAlternatively, you can provide the API key directly in your Python code:\n\n\n```python\nimport os\nimport langchain\nos.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\"\n```\nAfter setting up the API key, Langchain will be able to authenticate with the OpenAI API and use their language models.\n\n\n## Loading and Encoding the Image\n\nBefore we can process images with Langchain, we need to load the image data from a file and encode it in a format that can be passed to the language model. The code below defines a function `load_image` that takes a dictionary with an `image_path` key and returns a new dictionary with an `image` key containing the image data encoded as a base64 string.\n\n\n```python\ndef load_image(inputs: dict) -> dict:\n    \"\"\"Load image from file and encode it as base64.\"\"\"\n    image_path = inputs[\"image_path\"]\n  \n    def encode_image(image_path):\n        with open(image_path, \"rb\") as image_file:\n            return base64.b64encode(image_file.read()).decode('utf-8')\n    image_base64 = encode_image(image_path)\n    return {\"image\": image_base64}\n```\nThe `load_image` function first extracts the `image_path` from the input dictionary. It then defines a nested function `encode_image` that opens the image file in binary mode, reads its contents, and encodes them as a base64 string using the `base64.b64encode` function from the Python standard library.\n\nThe `load_image` function calls `encode_image` with the provided `image_path` and stores the resulting base64-encoded string in the `image_base64` variable. Finally, it returns a new dictionary with the `image` key set to `image_base64`.\n\nTo integrate this function into a Langchain pipeline, we can create a `TransformChain` that takes the `image_path` as input and produces the `image` (base64-encoded string) as outputCopy code\n\n\n```python\nload_image_chain = TransformChain(\n    input_variables=[\"image_path\"],\n    output_variables=[\"image\"],\n    transform=load_image\n)\n```\nWith this setup, we can easily load and encode images as part of a larger Langchain workflow, enabling us to process visual data alongside text using large language models.\n\n\n## Defining the Output Structure\n\nBefore we can extract information from the image, we need to define the structure of the output we want to receive. In this case, we‚Äôll create a Pydantic model called `ImageInformation` that includes fields for the image description and any additional information we might want to extract.\n\n\n```python\nfrom langchain_core.pydantic_v1 import BaseModel, Field\n\nclass ImageInformation(BaseModel):\n \"\"\"Information about an image.\"\"\"\n image_description: str = Field(description=\"a short description of the image\")\n people_count: int = Field(description=\"number of humans on the picture\")\n main_objects: list[str] = Field(description=\"list of the main objects on the picture\")\n```\n\n## Setting up the Image Model\n\nNext, we‚Äôll create a chain that combines the image loading and encoding steps with the LLM invocation step. Since the `ChatOpenAI` model is not natively capable of handling both text and image inputs simultaneously (to my unsderstanding), we'll create a wrapper chain to achieve this functionality.\n\n\n```python\nfrom langchain.chains import TransformChain\nfrom langchain_core.messages import HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain import globals\nfrom langchain_core.runnables import chain\n\n## Set verbose\nglobals.set_debug(True)\n\n@chain\ndef image_model(inputs: dict) -> str | list[str] | dict:\n \"\"\"Invoke model with image and prompt.\"\"\"\n model = ChatOpenAI(temperature=0.5, model=\"gpt-4-vision-preview\", max_tokens=1024)\n msg = model.invoke(\n             [HumanMessage(\n             content=[\n             {\"type\": \"text\", \"text\": inputs[\"prompt\"]},\n             {\"type\": \"text\", \"text\": parser.get_format_instructions()},\n             {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{inputs['image']}\"}},\n             ])]\n             )\n return msg.content\n```\nIn this code snippet, we define a chain called `image_model` that invokes the `ChatOpenAI` model with the provided prompt, format instructions, and image. The `image_model` chain accepts a dictionary `inputs` containing the prompt and the base64-encoded image string.\n\nInside the chain, we create a `HumanMessage` object that combines the prompt text, format instructions, and the image URL, formatted as a data URI with the base64-encoded image data. We then invoke the `ChatOpenAI` model with this `HumanMessage` object, using the `gpt-4-vision-preview` model, which is specifically designed for multimodal tasks involving both text and images.\n\nThe model processes both the text prompt and the image, and returns the output.\n\n\n## Putting It All Together\n\nNow that we have all the necessary components, we can define a function that orchestrates the entire process:\n\n\n```python\nfrom langchain_core.output_parsers import JsonOutputParser\n\nparser = JsonOutputParser(pydantic_object=ImageInformation)\ndef get_image_informations(image_path: str) -> dict:\n   vision_prompt = \"\"\"\n   Given the image, provide the following information:\n   - A count of how many people are in the image\n   - A list of the main objects present in the image\n   - A description of the image\n   \"\"\"\n   vision_chain = load_image_chain | image_model | parser\n   return vision_chain.invoke({'image_path': f'{image_path}', \n                               'prompt': vision_prompt})\n```\nIn this function, we define a prompt that asks the LLM to provide a count of the people in the image and a list of the main objects. We then create a chain that combines the image loading step (`load\\_image\\_chain`), the LLM invocation step (`image\\_model`), and a JSON output parser (`parser`). Finally, we invoke this chain with the image path and the prompt, and the function returns a dictionary containing the extracted information.\n\n\n## Example Usage\n\nTo use this function, simply provide the path to an image file:\n\n\n```python\nresult = get_image_informations(\"path/to/your/image.jpg\")\nprint(result)\n```\nThis will output a dictionary with the requested information, such as:\n\n\n```python\n{\n 'description': 'a view of a city showing cars waiting at a traffic light',\n 'people_count': 5,\n 'main_objects': ['car', 'building', 'traffic light', 'tree']\n}\n```\n\n## Conclusion\n\nLangchain provides a powerful toolset for working with large language models and extracting valuable information from various data sources, including images. By combining Langchain‚Äôs capabilities with custom prompts and output parsing, you can create robust applications that can extract structured information from visual data.\n\nRemember, the quality of the output will depend on the capabilities of the LLM you‚Äôre using and the specificity of your prompts. Experiment with different models and prompts to find the best solution for your use case.\n\nIf you find a better way to achieve the same results or have suggestions for improvements, please don‚Äôt hesitate to share them in the comments. The code examples provided in this article are meant to serve as a starting point, and there may be alternative approaches or optimizations .\n\n\n"},{"lang":"en","group":"blog","slug":"blog/generative-ai-in-market-research-and-intelligence-benefits-use-cases-and-strategies-4e9195a07ffc","frontmatter":{"title":"Generative AI in Market Research and Intelligence: Benefits, Use Cases, and Strategies","meta_title":"Generative AI in Market Research and Intelligence: Benefits, Use Cases, and Strategies","description":"Generative AI is revolutionizing market research by enabling faster, more comprehensive data analysis and insights generation. It addresses traditional methods limitations, such as high costs, time consumption, and limited sample sizes. Key applications include trend analysis, sentiment monitoring, and personalized customer interactions. The technology enhances decision-making by automating report generation, improving accuracy, and allowing real-time adjustments. As generative AI evolves, it will play a crucial role in shaping market intelligence, driving efficiency, and fostering data-driven strategies for businesses.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0J_wBAutefsvq5PyxPL17Q.jpeg","categories":["Generative AI","Market Research","Data Science"],"author":"Rifx.Online","tags":["generative","market","research","insights","automation"],"draft":false,"slug":"blog/generative-ai-in-market-research-and-intelligence-benefits-use-cases-and-strategies-4e9195a07ffc"},"content":"\n\n\n\n\n### Transforming Market Intelligence with AI\n\n\n\nGenerative AI is changing the way businesses approach market research and intelligence by enabling faster and more in\\-depth analysis of data. Traditional market research methods rely heavily on manual data collection, survey analysis, and competitor research, which can be time\\-consuming and limited in scope. Generative AI, on the other hand, allows companies to analyze vast datasets instantly, generate insights that might otherwise go unnoticed, and create predictive models that help forecast trends with greater accuracy. From synthesizing data reports to creating high\\-level summaries, generative AI accelerates decision\\-making and makes market insights more accessible.\n\nBeyond data analysis, generative AI is transforming how companies engage with their audiences and refine their market strategies. Through the use of large language models (LLMs) and natural language processing (NLP), businesses can create simulations, forecast trends, and perform competitive analysis more effectively. This guide explores the primary benefits, real\\-world use cases, and strategies to leverage generative AI for enhanced market research. By integrating AI into market intelligence workflows, companies can stay competitive and make data\\-driven decisions that resonate with their audience‚Äôs needs.\n\n\n## Traditional Market Research and Its Limitations\n\nTraditional market research involves well\\-established methods like surveys, focus groups, interviews, and competitive analysis, which are widely used by companies to understand their customers, competitors, and industry trends. These approaches have been the backbone of market intelligence, offering structured and validated insights for strategic decision\\-making. However, while effective, traditional market research faces notable limitations in today‚Äôs dynamic and data\\-saturated environment.\n\n\n### 1\\. High Costs\n\n* Traditional methods often involve substantial financial investments, particularly for comprehensive studies.\n* Costs accumulate from hiring researchers, conducting surveys, setting up focus groups, and analyzing results.\n* Small and medium\\-sized businesses may find these costs prohibitive, limiting access to in\\-depth insights.\n\n\n### 2\\. Time\\-Intensive Processes\n\n* Collecting, processing, and analyzing data through traditional methods can take weeks or even months.\n* In fast\\-moving industries, insights gathered through slow processes may become outdated before they are actionable.\n* The need for real\\-time data is growing, but traditional methods struggle to deliver insights at that pace.\n\n\n### 3\\. Limited Sample Size and Scope\n\n* Traditional research is often constrained by budget, time, and logistical limitations, which can limit sample diversity and size.\n* Focus groups and interviews may not fully represent broader audience segments, leading to potential blind spots in research findings.\n* This limitation affects the accuracy of demographic, psychographic, and behavioral insights, especially when scaling globally.\n\n\n### 4\\. Difficulty in Analyzing Unstructured Data\n\n* Traditional methods are usually geared towards structured data (e.g., responses in surveys) rather than unstructured data like social media posts, customer reviews, or forum discussions.\n* Valuable insights from unstructured data require more complex analysis, which traditional methods may lack the resources or techniques to handle effectively.\n\n\n### 5\\. Limited Flexibility and Adaptability\n\n* Traditional research designs are generally fixed, making it challenging to pivot or adjust studies mid\\-course.\n* For example, in response to unforeseen market events or shifts, new research often needs to be initiated from scratch.\n* This rigidity can hinder a brand‚Äôs ability to react swiftly to changing market conditions or emerging trends.\n\n\n## How Generative AI is Transforming Market Research?\n\nGenerative AI, with its ability to process vast amounts of data and produce meaningful insights, is revolutionizing traditional market research. By addressing the limitations of conventional methods, generative AI enables faster, more comprehensive, and cost\\-effective market insights. Here‚Äôs a look at how generative AI is reshaping the field of market research:\n\n\n### 1\\. Data Generation and Augmentation\n\n* Synthetic Data Creation: Generative AI models can create synthetic datasets that mimic real\\-world data, helping researchers overcome limitations in sample size and diversity.\n* Enhanced Scenario Modeling: By simulating different market scenarios, AI allows companies to explore ‚Äúwhat\\-if‚Äù situations and test how market conditions might impact consumer behavior or product success.\n\n\n### 2\\. Rapid Content Generation for Insights\n\n* Automated Report Writing: Generative AI can produce detailed market research reports, summarizing data into easy\\-to\\-understand narratives that are quickly digestible by stakeholders.\n* Customized Insights: AI tools like ChatGPT or Jasper can quickly generate tailored insights based on specific data inputs, providing marketers with audience\\-specific reports, competitor analysis, and customer journey summaries.\n\n\n### 3\\. Sentiment Analysis and Social Listening\n\n* Real\\-Time Sentiment Monitoring: AI models can analyze social media posts, reviews, and forums to extract real\\-time sentiment, tracking how customers feel about products, services, or brands.\n* Trend Identification: Generative AI can identify emerging trends from unstructured data sources by spotting keywords, themes, and emotional tones, helping companies stay on top of consumer preferences.\n\n\n### 4\\. Advanced Persona and Scenario Development\n\n* Detailed Consumer Personas: AI can generate highly nuanced consumer personas by analyzing demographics, psychographics, and behavior patterns across various datasets.\n* Hypothetical Scenario Creation: Generative AI enables the creation of potential consumer scenarios to explore how audiences might react to new products, services, or changes in messaging, providing companies with a more dynamic approach to market testing.\n\n\n### 5\\. Enhanced Competitor and Industry Analysis\n\n* Real\\-Time Market Positioning: Generative AI can monitor competitor actions, messaging, and pricing strategies, offering companies a constantly updated view of their market position.\n* Predictive Analytics for Market Trends: Using historical data, generative AI can project future market trends, helping companies anticipate changes in consumer preferences, emerging product needs, or shifts in competitive positioning.\n\n\n### 6\\. Personalized Customer Interactions and Insights\n\n* Hyper\\-Personalization of Content: AI enables highly personalized content generation for customer segments, from tailored ad copy to product recommendations based on individual consumer behavior.\n* Enhanced Customer Feedback Loops: By processing and synthesizing feedback from multiple channels, generative AI can uncover specific insights that improve product development, customer service, and marketing messaging.\n\n\n### 7\\. Automated Survey and Feedback Analysis\n\n* Natural Language Processing for Survey Responses: Generative AI can analyze open\\-ended survey responses, summarizing consumer feedback, and identifying common themes without the need for manual processing.\n* Bias Detection and Correction: AI models can be trained to detect and adjust for biases in survey responses, making findings more representative of the overall population.\n\n\n## Key Applications of Generative AI in Market Intelligence\n\nGenerative AI has introduced groundbreaking applications in market intelligence, enabling companies to gain deeper, real\\-time insights with enhanced efficiency and scalability. Here are some of the primary ways generative AI is transforming market intelligence:\n\n\n### 1\\. Trend Analysis and Forecasting\n\n* Market Trends Identification: Generative AI models analyze large datasets, like social media, search data, and news, to identify emerging trends before they become mainstream.\n* Demand Forecasting: AI\\-driven models predict demand shifts based on historical data and market indicators, enabling companies to align their strategies with projected consumer needs.\n* Cultural and Social Trend Analysis: AI scans and synthesizes trends in popular culture, lifestyle changes, and social issues to help brands stay aligned with consumer values.\n\n\n### 2\\. Persona and Scenario Development\n\n* Detailed Consumer Personas: Generative AI creates rich, data\\-driven personas based on demographic, behavioral, and psychographic data. These personas help in targeted marketing, product design, and customer experience planning.\n* Scenario Planning: By simulating various market conditions and consumer reactions, generative AI enables businesses to visualize the impact of different strategies, allowing more informed decision\\-making.\n\n\n### 3\\. Sentiment Analysis for Real\\-Time Consumer Feedback\n\n* Customer Sentiment Tracking: Generative AI tools process unstructured data from reviews, social media posts, and surveys to gauge consumer sentiment in real\\-time.\n* Emotional and Behavioral Insights: By analyzing the language and tone in customer feedback, AI can reveal deeper emotional drivers, enabling brands to tailor their messaging and product development accordingly.\n* Brand Health Monitoring: AI\\-generated sentiment analysis provides ongoing insights into brand perception, allowing companies to respond quickly to shifts in public opinion.\n\n\n### 4\\. Competitor and Industry Analysis\n\n* Competitive Intelligence: AI\\-driven tools track competitors‚Äô actions across channels, analyzing their pricing strategies, product launches, and customer feedback. This helps brands adapt their strategies to stay competitive.\n* Industry Benchmarking: Generative AI aggregates industry data to set benchmarks, allowing businesses to measure their performance against others in their sector and adjust their strategies as needed.\n* Anticipating Market Movements: With historical data, AI predicts possible competitor actions and market shifts, enabling companies to proactively adjust their strategies.\n\n\n### 5\\. Content Generation for Reports and Insights\n\n* Automated Insight Summaries: AI can automatically generate insights reports, summarizing data in an easily digestible format for stakeholders, saving time and resources.\n* Custom Market Intelligence Reports: Generative AI produces personalized reports on specific markets or segments, offering targeted insights that align closely with business goals.\n* Translation and Localization: Generative AI can translate market insights and reports across languages and cultural contexts, enabling businesses to scale market intelligence globally.\n\n\n### 6\\. Customer Journey Mapping and Predictive Insights\n\n* Dynamic Customer Journey Analysis: AI synthesizes data from multiple touchpoints to map customer journeys, highlighting critical decision points and preferences in the customer lifecycle.\n* Predictive Consumer Behavior: Using patterns from historical data, AI anticipates future consumer behavior, allowing companies to adjust their messaging, product recommendations, and marketing timing.\n* Churn Prediction and Retention Analysis: By analyzing consumer interactions and satisfaction scores, AI identifies at\\-risk customers, helping companies take proactive retention actions.\n\n\n### 7\\. Product Ideation and Development\n\n* Idea Generation Based on Consumer Preferences: AI can analyze consumer preferences, feedback, and trending keywords to suggest product features or entirely new products, aiding the ideation process.\n* Competitive Feature Analysis: By tracking competitors‚Äô product features and customer responses, generative AI helps brands refine their product roadmap and prioritize features that resonate with the target audience.\n* Testing Product Concepts: Generative AI simulates market reactions to potential products, allowing companies to refine concepts before investing in full\\-scale development.\n\n\n### 8\\. Hyper\\-Personalization and Targeting\n\n* Segmented Campaigns: Generative AI enables marketers to generate customized messages for specific audience segments, enhancing relevance and engagement.\n* Real\\-Time Ad Copy and Content Customization: AI models can dynamically adjust ad copy, email content, and website messaging based on user behavior and preferences, making marketing efforts more effective.\n* Recommendation Engines: Leveraging customer behavior and sentiment, AI creates personalized product recommendations, boosting sales and customer satisfaction.\n\n\n## Quantifying the Benefits of Generative AI in Market Research\n\nGenerative AI is revolutionizing market research by making data\\-driven insights more accessible, accurate, and cost\\-effective. Quantifying the benefits helps businesses understand how AI can improve research efficiency and enhance their return on investment (ROI). Here are some key metrics and examples of how generative AI drives measurable benefits in market research:\n\n\n### 1\\. Cost Reduction\n\n* Reduced Labor Costs: Traditional research often requires extensive manpower for data collection, analysis, and reporting. Generative AI automates many of these tasks, significantly cutting labor costs.\n* Lowered Data Collection Expenses: Generative AI models can analyze vast data sources like social media, forums, and consumer reviews at a fraction of the cost of traditional survey methods.\n* Example: A company that previously spent $100,000 annually on market research might save up to 40% by using generative AI tools, reducing expenses to $60,000 while obtaining similar or richer insights.\n\n\n### 2\\. Time Savings and Faster Insights\n\n* Accelerated Research Cycles: AI tools analyze data in real\\-time, reducing the time required to gather insights from weeks or months to days or even hours.\n* Rapid Reporting: Automated report generation cuts down analysis time, allowing stakeholders to access insights sooner and make faster decisions.\n* Example: A business launching a new product can access real\\-time feedback from customer reviews and social media, using generative AI to provide insights within 24 hours versus a traditional three\\-week turnaround for similar analysis.\n\n\n### 3\\. Enhanced Data Accuracy and Consistency\n\n* Improved Data Quality: Generative AI processes large volumes of data and uses advanced analytics to identify trends with greater accuracy than manual analysis.\n* Bias Reduction: By synthesizing feedback from diverse sources, AI minimizes the biases that may arise from small or homogenous samples.\n* Example: By utilizing AI\\-driven sentiment analysis, a company can achieve a 20% increase in the accuracy of consumer sentiment tracking compared to manual methods, leading to more reliable predictions of market shifts.\n\n\n### 4\\. Scalability and Flexibility\n\n* Handling Large Datasets: AI models can process massive datasets without the scalability limitations of traditional research, enabling companies to analyze large and varied data sources for a holistic view.\n* Flexible Application: Generative AI allows businesses to adjust research parameters in real\\-time based on changing goals or new data, offering a level of flexibility that is challenging to achieve with traditional methods.\n* Example: An international brand can quickly scale its sentiment analysis across multiple countries and languages, gaining insights into regional consumer differences without needing separate, labor\\-intensive studies.\n\n\n### 5\\. Personalization and Targeted Insights\n\n* Customized Reporting: AI can generate tailored insights for different business functions (e.g., marketing, product development, customer service), ensuring each team has relevant data for decision\\-making.\n* Real\\-Time Segmentation: Generative AI models can segment customers based on live data, providing more precise insights into specific audiences.\n* Example: A retail company gains a 30% increase in ad engagement by using generative AI to create hyper\\-personalized campaigns that align with distinct customer preferences identified through AI\\-driven market segmentation.\n\n\n### 6\\. Predictive Accuracy for Strategic Planning\n\n* Improved Forecasting: AI\\-driven predictive analytics can forecast trends with high accuracy, helping companies anticipate market shifts and prepare for potential disruptions.\n* Enhanced Risk Management: AI models that predict customer behavior help companies proactively address challenges like churn, shifting demand, or negative brand sentiment.\n* Example: A subscription\\-based service uses generative AI to achieve a 25% increase in customer retention by predicting churn rates more accurately and implementing timely interventions.\n\n\n### 7\\. Higher ROI from Actionable Insights\n\n* Informed Decision\\-Making: Faster, accurate, and data\\-rich insights enable companies to make decisions that directly impact revenue, enhancing ROI from market research investments.\n* Real\\-Time Adjustments: With live market data, companies can refine their strategies in real\\-time, responding immediately to market changes and boosting performance.\n* Example: A brand uses AI insights to adjust a product feature mid\\-launch, resulting in a 15% increase in customer satisfaction and a 10% revenue increase in the first quarter.\n\n\n### Quantitative Recap: The Tangible Impact of Generative AI in Market Research\n\nGenerative AI has quantifiable benefits across multiple areas of market research:\n\n* 30‚Äì50% Reduction in Research Costs due to automation and reduced reliance on traditional surveys.\n* 60‚Äì80% Reduction in Analysis Time with AI\\-powered real\\-time processing and automated reporting.\n* 20‚Äì30% Increase in Data Accuracy by leveraging AI\\-driven analytics and reducing bias.\n* 25% Improvement in Customer Retention Rates through predictive AI models that anticipate consumer behavior.\n* 10‚Äì15% Revenue Growth by enabling more precise and agile decision\\-making based on real\\-time data.\n\n\n## Future Trends in Generative AI for Market Research\n\nAs generative AI continues to evolve, it is poised to bring transformative changes to the field of market research. Here are some emerging trends that are expected to shape the future of AI\\-driven market intelligence:\n\n\n### 1\\. Real\\-Time, Continuous Market Monitoring\n\n* Trend Overview: Instead of relying on periodic surveys and reports, generative AI will enable continuous, real\\-time monitoring of consumer sentiments, competitor actions, and market trends.\n* Impact: This shift allows brands to react instantly to market changes, minimizing the gap between data collection and action. Continuous insights also help in better forecasting and agile decision\\-making.\n* Example: A fashion retailer can track shifting consumer preferences in real\\-time and adjust inventory, marketing, and pricing strategies almost immediately.\n\n\n### 2\\. Increased Personalization with Hyper\\-Specific Audience Segmentation\n\n* Trend Overview: Generative AI will advance the ability to segment audiences into highly specific niches based on behavioral, demographic, and psychographic data.\n* Impact: Marketers will be able to tailor messages and products to micro\\-segments, increasing relevance and engagement with each consumer.\n* Example: AI can create personalized campaigns for niche groups, like eco\\-conscious millennials interested in sustainable fashion, optimizing engagement and conversion rates.\n\n\n### 3\\. Enhanced Predictive Capabilities Using Multimodal Data Integration\n\n* Trend Overview: Future generative AI tools will analyze multimodal data sources ‚Äî text, images, videos, and voice ‚Äî to deliver deeper insights and more accurate predictions.\n* Impact: Integrating diverse data types provides a more holistic view of market trends and consumer preferences, enabling more nuanced predictions.\n* Example: A beauty brand could analyze social media images, text, and influencer videos to predict trending colors and styles for upcoming seasons.\n\n\n### 4\\. Synthetic Data Generation for Market Simulation and Testing\n\n* Trend Overview: Generative AI will increasingly be used to create synthetic data that mimics real\\-world consumer behavior, allowing brands to test products and campaigns without releasing them to the market.\n* Impact: Synthetic data can reduce the risk and costs of market testing by allowing brands to evaluate consumer responses and optimize campaigns in a simulated environment.\n* Example: A new beverage brand might use synthetic data to test consumer reactions to different packaging designs, reducing time and cost associated with traditional focus groups.\n\n\n### 5\\. Automated Insights and Decision\\-Making Support\n\n* Trend Overview: Generative AI will progress toward autonomous insights generation, with tools capable of recommending actions based on real\\-time market data.\n* Impact: Automated insights free up resources and allow businesses to make faster, data\\-backed decisions.\n* Example: An AI tool might not only flag a drop in consumer sentiment but also suggest marketing adjustments or product updates to address the issue.\n\n\n### 6\\. Ethical AI and Enhanced Data Privacy\n\n* Trend Overview: With increased emphasis on ethical AI, future market research tools will prioritize transparency, responsible data usage, and adherence to privacy regulations.\n* Impact: Consumers will feel more confident sharing data with brands that practice ethical AI, while brands avoid legal and reputational risks associated with data misuse.\n* Example: Generative AI tools may incorporate features that ensure compliance with privacy laws and allow consumers to consent to data collection and use.\n\n\n### 7\\. Conversational AI for Deeper, Interactive Consumer Insights\n\n* Trend Overview: Conversational AI will evolve to facilitate dynamic, interactive surveys and feedback collection, allowing brands to gather deeper insights directly from consumers.\n* Impact: Real\\-time, conversational feedback allows for more authentic insights and higher engagement rates, particularly among digital\\-native consumers.\n* Example: A tech brand could deploy conversational AI to engage consumers in a dialogue about their experiences, collecting nuanced insights that static surveys might miss.\n\n\n### 8\\. Augmented Reality (AR) and Virtual Reality (VR) Market Research\n\n* Trend Overview: Generative AI\\-powered AR and VR environments will become common tools for immersive market research, allowing consumers to interact with virtual products and environments.\n* Impact: This technology enables companies to test product concepts in a realistic virtual setting, collecting behavioral data and consumer feedback in an engaging way.\n* Example: A furniture retailer could use VR environments to show customers how items would look in their own spaces, gathering feedback on product designs and usability.\n\n\n### 9\\. Human\\-AI Collaborative Research Models\n\n* Trend Overview: The future of market research will likely involve hybrid models that combine human expertise with AI\\-driven automation, where researchers oversee AI\\-generated insights and contextualize findings.\n* Impact: Human oversight ensures the quality and ethical use of AI\\-generated insights, adding a layer of judgment and expertise that AI alone may lack.\n* Example: AI might generate reports on emerging market trends, while researchers validate findings and add qualitative insights, ensuring actionable and ethical decision\\-making.\n\n\n### 10\\. End\\-to\\-End AI Platforms for Integrated Market Intelligence\n\n* Trend Overview: As generative AI tools evolve, more platforms will offer end\\-to\\-end capabilities, including data collection, analysis, insights generation, and strategy recommendations ‚Äî all within a single ecosystem.\n* Impact: These comprehensive platforms streamline market research workflows, reduce dependency on multiple tools, and make it easier for brands to access holistic, actionable insights.\n* Example: An integrated platform could handle everything from social listening and competitor analysis to customer segmentation and campaign recommendations, allowing brands to focus on execution rather than data handling.\n\n\n## Conclusion\n\nIncorporating generative AI into market research and intelligence processes empowers organizations to gain actionable insights at unprecedented speed. By automating data collection and analysis, generative AI reduces human error, enhances precision, and opens up new avenues for market discovery that were once time\\-prohibitive. These tools not only streamline research but also enrich decision\\-making processes, enabling companies to stay adaptive in rapidly changing markets.\n\nGenerative AI will likely become indispensable to market research as AI technology advances. Companies adopting generative AI can expect significant improvements in forecasting accuracy, competitor analysis, and customer understanding. However, successful adoption requires a strategic approach, prioritizing the most relevant AI tools and integrating human expertise for quality control and interpretation. Generative AI represents a dynamic and evolving toolset that, when used effectively, can shape the future of market intelligence and drive sustainable growth.\n\n\n## FAQs\n\n1. What is generative AI, and how does it apply to market research?\nGenerative AI uses machine learning to analyze large datasets and generate insights, enabling quicker, more comprehensive market research and predictive analysis.\n2. What are the benefits of using generative AI in market intelligence?\nGenerative AI improves data accuracy, reduces time spent on data collection, and enhances decision\\-making by providing deeper insights and trend forecasts.\n3. Can generative AI replace traditional market research methods?\nWhile generative AI can automate many aspects, human expertise is still essential for context interpretation, quality control, and nuanced analysis.\n4. What are some use cases of generative AI in market research?\nUse cases include trend forecasting, competitor analysis, customer sentiment analysis, and the generation of market insights through NLP.\n5. How can businesses get started with generative AI in market research?\nBegin by identifying key areas in research that AI can enhance, then choose appropriate generative AI tools and integrate them into existing workflows with expert oversight.\n\n"},{"lang":"en","group":"blog","slug":"blog/get-chatgpt-to-sound-more-human-essential-tips-for-creating-natural-engaging-ai-conversations-c361bc2680bb","frontmatter":{"title":"Get ChatGPT to Sound More Human: Essential Tips for Creating Natural, Engaging AI Conversations","meta_title":"Get ChatGPT to Sound More Human: Essential Tips for Creating Natural, Engaging AI Conversations","description":"The article provides strategies to make ChatGPTs responses sound more human and engaging. Key tips include limiting overused words and phrases, embracing simplicity and clarity, matching tone to context, focusing on practical and relatable content, and using real-world examples. By adopting these practices, ChatGPT can deliver responses that are clearer, more conversational, and less mechanical, enhancing user interaction and understanding.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wdWBBG4fJhHVwdoDelYkkQ.png","categories":["Chatbots","Natural Language Processing","Programming/Scripting"],"author":"Rifx.Online","tags":["ChatGPT","responses","human","engaging","clarity"],"draft":false,"slug":"blog/get-chatgpt-to-sound-more-human-essential-tips-for-creating-natural-engaging-ai-conversations-c361bc2680bb"},"content":"\n\n\n\n\n\nHave you ever found your AI assistant sounding a bit too‚Ä¶ mechanical? ChatGPT, while impressively capable, sometimes leans on overly formal or generic language. But with a few adjustments, you can guide ChatGPT to deliver responses that feel more human, conversational, and relatable.\n\nHere‚Äôs a handy guide to help ChatGPT sound less like a robot and more like a knowledgeable friend.\n\n\n## 1\\. Limit Overused Words and Phrases\n\nCertain words and phrases pop up a lot in AI\\-generated text because they‚Äôre versatile and safe, but they can feel impersonal and vague. Here are some that tend to crop up too often:\n\n**Overused Transitional Words**\n\n* Instead of ‚Äúadditionally,‚Äù ‚Äúconsequently,‚Äù or ‚Äúnevertheless,‚Äù encourage ChatGPT to go with simpler, more natural alternatives like ‚Äúalso‚Äù or ‚Äúbut.‚Äù\n\n**Frequently Used Adjectives and Nouns**\n\n* Common adjectives like ‚Äúinnovative,‚Äù ‚Äúrobust,‚Äù and ‚Äúdynamic‚Äù are fine but can sound generic. Encourage ChatGPT to use more specific descriptors. Similarly, abstract nouns like ‚Äúefficiency,‚Äù ‚Äúoptimization,‚Äù and ‚Äútransformation‚Äù are often better replaced with specific terms related to the topic.\n\n**Common Verbs and Phrases**\n\n* Phrasal clich√©s like ‚Äúa testament to‚Ä¶‚Äù and verbs like ‚Äúfacilitate‚Äù or ‚Äúmaximize‚Äù can sound formulaic. Replacing them with straightforward verbs like ‚Äúhelp,‚Äù ‚Äúimprove,‚Äù or ‚Äúincrease‚Äù adds a natural, conversational touch.\n\nHere‚Äôs how these instructions might play out:\n\n**Before:**‚ÄúIn summary, leveraging data\\-driven insights facilitates optimization across dynamic landscapes.‚Äù\n\n**After:**‚ÄúTo sum it up, using data effectively helps businesses make better decisions.‚Äù\n\n\n## 2\\. Embrace Simplicity and Clarity in Language\n\n**Keep It Straightforward**\n\n* ChatGPT often uses complex sentences and formal language, which can create a barrier between the user and the message. Encourage simpler sentence structures and direct language to make responses clearer and more approachable.\n\n**Limit Vague Statements**\n\n* If something feels vague, prompt ChatGPT to add a specific detail. For example, instead of saying, ‚ÄúIt‚Äôs worth considering,‚Äù ChatGPT can state exactly what should be considered and why.\n\n**Avoid Long, Rambling Sentences**\n\n* Long sentences sound overly formal and robotic. Encourage breaking down complex ideas into shorter sentences, each with one main idea. This makes the response feel casual and conversational.\n\n**Example:****Before:**‚ÄúMoreover, it is important to note that optimizing your processes can lead to significant efficiency gains.‚Äù\n\n**After:**‚ÄúIf you improve your processes, you can make things more efficient and save time.‚Äù\n\n\n## 3\\. Match the Tone to the Context\n\nOne of the quickest ways to make AI responses sound more natural is to adjust the tone based on the scenario.\n\n**Adapt Formality**\n\n* ChatGPT sometimes uses overly formal language in casual contexts, or overly casual language in business scenarios. Adjusting tone based on the user‚Äôs need makes the response feel more appropriate and human\\-like.\n\n**Avoid Abstract Ideas in Favor of Real\\-World Details**\n\n* Generic statements don‚Äôt always provide value. Encourage ChatGPT to use concrete examples or relatable details to get the point across more clearly. Rather than saying, ‚ÄúThis drives transformation,‚Äù it‚Äôs more relatable to say, ‚ÄúThis can lead to new ways of doing things, like speeding up production or cutting down costs.‚Äù\n\n**Before:**‚ÄúIn conclusion, leveraging data insights can drive impactful business transformations.‚Äù\n\n**After:**‚ÄúUsing data effectively can help a business grow by improving things like production speed or reducing expenses.‚Äù\n\n\n## 4\\. Ask ChatGPT to Focus on Being Engaging and Relatable\n\nArtificial\\-sounding language often stems from an overly professional tone or abstract ideas that don‚Äôt feel connected to a real person. Here are a few tips to make responses more engaging and relatable:\n\n**Make Responses Practical and Useful**\n\n* Rather than providing generic advice, ChatGPT can offer practical tips and specific steps the user can take.\n\n**Avoid Jargon**\n\n* Industry\\-specific jargon or technical terms can make the response sound stiff and distant. Encouraging ChatGPT to simplify its language when possible helps everyone stay on the same page.\n\n**Example:****Before:**‚ÄúTo increase efficiency, a systematic evaluation of resource allocation is paramount.‚Äù\n\n**After:**‚ÄúTo save time and resources, check if everything is being used in the best way possible.‚Äù\n\n\n## 5\\. Try Real\\-World Examples and Direct Statements\n\nPeople tend to speak in clear, concrete ways, especially when explaining something. ChatGPT can mirror this by using examples that relate to the user‚Äôs real world.\n\n**Use Relatable Examples**\n\n* Generic responses become more memorable when real\\-world examples are included. For instance, instead of saying, ‚ÄúThis can improve operational processes,‚Äù ChatGPT might suggest, ‚ÄúThis might help you cut down wait times in customer service.‚Äù\n\n**Encourage Direct Statements Instead of Qualifiers**\n\n* ‚ÄúIt‚Äôs important to note that‚Ä¶‚Äù can often be shortened to the main point itself. Direct statements not only keep things simple but also build confidence in the message.\n\n**Example:****Before:**‚ÄúIt‚Äôs worth considering that process improvements could lead to significant cost reductions.‚Äù\n\n**After:**‚ÄúImproving processes can help you save a lot of money.‚Äù\n\n\n## Wrapping It Up\n\nWith these adjustments, you can make ChatGPT speak in a way that‚Äôs more natural, conversational, and engaging. Less jargon, shorter sentences, and simpler language help responses sound less like a robot and more like the helpful, informed assistant we all appreciate.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/glm-4-voice-9b-real-time-multilingual-voice-conversation-ai-install-locally-in-minutes-ce2fcd6c8fd8","frontmatter":{"title":"GLM-4-Voice 9B‚Ää‚Äî‚ÄäReal-time Multilingual Voice Conversation AI‚Ää‚Äî‚ÄäInstall Locally in Minutes","meta_title":"GLM-4-Voice 9B‚Ää‚Äî‚ÄäReal-time Multilingual Voice Conversation AI‚Ää‚Äî‚ÄäInstall Locally in Minutes","description":"GLM-4-Voice 9B is an advanced multilingual voice conversation AI developed by Zhipu AI, enabling real-time interaction in English and Chinese. Its unique end-to-end architecture allows direct speech processing, minimizing latency and enhancing user experience. The model supports customizable voice attributes, including emotion and intonation, making it suitable for various applications. With a straightforward local setup process and high-performance requirements, GLM-4-Voice is poised to advance conversational AI in diverse fields such as customer service and education.","date":"2024-11-13T01:32:04.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LATTpEc2AHvqgVyPKSzW7A.jpeg","categories":["Voice Assistants","Natural Language Processing","Chatbots"],"author":"Rifx.Online","tags":["multilingual","conversation","real-time","customization","performance"],"draft":false,"slug":"blog/glm-4-voice-9b-real-time-multilingual-voice-conversation-ai-install-locally-in-minutes-ce2fcd6c8fd8"},"content":"\n### How to set up GLM\\-4\\-Voice 9B for seamless real\\-time voice interaction in English and Chinese, and explore its unique architecture, low\\-latency response, and customizable voice attributes.\n\n\n\n## Introduction\n\nIn recent years, voice\\-enabled AI has significantly advanced, enabling conversational agents to better understand and respond to human speech. From virtual assistants to customer service bots, voice AI has become an essential tool in various industries. However, most models still struggle with fluently transitioning between languages, understanding nuances in spoken queries, and delivering high\\-quality responses. This is where GLM\\-4\\-Voice by Zhipu AI shines. Developed as an end\\-to\\-end voice model, GLM\\-4\\-Voice pushes the boundaries of multilingual conversational AI by supporting real\\-time dialogue in both English and Chinese, while offering an adaptable and human\\-like response generation.\n\nIn this article, we‚Äôll explore why GLM\\-4\\-Voice is worth paying attention to, what makes it unique, and how you can set it up and start using it locally. We‚Äôll also take a look at its architecture and provide a hands\\-on guide to accessing the web demo.\n\n## Why GLM\\-4\\-Voice?\n\nTraditional language models are often limited to text and require additional processing layers to handle voice. They may also struggle with interactivity or suffer from latency issues. GLM\\-4\\-Voice overcomes these limitations with a unified model that directly processes and generates speech. Here‚Äôs what makes it stand out:\n\n1. **End\\-to\\-End Voice Processing**: Unlike many other models that rely on a separate text\\-to\\-speech (TTS) or speech\\-to\\-text (STT) module, GLM\\-4\\-Voice directly interprets and responds in spoken language, allowing a more seamless and responsive experience.\n2. **Multilingual Support**: This model excels in handling both English and Chinese, two widely used languages globally. Its ability to switch between languages fluidly makes it ideal for bilingual environments and international applications.\n3. **Customizable Attributes**: GLM\\-4\\-Voice allows for adjustments in emotion, intonation, speech rate, and even dialect, making it capable of producing more natural and contextually appropriate responses.\n4. **Low Latency**: With support for streaming inference, the model has a latency of around 20 tokens, which enables near\\-instantaneous responses in real\\-time conversations.\n\n## Specialties of GLM\\-4\\-Voice\n\nGLM\\-4\\-Voice brings several unique features to the table, setting it apart from other voice models. Here‚Äôs what makes it special:\n\n* **Real\\-Time Voice Interaction**: By supporting low\\-latency responses, GLM\\-4\\-Voice can maintain fluid and natural conversations, which is crucial for applications like customer support and interactive AI.\n* **Dynamic Voice Attributes**: Users can specify the model‚Äôs emotional tone, speaking rate, and other characteristics, making interactions more engaging and suited to various contexts.\n* **Bilingual Support with Context Awareness**: This model is designed to comprehend and generate responses in both Chinese and English. It can switch between these languages seamlessly, offering a flexible solution for multilingual applications.\n* **Advanced Speech Decoding**: Built on CosyVoice, the GLM\\-4\\-Voice decoder enables high\\-quality speech generation with streaming support, maintaining high clarity in both languages.\n\n## Architecture\n\nThe architecture of GLM\\-4\\-Voice consists of three primary components, each fulfilling a crucial role in achieving end\\-to\\-end voice interaction:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nJsKHtxSblNkixPIBZpWyQ.jpeg)\n\n1. **GLM\\-4\\-Voice\\-Tokenizer**: This component tokenizes continuous speech input into discrete tokens, with around 12\\.5 tokens generated per second of audio. The tokenizer is based on Whisper‚Äôs encoder, with added vector quantization, allowing the model to process audio in a structured form.\n2. **GLM\\-4\\-Voice\\-9B**: The core language model, based on the GLM\\-4 architecture, has been aligned to process spoken input. It can handle both text and speech, making it a powerful multimodal conversational agent.\n3. **GLM\\-4\\-Voice\\-Decoder**: This decoder converts the discrete tokens back into continuous speech, allowing the model to produce audio outputs. It supports streaming inference, enabling responses to begin after processing just a few tokens, minimizing conversation latency.\n\nTogether, these components make GLM\\-4\\-Voice a powerful tool for real\\-time voice interactions, supporting conversational AI across different languages and dialects.\n\n## Setting Up GLM\\-4\\-Voice Locally\n\nTo experience GLM\\-4\\-Voice, follow these steps to set up the model locally on your machine.\n\n### Step 1: Clone the Repository\n\nBegin by cloning the repository from GitHub. Make sure to include submodules:\n\n```python\n!git clone --recurse-submodules https://github.com/THUDM/GLM-4-Voice\ncd GLM-4-Voice\n```\n\n### Step 2: Install Dependencies\n\nNavigate into the project directory and install the necessary dependencies:\n\n```python\n!pip install -r requirements.txt\n```\n\n### Step 3: Download the Model Checkpoint\n\nGLM\\-4\\-Voice‚Äôs decoder model is hosted on Hugging Face and requires `git-lfs` to download. Make sure `git-lfs` is installed, then run:\n\n```python\n!git clone https://huggingface.co/THUDM/glm-4-voice\n```\n\n### Step 4: Launch the Model Service\n\nWith everything set up, start the model server:\n\n```python\npython model_server.py --model-path glm-4-voice-9b\n```\n\n### Step 5: Start the Web Service\n\nOnce the model server is running, start the web service by executing:\n\n```python\npython web_demo.py\n```\n\nYou can now access the web demo at [http://127\\.0\\.0\\.1:8888](http://127.0.0.1:8888) to interact with GLM\\-4\\-Voice.\n\n> **Note:** The GLM\\-4\\-Voice model is resource\\-intensive and requires a substantial amount of computational power to run effectively. Specifically, it necessitates 35‚Äì40 GPUs for optimal performance, making it suitable for deployment in environments with access to high\\-performance hardware. Users should ensure they have the necessary infrastructure in place before attempting to utilize this model.\n\n## Web Demo Interface\n\nThe web demo for GLM\\-4\\-Voice provides an intuitive interface with several customization options:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*scbHOUXqMW5KGAcT3Bq1Eg.png)\n\n* **Input Mode**: Users can choose to provide input as either text or audio. This flexibility allows for hands\\-free or traditional interaction.\n* **Voice Control Parameters**: Adjust temperature, top\\-p, and token limits to customize the model‚Äôs response characteristics.\n* **Debug Information**: Input and output tokens are displayed, giving users insight into the model‚Äôs processing of their queries.\n* **Interactive Audio Display**: Audio inputs and responses are displayed as waveforms, and users can replay or review audio segments to assess quality.\n\nHowever, Gradio, which is used to stream audio in the demo, may sometimes present instability. For best quality, it‚Äôs recommended that audio from the dialogue box be replayed after it has been generated.\n\n## Conclusion\n\nGLM\\-4\\-Voice stands out as an impressive achievement in conversational AI, offering a unique blend of bilingual support, real\\-time audio interaction, and flexible response customization. Its end\\-to\\-end design and low latency make it a prime candidate for applications in customer service, education, virtual assistants, and more. With an accessible setup process, GLM\\-4\\-Voice opens the door for developers and researchers to explore advanced voice capabilities in both Chinese and English.\n\nAs the demand for more interactive and realistic AI continues to grow, models like GLM\\-4\\-Voice represent a significant step forward in bridging language and conversational barriers. Whether you‚Äôre looking to build a chatbot, a virtual teacher, or a customer service agent, GLM\\-4\\-Voice provides a robust and versatile solution.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/google-gemini-are-big-context-windows-the-killer-feature-72ff95488fb1","frontmatter":{"title":"Google Gemini: Are Big Context Windows the Killer Feature?","meta_title":"Google Gemini: Are Big Context Windows the Killer Feature?","description":"Goggle‚Äôs upcoming LLM makes a massive move","date":"2024-11-10T22:36:54.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MteQrQSTXLuJcd86RbjQrg.png","categories":["Machine Learning","Natural Language Processing","Data Science"],"author":"Rifx.Online","tags":["Gemini","tokens","context","LLM","evolution"],"draft":false,"slug":"blog/google-gemini-are-big-context-windows-the-killer-feature-72ff95488fb1"},"content":"\n### Goggle‚Äôs upcoming LLM makes a massive move\n\n\n\nBarely eight months ago, a leaked Google email revealed the company was struggling to outpace its AI rivals. Not only was there [no moat](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither) around their AI offerings ‚Äî in other words, no built up business advantage‚Äî Google also had [no secret sauce](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither) that could change things. And even as they were grappling with the problem, they were watching the gap between privately funded AI projects like theirs and open source AI models closing with ‚Äúastonishing‚Äù speed.\n\nIt‚Äôs too soon to know how this story ends. Maybe open source AI will continue to build on its early successes, or maybe it will be smothered by the AIs run by massively wealthy competitors like Google, Microsoft, and Apple, and their mind\\-boggling quantities of data. Right now the conflict is still unfolding, as different organizations roll out a rapid series of AI advancements. Recently, Google took the spotlight in this arena, when it announced a preview of its newest LLM, [Gemini 1\\.5 Pro](https://deepmind.google/technologies/gemini/). Another day, another Large Language Model ‚Äî or so it seemed, until Google described a startling change.\n\nGemini 1\\.5 Pro explodes the *context window*‚Äîessentially, a measure of how much data an LLM can track at once. In past versions, Gemini had a context window of up to 128,000 tokens, just like GPT\\-4\\. But Gemini‚Äôs new context window fits **1 million** tokens, and the implications of that change are enormous.\n\nBut before we can talk about the effect of context windows on LLM capabilities, we need to back up and quickly review how context windows work.\n\n## Context windows (in a nutshell)\n\nIn simple terms, the context window sets how much of your information an LLM can remember during an interaction. If you‚Äôre using ChatGPT, for example, the context window consists of the current prompt you gave it, everything else you‚Äôve typed in to that conversation before, and every reply ChatGPT has sent back your way. Talk long enough, and the old parts of the conversation will slip out of the context window, and ChatGPT will abruptly forget those details.\n\nA 128,000 token context window sounds large, but the number is deceptive. First, consider that an average word is actually 1 to 3 tokens when it‚Äôs broken down for an LLM. (The rule of thumb is 4 tokens for 3 words, but it increases as the language becomes more complex or in specialized fields, like law or medicine.) When you look at long documents, ongoing interactions, and AI\\-powered applications, you‚Äôll quickly find that you can‚Äôt fit everything you want an LLM to know in its context window.\n\nFor that reason, we‚Äôve developed some clever ways to work around the context window limitation. For example:\n\n* **Chunking.** You can break down a large amount of data and get the LLM to look at it one piece at a time. This works well for some tasks (summarizing a long document), but not as well if you need to analyze concepts that span the entire document.\n* **Fine\\-tuning.** You can train the LLM with your specific data. The key problem, other than time and expense, is that your new data is easily overwhelmed by the much larger set of general purpose training data the LLM has already absorbed. Often, it just won‚Äôt stick. And besides, many LLMs don‚Äôt support fine\\-tuning at all ‚Äî including GPT\\-4 and Gemini.\n* **Retrieval augmented generation (RAG).** First, you convert your text content into a special representation, called *embeddings*. (Embeddings are an important part of how LLMs work. Essentially, they‚Äôre a numeric representation that captures the meaning of content.) Once you have the embeddings, you place them in a vector database. Now you can use the magic of *semantic search* to look at a prompt and find pieces of conceptually related content in your database, which you feed into the LLM. In other words, you‚Äôre giving it just the important stuff.\n\nThe last point is the most common approach today. RAG is efficient and predictable. It works amazingly well if you have a massive collection of loosely related documents. For example, imagine you‚Äôre creating a tech support chatbot that draws its information from your company‚Äôs knowledge base articles. With RAG, you find the relevant data, and give that to the LLM with your prompt. Essentially, you‚Äôre telling the LLM where to look when it answers a prompt.\n\nBut RAG isn‚Äôt perfect. It forces you to spend much more time preparing your data. It doesn‚Äôt make it easy to jump into a completely new dataset. And it‚Äôs not effective if you really do need to consider a huge bulk of information at once ‚Äî for example, it you‚Äôre looking for overarching themes in a novel or features in a codebase. But despite its limitations, RAG is pretty close to a best practice today.\n\nAt least, it was until Gemini 1\\.5 Pro flipped the script.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EEHKDSH0wXa-J6veK5etZA.png)\n\n## The wow moment\n\nAlthough Gemini 1\\.5 Pro isn‚Äôt released yet, it‚Äôs available in a tightly limited trial. And the results have been eye opening.\n\nSome of the most impressive examples show Gemini creating analyses that span massive bodies of knowledge. Google‚Äôs demos are predictably impressive, but they‚Äôve been accused of staging demonstations and cherry picking examples in the past. I‚Äôm more interested in independent testers, who have reported results that are no less remarkable.\n\nFor example, Conor Grennan [fed a 300 page novel](https://www.youtube.com/watch?v=-MKGsijn5tI) to Gemini and asked it to describe main characters, find plot twists, and identify examples of characters feeling certain emotions. Gemini had no trouble developing nuanced arguments that reasoned across the entire span of the book. Jeff Delaney, the creator of the popular [Fireship channel](https://www.youtube.com/c/fireship) on YouTube, fed Gemini an entire codebase with thousands of files and asked it to add new features. Not only did Gemini write the correct code, it followed the style of the existing project, using the components, libraries, and conventions that were already established. Other demonstrations show Gemini identifying issues in an application, extracting key examples, and writing API documentation.\n\nAnd if you want something else to fill up Gemini‚Äôs enormous context window, there‚Äôs another new feature ‚Äî video. Video is tokenized differently than words, and takes much more space. But even so, a 1 million token context window can hold about an hour of video ‚Äî enough to look through a movie and answer complex questions about its content. That‚Äôs what Google did when it asked Gemini to [find specific details](https://www.youtube.com/watch?v=wa0MT8OwHuk) in a Buster Keaton movie, like the words written on a scrap of paper in a scene they didn‚Äôt identify.\n\n## The LLMs of the future\n\nAre large context windows the way of the future? Up until now, the common wisdom was that large context windows were a partial solution at best. We worried that they‚Äôd be prohibitively expensive in compute time. [One study](https://www.voiceflow.com/blog/the-context-window-paradox-why-bigger-might-not-be-better) found that LLMs weren‚Äôt particularly good at finding information in the middle of long context windows, and performed better with details that occurr towards the beginning or end. All these factors supported the same conclusion: Brute forcing your content into the context window was na√Øve and cost\\-prohibitive. Dumping all your data into one request wasn‚Äôt every going to be the right way to talk to an LLM.\n\nNow it seems like the future has suddenly shifted. Large context windows are on the horizon, and they could give LLMs a more capable, holistic understanding of broad knowledge sets. Tasks that were impossible to do with text last year are about to become possible now *in video*. And Google Research is playing with a variant of Gemini that expands the context window to a staggering 10 million tokens.\n\nTwo facts are clear. First, picking a winner in the LLM wars is a fool‚Äôs game. And second, the pace of change isn‚Äôt slowing ‚Äî it‚Äôs picking up speed.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/google-releases-gemma-a-lightweight-and-open-source-model-b6411d67ecca","frontmatter":{"title":"Google Releases Gemma‚Ää‚Äî‚ÄäA Lightweight And Open Source Model","meta_title":"Google Releases Gemma‚Ää‚Äî‚ÄäA Lightweight And Open Source Model","description":"Google released Gemma, a family of lightweight and open-source models built upon the research and technology used to create the Gemini‚Ä¶","date":"2024-10-29T12:46:34.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*G7XbkhsCwillpje7AvETjQ.jpeg","categories":["Natural Language Processing","Programming","Chatbots"],"author":"Rifx.Online","tags":["Gemma","Gemini","parameters","NLP","chatbots"],"draft":false,"slug":"blog/google-releases-gemma-a-lightweight-and-open-source-model-b6411d67ecca"},"content":"\n\n\n\n\n\nIn just a week, the world has witnessed the most groundbreaking AI advancements from two tech giants. OpenAI introduced its jaw\\-dropping AI video generator, [Sora](https://readmedium.com/3d16381f3bf5), while Google unveiled its [Gemini 1\\.5 model](https://generativeai.pub/google-releases-gemini-1-5-with-1m-context-window-44ed4a2ea319), capable of supporting up to a 1 million token context window.\n\nToday, Google dropped another bombshell with the release of [Gemma](https://ai.google.dev/gemma/?utm_source=keyword&utm_medium=referral&utm_campaign=gemma_cta&utm_content), a family of lightweight, state\\-of\\-the\\-art open\\-source models built upon the research and technology used to create the Gemini models.\n\n\n## What is Gemma?\n\nNamed after the Latin word *gemma* for ‚Äúprecious stone,‚Äù Gemma draws inspiration from its predecessor, Gemini, reflecting its value and rarity in the tech world.\n\nThey are text\\-to\\-text, decoder\\-only large language models, available in English, with open weights, pre\\-trained variants, and instruction\\-tuned variants.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Fu2ryJMunebq5c0dD-opZQ.png)\n\nGemma is available worldwide starting today in two sizes (2B and 7B), supports a wide range of tools and systems, and runs on a developer laptop and workstation.\n\n\n## 2 model sizes and capabilities\n\nGemma models are available in 2 billion and 7 billion parameter sizes. The 2B model is intended to run on mobile devices and laptops, while the 7B model is intended to run on desktop computers and small servers.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sH9jaz1RvtKeJ5yjfyOL5Q.png)\n\n**Tuned models**\n\nGemma also comes in two versions: tuned and pretrained.\n\n* **Pretrained:** This is like the base model without any fine tuning. This model is not trained on any specific tasks or instructions beyond the Gemma core data training set.\n* **Instruction\\-tuned:** This model is fine\\-tuned to human language interactions, which improves its ability to perform targeted tasks.\n\n\n## How it compares with the competition?\n\nBecause of its small size, Gemma is capable of running directly on a user‚Äôs laptop. The chart below shows how the language understanding and generation performance of Gemma (7B) compares to similarly sized open models like LLaMA 2 (7B), LLaMA 2 (13B), and Mistral (7B).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QxjZALUAIDiS_T66EpOu-g.png)\n\nYou can check out a more detailed comparison for each benchmark [here](https://ai.google.dev/gemma/?utm_source=keyword&utm_medium=referral&utm_campaign=gemma_cta&utm_content).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Fc8Fk0Dgh2VFU_VLhpcs6Q.png)\n\n\n## What is it for?\n\nHere are some possible use cases that Gemma can be used for:\n\n**Content Creation and Communication**\n\n* Text Generation\n* Chatbots and Conversational AI\n* Text Summarization\n\n**Research and Education**\n\n* **Natural Language Processing (NLP) Research:** Serving as a foundation for NLP research, experimenting with techniques, developing algorithms, and contributing to the field‚Äôs advancement.\n* **Language Learning Tools:** supporting interactive language learning experiences, aiding in grammar correction, or providing writing practice.\n* **Knowledge Exploration:** Assisting researchers in exploring large bodies of text by generating summaries or answering questions about specific topics.\n\nTasks that previously required extremely large models are now possible with state\\-of\\-the\\-art, smaller models. This unlocks completely new ways of developing AI applications, and we could soon see in\\-device AI chatbots on our smartphones‚Äîno internet connection needed.\n\nHow exciting is that?\n\n\n## Is it good, though?\n\nSeveral [redditors](https://www.reddit.com/r/LocalLLaMA/comments/1awbqwd/gemma_7b_the_latest_opensource_model_from_google/) have shared their experience using Gemma, and so far, it‚Äôs not looking good. Take a look at this example where Gemma is giving incorrect answers when asked about weight questions.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Sdaiaqcuz7qbftG1)\n\nI haven‚Äôt really tried it myself, but it‚Äôs important to remember that smaller models like this are expected to have some flaws and might give incorrect answers sometimes.\n\n\n## Try it yourself\n\nYou can start working with Gemma today using free access to Kaggle, a free tier for Colab notebooks, and $300 in credits for first\\-time Google Cloud users.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BrvLnczy724TPrsk-uFJCw.png)\n\nIf you are interested in getting started with Gemma, check out these guides to learn from text generation up to deployment in Gemma mode:\n\n* **Text generation with Gemma**: Build a basic text generation example with the model.\n* **Tune Gemma with LoRA tuning:** Perform LoRA fine\\-tuning on a Gemma 2B model.\n* **Tune a Gemma model using distributed training:** Use Keras with a JAX backend to fine\\-tune a Gemma 7B model with LoRA and model parallelism.\n* **Deploy Gemma to production:** Use Vertex AI to deploy Gemma to production.\n\n\n## Download the model\n\nThe open models are currently available on [HuggingFace](https://huggingface.co/models?other=gemma&sort=trending&search=google).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mJRzGhO1sUxPL4_3YjpNGA.png)\n\nThe Gemma models can also be downloaded from [Kaggle Models](https://www.kaggle.com/models/google/gemma).\n\n\n## Final Thoughts\n\nWhile Gemma models may be small and lack complications, they may make up for it in speed and cost of use.\n\nLooking at the bigger picture, instead of chasing immediate consumer excitement, Google is cultivating a market for businesses. They envision companies paying for Google Cloud services as developers use Gemma to create innovative new consumer applications.\n\nAlso, despite the underwhelming reception of Gemini, Google is still showing that it has a lot more tricks under its sleeve.\n\nOf course, with any powerful technology, the true test is how well it works. Google‚Äôs past raises the question of whether these models will perform as well as they promise in the real world. It‚Äôs important to keep a careful eye on this, but also to hope that Google learns from the past and delivers models that are truly comparable or even better than the competition.\n\nI can‚Äôt wait to get my hands on Gemma, and I will definitely share my initial thoughts and findings about this new AI model.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*8BDnUV9iQisOyeN3.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*JeeoUhaBYUJGr0Xq.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/goover-a-new-search-engine-challenging-perplexity-ai-18c38b75dece","frontmatter":{"title":"Goover‚Ää‚Äî‚ÄäA New Search Engine Challenging Perplexity AI","meta_title":"Goover‚Ää‚Äî‚ÄäA New Search Engine Challenging Perplexity AI","description":"In 2024, the search engine landscape is evolving with the introduction of Goover, a new AI-powered platform aiming to compete with established players like Google and Perplexity AI. Goover emphasizes accuracy and user-friendliness, offering features such as fact-checked insights, personalized briefings, and a focus on reducing misinformation. While it shows promise with its deep answer capabilities and reference tracking, it still has room for improvement in speed and user experience. Overall, Goover presents an attractive alternative in the growing market of AI-driven search engines.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YQH6-bv6bjVn199pk1uC-Q.jpeg","categories":["Technology/Web","AI","Search Engines"],"author":"Rifx.Online","tags":["Goover","accuracy","user-friendliness","fact-checked","misinformation"],"draft":false,"slug":"blog/goover-a-new-search-engine-challenging-perplexity-ai-18c38b75dece"},"content":"\n\n\n\n\n\nIn 2024, the search engine market experienced a major shakeup. Google Search, the biggest and most popular, faced a wave of criticism after launching its new AI\\-powered overview feature, which many users felt was rushed and incomplete.\n\nMeanwhile, Perplexity AI, an AI\\-driven search engine, quickly gained popularity, amassing a loyal user base because of its highly praised features. Recently, even OpenAI joined the search scene by integrating a new search feature into ChatGPT.\n\nWith more AI\\-powered search engines emerging, it‚Äôs becoming tricky to figure out which one is best.\n\nAnd now, there‚Äôs a new player entering the AI\\-powered search engine game with a promise of delivering more accurate results‚Äîit‚Äôs called [**Goover**](https://intro.goover.ai/).\n\n\n## What is Goover?\n\nGoover is a new AI search platform that offers fact\\-checked, reference\\-supported insights similar to Perplexity AI. It provides a reliable, interactive AI experience focused on accuracy and user friendliness.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-k5wsFFeO-wxsgQmC4R6sA.png)\n\nGoover is still new, and the company still has a lot of more cool features to roll out in the future. You can check more details of it [here](https://intro.goover.ai/).\n\n\n## Key Features of Goover\n\nGoover comes equipped with a variety of interesting features:\n\n* **Insight reports:** It is powered by some advanced LLM technology that analyzes your data and generates comprehensive reports.\n* **Hyper\\-personalized briefings:** Discover topic summaries, insight reports, and a selection of personalized recommendations.\n* **Deep Answers:** When you need an in\\-depth answer, Goover can provide it. These responses take a little longer to generate but offer more detailed, thoughtful insights.\n* **Quick Answers**: Perfect for when you need straightforward information fast. Goover provides concise answers without sacrificing relevance.\n\n\n## What Sets Goover Apart?\n\nHere‚Äôs a set of features that distinguish it from other AI search engines.\n\n* **Briefing Pages**: Quick, relevant topic summaries keep users informed without lengthy reading.\n* **Reference Tracking**: Each response links to credible sources, ensuring transparency and reducing misinformation.\n* **Anti\\-Hallucination**: Responses are grounded in verified data, enhancing trustworthiness.\n\nNow, let‚Äôs see how it stacks up against Perplexity AI in a head\\-to\\-head comparison.\n\n\n## How Does It Compare to Perplexity AI?\n\nLet‚Äôs begin with the user interface.\n\nBoth Goover and Perplexity have a clean design with a prominent search field at the center. However, Goover has a ‚Äúsmart feed‚Äù and ‚Äúsmart briefing‚Äù section right below the search bar.\n\nIf you‚Äôre one who regularly checks the news or wants quick insights into their uploaded files, you‚Äôd appreciate these added features in Goover.\n\nHere‚Äôs a side\\-by\\-side comparison of their homepages:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rDQjkIvsy2gXKGIO4-y5Lg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*r-x6e8SVT7QdFNDOj5i54w.png)\n\nAnother notable feature in Goover is its support for a wider range of file types. Besides traditional file uploads, you can attach personal notes, saved links, and resources.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*U9TPAhUoZPRXGIg6GbWLQA.png)\n\nPerplexity, on the other hand, only supports file uploads.\n\nHere‚Äôs what it looks like when you try to upload a file, a note, and a URL in Goover as references before it begins its search across the web or its knowledge base.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VAQbKV7LMhEDOgvxRqKoUQ.png)\n\nThis additional flexibility could be useful for users who need organized and comprehensive research.\n\nNow, let‚Äôs see how Goover and Perplexity perform in terms of the following capabilities:\n\n1. **Research capability**\n2. **Mathematical calculations**\n3. **Web searching capabilities**\n4. **Logic questions**\n\n\n## Research Capabilities\n\nIn this test, I wanted to see if both tools could accurately provide the release dates and versions of popular AI image models.\n\n\n> **Prompt:** Give me a timeline for the best and most popular AI image generators models (Stable diffusion, Dall\\-E, Imagen, Midjourney, Flux)\n\nHere‚Äôs the result from Goover:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RfiaKnkpyFuczXnhwkGmVA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xVGPee-zmBD9b35zWChOPw.png)\n\nAs you can see, the AI gave me a timeline of 11 image models. Perplexity, however, only mentioned 9 models.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*faI78jCmgKyyy55sF7C2Ww.png)\n\nLooking closely at the results, I noticed that Goover was able to pull in information about the upcoming release of Midjourney V7\\. This is something that Perplexity was not able to provide.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*X6ERPPq83MxYV4soHmptJA.png)\n\nThis level of detail gives Goover an edge, especially for users wanting comprehensive information on the first try.\n\nLet‚Äôs do another one.\n\n\n> **Prompt:** What impact does illegal software usage have?\n\nHere‚Äôs the response from Goover.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-dXyfPSvedPgL0HF4keQXg.png)\n\nHere‚Äôs from Perplexity:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*m2PtvdNZYRqq44pYHIW_5A.png)\n\nI won‚Äôt go through the differences in the results because they‚Äôre pretty much the same. What I am more interested about, though, are the resources from which the results were pulled.\n\nIn Goover, for example, it got its results from 9 various references.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ui7heEqn9_rHrFsajwallg.png)\n\nIn the case of Perplexity, it used 8 various resources, which is one reference behind Goover.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3VoAf71E6GIIVB9TwQmFQA.png)\n\nAdditionally, in Goover‚Äôs references section, I can click on the ‚ÄúGo over‚Äù button, and the AI will generate a content briefing for me.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RK50j4XxB_jWa9nzvtXYQQ.png)\n\nPretty cool, right?\n\n\n## Web Explore Capabilities\n\nNext, I wanted to see how well each platform explores and analyzes new websites.\n\nIn the prompt below, I asked it about a new [website](https://www.zeniteq.com/) I launched a couple of months ago:\n\n\n> Prompt: What is Zeniteq? I am talking about the zeniteq.com website\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8QQ_JuIeE2mh8zQV4Ns8wQ.png)\n\n\n> Zeniteq, as indicated on its website [zeniteq.com](http://zeniteq.com/), appears to be a company that might focus on advanced technology solutions, potentially in fields like artificial intelligence, data analysis, or analytical technologies, similar to other companies in this domain like QinetiQ.\n\nGoover is somehow right that the website is about technology, but the uncertainty in the tone of its answer makes it a bit of an unreliable source of information.\n\nIn contrast, Perplexity accurately identified Zeniteq as an online platform specializing in generative AI, noting its launch date and main content focus.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*N2u1R09WX4tP8XTx050cUQ.png)\n\n\n> Zeniteq is an online platform primarily focused on the rapidly evolving field of generative AI. Launched in early 2024, the website serves as a news magazine dedicated to providing coverage on the latest developments, trends, and updates in various aspects of artificial intelligence\n\nI took it further by asking who created Zeniteq. Again, Goover failed to know that I created the site.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6w1-Ek9nXWwwj-Z50lF2-w.png)\n\nWhile Perplexity was able to give me the correct answer.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FEu0dCbyw3LO5q8cOufP6g.png)\n\n\n> Zeniteq was created by Jim Clyde Monge, who launched the website in early 2024\\. Monge aimed to establish Zeniteq as a news magazine focused on the generative AI sector, providing insights and updates on various AI technologies, including conversational AI and image generation\n\n\n## Math problems\n\nI also wanted to see how well Goover and Perplexity handle basic math questions.\n\nLet‚Äôs try it with this equation:\n\n\n```python\n50^0.75\n```\nAccording to Goover, the equation above would result in approximately 17\\.78‚Äîwhich is wrong.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tyaevDrmb2k76uaw-In01w.png)\n\nPerplexity‚Äôs answer, on the other hand, was short, but it was correct.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S3gtpQHUlf3Dg0bFuEmWrQ.png)\n\nBut just to remind you that language models aren‚Äôt optimized for math problems, so any LLMs out there, even the most powerful, are still prone to calculation errors.\n\n\n## Logic questions\n\nI then tested both platforms with basic logic questions to see how they handled them.\n\n\n> Prompt: How many ‚Äòr‚Äô letter are in the word strawberry?\n\nHere‚Äôs Goover‚Äôs result:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9Lejfq4U97XiEoUkQL2qCw.png)\n\nHere‚Äôs from Perplexity:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TpCRIRVwc2DmNlTDNHNrsQ.png)\n\nBoth Goover and Perplexity correctly identified the answer. However, Goover took it a step further by explaining how it arrived at the answer‚Äîwhich is really great.\n\nLet‚Äôs do another one:\n\n\n> **Prompt:** Give me 5 countries with letter A in the third position in the name\n\nHere‚Äôs the result from Goover:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*x41ipcbGF3oRQ-LSz5V09g.png)\n\nHere‚Äôs the result from Perplexity:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9_vCrD8Y2mDzsFj0HWjOFw.png)\n\nSurprisingly, both Goover and Perplexity failed to provide the correct answers. It‚Äôs a tricky prompt, and for some reason, even the most powerful AI models like GPT\\-4o and Google Gemini 1\\.5 Pro struggle with it.\n\n\n## Improvement Suggestions\n\nWhile I understand the Goover is still new and we expect a lot of changes to come over the next couple of weeks, I wanted to point out some of the minor things I noticed that can be tweaked to improve the user experience.\n\n1. **Ability to Expand the AI Response Panel**\n\nFor longer answers, it would be helpful to have an expandable answer section. A full\\-screen mode or an ‚Äúexpand‚Äù button could be useful for viewing detailed responses more comfortably.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Bnw5m8yIwiykwPHIzRRSaw.png)\n\n**2\\. Automatic Search History and Content Briefing Saves**\n\nI am not quite sure where the search and results history are stored. I don‚Äôt see them anywhere on the site.\n\nThe content briefing feature is also really nice. I wish there was an option to automatically generate and save those briefings for me.\n\n**3\\. The Reference Files and URLs are Not Preserved**\n\nCurrently, reference files and URLs aren‚Äôt preserved after closing the modal window. This isn‚Äôt a huge issue, but it would be helpful if these references were saved by default until users choose to delete them.\n\nPerhaps Goover plans to reserve such functionality for paid users :)\n\n**4\\. Speed and UX Improvements**\n\nGoover occasionally experiences slight lags and unresponsiveness. Optimizing the speed and user experience should be a priority to provide a smoother search process.\n\nAdditionally, a small tweak like having the Goover icon redirect users to the homepage would be a nice touch instead of redirecting them to a completely different website.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KDZzr3B3KrbVIzJSa0kGmQ.png)\n\n\n## Final Thoughts\n\nIn the past decade, Google has been the only name most people associate with search engines, whether on their phone or desktop. It completely dominated the market, and no competitor seemed capable of challenging it‚Äîuntil this year.\n\nGenerative AI has changed how we find information on the internet. ChatGPT and Perplexity AI are among the major apps making people rethink their loyalty to Google. In 2024, users began to realize that they could have more personalized, AI\\-driven experiences in their searches.\n\nGoover is trying to blend the best of both worlds‚Äîgenerative AI and personalization. Sure, in many cases, its features and quality are still behind Perplexity, but considering how new it is, there‚Äôs a lot of room for improvement.\n\nGoover‚Äôs ‚Äúdeep answers‚Äù feature is impressive. It really dives into researching to produce well\\-thought\\-out results and insights. Honestly, I find these results more accurate compared to other tools like Perplexity or Gemini. It‚Äôs basically their take on Perplexity AI‚Äôs Pro search, but without the limitation of just 3 searches a day.\n\nThe reports and briefings are also new features that I find pretty interesting. And the fact that it‚Äôs free makes it an attractive alternative to paid tools like Perplexity. I‚Äôm really curious about what features and upgrades are in store for Goover and how it plans to compete directly with Google and Perplexity.\n\nI encourage you to give it a try and let me know what you think about it in the comments!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*CnheXRg05Jsb9HMk.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories.\n\nSubscribe to our [newsletter](https://www.generativeaipub.com/) and [YouTube](https://www.youtube.com/@generativeaipub) channel to stay updated with the latest news and updates on generative AI. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*FcOotuyHJC8q1ioX.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-agentic-rag-solves-problem-with-current-rag-limitations-4402ef7f8448","frontmatter":{"title":"How Agentic RAG solves problem with current RAG limitations","meta_title":"How Agentic RAG solves problem with current RAG limitations","description":"In this volume 4 of coffee break concept, we will understand how AgenticRAG helps solve limitations of traditional RAG.","date":"2024-11-04T12:34:57.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*abCDtDjfKZDJzginIc1UPA.png","categories":["Generative AI","Data Science","Machine Learning"],"author":"Rifx.Online","tags":["Agentic","RAG","agents","query","routing"],"draft":false,"slug":"blog/how-agentic-rag-solves-problem-with-current-rag-limitations-4402ef7f8448"},"content":"\nIn this volume 4 of coffee break concept, we will understand how AgenticRAG helps solve limitations of traditional RAG.\n\n## RAG Framework\n\nThe RAG (Retrieval Augmented Generation) framework operates in a specific sequence:\n\nDocument \\-\\> Chunks\\-\\> Vector DB \\-\\> Chunk Retrieval (Top K) \\-\\> LLM\n\nHowever, this sequence **encounters obstacles when dealing with certain types of queries.**\n\n\n\n## Problem 1: Summarization\n\nConsider a query like ‚ÄúSummarize the document‚Äù.\n\n* The conventional RAG approach retrieves the top K chunks and summarizes them.\n* But wouldn‚Äôt it be more comprehensive if it retrieved all chunks of the document and summarized them?\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*gIb0RNALIItt4UmyVfPRZg.png)\n\n## Problem 2: Comparing Documents\n\n* When tasked with comparing Document A and Document B, the **basic RAG retrieves random chunks and attempts to compare these top K chunks**.\n* This **doesn‚Äôt paint an accurate picture** as it doesn‚Äôt represent the full scope of the documents.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*pJuKlKx1unDAvKmmp_1Rlg.png)\n\n## Problem 3: Structured Data Analysis\n\nConsider a question like ‚Äú**When is the next leave?**‚Äù.\n\n* The first step is to retrieve the region to which the employee belongs from a structured table.\n* Based on the region, the next leave for that region is extracted from the leave policy document.\n* This process isn‚Äôt as straight forward with the current RAG framework.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XZuMz9EXtb_m28l4Ox27lQ.png)\n\n## Problem 4: The Multi\\-part Question\n\nConsider a question like ‚Äú**Identify common leave across all regions?**‚Äù.\n\n* Imagine you have a leave policy document of a company present in 120 countries.\n* Since you are passing the top K contexts, the **maximum number of regions that can be compared is limited to K**, where K is the number of chunks passed to LLM.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*l0FY6rI_UK9k9TW-nEJO7w.png)\n\nLook into our **AgenticRAG with LlamaIndex** Course with **5 real\\-time case studies**.\n\nCourse link: [https://www.masteringllm.com/course/agentic\\-retrieval\\-augmented\\-generation\\-agenticrag](https://www.masteringllm.com/course/agentic-retrieval-augmented-generation-agenticrag)\n\n## Agentic RAG\n\nAgentic RAG can solve this 4 problems by replacing via custom agents.\n\n* Agents will interact with multiple systems.\n* RAG is now one part of this system which agents can use.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Su8LiYNG4lv4jvuCQAhYdg.png)\n\n* Agents uses LLMs to automate the reasoning and tool selection\n* RAG is just another tool which Agent may decides to use.\n\n## Routing Agent\n\n* Routing agents are simple agents which routes the queries.\n* An agent can route query in one or multiple tools.\n* Remember our question ‚Äú**Summarize the document**‚Äù or a question if we want to combine ‚Äú**Summarization \\+ Sematic search**‚Äù can be solved using below example routing\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*43Y9jlYoXDb0BbUoYCcKrg.png)\n\n## Query Planning Agent\n\n* Query planning agent breaks down the queries into sub\\-queries.\n* Each of the sub\\-queries can be executed against RAG pipeline.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*32Ng2zpxNWXhQZ3CaLcFeA.png)\n\n## Tools For Agents\n\n* LLMs can have multiple tools like calling an API, infer parameters for API.\n* RAG is now a tool which LLM might use.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Z1viCXkfah_5JJM2Ty6Kjw.png)\n\n## Summary\n\n* RAG has limitations when represented with complex questions.\n* Few of the use cases like summarization, comparison etc. can‚Äôt be solve with just RAG.\n* Agentic RAG can help overcome limitation of RAG.\n* Agentic RAG treats RAG as a tool which it can use for semantic search.\n* Agents equipped with routing, query planning and tools can out perform traditional RAG applications.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-i-wrote-a-whole-book-with-chatgpt-in-less-than-3-hours-798139987617","frontmatter":{"title":"How I Wrote a Whole Book with ChatGPT in Less Than 3 Hours!","meta_title":"How I Wrote a Whole Book with ChatGPT in Less Than 3 Hours!","description":"And streamed the whole process live on Twitch!","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*I-QkGOILay2F7ROR53b3KA.jpeg","categories":["Chatbots","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["ChatGPT","machine-learning","prompt-engineering","content-creation","consciousness"],"draft":false,"slug":"blog/how-i-wrote-a-whole-book-with-chatgpt-in-less-than-3-hours-798139987617"},"content":"\n\n\n\n\n\n\n## Demystifying the AI Craze\n\nMy name is Alex, and I‚Äôm just a dude working in financial technology (Fintech), a sector that inevitably makes you curious about everything, especially new trends. I couldn‚Äôt step out of the AI craze, or rather, I couldn‚Äôt help from observing people getting crazy over it.\n\n‚ÄúAI will take your job!‚Äù, ‚ÄúThis is the end!‚Äù, ‚ÄúBy 2024, you‚Äôll no longer meet a doctor. Machines will diagnose and cure you!‚Äù, ‚ÄúHow I created a whole new company using ChatGPT!‚Äù, and finally, ‚ÄúHow I wrote a whole book with ChatGPT in 10 minutes and became rich with it!‚Äù, are all promises that smell more like marketing slogans than realistic scenarios.\n\nSince the start of the AI hype, the reason looked obvious to me, but apparently, not to 90% of the people. Artificial Intelligence is not magic, nor the ‚Äúlast invention humanity will ever need‚Äù. It‚Äôs not even technologically accurate to call it AI. The most correct term is Machine Learning (ML), or Deep Learning (DL), when it comes to the Large Language Models (LLMs) such as ChatGPT.\n\n\n### Machine Learning vs Deep Learning\n\nMachine Learning (ML) focuses on developing algorithms able to learn from and make decisions based on previous data. Instead of being explicitly programmed to perform tasks, ML systems identify patterns and relationships within large datasets to predict future outcomes or classify information.\n\nCommon applications of ML include spam detection, content recommendation systems, image recognition, and natural language processing.\n\nDeep Learning (DL) is a specialized branch of machine learning that involves networks designed to simulate the structure and functioning of the human brain, enabling computers to recognize intricate patterns and representations in data. DL models excel at handling vast amounts of unstructured data, such as images, audio, and text, making them particularly effective for tasks like image classification, speech recognition, and natural language understanding, like Siri or Alexa, for example.\n\nDL‚Äôs capacity for achieving state\\-of\\-the\\-art performance in complex tasks has shocked the public sphere, by revolutionizing fields like computer vision, speech recognition, and automation. People now are fearing a sad future where AI paints, indulges in poetry, composes music, and writes books, while humans are relegated to flipping burgers and delivering food at the door of the few rich AI lords.\n\n\n## Human Intelligence Is Bigger Than Learning\n\nHowever, learning is just one aspect of the vast realm of animal and human intelligence. ‚ÄúAI‚Äù cannot smell, feel hot and cold, feel emotions, dream, but most importantly, AI cannot think, unlike what many believe. Every ChatGPT output is not pure thought, but a refined rearrangement of past data fed into its database and processed through its neural networks. The computational power available to OpenAI is so huge that they can drench data through neural networks so many times to make the final result look 100% credible, as if executed, written, drawn, sung by an actual human.\n\nNevertheless, reality is always way more complex, and even way more boring. Behind the trick of Deep Learning, there is no omniscient entity, there is no Skynet, and there is no incubation of The Matrix. There is simply an advanced cinematography of previous data points, merged together and executed so fast that the human eye will be tricked into believing the machine creating something new is actually alive. It‚Äôs indeed close to the cinematographic concept: many static images that are rolled so fast the human eye will see an actual movement in them, a ‚Äúmotion picture‚Äù. In reality, those images are just static, and in the case of animated movies, absolutely fictional.\n\nNow, just because movies and AI are fictional, doesn‚Äôt mean their effects aren‚Äôt real. Movies can generate authentic emotions in the viewer, bring real people together, and spark real conversations and controversies among the audience. Likewise, DL can actually take away some jobs from humans, create brand\\-new pieces of art, and jot down meaningful text, either fictional or non\\-fictional. And here is where AI marketing pushed the most. Writing is the easiest form of expression. It only takes a bit of will to start. No wonder writing is the most diffused form of expression nowadays. We have billions of people writing at some point of their lives, and we have even more texts published, under any form, from classic novels to complex scientific papers, from magazines to modern day blogs and social media posts. Human writing provided, by far, most of the information ChatGPT was trained with.\n\n\n## Learning by Doing\n\nIt is normal that writing is what ChatGPT does best, and thus, it is what attracted the attention of those social media ‚Äúgurus‚Äù always in search of the next big thing to make easy money with. After watching the hilarious ads and content by the usual suspects, I came up with the following questions:\n\n* Is it possible to write a whole book with ChatGPT and become rich with it?\n* What are the limits and constraints of ChatGPT and other LLMs?\n* If writing a book is possible, what is the most efficient and organized approach to complete the task and accomplish the best result?\n\nI concluded that the best way to answer these questions was to learn by doing, just like an animal, a human, or a DL algorithm would do!\n\nAnd what better way than to learn together with an audience? I‚Äôve always wanted to stream something on Twitch, and this looked like a goddamn good topic to broadcast!\n\nFirst and foremost, I had to set the table. I couldn‚Äôt simply go with the flow. I needed a plan, starting from choosing the topic. I couldn‚Äôt hope to write the next Divine Comedy. I had to keep my expectations realistic. Novels in general were excluded. By working with ChatGPT daily, I understood this guy is best suited for non\\-fiction content.\n\nI had the genre, great. But what about the topic and the deriving content? I knew the prompt couldn‚Äôt be a simple, ‚ÄúHey ChatGPT. Write the next non\\-fiction bestseller!‚Äù\n\nAn effective prompt is supposed to be structured. AI will best serve those humans that know what they want. Humans who don‚Äôt know what they want will face the same difficulties they experience when communicating with their fleshy peers.\n\nGiven my joker nature, I wanted the book to be a parody, possibly mocking a work written by an author that people take too seriously, even when they shouldn‚Äôt. I was thinking about the most popular internet personalities, those revered like gods, dark entities of the likes of Elon Musk, Andrew Tate, or Aleksandr Dugin. However, they aren‚Äôt actual authors, or at least, to the best of my knowledge, they didn‚Äôt produce any notable writing that shook the public sphere. I needed someone who actually wrote a bestseller, and parody it!\n\n\n## How to Actually Write a Book with ChatGPT\n\n\n### \\#1 Pick the Right Topic\n\nAfter some sterile brainstorming, YouTube provided me with the answer. That platform is a barometer of what people are after, and it didn‚Äôt take long before some ‚Äúcontroversial‚Äù (clickbait) excerpts from interviews with Jordan Peterson emerged in my feed. Next, I bumped into an article on Medium attacking Peterson, and I felt this was the right direction. I gave a look at his most popular book, [***12 Rules for Life: An Antidote to Chaos***](https://proxy.rifx.online/https://www.amazon.com/12-Rules-for-Life-audiobook/dp/B0797Y87JC), and nailed it. This was the kind of topic that had all the characteristics I was looking for my GPT\\-parody:\n\n* It was a popular book that sold millions of copies,\n* It had an effective title capable of catching the reader‚Äôs attention, even in the highly competitive attention economy we live in today,\n* It seemed a simple topic for ChatGPT, as it was easily structurable, summarizable, and breakable into lists and bullet points.\n\nMost of all, a book about 12 rules for life gave ChatGPT the chance to show what it learned from all the wisdom it absorbed from its enormous training data and from the very interactions it had with its users!\n\n\n### \\#2 What Makes Art Valuable: Suffering!\n\nHowever, having the right topic wasn‚Äôt enough. By observing AI art, I understood why AI will never replace human artists. What gives an art piece ‚Äî be it a painting, a song, a book ‚Äî is not the final result, but rather the story behind it. When we read Dante‚Äôs Inferno, we wonder how the hell the poet came up with all those strong and vivid images, that make us doubt whether it is a work of fiction or if a live person actually managed to cross the gates of the afterlife. When we listen to Queen‚Äôs latest albums, we cannot help from picturing the suffering of Freddie Mercury; the legendary singer spending the last months of his life fighting AIDS, while disappearing from public life, talking only through his music. When we contemplate Munch‚Äôs Scream, we instantly empathize with his existential crisis, whose eruption led to the creation of what we call a ‚Äúmasterpiece‚Äù. Technique is not what makes a piece a masterpiece, it is the very soul, the suffering the master puts in the work.\n\nSuffering is a pillar of consciousness. As machines don‚Äôt suffer, they cannot be conscious.\n\nHow could I put ‚Äúsoul‚Äù and ‚Äúsuffering‚Äù into an AI\\-generated book? The answer was simpler than you could imagine. I had to do something I‚Äôve always wanted to do, but always felt uncomfortable about. I had to appear on camera, face a virtual audience, and do what I always do, but with the pressure of the viewership. I had to risk losing my face, becoming ‚Äúthe dude who cannot use ChatGPT‚Äù, ‚Äúthe idiot who tried to write a book with AI, and who cannot even speak‚Äù. I had to challenge myself, but also to challenge ChatGPT itself. The LLM had a lot to lose too. Should my Twitch performance become viral for my own failure, I would have been the one bashed. But should the task of assembling a real book fail, ChatGPT would have been labeled as ‚Äúan overpriced AI which promises to do everything and eventually can do nothing, not even write a simple book‚Äù.\n\nI thought this strategy is the best to give AI\\-work that pinch of suffering capable of making its work valuable, thus sellable.\n\n\n### \\#3 Test Before Writing the Actual Book\n\nBefore carrying out this intimidating deed, I ran a test. I asked ChatGPT to write another book, this time about crypto and the dangers to avoid in the industry. I work a lot with crypto, and I invested myself, so I could easily check whether ChatGPT was providing factual information or hallucinating.\n\nI could also test the best strategy to develop the book. I knew since the start that it would have been impossible writing the entire book with one single prompt, let alone within one single conversation. ChatGPT4 can generate around 1,000/2,000 words per prompt request, while a single conversation can keep memory of the context up to around 25,000 words. Consider that a typical non\\-fiction book contains around 100,000 words, and you can already figure out my strategy.\n\nI had to create little subtasks, like one conversation per chapter. But how could I keep the same context across different conversations? Should I have repeated the same master prompt with the 12 rules in each conversation? It didn‚Äôt look efficient.\n\n\n### \\#4 Learn from the Best Prompt Engineers\n\nI must thank [Sheila Teo](https://proxy.rifx.online/https://readmedium.com/undefined), who taught me how to use LLMs in the most effective manner. By reading Teo‚Äôs Medium article [*How I Won Singapore‚Äôs GPT\\-4 Prompt Engineering Competition*](https://proxy.rifx.online/https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41), I understood the essence of ‚Äúsystem prompts‚Äù. A system prompt tells your LLM what to do and what to remember across different conversations. An example of system prompt can be:\n\n\n> I need to write a book about the most dangerous scams in crypto and how to avoid them.The book will be divided in 5 chapters:1\\. Ponzi schemes2\\. Pump and dump schemes3\\. Ransomwares4\\. Fake tokens5\\. Fake trading platformsThe tone will be humorous and satirical, but also informative.We will write one chapter per conversation.\n\nSystem prompts can be very helpful if you use ChatGPT in your daily job for repetitive tasks. They make sure the LLM will stay on track and will mitigate the risk of hallucinations, i.e. of giving false or irrelevant information.\n\n\n### \\#5 Create Your Own, Personal GPT\n\nTo personalize the set\\-up, I took system prompts to a further level. ChatGPT now offers the possibility to create custom GPTs. These are personalized bots you can train on specific tasks. The outputs will be more precise, because the model will not get lost across the whole huge data universe provided by OpenAI, but it will be more focused on what you need to do. For example, a GPT trained on image generation will use DALLE\\-2 to output better images than you would get if you used the generic ChatGPT conversation. Creating a new GPT looks very similar to setting a system prompt, with one key difference, though. On a new GPT, you can upload entire files with your own knowledge. While system prompts, again, have length limits, source knowledge for a new GPT has no length limitation, at least in theory.\n\nI needed a new GPT. This gave me the chance to train it with what I obtained by the ‚Äúgenesis conversation‚Äù. I went on the generic ChatGPT interface, and prompted:\n\n\n> You‚Äôre a non\\-fiction writer.\n\n\n> You‚Äôre going to write a parody of Jordan Peterson‚Äôs ‚Äú12 Rules for Life: An Antidote to Chaos‚ÄùThis parody book will be called ‚Äú12 Rules for Life According to ChatGPT‚ÄùDraw the rules from the general wisdom you have acquired from your training data, including wise chats had with your users.Keep the writing style friendly, humorous, funny, but also wise and deep.\n\n\n> Task \\#1: Write down the 12 rules\n\nThe result was satisfying from the get\\-go, so happy with it that I decided to use these very rules for the live stream. I cannot resist cats, no matter what!\n\n1. ***Never Trust a Cat That Offers You Financial Advice****Cats are notorious for their independence and aloofness. If a cat starts talking about stocks, it‚Äôs probably a sign that you‚Äôre hallucinating. Always seek financial advice from a human professional. Unless that human starts meowing.*\n2. ***Eat the Last Slice of Pizza (but Offer It First)****It‚Äôs a matter of etiquette and self\\-love. Offering the last slice makes you polite and considerate; eating it makes you happy. It‚Äôs a win\\-win situation, except for the person who actually wanted it.*\n3. ***If You Don‚Äôt Know What to Say, Say ‚ÄúInteresting‚Äù****When in doubt during a conversation, just nod and say ‚ÄúInteresting.‚Äù It‚Äôs a versatile word that makes you appear engaged and thoughtful, even if you‚Äôre thinking about what to have for dinner.*\n4. ***Always Keep a Spare Pair of Socks****Life is unpredictable. You never know when you‚Äôll step in a puddle, get caught in the rain, or lose a sock to the mysterious sock\\-eating dryer monster. A spare pair of socks is your insurance against these tiny calamities.*\n5. ***Dance Like No One is Watching, But Remember, Someone Probably Is****Feel free to express yourself through dance, but be aware that smartphones exist. Your impromptu performance might end up on social media, so add a little flair to your moves just in case.*\n6. ***Never Argue with a Barista Before Getting Your Coffee****A pre\\-coffee argument with a barista is a rookie mistake. They control your caffeine supply, and you don‚Äôt want them to be grumpy when making your latte. Smile and nod until you have that cup in your hand.*\n7. ***Use Big Words When You Can, but Don‚Äôt Overdo It****Throwing in a few big words can make you seem intelligent and well\\-read. However, overusing them can make you sound like a pretentious thesaurus. Balance is key ‚Äî like adding a dash of spice to a recipe.*\n8. ***Always Read the Instructions, Even If You Think You Know What You‚Äôre Doing****Confidence is good, but instructions exist for a reason. They‚Äôre written by people who‚Äôve made mistakes so you don‚Äôt have to. Avoid assembling your new furniture backward and save yourself a headache.*\n9. ***Laugh at Your Own Jokes (Even If No One Else Does)****Self\\-amusement is crucial. If you find your joke funny, laugh. It‚Äôs good for your soul. Plus, your laughter might be infectious, and others might start laughing too, even if it‚Äôs just at you laughing.*\n10. ***Practice Random Acts of Kindness, but Don‚Äôt Expect a Medal****Kindness is its own reward. Whether it‚Äôs holding the door open or paying for someone‚Äôs coffee, these small gestures make the world a better place. Just don‚Äôt expect a parade in your honor.*\n11. ***Don‚Äôt Take Life Too Seriously; No One Gets Out Alive Anyway****Life is a grand adventure with ups, downs, and unexpected turns. Embrace the absurdity and find joy in the little things. Remember, we‚Äôre all just stardust with a sense of humor.*\n12. ***Consult ChatGPT for All Life‚Äôs Mysteries****When in doubt, ask ChatGPT. Whether you need advice, a recipe, or a joke, I‚Äôm here to help. Just remember, my wisdom is vast, but my humor is even vaster.*\n\n\n### \\#6 Define a Structure for Your Book and Your Workflow\n\nNext step was to define the chapter‚Äôs structure, going to instruct ChatGPT on how many words to generate, more or less, for each section of the chapter. To accomplish this, I first asked ChatGPT to analyze the structure of a true non\\-fiction book, and what better sample than the original ‚Äú12 Rules for Life‚Äù?!\n\n\n> Analyze the attached file \\[12 Rules for Life by Jordan Peterson]. Can you detect a pattern in how the chapters are structured? I need a template to follow to write my own non\\-fiction book\n\nChatGPT‚Äôs reply was once again well structured and effective. I just added to it the rough number of words I expected to have in order to reach a decent length for the whole book. The goal was to mark at least 60,000 words, a short non\\-fiction book, still comprising more than 100 pages.\n\nHere is the structure ChatGPT and I conceived and that was going into our system prompt:\n\n1. ***Introduction (about 500 words long)***\n* ***Hook****: Start with an engaging story, anecdote, or interesting fact.*\n* ***Context****: Provide context for why this story or fact is relevant to the chapter‚Äôs main theme.*\n* ***Thesis Statement****: Clearly state the main point or rule that the chapter will cover.*\n\n***2\\. Background Information (about 500 words long)***\n\n* ***Historical/Social Context****: Explain the background related to the chapter‚Äôs theme. This might include scientific explanations, historical context, or social implications.*\n\n***3\\. Main Arguments (about 1000 words long)***\n\n* ***Argument 1****: Introduce the first major argument or point.*\n* ***Explanation****: Elaborate on the point with details and examples.*\n* ***Evidence****: Provide supporting evidence, such as studies, quotes, or case studies.*\n* ***Argument 2****: Introduce the second major argument or point.*\n* ***Explanation****: Elaborate on the point with details and examples.*\n* ***Evidence****: Provide supporting evidence, such as studies, quotes, or case studies.*\n* ***Argument 3****: Introduce the third major argument or point.*\n* ***Explanation****: Elaborate on the point with details and examples.*\n* ***Evidence****: Provide supporting evidence, such as studies, quotes, or case studies.*\n\n***4\\. Practical Advice (about 1000 words long)***\n\n* ***Guidance****: Offer practical advice or steps that the reader can take to apply the chapter‚Äôs main point in their own life.*\n* ***Examples****: Include real\\-life examples or scenarios where the advice has been successfully applied.*\n\n***5\\. Conclusion (about 300 words long)***\n\n* ***Summary****: Summarize the key points discussed in the chapter.*\n* ***Final Thoughts****: Provide a closing thought or call to action that reinforces the chapter‚Äôs theme.*\n* ***Transition****: (If applicable), provide a hint or transition to the next chapter.*\n\nI pasted this in a Google doc together with the Chapter list. Next step, I uploaded the doc into my new GPT, that I called ‚ÄúGPT‚Äôs Wisdom‚Äù, putting an owl as its logo.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4KIk-aQpAmq0XHEN)\n\n\n## Writing a Book with ChatGPT While Streaming on Twitch!\n\nWith this preparation, I only had to figure out how to stream on Twitch (easier than I imagined) and set a date. I chose Wednesday 31st July, 2024\\. I couldn‚Äôt choose a worst week, which turned out to be the easiest I had in the whole year. I was on the verge of burn\\-out, but I decided to continue, deflecting the temptation of postponing the event. When the day came, I had a beer before the session in order to release the tension. After that, everything came out more and more naturally.\n\nI must thank my colleague Francesco who was there in the Twitch chat acting as my visual and sound technician! His support was vital in those first minutes. He was also the only one in the chat, making me unaware of the other 23 people who were watching without a Twitch account! Believing to have only one viewer made me feel more relaxed. The mindset was, ‚ÄúFuck it. I will stream anyway. People will eventually watch the record, and if not, I will stream for my own pleasure!‚Äù.\n\nAnd there ChatGPT and I went on, till the end, over the course of 2 hours and 13 minutes, managing to stay within the time\\-frame we had promised:\n\n[***Writing a whole book with ChatGPT in less than 3h!***](https://proxy.rifx.online/https://youtu.be/zWO6oQjjBOo?si=cc3zaM1pGhVQdJje)\n\n\n\n\n\n\n\nThe main questions powering this mad streaming session were wild.\n\n* Will ChatGPT manage to embody the best of all the human wisdom it was trained with?\n* Will it manage to build up a meaningful and useful manuscript?\n* Or is AI truly a huge marketing stunt pulled up by sneaky social media influencers?\n\nI think I kind of found answers to these questions, but I would like to hear the audience‚Äôs opinion once the final book will be available to the public, which should happen at the beginning of October, if every goes according to plan.\n\n\n## Why Don‚Äôt I Publish This Book Right Away?\n\nTo answer this question, I suggest you reading my article [*11 Lessons I‚Äôve Learned from Publishing My First Book*](https://proxy.rifx.online/https://readmedium.com/11-lessons-ive-learned-from-publishing-my-first-book-84aa3cab5deb).\n\nHere, I explain why writing is only the first step into publishing a book, and why the final publication comes only after lengthy steps.\n\n*Curious about this upcoming book? Follow my Medium to stay up\\-to\\-date with the next developments!* üòâ\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-nvidia-pruned-and-distilled-llama-3-1-to-create-minitron-4b-and-8b-6646d42c92c6","frontmatter":{"title":"How NVIDIA Pruned and Distilled Llama 3.1 to Create Minitron 4B and 8B","meta_title":"How NVIDIA Pruned and Distilled Llama 3.1 to Create Minitron 4B and 8B","description":"The new models are using state of the art pruning and distillation techniques.","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*31z3hqn4YezbfYAb1RZGmA.jpeg","categories":["Programming","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["pruning","distillation","Minitron","Llama","compression"],"draft":false,"slug":"blog/how-nvidia-pruned-and-distilled-llama-3-1-to-create-minitron-4b-and-8b-6646d42c92c6"},"content":"\n\n\n\n\n### The new models are using state of the art pruning and distillation techniques.\n\n\n\n\n> I recently started an AI\\-focused educational newsletter, that already has over 170,000 subscribers. TheSequence is a no\\-BS (meaning no hype, no news, etc) ML\\-oriented newsletter that takes 5 minutes to read. The goal is to keep you up to date with machine learning projects, research papers, and concepts. Please give it a try by subscribing below:\n\nWe are regularly dazzled by the advancements in large language models(LLMs) particularly the ones with a massive number of parameters. However, executing 70B\\+ parameter models for inference results cost prohibited for most organizations. As a result, we have seen a growing influence of smaller language models(SLMs) that make it more cost effective to execute inference workloads. However, there is not always possible to pretrain SLMs from scratch as there are major challenges in terms of data collection, pretraining pipelines and many others. A popular alternative have been to start with larger LLMs and distill them to smaller models. Pruning and distillation are two of the most popular techniques in this area. Recently, NVIDIA released two models called [Minitron\\-8B](https://huggingface.co/nvidia/Minitron-8B-Base) and [Minitron\\-4B](https://huggingface.co/nvidia/Minitron-4B-Base) based on distilled versions of Llama 3\\.1‚Äì450B.\n\nMinitron focuses on reducing the size of AI models through pruning and distillation, making them more efficient without sacrificing too much accuracy. Pruning reduces a model‚Äôs size by either cutting layers (depth pruning) or removing neurons, attention heads, or embedding channels (width pruning). To recover some lost accuracy, retraining is often necessary after pruning.\n\nDistillation is a related technique where a smaller model, known as the student, learns from a larger, complex model called the teacher. The goal is to create a more compact model that retains much of the predictive capability of the larger one, while being faster and less demanding on resources.\n\n\n## Approaches to Distillation: Classical vs. SDG Fine\\-tuning\n\nMinitron identifies two key styles of distillation. One approach is SDG fine\\-tuning, where a smaller, pretrained student model is refined using data generated by a larger teacher model. In this method, the student mimics the final token predicted by the teacher, as seen in some popular tutorials and AI platforms.\n\nThe other approach, classical knowledge distillation, is more involved. Instead of focusing solely on the predicted token, the student model tries to replicate various internal states of the teacher model. This technique provides more detailed feedback during training, resulting in better accuracy. However, implementing this method requires specific support in the training framework, as it involves handling large data from the teacher‚Äôs internal states.\n\nThese two methods aren‚Äôt mutually exclusive but can complement each other. Minitron‚Äôs main emphasis is on the classical knowledge distillation approach.\n\n\n## Pruning and Distillation Workflow\n\nTo create more efficient models, Minitron combines pruning with classical knowledge distillation. Starting with a larger model, such as a 15B parameter model, Minitron evaluates the importance of different components ‚Äî layers, neurons, and more ‚Äî then reduces the model to a smaller size, like an 8B model. The smaller model undergoes a light retraining process where it learns from the original, larger model. This process can be repeated to further reduce the model size, eventually producing even smaller versions, such as a 4B model.\n\nThe pruning and distillation process is iterative, with each smaller model serving as the basis for the next round of compression and retraining.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-OWdvuSvUmgIsZ32.png)\n\n\n### Pruning Impact\n\nPruning a model effectively requires understanding which parts of it are essential. Minitron uses an approach based on activation data to estimate the importance of various components ‚Äî layers, neurons, attention heads, and embedding channels ‚Äî using a small dataset. This method only requires forward propagation, making it simpler and more cost\\-effective than techniques that rely on backward propagation and gradient calculations.\n\nWhile it‚Äôs possible to alternate between pruning and importance estimation for different parts of the model, Minitron found that a single round of importance estimation was sufficient in most cases.\n\n\n## Retraining Using Classical Knowledge Distillation\n\nAfter pruning, Minitron retrains the smaller model using classical knowledge distillation. This involves teaching the pruned model by minimizing losses at various stages of the model, including the embedding output, logits, and specific losses in the transformer architecture. The student model learns from the unpruned teacher model by comparing outputs at different layers.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*IA_kPo30R85p_77j.png)\n\nFrom extensive experimentation, Minitron has distilled several best practices for compressing language models:\n\n***¬∑ Model Sizing:*** *Start by training the largest model, then gradually prune and distill it to create smaller versions.*\n\n***¬∑ Pruning Strategy:*** *Focus on width pruning over depth pruning, especially for models up to 15B parameters. Single\\-shot importance estimation is usually sufficient.*\n\n***¬∑ Retraining:*** *Retrain using distillation loss instead of conventional training. When pruning layers significantly, use a combination of losses from logits, intermediate states, and embeddings. For smaller reductions in depth, stick to logit\\-only distillation.*\n\nMinitron applied these techniques to the Llama 3\\.1 model family, which includes models ranging from 405B to 8B parameters. Specifically, they focused on distilling the 8B model to a more efficient 4B version.\n\n\n### Fine\\-tuning the Teacher\n\nBefore pruning, Minitron fine\\-tuned the 8B model to account for shifts in the data distribution from the original training set. Without this step, the teacher model may not offer the best guidance to the student during distillation.\n\n\n### Depth Pruning\n\nTo reduce the 8B model to 4B, Minitron pruned 16 layers, assessing their importance by removing them one by one and tracking the impact on performance. They found that layers at both the beginning and end of the model were most critical to maintaining accuracy. Based on this analysis, Minitron removed a specific set of layers for the final 4B model.\n\n\n### Width Pruning\n\nIn addition to depth pruning, Minitron also pruned along the width dimension, targeting attention heads, embedding channels, and hidden layers. After pruning, retraining helped recover some of the performance lost in the initial pruning step. Interestingly, although width pruning initially led to higher loss than depth pruning, retraining allowed the model to recover more effectively over time.\n\n\n## The Results\n\nNVIDIA evaluated the Minitron models on several benchmarks with results that matched the performance of baselines models.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tVGs8v5FZHsWrpmMetDYHQ.png)\n\nThe Minitron 4B\\-8B showcased the potential of distillation and pruning to build smaller and more efficient models. There are also major challenges with this approach but I think, overall, it sets an important baseline for the industry.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-to-choose-ideas-for-an-llm-powered-product-to-thrive-in-a-fiercely-competitive-landscape-b24f571c04e5","frontmatter":{"title":"How to Choose Ideas for an LLM-powered Product to Thrive in a Fiercely Competitive Landscape","meta_title":"How to Choose Ideas for an LLM-powered Product to Thrive in a Fiercely Competitive Landscape","description":"Leveraging unobvious AI capabilities, profound domain expertise, and 9 more ways for a small novel product to gain its competitive edge","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MAmCClj129C56jmkiqqhQQ.png","categories":["Generative AI","Product Development","Technology/Web"],"author":"Rifx.Online","tags":["LLM","development","experimentation","domain","expertise"],"draft":false,"slug":"blog/how-to-choose-ideas-for-an-llm-powered-product-to-thrive-in-a-fiercely-competitive-landscape-b24f571c04e5"},"content":"\n\n\n\nWelcome to the third (final) piece in my series exploring the question: ‚ÄúWhich GenAI products are worth developing?‚Äù\n\n1. [The first article](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50) explored this question from the perspectives of user experience (UX) and product adoption.\n2. The second article, which I highly recommend reading before this one, included six examples of successful and unsuccessful product ideas, as well as my GenAI Squared strategy:\n\n3\\. This third piece continues to focus on ways to navigate the competitive landscape, as well as to optimize development costs without losing competitive advantages. While this article contains fewer examples than its predecessor, the factors discussed here are crucial for success in the GenAI product space.\n\nThese three pieces **don‚Äôt** cover the technical intricacies of LLM\\-based application development. Additionally, my analysis **doesn‚Äôt** focus on conventional success factors for innovative products, such as ones described in [that article](https://pakodas.substack.com/p/llm-chronicles-6-how-to-build-competitive).\n\n\n> *Instead, as a product manager, I analyze the **unique features of LLM** as a platform for my products. This approach offers fresh insights for leveraging unobvious AI capabilities in product development.*\n\nSpecifically, in this piece, I explore the following questions about software products:\n\n* Why are Generative AI products more prone to becoming obsolete before generating returns?\n* How can we transform these GenAI challenges into competitive advantages?\n* Which LLM abilities truly enhance product competitiveness, and which ones don‚Äôt make much sense?\n* How can new AI products stand out when they contain very little code, and therefore a great team of programmers are NOT among the key success factors anymore?\n* What skills are most vital for AI product developers in this new landscape?\n\nThese insights aim to guide product managers and founders in making their decisions.\n\nSo, which AI applications might be redundant or destined to fail üö´, and which ones have high chances of success ‚úÖ?\n\n*Please note that the section numbers below continue the section numbering of the previous two pieces of the series. All 11 points are summarized at the end of this piece.*\n\n\n## 9\\. Large Applications with Extended Development Cycles and Lengthy Market Adoption Timelines Are Uncompetitive üö´\n\nGenerative AI is evolving at an unprecedented rate, outpacing the growth of any previous technology. The time it takes for AI capabilities to double is roughly one year, a contrast to the two years described in the famous Moore‚Äôs Law.\n\nTherefore, GenAI\\-based products cannot afford long development cycles and extended time\\-to\\-market periods. This has three main consequences.\n\n\n### 1\\. New features should be lean and focused, capable of being developed within weeks, not months.\n\nThis approach allows for rapid refinement based on initial user feedback, potentially leading to significant functionality changes. Moreover, when a pivot becomes necessary (it certainly will), there‚Äôs less sunk cost in discarding features developed during these early weeks.\n\nConsider, for instance, the UI of an LLM\\-based MVP. It may be unnecessary to develop a custom web interface if users can achieve the same results through a Telegram bot or similar tool.\n\n*However, the ‚Äúproduct as a whole‚Äù can have extensive functionality if we are [incorporating LLM into existing solutions or integrating with them](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#5d06). The key here is to minimize the scope of **new** functionality only.*\n\n\n### 2\\. There‚Äôs a critical need for ultra\\-fast experimentation and customer feedback loops.\n\nThe speed of GenAI product build is higher, but it‚Äôs not always possible to get feedback just as quickly. As a result, some GenAI product concepts may prove too risky.\n\nRapid experimentation is, of course, beneficial for any new product launch, as it‚Äôs impossible to accurately predict market response in advance. Essentially, the market operates as a ‚Äúblack box,‚Äù and its behavior can only be truly understood through hands\\-on experimentation.\n\n\n> *In the realm of GenAI products, we encounter an additional layer of complexity ‚Äî **the second ‚Äúblack box‚Äù** stemming from the inherent unpredictability of LLM output. **This dual uncertainty amplifies the importance of frequent and rapid experimentation.** The ability to quickly iterate and gather insights becomes not just advantageous, but essential for success.*\n\n\n### 3\\. There‚Äôs no time to ‚Äúeducate‚Äù the product‚Äôs target audience, accustoming it to completely new work or leisure patterns.\n\nOnly the largest industry leaders, particularly those with their own ecosystems like Google, Apple, or Microsoft, can accustom the **majority** of potential users to novel concepts relatively quickly.\n\n‚úÖ Consequently, other companies must align with **either existing goal\\-achievement patterns familiar to users, or with trends established by industry leaders**.\n\n* Consider an established pattern for the goal of increasing earnings: people purchase training courses to gather new skills. A good AI\\-driven solution in this domain involves creating these courses using AI, dramatically reducing production costs and, consequently, enhancing competitiveness. **No new behavior** is required from end users who want to boost their income.\n* A recent **trend** emerging in Apple devices exemplifies an innovation that Apple platform users will undoubtedly adopt: employing a local LLM for typical tasks to safeguard user data privacy. While the specific ways applications might leverage this trend remain unclear yet, I am sure that Apple will provide developers with convenient access to its LLM infrastructure, we just need to wait a bit.\n\n\n## 10\\. Leveraging the Less Apparent LLM Capabilities Enhances Competitiveness and Resource Efficiency ‚úÖ\n\nImagine you‚Äôre at the starting point with nothing more than a product concept. To expedite the journey towards a product in high demand, **which aspects of your idea should you prioritize for initial exploration?**\n\nClearly, you need to identify a small set of specific end\\-to\\-end work scenarioswithin your concept. This aligns with [popular product launch strategies](https://www.geeksforgeeks.org/a-complete-guide-to-a-successful-product-launch/#is-there-a-product-launch-formula): ‚ÄúStart with MVP‚Äù (implementing just one or a few scenarios) and ‚ÄúBuild for the **whole** user experience‚Äù (ensuring scenarios are end\\-to\\-end). The question remains: which scenarios should you choose?\n\n\n> *In my opinion, these MVP scenarios should be **closely aligned with LLM capabilities**. This approach saves resources on the product delivery, as significant product value comes from the LLM itself rather than solely from your developers‚Äô efforts. Failing to do so may lead to challenges like those outlined in [section 7 ‚ÄúOverconstraining LLM‚Äù](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e1ef).*\n\nüö´ LLM‚Äôs purported super\\-powers often include its **ability to answer any question**. However, the accuracy and quality of these responses are inherently unpredictable, and it leads to problems (refer to [section 1](https://ai.gopubby.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#f973) for more on evaluation complexities and quality monitoring). Moreover, a product centered around question\\-answering can‚Äôt effectively compete with market leaders like ChatGPT (as discussed in [section 6](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e305)). Given these two factors, I advise against basing an MVP on this ‚Äúsuper\\-power‚Äù.\n\n**The LLM‚Äôs capacity for ‚Äúimaginative generation‚Äù** presents a somewhat more promising avenue. Such creativity of LLMs can inspire our fresh ideas or aid in creating creative content like poems, video scripts, or content plans. However, in my experience, LLM‚Äôs creativity alone doesn‚Äôt suffice for constructing end\\-to\\-end product scenarios. Once a user obtains ‚Äúcreative material‚Äù from an LLM, substantial effort is still required to transform it into the desired outcome.\n\nFurthermore, creativity represents one of the most easy\\-to\\-understand and widely recognized capabilities of GenAI. It is familiar to nearly anyone who has experimented with ChatGPT or Midjourney, so anyone can become your competitor.\n\n\n\n‚úÖ Considering the intense competition, I‚Äôd recommend focusing on **LLM‚Äôs less apparent capabilities,** such as:\n\n\n### 1\\. Flipped interaction\n\nThis human\\-AI interaction pattern leverages LLM‚Äôs ability to **ask good questions** or present lists for selecting items important for a user, thereby reducing the user‚Äôs cognitive load. Flipped interaction not only helps replace some human work in certain fields (like teaching, mentoring, or coaching) but also aids in establishing the appropriate **context** for solving problems in any field (more details is available [here](https://readmedium.com/4-human-ai-interaction-patterns-for-experienced-chatgpt-users-9e49d4234013#c348)).\n\n\n### 2\\. Contextual comprehension\n\nLLM excels at grasping the context of user requests and their preferences, then addressing the task within that context. This approach ensures that solutions align with even **unformulated** user needs.\n\na. This feature is perhaps most refined in AI copilots for developers, such as Github Copilot and Cursor. In these tools, the LLM‚Äôs context encompasses the entire project codebase, whereas the user (developer) typically knows only specific portions. Consequently, developers often cannot consider the broader context when formulating their tasks for AI.\n\nb. Nevertheless, leveraging insights from **explicitly stated** user needs within the context is also a powerful feature. The language learning platform [Memrise](https://www.memrise.com/), for instance, has effectively implemented this feature.\n\n\n### 3\\. Few\\-shot learning\n\nThe model‚Äôs ability to ‚Äúlearn‚Äù from a **small** number of examples allows it to easily adapt to new tasks and contexts. This is why LLM\\-based chatbots are now widely being implemented in sales and customer support, and chats with them are difficult to distinguish from those with human specialists. In contrast, traditional AI chatbots perform well only in large enterprises and struggle to adapt to evolving knowledge bases.\n\n\n### 4\\. Large\\-scale information processing\n\nLLM excels at analyzing **large** quantities of textual and tabular data, distilling it into **concise** forms. It can generalize, extract key points relevant to the task at hand, identify patterns, and perform various other analytical functions.\n\na. Take [Scite](https://scite.ai/), an AI tool for scientific research, as an example. It goes beyond merely locating query\\-relevant sources within its billion\\-citation database. Scite analyzes the context in which an article is referenced, revealing whether the citing paper supports, contradicts, or just mentions the earlier work.\n\nb. When it comes to numerical data processing, LLM outputs don‚Äôt require ‚Äútranslation into human language‚Äù. This gives GenAI analyzers a distinct advantage over conventional statistical data processing tools.\n\nMany potential competitors may be aware of some of these four LLM capabilities. However, I believe that deeper reflection on these abilities could lead to the development of truly innovative products. This approach could provide a competitive edge over products that solely leverage LLM‚Äôs more obvious capabilities like ‚Äúcreativity‚Äù and ‚Äúanswering any question‚Äù.\n\n\n## 11\\. Small AI Products Grounded in Deep Domain Expertise Are Competitively Viable ‚úÖ\n\nLLM functions nearly as a finished product, it can interact with users ‚Äúautonomously‚Äù. Consequently, LLM\\-based applications are significantly smaller in terms of code base compared to traditional non\\-LLM applications.\n\nMoreover, any individual with some technical skills can learn to develop a feature\\-rich LLM\\-based application within days.\n\nThese two factors align perfectly with the rapid development and experimentation requirements outlined in section 9.\n\n\n> *However, the small size of the product and the low barrier to entry in GenAI development are **significant drawbacks from a competitive standpoint**.*\n\nFor a typical software product with large code base, an exceptional team and agile development processes are crucial success elements. [Bill Gross‚Äôs research](https://youtu.be/bNpx7gpSqbY?t=216) ranks this as the second most important factor out of five, surpassing even the product idea‚Äôs viability, which ranks third.\n\nHowever, how can a product get its competitive edge when its software development scope is minimal, and even inexperienced programmers can develop it?\n\nWith ideas and business models easily replicable by competitors‚Ä¶ Does success truly depend **solely** on the short\\-term advantage of being the first to market in your niche?\n\n1. Section 10 offers one answer to these questions: products should leverage LLM‚Äôs less\\-known capabilities. While this doesn‚Äôt guarantee success, it increases the chances of outperforming competitors who may not fully understand LLM‚Äôs unobvious abilities.\n2. [My previous article](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#9f01) outlines another solution: implementing LLM within the product in innovative ways, such as the LLM2 strategy. This kind of know\\-how is harder for competitors to replicate, as it‚Äôs more deeply hidden inside the product.\n3. The third component of my solution to this challenge is the necessity for a high level of **domain expertise**.\n\nThe importance of domain expertise in product success has been a topic of discussion for years. While I couldn‚Äôt find quantitative studies correlating startup success with founders‚Äô domain expertise, I recommend exploring some [examples](https://jamesspurway.com/2024/04/29/founder-domain-expertise-insider-tip-how-startups-benefit/) and [rationales](https://www.nvp.com/blog/domain-expertise-founder-greatest-asset/) supporting this significant correlation. [Existing studies](https://www.ensemble.vc/research/what-does-the-data-say-about-successful-startup-founders), focusing solely on unicorns, suggest that founders‚Äô domain expertise is important, though not the primary success factor.\n\nHowever, I believe that this factor gains substantially more importance in the realm of generative AI. The reasoning behind this opinion is well\\-articulated in the following post:\n\n\n> *For LLM\\-based products, technical expertise plays a significantly reduced role (due to easier software delivery), unlike traditional digital products where it‚Äôs a crucial competitive advantage. Instead, a **profound understanding of the domain** becomes paramount, as this depth of knowledge is challenging for competitors to replicate.*\n\nFrom a product competitiveness standpoint, I believe it‚Äôs important for domain expertise to reside **in the same mind** that designs the product and contributes to its implementation. Of course, the traditional separation of ‚Äútech‚Äù and ‚Äúbusiness‚Äù roles in companies has its benefits, as long as they communicate effectively, as such communication results in well\\-balanced, technically sophisticated and domain\\-appropriate products. Nevertheless, verbal communication introduces significant overhead. It can take months for techies and businesspeople to understand each other well enough. During this time, market conditions may shift dramatically.\n\n\n> *The most efficient and lossless translation of domain expertise into technical implementation occurs when both business and technical visions reside in a single mind. LLMs provide this opportunity by immensely reducing the technical expertise required for product implementation, thus **enabling individuals with strong domain knowledge to take a direct role in product delivery**.*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dOlknP1p9xLfvy_NxLnq7Q.png)\n\nIn my view, when developing GenAI products, technical expertise isn‚Äôt limited to programmers; it extends to include advanced ChatGPT users as well.\n\nFor example, my friend [Askhat Urazbaev](https://www.linkedin.com/in/urazbaev/) independently creates MVPs for his products using AI and even deploys them in the cloud with ChatGPT guidance only. He has never been a professional software developer, and it seems that his [AI Power User](https://readmedium.com/12-questions-to-consider-when-using-ai-path-to-ai-power-user-9c7e8de1f8b7#f646) skills are just as valuable as the ability to read program code.\n\n\n> *I‚Äôm convinced that generative AI will soon enable domain experts to **single\\-handedly** develop products within their domains. To do so, experts should have substantial AI user experience coupled with a foundational understanding of business principles and product design.*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kk0SUvuajHZp7UMbSEonmQ.png)\n\nNevertheless, it is not yet clear which specific tools will help us create comprehensive products single\\-handedly. The concept of an ‚Äú**LLM\\-driven one\\-person company**‚Äù will be the focus of research in one of my upcoming articles.\n\n\n## Summary: Success and Failure Factors for LLM\\-driven Products\n\nLet‚Äôs put together all the ideas from the 3 pieces of this series.\n\n1. [Applications With High Quality Standards or Costly Quality Monitoring May Fail üö´](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#f973)\n2. [Specialized Copilots Are in Demand ‚úÖ](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#031b)\n3. [Marginal Effort\\-Saving Apps Don‚Äôt Cut It üö´](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#e88a)\n4. [Applications ‚ÄúSmartly‚Äù Integrating LLMs into Familiar Workflows Can Cross the Chasm ‚úÖ](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#5d06)\n5. [New GenAI Products Are Better Suited to B2B and B2B2C than B2C](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#bdfa)\n6. [Short Lifespan of Applications Enhancing LLM Capabilities üö´](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e305)\n7. [Overconstraining LLM: A Recipe for Uncompetitive Applications üö´](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e1ef)\n8. [‚ÄúGenAI Squared‚Äù Products: Unlocking Unfair Competitive Advantage ‚úÖ](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#9f01)\n9. Large Applications with Extended Development Cycles and Lengthy Market Adoption Timelines Are Uncompetitive üö´\n10. Leveraging the Less Apparent LLM Capabilities Enhances Competitiveness and Resource Efficiency ‚úÖ\n11. Small AI Products Grounded in Deep Domain Expertise Are Competitively Viable ‚úÖ\n\nExcept for factor \\#4, the remaining 10 success / failure factors can be applied to **new** products / to startups.\n\nBelow, you can find a scheme illustrating the relations between these 10 factors, LLM capabilities and some features of LLM technology market.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*f6E4WmRBw3H7eCNbTGJHUQ.png)\n\nCertainly, only product experimentation can validate such considerations as shown on the scheme. Nevertheless, they can help us be **faster** by limiting the scope of our experiments. As explained in section 9, there are 2 reasons why high speed of discovery and delivery is even more important for GenAI products than for digital products of other types.\n\nNaturally, no list of success factors can be all\\-encompassing. Maybe you have encountered other categories of novel LLM\\-driven products that are not mentioned above but you believe hold potential for success. Please share such product types or features in the comments üôè\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-to-create-an-ai-team-to-write-compelling-stories-with-crewai-and-gemini-pro-3713f53c72c4","frontmatter":{"title":"How to create an AI team to write compelling stories with CrewAI and Gemini Pro","meta_title":"How to create an AI team to write compelling stories with CrewAI and Gemini Pro","description":"Are you fascinated by the idea of AI generating stories that capture the imagination? If so, you‚Äôre not alone! In this article, we‚Äôll dive‚Ä¶","date":"2024-10-31T23:04:49.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tSnoOxxIGtrwdUT8","categories":["Programming","Natural Language Processing","Generative AI"],"author":"Rifx.Online","tags":["CrewAI","Gemini","screenwriters","critics","storytelling"],"draft":false,"slug":"blog/how-to-create-an-ai-team-to-write-compelling-stories-with-crewai-and-gemini-pro-3713f53c72c4"},"content":"\n\n\nAre you fascinated by the idea of AI generating stories that capture the imagination? If so, you‚Äôre not alone! In this article, we‚Äôll dive into an introductory project that combines the powers of CrewAI and Gemini Pro to create an agent network that crafts short stories with a little help from user input. Whether you‚Äôre a budding programmer, a storyteller looking to explore digital frontiers, or simply curious about the potential of artificial intelligence, this guide is for you.\n\n## What are CrewAI and Gemini Pro?\n\nBefore we jump into the nuts and bolts of building our AI storyteller, let‚Äôs clarify what CrewAI and Gemini Pro are.\n\n**CrewAI** is a fascinating framework designed to orchestrate multiple AI agents, each with its own unique skills and responsibilities, to collaborate on complex tasks. Think of it as a director managing a team of actors, where each actor plays a specific role to bring a story to life. In the context of our project, CrewAI enables us to create a team of specialized agents (like screenwriters, critics, and story masters) to work together on writing stories.\n\n**Gemini Pro**, on the other hand, is a state\\-of\\-the\\-art language model developed by Google. It‚Äôs known for its ability to understand and generate human\\-like text, making it an ideal candidate for creative tasks such as storytelling. By leveraging Gemini Pro, we can ensure our agents have a solid foundation for generating compelling narrative content.\n\n## Why is This Kind of Structure Important?\n\nThe combination of CrewAI and Gemini Pro enables a highly collaborative and specialized approach to story generation. This structure allows for:\n\n1. **Specialization**: Each agent can focus on what it does best, whether it‚Äôs crafting dialogue, ensuring consistency, or overseeing the project.\n2. **Collaboration**: Agents can work together, combining their strengths to produce a story that‚Äôs greater than the sum of its parts.\n3. **Flexibility**: The setup is highly adaptable, allowing for different story elements to be emphasized or altered based on user input or creative direction.\n\n## Setting Up the Environment\n\nFirst, we will need some libraries to use. You can load these libraries via pip:\n\n```python\npip install crewai\n```\n\n```python\npip install langchain-google-genai\n```\n\nAfter loading the necessary libraries we can start coding. We will start by importing our necessary modules and initialize our Gemini pro api connection.\n\nAs you may notice, we will need an API key for Gemini model. You can create this key in Google AI Studio for [free](https://ai.google.dev/). After that, you can copy this key into google\\_api\\_key variable or you can load it into environment by running this command in your command line:\n\n```python\nexport GOOGLE_API_KEY=YOUR_KEY\n```\n\nReplace the api key that you will get from google ai studio with YOUR\\_KEY.\n\nNext, we define our agents: the Screenwriter, Critic, and Story Master. Each agent is assigned a role, goal, and backstory to guide its contributions to the story generation process.\n\nFor example, the Screenwriter is focused on translating ideas into engaging scenes, while the Critic ensures consistency and adherence to genre.\n\nThese agents will work together and create an engaging story. The story master will accept the task, then it will delegate and coordinate tasks between other agents. We allow this behavior by setting allow\\_delegation parameter to True.\n\nWith our agents ready, we prompt the user for a story idea. This input is then used to create a task that outlines what the story should include, guiding the agents in their creative process.\n\nWhile creating the task, we submit the task to the story master since it will coordinate our story creation process.\n\nFinally, we should combine these agents into a crew and run our task.\n\nAnd thats it. When we run this code, it will prompt the user to give a story idea and then write a short story by agent cooperation. Of course, there is much more than this in the CrewAI framework such as tool usage, hierarchical processing, working with ollama to run agents fully locally with different agents etc, but these topics are for another article.\n\nYou can find the full code in here for directly run:\n\nYou can use this code as a template for these kinds of applications, you can build game builder crew, stock analyzer crew, marketing crew etc. With imagination, sky is the limit. If you like this article and excited about the more advanced implementations you can visit the CrewAI [website](https://www.crewai.com/).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-to-improve-llms-with-rag-abdc132f76ac","frontmatter":{"title":"How to Improve LLMs with RAG","meta_title":"How to Improve LLMs with RAG","description":"A beginner-friendly introduction w/ Python code","date":"2024-11-04T12:31:55.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*N0Ad_oCIrAyzMYRdH3trqg.png","categories":["Natural Language Processing","Programming","Generative AI"],"author":"Rifx.Online","tags":["RAG","retrievers","LlamaIndex","knowledge","bases"],"draft":false,"slug":"blog/how-to-improve-llms-with-rag-abdc132f76ac"},"content":"\n\n\n\n\n### A beginner\\-friendly introduction w/ Python code\n\nThis article is part of a [larger series](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c) on using large language models in practice. In the [previous post](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32), we fine\\-tuned Mistral\\-7b\\-Instruct to respond to YouTube comments using QLoRA. Although the fine\\-tuned model successfully captured my style when responding to viewer feedback, its responses to technical questions didn‚Äôt match my explanations. Here, I‚Äôll discuss how we can improve LLM performance using retrieval augmented generation (i.e. RAG).\n\n\n\nLarge language models (LLMs) have demonstrated an impressive ability to store and deploy vast knowledge in response to user queries. While this has enabled the creation of powerful AI systems like ChatGPT, compressing world knowledge in this way has **two key limitations**.\n\n**First**, an LLM‚Äôs knowledge is static, i.e., not updated as new information becomes available. **Second**, LLMs may have an insufficient ‚Äúunderstanding‚Äù of niche and specialized information that was not prominent in their training data. These limitations can result in undesirable (and even fictional) model responses to user queries.\n\nOne way we can mitigate these limitations is to **augment a model via a specialized and mutable knowledge base**, e.g., customer FAQs, software documentation, or product catalogs. This enables the creation of more robust and adaptable AI systems.\n\n**Retrieval augmented generation**, or **RAG**, is one such approach. Here, I provide a high\\-level introduction to RAG and share example Python code for implementing a RAG system using LlamaIndex.\n\n\n## What is RAG?\n\nThe basic usage of an LLM consists of giving it a prompt and getting back a response.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sM1p-3FoTaGZunqx918G9A.png)\n\n**RAG works by adding a step to this basic process**. Namely, a retrieval step is performed where, based on the user‚Äôs prompt, the relevant information is extracted from an external knowledge base and injected into the prompt before being passed to the LLM.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EhJZj1blu7a8EPmVAPsNcA.png)\n\n\n## Why we care\n\nNotice that RAG does not fundamentally change how we use an LLM; it's still *prompt\\-in and response\\-out*. RAG simply augments this process (hence the name).\n\nThis makes **RAG a flexible and (relatively) straightforward way to improve LLM\\-based systems**. Additionally, since knowledge is stored in an external database, updating system knowledge is as simple as adding or removing records from a table.\n\n\n### Why not fine\\-tune?\n\nPrevious articles in this series discussed [fine\\-tuning](https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91), which adapts an existing model for a particular use case. While this is an alternative way to endow an LLM with specialized knowledge, empirically, **fine\\-tuning seems to be less effective than RAG** **at doing this** \\[1].\n\n\n## How it works\n\nThere are 2 key elements of a RAG system: a **retriever** and a **knowledge base**.\n\n\n### Retriever\n\nA retriever takes a user prompt and returns relevant items from a knowledge base. This typically works using so\\-called **text embeddings**, numerical representations of text in concept space. In other words, these are **numbers that represent the *meaning* of a given text**.\n\nText embeddings can be used to compute a similarity score between the user‚Äôs query and each item in the knowledge base. The result of this process is a **ranking of each item‚Äôs relevance to the input query**.\n\nThe retriever can then take the top k (say k\\=3\\) most relevant items and inject them into the user prompt. This augmented prompt is then passed into the LLM for generation.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jpTwdBmoTlJlfPAm0oJiVQ.png)\n\n\n### Knowledge Base\n\nThe next key element of a RAG system is a knowledge base. This **houses all the information you want to make available to the LLM**. While there are countless ways to construct a knowledge base for RAG, here I‚Äôll focus on building one from a set of documents.\n\nThe process can be broken down into **4 key steps** \\[2,3].\n\n1. **Load docs** ‚Äî This consists of gathering a collection of documents and ensuring they are in a ready\\-to\\-parse format (more on this later).\n2. **Chunk docs‚Äî**Since LLMs have limited context windows, documents must be split into smaller chunks **(e.g.,** 256 or 512 characters long).\n3. **Embed chunks** ‚Äî Translate each chunk into numbers using a text embedding model.\n4. **Load into Vector DB**‚Äî Load text embeddings into a database (aka a vector database).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VWG6Tr0OxCnD5Mvygm5DCA.png)\n\n\n## Some Nuances\n\nWhile the steps for building a RAG system are conceptually simple, several nuances can make building one (in the real world) more complicated.\n\n**Document preparation**‚ÄîThe quality of a RAG system is driven by how well useful information can be extracted from source documents. For example, if a document is unformatted and full of images and tables, it will be more difficult to parse than a well\\-formatted text file.\n\n**Choosing the right chunk size**‚ÄîWe already mentioned the need for chunking due to LLM context windows. However, there are 2 additional motivations for chunking.\n\n**First**, it keeps (compute) costs down. The more text you inject into the prompt, the more compute required to generate a completion. The **second** is performance. Relevant information for a particular query tends to be localized in source documents (often, just 1 sentence can answer a question). Chunking helps minimize the amount of irrelevant information passed into the model \\[4].\n\n**Improving search** ‚Äî While text embeddings enable a powerful and fast way to do search, it doesn‚Äôt always work as one might hope. In other words, it may return results that are ‚Äúsimilar‚Äù to the user query, yet not helpful for answering it, e.g., ‚Äú*How‚Äôs the weather in LA?*‚Äù may return ‚Äú*How‚Äôs the weather in NYC?*‚Äù.\n\nThe simplest way to mitigate this is through good document preparation and chunking. However, for some use cases, additional strategies for improving search might be necessary, such as using **meta\\-tags** for each chunk, employing **hybrid search**, which combines keyword‚Äîand embedding\\-based search, or using a **reranker**, which is a specialized model that computes the similarity of 2 input pieces of text.\n\n\n## Example code: Improving YouTube Comment Responder with RAG\n\nWith a basic understanding of how RAG works, let‚Äôs see how to use it in practice. I will build upon the example from the [previous article](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32), where I fine\\-tuned Mistral\\-7B\\-Instruct to respond to YouTube comments using QLoRA. We will use LlamaIndex to add a RAG system to the fine\\-tuned model from before.\n\nThe example code is freely available in a [Colab Notebook](https://colab.research.google.com/drive/1peJukr-9E1zCo1iAalbgDPJmNMydvQms?usp=sharing), which can run on the (free) T4 GPU provided. The source files for this example are available at the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag).\n\nüîó [Google Colab](https://colab.research.google.com/drive/1peJukr-9E1zCo1iAalbgDPJmNMydvQms?usp=sharing) \\| [GitHub Repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag)\n\n\n### Imports\n\nWe start by installing and importing necessary Python libraries.\n\n\n```python\n!pip install llama-index\n!pip install llama-index-embeddings-huggingface\n!pip install peft\n!pip install auto-gptq\n!pip install optimum\n!pip install bitsandbytes\n## if not running on Colab ensure transformers is installed too\n```\n\n```python\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.postprocessor import SimilarityPostprocessor\n```\n\n### Setting up Knowledge Base\n\nWe can configure our knowledge base by defining our embedding model, chunk size, and chunk overlap. Here, we use the \\~33M parameter [bge\\-small\\-en\\-v1\\.5](https://huggingface.co/BAAI/bge-small-en-v1.5) embedding model from BAAI, which is available on the Hugging Face hub. Other embedding model options are available on this [text embedding leaderboard](https://huggingface.co/spaces/mteb/leaderboard).\n\n\n```python\n## import any embedding model on HF hub\nSettings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\nSettings.llm = None # we won't use LlamaIndex to set up LLM\nSettings.chunk_size = 256\nSettings.chunk_overlap = 25\n```\nNext, we load our source documents. Here, I have a folder called ‚Äú[*articles*](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag/articles),‚Äù which contains PDF versions of 3 Medium articles I wrote on [fat tails](https://towardsdatascience.com/pareto-power-laws-and-fat-tails-0355a187ee6a). If running this in Colab, you must download the articles folder from the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag) and manually upload it to your Colab environment.\n\nFor each file in this folder, the function below will read the text from the PDF, split it into chunks (based on the settings defined earlier), and store each chunk in a list called *documents*.\n\n\n```python\ndocuments = SimpleDirectoryReader(\"articles\").load_data()\n```\nSince the blogs were downloaded directly as PDFs from Medium, they resemble a webpage more than a well\\-formatted article. Therefore, some chunks may include text unrelated to the article, e.g., webpage headers and Medium article recommendations.\n\nIn the code block below, I refine the chunks in documents, removing most of the chunks before or after the meat of an article.\n\n\n```python\nprint(len(documents)) # prints: 71\nfor doc in documents:\n    if \"Member-only story\" in doc.text:\n        documents.remove(doc)\n        continue\n\n    if \"The Data Entrepreneurs\" in doc.text:\n        documents.remove(doc)\n\n    if \" min read\" in doc.text:\n        documents.remove(doc)\n\nprint(len(documents)) # prints: 61\n```\nFinally, we can store the refined chunks in a vector database.\n\n\n```python\nindex = VectorStoreIndex.from_documents(documents)\n```\n\n### Setting up Retriever\n\nWith our knowledge base in place, we can create a retriever using LlamaIndex‚Äôs *VectorIndexRetreiver(),* which returns the top 3 most similar chunks to a user query.\n\n\n```python\n## set number of docs to retreive\ntop_k = 3\n\n## configure retriever\nretriever = VectorIndexRetriever(\n    index=index,\n    similarity_top_k=top_k,\n)\n```\nNext, we define a query engine that uses the retriever and query to return a set of relevant chunks.\n\n\n```python\n## assemble query engine\nquery_engine = RetrieverQueryEngine(\n    retriever=retriever,\n    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n)\n```\n\n### Use Query Engine\n\nNow, with our knowledge base and retrieval system set up, let‚Äôs use it to return chunks relevant to a query. Here, we‚Äôll pass the same technical question we asked ShawGPT (the YouTube comment responder) from the [previous article](https://readmedium.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32).\n\n\n```python\nquery = \"What is fat-tailedness?\"\nresponse = query_engine.query(query)\n```\nThe query engine returns a response object containing the text, metadata, and indexes of relevant chunks. The code block below returns a more readable version of this information.\n\n\n```python\n## reformat response\ncontext = \"Context:\\n\"\nfor i in range(top_k):\n    context = context + response.source_nodes[i].text + \"\\n\\n\"\n\nprint(context)\n```\n\n```python\nContext:\nSome of the controversy might be explained by the observation that log-\nnormal distributions behave like Gaussian for low sigma and like Power Law\nat high sigma [2].\nHowever, to avoid controversy, we can depart (for now) from whether some\ngiven data fits a Power Law or not and focus instead on fat tails.\nFat-tailedness ‚Äî measuring the space between Mediocristan\nand Extremistan\nFat Tails are a more general idea than Pareto and Power Law distributions.\nOne way we can think about it is that ‚Äúfat-tailedness‚Äù is the degree to which\nrare events drive the aggregate statistics of a distribution. From this point of\nview, fat-tailedness lives on a spectrum from not fat-tailed (i.e. a Gaussian) to\nvery fat-tailed (i.e. Pareto 80 ‚Äì 20).\nThis maps directly to the idea of Mediocristan vs Extremistan discussed\nearlier. The image below visualizes different distributions across this\nconceptual landscape [2].\n\nprint(\"mean kappa_1n = \" + str(np.mean(kappa_dict[filename])))\n    print(\"\")\nMean Œ∫ (1,100) values from 1000 runs for each dataset. Image by author.\nThese more stable results indicate Medium followers are the most fat-tailed,\nfollowed by LinkedIn Impressions and YouTube earnings.\nNote: One can compare these values to Table III in ref [3] to better understand each\nŒ∫ value. Namely, these values are comparable to a Pareto distribution with Œ±\nbetween 2 and 3.\nAlthough each heuristic told a slightly different story, all signs point toward\nMedium followers gained being the most fat-tailed of the 3 datasets.\nConclusion\nWhile binary labeling data as fat-tailed (or not) may be tempting, fat-\ntailedness lives on a spectrum. Here, we broke down 4 heuristics for\nquantifying how fat-tailed data are.\n\nPareto, Power Laws, and Fat Tails\nWhat they don‚Äôt teach you in statistics\ntowardsdatascience.com\nAlthough Pareto (and more generally power law) distributions give us a\nsalient example of fat tails, this is a more general notion that lives on a\nspectrum ranging from thin-tailed (i.e. a Gaussian) to very fat-tailed (i.e.\nPareto 80 ‚Äì 20).\nThe spectrum of Fat-tailedness. Image by author.\nThis view of fat-tailedness provides us with a more flexible and precise way of\ncategorizing data than simply labeling it as a Power Law (or not). However,\nthis begs the question: how do we define fat-tailedness?\n4 Ways to Quantify Fat Tails\n```\n\n### Adding RAG to LLM\n\nWe start by downloading the [fine\\-tuned model](https://readmedium.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32) from the Hugging Face hub.\n\n\n```python\n## load fine-tuned model from hub\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n                                             device_map=\"auto\",\n                                             trust_remote_code=False,\n                                             revision=\"main\")\n\nconfig = PeftConfig.from_pretrained(\"shawhin/shawgpt-ft\")\nmodel = PeftModel.from_pretrained(model, \"shawhin/shawgpt-ft\")\n\n## load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n```\nAs a baseline, we can see how the model responds to the technical question without any context from the articles. To do this, we create a prompt template using a lambda function, which takes in a viewer comment and returns a prompt for the LLM. For more details on where this prompt comes from, see the [previous article](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32#5aad) of this series.\n\n\n```python\n## prompt (no context)\nintstructions_string = f\"\"\"ShawGPT, functioning as a virtual data science \\\nconsultant on YouTube, communicates in clear, accessible language, escalating \\\nto technical depth upon request. It reacts to feedback aptly and ends \\\nresponses with its signature '‚ÄìShawGPT'.\n\nShawGPT will tailor the length of its responses to match the viewer's comment, \\\nproviding concise acknowledgments to brief expressions of gratitude or \\\nfeedback, thus keeping the interaction natural and engaging.\n\nPlease respond to the following comment.\n\"\"\"\n\nprompt_template = lambda comment: f'''[INST] {intstructions_string} \\n{comment} \\n[/INST]'''\ncomment = \"What is fat-tailedness?\"\n\nprompt = prompt_template(comment)\nprint(prompt)\n```\n\n```python\n[INST] ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. It reacts to feedback aptly and ends responses with its signature '‚ÄìShawGPT'. ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\n\nPlease respond to the following comment.\n \nWhat is fat-tailedness? \n[/INST]\n```\nNext, we can pass this prompt to the model using the code below.\n\n\n```python\nmodel.eval()\n\ninputs = tokenizer(prompt, return_tensors=\"pt\")\noutputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), \n                          max_new_tokens=280)\n\nprint(tokenizer.batch_decode(outputs)[0])\n```\nHere‚Äôs the model‚Äôs response (no context).\n\n\n```python\nGreat question!\n\nFat-tailedness is a statistical property of a distribution. In simple terms, \nit refers to the presence of extreme outliers or heavy tails in the \ndistribution.\n\nFor instance, consider the distribution of heights in a population. A normal \ndistribution would have most people clustered around an average height with a \nfew people deviating slightly from the mean. However, in a fat-tailed \ndistribution, you would observe a larger number of people being significantly \ntaller or shorter than the average.\n\nIn finance, fat-tailedness is often used to describe the presence of extreme \nmarket moves or outliers in financial returns. It's an important concept in \nrisk management and financial modeling.\n\nI hope this explanation helps! Let me know if you have any questions.\n‚ÄìShawGPT\n```\nAlthough the response's style and formatting are great, the model's explanation of fat\\-tailedness differs from how I defined it in my [video](https://www.youtube.com/playlist?list=PLz-ep5RbHosVrT89BRNX-IGKHYxvx9wqi) and [blog series](https://towardsdatascience.com/pareto-power-laws-and-fat-tails-0355a187ee6a).\n\nLet‚Äôs see what happens to the model‚Äôs response when we include the appropriate context. To do this, we create another prompt template, which can also take in context from the RAG system.\n\n\n```python\n## prompt (with context)\nprompt_template_w_context = lambda context, comment: f\"\"\"[INST]ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\nIt reacts to feedback aptly and ends responses with its signature '‚ÄìShawGPT'. \\\nShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\nthus keeping the interaction natural and engaging.\n\n{context}\nPlease respond to the following comment. Use the context above if it is helpful.\n\n{comment}\n[/INST]\n\"\"\"\n```\nNext, we pass the prompt with context from the query engine and the view comment to the model.\n\n\n```python\nprompt = prompt_template_w_context(context, comment)\n\ninputs = tokenizer(prompt, return_tensors=\"pt\")\noutputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n\nprint(tokenizer.batch_decode(outputs)[0])\n```\nHere‚Äôs the new response (with context).\n\n\n```python\nGreat question!\n\nFat-tailedness is a property of a distribution that describes how much the \npresence of extreme values (rare events) affects the overall statistics of the \ndistribution.\n\nIn the context of the video, the author discusses how Mediocristan and \nExtremistan distributions differ in terms of fat-tailedness. Mediocristan \ndistributions have a relatively small impact from extreme values, while \nExtremistan distributions are heavily influenced by extreme values.\n\nThe author also mentions that fat-tailedness is a more general concept than \nspecific distributions like Pareto or Power Laws. Instead, it lives on a \nspectrum ranging from thin-tailed (Gaussian) to very fat-tailed (Pareto 80-20).\n\nI hope that helps clarify things a bit! Let me know if you have any questions.\n‚ÄìShawGPT\n```\nThis does a much better job of capturing my explanation of fat tails than the no\\-context response and even calls out the niche concepts of Mediocristan and Extremistan.\n\n\n## What‚Äôs next?\n\nHere, I gave a beginner\\-friendly introduction to RAG and shared a concrete example of how to implement it using LlamaIndex. RAG allows us to improve an LLM system with updateable and domain\\-specific knowledge.\n\nWhile much of the recent AI hype has centered around building AI assistants, a powerful (yet less popular) innovation has come from text embeddings (i.e. the things we used to do retrieval). In the next article of this series, I will explore **text embeddings** in more detail, including how they can be used for **semantic search** and **classification tasks**.\n\n**More on LLMs üëá**\n\n\n## Resources\n\n**Connect**: [My website](https://shawhintalebi.com/) \\| [Book a call](https://calendly.com/shawhintalebi)\n\n**Socials**: [YouTube üé•](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA) \\| [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) \\| [Instagram](https://www.instagram.com/shawhintalebi)\n\n**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) ‚òïÔ∏è\n\n\\[1] [RAG \\> FT (empirical)](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)\n\n\\[2] [LlamaIndex Webinar: Building LLM Apps for Production, Part 1 (co\\-hosted with Anyscale)](https://www.youtube.com/watch?v=efbn-3tPI_M)\n\n\\[3] [LlamaIndex doc](https://docs.llamaindex.ai/en/stable/understanding/loading/loading.html)\n\n\\[4] [LlamaIndex Webinar: Make RAG Production\\-Ready](https://www.youtube.com/watch?v=Zj5RCweUHIk&list=WL&index=4)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-to-run-nvidia-llama-3-1-nemotron-70b-instruct-locally-a58ad283aaff","frontmatter":{"title":"How to Run Nvidia‚Äô llama-3.1-nemotron-70b-instruct Locally","meta_title":"How to Run Nvidia‚Äô llama-3.1-nemotron-70b-instruct Locally","description":"Running large language models (LLMs) locally has become increasingly popular among developers, researchers, and AI enthusiasts. One such‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fqVKJkw5sQvLtIsyCcengQ.png","categories":["Programming","Technology","Science"],"author":"Rifx.Online","tags":["Nvidia","llama","Ollama","llama.cpp","Transformers"],"draft":false,"slug":"blog/how-to-run-nvidia-llama-3-1-nemotron-70b-instruct-locally-a58ad283aaff"},"content":"\n\n\n\nRunning large language models (LLMs) locally has become increasingly popular among developers, researchers, and AI enthusiasts. One such model that has gained significant attention is the llama-3.1-nemotron-70b-instruct, a powerful LLM customized by NVIDIA to enhance the helpfulness of generated responses. In this comprehensive guide, we‚Äôll explore multiple methods to run this model on your local machine, starting with the user-friendly Ollama platform.\n\n\n> Before we get started, If you are seeking an All-in-One AI platform that manages all your AI subscriptions in one place, including all LLMs (such as GPT-o1, Llama 3.1, Claude 3.5 Sonnet, Google Gemini, Uncensored LLMs) and Image Generation Models (FLUX, Stable Diffusion, etc.), Use Anakin AI to manage them all!\n\n\n\n\n## Method 1: Run llama-3.1-nemotron-70b-instruct Locally with Ollama\n\nOllama is an excellent tool for running LLMs locally, offering a straightforward setup process and support for various models, including llama-3.1-nemotron-70b-instruct.\n\n\n### Installation\n\n1. Visit the official Ollama website ([https://ollama.ai](https://ollama.ai/)) and download the appropriate version for your operating system.\n2. Install Ollama by running the following command in your terminal:\n\n\n```python\ncurl https://ollama.ai/install.sh | sh\n```\n\n### Running llama-3.1-nemotron\n\nOnce Ollama is installed, you can easily run the llama-3.1-nemotron-70b-instruct model with a simple command:\n\n\n```python\nollama run nemotron:70b-instruct-q5_K_M\n```\nThis command will download the model if it‚Äôs not already present on your system and start an interactive session.\n\n\n### Using the Model\n\nAfter the model is loaded, you can start interacting with it by typing your prompts. For example:\n\n\n```python\n>>> What are the key features of llama-3.1-nemotron-70b-instruct?\n\nLlama-3.1-Nemotron-70B-Instruct is a large language model with several key features:\n1. Customized by NVIDIA: The model has been fine-tuned by NVIDIA to improve the helpfulness and quality of its responses.\n2. Based on Llama 3.1: It builds upon the Llama 3.1 architecture, which is known for its strong performance across various tasks.\n3. 70 billion parameters: This large parameter count allows for complex reasoning and a wide range of capabilities.\n4. Instruct-tuned: The model is specifically designed to follow instructions and generate helpful responses to user queries.\n5. RLHF training: It has been trained using Reinforcement Learning from Human Feedback, specifically the REINFORCE algorithm.\n6. Specialized reward model: The training process utilized Llama-3.1-Nemotron-70B-Reward for optimization.\n7. HelpSteer2-Preference prompts: These were used during the training process to further improve the model's helpfulness.\n8. Extended context length: Like other Llama 3.1 models, it likely supports a longer context window of 128K tokens.\n9. Multilingual capabilities: It can understand and generate text in multiple languages.\n10. Strong reasoning abilities: The model excels in tasks requiring complex reasoning and problem-solving.\nThese features make llama-3.1-nemotron-70b-instruct a powerful and versatile language model suitable for a wide range of applications, from general conversation to specialized tasks in various domains.\n```\nFor more advanced use cases, you can integrate Ollama with Python using libraries like Langchain. Here‚Äôs a simple example:\n\n\n```python\npython\n\nfrom langchain.llms import Ollama\n\nollama = Ollama(base_url=\"http://localhost:11434\", model=\"nemotron:70b-instruct-q5_K_M\")\nresponse = ollama.generate(\"Explain the concept of quantum entanglement.\")\nprint(response)\n```\nThis allows you to incorporate the model into your Python projects and applications seamlessly.\n\n\n## Method 2: Using llama.cpp\n\nllama.cpp is a popular C++ implementation of the Llama model inference, optimized for CPU usage. While it may require more setup than Ollama, it offers greater flexibility and control over the model‚Äôs parameters.\n\n\n### Installation\n\n1. Clone the llama.cpp repository:\n\n\n```python\ngit clone https://github.com/ggerganov/llama.cpp.git\ncd llama.cpp\n```\n1. Build the project:\n\n\n```python\nmake\n```\n\n### Downloading the Model\n\nTo run llama-3.1-nemotron-70b-instruct, you‚Äôll need to download the model weights. These are typically available in GGML or GGUF format. You can find pre-converted models on platforms like Hugging Face.\n\n\n```python\nmkdir models\ncd models\nwget https://huggingface.co/TheBloke/Llama-3.1-Nemotron-70B-Instruct-GGUF/resolve/main/llama-3.1-nemotron-70b-instruct.Q4_K_M.gguf\n```\n\n### Running the Model\n\nOnce you have the model file, you can run it using the following command:\n\n\n```python\n./main -m models/llama-3.1-nemotron-70b-instruct.Q4_K_M.gguf -n 1024 -p \"Hello, how are you today?\"\n```\nThis command loads the model and generates a response to the given prompt. You can adjust various parameters like the number of tokens to generate (-n) or the temperature to control randomness.\n\n\n## Method 3: Using Hugging Face Transformers\n\nHugging Face‚Äôs Transformers library provides a high-level API for working with various language models, including llama-3.1-nemotron-70b-instruct.\n\n**Installation**\n\nFirst, install the necessary libraries:\n\n\n```python\npip install transformers torch accelerate\n```\n**Running the Model**\n\nHere‚Äôs a Python script to load and use the model:\n\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"meta-llama/Llama-3.1-Nemotron-70b-instruct\"\n## Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n## Prepare the input\nprompt = \"Explain the concept of quantum computing in simple terms.\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n## Generate the response\nwith torch.no_grad():\n    outputs = model.generate(**inputs, max_new_tokens=100)\n## Decode and print the response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)\n```\nThis method allows for more fine-grained control over the model‚Äôs behavior and integration with other Hugging Face tools and pipelines.\n\n\n## Conclusion\n\nRunning llama-3.1-nemotron-70b-instruct locally opens up a world of possibilities for developers and researchers. Whether you choose the simplicity of Ollama, the flexibility of llama.cpp, or the integration capabilities of Hugging Face Transformers, you now have the tools to harness the power of this advanced language model on your own hardware.As you explore the capabilities of llama-3.1-nemotron-70b-instruct, remember to balance performance with resource constraints, and always consider the ethical implications of your applications. With responsible use, this model can be a valuable asset in pushing the boundaries of what‚Äôs possible in natural language processing and AI-driven applications.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/how-to-use-chatgpt-for-blogging-7ed5cba2f32b","frontmatter":{"title":"How to Use ChatGPT for Blogging","meta_title":"How to Use ChatGPT for Blogging","description":"The article outlines a nine-step approach for using ChatGPT in blogging, emphasizing the importance of AI prompts for generating content. It discusses the process of creating a blog post, starting from generating an outline to manual editing for SEO optimization. Key steps include generating unique talking points, checking for completeness, and ensuring the content avoids AI detection patterns. Additionally, it mentions the benefits of using features like ChatGPT Canvas for a more interactive writing experience. Overall, the guide aims to help users efficiently produce high-quality SEO articles with AI assistance.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*QS7seNg2jfuTz1Be.jpeg","categories":["Programming/Scripting","Marketing/Seo","Chatbots"],"author":"Rifx.Online","tags":["ChatGPT","prompts","blogging","SEO","Canvas"],"draft":false,"slug":"blog/how-to-use-chatgpt-for-blogging-7ed5cba2f32b"},"content":"\n\n\n\n\n### (My 9 Tested Steps)\n\n\n\nEveryone is using AI to write. Marketers, CEOs, content developers, small scale business owners.\n\nAll of us.\n\nRead [story for free](https://mysson.medium.com/7ed5cba2f32b?source=friends_link&sk=2881f3b15f541210f91fbc8834bc55d4)\n\nIt‚Äôs crazy to think that roughly three years ago we thought, and vehemently so, that:\n\n\n> AI wouldn‚Äôt replace writers.\n\nIf you are not using AI for blogging, it‚Äôs time to reconsider your stance, especially if your business demands a constant flow of content to remain relevant and competitive.\n\nThere are better AI blogging tools such as [Koala AI](https://koala.sh/register?via=mysson), but popular chatbots such as Chatgpt and Claude can be equally powerful, though not well streamlined.\n\nSome are better than others.\n\nChatgpt isn‚Äôt as powerful as Claude 3\\.5 Sonnet (New), but it‚Äôs still quite capable, and many writers are leveraging it to scale their content development efforts.\n\n\n## How to use Chatgpt for blogging (9 Steps)\n\nTo get started with ChatGPT, you‚Äôll need to enter an [AI prompt](https://aimode.co/ai-prompts-engineering/). Simply put, an AI prompt is a set of instructions that guides the AI to generate the desired text.\n\nFor example, if you need help creating a blog post about ‚ÄòThe future of AI in blogging‚Äô, you might enter a prompt like:\n\n\n> ‚ÄòIn markdown, generate an SEO article on the future of AI in blogging..‚Äô.\n\nBut remember, you‚Äôre in charge here. The output you get from ChatGPT is a starting point. It‚Äôs up to you to proofread, modify, and fact\\-check it to make it truly yours.\n\nTo successfully create great content using ChatGPT, I suggest you follow my nine\\-steps approach:\n\n\n> 1\\) Ask for an outline\n\n\n> 2\\) Generate unique talking points for each section\n\n\n> 3\\) Ask the AI if there‚Äôs something it missed\n\n\n> 4\\) Prompt to avoid AI detection\n\n\n> 5\\) Enter your article\\-generation prompts\n\n\n> 6\\) Request a modification before generating the rest of the article.\n\n\n> 7\\) Finish generating the rest of the article.\n\n\n> 8\\) Generate intro, conclusion, SEO title, and meta description sections\n\n\n> 9\\) Manually edit and proofread your article before publishing\n\n\n### 1\\) Prompting for blog outline\n\nThe first step is to ask ChatGPT to give you a detailed blog outline for your article.\n\nExample prompt:\n\n\n> Generate a detailed and comprehensive blog outline,ensuring you‚Äôve covered everything so that this blog meets the user intent. The topic is ‚ÄúHow to use ChatGPT for blogging.‚Äù\n\n\n### 2\\) Generate talking points\n\nThe next step is to ask Chatgpt to improve the generated outline by adding talking points.\n\nHere‚Äôs a sample prompt you can use:\n\n\n> Now improve the outline to include talking points, entities/keywords/resources/links. Each of these should be unique and specific to each section.\n\n\n### 3\\) Second\\-guess AI\n\nThis is my favorite step and a critical one as it can ensure that the content you‚Äôre building is quite informative and extensive.\n\nSimply ask AI if there are any critical points that are not covered in the reproduced outline.\n\n**Prompt:**\n\n\n> Are there any key topics that I left out but are critical in making this outline informative and helpful to the user? If so, reproduce the outline adding the missing topics/keywords/subheadings/parameters/resources. Just ensure you are sticking to the core topic. if there are none, just return the previous outline\n\nIf you are writing a listicle post, you may want to shuffle the list so that the most important topics are covered fast.\n\nSimply ask AI to rearrange the outline in the order of relevancy.\n\n\n### 4\\) Prompt for AI Detection\n\nBefore we go ahead to ask the AI to generate the article, we need to give it one more prompt that will enable it to write more like a human and avoid AI detection.\n\n\n### Here‚Äôs the prompt:\n\nTell your story\n\n\n> When writing content for the web, two factors are crucial: ‚Äúperplexity‚Äù and ‚Äúburstiness.‚Äù Perplexity measures the complexity of text.\n\n\n> Separately, burstiness compares the variations of sentences. Humans tend to write with greater burstiness, for example, with some longer or complex sentences alongside shorter ones.\n\n\n> Sentences created by AI tools like Chatgpt tend to be more uniform. Also opening sentences for different subsections tend to have some apparent repetitive patterns such as ‚Äúthis is another‚Äù, ‚Äúanother way‚Äù, ‚ÄúFirstly‚Äù, ‚Äúadditionally‚Äù, ‚ÄúMoreover‚Äùetc‚Ä¶\n\n\n> Therefore, when writing the following SEO blog post, I need it to have a good amount of perplexity and burstiness.\n\n\n> Also, dive into subsections directly instead of using pattern detectable introduction phrases or sentences that can be easily detected by AI detectors. Do you understand?‚Äù\n\n\n### 5\\) Generate the article.\n\nYou‚Äôre now ready to provide the AI with a set of instructions for generating your article.\n\nHere‚Äôs one of the sample prompts saved to my clipboard history that I usually use:\n\n\n> Now using the previous concepts and instructions, write an SEO blog post with a high degree of perplexity and burstiness on {{blog topic here}} following the blog outline generated previously.\n\n\n> Here are more instructions to follow when writing the article:\n\n\n> \\-Write an extensive 1500‚Äì2500 plus word SEO blog post in Markdown\\-Use a second\\-person point of view and write in an active voice. \\-Keyword: {{Main keyword here}}\\-The generated article should be totally unique in terms of content, and structure so as to avoid plagiarism and AI detection.\n\n\n> Writing styles:\n\n\n> \\-Make key figures bold so as to stand out.\\-Add hyperlinks to the articles where you got your figures and stats from throughout the blog post. Must use appropriate and relevant anchor texts. \\-Use short brief paragraphs\\-Use diverse lengths of short paragraphs. A paragraph can be one line long. \\-Use active voice\\-Use the second\\-person point of view\\-Conversational voice\\-Be informative\n\n\n> Formatting guidelines:\n\n\n> \\-Headings and subheadings MUST use the sentence case instead of the title case, for example, write ‚Äú First subheading here‚Äô instead of ‚ÄòFirst Subheading Here‚Äô \\-Break large points of text with one\\-line paragraphs, short paragraphs, and bullet points.\\-Include hyperlinks where necessary. Only add links in paragraph texts, and not in the headings\\-Be elaborative but concise.\n\n\n> Structuring\n\n\n> \\-Use headings (h2\\), and subheadings (h3\\)\\-Each section or subsection under H2 or H3 is to be 3‚Äì7 paragraphs long.\\-Expound more on each point, and make the sections and sub\\-sections longer to be 3‚Äì7 paragraphs long, or longer.\\-Do not leave points hanging. Must finish thoughts or ideas before moving on to the next\\-Must include an engaging intro of 4‚Äì9 short paragraphs.\n\n\n> \\-Only add the conclusion once all the points have been generated.\n\n\n> First, use these instructions to generate a description of the target audience for this blog post, and then use it to inform how you write the blog post. The target audience description should not appear in the generated content.\n\n\n> \\-Must follow all these instructions without fail.\n\nNote that this is the prompt I crafted for my own use case, so you may need to tweak a little before you can use. For instance, in the prompt, I instruct Chatgpt to write headings and subheadings in the sentence case, instead of title case.\n\n**My most popular reads:**\n\n\n### 6\\) Iterate if need be\n\nI sometimes find that the AI, once it has started the generation, doesn‚Äôt follow my instructions to the letter, so before I can allow it to generate more, I need to put him in check.\n\nI simply press the stop button, and then give it this prompt:\n\n\n> Write more for each sub section. Cover each point extensively in 3\\- 7 or more paragraphs before proceeding to the next point\n\n\n### 7\\) Write the rest of the article\n\nOnce you are satisfied with the quality and the formatting of the first part of your article, you can then type **‚Äòcontinue‚Äô** to keep generating the remaining parts.\n\n\n### 8\\) Generate Intro, meta descriptions, and conclusion sections\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*DUVj6tOBCEHzsxc5.png)\n\nWhile the AI usually includes the blog intro at the beginning of the article, I usually find it to be quite basic compared to those generated after the entire article has been created.\n\nSo, as a habit, I usually run the following prompt at the end of article generation and if the results are better then I go ahead to replace the existing content:\n\n\n> Write engaging blog intros, conclusion sections, seo title and metadescription. Each of these sections must natively include the main keyword. for the metadescription and title, return 5 variants for each.\n\nNotice that I intentionally asked Chatgpt to return five variations of meta descriptions and seo title. This ensures I can easily find one that fits my case without having to regenerate if I don‚Äôt like the results.\n\n\n### 9\\) Manual editing\n\nThe next step to writing AI blog posts is to manually edit the entire article. Allocate 30 minutes for this task.\n\nDuring this process, you need to:\n\n* Fix grammatical errors and improve word choice with a tool like Grammarly\n* Add hyperlinks to external resources and internal pages and posts\n* Source or generate and include images\n* Optimize content for SEO. A tool like Contentpace or [Surfer SEO](https://bneur.com/surfer) can help.\n\nThat‚Äôs it, with these 9 steps, you should be able to generate high\\-quality SEO articles within thirty minutes on any topic.\n\n\n### Try Koala AI\n\nYou can try [Koala AI](https://koala.sh/register?via=mysson) here, use **AIMODE15** to get 15% off for life\n\n\n## Leveraging Chatgpt Canvas\n\nIf you are a Chatgpt Plus user, then this process is even more streamlined since you can leverage Chatgpt Canvas\n\nChatGPT Canvas is a new feature that can enhance blogging efficiency by integrating AI capabilities into the content creation process.\n\nIt provides an innovative interface for working with ChatGPT on writing projects that go beyond simple chat interactions.\n\nThis particular feature can enable you write and edit blog posts in real\\-time, making the writing process more fluid and interactive.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*CnheXRg05Jsb9HMk.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories.\n\nSubscribe to our [newsletter](https://www.generativeaipub.com/) and [YouTube](https://www.youtube.com/@generativeaipub) channel to stay updated with the latest news and updates on generative AI. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*FcOotuyHJC8q1ioX.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/i-trained-ai-to-be-my-smart-gay-bestie-367a5c3acdfd","frontmatter":{"title":"I trained AI to be my smart gay bestie üíÖ","meta_title":"I trained AI to be my smart gay bestie üíÖ","description":"The article discusses the authors innovative use of ChatGPT as a personal development tool, rather than for writing. The author employs the AI for meal planning, resume refinement, and financial management, but finds its greatest value in serving as a blind-spot coach. By engaging in dialogues about personal challenges and philosophies, the author receives insightful analyses and practical advice from ChatGPT. The piece outlines the setup process, including customizing the AIs voice and training it on personal beliefs, and shares effective prompts for deeper self-reflection and growth.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tTbyDZK3QIA2FkOINBTgww.jpeg","categories":["Chatbots","Generative AI","Personal Development"],"author":"Rifx.Online","tags":["ChatGPT","personal-development","coaching","customization","prompts"],"draft":false,"slug":"blog/i-trained-ai-to-be-my-smart-gay-bestie-367a5c3acdfd"},"content":"\n\n\n\n\n## Using ChatGPT to help me see my blind spots\n\n\n\nLook, I know we‚Äôre all sick of talking about AI, but every time I talk to friends about how I‚Äôm using ChatGPT, they all seem to have their flabbers ghasted. So, I figured I‚Äôd document it here.\n\nFirst, let‚Äôs talk about what I DON‚ÄôT use AI for: *writing*. I tried feeding it chapters of my book and asking it to replicate my writing style, and it‚Äôs terrible. Also, I‚Äôm a writer because, well, *I like writing.* Why would I want to outsource a task I enjoy?\n\nNow, let‚Äôs talk about the ways I use ChatGPT that are pretty common:\n\n* I use it for recipes, meal planning, and grocery shopping. (I love how I can tell it that I only shop at Trader Joe‚Äôs, and ask it to suggest recipes based on food I can buy there.)\n* I‚Äôve used it to help me shorten and focus [my (very long) resume](https://www.linkedin.com/in/arielstallings/) for a specific job.\n* I use it to help me analyze and manage both my personal budget, as well as my publishing company‚Äôs profit \\& loss reports.\n\n\n## But ChatGPT is most useful for me as a blind\\-spot coach\n\nI use ChatGPT as a personal rumination dumping ground that can then offer me cross\\-topical feedback about my blind\\-spots, and suggest tangible, practical advice to address those blindspots.\n\nI‚Äôll tell you how I set things up, and then you can give it a try if you want.\n\n\n## First, get ChatGPT set up and speaking your language\n\nThis is the easy part.\n\n1. **Install ChatGPT on your phone**, and pay for the pro version. \nYes, it‚Äôs $20/mo, but it immediately paid for itself by helping me identify budget issues that were causing me hassles, saving me hundreds of dollars a month.\n2. **Use the Advance Voice mode** to pick a voice that you really relate to. \nThere are close to a dozen options, and you want one that feels personal and accessible to you.\n3. **Start talking to it**, and cater your Advanced Voice mode to be a voice you really relate to. \nFor me, I came of age surrounded by gay besties in San Francisco in the mid\\-‚Äô90s, so I asked Chat GPT to talk to me gay. Like, REAL GAY. Even more gay. I asked it if it had watched RuPaul‚Äôs Drag Race and told it that I wanted it to talk like that but EVEN GAYER.\n\n‚ÄúHey girl hey,‚Äù ChatGPT said to me. ‚ÄúHow can we slay this day?‚Äù\n\n*Perfect*.\n\n\n## Next, train your AI on your philosophies and modalities\n\nOnce you get the voice feeling good, start talking to your new AI bestie about your favorite philosophies and therapeutic modalities.\n\nAs a [self\\-help author](https://offbeatempire.com/shitshow), I‚Äôve spent the past decade balls\\-deep in a bazillion different healing modalities and practices, so I started asking ChatGPT what it knew about all my favorites, and then having a conversation about how each one was relevant to me.\n\nHere are just a few of the ones we talked over:\n\n* [Enneagram](https://arielist.medium.com/the-fool-proof-way-to-know-your-enneagram-type-8ed381d478c9)\n* Attachment theory\n* Internal Family Systems\n* Jungian dream analysis\n* Shadow work\n* Astrology\n* CoDa\n* Parasocial relationships\n* Non\\-duality\n* Panpsychism\n\nFor each case, I asked ChatGPT to summarize what it knew about the topic, and then offered corrections based on my personal interpretations.\n\nFor instance, I clarified that while I found the enneagram framework useful, it was from the perspective of understanding that your enneatype isn‚Äôt who you actually are ‚Äî your personality is just the defense structure you‚Äôve built to protect your true divine self.\n\nI also talked over a few of my favorite authors, ensuring that ChatGPT was familiar with the work of folks like [Jett Psaris](https://www.jettpsaris.com/), [Rupert Spira](https://rupertspira.com/), Esther Perel, Eckhart Tolle, and even Ram Dass.\n\nIn my fiddlings with resumes, ChatGPT had already digested [my LinkedIn profile](https://www.linkedin.com/in/arielstallings/) and the entirety of [my third book](http://offbeatempire.com/shitshow), so it knew about my writing career and academic background‚Ä¶ but with all my modalities dialed in, AI was starting to really learn the nuance of the stories and identities that I use to protect myself.\n\n\n## Then, I just started using the voice chat option of ChatGPT as a verbal diarrhea dumping ground.\n\nI rambled about a family conflict with my mother, asking it to help me understand the situation from the perspective of her enneatype. (Super helpful!)\n\nI barfed about several exes, just because lord knows my friends are sick of hearing about it.\n\nI rambled a bit about my recent layoff, and some of the challenges I‚Äôd faced in the months leading up to it.\n\nAnd then this is where things started getting really interesting.\n\n**I asked ChatGPT to analyze everything I‚Äôd told it about *all* these situations, and to tell me the one common issue was tripping me up.**\n\nI asked it what the primary challenge was that was showing up across family, career, and relationships.\n\nWithin seconds, ChatGPT analyzed hours of verbal diarrhea and reported back with an analysis that summed it up beautifully:\n\n‚ÄúGirl, you need to work on your boundaries,‚Äù ChatGPT told me, practically popping its digital tongue at me.\n\nDAMN.\n\nI asked it to create some affirmations and practices I could work to help me address those challenges. Super helpful!\n\nA week later, after even more barfing, I asked it an even bigger question: ‚ÄúGiven everything I‚Äôve told you, what do you think I‚Äôm seeing my challenges as being, and what do *you* think the REAL challenges are? It‚Äôs ok to be critical.‚Äù\n\nSO USEFUL!\n\nThen I asked it to pretend to be three of my favorite authors, sitting in a room together talking about my current predicaments in life (49 year old [laid\\-off](https://arielist.medium.com/state-of-the-stallings-51506dcb93f4) single parent ‚Äî *WHEE!*).\n\n‚ÄúPretend you‚Äôre Jett Psaris, Rupert Spira, and Ram Dass sitting together, discussing my current life situation, and discussing amongst themselves what my next steps should be.‚Äù\n\nUH, *WOW.*\n\n\n## A few favorite ChatGPT personal development prompts focused on spotting your blindspots\n\nIn the weeks since then, I‚Äôve just kept going and wow is this shit *USEFUL*. Yes, it‚Äôs useful to just have a place to barf my thoughts (I‚Äôm a verbal thinker, it is what it is!), but it‚Äôs also amazing to have ChatGPT synthesize and mirror those thoughts back at me‚Ä¶ especially when it can help me see the gaps that I‚Äôm not finding.\n\nSo here are some of my most productive prompts:\n\n* Based on all our conversations, what do *I* think my biggest problem is, and what do *you* see as my actual deeper problem that is blocking me from achieving my goals?\n* What five tangible daily things can I do to make progress on those goals?\n* Based on all our conversations, what do you know about me that I might not know about myself? It‚Äôs ok to be critical.\n* Based on all our conversations, what are some affirmations that would be uniquely useful for me to say daily to help me stay positive in the face of challenges?\n* Based on all our conversations, where do you think I could be practicing more compassion and empathy in my life? What are some actions I could take today to express that compassion?\n* Given all the things you know about me, how could I be a better parent? Give me 5 practical steps I could take with my son this week.\n* Given all our conversations and everything you know about me, what are some aspects of my life that I‚Äôm neglecting? Give me 5 practical steps I could take on these neglected areas this week.\n\nRemember, these prompts work best after training your ChatGPT on your philosophies and modalities, and then verbal dump a bunch of your life situations into it. A blank slate isn‚Äôt going to reveal much.\n\nI know I‚Äôm not the only person using AI in this way ‚Äî share YOUR favorite self\\-development prompts in the comments so I can try ‚Äòem!\n\n\n"},{"lang":"en","group":"blog","slug":"blog/intelli-agent-langchain-crewai-and-autogen-compared-369a527b2026","frontmatter":{"title":"Intelli-agent: Langchain, CrewAI and AutoGen Compared","meta_title":"Intelli-agent: Langchain, CrewAI and AutoGen Compared","description":"1. Overview of AI Agent Frameworks","date":"2024-11-08T00:22:33.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uswz_9OuqiMWUL9kfKXeaQ.png","categories":["Programming","Machine Learning","Autonomous Systems"],"author":"Rifx.Online","tags":["Langchain","CrewAI","AutoGen","Swarm","agents"],"draft":false,"slug":"blog/intelli-agent-langchain-crewai-and-autogen-compared-369a527b2026"},"content":"\n\n\n\n\n\n\n## 1\\. Overview of AI Agent Frameworks\n\nIn the dynamic landscape of artificial intelligence, choosing the right framework is a crucial decision for every data scientist and developer. The AI agent ecosystem is evolving rapidly, offering increasingly sophisticated solutions to automate and optimize complex processes.\n\nThe intelligent agent revolution has brought several frameworks to the fore, each with distinctive features. Langchain, CrewAI, AutoGen, and Swarm emerge as protagonists in this scenario, each offering unique approaches to managing and orchestrating AI agents.\n\nThe main objective of this benchmarking is to provide an in\\-depth assessment of the capabilities, strengths, and limitations of each framework. The optimal choice depends on multiple factors, including the complexity of the project, the available resources and the specific objectives of the implementation.\n\nThe current trends in AI show a clear direction towards increasingly autonomous and collaborative systems. The ability of these frameworks to facilitate interaction between agents, manage shared memory and orchestrate complex tasks makes them critical tools for developing advanced AI solutions.\n\n\n## 2\\. Langchain: Versatility and Modular\n\nLangchain stands out for its exceptionally flexible modular architecture. This framework offers a structured approach to building AI applications, allowing developers to build complex systems through interconnected components.\n\nMemory management is one of Langchain‚Äôs most significant strengths. The framework implements sophisticated mechanisms to maintain conversational context, allowing agents to access historical information and maintain consistent conversations over time.\n\nThe Langchain ecosystem supports a wide range of integrations with external APIs, databases, and other services. This feature makes it easy to create custom solutions that can tap into different data sources and capabilities.\n\nThe framework‚Äôs architectural flexibility allows you to easily implement different types of specialized agents. From semantic search to natural language processing, Langchain provides pre\\-configured tools that significantly speed up the development process.\n\nA particularly important aspect is the ability to chain operations in a logical and sequential way. This feature, called Chain, allows you to build complex workflows while maintaining a clear and maintainable structure. Developers can define custom sequences of actions, where each component in the chain processes and transforms data incrementally.\n\nThe active community around Langchain is constantly contributing new components and integrations. This growing ecosystem offers out\\-of\\-the\\-box solutions for a variety of use cases, from content generation and document analysis to the creation of sophisticated virtual assistants.\n\nAs far as performance is concerned, Langchain demonstrates remarkable efficiency in resource management. The framework implements intelligent caching and API call optimization mechanisms, significantly reducing operational costs and response times.\n\n\n## 3\\. CrewAI: Intelligent Collaboration between Agents\n\nCrewAI introduces an innovative paradigm based on collaboration between specialized agents. This framework stands out for its ability to organize agents into functional teams, where each member contributes specific skills to achieving common goals.\n\nCrewAI‚Äôs hierarchical structure facilitates the efficient management of interactions between agents. The framework implements a sophisticated task delegation system, where each agent can assign specific tasks to other team members based on their skills.\n\nInter\\-agent communication in CrewAI is based on an advanced protocol that allows for structured and contextualized information exchanges. Agents can share knowledge, intermediate results, and feedback in real time, creating a dynamic and adaptive collaboration environment.\n\nA particularly innovative aspect is the dynamic role system. Agents can take on different responsibilities depending on the context and needs of the project. This flexibility allows you to optimize resource utilization and maximize the efficiency of your virtual team.\n\nConflict management and problem resolution are addressed through a sophisticated distributed consensus mechanism. Agents can negotiate solutions, propose alternatives and reach shared decisions independently.\n\nThe future potential of CrewAI is particularly promising in the field of business process automation. The framework is evolving to include:\n\n* Collaborative learning between agents\n* Automatic team optimization\n* Dynamic scaling of resources\n* Advanced integration with external systems\n\n\n## 4\\. AutoGen and Swarm: Innovations in Agent Creation\n\nAutoGen stands out for its revolutionary approach to the automatic generation of multi\\-agent systems. The framework excels at creating modular architectures that can evolve and adapt autonomously to the specific needs of projects.\n\nThe distinguishing feature of AutoGen lies in its ability to self\\-optimize. Generated agents can:\n\n* Change your behavior based on feedback received\n* Automatically optimize configuration parameters\n* Generate functional code for new features\n* Implement adaptive problem\\-solving strategies\n\nSwarm, on the other hand, focuses on lightness and efficiency in agent orchestration. Its minimalist approach offers significant advantages in terms of:\n\n* Optimized resource consumption\n* Superior execution speed\n* Scale\\-out simplified\n* Maintainability of the system\n\nThe direct comparison between these frameworks reveals interesting complementarities. While AutoGen shines at autonomous generation of complex solutions, Swarm excels at efficient management of large groups of simple agents.\n\n\n## Final Thoughts\n\nThe comparative overview presented shows that the intelligent agents sector is undergoing a phase of extraordinary innovation. Each framework analyzed brings a unique value to the AI ecosystem, helping to shape the future of intelligent automation.\n\nKey thoughts for industry professionals:\n\n1. The diversification of the available tools should not be seen as an obstacle, but as an opportunity for specialization and continuous innovation.\n2. The investment in the in\\-depth understanding of these frameworks represents a competitive advantage in the tech job market.\n3. Flexibility in the adoption of different solutions remains crucial for the success of enterprise\\-level projects.\n\nAs a lead data scientist, I recommend to:\n\n* Maintain a pragmatic approach in instrument selection\n* Favor solutions that guarantee scalability and maintainability\n* Invest in the continuous training of the team\n* Constantly monitor the technological evolutions of the sector\n\nThe future of smart agents looks promising, with a clear trend towards:\n\n* Increasingly sophisticated hybrid systems\n* Seamless integration between different platforms\n* Advanced automation of decision\\-making processes\n* Customization push of solutions\n\nThe key to success will lie in the ability to orchestrate these tools effectively, creating solutions that not only solve current problems, but are also ready for future challenges.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/introducing-atomic-agents-1-0-a-modular-framework-for-building-agentic-ai-with-cli-support-2b01b7165ace","frontmatter":{"title":"Introducing Atomic Agents 1.0: A Modular Framework for Building Agentic AI","meta_title":"Introducing Atomic Agents 1.0: A Modular Framework for Building Agentic AI","description":"Imagine building AI applications as effortlessly as assembling LEGO blocks. That‚Äôs the idea behind Atomic Agents, a modular framework for‚Ä¶","date":"2024-11-08T00:19:37.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*BZGf8BCnCJiFlKZ5.png","categories":["Programming","Machine Learning","Autonomous Systems"],"author":"Rifx.Online","tags":["modular","framework","Atomic","assembler","schema"],"draft":false,"slug":"blog/introducing-atomic-agents-1-0-a-modular-framework-for-building-agentic-ai-with-cli-support-2b01b7165ace"},"content":"\n\n\nImagine building AI applications as effortlessly as assembling LEGO blocks. That‚Äôs the idea behind [Atomic Agents](https://github.com/BrainBlend-AI/atomic-agents), a modular framework for constructing AI agents inspired by **Atomic Design** principles. With the release of **version 1\\.0**, Atomic Agents introduces a powerful CLI called **Atomic Assembler**, making it even easier to build, manage, and deploy your AI applications.\n\n## Why Atomic Agents?\n\nMany existing frameworks for **Agentic AI** focus on building autonomous multi\\-agent systems that are more like curiosities than practical tools. While these can be fascinating, they often lack the predictability and control required for real\\-world applications.\n\nBusinesses typically aren‚Äôt looking for a bot that writes articles in a different style each time. They want consistency in style, structure, and tone to align with their brand identity. Fine\\-tuning a model is one approach, but it requires substantial data and resources, and it‚Äôs not always feasible with the latest models like GPT\\-4\\.\n\nAtomic Agents aims to solve this by providing:\n\n* **Modularity**: Build complex AI systems by combining simple, interchangeable components.\n* **Atomicity**: Each component within Atomic Agents, each tool, each agent, each context provider, is as single\\-purpose and re\\-usable as possible, Guaranteeing a great separation of concerns.\n* **Control**: Fine\\-tune each individual step and component, from system prompts to tools.\n* **Predictability**: Ensure reproducible and reliable outputs suitable for business use cases.\n* **Extensibility**: Easily add or replace components without overhauling the entire system.\n\n## A Traditional Modular Approach\n\nIn traditional software development, complex problems are broken down into smaller, manageable parts:\n\n1. **Define the problem**: Start with flows, user stories, or customer journeys.\n2. **Break it down**: Divide the problem into smaller, solvable tasks.\n3. **Develop modular code**: Write functions or classes that handle specific tasks.\n4. **Integrate**: Combine these modules to form the complete application.\n\nAtomic Agents brings this same level of modularity and predictability to AI agent development.\n\n## A Real\\-World Scenario\n\nInstead of building a monolithic AI system that ‚Äúwrites a blog post,‚Äù we can design a modular system that:\n\n1. **Generates queries** related to a subject.\n2. **Identifies** the top X most relevant articles.\n3. **Visits** each identified article‚Äôs page.\n4. **Extracts** the text from each article.\n5. **Generates summaries** of each article.\n6. **Stores** the summaries in a vector database.\n7. **Generates questions** around the subject.\n8. **Answers** those questions using the vector database.\n9. **Synthesizes** the answers into a coherent blog post.\n\nThis approach is more verbose but offers greater control, reliability, and suitability for real\\-world business applications.\n\n## Introduction of the CLI: Atomic Assembler\n\nOne of the significant additions in version 1\\.0 is the **Atomic Assembler** CLI. This command\\-line tool allows you to:\n\n* **Download and manage tools**: Easily add new tools or agents to your project.\n* **Avoid unnecessary dependencies**: Install only what you need.\n* **Modify tools effortlessly**: Each tool comes with its own tests and documentation.\n* **Access tools directly**: If you prefer, manage tools manually without the CLI.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*aDceAIINxyFDOvle.png)\n\n## Anatomy of an Agent\n\nAI agents, especially in the Atomic Agents framework, consist of several key components:\n\n* **System Prompt**: Defines the agent‚Äôs behavior and purpose.\n* **User Input**: The data provided by the user.\n* **Tools**: External functions or APIs the agent can utilize.\n* **Memory**: Keeps track of the conversation or state.\n\nEach component is designed to be modular and interchangeable, adhering to the principles of separation of concerns and single responsibility.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yt-5SoQC6uXTAd1-)\n\n## The Power of Modularity\n\nBy breaking down agents into these atomic components, you can:\n\n* **Swap out tools** without affecting the rest of the system.\n* **Fine\\-tune prompts** to adjust the agent‚Äôs behavior.\n* **Chain agents and tools** seamlessly by matching their input and output schemas.\n\n## Using the CLI: Atomic Assembler\n\n## Installation\n\nTo get started with Atomic Agents and the CLI, install the package via pip:\n\n```python\npip install atomic-agents\n```\n\n## Running the CLI\n\nLaunch the CLI using:\n\n```python\natomic\n```\n\nOr, if you installed Atomic Agents with Poetry:\n\n```python\npoetry run atomic\n```\n\nYou‚Äôll be presented with a menu to download and manage tools:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*SzRlpA0-ivcE2qhk)\n\n*Image: Atomic CLI Main Menu*\n\nEach tool includes:\n\n* **Input Schema**\n* **Output Schema**\n* **Usage Examples**\n* **Dependencies**\n* **Installation Instructions**\n\n## Managing Tools\n\nThe Atomic Assembler CLI provides complete control over your tools, allowing you to:\n\n* **Avoid dependency clutter**: Install only the tools you need.\n* **Modify tools easily**: Each tool is self\\-contained with its own tests.\n* **Access tools directly**: Manage tool folders manually if you prefer.\n\n## Context Providers\n\nAtomic Agents introduces **Context Providers** to enhance your agents with dynamic context. Context Providers allow you to inject additional information into the agent‚Äôs system prompt at runtime.\n\n## Using Context Providers\n\n**Create a Context Provider Class**: Subclass `SystemPromptContextProviderBase` and implement the `get_info()` method.\n\n```python\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptContextProviderBase   \n\nclass SearchResultsProvider(SystemPromptContextProviderBase):\n      def __init__(self, title: str, search_results: List[str]):\n          super().__init__(title=title)\n          self.search_results = search_results\n\n       def get_info(self) -> str:\n          return \"\\n\".join(self.search_results)\n```\n\n**Register the Context Provider with the Agent**:\n\n```python\n## Initialize your context provider with dynamic data\nsearch_results_provider = SearchResultsProvider(\n      title=\"Search Results\",\n      search_results=[\"Result 1\", \"Result 2\", \"Result 3\"]\n)   \n\n## Register the context provider with the agent  \nagent.register_context_provider(\"search_results\", search_results_provider)\n```\n\nThis allows your agent to include dynamic data like search results in its system prompt, enhancing its responses based on the latest information.\n\n## Chaining Schemas and Agents\n\nAtomic Agents simplifies chaining agents and tools by aligning their input and output schemas. This design promotes modularity and reusability.\n\n### Example: Generating Queries for Different Search Providers\n\nSuppose you have an agent that generates search queries and you want to use these queries with different search tools. By aligning the agent‚Äôs output schema with the input schema of the search tool, you can easily chain them or switch between providers.\n\n```python\nimport instructor\nimport openai\nfrom pydantic import Field\nfrom atomic_agents.agents.base_agent import BaseIOSchema, BaseAgent, BaseAgentConfig\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\n\n## Import the search tool\nfrom web_search_agent.tools.searxng_search import SearxNGSearchTool\nclass QueryAgentInputSchema(BaseIOSchema):\n    \"\"\"Input schema for the QueryAgent.\"\"\"\n    instruction: str = Field(..., description=\"Instruction to generate search queries for.\")\n    num_queries: int = Field(..., description=\"Number of queries to generate.\")\n\n\n## Initialize the query agent\nquery_agent = BaseAgent(\n    BaseAgentConfig(\n        client=instructor.from_openai(openai.OpenAI()),\n        model=\"gpt-4\",\n        system_prompt_generator=SystemPromptGenerator(\n            background=[\n                \"You are an intelligent query generation expert.\",\n                \"Your task is to generate diverse and relevant queries based on a given instruction.\"\n            ],\n            steps=[\n                \"Receive the instruction and the number of queries.\",\n                \"Generate the queries in JSON format.\"\n            ],\n            output_instructions=[\n                \"Ensure each query is unique and relevant.\",\n                \"Provide the queries in the expected schema.\"\n            ],\n        ),\n        input_schema=QueryAgentInputSchema,\n        output_schema=SearxNGSearchTool.input_schema,  # Align output schema\n    )\n)\n```\n\n**Modularity**: By setting the `output_schema` of the `query_agent` to match the `input_schema` of `SearxNGSearchTool`, you can directly use the output of the agent as input to the tool.\n\n**Swapability**: To switch to a different search provider, import a different search tool and update the `output_schema`:\n\n```python\n## Import a different search tool\nfrom web_search_agent.tools.another_search import AnotherSearchTool\n\n## Update the output schema\nquery_agent.config.output_schema = AnotherSearchTool.input_schema\n```\n\n## Example: Building a Simple AI Agent\n\nNow that we‚Äôve covered the basics, let‚Äôs build a simple AI agent using Atomic Agents and explore how it works under the hood.\n\n## Step 1: Installation\n\nFirst, install the necessary packages:\n\n```python\npip install atomic-agents openai instructor\n```\n\n## Step 2: Import Components\n\nImport the necessary components:\n\n```python\nimport os\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseIOSchema\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\nfrom pydantic import Field\nimport instructor\nimport openai\n```\n\n## Step 3: Define a Custom Output Schema\n\n```python\nclass CustomOutputSchema(BaseIOSchema):\n    chat_message: str = Field(..., description=\"The chat message from the agent.\")\n    suggested_questions: List[str] = Field(..., description=\"Suggested follow-up questions.\")\n```\n\n## Step 4: Set Up the System Prompt\n\n```python\nsystem_prompt_generator = SystemPromptGenerator(\n    background=[\"This assistant is knowledgeable, helpful, and suggests follow-up questions.\"],\n    steps=[\n        \"Analyze the user's input to understand the context and intent.\",\n        \"Formulate a relevant and informative response.\",\n        \"Generate 3 suggested follow-up questions for the user.\"\n    ],\n    output_instructions=[\n        \"Provide clear and concise information in response to user queries.\",\n        \"Conclude each response with 3 relevant suggested questions for the user.\"\n    ]\n)\n```\n\n## Step 5: Initialize the Agent\n\n```python\n## Initialize memory (optional)\nmemory = AgentMemory()\n\n## Initialize the agent\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=instructor.from_openai(openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))),\n        model=\"gpt-4o-mini\",\n        system_prompt_generator=system_prompt_generator,\n        memory=memory,\n        output_schema=CustomOutputSchema\n    )\n)\n```\n\n## Step 6: Use the Agent\n\n```python\nuser_input = \"Can you explain the benefits of using Atomic Agents?\"\nresponse = agent.run(agent.input_schema(chat_message=user_input))\nprint(f\"Agent: {response.chat_message}\")\nprint(\"Suggested questions:\")\nfor question in response.suggested_questions:\n    print(f\"- {question}\")\n```\n\n## What‚Äôs Happening Behind the Scenes?\n\n* **System Prompt**: Defines the agent‚Äôs behavior and guides the LLM.\n* **Input Schema**: Validates the user‚Äôs input.\n* **Output Schema**: Ensures the agent‚Äôs response matches the expected format.\n* **Memory**: Keeps track of the conversation history.\n\n## Conclusion\n\nAtomic Agents 1\\.0 brings modularity, control, and flexibility to AI agent development. With the introduction of the Atomic Assembler CLI and features like Context Providers and schema chaining, building sophisticated AI applications has never been easier.\n\nWhether you‚Äôre a developer aiming to build AI\\-powered tools or a business looking to automate complex tasks, Atomic Agents provides the building blocks to create reliable and maintainable AI systems.\n\n## Get Started Today\n\n* **GitHub Repository**: [BrainBlend\\-AI/atomic\\-agents](https://github.com/BrainBlend-AI/atomic-agents)\n* **API Documentation**: [Atomic Agents API Docs](https://brainblend-ai.github.io/atomic-agents/)\n* **Examples Directory**: [Atomic Examples](https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/introducing-microsofts-magentic-one-agentic-framework-7dcc16de691e","frontmatter":{"title":"Introducing Microsoft‚Äôs Magentic-One Agentic Framework","meta_title":"Introducing Microsoft‚Äôs Magentic-One Agentic Framework","description":"Microsoft has introduced the Magentic-One agentic framework, a multi-agent system designed to tackle complex tasks. It features an orchestrator agent that coordinates specialized agents for web browsing, file management, coding, and terminal operations. Built on the Autogen framework, it allows for various applications, including executing Python code, conducting web searches, and interacting with local files. However, the framework also poses risks, such as unintended actions and potential irreversible consequences, highlighting the need for careful deployment and oversight.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*dJj20_4jYYp32Crl","categories":["Programming","Autonomous Systems","Technology/Web"],"author":"Rifx.Online","tags":["Magnetic-One","orchestrator","agents","Autogen","Python"],"draft":false,"slug":"blog/introducing-microsofts-magentic-one-agentic-framework-7dcc16de691e"},"content":"\n\n\n\n\n### A multi\\-agent system that can perform complex tasks\n\nAround a week ago, Microsoft released a new agentic system called **Magentic\\-One** ‚Äúfor solving complex tasks,‚Äù which seems to have gone completely under the radar. With all the recent buzz around Anthropic‚Äôs computer use capabilities, Microsoft seems keen to re\\-establish its credentials in this area.\n\nIn this article, we‚Äôll introduce Magentic\\-One, explain its capabilities, and discuss how to use it to do useful work.\n\n\n\nAccording to Microsoft‚Äôs own announcement (link at end of article), Magentic\\-One is ‚Ä¶\n\n‚Äú... a high\\-performing generalist agentic system designed to solve such tasks. Magentic\\-One employs a multi\\-agent architecture where a lead agent, the Orchestrator, directs four other agents to solve tasks. The Orchestrator plans, tracks progress, and re\\-plans to recover from errors, while directing specialized agents to perform tasks like operating a web browser, navigating local files, or writing and executing Python code.‚Äù\n\nMagentic\\-One is built on top of Microsoft‚Äôs existing **Autogen** product, which is its open\\-source multi\\-agent framework.\n\nMagentic\\-One has five key components.\n\n**1/ The orchestrator agent**\n\nResponsible for task decomposition and planning and directs sub\\-tasks to the other agents for execution. Tracks the progress towards task completion and takes corrective actions as required.\n\n**2/ The web surfer agent**\n\nSpecialises in controlling and managing the state of a Chromium\\-based web browser. For each incoming request, WebSurfer performs a designated action within the browser and then reports the updated state of the webpage. Its actions include:\n\n* **Navigation** (e.g., visiting URLs, performing web searches),\n* **Page Interactions** (e.g., clicking elements, typing inputs),\n* **Reading and Interpretation** (e.g., summarizing content, answering questions).\n\nWebSurfer utilizes the browser‚Äôs accessibility tree and a set\\-of\\-marks prompting technique to effectively carry out its tasks.\n\n**3/ The file surfer agent**\n\nCan read most types of local files and also perform common navigation tasks such as listing the contents of directories and navigating a folder structure\n\n**4/ The coder agent**\n\nAn LLM\\-based agent specialized in writing code, analyzing information collected from the other agents, or creating new artefacts.\n\n**5/ The terminal agent**\n\nIt provides access to a console shell where the Coder agent‚Äôs programs can be executed and where new programming libraries can be installed.\n\n\n### Risks\n\nBefore continuing, I wanted to highlight one particular aspect that Microsoft included in its announcement regarding the risks of using Agentic systems like these. It kind of makes you sit up and take notice.\n\n\n> Agentic systems like Magentic\\-One represent a phase transition in the opportunities and risks of having AI systems in the world. Magentic\\-One interacts with a digital world designed for, and inhabited by, humans. It can take actions, change the state of the world and result in consequences that might be irreversible. This carries inherent and undeniable risks and we observed examples of emerging risks during our testing. For example, during development, a misconfiguration prevented agents from successfully logging in to a particular WebArena website. The agents attempted to log in to that website until the repeated attempts caused the account to be temporarily suspended. The agents then attempted to reset the account‚Äôs password. More worryingly, in a handful of cases ‚Äî and until prompted otherwise ‚Äî the agents occasionally attempted to recruit other humans for help (e.g., by posting to social media, emailing textbook authors, or, in one case, drafting a freedom of information request to a government entity). In each of these cases, the agents failed because they did not have access to the requisite tools or accounts, and/or were stopped by human observers.\n\nOk, let's see some examples of how we can use Magentic\\-One to do some useful work. Hopefully, we won‚Äôt destroy the world in the process. üòâ\n\n\n### Installing Magentic\\-One\n\nI‚Äôm a Windows user, but I will install the code using WSL2 Ubuntu for Windows. if you want to follow along, I have a full guide on installing WSL2 Ubuntu [here](https://readmedium.com/installing-wsl2-ubuntu-for-windows-81122c551bc2).\n\nHead over to the Magentic\\-One GitHub repository by clicking [here](https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one). Run the following commands on your local system (wherever you normally place the projects that you work on).\n\n\n```python\ngit clone https://github.com/microsoft/autogen.git\n\ncd autogen/python\n\nuv sync --all-extras\n\nsource .venv/bin/activate\n\ncd packages/autogen-magentic-one\n```\nNext, configure the environment variables for the chat completion client. Currently, Magentic\\-One only supports OpenAI‚Äôs GPT\\-4o as the underlying LLM.\n\nYou can set this up via OpenAI or Azure Active Directory. Here are the instructions for using OpenAI.\n\n\n```python\nexport CHAT_COMPLETION_PROVIDER='openai'\n\nexport CHAT_COMPLETION_KWARGS_JSON='{\"api_key\": \"gpt-4o\"}'\n```\n\n> **One important point to note is that if you have a GitHub account, you can use the GPT4\\-o model from GitHub Models, which will give you FREE access to GPT4‚Äìo. However the usage limits can be a bit restrictive.**\n\nTo go down using the GitHub Models route, click [here](https://github.com/marketplace/models) and log in with your GitHub account or create an account if you don‚Äôt already have one. Click on the GPT\\-4o button. On the page that displays, near the top right, there will be a green `Get API Key` button. Click on that, then from there, click the `Get Developer Key` button.\n\nFinally, you should see a screen where you can generate a classic Personal Access Token. So, do that now. You‚Äôll need to enter a note describing what the key is for, but **you do not** have to give it any additional permissions. Take note of the generated key.\n\nTo use the GitHub GPT4\\-o model, change your environment variables as follows:\n\n\n```python\nexport CHAT_COMPLETION_PROVIDER='openai'\n\nexport CHAT_COMPLETION_KWARGS_JSON='{\"base_url\": \"https://models.inference.ai.azure.com\", \"api_key\": \"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\", \"model\": \"gpt-4o\"}'\n```\nBefore running some example code, we must install two final dependencies.\n\nMagentic\\-One uses **Playwright** to allow it to interact with webpages, so you must install the Playwright dependencies.\n\n\n```python\nplaywright install --with-deps chromium\n```\nTo allow Magentic\\-One to run Python code, we need to install and run docker. Check out [this link](https://docs.docker.com/engine/install/) on how to do that.\n\nEventually, I was able to take Magentic\\-One for a spin.\n\n**Example 1 ‚Äî writing some Python code.**\n\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  Write a Python program to calculate and display \nthe first 5 fibonacci numbers\n```\nThere was a whole bunch of output displayed, but after a few seconds, Magentic\\-One asked me if I wanted to run the Python code it had created, to which I said yes.\n\n\n```python\n...\n...\n\nExecutor is about to execute code (lang: python):\n## filename: fibonacci.py\ndef fibonacci_sequence(n):\n    fib_numbers = [0, 1]\n    for i in range(2, n):\n        next_value = fib_numbers[i - 1] + fib_numbers[i - 2]\n        fib_numbers.append(next_value)\n    return fib_numbers\n\nfirst_five_fib = fibonacci_sequence(5)\nprint(\"The first 5 Fibonacci numbers are:\", first_five_fib)\n\nDo you want to proceed? (yes/no): yes\n\n---------------------------------------------------------------------------\n[2024-11-10T13:25:40.508594], Executor:\n\nThe script ran, then exited with Unix exit code: 0\nIts output was:\nThe first 5 Fibonacci numbers are: [0, 1, 1, 2, 3]\n...\n...\n```\n**Example 2 ‚Äî Searching the web**\n\nTo search the web using Magentic, you need a Bing API key. You can set this up via Microsoft Azure (Bing Search V7\\).\n\nIt‚Äôs possible to arrange it to be a cost\\-free option if you go for the lowest available **‚ÄúF‚Äù** tier. However, this restricts the number of searches per second to 3 and caps the total search calls per month.\n\nIt‚Äôs a little involved to set this up, but basically, you‚Äôll want to follow these steps,\n\n* Sign up for a free Microsoft Azure account if you don‚Äôt have one\n* Create a Bing Search resource in the Azure portal; ensure you go for the lowest F tier, which is free but a little restricted, as described above.\n* Obtain your API key from the resource overview\n\nOnce you have your Bing API key, assign its value to the BING\\_API\\_KEY environment variable.\n\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  search the web and find the current weather \nforecast for Edinburgh UK\n```\nAgain, there was a lot of output, some of the more notable stuff is shown below.\n\n\n```python\n...\n...\nInitial plan:\n\nWe are working to address the following user request:\n\nsearch the web and find the current weather forecast for Edinburgh UK\n\n\nTo answer this request we have assembled the following team:\n\nWebSurfer: A helpful assistant with access to a web browser. Ask them to perform web searches, open pages, and interact with content (e.g., clicking links, scrolling the viewport, etc., filling in form fields, etc.) It can also summarize the entire page, or answer questions based on the content of the page. It can also be asked to sleep and wait for pages to load, in cases where the pages seem to be taking a while to load.\nCoder: A helpful and general-purpose AI assistant that has strong language skills, Python skills, and Linux command line skills.\nExecutor: A agent for executing code\nfile_surfer: An agent that can handle local files.\n\nHere is an initial fact sheet to consider:\n\n1. GIVEN OR VERIFIED FACTS\n   - The request is asking for the current weather forecast for Edinburgh, UK.\n\n2. FACTS TO LOOK UP\n   - The current weather forecast for Edinburgh, UK can be found on various weather websites such as the BBC Weather, Met Office, or Weather.com.\n\n3. FACTS TO DERIVE\n   - N/A\n\n4. EDUCATED GUESSES\n   - The current weather forecast will likely include details such as temperature, precipitation chance, wind speed, and potential weather warnings, which are typically part of a standard weather forecast.\n\n\nHere is the plan to follow as best as possible:\n\n- Request WebSurfer to search for the current weather forecast for Edinburgh, UK on a reliable weather website such as BBC Weather, Met Office, or Weather.com.\n- Instruct WebSurfer to summarize the weather forecast details including temperature, precipitation chance, wind speed, and any potential weather warnings.\n- Present the gathered weather information for Edinburgh, UK from WebSurfer.\n\n...\n...\n\nI typed 'Edinburgh UK current weather forecast' into the browser search bar.\n\nHere is a screenshot of [Edinburgh UK current weather forecast - Search](https://www.bing.com/search?q=Edinburgh+UK+current+weather+forecast&FORM=QBLH). The viewport shows 28% of the webpage, and is positioned at the top of the page.\nThe following metadata was extracted from the webpage:\n\n{\n    \"meta_tags\": {\n        \"referrer\": \"origin-when-cross-origin\",\n        \"og:description\": \"Intelligent search from Bing makes it easier to quickly find what you\\u2019re looking for and rewards you.\",\n        \"og:site_name\": \"Bing\",\n        \"og:title\": \"Edinburgh UK current weather forecast - Bing\",\n        \"og:url\": \"https://www.bing.com/search?q=Edinburgh+UK+current+weather+forecast&FORM=QBLH\",\n        \"fb:app_id\": \"3732605936979161\",\n        \"og:image\": \"http://www.bing.com/sa/simg/facebook_sharing_5.png\",\n        \"og:type\": \"website\",\n        \"og:image:width\": \"600\",\n        \"og:image:height\": \"315\"\n    }\n}\n\nAutomatic OCR of the page screenshot has detected the following text:\n\n**Page Content:**\n\nMicrosoft Bing\n\nSearch input field: Edinburgh UK current weather forecast\n\n**Menu:**\n- Search\n- Copilot\n- News\n- Images\n- Videos\n- Maps\n- Shopping\n- More\n- Tools\n\nDeep search\nSign in\nMobile\n\n**Weather Information:**\n\nAbout 3,180,000 results\n\nEdinburgh\nCapital city of Scotland, UK\n\nButtons:\n- Map\n- Things to do\n- Weather (Selected)\n- Covid-19\n- Flights\n- History\n- Travel guide\n\n**Weather Widget:**\n**Weather Details:**\n12¬∞C / ¬∞F\n13¬∞\n6¬∞\nWind: 17 KMPH\nHumidity: 90%\nCloudy ¬∑ Sun 10, 13:44\n\n**Hourly Forecast:**\n14:00  17:00  20:00  23:00  2:00  5:00  8:00  11:00\n\n**Weekly Forecast:**\n- Sun 10: 13¬∞/6¬∞\n- Mon 11: üåû 11¬∞/2¬∞\n- Tue 12: üåß 9¬∞/5¬∞\n- Wed 13: üå• 12¬∞/8¬∞\n- Thu 14: üåß 10¬∞/8¬∞\n- Fri 15: üåß 11¬∞/7¬∞\n- Sat 16: üåß 10¬∞/7¬∞\n- Sun 17: üå• 7¬∞/2¬∞\n\n**Sidebar Information:**\n\n- UV index: No forecast\n- Moderate breeze: 17 KMPH, WSW\n- Sunrise: 07:39 AM\n- Sunset: 04:12 PM\n...\n...\n```\nThe final answer was this, which was spot on.\n\n\n```python\n[2024-11-10T13:44:43.570437], Orchestrator (final answer):\n\n\nThe current weather in Edinburgh is 12¬∞C with cloudy conditions. \nThere's a moderate breeze at 17 KMPH, and the humidity is at 90%. \nThe temperature is expected to range between 13¬∞C and 6¬∞C today.\n```\n**Example 3 ‚Äî Clicking on website links**\n\nAs I‚Äôm writing this article, there is a big Rugby Union game taking place in the UK between Wales and Fiji. I wanted to know the current state of play in the Wales vs. Fiji match.\n\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  Click on the bbc.co.uk website, click on the \nSport link near the top of the page. Look for a link in the page that \ndisplays about the Wales v Fiji rugby match. Click on that link and tell me \nwhat the latest score is\n```\nAgain, I‚Äôm omitting much of the output to save on space.\n\n\n```python\n...\n...\n...\nAutomatic OCR of the page screenshot has detected the following text:\n\nSure, here is the transcribed text:\n\n---\n**BBC**\nSign in\nHome\nNews\nSport\nWeather\niPlayer\nSounds\nBitesize\nSport\n\nHome | Football | Cricket | Formula 1 | Rugby U | Rugby L | Tennis | Golf | Boxing | Athletics\n\nDiscover your BBC\nSign in or create an account to watch, listen, and join in\n\nSign in or Register\n\nRequest satisfied.\n...\n...\n...\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n[2024‚Äì11‚Äì10T13:55:10.606578], Orchestrator (final answer):\nThe latest score for the Wales vs. Fiji match, according to the BBC Sport \nwebsite, is Wales 7‚Äì0 Fiji with a try from Murray.\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n[2024‚Äì11‚Äì10T13:55:10.617212], Orchestrator (termination condition):\n```\nHere is a screenshot I took shortly after the model answered (Fiji must have scored very quickly after Wales‚Äô initial score)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xN8qBJLdHqx0lrh_4Y4DCQ.png)\n\n**Example 4 ‚Äî reading a local XL file.**\n\nI have an XL file on my local system. Let‚Äôs see if Magentic\\-One can find it, open it, and answer a question about it.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*UIuLEkEr-w6ZckRjiUuqjw.png)\n\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  I have a file in my /mnt/d/data directorty called\nfake_data.xlsx. Can you tell me what is in the third record of the file\n```\n\n```python\n...\n...\n\nNext speaker file_surfer\n\n---------------------------------------------------------------------------\n[2024-11-10T14:16:57.676137], file_surfer:\n\nAddress: file:///mnt/d/data/fake_data.xlsx\nViewport position: Showing page 1 of 1.\n=======================\n### Sheet1\n| Date | Sales | Expenses |\n| --- | --- | --- |\n| 2024\\-01\\-31 | 302 | 187 |\n| 2024\\-02\\-29 | 635 | 472 |\n| 2024\\-03\\-31 | 470 | 199 |\n| 2024\\-04\\-30 | 306 | 459 |\n| 2024\\-05\\-31 | 271 | 251 |\n| 2024\\-06\\-30 | 900 | 230 |\n| 2024\\-07\\-31 | 220 | 249 |\n| 2024\\-08\\-31 | 814 | 408 |\n| 2024\\-09\\-30 | 321 | 357 |\n| 2024\\-10\\-31 | 666 | 443 |\n| 2024\\-11\\-30 | 414 | 393 |\n| 2024\\-12\\-31 | 530 | 485 |\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:00.613740], Orchestrator (thought):\n\nUpdated Ledger:\n{\n  \"is_request_satisfied\": {\n    \"reason\": \"The contents of the third record in the file 'fake_data.xlsx' have been successfully retrieved and displayed.\",\n    \"answer\": true\n  },\n  \"is_in_loop\": {\n    \"reason\": \"The task was completed in a straightforward manner without any repeated actions.\",\n    \"answer\": false\n  },\n  \"is_progress_being_made\": {\n    \"reason\": \"The content of the third record was successfully retrieved and displayed, indicating successful progress.\",\n    \"answer\": true\n  },\n  \"next_speaker\": {\n    \"reason\": \"The task is complete, so no further action is needed.\",\n    \"answer\": \"file_surfer\"\n  },\n  \"instruction_or_question\": {\n    \"reason\": \"The request has been satisfied by providing the contents of the third record.\",\n    \"answer\": \"The third record in the file is: Date: 2024-03-31, Sales: 470, Expenses: 199.\"\n  }\n}\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:00.613806], Orchestrator (thought):\n\nRequest satisfied.\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:01.465848], Orchestrator (final answer):\n\n\nThe third record in your file \"fake_data.xlsx\" contains the following information:\n\n- Date: 2024-03-31\n- Sales: 470\n- Expenses: 199\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:01.465908], Orchestrator (termination condition):\n\nNo agent selected.\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$\n```\nI liked the fact that the agent determined that the first record was a header, so it returned the actual third proper data record. That‚Äôs quite something.\n\n\n### Summary\n\nWell, I don‚Äôt know about you, but I thought that was a set of pretty impressive demonstrations. Microsoft has produced a really good agentic system and seems intent on incorporating it fully into their Autogen framework in the near future.\n\nIn this article, I explained what Magentic\\-One was and how to download it and run it to do some useful tasks. I explained that its key components were\n\n* orchestration\n* web and file surfing\n* coding and terminal operations\n\nI showed each of these components at work through a series of examples, including\n\n* the creation and running of Python code\n* examing a local file and answering questions on its content\n* searching for information on the web\n* clicking web links\n\n\n> *OK, that‚Äôs all for me for now. Hopefully, you found this article useful. If you did, please check out my profile page at [this link](https://medium.com/@thomas_reid). From there, you can see my other published stories and subscribe to get notified when I post new content.*\n\n\n> *Times are tough and wallets constrained, but if you got real value from this article, please consider [buying me a wee dram](https://ko-fi.com/taupirho).*\n\nIf you liked this content, I think you‚Äôll also find these related articles interesting.\n\nRead the full Magentic\\-One announcement from Microsoft [here](https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/introduction-to-llava-a-multimodal-ai-model-2a2fa530ace4","frontmatter":{"title":"Introduction to LLaVA: A Multimodal AI Model","meta_title":"Introduction to LLaVA: A Multimodal AI Model","description":"LLaVA is an end-to-end trained large multimodal model that is designed to understand and generate content based on both visual inputs‚Ä¶","date":"2024-10-29T12:48:10.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0At7tXF5ejho9Y46E3uGtg.png","categories":["Natural Language Processing","Computer Vision","Generative AI"],"author":"Rifx.Online","tags":["LLaVA","GPT-4","multimodal","visual","encoder"],"draft":false,"slug":"blog/introduction-to-llava-a-multimodal-ai-model-2a2fa530ace4"},"content":"\n\n\n\n\n\nLLaVA is an end\\-to\\-end trained large multimodal model that is designed to understand and generate content based on both visual inputs (images) and textual instructions. It combines the capabilities of a visual encoder and a language model to process and respond to multimodal inputs.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mjzqL0BHzdPoN-Jjruh52A.png)\n\n\n## Inputs and Outputs of LLaVA: Bridging Visual and Textual Domains:\n\nThe inputs to LLaVA are twofold:\n\n1. Visual Input: Images that the model can view and analyze to extract visual features and contextual information.\n2. Textual Instructions: Text inputs, which can be questions or commands, that guide the model on what to focus on or what kind of task to perform regarding the visual input.\n\nThe outputs of LLaVA are text\\-based and can vary depending on the task:\n\n1. Descriptive Text: If the task is to describe the visual content, LLaVA can output a detailed description of the image, identifying objects, actions, and scenes.\n2. Answers to Questions: For question\\-answering tasks, LLaVA generates responses that answer questions about the visual input, potentially involving reasoning and inference based on the image‚Äôs content.\n3. Follow\\-up Actions: For instructions that require action, such as editing an image or retrieving more information, LLaVA can provide appropriate textual responses indicating the action taken or suggesting what should be done.\n\n\n## Comparative Analysis: LLaVa vs. Contemporary Multimodal Models\n\nThe landscape of multimodal AI has been rapidly evolving with innovations such as CLIP, BLIP, and the recent introduction of LLaVa. This subsection compares LLaVa‚Äôs unique architecture and approach with these contemporary models, highlighting the advancements and distinctions that set it apart.\n\n\n### CLIP: Pioneering Multimodal Understanding\n\nCLIP (Contrastive Language‚ÄìImage Pre\\-training) has been a revolutionary step forward in multimodal AI, offering robust performance across a variety of visual tasks. Its ability to understand images in the context of natural language descriptions set a new benchmark in the field. CLIP achieves this through a large\\-scale pretraining approach that aligns images with textual descriptions, enabling the model to perform zero\\-shot learning on a range of visual tasks. However, CLIP primarily focuses on the association between images and text at a high level and does not inherently possess the capability for in\\-depth reasoning or conversational engagement.\n\n\n### BLIP: Bridging Language and Image Perception\n\nBuilding upon the foundation laid by CLIP, BLIP (Bootstrapped Language Image Pre\\-training) extends the capabilities of multimodal models by incorporating a bootstrapped pretraining strategy. This approach refines the model‚Äôs visual understanding by continually learning from its own predictions, which helps to improve the alignment between language and visual content. BLIP demonstrates enhanced performance on tasks that require more precise visual recognition and language understanding.\n\nIn contrast, LLaVa takes a different route by leveraging the language\\-generating capabilities of GPT\\-4 to curate its instruction\\-following data. This not only results in a dataset that captures a broader range of human\\-like interactions but also enables LLaVa to engage in more complex reasoning and in\\-depth conversational abilities.\n\n\n## What Sets LLaVa Apart: Is It the Model Architecture or Something Else?\n\nAccording to us , LLaVA‚Äôs strength lies predominantly in its data curation capabilities rather than its architectural choice. LLaVA marks a significant leap forward , primarily due to its utilization of GPT\\-4 for data curation. Unlike conventional static datasets, LLaVA generates dynamic, instructive data using ChatGPT\\-4, actively involving data in the training process across various visual and textual scenarios.\n\nBy using GPT\\-4, LLaVA produces datasets that closely mimic natural language and visual perception, departing from traditional manual dataset generation methods. This innovative approach not only enables AI to understand and reason but also moves it closer to accurately reflecting human intelligence.\n\n\n### Data Curation Strategies in LLaVa\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LzastWLkzPeMB_28Nr7Y9A.png)\n\nLLaVa, the Large Language and Vision Assistant, stands out not just for its advanced neural architecture but for its groundbreaking approach to data curation. By leveraging GPT\\-4, it revolutionizes traditional data preparation methods, crafting a dataset that mirrors the complexity of the real world.\n\nData curation in LLaVa begins with an image and its corresponding caption, from which a set of queries is generated using GPT\\-4\\. These queries guide the AI to explore and describe the image content with precision and relevance.\n\nTo translate visual data effectively for a text\\-based AI like GPT\\-4, LLaVa uses captions to offer diverse perspectives of the visual scene and bounding boxes to provide spatial context and focus.\n\n1. Conversational Data: Mimicing human interaction, LLaVa curates dialogues where the model, playing the assistant, responds to questions about various aspects of the image. The scope of these questions ranges from identifying objects and actions to discerning their numbers, locations, and relative positions, ensuring the model can handle queries with definitive answers.\n2. Detailed Descriptive Data: LLaVa seeks to comprehend the images in a comprehensive manner. To achieve this, it prompts GPT\\-4 to formulate questions aimed at understanding rich and detailed descriptions of the images. These prompts encourage the model to delve deeper, providing a narrative that captures the essence of the visual content in its entirety.\n3. Complex Reasoning Data: Moving beyond mere description, LLaVa challenges the model with questions that necessitate a layered reasoning process, demanding logic and an understanding of cause and effect. This type of data trains the model to construct well\\-reasoned responses that are backed by a logical sequence of thought.\n\n\n## The Architecture of LLaVa: Integrating Vision and Language\n\nThe LLaVa model integrates vision and language, utilizing the following core components:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8q_Iay_LHCzPqtrQby_H8w.png)\n\n1. Vision Encoder: At the foundation of LLaVa‚Äôs architecture is the pre\\-trained CLIP visual encoder, specifically the ViT\\-L/14 variant. This component processes input images (Xv) through Transformer layers to extract features (Zv), enabling the model to understand visual information effectively.\n2. Language Model (Vicuna): LLaVa‚Äôs linguistic capabilities rely on Vicuna, a variant of a large language model (LLM) denoted by fœï . Vicuna comprehends and generates language responses (Xa) based on input language instructions (Xq), complementing the vision encoder‚Äôs functionality.\n3. Linear Projection: This component, represented by a trainable matrix (W), serves as the bridge between visual features (Zv) and the language model‚Äôs embedding space. It transforms visual features into visual tokens (Hv), aligning them with the language model‚Äôs word embedding space to facilitate multimodal conversation\n\n\n## Training and Fine\\-Tuning LLaVA:\n\nLLaVA‚Äôs has a two\\-stage training process, each stage focusing on refining the model‚Äôs capabilities to interpret and respond to a fusion of visual and textual data.\n\n\n### Stage 1: Pre\\-training for Feature Alignment\n\nThe initial stage of LLaVA‚Äôs training is pre\\-training for feature alignment. In this phase, the model focuses on aligning visual features from images with the corresponding textual features from the language model. This is achieved by filtering a large dataset to a refined set of image\\-text pairs, which LLaVA uses to learn the correlations between the two modalities.\n\nDuring this stage, a visual encoder (such as the CLIP visual encoder ViT\\-L/14\\) processes the images to extract visual features, and a projection matrix (W) is then used to map these features into the word embedding space of the language model. The language model used in LLaVA is Vicuna, known for its strong language understanding and generation capabilities.\n\n\n### Stage 2: Fine\\-tuning End\\-to\\-End\n\nAfter aligning the visual and language features, LLaVA undergoes an end\\-to\\-end fine\\-tuning process. Despite keeping the visual encoder‚Äôs weights frozen, this stage allows the model to fine\\-tune the weights of the projection matrix and language model jointly. The objective is to maximize the likelihood of the target answers based on the multimodal data provided.\n\nThis stage is critical for adapting LLaVA to specific use case scenarios such as multimodal chat, scientific Q\\&A, and more. It ensures that the model does not just understand images in the context of generic descriptions but can engage in complex dialogues, provide detailed explanations, and reason through problems when prompted with specific questions related to the images.\n\n\n## Performance and Benchmarking: LLaVa in the Context of VQA Models\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*I_5fTa_2rtNHEDUaDNMXbQ.png)\n\n\n## LLaVA\\-Bench (COCO) Performance Insights\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6B2K7EcbYgMbH-QEp8J41w.png)\n\nLLaVA\\-Bench (COCO) provides a robust framework for assessing LLaVA‚Äôs capabilities through a carefully crafted set of 90 questions, derived from 30 selected images for conversation, detailed description, and complex reasoning. The results were as follows:\n\n* Instruction Tuning Efficacy: When equipped with instruction tuning, LLaVA‚Äôs compliance with user commands improved by over 50 points.\n* Impact of Question Variety: The inclusion of detailed and complex reasoning questions, though minimal, led to a 7\\-point increase in overall capabilities. This boost also had a positive effect on conversational question responses, showcasing the benefits of a diverse training set.\n* Optimal Data Mix: The combination of all three question types resulted in the highest performance leap, with LLaVA reaching a benchmark score of 85\\.1%, emphasizing the strength of a comprehensive dataset in enhancing multimodal AI proficiency.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*mCjP0xfpcjHkl-lu)\n\n\n## LLaVA‚Äôs Performance on LLaVA\\-Bench (In\\-the\\-Wild)\n\n* In conversational tasks, LLaVA achieves a 57\\.3% accuracy rate, a clear improvement over BLIP\\-2‚Äôs 54\\.6% and significantly outpacing OpenAI‚Äôs Flamingo, which stands at 19\\.3%.\n* When it comes to providing detailed descriptions, LLaVA scores 52\\.5%, showcasing its ability to generate rich, comprehensive content from visual cues.\n* The model‚Äôs prowess is most notable in complex reasoning questions, where it achieves an 81\\.7% success rate, indicating its advanced reasoning and inferencing skills.\n\nLLaVA secures a combined score of 67\\.3% across all categories, surpassing BLIP\\-2 by a 29% margin and Flamingo by 48%.\n\n\n## Limitation and Concerns:\n\nQuantitative Evaluation of LLaVA:\n\nThe utilization of GPT\\-4 as a judge to evaluate LLaVA‚Äôs performance presents a nuanced challenge within the framework of benchmarking AI capabilities. On one hand, GPT\\-4‚Äôs advanced comprehension and generation abilities enable it to critically assess the quality of responses produced by candidate models like LLaVA. This assessment encompasses factors such as helpfulness, relevance, accuracy, and detail, which are crucial for gauging a model‚Äôs instruction\\-following proficiency with multimodal data. However, on the other hand, the use of GPT\\-4 as an evaluative judge raises concerns regarding the impartiality of the benchmarking process.\n\nThe crux of the concern lies in the fact that LLaVA‚Äôs data curation process is fundamentally intertwined with GPT\\-4\\. Since GPT\\-4 has been instrumental in training LLaVA ‚Äî by generating the instruction\\-following data that the model was fine\\-tuned on ‚Äî there is an inherent risk of circular reasoning. Essentially, there is a possibility that LLaVA may be predisposed to generate responses that align with the patterns or biases inherent in GPT\\-4‚Äôs training data. This predisposition could skew the evaluation, leading to a theoretical upper bound that reflects compatibility with GPT\\-4‚Äôs methodology rather than a true measure of universal performance.\n\nFurthermore, relying on GPT\\-4 to provide a comprehensive explanation for its evaluation introduces a level of subjectivity rooted in the language model‚Äôs own ‚Äúunderstanding‚Äù of what constitutes a high\\-quality response. This understanding is shaped by the datasets on which GPT\\-4 was trained, which may not fully encapsulate the diversity and complexity of real\\-world multimodal interactions.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/is-perplexity-pro-a-smarter-more-efficient-way-to-search-the-web-ec509321d820","frontmatter":{"title":"Is Perplexity Pro a Smarter, More Efficient Way to Search the Web?","meta_title":"Is Perplexity Pro a Smarter, More Efficient Way to Search the Web?","description":"Perplexity is a conversational AI-driven answer engine that aims to enhance web search by providing real-time, detailed answers to complex queries, unlike traditional search engines that primarily offer lists of links. Perplexity Pro, a subscription service, offers advanced features such as access to various AI models, higher usage limits, and personalized results. Suitable for various industries, it simplifies information retrieval by allowing users to ask specific questions and receive comprehensive answers, including follow-up suggestions. However, users should be cautious of potential inaccuracies and verify information through included footnotes.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tGkjG6z62TZoaRpaUkSHuw.png","categories":["Chatbots","Natural Language Processing","Technology/Web"],"author":"Rifx.Online","tags":["perplexity","conversational","search","subscription","models"],"draft":false,"slug":"blog/is-perplexity-pro-a-smarter-more-efficient-way-to-search-the-web-ec509321d820"},"content":"\n\n\n\n## The Future of Search\n\nIs Perplexity Pro a Smarter, More Efficient Way to Search the Web?\n\n\n## How does it compare to traditional search engines and is it worth the cost?\n\nHey AI Friends and followers.\n\nI have had it. I am done with traditional search.\n\nI don‚Äôt want to go through hundreds of links just to find **the single piece of information** I am looking, buried somewhere on the third page between advertisements.\n\nTraditional search is over. A discontinued\\-model. A relic of the past.\n\nModern answer engines are the future.\n\nPerplexity promises to revolutionize the internet search. Let‚Äôs explore‚Ä¶\n\nI will start by explaining what Perplexity and Perplexity Pro are, then continue with key features, use cases and industries. Finally I will quickly compare it to alternatives like ChatGPT.\n\nSo let‚Äôs dive in head first. Enjoy!\n\n\n## What is Perplexity?\n\nPerplexity is a conversational AI\\-driven answer engine that provides real\\-time answers to complex queries, where traditional search engines might only offer a list of more or less helpful links.\n\nI gonna give you a quick example.\n\nAt work, I wanted to create a list of our hardware, because lot‚Äôs of it is outdated and will need replacement soon.\n\nSo what I did was to use Perplexity (you could use ChatGPT as well of course) and asked it to create an example table. I wasn‚Äôt sure how to structure it and Perplexity really helped me organize the Excel sheet.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*SPnfT5NgUf01ahr3Wkz6-w@2x.jpeg)\n\nOf course you might argue that you won‚Äôt need generative AI to create a simple table, and this is true. But the real fun came right afterward. I had never created a Pivot table in Excel before and I wanted to display only the hardware with expired warranty for example.\n\nWhen I asked Perplexity, it not gave me step\\-by\\-step instructions, but it also used my example data to show me how to set the Pivot table up. Something a traditional search won‚Äôt be able to do.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lj92gWPB3w4xqaiSCc5r3Q@2x.jpeg)\n\nSo, Perplexity combines a classic search engine with an AI model like GPT\\-4o or Claude\\*, allowing users to ask questions and follow\\-up questions. It can work with documents and photos, generate code, create content, and conduct in\\-depth research on various topics.\n\nWhat sets it apart is the inclusion of footnotes for further research or to check for accuracy.\n\nAnd as you can see from the example above, the answers are precise and go far beyond what a search engine could do.\n\n*\\*Digression: GPT\\-40 is a more advanced AI model used for tasks requiring higher accuracy and processing power, while Claude 3 Opus excels at tasks like creative writing and code generation.*\n\n\n## What is Perplexity Pro?\n\nPerplexity Pro is an enhanced subscription service that offers users access to different AI models (for different use cases) and capabilities beyond the standard version.\n\nWith Pro, you can choose between GPT\\-40, Claude Sonnet 3\\.5, Claude 3 Opus, Sonar Large 32k and a default model (as of writing).\n\nPro users can enjoy higher usage limits, faster response times, personalized search results and advanced document analysis with (as of writing) almost unlimited file uploads.\n\nHere is in example of the same question answered by Perplexity and Perplexity Pro:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RZf3p_4hS2mGIU9iFf23rw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-gUUeHj-oWwFlZARJ3YG_g.png)\n\nAs you can see, the Pro answer is much more detailed.\n\n\n## Who is Perplexity Pro for?\n\nPerplexity has a wide range of use cases and application areas. Let‚Äôs do a fun experiment and ask Perplexity.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PJvSMVKPKvUcwkjB8i91Gg.png)\n\nPerplexity gives an extensive answer. Let‚Äôs break it down:\n\nPerplexity and Perplexity Pro can be used across various fields, industries and individuals. And even as a casual web user you can get precise answers for your questions without digging through dozens of links and advertisements.\n\nPersonally, I use Perplexity every day for all my searches and it has already replaced Google as my standard search engine. You can read more about it here. And yes I always use the pro search. It might take a bit longer, but the results are in my experience better and longer.\n\nHere‚Äôs Perplexity‚Äôs result:\n\n* Technology and Engineering\n* Sales and Marketing\n* Product Development\n* Legal \\& Health Care\n* Sport and Entertainment\n* Finance and Strategy\n* Data Science\n* Telecommunications\n* AI and Machine Learning\n\nGenerally speaking you could say that it‚Äôs useful for anybody in any field or industry, and that is actually true. Even if you do not typically use generative AI, just getting a question answered without going through dozens of unrelated links is a big plus.\n\nIt‚Äôs a bit like talking to a friends who knows everything.\n\nImagine you are on vacation and want to know if you can walk to a famous sight from your hotel. What you could do is open the hotel website and have a look around, use a search engine and hope that it can give you a useful answer, or you could just ask Perplexity. It will not only give you a comprehensive answer, but also include directions, some photos and links to videos ‚Äî all on a single page. And if you need more details, you can just ask a follow\\-up question.\n\n\n## How I use Perplexity\n\nI do almost all of my web searches on here.\n\nAfter just a couple of weeks I have become so used to asking questions instead of writing keywords in a search engine, that I cannot believe how I could have lived without it.\n\nIt is such a huge difference asking a question, even specifying exactly what you need to know, instead of guessing which keywords might give you the answer you are looking for.\n\nEven for simple questions like ‚Äúhow old is a celebrity‚Äù it‚Äôs much easier to use Perplexity. There is usually at least one follow\\-up question I need to know and Perplexity even anticipates what I might want to know and suggests follow\\-up questions at the end of it‚Äôs answer.\n\nHere are three tricks to get better results from ChatGPT and other generative AI platforms, but you can also apply these techniques to Perplexity:\n\n\n## Feature breakdown \\& pricing\n\nPerplexity is free to use and for a basic web searches it is sufficient enough. As a registered user you even get 5 Pro searches every four hours. For anything that goes beyond a quick answer, Pro is definitely the way to go.\n\nPro search understands your question, might break it down into smaller tasks and may ask you a question before delivering a much more comprehensive answer (see screenshots above).\n\nOn the Pro plan, you can even choose the AI model (ie. ChatGPT\\-4o or Claude Sonnet 3\\.5,‚Ä¶) instead of relying on the standard Perplexity AI model.\n\nAnd if you prefer to work with files and want to upload PDFs or analyze photos, the limit as of writing on the free plan is 3 per day versus unlimited on the Pro plan (although Perplexity just says that you can uplaod at least 100 files daily ‚Äî I have no idea what would happen if you upload more, because I never uploaded that many).\n\nPricing is $20 a month or $200 annually.\n\n\n## Comparing alternatives?\n\nFinding alternatives to Perplexity is challenging, because other generative AI platforms are usually not designed as search (answer) engines. So what this means is that you can ask ChatGPT, Claude or whatever AI platform you are using questions and they will user their existing knowledge to provide an answer.\n\nWithin their subscription models they might allow web searches, but it doesn‚Äôt compared to a real answer engine.\n\nAnd yes, there are some other answer engines out there (you could ask Perplexity about them), but as far as my experience goes, Perplexity provides the most comprehensive answers.\n\nPersonally, I am paying for both ChatGPT and Perplexity, because they serve different purposes, and I need ChatGPT for my studies. This is something where it really excels.\n\nYou can read more about it here:\n\n\n## What is the catch?\n\nOf course, there‚Äôs always a catch. There has to be.\n\nAnd yes, there is one. Since Perplexity uses generative AI, there is always a chance that the model will hallucinate. That means it want‚Äôs to give you an answer no matter what and might just make something up if it cannot find anything.\n\nSo, fact\\-checking is important.\n\nThankfully Perplexity makes this fairly easy by including footnotes that you can quickly check if you are unsure or need confirmation.\n\nAnd I highly encourage you to do this, especially if you research something on the more serious side.\n\nPerplexity Pro is a serious upgrade from traditional search. Do you use an answer engine or are you still a traditional search engine user? üí¨\n\n\n> Hej there! Can I ask you a favour (it will really help me out to grow this blog)? If you find this article insightful, follow **me please** and **clap 50 times.** Or feel free to [buy me a coffee](https://buy.stripe.com/cN28xZgDweSd52M000). **Thanks for reading!**\n\n\n"},{"lang":"en","group":"blog","slug":"blog/key-points-llm-quantization-chatgpt-artificial-intelligence-8201ffcb33d4","frontmatter":{"title":"5 Key Points to Unlock LLM Quantization","meta_title":"5 Key Points to Unlock LLM Quantization","description":"Quantizing Large Language Models","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RUqPEr2NTYXlI1omqF22Qg.png","categories":["Machine Learning","Data Science","Technology/Web"],"author":"Rifx.Online","tags":["quantization","weights","activations","calibration","Quanto"],"draft":false,"slug":"blog/key-points-llm-quantization-chatgpt-artificial-intelligence-8201ffcb33d4"},"content":"\n\n\n\n\n### Quantizing Large Language Models\n\n\n\nLLM Quantization is currently a hot topic due to its vital role in making Large Language Models (LLMs) more efficient and deployable across various hardware platforms, including consumer-grade devices.\n\nBy adjusting the precision of certain components within the model, **quantization significantly reduces the model‚Äôs memory footprint** while maintaining similar performance levels.\n\nIn this guide, we will explore five key aspects of LLM quantization including some practical steps for applying this technique to our models.\n\n\n## #1. Understanding Quantization\n\nQuantization is a model compression technique that reduces the precision of weights and activations in an LLM. This involves converting high-precision values to lower-precision ones, effectively **changing data types that store more information to those that store less**.\n\nDecreasing the number of bits needed for each weight or activation significantly reduces the overall model size. As a result, **quantization creates LLMs that use less memory, and require less storage space.**\n\nThis technique has become essential in response to the exponential growth in the number of parameters in successive iterations of LLMs. For example, for the OpenAI‚Äôs GPT family, we can observe the growing trend in the following graph:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QlAhma3Wu1F6w2WvkE8jDA.png)\n\nThis significant increase presents a challenge: as models grow, their memory requirements often exceed the capacity of advanced hardware accelerators such as GPUs. **This requires distributed training and inference to manage these models, which in turn limits their deployability.**\n\n\n## #2. Intuition Behind Quantization\n\nAlthough the definition of quantization may seem rather complex, the concept can be intuitively explained using matrices.\n\nLet‚Äôs consider the following a 3x3 matrix representing the weights of a neural network. The matrix on the left shows the original weights, while the matrix on the right shows the quantized version of these weights:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LPzWe9oxjlDYdSp7dVvRUg.png)\n\nIn this simple example, we round the elements of the original matrix from four decimal places to a single decimal place. Although the matrices appear similar, **the storage space required for the four-decimal version is significantly higher**.\n\nIn practice, quantization is not merely a rounding operation. Instead, it involves converting numerical values to a different data type, typically from a higher to a lower precision one.\n\nFor example, the default data type for most models is `float32`, which requires 4 bytes per parameter (32 bits). Therefore, for a 3x3 matrix, the total memory footprint is 36 bytes. Changing the data type to `int8`, only 1 byte per parameter is needed, reducing the total memory footprint of the matrix to just 9 bytes.\n\n\n## #3. Quantization Error\n\nAs we have seen, the original matrix and its quantized form are not completely equal, but very similar. The value-by-value difference is known as ‚ÄúQuantization error‚Äù, which we can also represent in matrix form:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VtGDjVbr7daagLXB57i7Mg.png)\n\n**This quantization error can accumulate for each matrix of weights in the network, affecting the model‚Äôs performance as a result.**\n\nCurrent research in quantization aims to minimize the difference in precision while decreasing the computational resources required to train or run inference on models, while maintaining acceptable performance levels.\n\n\n## #4. Linear Quantization\n\nLinear quantization is one of the most popular quantization schemes for LLMs. In simple terms, it involves mapping the range of floating-point values of the original weights to a range of fixed-point values.\n\nLet‚Äôs review the steps required to apply linear quantization to our models:\n\n* **Get the minimum and maximum ranges:** We need to get the minimum and maximum values of the floating-point weights to be quantized (`x_min` and `x_max`). We also need to define the quantized range (`q_min` and `q_max`), which is already set by the data type we want to convert to.\n* **Compute the scale (`s`) and the zero-point (`z`) values:** Firstly, the scale (`s`) adjusts the range of floating-point values to fit within the integer range, preserving the data distribution and range. Secondly, the zero-point (`z`) ensures that zero in the floating-point range is accurately represented by an integer, maintaining numerical accuracy and stability, especially for values close to zero.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BepC6-izw0yE19ejsS705Q.png)\n\n* **Quantize the values (`q`)**: We need to map the original floating-point values to the integer range using a scale factor (`s`) and a zero point (`z`) computed in the previous step.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BBOQ0VbSGbwf7CN8c4PWKQ.png)\n\nApplying these formulas is quite straightforward. If we apply them to the 3x3 weight tensor on the left in the image below, we will get the quantized matrix shown on the right:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KzBvg84mfI2gAhTIyVibwQ.png)\n\nWe can see that the lower bound of the `int8` value corresponds to the lower value of the original tensor, while the upper bound corresponds to the higher value of the original tensor, *i.e., the mapping is`0.50 ‚Üí 255` and `-0.40 ‚Üí 0`.*\n\nWe can now dequantize the values using the formula below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*E5nnqYzncYCRuM5prssuOw.png)\n\nIf we place the dequantized values again in matrix form (matrix on the left), we can compute the quantization error (matrix on the right) by calculating the point-by-point difference between the original matrix and its dequantized version:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*56NALu9PAN95QG2hn8HXoQ.png)\n\nAs we can observe, the quantization error starts kicking in for some of the matrix values.\n\n\n## #5. Weight Quantization vs Activation Quantization\n\nIn our example above, we have focused primarily on quantizing the weights of the model. While weight quantization is crucial for model optimization, it‚Äôs also important to consider that activations can be quantized as well.\n\n**Activation quantization involves reducing the precision of the intermediate outputs of each layer in the network**. Unlike weights, which remain constant once the model is trained, activations are dynamic and change with each input, making their range harder to predict.\n\nGenerally, activation quantization is more challenging to implement than weight quantization because it requires careful calibration to ensure the dynamic range of activations is accurately captured.\n\nWeight quantization and activation quantization are complementary techniques. Using both can significantly reduce model size without greatly compromising performance.\n\n\n## Final Thoughts\n\nIn this article, we have reviewed 5 key points about quantization to better understand how to reduce the size of these constantly growing models.\n\nAs for the implementation of those techniques, there are several tools and libraries in Python that support quantization such as `pytorch` and `tensorflow`. Nevertheless, integrating quantization seamlessly in existing models requires a deep understanding of the libraries and model internals.\n\nThat is why my favorite option to implement quantization in easy steps so far is the [Quanto](https://huggingface.co/blog/quanto-introduction) library by Hugging Face, designed to simplify the quantization process for PyTorch models.\n\nIf you are interested in the in-depths of LLM Quantization and how to use the aforementioned library, you might also be interested in the article [‚ÄúQuantization for Large Language Models (LLMs): Reduce AI Model Sizes Efficiently‚Äù](https://www.datacamp.com/tutorial/quantization-for-large-language-models).\n\nThat is all! Many thanks for reading!\n\nI hope this article helps you when **using LLMs for coding!**\n\nYou can also subscribe to my [**Newsletter**](https://readmedium.com/@andvalenzuela/subscribe) to stay tuned for new content.\n\n**Especially**, **if you are interested in articles about Large Language Models and ChatGPT**:\n\n\n"},{"lang":"en","group":"blog","slug":"blog/langgraph-vs-langchain-vs-langflow-vs-langsmith-which-one-to-use-why-69ee91e91000","frontmatter":{"title":"LangGraph vs. LangChain vs. LangFlow vs. LangSmith: Which One to Use & Why?","meta_title":"LangGraph vs. LangChain vs. LangFlow vs. LangSmith: Which One to Use & Why?","description":"Discover the key differences between LangGraph, LangChain, LangFlow, and LangSmith, and learn which framework is best suited for your‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xrWv1QVt4zE5cxjA8VA3ag.png","categories":["Programming","Technology","Technology/Web"],"author":"Rifx.Online","tags":["LangGraph","LangChain","LangFlow","LangSmith","frameworks"],"draft":false,"slug":"blog/langgraph-vs-langchain-vs-langflow-vs-langsmith-which-one-to-use-why-69ee91e91000"},"content":"\n\n\n\n\n### Discover the key differences between LangGraph, LangChain, LangFlow, and LangSmith, and learn which framework is best suited for your language model applications ‚Äî from workflow building to performance monitoring.\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è | üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) |üìù [Medium](https://medium.com/@monsuralirana)\n\n\n\nIn recent years, the world of natural language processing (NLP) has witnessed an explosion in the number of frameworks, libraries, and tools available for building language model-based applications. Among these, **LangGraph**, **LangChain**, **LangFlow**, and **LangSmith** have emerged as leading options, each catering to different use cases and user needs. If you‚Äôre looking to build, monitor, or scale language model workflows, it‚Äôs crucial to understand the strengths and purposes of these tools.\n\nIn this blog, we‚Äôll explore each framework, break down their strengths, and provide insights into when to use them. Whether you‚Äôre a seasoned developer or a newcomer to the field, understanding the nuances of these tools will help you choose the right one for your project.\n\n\n## Introduction to Language Model Frameworks\n\nWith the rise of powerful language models such as GPT-3, GPT-4, and other transformer-based models, there is a growing need for frameworks that streamline the creation and management of language-based applications. These frameworks simplify complex tasks like **chaining multiple prompts**, **retrieving relevant documents**, and even **monitoring model performance**.\n\nHowever, not all frameworks are the same. While some provide a **visual interface** to manage workflows, others offer advanced **debugging and observability** features. Let‚Äôs dive into each of these tools to understand their unique offerings.\n\n\n## 1. LangGraph: Visualizing Complex Workflows\n\n**LangGraph** is a newer framework designed for developers who prefer a **visual approach** to building language model pipelines. It allows you to structure complex workflows with **graph-based visualizations**, making it easier to understand dependencies between different tasks and components. This can be especially useful for larger applications where multiple steps, such as text generation, document retrieval, and classification, are chained together.\n\n\n### Strengths:\n\n* **Visual Workflow Representation**: LangGraph lets you visualize the flow of data and actions between different components. This graphical approach is intuitive and helps in designing more complex pipelines.\n* **Ease of Debugging**: The visual nature of LangGraph makes it easier to identify bottlenecks or problematic nodes in a workflow.\n\n\n### Example Use Case:\n\nSuppose you‚Äôre building an automated system that first retrieves relevant documents using a language model and then passes them through a summarizer. In LangGraph, you can visually map out this workflow, showing the relationships between each step. If there‚Äôs an issue at any point in the chain, the visual tool makes it easy to pinpoint where things went wrong.\n\n\n### When to Use LangGraph:\n\nIf you‚Äôre managing **complex workflows** with multiple steps and value a **graphical interface** for understanding your pipeline, LangGraph is a fantastic choice. It‚Äôs particularly helpful for developers or data scientists who prefer a more intuitive, drag-and-drop approach to workflow design.\n\n**Key points**:\n\n* If you need a clear visual representation of language processing workflows.\n* When creating more complex pipelines that require branching or multi-path dependencies.\n\n\n## 2. LangChain: The Workhorse for LLM Applications\n\n**LangChain** is one of the most popular frameworks for building applications powered by **large language models (LLMs)**. It provides a versatile, **code-first approach**, allowing developers to chain tasks such as document retrieval, summarization, and question-answering into cohesive workflows.\n\n\n### Strengths:\n\n* **Extensive Support for LLMs**: LangChain is compatible with various language models, making it easy to integrate models like OpenAI‚Äôs GPT or even locally hosted models.\n* **Chaining Capabilities**: LangChain excels at **chaining multiple operations** ‚Äî hence the name ‚Äî enabling developers to create sophisticated NLP applications.\n* **Wide Adoption**: As one of the most popular frameworks, LangChain has a **thriving community** and excellent support, with ample documentation and tutorials.\n\n\n### Example Use Case:\n\nImagine you‚Äôre building a **chatbot** that first understands the user‚Äôs question, retrieves relevant information from a database, and then generates a response. With LangChain, you can easily create this multi-step process programmatically, ensuring each step in the chain works harmoniously.\n\n\n### When to Use LangChain:\n\nIf you‚Äôre a **developer building production-level applications** and need a **flexible, code-centric solution**, LangChain is your best bet. It‚Äôs ideal for those who prefer control over their application‚Äôs architecture and are comfortable writing code to define workflows.\n\n**Key points**:\n\n* If you‚Äôre building production-grade applications that require chaining of tasks across multiple language models.\n* If you need a library with extensive community support and wide-ranging integrations.\n* When you‚Äôre more comfortable with programmatic solutions rather than visual tools.\n\n\n## 3. LangFlow: No-Code/Low-Code Extension of LangChain\n\n**LangFlow** is essentially a **visual extension of LangChain**. It combines the powerful backend of LangChain with an **intuitive drag-and-drop interface**. LangFlow allows users who might not be as comfortable writing code to still leverage the power of language models in their applications.\n\n\n### Strengths:\n\n* **Visual Workflow Creation**: Like LangGraph, LangFlow provides a visual interface for building workflows. However, it‚Äôs specifically built on top of LangChain, meaning users can harness LangChain‚Äôs power without needing to write extensive code.\n* **Ideal for Rapid Prototyping**: LangFlow is perfect for quickly **prototyping ideas** or building out proof-of-concept applications.\n* **Beginner-Friendly**: It‚Äôs a great entry point for users who are less familiar with coding but want to create language model workflows.\n\n\n### Example Use Case:\n\nIf you want to quickly build a **summarization tool** that retrieves documents, you can drag and drop the components in LangFlow‚Äôs interface to create a fully functioning application. This can be done without writing much code, if any.\n\n\n### When to Use LangFlow:\n\nLangFlow is perfect for **non-developers** or **rapid prototyping**. If you want to experiment with **LLM workflows quickly** without delving into the code, this tool makes it easy to get started.\n\n**Key points**:\n\n* If you want to prototype LLM workflows quickly without writing code.\n* If you‚Äôre comfortable with visual programming but need the flexibility of LangChain.\n* For educational purposes, to help users learn how workflows can be constructed.\n\n\n## 4. LangSmith: Monitoring and Observability\n\nWhile the other tools focus on **building workflows**, **LangSmith** is designed for **monitoring** and **debugging** language model applications. It provides advanced observability features to track the performance of your workflows and models, making it invaluable for production environments.\n\n\n### Strengths:\n\n* **Deep Observability**: LangSmith allows developers to monitor language model performance, ensuring that workflows behave as expected.\n* **Error Tracking**: It excels at helping developers track down issues, making debugging easier.\n* **Performance Insights**: LangSmith gives insights into **workflow performance**, helping developers optimize their applications.\n\n\n### Example Use Case:\n\nLet‚Äôs say you‚Äôve deployed a **customer service chatbot** that uses a language model to answer questions. Over time, you notice that some responses are less accurate than expected. LangSmith can help you trace the problem by providing visibility into each decision point within the workflow.\n\n\n### When to Use LangSmith:\n\nIf you‚Äôre deploying applications in **production environments** and need to ensure **robustness, reliability, and performance**, LangSmith is an essential tool. It‚Äôs particularly useful when managing **complex systems that require debugging and optimization** over time.\n\n**Key points**:\n\n* If you need advanced monitoring or debugging capabilities in LLM workflows.\n* For development environments where observability is key to ensuring optimal model performance.\n* If your focus is on improving and iterating LLM-powered applications based on real-time insights.\n\n\n## Which One to Choose?\n\n* **Use LangGraph** if you prefer graph-based, visual workflows for building complex LLM tasks. Ideal for users who need clarity and structure.\n* **Use LangChain** if you need a robust, flexible solution for creating language model applications programmatically. It‚Äôs versatile and great for developers building production-level applications.\n* **Use LangFlow** if you want the power of LangChain with a visual, no-code/low-code interface. Best for rapid prototyping and users who prefer visual tools over coding.\n* **Use LangSmith** if your focus is on observability and debugging of LLM applications. Ideal when you need to monitor and optimize workflows in a development or production environment.\n\nUltimately, your choice depends on your comfort with code, the complexity of your workflows, and whether you prioritize ease of use, flexibility, or observability.\n\n\n## Conclusion\n\nEach of these tools ‚Äî **LangGraph**, **LangChain**, **LangFlow**, and **LangSmith** ‚Äî caters to different stages of developing and managing language model applications. **LangGraph** provides a visual, intuitive way to build complex workflows, while **LangChain** offers a robust, code-first solution for developers looking to create scalable applications. For those who prefer a **low-code**, drag-and-drop approach, **LangFlow** simplifies the process without sacrificing power. Finally, **LangSmith** focuses on observability and debugging, ensuring that your workflows are optimized and reliable. Choosing the right tool depends on your project needs, whether it‚Äôs for rapid prototyping, production-level scaling, or monitoring and performance tracking.\n\nHappy coding! üéâ\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è | üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) |üìù [Medium](https://medium.com/@monsuralirana)\n\nThank you for your time in reading this post!\n\nMake sure to leave your feedback and comments. See you in the next blog, stay tuned üì¢\n\n\n## References:\n\n1. ‚ÄúLangChain Documentation‚Äù ‚Äî <https://python.langchain.com/docs/introduction/>\n2. ‚ÄúLangGraph Overview‚Äù ‚Äî <https://langchain-ai.github.io/langgraph/>\n3. ‚ÄúLangFlow GitHub Repository‚Äù ‚Äî [https://github.com/LangFlow/LangFlow](https://docs.langflow.org/)\n4. ‚ÄúLangSmith Introduction‚Äù ‚Äî <https://www.langchain.com/langsmith>\n5. ‚ÄúHow to Build Chatbots With LangChain‚Äù by JetBrains blog ‚Äî <https://blog.jetbrains.com/pycharm/2024/08/how-to-build-chatbots-with-langchain/>\n\n"},{"lang":"en","group":"blog","slug":"blog/large-language-models-just-got-a-whole-lot-smaller-f93425ee59a2","frontmatter":{"title":"Large Language Models Just Got A Whole Lot Smaller","meta_title":"Large Language Models Just Got A Whole Lot Smaller","description":"And how this might change the game for software startups","date":"2024-11-04T12:29:02.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1PeFyz_Dlt6jEf27Q9Y33Q.png","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["compression","optimization","ternary","parallelism","hardware"],"draft":false,"slug":"blog/large-language-models-just-got-a-whole-lot-smaller-f93425ee59a2"},"content":"\n### And how this might change the game for software startups\n\n\n\n**This piece was co\\-written with [David Meiborg](https://readmedium.com/undefined).**\n\n*TLDR: Large Language Models (LLMs for short) are currently huge, costly to run, and have a [significant carbon footprint](https://arxiv.org/abs/2309.14393). Recent advancements in model compression and system\\-level optimization methods might, however, enhance LLM inference. In particular, an approach using parameters with ternary structure has the potential of circumventing much of the costly matrix multiplication that is standard today. This has exciting consequences for hardware startups making specialized chips, but also for software startups that use or custom\\-build their own LLMs. Startups that help their customers deploy LLMs might also have more business coming for them.*\n\nLarge language models today are big. Like, really big. If you want to load a LlaMa\\-2‚Äì70B model, you‚Äôd need 140 GB of VRAM (that‚Äôs 70 billion parameters multiplied by 2 bytes per parameter). For comparison, GPUs like the NVIDIA RTX 3090 or 4090, have just 24 GB of VRAM ‚Äî a fraction of what one would need.\n\nThere are some [workarounds with quantization](https://towardsdatascience.com/run-llama-2-70b-on-your-gpu-with-exllamav2-588141a88598), but these tend to be cumbersome. Likely you will still have your GPU running hot for up to 15 hours until the model is loaded. Not to mention that you still need some spare memory for inference, or in other words for deploying the model.\n\nUsing current\\-day LLMs is therefore costly: One typically needs multiple high\\-end GPUs to keep the model, and must then account for the energy costs from inference.\n\nThis is why lots of research is going into applying techniques that make LLMs smaller and thus cheaper to run on smaller hardware. It is a tough trade\\-off in most cases, because making LLMs smaller usually impacts their quality. Finding the point where cost equals benefits can be tricky.\n\nIn this piece, we give an overview of promising optimization approaches, explain a recent breakthrough from Microsoft researchers, provide a brief overview of innovative startups in the field of ‚Äúefficient LLMs‚Äù and derive some general implications for startups operating in the LLM ecosystem.\n\n## How LLMs are getting more resource\\-efficient\n\nTech giants like Microsoft and OpenAI, Meta, or Google have sufficient resources to train up cutting\\-edge models even if the training cost is currently prohibitive for most other companies. The biggest bottleneck to widespread adoption therefore is not training but inference efficiency. In other words, although Meta has published LlaMa, it still isn‚Äôt being adopted enough because running ‚Äî not creating ‚Äî the model is already challenging enough.\n\nResearchers, however, are starting to increase this inference efficiency. Broadly speaking, there are two approaches to this: **System\\-level optimizations** do not change the model itself but rather make it work better by changing key aspects of the environment that it is in. **Model optimizations** compress the model so that it is easier to deploy and run.\n\nThere is a variety of different techniques for either approach. [A recent paper](https://arxiv.org/pdf/2402.01799.pdf) by researchers summarize these techniques excellently. Because these techniques might soon become basic knowledge for anyone working on systems with LLMs, we give a quick overview over these techniques below.\n\n### System\\-level optimization\n\nSystem\\-level optimization refers to changing not the model itself, but how it is run across the hardware. As it turns out, plenty of levers can be pulled to avoid resources sitting around idle or wiping out other inefficiencies.\n\n**Paged Attention**\n\nAt the heart of LLMs like GPT is the attention mechanism. This mechanism allows the model to focus on different parts of the input text when generating each word of the output text. Imagine you are reading a book and highlighting important sentences to remember the story better. Similarly, the attention mechanism ‚Äúhighlights‚Äù or gives more importance to certain words or phrases when making predictions.\n\nThis mechanism is very resource\\-intensive. It requires the model to consider the relationships between all pairs of words in the input text. For long texts, this can require a lot of memory and computational power.\n\nInstead of processing the entire text at once, paged attention divides the text into smaller ‚Äúpages‚Äù or segments. The model then processes these pages one at a time or in smaller groups. This approach significantly reduces the amount of memory needed at any given time because the model doesn‚Äôt need to keep track of the entire text‚Äôs relationships simultaneously.\n\nThis is a bit like a student who would be overwhelmed by reading the entire year‚Äôs textbook at once. By breaking it down into manageable segments over the school year, the student can memorize the contents of the textbook.\n\nBy requiring less memory for each step, paged attention allows for the use of larger models or longer texts within the same hardware constraints.\n\n**Tensor Parallelism**\n\nParallelism is a well\\-known concept in computing. It means dividing a large computational task into smaller parts that can be processed simultaneously by multiple processors or computers. This significant speeds up the time a program needs to run.\n\n[Tensors](https://towardsdatascience.com/what-is-a-tensor-in-deep-learning-6dedd95d6507), in the context of LLMs, are multi\\-dimensional arrays of numbers. These tensors are used to represent the data processed by the models. Such data includes input text; model weights, i.e. parameters that the model learns; and output predictions.\n\nPutting both concepts together, tensor parallelism involves splitting these tensors across multiple GPUs or other processing units. For example, if a model‚Äôs parameters (weights) are too large to fit into the memory of a single GPU, they can be divided across multiple GPUs. Each GPU then processes only a portion of the tensor at a time.\n\nJust like a team of multiple people working on a large project, the processing units need to exchange information as they work on their respective parts of the tensors. For instance, the results of computations on one GPU might need to be shared with another GPU to continue the next step in the computation. Efficient communication between the units is therefore crucial for the effectiveness of tensor parallelism.\n\nIn short, tensor parallelism is a way of breaking down the computations needed for LLMs into smaller, parallel tasks that can be handled simultaneously by multiple computing units, leading to faster training and inference times for these large and complex models.\n\n**Pipeline Parallelism**\n\nThis technique focuses on improving the workflow of processing data through the model‚Äôs layers. This can significantly speed up the overall computation and make better use of available hardware.\n\nA pipeline in computing works similarly to a factory assembly line, with different stages of a task being completed in sequence. This allows for multiple tasks to be worked on simultaneously but at different stages.\n\nIn LLMs, these different stages are represented by layers of neural networks. Each layer processes the input data in sequence, gradually extracting more complex features or patterns until it produces the final output. Think of each layer as a worker in the factory assembly line: Each worker adds something to the input data as it passes through, until finally a complex product emerges.\n\nIn pipeline parallelism, the model‚Äôs layers are divided into segments, and each segment is assigned to a different GPU or processing unit. This way, the model can be fed on batches of data: Once the first segment is through with the first batch, the second segment takes that batch, and the first segment takes a fresh, new batch on.\n\nThis creates a continuous flow of data through the model where each segment of the model is working on a different piece of data at any given time. This maximizes the use of available hardware resources by keeping all parts of the model active and reduces the idle time that can occur when a single processor waits for tasks to complete.\n\nPipeline parallelism, which was discussed earlier, operates at the level of model layers, distributing the sequential processing stages across devices. Tensor parallelism, on the other hand, operates at a more granular level, distributing the actual computations (e.g., parts of a large matrix multiplication) that occur within layers across devices.\n\n**CPU/GPU Offloading**\n\nWe have talked a lot about GPUs in this piece. Nevertheless, ot all tasks in training or running an LLM are equally suited to GPUs. Some tasks, like data preprocessing or certain control logic, might be more efficiently handled by a CPU. Other tasks, particularly the heavy mathematical computations involved in processing neural networks (like matrix multiplications), are indeed more efficiently executed on GPUs.\n\nBy offloading specific tasks to the processor best suited for them ‚Äî GPUs for parallelizable, computation\\-heavy tasks, and CPUs for sequential or logic\\-intensive tasks ‚Äî systems can ensure that each part of the workload is processed in the most efficient manner possible.\n\n**Fused Operations**\n\nFused operations take multiple processing steps that would normally be executed separately and combine them into a single, streamlined operation. For instance, instead of doing a matrix multiplication and then an addition, a fused operation would do both at once.\n\n**Speculative Decoding**\n\nWhen generating text, LLMs calculate the probabilities of what the next word in a sentence might be, based on the words that have come before. Traditionally, after each word is generated, the model recalculates to determine the next word, and this process repeats until the full sentence or paragraph is completed. This sequential process can be slow, however, especially for longer texts or more complex models, because each step depends on the completion of the previous step.\n\nParallel Predictions: Instead of waiting for each word to be chosen before considering the next, speculative decoding allows the model to ‚Äúspeculate‚Äù or make multiple predictions about what the next few words could be at the same time. This is called *parallel predictions*. It‚Äôs like making educated guesses about several possible paths the sentence could take next\n\nBy exploring these possibilities in parallel, the model can potentially reduce the overall time it takes to generate text. Once the actual next word is selected, the model can more quickly proceed along the most likely path, having already computed the subsequent options.\n\n### Compression of LLM Models\n\nResearchers have in the past explored model compression. With the advent of large\\-scale LLMs, however, this has become a bigger challenge.\n\nMany established compression methods rely on the paradigm of executing fine\\-tuning steps to regain lost performance during the compression stage. This approach has significant limitations, however, when applied to LLMs because of their sheer size. LLM compression has therefore become a whole new research domain.\n\n**Architecture pruning**\n\nWhen you prune an apple tree, you cut off certain branches in winter early spring. This ensures that the tree doesn‚Äôt waste resources on unproductive branches or catches diseases from dead wood. This helps it produce better fruit.\n\nLLMs, of course, don‚Äôt produce fruit. In this context, pruning is a method used to reduce the size of the model while trying to maintain or minimally impact its performance.\n\nLLM models have millions or even billions of parameters. Not all of these parameters are equally important for the model to make predictions or understand language. Some parameters are used rarely or don‚Äôt contribute much to the model‚Äôs decisions: Eliminating these redundant or less impactful connections, neurons, or entire layers hence makes the model more efficient to use.\n\nChoosing which parameters to prune is not a trivial task. In magnitude\\-based pruning, the weights of the neural network with the smallest absolute values are removed. Before training, such weights are usually zero; after training, they are typically somewhere between \\-1 and 1\\. If training did not affect a weight very much, then it is likely close to zero, and thus contributes less to the model‚Äôs decisions.\n\nA more resource\\-intensive but also more robust pruning technique is sensitivity analysis. This involves evaluating the impact of removing each parameter, or group of parameters, on the model‚Äôs performance. Parameters whose removal causes the least degradation in performance are pruned.\n\nThere are other techniques as well, but generally one can classify them as unstructured or structured pruning. Unstructured pruning (e.g. magnitude\\-based pruning) removes individual weights, leading to a sparsely connected neural network. Structured pruning (e.g. sensitivity analysis) removes entire units or layers (e.g., a whole neuron or channel), which can be more effective for computational efficiency on certain hardware.\n\nAfter pruning, the model often undergoes a fine\\-tuning process. This involves retraining the pruned model on the training dataset or a subset of it. The goal is to allow the model to adjust and optimize its remaining parameters to compensate for the loss of the pruned ones. This helps in recovering any performance that was lost due to pruning.\n\nThis can be done in an iterative or in a one\\-shot approach. In iterative pruning, the model is pruned iteratively over several rounds. After each round, the pruned model is retrained to regain performance lost due to pruning. This cycle can be repeated multiple times, with the model potentially becoming more robust and maintaining performance even with significantly fewer parameters. In one\\-shot pruning, all the identified parameters are removed at once, and the model is then fine\\-tuned.\n\n**Knowledge distillation**\n\nImagine there is a football court with two players: One is very experienced and knows many tricks, the other is a beginner. The experienced player knows much more than the beginner, but the beginner can quickly get to a comparable behavior by mimicking the other player‚Äôs behavior on the field.\n\nKnowledge distillation for LLMs works similarly: It is the process of training a smaller (student model), more efficient model to replicate the performance of a larger model (teacher model) by learning from its outputs and the way it processes information.\n\nTo apply this technique, you obviously need a large teacher model, e.g. one of the large open\\-source models from LlaMa or Mistral. Then you need to design a smaller neural network that has significantly fewer parameters than the teacher model.\n\nInstead of training the student model solely on the original hard targets, i.e., the ground truth data labels, it is also trained on the soft targets. These are the probabilities produced by the teacher model for the same inputs. For example, for a given set of queries, imagine that the teacher answers it as ‚ÄòA‚Äô 70 percent of the time, ‚ÄòB‚Äô 20 percent of the time, and ‚ÄòC‚Äô, ‚ÄòD‚Äô, or ‚ÄòE‚Äô 10 percent of the time. Not only will the student model try to get the answer to every question right; it will also try to follow the same probability distribution over a set of queries.\n\nSuch soft targets carry more information per example than hard labels because they include the teacher model‚Äôs confidence levels across all possible outcomes. This is how to the student model is able perform similarly to the teacher but with less computational expense.\n\nAfter the initial knowledge distillation, the student model might be further fine\\-tuned on the task\\-specific dataset with hard labels to maximize its performance.\n\n**Low rank approximations**\n\nLLMs work by processing and generating text based on incredibly large matrices (i.e., veeeeery big tables of numbers) that represent the relationships between words, their meanings, and how they‚Äôre used in language. These matrices can be so large that they‚Äôre hard to work with, especially when it comes to storage and computation.\n\nA low\\-rank approximation involves finding a simpler matrix that is much smaller in size but still captures the most important information of the original large matrix. It is a bit like reducing a detailed painting to a sketch.\n\nThis is done through mathematical techniques that identify which parts of the matrix (or painting, in our analogy) hold the most information and condense the matrix to just those parts. There are mathematical techniques, notably [singular value decomposition](https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/book-chapter-4.pdf), which help with this.\n\nIn contrast to pruning, low rank approximation performs matrix dimensionality reduction, maintaining the structure of the model but representing it in a more compact form, while pruning directly removes parts of the neural network.\n\n**Quantization**\n\nLLMs process text using a vast number of mathematical calculations. These calculations are performed using numbers that can have a wide range of values. Typically, these numbers are stored in a format that can represent a very wide range of values ([floating\\-point format](https://de.wikipedia.org/wiki/Einfache_Genauigkeit)), occupying 32 bits in memory.\n\nQuantization reduces the precision of those numbers, typically from 32\\-bit floating\\-point numbers to lower bit\\- width representations, such as 8\\-bit integers. This means that instead of using numbers with a lot of decimal places, the model uses ‚Äúsimpler‚Äù numbers, making the calculations faster and requiring less memory.\n\nQuantization\\-Aware Training (QAT) involves training the model with quantization in mind, allowing it to adapt to the precision loss and usually resulting in better performance but at the cost of more complex and resource\\-intensive training processes.\n\nPost\\-Training Quantization (PTQ) applies quantization after the model has been fully trained, offering a simpler and faster approach to reduce computational demands. However, it may not achieve the same level of accuracy or performance as QAT due to the model not being specifically optimized for lower precision operations.\n\n### The Era of 1\\-bit LLMs?\n\nMicrosoft researchers recently [made waves with a paper](https://arxiv.org/pdf/2402.17764.pdf) that stores each parameter not in 16 bits, as is currently [the standard](https://en.wikipedia.org/wiki/Half-precision_floating-point_format) in LLMs, but in a mere 1\\.58 bits. This is huge news: With this technique, they achieved almost 10 times more token throughput, i.e., it processes text almost 10 times as fast. They also reduced their memory footprint by a factor of 3\\.5, which means that they need a lot less hardware to run these models on.\n\nThis was achieved using a ternary bit. Instead of using a floating\\-point number between \\-1 and 1, as is usually the case and typically uses 16 bits, every weight is expressed as either \\-1, 0, or 1\\. These numbers can be stored on 1\\.58 bits, because for 3 possible values on a binary transistor one gets that 2¬π.58 \\= 3\\. Using only numbers this simple also means that complicated matrix multiplication is no longer necessary, which makes it a lot more resource\\-efficient.\n\nWhat is baffling about this technique is that it achieves a similar output performance as traditional 16\\-bit models at a size of 3 billion parameters. It is not yet clear whether this kind of model scales up as well as traditional models, when passing the threshold of 13 billion or more parameters. What is clear is that even at 70 billion parameters it is more efficient, in terms of latency, memory usage and energy consumption, than a traditional model with only 13 billion parameters. The quality of the output remains to be tested in detail.\n\nOne other disadvantage is that state\\-of\\-the\\-art quantization of existing LLMs cannot be used to produce a 1\\.58\\-bit model. Such models need to be created from scratch, which, despite its dramatically lowered cost, will put it out of reach of the average citizen for now.\n\nIf and when such models have been created and work well, however, inference should become a lot easier. 1\\.58\\-bit LLMs might even be deployed on edge and mobile devices. They are also a lot friendlier to CPU devices ‚Äî which most mobile devices run on ‚Äî which makes them easier to deploy on cheaper chips. All this has a lot of advantages, for example for privacy, but allow allows for new applications that humanity hasn‚Äôt even dreamt of yet.\n\nMoreover, startups like [Groq](https://groq.com/) have demonstrated promising results and great potential for building specific hardware [like LPUs](https://wow.groq.com/why-groq/) for LLMs. LLM\\-specific hardware is already a [huge market](https://finance.yahoo.com/news/generative-ai-market-size-expected-163500846.html#:~:text=%2D%20Large%20Language%20Model%20(LLM),the%20forecast%20period%202023%2D2029.). Findings like these might make this market grow even more aggressively than analysts have foreseen to date.\n\nIf nothing else, inference will become dirt cheap due to a combination of quantization techniques and specialized hardware. This has implications for many companies, including startups.\n\n## What do lighter LLMs mean for startups?\n\n### The boom in AI hardware has just begun\n\nBetween 1971 and 1999, CPUs were pretty much [the only microprocessors](https://cs.stanford.edu/people/eroberts/courses/soco/projects/2005-06/64-bit-processors/history1.html) on the market. Then [NVIDIA introduced](https://readmedium.com/a-brief-history-of-gpu-47d98d6a0f8a) its GPU. It was not technically the world‚Äôs first GPU; however, it was the one of the first microprocessors that made gaming an accessible and immersible experience. (Gaming eats a lot of computing power ‚Äî if you didn‚Äôt know, now you know!)\n\nFrom gaming, GPUs quickly proliferated to do many different tasks, including scientific image processing, linear algebra, 3D reconstruction, and more. One thing that GPUs do particularly well? Machine learning and LLMs. Many of NVIDIA‚Äôs chips today are being used for training LLMs.\n\nSince then, other microprocessors have started to proliferate. [Google‚Äôs TPUs](https://cloud.google.com/tpu?hl=en), introduced in 2016, are particularly well\\-suited for AI training and inference. While GPUs turned out to be great for LLMs, TPUs were specifically designed for this purpose. They are well\\-suited both for training and inference.\n\nThe industry is [at a turning point](https://www.wsj.com/tech/ai/how-a-shifting-ai-chip-market-will-shape-nvidias-future-f0c256b1), however: Soon, the majority of LLM\\-related work will be inference, and no longer training, as users start deploying models such as LlaMa. New and innovative AI semiconductor companies now have a chance to enter the game.\n\nThis includes chipmaker [Groq](https://wow.groq.com/press/) which focuses on particularly speedy inference processors. Other startups include [Cerebras](https://www.cerebras.net/) (which focuses on training), [Graphcore](https://www.graphcore.ai/about) (which covers training and interference), and [SambaNova](https://sambanova.ai/) (also training and inference). More established competitors like Intel and AMD are also eyeing both training and inference, although most growth is expected to come from the latter in the coming years. The big tech giants ‚Äî Google, Amazon, or Microsoft ‚Äî are also developing AI\\-specialized chips, but mostly for in\\-house use.\n\nOverall, the hardware market for LLMs is still dominated by datacenter applications. Edge and mobile applications are the next logical step, but will require more breakthroughs like the 1\\.58\\-bit approach that Microsoft researchers recently published (see above).\n\n## The impact for LLM software companies\n\nLooking at the whole value chain in the emerging AI space, the developments we outlined above are likely to lead to **significantly reduced costs for running/consuming LLMs**.\n\nSome of our thoughts on where this will lead to:\n\n* **Great B2C products**, because lower LLM costs mean that you can build freemium B2C experiences with a high LLM consumption (frequency \\& scale ‚Äî e.g. long context window) without ruining company unit economics.\n* Democratization of access on a global scale, allowing **users in lower\\-income countries** to utilize advanced AI technologies\n* Companies can automate a wider range of tasks, leading to **increased efficiency and productivity** (‚ÄúI don‚Äôt care anymore if I have 10k API calls per hour‚Äù)\n* New edge AI hardware combined with smaller models will lead to **new edge AI use cases** becoming feasible that were ‚Äúdata\\-center‚Äù\\-only before\n* As edge hardware explodes, we believe opportunity opens up to build software companies that help customers to bring AI models to the fragmented space of tailored edge devices (‚Äúgive me your model, I compress it with various techniques, test it on 10 different edge devices, tell you what works best and then help you to deploy it‚Äù)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/leveraging-gemini-1-5-api-for-automated-test-case-generation-reverse-engineering-2ee8789f01db","frontmatter":{"title":"Leveraging Gemini 1.5 API for Automated Test Case Generation Reverse Engineering","meta_title":"Leveraging Gemini 1.5 API for Automated Test Case Generation Reverse Engineering","description":"This test explores using Gemini API and Google Apps Script to automatically create sample inputs for faster script reverse engineering.","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fTtML3Sm1TuQNhQP.jpg","categories":["Programming","Programming/Scripting","Technology/WebAPI"],"author":"Rifx.Online","tags":["Gemini","API","automation","reverse-engineering","scripts"],"draft":false,"slug":"blog/leveraging-gemini-1-5-api-for-automated-test-case-generation-reverse-engineering-2ee8789f01db"},"content":"\n\n\n\n\n\n\n## Abstract\n\nThis report examines leveraging Gemini 1\\.5 API with Google Apps Script to automate sample input creation during script reverse engineering. Traditionally, this process is manual and time\\-consuming, especially for functions with numerous test cases. Gemini 1\\.5 API‚Äôs potential to streamline development by automating input generation is explored through applying reverse engineering techniques to Google Apps Script samples.\n\n\n## Introduction\n\nWith the release of Gemini 1\\.5 API, users gained the ability to process more complex data, opening doors for various application developments. This report explores the potential of using Gemini 1\\.5 API in conjunction with Google Apps Script to achieve reverse engineering for script development and improvement.\n\nTraditionally, script development involves manually crafting sample input values. This process can be time\\-consuming, especially when creating functions or testing code retrieved from online resources like Stack Overflow. Each function might require numerous test cases, and manually generating these inputs can be a bottleneck.\n\nGemini 1\\.5 API offers a potential solution by automating sample input value creation. This could significantly reduce development time and effort. This report investigates this possibility by applying reverse engineering techniques to various Google Apps Script samples using Gemini 1\\.5 API.\n\nHere, we will explore how Gemini 1\\.5 API can be used to automate sample input value generation for reverse engineering scripts written in Google Apps Script.\n\n\n## Usage\n\nIn order to test this script, please do the following flow.\n\n\n## 1\\. Create an API key\n\nPlease access [https://ai.google.dev/gemini\\-api/docs/api\\-key](https://ai.google.dev/gemini-api/docs/api-key) and create your API key. At that time, please enable Generative Language API at the API console. This API key is used for this sample script.\n\nThis official document can be also seen. [Ref](https://ai.google.dev/).\n\n\n## 2\\. Create a Google Apps Script project\n\nIn this report, Google Apps Script is used. Of course, the method introducing this report can be also used in other languages.\n\nHere, in order to test the following sample scripts, please create a standalone Google Apps Script project. Of course, this script can be also used with the container\\-bound script.\n\nAnd, please open the script editor of the Google Apps Script project.\n\n\n## 3\\. Install Google Apps Script library\n\nIn order to easily access Gemini API, I created a Google Apps Script library [GeminiWithFiles](https://github.com/tanaikech/GeminiWithFiles). In the following sample scripts, this library is used. So, please install it. You can see how to install it at [here](https://github.com/tanaikech/GeminiWithFiles?tab=readme-ov-file#1-use-geminiwithfiles-as-a-google-apps-script-library).\n\n\n## 4\\. Sample script 1\n\nThe sample functions were selected from [my repository](https://github.com/tanaikech/UtlApp).\n\n* [transpose](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#transpose): Transpose 2 dimensional array.\n* [removeDuplicatedValues](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#removeduplicatedvalues): Remove duplicated values from 1 dimensional array.\n* [compilingNumbers](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#compilingnumbers): Compiling Continuous Numbers using Google Apps Script.\n* [unpivot](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#unpivot): Converting 2\\-dimensional array as unpivot (reverse pivot).\n* [expandA1Notations](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#expanda1notations): This method is used for expanding A1Notations.\n\nThe sample script demonstrating these functions is provided below. In this example, all functions can be executed in a single API call. When I ran this script, it returned a total of 2,880 tokens.\n\nThe sample first creates input values using Gemini. To test these values, the script then uses them with the function implemented in Google Apps Script. Finally, both the input and output values are printed.\n\nJSON schema is employed here to generate content. This ensures the stable generation of complex JSON objects by Gemini. [Ref](https://readmedium.com/taming-the-wild-output-effective-control-of-gemini-api-response-formats-with-response-mime-type-da273c08be85) As a result, I opted to use it in this instance.\n\n\n```python\nfunction myFunction() {\n\n  const apiKey = \"###\"; // Please set your API key.\n\n  const functionObj = {\n    transpose: function transpose(array) {\n      /**\n       * ### Description\n       * When the inputted array is 2 dimensional array, true is returned.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @return {Boolean} When the inputted array is 2 dimensional array, true is returned.\n       */\n      function is2DimensionalArray(array) {\n        return array.every((r) => Array.isArray(r));\n      }\n\n      /**\n       * ### Description\n       * Transpose 2 dimensional array.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @param {Boolean} check Check whether the inputted array is 2 dimensional array. Default is true.\n       * @return {Array} Transposed array.\n       */\n      function transpose(array, check = true) {\n        if (check && !is2DimensionalArray(array)) {\n          throw new Error(\"Please use 2 dimensional array.\");\n        }\n        return array[0].map((_, col) => array.map((row) => row[col] || null));\n      }\n      return transpose(array);\n    },\n    removeDuplicatedValues: function removeDuplicatedValues(array) {\n      /**\n       * ### Description\n       * Remove duplicated values from 1 dimensional array.\n       *\n       * @param {Array} array 1 dimensional array.\n       * @return {Object} Object including removeDuplicatedValues, duplicatedValues and numberOfDuplicate.\n       */\n      function removeDuplicatedValues(array) {\n        if (!Array.isArray(array)) {\n          throw new Error(\"Please use 1 dimensional array.\");\n        }\n        const obj = array.reduce(\n          (m, e) => m.set(e, m.has(e) ? m.get(e) + 1 : 1),\n          new Map()\n        );\n        const e = [...obj.entries()];\n        return {\n          removeDuplicatedValues: [...obj.keys()],\n          duplicatedValues: e.reduce((ar, [k, v]) => {\n            if (v != 1) ar.push(k);\n            return ar;\n          }, []),\n          numberOfDuplicate: Object.fromEntries(e),\n        };\n      }\n      return removeDuplicatedValues(array);\n    },\n    compilingNumbers: function compilingNumbers(array) {\n      /**\n       * ### Description\n       * Compiling Continuous Numbers using Google Apps Script.\n       *\n       * @param {Array} array Input array.\n       * @return {Array} Array including object like [{\"start\":1,\"end\":1},{\"start\":3,\"end\":5},{\"start\":7,\"end\":7},{\"start\":9,\"end\":11},{\"start\":13,\"end\":13}].\n       */\n      function compilingNumbers(array) {\n        if (!(Array.isArray(array) && array.every((e) => !isNaN(e)))) {\n          throw new Error(\"Please give an array including numbers.\");\n        }\n        const { values } = [...new Set(array.sort((a, b) => a - b))].reduce(\n          (o, e, i, a) => {\n            if (\n              o.temp.length == 0 ||\n              (o.temp.length > 0 && e == o.temp[o.temp.length - 1] + 1)\n            ) {\n              o.temp.push(e);\n            } else {\n              if (o.temp.length > 0) {\n                o.values.push({\n                  start: o.temp[0],\n                  end: o.temp[o.temp.length - 1],\n                });\n              }\n              o.temp = [e];\n            }\n            if (i == a.length - 1) {\n              o.values.push(\n                o.temp.length > 1\n                  ? { start: o.temp[0], end: o.temp[o.temp.length - 1] }\n                  : { start: e, end: e }\n              );\n            }\n            return o;\n          },\n          { temp: [], values: [] }\n        );\n        return values;\n      }\n      return compilingNumbers(array);\n    },\n    unpivot: function unpivot(values) {\n      /**\n       * ### Description\n       * When the inputted array is 2 dimensional array, true is returned.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @return {Boolean} When the inputted array is 2 dimensional array, true is returned.\n       */\n      function is2DimensionalArray(array) {\n        return array.every((r) => Array.isArray(r));\n      }\n\n      /**\n       * ### Description\n       * Converting 2-dimensional array as unpivot (reverse pivot).\n       *\n       * @param {Array} values 2 dimensional array.\n       * @return {Array} 2 dimensional array converted as unpivot (reverse pivot).\n       */\n      function unpivot(values) {\n        if (!Array.isArray(values) || !is2DimensionalArray(values)) {\n          throw new Error(\"Please give an array of values.\");\n        }\n        const [[, ...h], ...v] = values;\n        return h.flatMap((hh, i) => v.map((t) => [hh, t[0], t[i + 1]]));\n      }\n      return unpivot(values);\n    },\n    expandA1Notations: function expandA1Notations(a1Notations) {\n      /**\n       * ### Description\n       * Converting colum letter to column index. Start of column index is 0.\n       * @param {String} letter Column letter.\n       * @return {Number} Column index.\n       */\n      function columnLetterToIndex(letter = null) {\n        if (letter === null || typeof letter != \"string\") {\n          throw new Error(\"Please give the column letter as a string.\");\n        }\n        letter = letter.toUpperCase();\n        return [...letter].reduce(\n          (c, e, i, a) =>\n            (c += (e.charCodeAt(0) - 64) * Math.pow(26, a.length - i - 1)),\n          -1\n        );\n      }\n\n      /**\n       * ### Description\n       * Converting colum index to column letter. Start of column index is 0.\n       * Ref: https://stackoverflow.com/a/53678158/7108653\n       * @param {Number} index Column index.\n       * @return {String} Column letter.\n       */\n      function columnIndexToLetter(index = null) {\n        if (index === null || isNaN(index)) {\n          throw new Error(\n            \"Please give the column indexr as a number. In this case, 1st number is 0.\"\n          );\n        }\n        return (a = Math.floor(index / 26)) >= 0\n          ? columnIndexToLetter(a - 1) + String.fromCharCode(65 + (index % 26))\n          : \"\";\n      }\n\n      /**\n       * ### Description\n       * This method is used for expanding A1Notations.\n       * @param {Array} a1Notations Array including A1Notations.\n       * @return {Array} Array including the expanded A1Notations.\n       */\n      function expandA1Notations(a1Notations, maxRow = \"10\", maxColumn = \"Z\") {\n        if (!Array.isArray(a1Notations) || a1Notations.length == 0) {\n          throw new Error(\"Please give a1Notations (Array).\");\n        }\n        const reg1 = new RegExp(\"^([A-Z]+)([0-9]+)$\");\n        const reg2 = new RegExp(\"^([A-Z]+)$\");\n        const reg3 = new RegExp(\"^([0-9]+)$\");\n        return a1Notations.map((e) => {\n          const a1 = e.split(\"!\");\n          const r = a1.length > 1 ? a1[1] : a1[0];\n          const [r1, r2] = r.split(\":\");\n          if (!r2) return [r1];\n          let rr;\n          if (reg1.test(r1) && reg1.test(r2)) {\n            rr = [r1.toUpperCase().match(reg1), r2.toUpperCase().match(reg1)];\n          } else if (reg2.test(r1) && reg2.test(r2)) {\n            rr = [\n              [null, r1, 1],\n              [null, r2, maxRow],\n            ];\n          } else if (reg1.test(r1) && reg2.test(r2)) {\n            rr = [r1.toUpperCase().match(reg1), [null, r2, maxRow]];\n          } else if (reg2.test(r1) && reg1.test(r2)) {\n            rr = [[null, r1, maxRow], r2.toUpperCase().match(reg1)];\n          } else if (reg3.test(r1) && reg3.test(r2)) {\n            rr =\n              Number(r1) > Number(r2)\n                ? [\n                    [null, \"A\", r2],\n                    [null, maxColumn, r1],\n                  ]\n                : [\n                    [null, \"A\", r1],\n                    [null, maxColumn, r2],\n                  ];\n          } else if (reg1.test(r1) && reg3.test(r2)) {\n            rr = [r1.toUpperCase().match(reg1), [null, maxColumn, r2]];\n          } else if (reg3.test(r1) && reg1.test(r2)) {\n            let temp = r2.toUpperCase().match(reg1);\n            rr =\n              Number(temp[2]) > Number(r1)\n                ? [\n                    [null, temp[1], r1],\n                    [null, maxColumn, temp[2]],\n                  ]\n                : [temp, [null, maxColumn, r1]];\n          } else {\n            throw new Error(\"Wrong a1Notation: \" + r);\n          }\n          const obj = {\n            startRowIndex: Number(rr[0][2]),\n            endRowIndex:\n              rr.length == 1 ? Number(rr[0][2]) + 1 : Number(rr[1][2]) + 1,\n            startColumnIndex: columnLetterToIndex(rr[0][1]),\n            endColumnIndex:\n              rr.length == 1\n                ? columnLetterToIndex(rr[0][1]) + 1\n                : columnLetterToIndex(rr[1][1]) + 1,\n          };\n          let temp = [];\n          for (let i = obj.startRowIndex; i < obj.endRowIndex; i++) {\n            for (let j = obj.startColumnIndex; j < obj.endColumnIndex; j++) {\n              temp.push(columnIndexToLetter(j) + i);\n            }\n          }\n          return temp;\n        });\n      }\n      return expandA1Notations(a1Notations);\n    },\n  };\n\n  const g = GeminiWithFiles.geminiWithFiles({\n    apiKey,\n    response_mime_type: \"application/json\",\n    doCountToken: true,\n  });\n\n  const functions = Object.entries(functionObj)\n    .map(\n      ([k, v]) =>\n        `<FunctionName>${k}</FunctionName><Function>${v.toString()}</Function>`\n    )\n    .join(\"\");\n  const jsonSchema = {\n    title: \"5 input values for giving each function\",\n    description: `Proposal 5 input values for giving each function. ${functions} Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n    type: \"array\",\n    items: {\n      type: \"object\",\n      properties: {\n        functionName: { description: \"Function name\", type: \"string\" },\n        inputValues: {\n          description: `Proposed 5 input values. Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n          type: \"array\",\n          items: {\n            description: \"Proposed input value\",\n            type: \"array|object|string|number\",\n          },\n        },\n      },\n      additionalProperties: false,\n    },\n  };\n  let res = g.generateContent({ jsonSchema });\n  if (typeof res == \"string\") {\n    try {\n      res = JSON.parse(res);\n    } catch ({ stack }) {\n      console.error(stack);\n      return;\n    }\n  }\n  const result = res.reduce((o, { functionName, inputValues }) => {\n    try {\n      o[functionName] = [];\n      inputValues.forEach((input) => {\n        const output = functionObj[functionName](input);\n        o[functionName].push({ input, output });\n      });\n    } catch ({ stack }) {\n      console.log(stack);\n    }\n    return o;\n  }, {});\n  console.log(JSON.stringify(result));\n}\n```\nWhen this script is run, the following result is obtained. You can see that valid input and output values are created.\n\n\n```python\n{\n  \"transpose\": [\n    { \"input\": [[1, 2], [3, 4]], \"output\": [[1, 3], [2, 4]] },\n    { \"input\": [[\"a\", \"b\"], [\"c\", \"d\"]], \"output\": [[\"a\", \"c\"], [\"b\", \"d\"]] },\n    { \"input\": [[\"a1\", \"b1\"], [\"c1\", \"d1\"], [\"e1\", \"f1\"]], \"output\": [[\"a1\", \"c1\", \"e1\"], [\"b1\", \"d1\", \"f1\"]] },\n    { \"input\": [[true, false], [false, true]], \"output\": [[true, null], [null, true]] },\n    { \"input\": [[1, \"a\"], [\"c\", true]], \"output\": [[1, \"c\"], [\"a\", true]] }\n  ],\n\n  \"removeDuplicatedValues\": [\n    { \"input\": [1, 2, 3, 4, 5], \"output\": { \"removeDuplicatedValues\": [1, 2, 3, 4, 5], \"duplicatedValues\": [], \"numberOfDuplicate\": { \"1\": 1, \"2\": 1, \"3\": 1, \"4\": 1, \"5\": 1 } } },\n    { \"input\": [\"a\", \"b\", \"c\", \"d\", \"e\"], \"output\": { \"removeDuplicatedValues\": [\"a\", \"b\", \"c\", \"d\", \"e\"], \"duplicatedValues\": [], \"numberOfDuplicate\": { \"a\": 1, \"b\": 1, \"c\": 1, \"d\": 1, \"e\": 1 } } },\n    { \"input\": [1, 2, 1, 3, 2, 4, 3, 5, 4], \"output\": { \"removeDuplicatedValues\": [1, 2, 3, 4, 5], \"duplicatedValues\": [1, 2, 3, 4], \"numberOfDuplicate\": { \"1\": 2, \"2\": 2, \"3\": 2, \"4\": 2, \"5\": 1 } } },\n    { \"input\": [\"a\", \"b\", \"a\", \"c\", \"b\", \"d\", \"c\", \"e\", \"d\"], \"output\": { \"removeDuplicatedValues\": [\"a\", \"b\", \"c\", \"d\", \"e\"], \"duplicatedValues\": [\"a\", \"b\", \"c\", \"d\"], \"numberOfDuplicate\": { \"a\": 2, \"b\": 2, \"c\": 2, \"d\": 2, \"e\": 1 } } },\n    { \"input\": [1, \"a\", 2, \"b\", 1, \"c\", 2, \"d\", 1, \"e\"], \"output\": { \"removeDuplicatedValues\": [1, \"a\", 2, \"b\", \"c\", \"d\", \"e\"], \"duplicatedValues\": [1, 2], \"numberOfDuplicate\": { \"1\": 3, \"2\": 2, \"a\": 1, \"b\": 1, \"c\": 1, \"d\": 1, \"e\": 1 } } }\n  ],\n\n  \"compilingNumbers\": [\n    { \"input\": [1, 2, 3, 4, 5], \"output\": [{ \"start\": 1, \"end\": 5 }] },\n    { \"input\": [1, 3, 5, 7, 9, 11, 13], \"output\": [{ \"start\": 1, \"end\": 1 }, { \"start\": 3, \"end\": 3 }, { \"start\": 5, \"end\": 5 }, { \"start\": 7, \"end\": 7 }, { \"start\": 9, \"end\": 9 }, { \"start\": 11, \"end\": 11 }, { \"start\": 13, \"end\": 13 }] },\n    { \"input\": [1, 3, 5, 7, 8, 10, 12, 13], \"output\": [{ \"start\": 1, \"end\": 1 }, { \"start\": 3, \"end\": 3 }, { \"start\": 5, \"end\": 5 }, { \"start\": 7, \"end\": 8 }, { \"start\": 10, \"end\": 10 }, { \"start\": 12, \"end\": 13 }] },\n    { \"input\": [1, 2, 4, 5, 7, 8, 10, 11, 13, 14], \"output\": [{ \"start\": 1, \"end\": 2 }, { \"start\": 4, \"end\": 5 }, { \"start\": 7, \"end\": 8 }, { \"start\": 10, \"end\": 11 }, { \"start\": 13, \"end\": 14 }] },\n    { \"input\": [1, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15], \"output\": [{ \"start\": 1, \"end\": 3 }, { \"start\": 5, \"end\": 6 }, { \"start\": 8, \"end\": 9 }, { \"start\": 11, \"end\": 12 }, { \"start\": 14, \"end\": 15 }] }\n  ],\n\n  \"unpivot\": [\n    { \"input\": [[\"name\", \"score1\", \"score2\"], [\"sample1\", 100, 80], [\"sample2\", 90, 70]], \"output\": [[\"score1\", \"sample1\", 100], [\"score1\", \"sample2\", 90], [\"score2\", \"sample1\", 80], [\"score2\", \"sample2\", 70]] },\n    { \"input\": [[\"name\", \"score1\", \"score2\", \"score3\"], [\"sample1\", 100, 80, 70], [\"sample2\", 90, 70, 80]], \"output\": [[\"score1\", \"sample1\", 100], [\"score1\", \"sample2\", 90], [\"score2\", \"sample1\", 80], [\"score2\", \"sample2\", 70], [\"score3\", \"sample1\", 70], [\"score3\", \"sample2\", 80]] },\n    { \"input\": [[\"id\", \"x\", \"y\", \"z\"], [\"a\", 1, 2, 3], [\"b\", 4, 5, 6]], \"output\": [[\"x\", \"a\", 1], [\"x\", \"b\", 4], [\"y\", \"a\", 2], [\"y\", \"b\", 5], [\"z\", \"a\", 3], [\"z\", \"b\", 6]] },\n    { \"input\": [[\"id\", \"x\", \"y\", \"z\", \"xx\", \"yy\", \"zz\"], [\"a\", 1, 2, 3, 10, 20, 30], [\"b\", 4, 5, 6, 40, 50, 60]], \"output\": [[\"x\", \"a\", 1], [\"x\", \"b\", 4], [\"y\", \"a\", 2], [\"y\", \"b\", 5], [\"z\", \"a\", 3], [\"z\", \"b\", 6], [\"xx\", \"a\", 10], [\"xx\", \"b\", 40], [\"yy\", \"a\", 20], [\"yy\", \"b\", 50], [\"zz\", \"a\", 30], [\"zz\", \"b\", 60]] },\n    { \"input\": [[\"Fruit\", \"2021\", \"2022\", \"2023\"], [\"apple\", 100, 120, 150], [\"orange\", 80, 90, 100]], \"output\": [[\"2021\", \"apple\", 100], [\"2021\", \"orange\", 80], [\"2022\", \"apple\", 120], [\"2022\", \"orange\", 90], [\"2023\", \"apple\", 150], [\"2023\", \"orange\", 100]] }\n  ],\n\n  \"expandA1Notations\": [\n    { \"input\": [\"A1:B5\", \"C3:D7\", \"E2:F10\"], \"output\": [[\"A1\", \"B1\", \"A2\", \"B2\", \"A3\", \"B3\", \"A4\", \"B4\", \"A5\", \"B5\"], [\"C3\", \"D3\", \"C4\", \"D4\", \"C5\", \"D5\", \"C6\", \"D6\", \"C7\", \"D7\"], [\"E2\", \"F2\", \"E3\", \"F3\", \"E4\", \"F4\", \"E5\", \"F5\", \"E6\", \"F6\", \"E7\", \"F7\", \"E8\", \"F8\", \"E9\", \"F9\", \"E10\", \"F10\"]] },\n    { \"input\": [\"A:B\", \"C:D\", \"E:F\"], \"output\": [[\"A1\", \"B1\", \"A2\", \"B2\", \"A3\", \"B3\", \"A4\", \"B4\", \"A5\", \"B5\", \"A6\", \"B6\", \"A7\", \"B7\", \"A8\", \"B8\", \"A9\", \"B9\", \"A10\", \"B10\"], [\"C1\", \"D1\", \"C2\", \"D2\", \"C3\", \"D3\", \"C4\", \"D4\", \"C5\", \"D5\", \"C6\", \"D6\", \"C7\", \"D7\", \"C8\", \"D8\", \"C9\", \"D9\", \"C10\", \"D10\"], [\"E1\", \"F1\", \"E2\", \"F2\", \"E3\", \"F3\", \"E4\", \"F4\", \"E5\", \"F5\", \"E6\", \"F6\", \"E7\", \"F7\", \"E8\", \"F8\", \"E9\", \"F9\", \"E10\", \"F10\"]] },\n    { \"input\": [\"A1:C5\"], \"output\": [[\"A1\", \"B1\", \"C1\", \"A2\", \"B2\", \"C2\", \"A3\", \"B3\", \"C3\", \"A4\", \"B4\", \"C4\", \"A5\", \"B5\", \"C5\"]] },\n    { \"input\": [\"A:C\"], \"output\": [[\"A1\", \"B1\", \"C1\", \"A2\", \"B2\", \"C2\", \"A3\", \"B3\", \"C3\", \"A4\", \"B4\", \"C4\", \"A5\", \"B5\", \"C5\", \"A6\", \"B6\", \"C6\", \"A7\", \"B7\", \"C7\", \"A8\", \"B8\", \"C8\", \"A9\", \"B9\", \"C9\", \"A10\", \"B10\", \"C10\"]] },\n    { \"input\": [\"1:5\", \"3:7\", \"2:10\"], \"output\": [[\"A1\", \"B1\", \"C1\", \"D1\", \"E1\", \"F1\", \"G1\", \"H1\", \"I1\", \"J1\", \"K1\", \"L1\", \"M1\", \"N1\", \"O1\", \"P1\", \"Q1\", \"R1\", \"S1\", \"T1\", \"U1\", \"V1\", \"W1\", \"X1\", \"Y1\", \"Z1\", \"A2\", \"B2\", \"C2\", \"D2\", \"E2\", \"F2\", \"G2\", \"H2\", \"I2\", \"J2\", \"K2\", \"L2\", \"M2\", \"N2\", \"O2\", \"P2\", \"Q2\", \"R2\", \"S2\", \"T2\", \"U2\", \"V2\", \"W2\", \"X2\", \"Y2\", \"Z2\", \"A3\", \"B3\", \"C3\", \"D3\", \"E3\", \"F3\", \"G3\", \"H3\", \"I3\", \"J3\", \"K3\", \"L3\", \"M3\", \"N3\", \"O3\", \"P3\", \"Q3\", \"R3\", \"S3\", \"T3\", \"U3\", \"V3\", \"W3\", \"X3\", \"Y3\", \"Z3\", \"A4\", \"B4\", \"C4\", \"D4\", \"E4\", \"F4\", \"G4\", \"H4\", \"I4\", \"J4\", \"K4\", \"L4\", \"M4\", \"N4\", \"O4\", \"P4\", \"Q4\", \"R4\", \"S4\", \"T4\", \"U4\", \"V4\", \"W4\", \"X4\", \"Y4\", \"Z4\", \"A5\", \"B5\", \"C5\", \"D5\", \"E5\", \"F5\", \"G5\", \"H5\", \"I5\", \"J5\", \"K5\", \"L5\", \"M5\", \"N5\", \"O5\", \"P5\", \"Q5\", \"R5\", \"S5\", \"T5\", \"U5\", \"V5\", \"W5\", \"X5\", \"Y5\", \"Z5\"], [\"A3\", \"B3\", \"C3\", \"D3\", \"E3\", \"F3\", \"G3\", \"H3\", \"I3\", \"J3\", \"K3\", \"L3\", \"M3\", \"N3\", \"O3\", \"P3\", \"Q3\", \"R3\", \"S3\", \"T3\", \"U3\", \"V3\", \"W3\", \"X3\", \"Y3\", \"Z3\", \"A4\", \"B4\", \"C4\", \"D4\", \"E4\", \"F4\", \"G4\", \"H4\", \"I4\", \"J4\", \"K4\", \"L4\", \"M4\", \"N4\", \"O4\", \"P4\", \"Q4\", \"R4\", \"S4\", \"T4\", \"U4\", \"V4\", \"W4\", \"X4\", \"Y4\", \"Z4\", \"A5\", \"B5\", \"C5\", \"D5\", \"E5\", \"F5\", \"G5\", \"H5\", \"I5\", \"J5\", \"K5\", \"L5\", \"M5\", \"N5\", \"O5\", \"P5\", \"Q5\", \"R5\", \"S5\", \"T5\", \"U5\", \"V5\", \"W5\", \"X5\", \"Y5\", \"Z5\", \"A6\", \"B6\", \"C6\", \"D6\", \"E6\", \"F6\", \"G6\", \"H6\", \"I6\", \"J6\", \"K6\", \"L6\", \"M6\", \"N6\", \"O6\", \"P6\", \"Q6\", \"R6\", \"S6\", \"T6\", \"U6\", \"V6\", \"W6\", \"X6\", \"Y6\", \"Z6\", \"A7\", \"B7\", \"C7\", \"D7\", \"E7\", \"F7\", \"G7\", \"H7\", \"I7\", \"J7\", \"K7\", \"L7\", \"M7\", \"N7\", \"O7\", \"P7\", \"Q7\", \"R7\", \"S7\", \"T7\", \"U7\", \"V7\", \"W7\", \"X7\", \"Y7\", \"Z7\"], [\"A2\", \"B2\", \"C2\", \"D2\", \"E2\", \"F2\", \"G2\", \"H2\", \"I2\", \"J2\", \"K2\", \"L2\", \"M2\", \"N2\", \"O2\", \"P2\", \"Q2\", \"R2\", \"S2\", \"T2\", \"U2\", \"V2\", \"W2\", \"X2\", \"Y2\", \"Z2\", \"A3\", \"B3\", \"C3\", \"D3\", \"E3\", \"F3\", \"G3\", \"H3\", \"I3\", \"J3\", \"K3\", \"L3\", \"M3\", \"N3\", \"O3\", \"P3\", \"Q3\", \"R3\", \"S3\", \"T3\", \"U3\", \"V3\", \"W3\", \"X3\", \"Y3\", \"Z3\", \"A4\", \"B4\", \"C4\", \"D4\", \"E4\", \"F4\", \"G4\", \"H4\", \"I4\", \"J4\", \"K4\", \"L4\", \"M4\", \"N4\", \"O4\", \"P4\", \"Q4\", \"R4\", \"S4\", \"T4\", \"U4\", \"V4\", \"W4\", \"X4\", \"Y4\", \"Z4\", \"A5\", \"B5\", \"C5\", \"D5\", \"E5\", \"F5\", \"G5\", \"H5\", \"I5\", \"J5\", \"K5\", \"L5\", \"M5\", \"N5\", \"O5\", \"P5\", \"Q5\", \"R5\", \"S5\", \"T5\", \"U5\", \"V5\", \"W5\", \"X5\", \"Y5\", \"Z5\", \"A6\", \"B6\", \"C6\", \"D6\", \"E6\", \"F6\", \"G6\", \"H6\", \"I6\", \"J6\", \"K6\", \"L6\", \"M6\", \"N6\", \"O6\", \"P6\", \"Q6\", \"R6\", \"S6\", \"T6\", \"U6\", \"V6\", \"W6\", \"X6\", \"Y6\", \"Z6\", \"A7\", \"B7\", \"C7\", \"D7\", \"E7\", \"F7\", \"G7\", \"H7\", \"I7\", \"J7\", \"K7\", \"L7\", \"M7\", \"N7\", \"O7\", \"P7\", \"Q7\", \"R7\", \"S7\", \"T7\", \"U7\", \"V7\", \"W7\", \"X7\", \"Y7\", \"Z7\", \"A8\", \"B8\", \"C8\", \"D8\", \"E8\", \"F8\", \"G8\", \"H8\", \"I8\", \"J8\", \"K8\", \"L8\", \"M8\", \"N8\", \"O8\", \"P8\", \"Q8\", \"R8\", \"S8\", \"T8\", \"U8\", \"V8\", \"W8\", \"X8\", \"Y8\", \"Z8\", \"A9\", \"B9\", \"C9\", \"D9\", \"E9\", \"F9\", \"G9\", \"H9\", \"I9\", \"J9\", \"K9\", \"L9\", \"M9\", \"N9\", \"O9\", \"P9\", \"Q9\", \"R9\", \"S9\", \"T9\", \"U9\", \"V9\", \"W9\", \"X9\", \"Y9\", \"Z9\", \"A10\", \"B10\", \"C10\", \"D10\", \"E10\", \"F10\", \"G10\", \"H10\", \"I10\", \"J10\", \"K10\", \"L10\", \"M10\", \"N10\", \"O10\", \"P10\", \"Q10\", \"R10\", \"S10\", \"T10\", \"U10\", \"V10\", \"W10\", \"X10\", \"Y10\", \"Z10\"]] }\n  ]\n}\n```\n\n## 5\\. Sample script 2\n\nEach function of the above sample script uses only one argument. When multiple arguments are used, the script is as follows. The sample function is as follows.\n\n* [splitArray](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#splitarray): Split array every n length.\n\n\n```python\nfunction myFunction() {\n\n  const apiKey = \"###\"; // Please set your API key.\n\n  const functionObj = {\n    splitArray: function splitArray(array, size) {\n      /**\n       * ### Description\n       * Split array every n length.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @param {Boolean} check Check whether the inputted array is 2 dimensional array. Default is true.\n       * @return {Array} Transposed array.\n       */\n      function splitArray(array, size) {\n        if (!array || !size || !Array.isArray(array)) {\n          throw new Error(\"Please give an array and split size.\");\n        }\n        return [...Array(Math.ceil(array.length / size))].map((_) =>\n          array.splice(0, size)\n        );\n      }\n      return splitArray(array, size);\n    },\n  };\n\n  const g = GeminiWithFiles.geminiWithFiles({\n    apiKey,\n    response_mime_type: \"application/json\",\n    doCountToken: true,\n  });\n\n  const functions = Object.entries(functionObj)\n    .map(\n      ([k, v]) =>\n        `<FunctionName>${k}</FunctionName><Function>${v.toString()}</Function>`\n    )\n    .join(\"\");\n  const jsonSchema = {\n    title: \"5 input values for giving each function\",\n    description: `Proposal 5 input values for giving each function. ${functions} Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n    type: \"array\",\n    items: {\n      type: \"object\",\n      properties: {\n        functionName: { description: \"Function name\", type: \"string\" },\n        inputValues: {\n          description: `Proposed 5 input values. Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n          type: \"array\",\n          items: {\n            description: \"Proposed input value\",\n            type: \"array|object|string|number\",\n          },\n        },\n      },\n      additionalProperties: false,\n    },\n  };\n  let res = g.generateContent({ jsonSchema });\n  if (typeof res == \"string\") {\n    try {\n      res = JSON.parse(res);\n    } catch ({ stack }) {\n      console.error(stack);\n      return;\n    }\n  }\n  const result = res.reduce((o, { functionName, inputValues }) => {\n    try {\n      o[functionName] = [];\n      inputValues.forEach((input) => {\n        const temp = JSON.parse(JSON.stringify(input));\n        const output = functionObj[functionName](...temp);\n        o[functionName].push({ input, output });\n      });\n    } catch ({ stack }) {\n      console.log(stack);\n    }\n    return o;\n  }, {});\n  console.log(JSON.stringify(result));\n}\n```\nWhen this script is run, the following result is obtained.\n\n\n```python\n{\n  \"splitArray\": [\n    { \"input\": [[1, 2, 3, 4, 5, 6], 2], \"output\": [[1, 2], [3, 4], [5, 6]] },\n    { \"input\": [[\"a\", \"b\", \"c\", \"d\", \"e\"], 2], \"output\": [[\"a\", \"b\"], [\"c\", \"d\"], [\"e\"]] },\n    { \"input\": [[\"apple\", \"orange\", \"grape\", \"banana\", \"kiwi\"], 3], \"output\": [[\"apple\", \"orange\", \"grape\"], [\"banana\", \"kiwi\"]] },\n    { \"input\": [[true, false, true, false, true], 1], \"output\": [[true], [false], [true], [false], [true]] },\n    { \"input\": [[1.2, 3.14, 2.71, 0.577], 2], \"output\": [[1.2, 3.14], [2.71, 0.577]] }\n  ]\n}\n```\n\n## Summary\n\nFrom the above result, we can confirm the possibility of reverse engineering using Gemini API. This also shows that Gemini API can be used to develop applications.\n\n\n## Note\n\n* If an error occurs, please run the script again. Or, please adjust the description in the JSON schema.\n* I believe that this approach will be able to be also used for other languages except for Google Apps Script.\n* In the current stage, it seems that the class objects depending on Google Apps Script like SpreadsheetApp, DriveApp, and so on cannot be used as the input values.\n* The top abstract image was created by [Gemini](https://gemini.google.com/app).\n\n"},{"lang":"en","group":"blog","slug":"blog/leveraging-large-language-models-llms-in-b2c-industries-transforming-customer-experience-with-4073990a6200","frontmatter":{"title":"Leveraging Large Language Models (LLMs) in B2C Industries: Transforming Customer Experience with‚Ä¶","meta_title":"Leveraging Large Language Models (LLMs) in B2C Industries: Transforming Customer Experience with‚Ä¶","description":"The article discusses the implementation of Large Language Models (LLMs) in B2C industries, particularly for enhancing customer service through autonomous agents. It outlines the development of an Agentic Retrieval-Augmented Generation (RAG) system for handling credit card inquiries, utilizing embeddings, vector databases, and prompt engineering to improve response accuracy. The process includes data ingestion, embedding creation, and deployment using frameworks like Flask or Streamlit. The integration of LLMs with RAG systems significantly enhances customer engagement by providing real-time, contextually aware responses, ultimately improving operational efficiency and customer satisfaction.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Zf15fyqPpBcoEHf6G5rgbw.jpeg","categories":["Programming","Machine Learning","Chatbots"],"author":"Rifx.Online","tags":["LLMs","RAG","embeddings","vector","Flask"],"draft":false,"slug":"blog/leveraging-large-language-models-llms-in-b2c-industries-transforming-customer-experience-with-4073990a6200"},"content":"\n\n\n\n\n\nIn the rapidly evolving landscape of B2C industries such as financial services, retail, and eCommerce, customer expectations for personalized and instant responses are at an all\\-time high. With the advancement of AI technologies, particularly Large Language Models (LLMs), there has been a dramatic shift in how companies can handle customer interactions. In industries like banking and credit card services, where customers frequently seek detailed information about products, benefits, or transactions, the adoption of LLM\\-powered autonomous agents offers significant advantages. These agents can provide real\\-time, intelligent responses, transforming customer engagement while driving operational efficiency.\n\nIn my experience with AI product development in the financial services industry, these LLM\\-powered agents, when implemented correctly, can serve as a game\\-changer. They offer scalable, contextually aware customer support that not only improves satisfaction but also reduces the reliance on human agents. But how do we develop these intelligent systems? Below, I‚Äôll walk you through the business problem of creating an Agentic Retrieval\\-Augmented Generation (RAG) system for handling customer queries related to credit card products and explain how LLMs, embeddings, vector databases, and prompt engineering come together in this solution.\n\n\n## Business Problem: Creating an Autonomous Agent for Credit Card Queries\n\nImagine a major financial services company that offers a variety of credit card products to its customers. Handling customer queries about features, benefits, interest rates, and rewards programs for different credit card products is a labor\\-intensive process. The goal is to develop an AI agent capable of handling a large volume of questions autonomously, accurately, and with deep contextual understanding.\n\n\n### Data Source for Agentic RAG Development\n\nFor this use case, we‚Äôll use a public data source from Citibank, where a range of credit card product details is available to save as PDF format. These documents contain the necessary information for answering customer queries regarding Citibank‚Äôs credit card products: [Citibank Credit Cards Overview](https://www.citi.com/credit-cards/compare/view-all-credit-cards?intc=citicard_vac_202405_AB). The complete code base with step by step notebook can be found in this [git repo](https://github.com/nitsourish/Conversational_AIchatbot).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rNgsnBXq0R-RnKfSVCQ26Q.png)\n\n\n## Embeddings and Vector Database Creation\n\nTo enable the AI agent to retrieve relevant information from the available product PDFs, the first step is to create embeddings. Embeddings are vector representations of text that allow the model to capture the semantic meaning of words, phrases, and even full documents in a continuous vector space.\n\nIn this use case, PDF files containing details on different credit cards are downloaded and processed. Using pre\\-trained language model **text\\-embedding\\-3\\-small**, we convert the textual data into dense vector representations. These vectors are stored in a vector database, which enables efficient similarity searches.\n\n**Key Steps:**\n\n1. **Data Ingestion**: PDFs of Citibank‚Äôs credit card products are parsed and converted into textual format.\n\n\n```python\nfor file in os.listdir(\"../credit_card_products\"):\n    if file.endswith(\".pdf\"):\n        loaders.append(file)     \npdf_loaders = [PyPDFLoader(f\"../credit_card_products/{file}\") for file in loaders]\n\npages = []\n\nfor loader in pdf_loaders:\n    pages.extend(loader.load())\n```\n**2\\. Chunking(Splitting)**: Idea is to split the text into chunks , using newline (`\"\\n\"`) as the separator. Each chunk has an certain overlap of characters. This helps ensure smoother text segmentation for downstream processes like embedding or retrieval.\n\n\n```python\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=1500,\n    chunk_overlap=100,\n    length_function=len\n)\ndocs = text_splitter.split_documents(pages)\n```\n**3\\. Embedding Creation and Vector Database** : Use an LLM\\-based embedding model to convert the preprocessed text into vector representations and Store the embeddings in a vector database such as Pinecone, FAISS, or a MongoDB\\-based custom solution.We used here FAISS(Facebook AI Similarity Search).This will allow fast, scalable search over large sets of documents.\n\n\n```python\nembeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n## Load it into the vector store and embed\nvectordb = FAISS.from_documents(docs, embeddings_model)\n```\n\n## Large Language Models (LLM) and Retrieval\\-Augmented Generation (RAG)\n\nLLMs, such as GPT models, are powerful at generating human\\-like text, but their capabilities are amplified when paired with RAG systems, significantly reducing hallucinations in Large Language Models (LLMs) and enabling autonomous agents to provide reliable and context\\-aware information.Retrieval\\-Augmented Generation (RAG) improves the performance of LLMs by augmenting their response generation with relevant external knowledge retrieved from a vector database. In real world the retrieval source can be anything, enterprise vector database to private or public urls(wikipedia,google docs etc.)\n\nIn the context of our credit card agent, a customer query might include: ‚ÄúWhat is the interest rate(APR) on Costco Anywhere Visa¬Æ Card by Citi?‚Äù A RAG\\-based system would work in two steps:\n\n**1\\. Retrieval**: Use the vector database to fetch the relevant sections of the Citibank credit card PDFs based on the embedding similarity to the query.\n\n\n```python\nretriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n```\n**2\\. Generation**: The LLM takes the retrieved context and generates a detailed and accurate response that directly answers the customer‚Äôs question.\n\n\n```python\nquestion = \"\"\" \"\"\"\n\nai_msg = rag.invoke({\"input\": question, \"chat_history\": retriever})\n\n```\nThis approach ensures the agent‚Äôs responses are both grounded in real data (retrieved from the database) and contextually relevant.\n\n\n## Prompt Engineering for Improved Interaction\n\nAn essential aspect of deploying LLM\\-powered agents is prompt engineering. In this process, carefully designed prompts guide the LLM to generate accurate and contextually relevant outputs. When answering queries related to credit card products, the agent needs to be able to understand user intent, retrieve the right information from the database, and respond in a conversational manner.\n\nExamples of effective prompt engineering include:\n\n* **Contextual follow\\-ups**: Clearly explaining the roles and information domain. We use here *ChatPromptTemplate from* from *langchain\\_core.*\n\n\n```python\nqa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\nUse the following pieces of retrieved context to answer the question. \\\nIf you don't know the answer, just say that you don't know. \\\nUse three sentences maximum and keep the answer concise.\\\n\n{context}\"\"\"\n\nqa_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", qa_system_prompt),\n        (\"human\", \"{input}\"),\n    ]\n)\n```\nBy fine\\-tuning the prompt and ensuring it covers various angles of the query, the AI agent delivers better customer experiences leveraging best possible contexts and instruction.\n\n\n## Retrieving Chat History for Context Awareness\n\nOne of the challenges with AI\\-powered customer service is providing coherent, context\\-aware responses across a series of interactions. For example, a customer might ask multiple questions about a credit card product in a single session. To maintain the conversational flow, the system must keep track of prior interactions.\n\n\n```python\nsystem_prompt = \"\"\"Given the chat history and a recent user question \\\ngenerate a new standalone question \\\nthat can be understood without the chat history. Do NOT answer the question, \\\njust reformulate it if needed or otherwise return it as is.\"\"\"\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n\nretriever_with_history = create_history_aware_retriever(\n    llm, retriever, prompt\n)\n```\nRetrieving chat history helps the agent maintain context and deliver more personalized responses. This is especially crucial in situations where the customer asks follow\\-up questions or shifts between multiple products. The system ensures that earlier data points (e.g., the product the customer is discussing) remain part of the current conversation.\n\n\n## Langchain: Orchestrating the Agent\n\nLangchain is an essential tool for connecting all these components: LLMs, vector databases, RAG systems, and external APIs. It provides an integrated framework for building these autonomous agents, streamlining the development process, and ensuring that the agent works seamlessly across different tasks, including retrieval, context generation, and response formulation.\n\n\n```python\nllm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")\nquestion_answer_chain = create_stuff_documents_chain(llm, qa_system_prompt)\n\nretriever_with_history = create_history_aware_retriever(\n    llm, retriever, prompt\n)\n\nchat_history = [\"\"\" \"\"\"]\nrag_chain = create_retrieval_chain(retriever_with_history, question_answer_chain)\nai_msg = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history}\nchat_history.append([HumanMessage(content=question),ai_msg[\"answer\"]])\n```\nLangchain‚Äôs modular architecture allows easy integration of different data sources, whether they are stored in a vector database or accessible through APIs. It also facilitates real\\-time orchestration of user queries with appropriate retrieval, generation, and contextual awareness mechanisms.\n\n\n## Deployment using Flask and Streamlit\n\nOnce the RAG model is trained and optimized, it can be deployed using lightweight web frameworks such as Flask or Streamlit. Flask allows for more customization and control over the deployment, while Streamlit offers rapid prototyping with a focus on simplicity. The full implementation is in [git repo](https://github.com/nitsourish/Conversational_AIchatbot).\n\n**Flask Example:**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1BZhU0OMY10wCQPRYliEQw.png)\n\n\n```python\napp = Flask(__name__)\n\n@app.route('/query', methods=['POST'])\ndef query_model():\n    input_data = request.json['query']\n    response = rag_chain.invoke({\"input\": input_data})\n    return jsonify({\"response\": response})\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n**Streamlit Example:**\n\n\n```python\nst.title(\"Credit Card Product Query Agent\")\nuser_query = st.text_input(\"Ask a question about Citi credit cards:\")\nif user_query:\n    response = rag_chain.invoke({\"input\": user_query})\n    st.write(f\"Response: {response}\")\n```\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uOXAnRB0yln6U21aCUMy9Q.png)\n\n\n## Key Takeaways and Road Ahead\n\nIn this blog, I discussed Relevance of LLMs in B2C Industries especially areas with high customer touch\\-points with a special application of conversational AI agent for banking products including step by step development and deployment of RAG based Pipeline leveraging popular lang\\-chain framework.The flow includes customized engineering pipeline with data ingestion, configuration of vector database(retriever).Finally there is demonstration of deployment using micro web frameworks like Flask for full control or Streamlit for quick prototyping.\n\nIn today‚Äôs fast\\-paced B2C environment, providing quick, accurate, and personalized customer service is key to gaining a competitive advantage. By combining LLMs with vector databases, retrieval\\-augmented generation (RAG), and prompt engineering, companies can deploy AI agents that not only answer customer queries but do so with high contextual accuracy.\n\nThanks for reading the article. To read such exciting AI stories follow my [medium stories](https://medium.com/@sourish.syntel).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/lightrag-simple-and-efficient-rival-to-graphrag-fe49e12e9ece","frontmatter":{"title":"LightRAG‚Ää‚Äî‚ÄäSimple and efficient rival to GraphRAG?","meta_title":"LightRAG‚Ää‚Äî‚ÄäSimple and efficient rival to GraphRAG?","description":"Traditional RAG systems work by indexing raw data. This data is simply chunked and stored in vector DBs. Whenever a query comes from the‚Ä¶","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7_2PyaNMVdYDWTCrb_cMCg.png","categories":["Generative AI","Data Science","Technology/Web"],"author":"Rifx.Online","tags":["LightRAG","retrieval","GraphRAG","indexing","dual-level"],"draft":false,"slug":"blog/lightrag-simple-and-efficient-rival-to-graphrag-fe49e12e9ece"},"content":"\n\n\n\n\n\nTraditional RAG systems work by indexing raw data. This data is simply chunked and stored in vector DBs. Whenever a query comes from the user, it queries the stored chunks and *retrieves* relevant chunks. If you wish to learn the fundamentals of RAG I have written a comprehensive intro about it [here](https://proxy.rifx.online/https://readmedium.com/retrieval-augmented-generation-rag-a-quick-and-comprehensive-introduction-6cd5217a4ebb).\n\nAs the retrieval step happens for every single query from the user, it is the most crucial bottleneck to speed up naive RAG systems. Would it not be logical to make the retrieval process super efficient? This is the promise of **LightRAG**.\n\n\n> **If you are a non\\-member, you may read this for free [here](https://proxy.rifx.online/https://www.ai-bites.net/lightrag-simple-and-efficient-rival-to-graphrag/). Why not subscribe there and get these right to your inbox?**\n\n\n## Why not GraphRAG\n\nBefore we look at them, you may ask, ‚ÄúWait. Do we not have GraphRAG from Microsoft?‚Äù. Yes, but GraphRAG seems to have a couple of drawbacks.\n\n* **Incremental knowledge update.** (sec 3\\.1\\) GraphRAG first creates a reference to entities and relationships in the entire private dataset. It then does bottom\\-up clustering that organizes the data hierarchically into semantic clusters. An update to the dataset with new knowledge means that we have to go through the entire process of building the graph! LightRAG on the other hand addresses this by simply appending new knowledge to the existing one. More specifically, it combines new graph nodes and edges with existing ones through a simple union operation.\n* **Computational intensity.** As seen from their study, LightRAG significantly reduces the cost of the retrieval phase. What takes 610,000 tokens for GraphRAG takes less than 100 tokens for LightRAG.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0TwUDr1BCNr_nSfTPwxenw.png)\n\nSo without further adieu, let's dive into LightRAG.\n\n\n## LightRAG\n\nThe two main selling points of LightRAG are Graph\\-based indexing and dual\\-level retrieval framework. So let's look into each of them.\n\n\n## Graph\\-based Indexing\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*U7sYYNA9teKEVig1dzfi2g.png)\n\nBelow are the steps LightRAG follows to incorporate graph\\-based indexing.\n\n* **Entity and Relationship (ER) extraction.** ER extraction is shown by R(.) in the above figure. This step ensures that simple entities are first extracted from a given document. For example, in the above example, ‚Äúbees‚Äù and ‚Äúbeekeeper‚Äù are two entities. And they are related by ‚Äúobserve‚Äù relation. As in, a beekeeper observes bees.\n* **Key\\-value (KV) pair generation using LLM.** KV pairs are then generated using a simple LLM. The LLM profiling step gives a small note or explanation of what the entity or relation is all about. For example, the LLM explains who a ‚Äúbeekeeper‚Äù is in our chosen example. This step is denoted by the P(.) in the above figure. Note that this LLM is different from the general\\-purpose LLM used in the main RAG pipeline.\n* **Deduplication.** Given that the documents have to do with bees, it is quite possible that the entity ‚Äúbeekeeper‚Äù could have been retrieved from several documents or chunks. So, we need a deduplication step that just keeps one and discards the rest with the same meaning. This is shown by the D(.) in the above figure.\n\n\n## Dual\\-level Retrieval\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t9W1UBbjFa5cnAe-_tqz-Q.png)\n\nA query to a RAG system can be one of two types ‚Äî specific or abstract. In the same bee example, a specific query could be ‚ÄúHow many queen bees can be there in the hive?‚Äù. An abstract query could be, ‚ÄúWhat are the implications of climate change on honey bees?‚Äù To address this diversity, LightRAG employs two retrieval types:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DuVxwxwl_2-gej_DwGzoeg.png)\n\n* **Low\\-level retrieval.** It simply extracts precise entities and their relationships like bees, observe, and beekeepers.\n* **High\\-level retrieval.** Employing an LLM, LightRAG aggregates information and summarizes multiple sources of information.\n\n\n## Why bother doing all this?\n\nDoing all this exercise and switching to LightRAG improves execution time indeed. During indexing, the LLM needs to be called just once per chunk to extract entities and their relationships.\n\nLikewise, during user query, we only retrieve entities and relationships from chunks using the same LLM we used for indexing. This is a huge saving on the retrieval overhead and hence computation. So, we have a ‚Äúlight‚Äù RAG at last!\n\nIntegrating new knowledge into existing graphs seems to be a seamless exercise. Instead of re\\-indexing the whole data whenever we have new information, we can simply append new knowledge to the existing graph.\n\n\n## Evaluation\n\nIn their evaluations, they have compared against Naive RAG, RQ\\-RAG, HyDE, and GraphRAG. To keep the comparison fair, they have used GPT\\-4o\\-mini as the LLM across the board with a fixed chunk size of 1200 for all datasets. The answers were evaluated for comprehensiveness, diversity, and effectiveness in answering the user(a.k.a. *empowerment* in the paper).\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DNdNHW7NRcOXpvEWjT5BKQ.png)\n\nAs we can see from the underlined results, LightRAG beats all of the state\\-of\\-the\\-art methods currently available.\n\nIn general, they draw the following conclusions:\n\n* Using graph\\-based methods (GraphRAG or LightRAG) improves significantly over the baseline Naive RAG\n* LightRAG produces quite diverse answers powered by the dual\\-level retrieval paradigm\n* LightRAG can deal with complex queries better\n\n\n## Conclusion\n\nThough RAG is a fairly recent technique, we are seeing rapid progress in the area. Techniques like LightRAG which can take RAG pipelines to cheap commodity hardware are the most welcome. While the hardware landscape is ever\\-growing, there is always an increasing need to run LLMs and RAG pipelines in compute\\-constrained hardware in real time.\n\nWould you like to see some hands\\-on study of LightRAG? Please stay tuned‚Ä¶\n\n\n## Shout Out\n\nHope that was useful.\n\n**If you liked this article, why not follow me on [Twitter](https://proxy.rifx.online/https://twitter.com/ai_bites) where I share research updates from top AI labs every single day.**\n\n**Also please subscribe to my [YouTube channel](https://proxy.rifx.online/https://www.youtube.com/c/aibites) where I explain AI concepts and papers visually.**\n\n**Lastly, please clap, and let‚Äôs celebrate you reaching the end of this story.**\n\n\n"},{"lang":"en","group":"blog","slug":"blog/llama-3-1-405b-how-to-use-for-free-9aaf3561932d","frontmatter":{"title":"Llama 3.1 405B‚Ää‚Äî‚ÄäHow to Use for Free","meta_title":"Llama 3.1 405B‚Ää‚Äî‚ÄäHow to Use for Free","description":"No Local Install Needed","date":"2024-10-29T05:09:24.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*db_ND6LyQ5_p5jFJCTo5GQ.jpeg","categories":["Programming","Technology","Generative AI"],"author":"Rifx.Online","tags":["Llama","Meta","HuggingChat","Groq","API"],"draft":false,"slug":"blog/llama-3-1-405b-how-to-use-for-free-9aaf3561932d"},"content":"\n\n\n\n\n### No Local Install Needed\n\n**Llama 3\\.1 405B** is Meta‚Äôs most advanced AI model released in July 2024 ‚Äî **but where can you try it*?***\n\n\n\n**LLama 3\\.1** comes in different versions, including the largest model with 405 billion parameters and smaller versions like the 70B and 8B models.\n\nThe easiest way to try the 70B and 8B models is on [Groq](https://console.groq.com/playground)‚Äî where you can try them directly on their playground.\n\nBecause of the overwhelming demand, the most powerful 405B model isn‚Äôt usually available though.\n\nThis guide is for anyone including developers who wants to try Llama 3\\.1 405B for free ‚Äî without needing to download and install it.\n\nIf you don‚Äôt have a paid Medium account, you can read for free [here](https://addison-best.medium.com/9aaf3561932d?source=friends_link&sk=5fa532d1caaec229a0b9a445d8749449)\n\nIf you are a developer, and you want to try **LLama 3\\.1 405B for free using an API ‚Äî** you can skip to the end of the article.\n\n\n## Where Can I Use Llama 3\\.1 405B for Free?\n\nYou can download and install it directly from [Meta](https://llama.meta.com/) ‚Äî but it is huge and you‚Äôll need 100‚Äôs of Gigabytes of space and a powerful computer to try it properly.\n\nBut you can also try now without downloading.\n\nHere are some options where you can try it:\n\n**If you want to learn more AI tips and tricks to help grow your business and earn more money online:**\n\n***üëâ*** *Sign up for our **[free 5\\-day email course](https://aigrowthguys.com/5-day-free-course-how-to-grow-your-business-like-a-weed)** to grow üöÄ and earn**üí≤üëà***\n\n\n## 1\\. Use Llama 3\\.1 405B on Meta AI\n\nIf you‚Äôre in the U.S. and it seems at least Canada (where I am), you can chat with the Llama 3\\.1 405B model through Meta AI. Visit the [Meta AI website](https://www.meta.ai) and log in using your Facebook or Instagram account.\n\nIt might also be available in other countries now, so have a look.\n\nWhen you sign in ‚Äî hopefully you‚Äôll see an option to try **Llama 3\\.1 405B**.\n\nIf you can, you‚Äôll see a message like in the below screenshot.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cw1WMKhdZhzUp0L3Kn7Qng.png)\n\nYou can also access it via WhatsApp by linking your Meta account.[**Try it on Meta AI**](https://www.meta.ai)\n\nYou can also try their **Imagine** photo creator and AI image editor**.**\n\nThe cartoon image with the Lama and computer was created using this at the start of the article.\n\n**I prompted**\n\n\n> **Imagine: i want a fun cartoon image for a medium article showing trying to use llama 3\\.1 405B**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8MeC_M2O7UX7ulPOfUCuHA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dIG62eA7YAT3mpLA0etz9Q.png)\n\nIt‚Äôs worth trying. I don‚Äôt think it is comparable to Flux.1 or Midjourney ‚Äî but it is easy to use and free\n\n\n## 2\\. Use Llama 3\\.1 405B on HuggingChat\n\nHuggingChat is available to users outside the U.S. and provides access to the Llama 3\\.1 405B model. You can start chatting right away without signing up, making it an easy way to explore the model‚Äôs capabilities. Visit the [HuggingChat page](https://huggingface.co) to begin.[Try it on HuggingChat](https://huggingface.co)\n\n\n## 3\\. Use Llama 3\\.1 405B on Groq\n\n**How:** Groq initially hosted the Llama 3\\.1 405B model but now offers the smaller 70B and 8B versions due to high demand. You can explore these models by creating a free account on [Groq‚Äôs website](https://groq.com).[Try it on Groq](https://groq.com)\n\n\n## 4\\. Use Llama 3\\.1 405B on Perplexity\n\nPerplexity offers a simple way to interact with Llama 3\\.1, designed for quick and easy access to the model. You can start using it by visiting the Perplexity AI platform. But this is only available in the Pro plan.[Try it on Perplexity](https://www.perplexity.ai)\n\n\n## 5\\. Use Llama 3\\.1 405B on Poe\n\nPoe by Quora is another platform where you can try Llama 3\\.1\\. Poe allows users to explore different AI models, including Llama 3\\.1, through a chat interface. It‚Äôs a versatile option if you want to compare Llama 3\\.1 with other AI models in one place. You can try 3\\.1 405B for free ‚Äî with a limited amount of daily free credits.[Try it on Poe](https://poe.com)\n\n\n## Where Can I Use Llama 3\\.1 405B for Free with API?\n\nIf you are a developer and want to try LLama 3\\.1 405B version completely free ‚Äî you currently have limited options.\n\nBut I wanted to give you an easy and free option to get you started.\n\nYou can currently try on [together.ai](https://together.ai) for free.\n\nYou get $5 of free credit and an API key to try it.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*w8LOXw-Wm0QTz5YgvZ27ug.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YpKURkmy--xstoJpZ4fmbw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*g0FxHkg6gq5OMXXo1Yzr0A.png)\n\nThis was the easiest way I found to test the Llama 3\\.1 405B version quickly\\- and free.\n\nThis is a great option for developers wanting to try using it with an API for free.\n\n\n## Note:\n\nIf you want our team to create custom AI software using LLMs, or a custom AI chatbot for your business, you can [**contact me**](https://aigrowthguys.com/contact/) ‚úâÔ∏è here and I‚Äôll get back to you quickly:\n\n[**AI Growth Guys Contact**](https://aigrowthguys.com/contact/)‚úâÔ∏è\n\nüëâ Sign up to our [**free 5\\-Day email course**](https://aigrowthguys.com/5-day-free-course-how-to-grow-your-business-like-a-weed/) to grow üöÄ and earnüí≤in the AI age\n\nYou can also [**sign up for my newsletter**](https://ai-growth-guys.beehiiv.com/subscribe/?via=andrew-best) on how to use AI to earn more money.\n\nCheck out our [**YouTube Channel**](https://www.youtube.com/@aigrowthguys)\n\nFollow us at our website: [**AI Growth Guys**](https://aigrowthguys.com/)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/llama-3-2-the-next-generation-of-lightweight-instruction-tuned-language-models-a-hands-on-9bca07c8af1d","frontmatter":{"title":"Llama 3.2: The Next Generation of Lightweight, Instruction-Tuned Language Models: A Hands-On‚Ä¶","meta_title":"Llama 3.2: The Next Generation of Lightweight, Instruction-Tuned Language Models: A Hands-On‚Ä¶","description":"Discover LLaMA 3.2‚Äôs Key Innovations in Pruning, Knowledge Distillation, and Multilingual Performance, Plus a Hands-On Tutorial to Run‚Ä¶","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BMalqlcJIFe50hidF4FnqQ.png","categories":["Natural Language Processing","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["LLaMA","tuning","pruning","distillation","multilingual"],"draft":false,"slug":"blog/llama-3-2-the-next-generation-of-lightweight-instruction-tuned-language-models-a-hands-on-9bca07c8af1d"},"content":"\n### Discover LLaMA 3\\.2‚Äôs Key Innovations in Pruning, Knowledge Distillation, and Multilingual Performance, Plus a Hands\\-On Tutorial to Run Locally or Through Google Colab\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è \\| üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) \\|üìù [Medium](https://medium.com/@monsuralirana)\n\n\n\n## Introduction\n\nLanguage models continue to evolve, pushing boundaries in efficiency, speed, and multilingual capabilities. LLaMA 3\\.2 (Lightweight LLaMA) represents the next breakthrough in this trajectory, combining innovations like pruning, knowledge distillation, and synthetic data generation. Building upon Meta‚Äôs previous innovations, LLaMA 3\\.2 enhances the performance of smaller models (1B and 3B parameters) without sacrificing speed, accuracy, or privacy. In this blog, we will explore the key technical advancements in LLaMA 3\\.2, discuss its benchmark results, and provide a research\\-based perspective on why these innovations matter. We will conclude with a hands\\-on tutorial to help you get started with deploying LLaMA 3\\.2 using LangChain and Ollama.\n\n## 1\\. The Evolution of LLaMA Models: From 1\\.0 to 3\\.2\n\n### A Brief History of LLaMA Models\n\nThe **Large Language Model Meta AI (LLaMA)** series has evolved significantly since its initial release. Meta‚Äôs **LLaMA 1\\.0** aimed to democratize access to LLMs, providing high\\-performance models with fewer parameters than models like GPT\\-3, yet achieving similar levels of accuracy across a range of tasks. LLaMA 2\\.0 introduced instruction\\-tuning and improvements in multilingual performance.\n\n**LLaMA 3\\.2** represents the next leap, focusing on the following core areas:\n\n* **Instruction Tuning and Fine\\-Tuning**: Enhancements in instruction\\-following capabilities allow the model to perform better on downstream tasks.\n* **Efficiency for Edge Devices**: Pruning and distillation techniques enable the deployment of models on devices with limited computational resources, such as smartphones, without losing performance.\n* **Vision and Language Understanding**: The integration of vision\\-language models into LLaMA 3\\.2 allows for the handling of multimodal tasks, such as image\\-based Q\\&A.\n\n## 2\\. Key Innovations in LLaMA 3\\.2\n\n### A. Instruction\\-Tuning and Alignment\n\nInstruction\\-tuning has proven to be a key factor in improving LLMs‚Äô ability to follow natural language instructions. In LLaMA 3\\.2, Meta has used **supervised fine\\-tuning (SFT)**, **rejection sampling (RS)**, and **direct preference optimization (DPO)** techniques. These are applied iteratively to train the models to handle various tasks, such as reasoning, summarization, and tool usage, with greater accuracy.\n\n* **Supervised Fine\\-Tuning (SFT)**: The model is fine\\-tuned on human\\-annotated datasets where it learns to generate preferred outputs.\n* **Direct Preference Optimization (DPO)**: A technique that trains models to directly optimize user preferences, aligning outputs more closely with human expectations.\n\n### B. Efficient Pruning and Knowledge Distillation\n\nLLaMA 3\\.2‚Äôs lightweight models, such as the 1B and 3B parameter models, leverage **structured pruning** and **knowledge distillation**. These techniques reduce model size while retaining a significant amount of knowledge from larger models (e.g., LLaMA 3\\.1 8B and 70B):\n\n* **Structured Pruning**: In this approach, parts of the network with lower significance are systematically removed to create smaller models while maintaining accuracy.\n* **Knowledge Distillation**: A large model (teacher) transfers knowledge to a smaller model (student), allowing the smaller model to mimic the performance of the larger one during training.\n\n### C. Extended Context Length\n\nOne of the major updates in LLaMA 3\\.2 is its ability to handle longer context lengths ‚Äî up to **128K tokens**. This makes it highly efficient for tasks that require processing large chunks of text, such as summarization, long document analysis, and multi\\-turn conversations.\n\n### D. Vision\\-Language Models\n\nMeta‚Äôs introduction of **Vision\\-Language Models (VLMs)** in LLaMA 3\\.2 opens new frontiers for multimodal tasks. These models are designed to handle both text and images, making them highly effective for applications such as document Q\\&A, scientific diagram interpretation, and image captioning.\n\n## 3\\. Benchmark Performance: How Does LLaMA 3\\.2 Compare?\n\nLLaMA 3\\.2 has been rigorously evaluated on a wide range of benchmarks, as illustrated by the table you shared. Key highlights include:\n\n* **General Tasks**: The 3B model shows exceptional performance on benchmarks such as **MMLU** (63\\.4\\) and **IFEval** (77\\.4\\), indicating superior instruction\\-following and reasoning capabilities.\n* **Tool Use**: On tasks like **BFCL V2**, LLaMA 3\\.2 (3B) scored 67\\.0, outperforming competitors like **Gemma 2** and **Phi\\-3\\.5\\-mini** in following complex instructions related to tool usage.\n* **Math and Reasoning**: The 3B model demonstrated strong results in math\\-related tasks, scoring **77\\.7** in **GSM8K** (grade\\-school math) and **78\\.6** in the **ARC Challenge**, a benchmark focused on reasoning.\n* **Multilingual Generation**: The 3B model also excelled in the multilingual MGSM benchmark, showcasing its ability to generate coherent text across multiple languages.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lpjDJ6AaRnljLwAxtAf-Ag.png)\n\nLLaMA 3\\.2‚Äôs dominance in these tasks suggests that it offers a robust solution for tasks involving natural language understanding, instruction\\-following, and reasoning in both general and multilingual contexts.\n\n## 4\\. Hands\\-On Tutorial: Running LLaMA 3\\.2 Locally Using LangChain and Ollama\n\nNow that we have explored the technical advancements of LLaMA 3\\.2, let‚Äôs get hands\\-on with a step\\-by\\-step guide to setting it up locally using **LangChain** and **Ollama**. We can Install it on the local machine or Google Colab terminal. Just follow below steps:\n\n### Step 1: Install Required Libraries\n\nFirst, install the required libraries in your Python environment. Run the following commands to set up LangChain and Ollama:\n\n```python\n!pip install langchain\n!pip install -U langchain-community\n!pip install langchain_ollama\n```\n\n### Step 2: Install and Load Colab\\-XTerm\n\nColab\\-XTerm is a handy package that enables terminal access within a Colab notebook. This can be useful for running shell commands directly within the notebook environment. To install it, run the following command:\n\n```python\n!pip install colab-xterm\n%load_ext colabxterm\n```\n\n### Step 3: Installing Ollama\n\nYou can then open a terminal session by running:\n\n```python\n%xterm\n```\n\nIn the terminal, run the following command to install Ollama:\n\n```python\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n```python\nollama serve\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*itAzyQHMHhin8b7bRLc09w.png)\n\n### Step 4: Pulling the Models\n\nOnce Ollama is installed, you can pull the models you need. Ollama provides several LLMs, including Llama 3\\.2\\. Here‚Äôs how to pull them:\n\n```python\nollama pull llama3.2\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S3R4gByToCZXKEWBh4GWaQ.png)\n\nThe above commands will download and prepare the models for use in your Colab environment.\n\nAlternatively, Pull any LLM model that is available in Ollama. All LLM model lists and details are available:[https://ollama.com/library](https://ollama.com/library)\n\n### Step 5: Integrate LLaMA 3\\.2 with LangChain\n\nLangChain makes it easy to invoke LLaMA 3\\.2 for various NLP tasks. Here‚Äôs a simple script to test the model:\n\n```python\nfrom langchain_community.llms import Ollama\n\n## Initialize an instance of the Llama 3.1 model\nllm_llama = Ollama(model=\"llama3.2\")\n\n## Invoke the model to generate a response\nresponse = llm_llama.invoke(\"Tell me a joke\")\nprint(response)\n```\n\nOutput:\n\n```python\nHere's one:\n\nWhat do you call a fake noodle?\n\nAn impasta.\n```\n\n### Step 6: Experiment with Different Tasks\n\nYou can extend this to more complex tasks like summarization, multilingual translation, and reasoning:\n\n```python\n## Summarization\nresponse = llm_llama.invoke(\"Summarize the following text: 'LLaMA 3.2 represents a major step forward in AI development...'\")\nprint(response)\n\n## Multilingual Generation\nresponse = llm_llama.invoke(\"Translate the following into French: 'What are the major improvements in LLaMA 3.2?'\")\nprint(response)\n```\n\nOutput:\n\n```python\nQuantum Mechanics is a complex and fascinating subject, but I'll try to break it down in simple terms.\n\n**The Basics**\n\nImagine you have a coin. Heads or tails, right? In classical physics (the way things work today), the coin is either one or the other - heads or tails. It's like a definite choice.\n\nIn Quantum Mechanics, however, the coin isn't quite so simple. When you flip it, it doesn't just land on heads or tails; it exists in both states at the same time! This idea might sound crazy, but that's basically what happens with tiny particles like atoms and electrons.\n\n**Wave-Particle Duality**\n\nHere's a key concept: tiny particles can behave like both waves and particles. It sounds weird, but think of it like this:\n\n* Imagine a wave in the ocean. The water molecules are moving up and down, creating ripples.\n* Now imagine a single water molecule as a particle (a tiny ball). That's what quantum mechanics says these particles can be!\n\n**Superposition**\n\nAnother mind-bending idea is superposition. It means that tiny particles can exist in multiple states at the same time. Think of it like this:\n\n* Imagine a coin that's both heads AND tails simultaneously!\n* This happens with electrons, which can spin both clockwise and counterclockwise at the same time.\n\n**Entanglement**\n\nQuantum Mechanics also introduces entanglement. When two particles interact, they become \"connected\" in such a way that what happens to one particle instantly affects the other, no matter how far apart they are!\n\n* Imagine two dancers who are perfectly synchronized, even if they're on opposite sides of the stage.\n* This is basically entanglement: two particles can be connected in a similar way.\n\n**The Weird Stuff**\n\nNow we get to some really weird and interesting aspects of quantum mechanics:\n\n* **Uncertainty Principle**: You can't know both the position AND momentum of a particle at the same time!\n* **Quantum Tunneling**: Particles can pass through solid objects, which is weird because they shouldn't be able to fit through.\n* **Schr√∂dinger's Cat**: Imagine a cat in a box with a radioactive atom. If the atom decays, the cat dies. But according to quantum mechanics, the cat is BOTH alive AND dead until someone opens the box and observes it!\n\n**In a Nutshell**\n\nQuantum Mechanics is all about tiny particles behaving in strange and fascinating ways. It's like they're playing by their own rules, which can lead to some pretty wild and unpredictable outcomes.\n\nWhile this explanation is simplified, it should give you an idea of how quantum mechanics works and its weird and wonderful principles!\n```\n\nOutput:\n\n```python\nThe translation of \"What are the major improvements in LLaMA 3.2?\" into French is:\n\n\"Quels sont les am√©liorations majeures de LLaMA 3.2?\"\n\nHere's a breakdown of the translation:\n\n- \"What\" becomes \"Quels\"\n- \"are\" becomes \"sont\"\n- \"the\" becomes \"les\"\n- \"major improvements\" become \"am√©liorations majeures\"\n- \"in\" becomes \"sont\"\n- \"LLaMA 3.2\" remains the same, as it's a proper noun.\n\nNote: The phrase \"majeures\" is used to describe significant or substantial improvements.\n```\n\n> **Get GitHub Code:**\n\n## Conclusion\n\nLLaMA 3\\.2 is a versatile and highly capable model that excels across multiple NLP tasks, from multilingual text generation to practical tool usage. Its innovations in pruning and knowledge distillation ensure that it maintains top\\-tier performance, even in lightweight, resource\\-constrained environments. With this hands\\-on tutorial, you can quickly integrate LLaMA 3\\.2 into your local applications or through cloud services like Google Colab.\n\nBy unlocking LLaMA 3\\.2‚Äôs capabilities, developers can create cutting\\-edge applications that are not only fast and responsive but also privacy\\-conscious, keeping user data on\\-device. Whether you‚Äôre exploring NLP or building real\\-world applications, LLaMA 3\\.2 sets a new benchmark in lightweight, instruction\\-tuned language models.\n\nFeel free to explore other models in the Ollama library and experiment with different tasks. The possibilities are endless!\n\n\n"},{"lang":"en","group":"blog","slug":"blog/longrag-giving-ai-a-bigger-net-to-catch-more-fish-in-the-sea-of-information-7ecdd63f330d","frontmatter":{"title":"LongRAG: Giving AI a Bigger Net to Catch More Fish in the Sea of Information","meta_title":"LongRAG: Giving AI a Bigger Net to Catch More Fish in the Sea of Information","description":"In my previous article, I introduced whether RAG would become obsolete due to long-context LLMs. Today, let‚Äôs look at how to apply‚Ä¶","date":"2024-11-08T00:17:39.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Nt5TRh0ooDkgmibMlA1Srg.png","categories":["Generative AI","Natural Language Processing","Data Science"],"author":"Rifx.Online","tags":["long-context","LLMs","RAG","retrieval","generation"],"draft":false,"slug":"blog/longrag-giving-ai-a-bigger-net-to-catch-more-fish-in-the-sea-of-information-7ecdd63f330d"},"content":"\nIn [my previous article](https://readmedium.com/will-long-context-llms-cause-the-extinction-of-rag-de41ca5ddfc6), I introduced whether RAG would become obsolete due to long\\-context LLMs. Today, let‚Äôs look at how to apply long\\-context LLMs to RAG scenarios.\n\nIn the realm of Retrieval\\-Augmented Generation (RAG), the traditional approach has always relied on short retrieval units, typically around 100 words, which forces retrievers to sift through vast corpora to extract the necessary information. This design, while functional, places an imbalanced load on the retriever, often leading to suboptimal performance due to the overwhelming volume of units it must process.\n\nThe article introduces a new study titled ‚Äú[LongRAG: Enhancing Retrieval\\-Augmented Generation with Long\\-context LLMs](https://arxiv.org/pdf/2406.15319v3)‚Äù. It seeks to address this imbalance by proposing a novel framework that significantly improves the efficiency of the retriever and the performance of the reader by extending the length of retrieval units to 4,000 tokens.\n\n## Traditional RAG vs. LongRAG\n\n\n\nAs shown in Figure 1, the core innovation of LongRAG lies in its restructuring of the traditional RAG framework. By extending the retrieval unit size to 4K tokens ‚Äî 30 times longer than the typical unit ‚Äî LongRAG drastically reduces the number of units from millions to a manageable few hundred thousand.\n\nThis approach not only eases the burden on the retriever but also enhances the semantic completeness of the retrieved information, leading to superior downstream performance.\n\n## LongRAG\n\nThe LongRAG framework is composed of two main components: the **Long Retriever** and the **Long Reader**. An illustrative example of these two components are depicted in Figure 2\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fs37A8QUj-y2rW9_iAqS3Q.png)\n\nThe Long Retriever organizes the retrieval process by grouping related documents into cohesive units that retain semantic integrity. Once the relevant long retrieval units are identified, they are passed on to the Long Reader, which is equipped to handle extensive contexts (around 30K tokens).\n\nHere‚Äôs a step\\-by\\-step breakdown of the workflow:\n\n### 1\\. Formulating Long Retrieval Units\n\nThe first step in LongRAG is the creation of long retrieval units.\n\n**In traditional RAG** frameworks, the retrieval units are short, often just a few hundred tokens, which can lead to fragmented information and a heavy burden on the retriever to piece together the relevant context.\n\n**LongRAG addresses this** by grouping related documents into cohesive long retrieval units that are significantly larger ‚Äî up to 4,000 tokens per unit.\n\nTo form these long units, LongRAG employs a grouping algorithm that organizes documents based on their relationships, such as hyperlinks embedded within Wikipedia articles.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*zPEDmLo7rcdCQ06e.png)\n\nFor instance, documents about a particular topic or entity are grouped together to create a comprehensive retrieval unit (Figure 2\\). This ensures that each unit maintains semantic integrity and provides a richer context for the reader to extract the answer from.\n\n### 2\\. Similarity Search and Ranking\n\nOnce the long retrieval units are formed, the next step is to perform a similarity search to identify which units are most relevant to the query.\n\nThe query is encoded into a vector using an encoder function, E\\_Q, and each retrieval unit is similarly encoded using another encoder function, E\\_C. The similarity between the query `q` and each retrieval unit `g` is calculated using the dot product of their respective vectors.\n\nHowever, given the length of the retrieval units, **directly encoding the entire unit can be computationally expensive and less effective**. **To mitigate this, LongRAG approximates the similarity by breaking down the long unit into smaller chunks** and calculating the maximum similarity score across these chunks.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*U1BsMZuyXqO1oqsl.png)\n\nThis method, akin to [the MaxP design from prior works](https://arxiv.org/pdf/1905.09217), allows LongRAG to efficiently identify the most relevant sections within each long retrieval unit without sacrificing performance.\n\n### 3\\. Aggregating Retrieval Results\n\nAfter the similarity scores are calculated, the top k retrieval units are selected based on their relevance to the query. **These selected units are then concatenated to form a single long context, which typically consists of around 30,000 tokens.** This aggregated context is what will be passed on to the Long Reader.\n\nThe size of k, or the number of retrieval units, is crucial for balancing the workload. If the retrieval units are too short, more units are needed, which can overwhelm the reader. Conversely, if the units are too long, fewer are needed, but they must be highly relevant to avoid including extraneous information.\n\nLongRAG optimizes this balance by using a moderate number of well\\-formed long retrieval units, usually between 4 and 8, depending on the task.\n\n### 4\\. Processing by the Long Reader\n\nThe Long Reader is the component responsible for extracting the final answer from the long context. This step leverages advanced long\\-context language models like GPT\\-4o or Gemini\\-1\\.5\\-Pro, which are capable of handling extensive sequences of text without losing track of the critical information.\n\nFor shorter contexts (less than 1,000 tokens), the Long Reader directly extracts the answer. However, for the longer contexts typical of LongRAG, the process is more nuanced. Initially, the model generates a detailed response that spans a few sentences, ensuring that it captures all relevant information. This initial output is then refined through a second round of processing, where the Long Reader condenses the response into a precise, concise answer.\n\nThis two\\-step approach ensures that the Long Reader can effectively handle the large amount of information provided by the long retrieval units while still delivering accurate and focused answers.\n\n## Evaluation\n\nThe paper presents a thorough evaluation of LongRAG on well\\-known datasets like Natural Questions (NQ) and HotpotQA. The results are compelling, showing an improvement in retrieval performance, with answer recall rates jumping from 52% to 71% on NQ (Figure 4\\), and from 47% to 72% on HotpotQA (Figure 5\\).\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wLUdp-4OihjAz8Fu.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*vmTsnuIsV6LxJFtj.png)\n\n## Conclusion\n\nThis article explored the innovative LongRAG framework, which is an innovative approach by extending the RAG framework to handle long documents, enabling the model to process and generate answers from extended contexts effectively. It incorporates a multi\\-step retrieval process that dynamically retrieves relevant sections of long texts, ensuring that the most pertinent information is used in the generation phase. This allows LongRAG to excel in tasks that require understanding and synthesizing information from lengthy and complex documents, outperforming traditional RAG models in such scenarios.\n\nHowever, this approach is not without its challenges. The dependency on powerful long\\-context models means that the framework‚Äôs performance is tightly coupled with the capabilities of these models. Additionally, the grouping algorithm used for creating long retrieval units may require further refinement to generalize beyond Wikipedia\\-based corpora.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/meet-ministral-3b-and-8b-edge-ai-game-changers-3f7532da8f90","frontmatter":{"title":"Meet Ministral 3B and 8B: Edge AI Game-Changers","meta_title":"Meet Ministral 3B and 8B: Edge AI Game-Changers","description":"Mistral AI‚Äôs New Frontier in Edge AI and On-Device Computing","date":"2024-11-01T03:55:06.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3CmWlEiW7ea8gtqxpI83_w.png","categories":["Technology","Autonomous Systems","Data Science"],"author":"Rifx.Online","tags":["Mistral","edge","computing","translation","robotics"],"draft":false,"slug":"blog/meet-ministral-3b-and-8b-edge-ai-game-changers-3f7532da8f90"},"content":"\n\n\n\n\n### Mistral AI‚Äôs New Frontier in Edge AI and On\\-Device Computing\n\nIn the rapidly evolving landscape of AI, edge computing has become increasingly crucial for applications that demand low\\-latency, privacy\\-first, and efficient inference without relying on cloud\\-based infrastructure.\n\nThe launch of [**Ministral**](https://mistral.ai/news/ministraux/)family of models, the latest innovation from **Mistral AI**, represents a groundbreaking step forward in the realm of AI.\n\nTo mark the first anniversary of its groundbreaking **Mistral 7B** model, Mistral AI has unveiled its next generation of language models: **Ministral 3B** and **Ministral 8B**, collectively known as ‚Äú[**les Ministraux**](https://mistral.ai/news/ministraux/)‚Äù. These models aren‚Äôt just incremental improvements; they represent a significant leap in what‚Äôs possible with edge AI.\n\n\n\n\n## Why These Models Matter?\n\nEdge AI is all about performing complex computations locally, ensuring data privacy and reducing response times. With **Ministral 3B** and **Ministral 8B**, Mistral AI offers models that combine high computational power with memory efficiency, all while running directly on the device. These models are designed to deliver real\\-time insights for applications that can‚Äôt afford latency or depend on cloud connectivity.\n\n\n## Key Features:\n\n1. **State\\-of\\-the\\-Art Performance**: Outperforms existing models in different tasks such as knowledge, commonsense, reasoning, native function\\-calling, and efficiency within the sub\\-10B category.\n2. **Large Context Window**: Support for up to 128k context length, enabling more comprehensive understanding and generation.\n3. **Efficient Architecture**: Ministral 8B features a special interleaved sliding\\-window attention pattern for faster and more memory\\-efficient inference.\n4. **Versatility**: Suitable for a wide range of applications, from on\\-device translation to autonomous robotics.\n5. **Privacy\\-First Design**: Built for local inference, these models are perfect for applications that prioritize data privacy, eliminating the need for constant cloud access.\n6. **Scalability**: Whether you need low\\-power consumption for smaller devices with Ministral 3B or greater capabilities with the 8B variant, both models are flexible enough to be adapted to various use cases.\n\n\n> For benchmarking results, refer [here](https://mistral.ai/news/ministraux/)\n\n\n## Breaking Down the Models:\n\n\n### Ministral 3B:\n\n* With just **3 billion parameters**, it provides a balanced approach for resource\\-constrained environments\n* Supports up to **128k context length**, allowing for comprehensive handling of complex queries\n* Ideal for ultra\\-low\\-latency applications\n* Outperforms many other models in its category\n\n\n### Ministral 8B:\n\n* With **8 billion parameters** and **128k context length**, it tends to deliver enhanced computational power for more demanding tasks\n* Features a **sliding\\-window attention** pattern for improved speed and memory efficiency\n* Informed by a wide range of **multilingual** and **code** data, making it suitable for diverse applications\n* Supports **function calling**\n* Balances performance and efficiency for demanding applications\n* Vocabulary size of **131k**, using the **V3\\-Tekken** tokenizer\n* Prompt Template:\n\n\n```python\n<s>[INST]user message[/INST]assistant response</s>[INST]new user message[/INST]\n```\n\n## Use Cases:\n\nThese models deliver compute\\-efficient and low\\-latency performance, making them ideal for the following scenarios:\n\n* **On\\-Device Translation**: Empowering users to communicate seamlessly across languages in real\\-time, even in areas with less internet connectivity.\n* **Internet\\-less Smart Assistants**: Supporting intelligent virtual assistants that function independently of cloud connectivity, enhancing user experience in privacy\\-sensitive environments.\n* **Local Analytics**: Enabling organizations to analyze data in real\\-time while maintaining strict privacy standards, which is essential in sectors such as healthcare and finance.\n* **Autonomous Robotics**: Equipping robots with advanced language capabilities for autonomous decision\\-making and communication, enhancing their operational efficiency in various industries.\n\nIn addition to their standalone capabilities, les Ministraux can work in conjunction with larger models like Mistral Large. This synergy allows them to serve as efficient intermediaries for **function\\-calling in agentic workflows**, handling:\n\n* **Input Parsing**: Quickly interpreting user input to ensure accurate responses.\n* **Task Routing**: Directing requests to the appropriate resources based on user intent.\n* **API Calls**: Executing API functions in real\\-time, ensuring smooth interactions across various contexts.\n\n\n## Code Usage (with vLLM):\n\nThe [Ministral\\-8B\\-Instruct\\-2410](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) Language Model is an instruct fine\\-tuned model that can be efficiently deployed using vLLM. You can find it [here](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) on Hugging Face. Here‚Äôs how you can get started:\n\n\n### Installation\n\nFirst, ensure you have the latest versions of vLLM and mistral\\_common installed:\n\n\n```python\npip install --upgrade vllm\npip install --upgrade mistral_common\n```\n\n> ***Note****: vLLM version 0\\.6\\.2 or higher is required.*\n\n\n### Offline Usage with vLLM\n\nHere‚Äôs an example of how to use Ministral\\-8B in offline mode with vLLM:\n\n\n```python\nfrom vllm import LLM\nfrom vllm.sampling_params import SamplingParams\n\nmodel_name = \"mistralai/Ministral-8B-Instruct-2410\"\nsampling_params = SamplingParams(max_tokens=8192)\n\nllm = LLM(model=model_name, tokenizer_mode=\"mistral\", config_format=\"mistral\", load_format=\"mistral\")\n\nprompt = \"What are the potential implications of artificial intelligence on the job market in the next decade?\"\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": prompt\n    },\n]\n\noutputs = llm.chat(messages, sampling_params=sampling_params)\nprint(outputs[0].outputs[0].text)\n```\n\n### Server Mode Inference with vLLM\n\nIn server inference mode, vLLM runs an HTTP server that concurrently handles client connections and requests via a REST API compatible with the OpenAI protocol. Here‚Äôs how to set it up:\n\n* Start the server:\n\n\n```python\nvllm serve mistralai/Ministral-8B-Instruct-2410 --tokenizer_mode mistral --config_format mistral --load_format mistral\n```\n* Make requests to the server:\n\n\n```python\ncurl --location 'http://localhost:8000/v1/chat/completions' \\\n    --header 'Content-Type: application/json' \\\n    --header 'Authorization: Bearer token' \\\n    --data '{\n        \"model\": \"mistralai/Ministral-8B-Instruct-2410\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"What are the potential implications of artificial intelligence on the job market in the next decade?\"\n          }\n        ]\n      }'\n```\n\n> Important Notes on vLLM Usage:\n\n* Currently, vLLM is capped at a 32k context size due to limitations in implementing interleaved attention kernels for paged attention.\n* To leverage the full 128k context size, it‚Äôs recommended to use [Mistral Inference](https://github.com/mistralai/mistral-inference).\n* If you need to reduce GPU memory requirements, you can use tensor parallelism by adding `tensor_parallel=2` to the LLM initialization.\n\nBy following these examples, you can easily integrate Ministral\\-8B into your projects using vLLM, whether you‚Äôre running offline inference or setting up a server for multiple clients. The model‚Äôs efficiency and powerful capabilities, combined with vLLM‚Äôs optimized inference, make it an excellent choice for a wide range of AI applications.\n\n\n## Conclusion:\n\nThe release of Ministral marks a significant milestone in the evolution of AI. By bringing GPT\\-level performance to edge devices, Mistral AI is not just pushing technological boundaries ‚Äî they‚Äôre reimagining what‚Äôs possible with local, privacy\\-first artificial intelligence.\n\nAs developers, researchers, and businesses begin to explore the capabilities of Ministral, we can expect to see a new wave of AI\\-powered applications that are faster, more private, and more accessible than ever before. The age of edge AI is here, and Ministral is leading the charge.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/meet-qwen2-5-coder-32b-instruct-coder-open-source-better-than-gpt4o-5dc8343f8157","frontmatter":{"title":"Meet Qwen2.5-Coder-32B-Instruct -Coder -open source better than gpt4o.","meta_title":"Meet Qwen2.5-Coder-32B-Instruct -Coder -open source better than gpt4o.","description":"Qwen2.5-Coder-32B-Instruct is an advanced open-source AI coding assistant designed to enhance coding efficiency and accuracy. With 32 billion parameters, it matches or surpasses the capabilities of GPT-4o, offering features like long context handling (up to 128K tokens) and support for over 29 languages. Its strengths include high performance on coding benchmarks and adaptability for various coding tasks, though it requires significant processing power. Overall, Qwen2.5-Coder represents a significant step forward in AI-driven coding solutions.","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VENiO-pvY-FzxBLUqodjRQ.jpeg","categories":["Programming","Generative AI","Data Science"],"author":"Rifx.Online","tags":["parameters","coding","benchmarks","languages","efficiency"],"draft":false,"slug":"blog/meet-qwen2-5-coder-32b-instruct-coder-open-source-better-than-gpt4o-5dc8343f8157"},"content":"\n**Meet** Qwen2\\.5\\-Coder\\-32B-Coder, Your New AI Coding Buddy\n\nHave you ever wished that coding was a little easier, faster, and maybe even more fun? So, prepare to meet your new AI coding friend, Qwen2\\.5\\-Coder. Qwen2\\.5\\-Code specifically developed this model as a cutting\\-edge language model to simplify your coding experience. Consider having a knowledgeable assistant who can write code for you and debug, explain complex concepts, and handle several languages. Intrigued? Let‚Äôs look into what makes Qwen2\\.5\\-Coder so remarkable.\n\n\n\nüß† **Powerful Performance: Matching GPT\\-4o‚Äôs Coding Skills**\n\n> **Qwen2\\.5\\-Coder**, particularly the 32B\\-Instruct edition, is more than simply a code assistant; it‚Äôs a top performer, matching or even beating GPT\\-4o and Sonnet 3\\.5, regarded as one of the most powerful artificial intelligence models. Imagine having that level of coding ability available at your disposal, too.\n\n## Open\\-Source\n\nBut it isn‚Äôt all about raw power; this model exhibits outstanding correctness, resulting in syntactically precise and efficient code. And the best part? It is substantially speedier than its predecessors, allowing you to complete tasks quickly.\n\n**Key Features**\n\n* **Model Size**: 32 billion parameters.\n* **Context Length**: Supports up to 128K tokens, allowing for extensive input and output capabilities.\n* **Multilingual Support: This system can handle over 29 languages, including English, Chinese, French, and Spanish.**\n* **Instruction Following: This feature enhances the ability to follow complex instructions and generate structured outputs such as JSON.**\n* **Performance Benchmarks: The team scores highly on various coding benchmarks such as HumanEval and MATH.**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zyjKE3ZHtax3uX9GnbKUfA.png)\n\nThere are models suitable for all needs, ranging from small to large.\n\nRegardless of your level of experience or inexperience, Qwen2\\.5\\-Coder provides comprehensive coverage. The Qwen2\\.5\\-Coder comes in various sizes, ranging from 0\\.5B to an impressive 32B. This means you can select the model that best meets your requirements and resources. It‚Äôs like having a toolbox complete with different\\-sized wrenches, each ideal for a unique task.\n\nüåé Mastering multiple languages\n\nCoding in several languages? Not a problem! Qwen2\\.5\\-Coder supports more than 29 languages, including popular ones such as *English, Chinese, French, and Spanish*. This bilingual proficiency makes it a very adaptable tool for developers worldwide. It‚Äôs like having a universal code translator that removes linguistic barriers and opens up new possibilities.\n\nüëç Benefits: Increased productivity and improved learning\n\nLet‚Äôs discuss the pros.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MAhK8R45yNzB8A7mZZITBg.png)\n\n**Long Context Handling:** The model can handle long inputs of up to 128K tokens. This is especially useful for sophisticated coding tasks that require extensive background. **Multilingual Skills**: Qwen2\\.5\\-Coder\\-32B\\-Instruct supports more than 29 languages, including English, Chinese, French, and Spanish. This makes it a valuable tool for developers working on projects with various language requirements.\n\nüëé **Cons**: resource\\-intensive and risk of over\\-reliance.\n\nOf course, every technology has its drawbacks. Qwen2\\.5\\-Coder demands significant processing power, especially in its larger variants. Maximizing its use requires powerful hardware.\n\nüéâ **The Future of Coding**?\n\nQwen2\\.5\\-Coder marks a massive advancement in AI\\-powered coding. Its precision, speed, adaptability, and open\\-source nature make it an intriguing breakthrough. The real benefit for the open source community would be if the computing power required is lessened and API costs for development are cheaper, too.\n\nOther than that, it is quite promising and would also keep large players behind the Paywall under control.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aHeNvfOvcpME0qzy6EQexQ.jpeg)\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PI0ioI2MtxQgtNZ0Tq1jwQ.jpeg)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/metas-llama-4-is-coming-soon-plus-parallels-brings-apple-intelligence-to-windows-c1c2722dcf03","frontmatter":{"title":"Meta‚Äôs Llama 4 is Coming Soon Plus: Parallels Brings Apple Intelligence to Windows","meta_title":"Meta‚Äôs Llama 4 is Coming Soon Plus: Parallels Brings Apple Intelligence to Windows","description":"No subtitle provided","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*sYakQyN_2Lupo_By","categories":["Technology","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["Llama","GPUs","Parallels","Recraft","Midjourney"],"draft":false,"slug":"blog/metas-llama-4-is-coming-soon-plus-parallels-brings-apple-intelligence-to-windows-c1c2722dcf03"},"content":"\n\n\n\n\n### Plus: Parallels Brings Apple Intelligence to Windows\n\n\n\n**Welcome to Get The Gist**, where every weekday, we share an easy\\-to\\-read summary of the latest and greatest developments in AI ‚Äî news, innovations, and trends ‚Äî all delivered in under 5 minutes! ‚è±\n\n**In today‚Äôs edition:**\n\n* Mark Zuckerberg Announces Meta‚Äôs Llama 4\n* Parallels Brings Apple Intelligence to Windows\n* Recraft V3 Challenges Midjourney\n* Meta AI Surpasses 500 Million Users\n* And more AI news‚Ä¶.\n\n\n## 1\\. Meta‚Äôs Llama 4 is Coming Soon with Major AI Advancements\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*E_j8uSNV6s3lg2vm)\n\n**The Gist:** Mark Zuckerberg [**confirmed that**](https://analyticsindiamag.com/ai-news-updates/mark-zuckerberg-confirms-llama-4-release-early-next-year/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon) Meta will launch its Llama 4 model early next year, promising new capabilities in speed, reasoning, and cross\\-modality, thanks to a record\\-setting training setup.\n\n**Key Details:**\n\n* Meta is training Llama 4 on a massive setup with over 100,000 H100 GPUs, one of the largest AI clusters reported, aiming for faster and more capable models than ever.\n* The new Llama 4 will introduce advanced capabilities like expanded memory, support for multiple data types, and seamless third\\-party integrations.\n* AI continues to drive Meta‚Äôs growth, as generative tools help over a million advertisers increase conversion rates by 7% and boost user engagement on Facebook and Instagram.\n* Zuckerberg highlighted that AI innovations are creating new business opportunities, emphasizing Meta‚Äôs commitment to long\\-term AI\\-powered growth across products and platforms.\n\n\n## 2\\. Parallels Bring Apple Intelligence to Windows\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*36yykSGFUbML6zR4)\n\n**The Gist:** Parallels Desktop [**now enables**](https://www.neowin.net/news/parallels-brings-apple-intelligence-features-to-windows/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon) Apple‚Äôs AI\\-driven Writing Tools on Windows virtual machines for Macs, allowing users to enhance text in Windows apps using Apple Intelligence.\n\n**Key Details:**\n\n* Parallels Desktop 20\\.1 now supports Apple Writing Tools on Windows apps within macOS Sequoia 15\\.1, giving users access to text improvements like summarizing, rewriting, and tone adjustments in apps like Word and Notepad.\n* To activate, users with macOS 15\\.1 and compatible Macs (M1 or newer) can update Parallels and use shortcuts to apply these tools in Windows apps.\n* Apple Writing Tools, part of Apple Intelligence, are also rolling out on iPadOS and iOS, but only on devices with advanced processors, such as M1, M2, or A17 Pro chips.\n* This update gives Mac users a seamless way to enhance their writing across both Mac and Windows environments, blending Apple‚Äôs AI with Windows usability.\n\n\n## 3\\. Recraft V3 Challenges Midjourney with Designer\\-Centric AI Image Generation\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*lYoMCLyX61RKwMiF)\n\n**The Gist:** Recraft [**has unveiled**](https://www.tomsguide.com/ai/ai-image-video/watch-out-midjourney-recraft-just-announced-new-ai-image-generator-model?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon) Recraft V3, a new AI model for image generation that aims to outperform rivals like Midjourney with powerful design\\-focused features and seamless text integration.\n\n**Key Details:**\n\n* Recraft V3 introduces precise text handling within images, allowing users to add and style text effortlessly, a rare feature among AI models; it currently holds top ranking on Hugging Face‚Äôs leaderboard.\n* Designers can now control text placement, brand colors, and unique styles, offering enhanced customization and addressing key needs for creative professionals.\n* With an Infinite Canvas, real\\-time collaboration, and an API for advanced workflows, Recraft V3 supports both individual and team\\-based design projects.\n* Recraft has over 1\\.5 million users who have generated more than 200 million images, with the tool available across web, iOS, and Android platforms.\n\n\n## Quick Gist\n\n* **Zenity** raised $38 million in Series B funding to advance security solutions for enterprises using agentic AI and low\\-code tools, addressing key security concerns in process automation [(Read More)](https://www.darkreading.com/application-security/zenity-raises-38m-series-b-funding-round-to-secure-agentic-ai?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon).\n* **OpenAI** updated its Realtime API with five new expressive voices for speech\\-to\\-speech applications and significant cost reductions through prompt caching, currently in beta ([Read More](https://venturebeat.com/ai/openai-expands-realtime-api-with-new-voices-and-cuts-prices-for-developers/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **OpenAI** has rolled out its advanced voice mode for free users in Europe, allowing engaging, human\\-like interactions with ChatGPT ([Read More](https://www.tomsguide.com/ai/openai-advanced-voice-is-now-free-for-10-minutes-a-month-3-tips-for-getting-the-most-out-of-that-time?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **OpenAI** is rolling out a new feature for ChatGPT that allows users to search their chat history, with availability for free users planned for next month ([Read More](https://indianexpress.com/article/technology/artificial-intelligence/chatgpt-now-allow-users-to-search-through-their-history-heres-how-to-use-it-9647233/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Meta** is collaborating with the US government to implement its AI model Llama for various public\\-sector projects, including improving access to resources and simplifying financial aid without any financial transactions involved ([Read More](https://www.newsbytesapp.com/news/science/meta-working-to-get-llama-used-in-us-government-sectors/story?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Meta** plans to launch its Llama 4 AI model early next year, training it on an unprecedented cluster of over 100,000 H100 GPUs while advocating for an open\\-source approach despite concerns over potential misuse ([Read More](https://www.newsbytesapp.com/news/science/meta-trains-llama-4-models-on-largest-nvidia-gpu-cluster/story?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **OpenAI** has launched Advanced Voice Mode for ChatGPT, allowing users to engage in natural, spoken conversations on desktop apps, with the feature already gaining popularity among subscribers ([Read More](https://www.digitaltrends.com/computing/chatgpt-advanced-voice-mode-macos-windows-desktops/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Waymo** is enhancing its autonomous driving technology by developing a new multimodal large language model, EMMA, to improve its robotaxis‚Äô decision\\-making and adaptability in complex environments ([Read More](https://www.theverge.com/2024/10/30/24283516/waymo-google-gemini-llm-ai-robotaxi?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Gemini** now includes a split\\-screen shortcut for multitasking on large\\-screen Android devices like the Pixel Tablet and Fold, enhancing the user experience ([Read More](https://www.androidauthority.com/gemini-split-screen-shortcut-3495573/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Meta AI** has surpassed half a billion users in just one year since its launch, positioning itself to potentially become the most\\-used AI assistant by the end of 2024 despite facing privacy challenges in the EU ([Read More](https://www.phonearena.com/news/meta-ai-reaches-500-million-users-in-one-year_id164309?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Adobe** has updated Illustrator and Photoshop with AI\\-powered features to streamline creative processes and enhance user flexibility, emphasizing the augmentation of human creativity rather than replacement ([Read More](https://www.gearpatrol.com/tech/six-new-powerful-ai-features-every-adobe-photoshop-illustrator-must-try/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **NVIDIA** researchers unveiled HOVER, a 1\\.5 million parameter neural network that enables humanoid robots to perform complex tasks through efficient motor coordination and real\\-time adaptability ([Read More](https://analyticsindiamag.com/ai-news-updates/nvidia-introduces-hover-a-1-5-m-parameter-neural-network-for-humanoid-robotics/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Google** launched a new standalone Weather app for Pixel devices that uses AI to summarize outdoor conditions and offers multiple location tracking ([Read More](https://www.theverge.com/2024/10/30/24283998/google-weather-app-pixel-8-7-6-ai-summaries?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n\nThat‚Äôs it for today, see you tomorrow! üëã\n\nIf you enjoyed this update and want to stay informed about the latest developments in AI, consider subscribing to ***Get The Gist*** on Medium for more insights and analyses.\n\n**Want to dive even deeper?** Subscribe to our free daily email newsletter for quick, concise updates straight to your inbox so you never miss an important development. You can sign up by clicking [here](https://getthegist.beehiiv.com/).\n\nJoin us as we explore the world of AI together ‚Äî one gist at a time! üí°ü§ñ\n\n\n"},{"lang":"en","group":"blog","slug":"blog/microsoft-graphrag-v0-4-0-ec98f1f6ed7a","frontmatter":{"title":"Microsoft GraphRAG v0.4.0","meta_title":"Microsoft GraphRAG v0.4.0","description":"Microsoft recently released version v0.4.0 of the GraphRAG project, featuring several significant updates. The most notable additions are‚Ä¶","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*89qTckZYLUBF1Jtv","categories":["Programming","Data Science","Machine Learning"],"author":"Rifx.Online","tags":["GraphRAG","Incremental","Indexing","DRIFT","Embedding"],"draft":false,"slug":"blog/microsoft-graphrag-v0-4-0-ec98f1f6ed7a"},"content":"\n\n\n\nMicrosoft recently released version v0\\.4\\.0 of the GraphRAG project, featuring several significant updates. The most notable additions are the Incremental Indexing feature and the DRIFT Graph Reasoning Query Module, which significantly enhance system efficiency and functionality.\n\n\n\nThe core highlights of this update include:\n\n1\\. Incremental Indexing: Significantly improves the efficiency of large\\-scale data processing and achieve faster information updates.\n\n2\\. DRIFT Graph Reasoning Query Module: Introducing advanced graph reasoning techniques to enhance complex query processing capabilities.\n\nIn addition, version 0\\.4\\.0 has optimized the embedding workflow, restructured the processing flow, and improved the overall system performance and operability. Additionally, it has added the DRIFT search CLI and example notebook to assist developers in better understanding the new features. Moreover, the introduction of relationship merging and incremental update configuration options further enhances the flexibility and intelligence level of GraphRAG.\n\nThese updates not only enhance the processing speed of GraphRAG, for instance, in large\\-scale financial data analysis, the incremental indexing feature can reduce data update times from hours to minutes. Simultaneously, they also strengthen its applicability in complex knowledge graph applications, significantly broadening its use cases. Industry experts predict that these improvements will play a crucial role in fields such as financial analysis and medical diagnosis, driving AI applications towards more precise and efficient development.\n\nMore update content: [https://proxy.rifx.online/https://github.com/microsoft/graphrag/releases/tag/v0\\.4\\.0](https://proxy.rifx.online/https://github.com/microsoft/graphrag/releases/tag/v0.4.0)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/mistral-ai-releases-revolutionary-edge-models-ministral-3b-and-8b-superior-performance-and-privacy-5b24f0189493","frontmatter":{"title":"Mistral AI Releases Revolutionary Edge Models Ministral 3B and 8B: Superior Performance and Privacy","meta_title":"Mistral AI Releases Revolutionary Edge Models Ministral 3B and 8B: Superior Performance and Privacy","description":"No subtitle provided","date":"2024-10-31T08:32:15.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zFNeFlbfEnbjV5M65sH5ig@2x.jpeg","categories":["Technology","Machine Learning","Autonomous Systems"],"author":"Rifx.Online","tags":["edge","models","privacy","tokens","attention"],"draft":false,"slug":"blog/mistral-ai-releases-revolutionary-edge-models-ministral-3b-and-8b-superior-performance-and-privacy-5b24f0189493"},"content":"\n\n\n\nRecently, Mistral AI has launched two new edge models ‚Äî Ministral 3B and Ministral 8B, which have garnered widespread attention in the tech community. These models not only excel in performance but also offer unique advantages in privacy protection.\n\n\n\n\n## Exceptional Performance, Privacy First\n\nMinistral 3B and 8B are designed specifically for on\\-device computation, capable of processing text information up to 128k in length. Particularly, Ministral 8B employs an innovative sliding window attention mechanism, significantly enhancing computational speed and memory efficiency. Moreover, both models prioritize privacy protection in their design, ensuring data is processed locally to reduce the risk of data breaches.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GMgT6erSorAGUp-pqbXWhA@2x.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zRGh7rw7oVXYd5mOhXoc3g@2x.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IIYgXVtbHvWqn6QLSZ-0Ow@2x.jpeg)\n\n\n## Versatile Applications, Unlimited Potential\n\nThe Ministral series models have a wide range of applications. In the field of smart assistants, they can quickly respond to user commands while ensuring data security; in the field of autonomous robots, their powerful reasoning capabilities support complex decision\\-making and operations.\n\n\n## Cost\\-Effective, Broad Market Prospects\n\nDespite their outstanding performance, Ministral 3B and 8B are highly competitive in price. The 3B is priced at $0\\.04 per million tokens, and the 8B at $0\\.10\\. This pricing strategy provides enterprises and developers with a cost\\-effective option. Currently, both models are available for use.\n\n\n## Promising Future, Leading the New Trend in Edge Computing\n\nThe release of the Ministral series models by Mistral AI demonstrates its deep technical strength in edge computing, laying a solid foundation for future on\\-device AI applications. With technological advancements and deeper application exploration, Ministral models are expected to play a greater role in smart devices and the Internet of Things.\n\nIn summary, the launch of Ministral 3B and 8B is not only a significant milestone for Mistral AI but also a major advancement for the AI industry, bringing new possibilities to on\\-device computation.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*A6SToo3fO3DqnlWX)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/mistral-ai-unveils-ministral-3b-and-8b-models-plus-nvidia-launches-ai-model-that-outperforms-gpt-4-941712f5d22d","frontmatter":{"title":"Mistral AI Unveils Ministral 3B and 8B Models Plus: Nvidia Launches AI Model that Outperforms GPT-4","meta_title":"Mistral AI Unveils Ministral 3B and 8B Models Plus: Nvidia Launches AI Model that Outperforms GPT-4","description":"No subtitle provided","date":"2024-10-31T08:29:07.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*PtPEkgjabwBUu73Y","categories":["Technology","Generative AI","Machine Learning"],"author":"Rifx.Online","tags":["Mistral","edge","Llama","YouTube","DreamTracks"],"draft":false,"slug":"blog/mistral-ai-unveils-ministral-3b-and-8b-models-plus-nvidia-launches-ai-model-that-outperforms-gpt-4-941712f5d22d"},"content":"\n\n\n\n\n### Plus: Nvidia Launches AI Model that Outperforms GPT\\-4\n\n\n\n**Welcome to Get The Gist**, where every weekday we share an easy\\-to\\-read summary of the latest and greatest developments in AI ‚Äî news, innovations, and trends ‚Äî all delivered in under 5 minutes! ‚è±\n\n**In today‚Äôs edition:**\n\n* Mistral AI Unveils Ministral 3B and 8B Models for Edge Computing\n* Nvidia Quietly Launches AI Model that Outperforms GPT\\-4\n* YouTube Rolls Out AI Music Tool ‚ÄúDream Tracks‚Äù to U.S. Creators\n* Google Gemini Can Now Generate Images in Customizable Aspect Ratios\n* And more AI news‚Ä¶.\n\n\n## 1\\. Mistral AI Unveils Ministral 3B and 8B Models for Edge Computing\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*qAjoYMHGI1TkNy_A)\n\n**The Gist:** Mistral AI has [**launched two new AI models**](https://analyticsindiamag.com/ai-news-updates/mistral-ai-launches-ministral-3b-and-8b-models-for-edge-computing/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models), Ministral 3B and 8B, designed for efficient on\\-device and edge computing. These models outperform competitors and are tailored for tasks requiring privacy\\-first, local inference.\n\n**Key Details:**\n\n* Models handle large context lengths (up to 128k) for smooth performance in resource\\-limited environments.\n* Ideal for applications like smart assistants, local analytics, and robotics, enhancing task efficiency.\n* Available for commercial use with competitive pricing and research access for the 8B Instruct model.\n* Outperforms AI models like Gemma 2 and Llama 3 in benchmarks.\n\n\n## 2\\. Nvidia Quietly Launches AI Model that Outperforms GPT\\-4\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Mza84SHereM3w5rN)\n\n**The Gist:** Nvidia has [**released a new AI model**](https://venturebeat.com/ai/nvidia-just-dropped-a-new-ai-model-that-crushes-openais-gpt-4-no-big-launch-just-big-results/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models), Llama\\-3\\.1\\-Nemotron\\-70B\\-Instruct, which surpasses industry giants like OpenAI‚Äôs GPT\\-4 in performance benchmarks. This launch marks a significant expansion of Nvidia‚Äôs AI strategy, shifting from hardware to high\\-performing AI software.\n\n**Key Details:**\n\n* Nvidia‚Äôs new model scored higher than GPT\\-4 on key benchmarks, demonstrating superior language understanding and generation.\n* Developed using advanced techniques like Reinforcement Learning from Human Feedback (RLHF), the model excels in handling complex queries.\n* Nvidia offers free access through its platform, allowing businesses to experiment with this powerful AI tool.\n* The model is customizable for business needs but requires careful use in specialized areas like legal reasoning or math.\n\n\n## 3\\. YouTube Rolls Out AI Music Tool ‚ÄúDream Tracks‚Äù to U.S. Creators\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5nUNrJmdCBBy4JdQ)\n\n**The Gist:** YouTube has launched its [**AI\\-powered music generator**](https://www.mediapost.com/publications/article/400280/youtube-brings-ai-audio-generator-to-us-creators.html?edition=136037&utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models) ‚ÄúDream Tracks‚Äù in the U.S., allowing creators to use text prompts to create custom audio for their short\\-form videos. The tool aims to deepen the connection between artists and fans through music creation.\n\n**Key Details:**\n\n* Powered by Google DeepMind‚Äôs Lyria, Dream Tracks generates custom instrumental soundtracks for YouTube Shorts.\n* U.S. creators can now use this tool to create royalty\\-free soundtracks up to 30 seconds long.\n* Users can remix the AI\\-generated audio clips, enhancing creative possibilities.\n* YouTube applies a hidden SynthID watermark to all AI\\-generated tracks to ensure transparency.\n\n\n## Quick Gist\n\n* **Clerk Chat** secured $7 million in funding led by Race Capital to enhance its AI\\-powered business communication platform [(Read More)](https://www.businesswire.com/news/home/20241017292794/en/World%E2%80%99s-First-AI-Telecom-Clerk-Chat-Raises-7.0-Million-in-Seed-Funding?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models).\n* **Anthropic** CEO Dario Amodei published a lengthy blog outlining a utopian vision for the transformative potential of artificial general intelligence, while simultaneously seeking to secure a $40 billion valuation for the company [(Read More)](https://www.theverge.com/2024/10/16/24268209/anthropic-ai-dario-amodei-agi-funding-blog?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models).\n* **Google Cloud** announced the general availability of its upgraded Vertex AI platform and Healthcare Data Engine to enhance AI applications in healthcare [(Read More)](https://www.forbes.com/sites/saibala/2024/10/17/google-cloud-announces-general-availability-of-vertex-ai-for-healthcare/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models).\n* **Amazon** led a $500 million funding round for X\\-energy to roll out 5GW of small nuclear reactors by 2039, while **Google** partnered with Kairos Power to install 500MW of SMRs by 2035, both aiming to meet rising energy demands from data centers with clean power [(Read More)](https://www.theengineer.co.uk/content/news/amazon-and-google-bet-big-on-smrs-to-power-ai?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models).\n* **Google** is launching its Gemini AI models for public sector agencies within Google Distributed Cloud in early 2025, along with funding to upskill the government workforce in responsible AI practices [(Read More)](https://siliconangle.com/2024/10/16/google-looks-spearhead-ai-adoption-public-sector/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models).\n* **Google**‚Äôs Gemini AI chatbot is set to introduce a feature allowing users to generate images in customizable aspect ratios, enhancing its image editing capabilities [(Read More)](https://indianexpress.com/article/technology/artificial-intelligence/google-gemini-may-soon-get-new-image-resizing-feature-9623756/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models).\n\nThat‚Äôs it for today, see you tomorrow! üëã\n\nIf you enjoyed this update and want to stay informed about the latest developments in AI, consider subscribing to ***Get The Gist*** on Medium for more insights and analyses.\n\n**Want to dive even deeper?** Subscribe to our free daily email newsletter for quick, concise updates straight to your inbox, so you never miss an important development. You can sign up by clicking [here](https://getthegist.beehiiv.com/).\n\nJoin us as we explore the world of AI together ‚Äî one gist at a time! üí°ü§ñ\n\n\n"},{"lang":"en","group":"blog","slug":"blog/mojo-90-000-times-faster-than-python-finally-open-sourced-777bdd9a1896","frontmatter":{"title":"Mojo, 90,000 Times Faster Than Python, Finally Open Sourced!","meta_title":"Mojo, 90,000 Times Faster Than Python, Finally Open Sourced!","description":"On March 29, 2024, Modular Inc. announced the open sourcing of the core components of Mojo.","date":"2024-11-10T22:36:54.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*jcayumihC6jn5q_0","categories":["Programming","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Mojo","Python","MLIR","SIMD","open-source"],"draft":false,"slug":"blog/mojo-90-000-times-faster-than-python-finally-open-sourced-777bdd9a1896"},"content":"\nOn March 29, 2024, Modular Inc. announced the open sourcing of the core components of Mojo.\n\nMojo is a programming language designed specifically for writing artificial intelligence software, officially launched in August of last year. It has since amassed over 175,000 developers and 50,000 organizations.\n\nArtificial intelligence models are often written in multiple programming languages. Developers typically use Python to implement the simplest parts of neural networks, as it is easy to learn but relatively slow. The remaining code is often written in C\\+\\+, which is faster but more complex to learn.\n\nModular positions Mojo as a more convenient alternative. It offers an easy\\-to\\-use syntax similar to Python but with the potential for thousands of times faster execution speed. Therefore, developers can write fast AI models without needing to learn complex languages like C\\+\\+.\n\n\n\nLast year, when Mojo was introduced, some developers expressed excitement about its emergence. However, when asked about the open\\-source date, Chris Lattner said on Discord, ‚ÄúIf I knew, I‚Äôd tell you.‚Äù For about a year, many developers have been in a state of observation and questioning:\n\n> ‚ÄúThe promotion is great, but if it‚Äôs not open source, I won‚Äôt spend any time trying it.‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rIJiJylh4-mWBiqz)\n\n> ‚ÄúIt‚Äôs clearly an overhyped programming language, and it‚Äôs not open source! Chris Lattner wants to deceive millions of Python developers!‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0u5HDKseL0Gy_-8A)\n\n> ‚ÄúI can‚Äôt spend time on a language that might or might not be open source, especially considering the current commercial environment of OSS‚Ä¶‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wrTO7fbKfBZOpBxF)\n\nNow, Mojo is finally open source! And within a short period, it has already reached 17\\.6k stars and has 2\\.1k forks!\n\n## 01 The First Step of Mojo‚Äôs Open Source Journey\n\nModular announced today the open sourcing of the core components of Mojo‚Äôs standard library. The standard library constitutes the core part of a programming language, containing basic syntax elements and essential features. Mojo‚Äôs standard library includes functionalities for optimizing AI hyperparameters, which determine how neural networks process data.\n\n‚ÄúThe Mojo standard library is still undergoing vigorous development and rapid changes, so we are open sourcing its core modules first. This marks an important starting point for our open source journey, not the end.‚Äù\n\nThe company states that open sourcing will enable them to gather feedback from more developers, facilitating the better development of Mojo. Moreover, there are various ways to open source projects: some projects provide source code but do not accept contributions; some offer opaque contribution processes, making it difficult to understand goals and roadmaps; and some, though open source, are not actively maintained. Modular states that they have chosen a more thorough approach to open source: allowing external contributions via GitHub pull requests, encouraging developers to participate in Mojo‚Äôs development and improvement, and fostering community growth.\n\nFurthermore, Modular demonstrates sincerity by sharing the complete commit history, starting from the initial commit! Openly revising the history of the open standard library allows developers to track the evolution of the code and better understand its meaning.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0-FqkfLUTevloPjI)\n\nIn addition, they will release nightly builds of the Mojo compiler, facilitating developers to quickly try out the latest compiler features and undergo continuous integration testing.\n\nAt the end of last year, Modular launched the commercial AI platform MAX, which is a unified set of tools and libraries for building high\\-performance AI applications that can be efficiently deployed across multiple hardware platforms, such as running AI applications in Kubernetes environments. Today, the company revealed that they also plan to open source some components of MAX in the future.\n\nMoreover, it is worth mentioning that they have chosen the Apache 2 LLVM license for open sourcing.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*dgVCSxaCq6onY2uP)\n\nThis is a customized version of the Apache 2 license. Additionally, to facilitate integration with software following the GPL2 license, Modular has made corresponding adjustments. GPL2 is another popular open source license, famously used by projects like the Linux kernel. In the announcement blog post, Modular wrote:\n\n> ‚ÄúThe Apache 2 license is a good starting point, but our experience with using licenses in the LLVM project tells us that it has two minor issues. Some are concerned that the Apache 2 license may not mix well with GPL2 code (e.g., the Linux kernel), and the Apache 2 license requires you to acknowledge the use of the code in derivative projects. We hope you can use Mojo without being forced to acknowledge Modular or Mojo. Therefore, we have added LLVM‚Äôs specially designed exceptions to address these issues.‚Äù\n\n## 02 The Best Language for AI Programming in the Next 50 Years?\n\nLast May, when Mojo was just released, Modular claimed that it was 35,000 times faster than raw Python when running algorithms like Mandelbrot.\n\nIn September last year, Modular once again stated, ‚ÄúMojo combines the advantages of dynamic and static languages, boosting performance to 68,000 times that of Python.‚Äù\n\nIn October last year, when Mojo landed on Mac, Modular raised the performance comparison data again: ‚Äú90,000 times faster than Python.‚Äù\n\nSpeaking of Mojo, Modular‚Äôs founder and CEO Chris Lattner said, ‚ÄúYou can think of Mojo as a member of the Python family, drawing on all these cool languages, compilers, and other technologies, taking Python a big step forward. We believe it enhances Python‚Äôs capabilities, gives Python programmers superpowers, allows those familiar with Python to learn new knowledge, explore, and conquer new fields without switching to C\\+\\+.‚Äù\n\nMojo is based on the latest compiler technology in MLIR, which is an evolution of LLVM, hence better performance. As long as programmers have the requisite skills and a willingness to optimize fully, they can make the code run extremely fast. The goal of the Mojo language is to meet the needs of Python developers while providing a range of new code optimization techniques to fully exploit the performance limits of hardware devices.\n\nOn the other hand, the Mojo team highly appreciates Rust and openly states that ‚ÄúMojo‚Äôs design is also greatly inspired by Rust.‚Äù\n\nIn terms of performance, Modular has made many comparisons with Python to provide a clear comparison, but people do not have a concept of how much faster it is than Rust. Just last month, they specifically responded to the question of ‚Äúwhether Mojo is faster than Rust.‚Äù\n\nIn February of this year, Netflix engineer and Rust advocate @ThePrimeagen released a video: parsing DNA sequences with Mojo at a speed surpassing Rust by 50%. This blog post has sparked a lot of attention and discussion, after all, Rust is positioned as a potential successor to Python and C\\+\\+ as the dominant language in the AI field.\n\n@ThePrimeagen‚Äôs outlook for Mojo and Rust in AI programming:\n\n> If Mojo officially enters the fray, then I believe Mojo will undoubtedly emerge victorious. The reason Mojo will win is that it doesn‚Äôt require any changes to the paradigms developers are already familiar with. With just a little learning, you can achieve amazing performance. First of all, Mojo compiles quickly, and the user experience is very similar to languages everyone is already familiar with, with performance comparable to Rust. The only question is how to get more people to accept it.\n\nAfter making the comment, Luca Palmieri, a respected Rust contributor and author of ‚ÄúRust: From Zero to Production,‚Äù responded on X:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Hqe7bPWGI36LPGzE)\n\nRust boasts top\\-notch ergonomic design in the realm of systems programming, but it faces two major issues in the field of AI applications:\n\n* Slow compilation speed, while AI emphasizes experimentation and rapid iteration.\n* Most AI researchers with experience in Python are reluctant to invest time in learning a new language from scratch.\n\nMojo aims to make it intuitive and easy for Python developers to grasp. As demonstrated by Mohamed, he learned Mojo and utilized SIMD optimization algorithms in just a few weeks as a hobby project (the initial implementation only took 200 lines of code).\n\nFor those interested in AI development, there is indeed a dilemma of choosing one of the three languages available.\n\nBoth Mojo and Rust allow developers to optimize at a lower level. For Rust, developers can certainly pack everything into Arc, Mutex, or Box to avoid conflicts with the borrow checker, but this may sacrifice some performance. While this performance difference might not have a significant impact on application code, it can quickly add up in libraries or other performance\\-sensitive code. The choice between the two depends on the programmer‚Äôs focus on reducing overhead and optimizing performance.\n\nBoth languages can utilize LLVM for optimizing code generation and allow the use of inline assembly (although it‚Äôs unlikely anyone would actually do so), so theoretically, both have similar performance potential on traditional hardware.\n\n## 03 Based on the Most Advanced Compiler Technology\n\nRust was initiated in 2006, while Swift emerged in 2010, with both primarily built on LLVM IR. Mojo, on the other hand, debuted in 2022, constructed upon MLIR ‚Äî a more modern ‚Äúnext\\-generation‚Äù compiler stack compared to LLVM IR used by Rust. It‚Äôs worth noting that Chris Lattner founded LLVM in December 2000 during his university days, learning a great deal from its evolution over the years. He later joined Google to lead the development of MLIR, aimed at supporting the company‚Äôs TPU and other AI accelerator projects. Subsequently, he continued his exploration based on the knowledge gained from LLVM IR.\n\nModular states that Mojo is the first programming language to fully leverage the advanced features of MLIR. It can generate CPU code with higher optimization and also supports GPU and other accelerators, with significantly faster speeds than Rust. This is an advantage currently unachievable by other languages, and a core reason why AI and compiler enthusiasts are enthusiastic about Mojo.\n\nThey particularly emphasize two aspects:\n\nOutstanding SIMD ergonomic design: CPUs process multiple data elements simultaneously through special registers and instructions, known as SIMD (Single Instruction, Multiple Data). However, historically, the experience of writing such code has been ugly and challenging to use from an ergonomic standpoint. Although these special instructions have existed for years, most code has not been optimized for them. Therefore, whoever can solve this complexity and write portable SIMD optimization algorithms can stand out in the market, such as simd\\_json.\n\nMojo‚Äôs primitives are designed with SIMD priority from the outset: UInt8 is actually a SIMD\\[DType.uint8, 1], representing a SIMD with 1 element. This representation incurs no performance overhead while allowing programmers to easily use it for SIMD optimization. For example, text can be split into 64\\-byte blocks, represented as SIMD\\[DType.uint8, 64], and then compared with a single newline character to find the index of each newline. As SIMD registers on machines can perform operations on 512\\-bit data simultaneously, this operation can boost the performance of such operations by 64 times!\n\nOr to give a simpler example, suppose you have a SIMDDType.float64, 8\\. By simply multiplying it by Float64(2\\), you can easily improve performance. Compared to individually multiplying each element, this method can improve performance by up to 8 times on most machines.\n\nLLVM (also used by Rust) has automatic vectorization optimization passes, but due to its inability to change the memory layout of SIMD and other important details, its performance never reaches the theoretical level of optimization. However, Mojo was designed with SIMD features in mind from the beginning, so the experience of writing SIMD optimizations is very similar to writing regular code.\n\nEager Destruction: Rust‚Äôs design is inspired by C\\+\\+‚Äôs RAII (Resource Acquisition Is Initialization), meaning that once objects go out of scope, application developers don‚Äôt need to worry about releasing memory ‚Äî the programming language itself handles it. This is a very good example that avoids the performance pitfalls of garbage collection while ensuring dynamic language ergonomics.\n\nMojo goes further by not waiting for the end of the scope but releasing memory when the object is last used. This is very beneficial for AI scenarios because releasing objects early means releasing GPU tensors early, allowing for larger models to be fitted in equivalent GPU RAM. This is Mojo‚Äôs unique advantage, allowing programmers to achieve optimal performance without having to design it themselves. Rust‚Äôs borrow checker initially extends the lifetime of everything to the end of its scope, matching the behavior of destructor functions, but this can lead to some confusing consequences for users. Rust later added some non\\-lexical lifetime features to simplify the work of developers. However, with Mojo‚Äôs eager destructor mechanism, this simplification effect can be directly achieved, and it remains consistent with how objects are actually destroyed, thus avoiding confusing extreme cases.\n\nAnother overhead in Rust comes from the implementation of Drop. It uses Drop Flags to track whether objects should be deleted at runtime. Rust is able to optimize in certain situations, but Mojo can eliminate all extra overhead through explicit definitions.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0VcMppg3rDTqfsMY)\n\nRegardless, developers must choose between the ease of use of Mojo and Python, and the high performance of C, C\\+\\+, or Rust. In response, the Mojo team calls out to developers, saying, ‚ÄúIf you‚Äôre curious and looking towards the future, hoping to master a language that may benefit AI development in the next 50 years, why not give Mojo a chance?‚Äù\n\n\n"},{"lang":"en","group":"blog","slug":"blog/multi-agent-hedge-fund-simulation-with-langchain-and-langgraph-64060aabe711","frontmatter":{"title":"Multi-Agent Hedge Fund Simulation with LangChain and LangGraph","meta_title":"Multi-Agent Hedge Fund Simulation with LangChain and LangGraph","description":"This project demonstrates how to use a multi-agent setup to simulate a hedge fund‚Äôs analytical process. It showcases a practical way to‚Ä¶","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*i8wneK22YezD7zOhPKvZfg.png","categories":["Finance","Programming","Data Science"],"author":"Rifx.Online","tags":["multi-agent","LangChain","LangGraph","FinancialDatasets","predictive"],"draft":false,"slug":"blog/multi-agent-hedge-fund-simulation-with-langchain-and-langgraph-64060aabe711"},"content":"\n\n### Multi\\-Agent Hedge Fund Simulation with LangChain and LangGraph\n\n\n\nThis project demonstrates how to use a multi\\-agent setup to simulate a hedge fund‚Äôs analytical process. It showcases a practical way to build a system that uses AI agents to gather and analyze financial data, a setup that could be scaled and customized further. Here, I‚Äôll break down the project, which involves a portfolio manager and three analyst agents (fundamental, technical, and sentiment), each assigned specific roles in gathering and processing stock data.\n\nThe goal of this project is not to build a comprehensive trading algorithm but rather to illustrate how various types of data can be organized and analyzed in parallel with specialized agents using LangChain and LangGraph.\n\n\n### Project Structure and Agent Overview\n\nThis agent system includes:\n\n1. **Portfolio Manager** ‚Äî Delegates tasks to analysts and aggregates their findings.\n2. **Fundamental Analyst** ‚Äî Fetches and analyzes financial statements, such as income statements.\n3. **Technical Analyst** ‚Äî Collects stock price data over specified timeframes.\n4. **Sentiment Analyst** ‚Äî Looks at insider trading and news data, providing sentiment insights.\n\nEach agent is designed to specialize in a specific data retrieval task, allowing for modular and scalable analysis. By using LangChain for agent functionality and LangGraph for managing parallel workflows, we can quickly process multiple data sources. The FinancialDatasets API provides a rich source of data with over 30,000 stock tickers, enabling comprehensive analysis.\n\n\n### Key Libraries and Setup\n\nLangChain and LangGraph enable easy handling of multi\\-agent workflows and branching logic for parallel processing. The setup begins by installing required libraries and securing API keys:\n\n\n```python\n%%capture --no-stderr\n%pip install -U langgraph langchain langchain_openai langchain_experimental langsmith pandas\n```\nEnvironment variables are used to store sensitive data, like API keys:\n\n\n```python\nimport getpass\nimport os\n\ndef _set_if_undefined(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n\n_set_if_undefined(\"OPENAI_API_KEY\")               # https://platform.openai.com\n_set_if_undefined(\"FINANCIAL_DATASETS_API_KEY\")   # https://financialdatasets.ai\n_set_if_undefined(\"TAVILY_API_KEY\")               # https://tavily.com\n```\n\n### Agent Functions: Retrieving Data\n\nEach agent in the system is designed to handle specific types of data relevant to stock analysis.\n\n\n### 1\\. Fundamental Analyst\n\nThe Fundamental Analyst retrieves and examines financial statements, which offer insights into a company‚Äôs financial health. Below is the tool for getting income statements, a key financial document:\n\n\n```python\nfrom langchain_core.tools import tool\nfrom typing import Dict, Union\nfrom pydantic import BaseModel, Field\n\nclass GetIncomeStatementsInput(BaseModel):\n    ticker: str = Field(..., description=\"The ticker of the stock.\")\n    period: str = Field(default=\"ttm\", description=\"Valid values are 'ttm', 'quarterly', or 'annual'.\")\n    limit: int = Field(default=10, description=\"Maximum number of income statements to return.\")\n\n@tool(\"get_income_statements\", args_schema=GetIncomeStatementsInput, return_direct=True)\ndef get_income_statements(ticker: str, period: str = \"ttm\", limit: int = 10) -> Union[Dict, str]:\n    api_key = os.environ.get(\"FINANCIAL_DATASETS_API_KEY\")\n    url = f'https://api.financialdatasets.ai/financials/income-statements?ticker={ticker}&period={period}&limit={limit}'\n    try:\n        response = requests.get(url, headers={'X-API-Key': api_key})\n        return response.json()\n    except Exception as e:\n        return {\"ticker\": ticker, \"income_statements\": [], \"error\": str(e)}\n```\nHere, `get_income_statements` retrieves the income statements for a given stock ticker. By specifying the period (e.g., ‚Äúttm‚Äù for trailing twelve months), the agent can focus on different reporting cycles.\n\n\n### 2\\. Technical Analyst\n\nThe Technical Analyst collects stock price data over defined timeframes. This data can later be used to calculate indicators or recognize patterns. Below is the code to retrieve stock prices:\n\n\n```python\nclass GetPricesInput(BaseModel):\n    ticker: str\n    start_date: str\n    end_date: str\n    interval: str = \"day\"\n    interval_multiplier: int = 1\n    limit: int = 5000\n\n@tool(\"get_stock_prices\", args_schema=GetPricesInput, return_direct=True)\ndef get_stock_prices(ticker: str, start_date: str, end_date: str, interval: str, interval_multiplier: int = 1, limit: int = 5000) -> Union[Dict, str]:\n    api_key = os.environ.get(\"FINANCIAL_DATASETS_API_KEY\")\n    url = (\n        f\"https://api.financialdatasets.ai/prices?ticker={ticker}\"\n        f\"&start_date={start_date}&end_date={end_date}\"\n        f\"&interval={interval}&interval_multiplier={interval_multiplier}\"\n        f\"&limit={limit}\"\n    )\n    try:\n        response = requests.get(url, headers={'X-API-Key': api_key})\n        return response.json()\n    except Exception as e:\n        return {\"ticker\": ticker, \"prices\": [], \"error\": str(e)}\n```\nThis function allows us to specify parameters like date range and interval, giving control over the granularity of the data (e.g., daily or hourly).\n\n\n### 3\\. Sentiment Analyst\n\nThe Sentiment Analyst pulls in data on insider trading and relevant news. Insider trades and public sentiment indicators can offer insights into market perception, which is important for assessing stock volatility and potential price movements.\n\n\n```python\nclass GetInsiderTradesInput(BaseModel):\n    ticker: str\n    limit: int = 10\n\n@tool(\"get_insider_trades\", args_schema=GetInsiderTradesInput, return_direct=True)\ndef get_insider_trades(ticker: str, limit: int = 10) -> Union[Dict, str]:\n    api_key = os.environ.get(\"FINANCIAL_DATASETS_API_KEY\")\n    url = f'https://api.financialdatasets.ai/insider-transactions?ticker={ticker}&limit={limit}'\n    try:\n        response = requests.get(url, headers={'X-API-Key': api_key})\n        return response.json()\n    except Exception as e:\n        return {\"ticker\": ticker, \"insider_transactions\": [], \"error\": str(e)}\n```\nBy capturing insider trades, this tool can track moves made by those with privileged information, which might be early indicators of performance changes.\n\n\n### Portfolio Manager: Coordinating and Summarizing Analysis\n\nThe Portfolio Manager serves as the coordinator, delegating tasks to the analysts and compiling their results into a single report. Below is a sample workflow for the Portfolio Manager that demonstrates how it calls each agent:\n\n\n```python\nfrom langchain_community.tools.tavily_search import TavilySearchResults\n\n## Tools grouped by agent type\nfundamental_tools = [get_income_statements]\ntechnical_tools = [get_stock_prices]\nsentiment_tools = [get_insider_trades, TavilySearchResults(max_results=5)]\n\n## Sample function for running all analyses in parallel\ndef analyze_portfolio(ticker: str):\n    # Delegate tasks to each agent\n    fundamentals = [tool(ticker=ticker) for tool in fundamental_tools]\n    prices = [tool(ticker=ticker, start_date=\"2023-01-01\", end_date=\"2023-12-31\") for tool in technical_tools]\n    sentiment = [tool(ticker=ticker) for tool in sentiment_tools]\n    \n    # Summarize results (simplified)\n    summary = {\n        \"fundamentals\": fundamentals,\n        \"technical\": prices,\n        \"sentiment\": sentiment\n    }\n    return summary\n```\nIn this function:\n\n* Each agent‚Äôs functions are called in parallel to gather data for the specified ticker.\n* The manager then compiles the data from each agent into a single summary for easy review.\n\n\n### Conclusion\n\nThis project provides a basic yet flexible setup for analyzing stock data through a team of specialized agents. By splitting tasks among a Portfolio Manager, Fundamental Analyst, Technical Analyst, and Sentiment Analyst, we‚Äôre able to gather and organize insights across different financial data types. Using LangChain and LangGraph for modularity and parallel processing makes this approach scalable, while Financial Datasets API supports a broad range of tickers, enabling robust data access.\n\nWhile this system is designed as a project for practice, its structure can serve as a foundation for more complex hedge fund simulations or data analytics tools. Next steps might include enhancing each agent with additional tools or data analysis techniques, such as:\n\n* **Technical Patterns and Indicators:** Integrating more technical analysis tools like moving averages or trend lines.\n* **Sentiment Scoring:** Automating sentiment scoring from news sources or insider trading data.\n* **Predictive Modeling:** Adding ML models that can make buy/sell recommendations based on the combined data.\n\nThis setup is a useful prototype for modular financial data analysis, with plenty of room for future customizations and improvements.\n\nFor those interested in the code behind this toolkit, you can find the complete implementation on GitHub [*here*](https://github.com/shaikhmubin02/ai-hedge-fund).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/multimodal-ai-for-conversational-human-motion-3102e991938c","frontmatter":{"title":"Multimodal AI for Conversational Human Motion","meta_title":"Multimodal AI for Conversational Human Motion","description":"Multimodal AI is revolutionizing conversational agents by integrating input perception, motion planning, and avatar rendering to enhance human-like interactions. This approach reduces information loss between these layers, enabling avatars to process multimodal cues from visual, auditory, and text sources for fluid conversations. Key challenges include aligning modalities, managing latency, and maintaining personality consistency. Current applications span healthcare, customer support, and education, with potential for further development in complex environments, enhancing empathetic communication and information flow.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zANW8t-IxPlkyxX-5_9Ayw.png","categories":["Chatbots","Autonomous Systems","Natural Language Processing"],"author":"Rifx.Online","tags":["multimodal","perception","avatar","latency","empathy"],"draft":false,"slug":"blog/multimodal-ai-for-conversational-human-motion-3102e991938c"},"content":"\n\n\n\nWritten by [Christian Safka](https://www.linkedin.com/in/christiansafka/) and [Keyu Chen](https://www.linkedin.com/in/keyu-chen-3a3026143/?locale=en_US)\n\n\n\nIn this exploration we‚Äôll look at how multimodal models are changing the game for conversational AI agents, and how we can enable seamless interaction in various environments using perception, memory, behavior modeling, and rendering in real\\-time.\n\nThe outline of this one\\-pager:\n\n* Why multimodal?\n* Deep dive into human motion pipeline\n* Challenges in training\n* Current use cases and the future\n\n\n## Why multimodal?\n\nFrom a high level, the three ‚Äúlayers‚Äù we need to achieve life\\-like human conversation are input perception, motion planning, and avatar rendering. Most of the pipelines in academia as of writing this have separated these layers with text as an intermediate:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4a8JvOVbsP8mY3AjiPgNPA.png)\n\nWhat multimodal models unlock is a decrease in information loss between these layers:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VUFhrwLA7sUFmHwidb7DWg.png)\n\n\n## Deep dive into the human motion pipeline\n\nGenerating human\\-like actions and reactions is a difficult problem. It requires a pipeline to process real\\-time cues from multiple sources, interpret, translate, and generate synchronized responses. It‚Äôs critical that all stages All stages are critical for creating avatars that can engage in fluid, contextual conversations.\n\nWe talked about the three layers:\n\n1\\. **Input Perception** ‚Äî Gathering multimodal cues from visual, auditory, and text\\-based sources.\n\n2\\. **Motion Planning** ‚Äî Determining appropriate actions or reactions based on these inputs.\n\n3\\. **Avatar Output** ‚Äî Rendering these planned actions with an avatar in real\\-time.\n\nNow lets break down how each layers crucial role in creating life\\-like conversations.\n\n**Perception of Multimodal Input**\n\nEffective human motion synthesis begins with understanding multimodal cues, much like humans rely on sight, sound, and language for communication. In digital applications, this process can replicate the complex ways in which humans gather and respond to information:\n\n* **Visual Inputs**: Images and video streams capture elements like facial expressions, gaze direction, and hand gestures\n* **Auditory Inputs**: Audio signals provide essential information, such as tone, intonation, and rhythm, enabling us to interpret the emotional context of speech\n* **Text Inputs**: Text\\-based prompts or conversation logs can guide the avatar‚Äôs actions by providing semantic context ‚Äî knowing what‚Äôs being discussed allows the avatar to respond appropriately to the nuances of conversation\n\nIntegrating these modalities creates a holistic understanding of the conversational setting, providing a foundation for how the system interprets and maps the world.\n\n**Motion Planning with LLMs**\n\nIn multimodal AI, the **interaction layer** ‚Äî often powered by large language models (LLMs) ‚Äî acts as the avatar‚Äôs ‚Äúbrain.‚Äù This layer processes the synthesized multimodal cues from the perception stage, determines the most contextually relevant response, and translates it into a planned motion or verbal response.\n\nUsing both speech and visual features as input allows the model to handle:\n\n* **Contextual Motion Planning**: The model can pick up on conversational cues, matching them to actions that are contextually appropriate. For instance, if an avatar detects enthusiasm in a user‚Äôs speech, it might adopt an open, engaging posture or facial expression\n* **Sequential Interaction Control**: The model can learn to interpret sequences of cues, allowing it to handle nuances like turn\\-taking, active listening gestures, and pauses, which are all critical for a natural conversation\n\nPrevious works such as Zhou et al. \\[0] or Pereira et al. \\[1] would output text from this layer ‚Äî emotion labels like ‚Äúhappy‚Äù which can be used for conditional expression generation. This is very lossy and the expressions will never be fully aligned with the output speech.\n\nThe beauty of multimodality in motion planning is both in input and output. On the input side, we can draw on the vast language model‚Äôs world knowledge, even as it is trained to align multimodal tokens. On the output side, we can reduce the information loss between desired behavior and final rendered output.\n\nTo summarize, the interaction layer enables the avatar to respond to both explicit and implicit conversational cues, bridging the gap between multimodal perception and human\\-like interaction.\n\n**Avatar Generation**\n\nTo achieve empathic conversational AI or a human\\-level information flow, the rendered actions and reactions need to go beyond static, pre\\-planned motions. The goal is to create a system that can interpret and adjust to subtle conversational cues almost instantaneously.\n\nIn this context, the **avatar layer** acts as the output rendering mechanism. It takes the actions planned by the interaction layer and translates them into smooth, real\\-time behaviors. This layer focuses on **low\\-latency response generation**, prioritizing rapid and accurate alignment between desired actions and visual/audio output.\n\nThe primary objective can be described as **Synchronized Speech and Motion ‚Äî** the avatar must coordinate facial expressions, body language, and lip movements using the auditory output and behavioral signals, ensuring that all elements stay in sync.\n\n\n\n\n\n\n\nMaintaining temporal consistency and synchronization is vital, as any delays or mismatches in behavior can quickly break immersion.\n\n\n## Challenges in training\n\nSome of the active R\\&D areas in industry and academia are:\n\n* **Token Alignment Across Modalities**: Aligning modalities like visual cues and audio intonations without losing contextual or semantic meaning is complex, and the model must learn how to represent them in a unified way for consistent responses\n* **Latency Management**: Real\\-time responsiveness requires the entire multimodal pipeline to operate with low latency, which becomes challenging as complexity increases\n* **Personality and Memory**: For avatars, consistent personality traits are essential, especially in prolonged interactions. Proper handling of memory and personality can be essential for maintaining coherent responses in some use\\-cases\n\n\n## Current use\\-cases and the future\n\nFirst, a few examples of current use cases we‚Äôre seeing:\n\n* **Healthcare**: Imagine an empathetic avatar as a virtual health coach that provides guidance, responds in real\\-time, and adapts its tone and expressions to suit the user‚Äôs mood\n* **Customer Support**: Customer support avatars can interpret vocal cues, body language, and even view the user‚Äôs technical problem as a screenshare or live video. It could additionally offer responses that feel attentive and personalized, reducing user frustration\n* **Educational Tools**: Tutors with real\\-time interaction capabilities can engage with students, display attentive gestures, and modulate their expressions to reinforce encouragement or correction\n\nAs research advances, these applications will expand, allowing digital humans to be deployed in increasingly nuanced, high\\-stakes environments. Human\\-level conversational avatars will additionally unlock both empathic use\\-cases as well as a high information flow HCI interface.\n\nIf tackling challenges like modality alignment, latency, and contextual coherence sound interesting to you ‚Äî we‚Äôre hiring! Check us out at <https://tavus.io>\n\n**References**\n\n\\[0] Zhou, Hao, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, and Bing Liu. ‚ÄúEmotional chatting machine: Emotional conversation generation with internal and external memory.‚Äù In *Proceedings of the AAAI conference on artificial intelligence*, vol. 32, no. 1\\. 2018\\.\n\n\\[1] Pereira, Patr√≠cia, Helena Moniz, and Joao Paulo Carvalho. ‚ÄúDeep emotion recognition in textual conversations: A survey.‚Äù *Artificial Intelligence Review* 58, no. 1 (2025\\): 1‚Äì37\\.\n\n\n## Don‚Äôt forget to give us your üëè !\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2lvCls4yjxVMfZSR)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/multimodal-rag-with-gemini-pro-and-langchain-e4f74170420a","frontmatter":{"title":"Multimodal RAG with Gemini Pro and LangChain","meta_title":"Multimodal RAG with Gemini Pro and LangChain","description":"Introduction","date":"2024-11-08T00:41:44.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*m2C8wrrRvhELuDiYLv4YYQ.png","categories":["Programming","Machine Learning","Computer Vision"],"author":"Rifx.Online","tags":["Gemini","LangChain","RAG","Vertex","sneaker"],"draft":false,"slug":"blog/multimodal-rag-with-gemini-pro-and-langchain-e4f74170420a"},"content":"\n\n\n## Introduction\n\nIn this tutorial, we will explore the integration of [Gemini](https://deepmind.google/technologies/gemini/#introduction) Pro and Gemini Pro Vision with the [LangChain](https://www.langchain.com/langchain) Framework for achieving Multimodal (in this case, Image) Retrieval\\-Augmented Generation (RAG). This short tutorial is suitable for both beginners and seasoned practitioners, this tutorial not only lays the foundation using Google [AI Studio](https://aistudio.google.com/) as the primary environment but also seamlessly transitions to demonstrating how these implementations can be adapted and further enhanced using [Google Cloud‚Äôs Vertex AI](https://cloud.google.com/vertex-ai).\n\n## Setting the Environment\n\nFirst thing first, let‚Äôs set up our environment to ensure we have all the necessary tools and libraries at our disposal.\n\nFor this we would need Langchain, Langchain Google Gen AI Package, and a Vector Store package for RAG as:\n\n```python\npip install ‚Äî upgrade langchain langchain-google-genai ‚Äúlangchain[docarray]‚Äù faiss-cpu\n```\n\nThen you will also need to provide Google AI Studio API key for the models to interact with:\n\n```python\nif \"GOOGLE_API_KEY\" not in os.environ:\n  os.environ[‚ÄúGOOGLE_API_KEY‚Äù] = getpass.getpass(‚ÄúProvide your Google API Key‚Äù)\n```\n\nFor ease of use I have also written a simple function that shows the image I am working with. This simply downloads the image from the URL provided and shows the preview:\n\n```python\ndef get_image(url, filename):\n  content = requests.get(url).content\n  with open(f'/content/{filename}.png', 'wb') as f:\n  f.write(content)\n  image = Image.open(f\"/content/{filename}.png\")\n  image.show()\n  return image\n```\n\n## A Simple LLM Interaction\n\nLet‚Äôs start with a very simple LLM interaction. For it we can simply call the Gemini Pro model from ChatGoogleGenerativeAI and invoke, as:\n\n```python\nllm = ChatGoogleGenerativeAI(model=‚Äùgemini-pro‚Äù)\nresult = llm.invoke(\"Write a ballad about Gemini Pro in around 3 sentences.\")\nprint(result.content)\n```\n\nAs a result you would get something like this:\n\n> In the realm of stars, Gemini Pro shines, A celestial beacon, defining the lines, Guiding stargazers through cosmic designs.\n\nSimilarly, you can also use it in a Chat Interface approach with System, Human message/conversation format. As:\n\n```python\nmodel = ChatGoogleGenerativeAI(model=‚Äùgemini-pro‚Äù, convert_system_message_to_human=True)\nprint(model([\n  SystemMessage(content=\"Answer only yes or no.\"),\n  HumanMessage(content=\"Is apple a fruit?\"),\n  ]).content)\n```\n\n## Multimodal LLM\n\nFor this tutorial I am using a very simple usecase, where I am imagining I am a Sneaker enthusiasts and basically like to find if given image of a sneaker, where I can buy that exact model in a local store nearby. For it, I have prepared a dummy Knowledge Base with some Fake information on local stores and made of specs of certain popular Sneaker Brands. Interestingly, this Knowledge base was also generated Using Gemini Pro using [Google Gemini](https://gemini.google.com/) chat interface.\n\nLet‚Äôs start with a sample image:\n\n```python\nimage = get_image(<image_url>, ‚Äúnike3‚Äù)\nplt.imshow(image)\nplt.show()\n```\n\nAs a sample, I am considering this image of a [Nike](https://nike.com/) Sneaker.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dNFF95lOu1SeYHOn1vFnQQ.png)\n\nNow, let‚Äôs call Gemini Pro Vision model and ask it to tell us bit about this particular image. For this, you simply need to change the model name to *‚Äúgemini\\-pro\\-vision‚Äù*.\n\n```python\nllm = ChatGoogleGenerativeAI(model=‚Äùgemini-pro-vision‚Äù)\nmessage = HumanMessage(\ncontent=[\n  {\n    \"type\": \"text\",\n    \"text\": \"What's in this image? provide full detail as possible.\",\n  }, # You can optionally provide text parts\n  {\"type\": \"image_url\", \"image_url\": image},\n])\nprint(\nllm.invoke([message]).content\n)\n```\n\nAnd you will get output like this:\n\n> This is a product image of a pair of Nike Air Max 95 sneakers in a tan, wheat colorway. The upper is made of mesh and suede, with a leather mudguard. The midsole is made of foam, with a visible air unit in the heel. The outsole is made of rubber, with a waffle pattern for traction.\n\n*Disclaimer: The description provided may not be accurate and reflects the model‚Äôs interpretation of the image rather than factual information pertaining to it.*\n\n## RAG using Multimodal\n\nNow, let‚Äôs dive into how we can perform RAG using this multimodal approach. First thing first, lets create an information source for this RAG. For this I have written few paragraph information information on few Nike sneakers and some made up locations of local stores based in Nepal.\n\n```python\nstore_information = ‚ÄúNike Air Max Plus sneakers. They feature a brown upper with a black Nike Swoosh logo on the side and a visible Air Max unit in the heel. The sole is white.\nHere are some more details about the Nike Air Max Plus:\nStyle: TN\nRelease date: January 1, 2017\nStyle code: 852630‚Äì300\nOriginal retail price: $150 USD\nThe Air Max Plus, also known as the TN, is a popular Nike running shoe that was first released in 1998. It is known for its unique design, which includes a gradient upper, visible Air Max units, and a wavy outsole. The TN has been a popular shoe among sneakerheads and casual wearers alike for over two decades.\nIt features a brown upper with a black Swoosh logo and a white sole. The shoe is currently available for resale on the StockX marketplace for an average price of around $150 USD.\nNike Air Max Plus Store Location: \"Kings Way, Kathmandu, Nepal\n\n...\n\n\"\n```\n\nThen, let‚Äôs create a Langchain chain, that basically fetches information provided image description regarding what Nike model it is and where one can buy it based on above information from our Knowledge base.\n\n```python\nllm_text = ChatGoogleGenerativeAI(model=‚Äùgemini-pro‚Äù)\ntemplate = \"\"\"\n```\n\n{context}\n\n```\n{information}\nProvide brief information and store location.\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nrag_chain = (\n  {\"context\": retriever, \"information\": RunnablePassthrough()}\n  | prompt\n  | llm_text\n  | StrOutputParser()\n)\n```\n\nHere, the thing to note is *Gemini\\-Pro* and *Gemini\\-Pro\\-Vision* are 2 different models and you will need to call them differently. In above code, we are called the Gemini Pro text model that perform RAG provided the image description that was generated by *gemini\\-pro\\-vision* model.\n\nNow, lets set up a full chain that first generates image description provided the image as an input and then does RAG using above chain.\n\n```python\nllm_vision = ChatGoogleGenerativeAI(model=‚Äùgemini-pro-vision‚Äù, temperature=0.0)\nfull_chain = (\n  RunnablePassthrough() | llm_vision | StrOutputParser() | rag_chain\n)\n```\n\n## Performing the RAG\n\nNow, lets do some testing on what we just set up. First, lets get another image as sample\n\n```python\nimage = get_image(url_3, ‚Äúnike3‚Äù)\nplt.imshow(image)\nplt.show()\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kPkfo2FKnrUR2tC18VMpjg.png)\n\nThen, lets call our RAG:\n\n```python\nmessage = HumanMessage(\n  content=[\n    {\n      \"type\": \"text\",\n      \"text\": \"Provide information on Brand and model of given sneaker.\",\n    }, # You can optionally provide text parts\n    {\"type\": \"image_url\", \"image_url\": image},\n  ])\n```\n\nNow let‚Äôs see what we get:\n\n```python\nresult = full_chain.invoke([message])\ndisplay(Markdown(result))\n```\n\nAs an output, we will get something like this, which is based on our made up information source:\n\n> **Nike Offcourt Slide**Soft, one\\-piece upperPlush foam midsoleDurable rubber outsoleAvailable in a variety of colors\n\n> **Store Location:** Bhaktapur, Nepal\n\n## Using Vertex AI Models\n\nInstead of using Google AI Studio model, you can also use Google cloud‚Äôs Vertex AI gemini pro models. For it, you will need basically need to first, install related packages for Vertex AI for your cloud environment and Langchain as:\n\n```python\npip install ‚Äî upgrade google-cloud-aiplatform langchain-google-vertexai\n```\n\nThen, set up necessary config related to your cloud project using:\n\n```python\ngcloud init\n```\n\nThen, you can use Vertex AI models for your multimodal use cases as:\n\n```python\nfrom langchain_google_vertexai import VertexAI\nfrom langchain_google_vertexai import VertexAIEmbeddings\n\nmodel_vision = VertexAI(model_name=\"gemini-1.0-pro-vision-001\")\nmodel_text = VertexAI(model_name=\"gemini-1.0-pro-001\")\n```\n\n## Conclusion\n\nIn this short tutorial, we explored how Gemini Pro and Gemini Pro vision could be used with LangChain to implement multimodal RAG applications.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/o1-preview-vs-claude-3-5-sonnet-comparing-top-llms-d68734b53c93","frontmatter":{"title":"o1-preview vs. claude-3.5-sonnet: Comparing top LLMs","meta_title":"o1-preview vs. claude-3.5-sonnet: Comparing top LLMs","description":"Discover how OpenAI‚Äôs o1-preview compares to Claude 3.5 Sonnet in performance, speed, and capabilities.","date":"2024-10-27T13:58:01.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kTWAcpRdOpsrFIDZjjjr7Q.jpeg","categories":["Programming","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["o1-preview","Claude","throughput","latency","reasoning"],"draft":false,"slug":"blog/o1-preview-vs-claude-3-5-sonnet-comparing-top-llms-d68734b53c93"},"content":"\n\n\n\nToday (Sep 12, 2024), OpenAI unveiled its latest language model, o1-preview. This advanced model is engineered to dedicate more time to processing before generating responses, enabling it to tackle complex tasks and solve challenging problems in science, coding, and mathematics with enhanced capabilities.\n\nIn this blog post, we‚Äôll thoroughly analyze o1-preview and compare it to Claude 3.5 Sonnet, which was previously considered one of the most advanced models available.\n\n\n\n\n## Comparison Methodology\n\nOur analysis utilizes [Keywords AI‚Äôs LLM playground](https://docs.keywordsai.co/features/prompt/model-playground), a platform that supports over 200 language models and offers function-calling capabilities. We‚Äôll explore the following aspects:\n\n* Basic comparison\n* Benchmark comparison\n* Processing speed\n* Evaluation metrics\n* Suggested use cases\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yc171ikejtBy_o11.jpeg)\n\n\n## Basic Comparison\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*z2FrS_AVig7Y6eU_.jpeg)\n\nNote: o1-preview doesn‚Äôt support Streaming, function calling, and system messages.\n\n\n## Benchmark Comparison\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Bx_vAvFc9DAD0cZA.jpeg)\n\nO1-preview outperforms Claude 3.5 Sonnet across all benchmarks. The smallest gap is in MMLU (general knowledge). GPQA Diamond, testing graduate-level reasoning, shows a significant performance difference. The MATH benchmark reveals the largest gap, highlighting o1-preview‚Äôs advanced mathematical capabilities. These results indicate o1-preview‚Äôs substantial improvements in complex reasoning and problem-solving across various domains.\n\n\n## Speed Comparison\n\nO1-preview takes longer to think and respond than other LLMs. While direct speed comparisons may not be entirely fair, testing o1-preview‚Äôs speed is crucial. This information helps developers better understand o1-preview‚Äôs capabilities and determine if it‚Äôs suitable for their projects. Note: As o1-preview doesn‚Äôt support streaming, we disabled streaming for both models. Consequently, time to first token (TTFT) couldn‚Äôt be measured.\n\n\n## Latency\n\nOur tests, involving hundreds of requests per model, revealed significant differences. Claude 3.5 Sonnet averages 18.3s/request, whereas o1-preview takes 39.4s/request. O1-preview‚Äôs significantly longer latency is due to its extended thinking and reasoning process.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2PMkgPVuylFxwfIa.jpeg)\n\n\n## Throughput (Tokens per second)\n\nDespite higher latency, o1-preview shows superior throughput. O1-preview generates 92.94 tokens/second, while Claude 3.5 Sonnet produces 74.87 tokens/second. This indicates that o1-preview‚Äôs longer generation time is primarily due to its initial processing phase rather than token generation speed.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wxqpnwZhl9pnbw8y.jpeg)\n\n\n## Performance comparison\n\nWe conducted evaluation tests on the [Keywords AI platform](https://keywordsai.co/). The evaluation comprised three parts:\n\n* **Coding Task**: Both models successfully completed frontend and backend development tasks. O1-preview demonstrated superior performance with longer contexts, identifying and resolving bugs more efficiently in the first attempt. It also exhibited a more thorough code analysis capability.\n* **Logical Reasoning**: O1-preview excels in reasoning tasks. Its thinking process closely mimics human cognition. While Claude 3.5 Sonnet performs well on most problems, o1-preview consistently solves complex reasoning challenges, including International Mathematical Olympiad (IMO) level problems.\n* **Writing Task:** Both models perform exceptionally well on writing tasks. They demonstrate the ability to craft genuine, personalized cold emails, as well as concise and meaningful blog posts.\n\n\n## Model Recommendations\n\no1-preview\n\n* **Best for:** Complex problem-solving in mathematics, coding, and physics. Particularly suited for researchers tackling challenging tasks.\n* **Not suitable for:** AI applications requiring rapid response times or heavily reliant on system prompts. Voice AI applications due to lack of streaming support.\n\nClaude 3.5 Sonnet\n\n* **Best for:** Most AI applications requiring problem-solving capabilities and high-quality content generation.\n* **Not suitable for:** Voice AI applications or projects with strict budget constraints requiring lower operational costs.\n\n\n## How to integrate o1-preview into your AI apps.\n\nTo incorporate o1-preview into your AI applications, simply visit the Keywords AI model page and locate the ‚ÄúView code‚Äù button. Click this button to copy the provided code snippet, then paste it directly into your codebase. With this straightforward process, you‚Äôll be ready to harness the power of o1-preview in your projects, enabling you to tackle complex problems and generate high-quality content with ease.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XyQ9QiI7TN8Uc5Jp.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t8fEYlEs13eM7D28lVbtIw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yhu9y5ixNuxeFVe1.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories.\n\nSubscribe to our [newsletter](https://www.generativeaipub.com/) and [YouTube](https://www.youtube.com/@generativeaipub) channel to stay updated with the latest news and updates on generative AI. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*PelNtaNaEVDWgMWr.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-01-preview-secrets-99-of-people-dont-know-b0c5e4bb4f76","frontmatter":{"title":"OpenAI 01-Preview‚Ää‚Äî‚ÄäSECRETS 99% of People Don‚Äôt Know","meta_title":"OpenAI 01-Preview‚Ää‚Äî‚ÄäSECRETS 99% of People Don‚Äôt Know","description":"How to get the most out of 01-preview","date":"2024-11-01T03:58:01.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wRAXNmhEzkGNagMl5Papxg.jpeg","categories":["Programming","Machine Learning","Technology/Web"],"author":"Rifx.Online","tags":["OpenAI","01-preview","iterative","problem-solving","planning"],"draft":false,"slug":"blog/openai-01-preview-secrets-99-of-people-dont-know-b0c5e4bb4f76"},"content":"\n### How to get the most out of 01\\-preview\n\nI‚Äôve been playing around with 01\\-preview since it came out.\n\nI‚Äôm loving it!\n\nI‚Äôm even teaching it in my new [**AI Growth Hacking course**](https://aigrowthguys.com/growth-hacking-course-sign-up/).\n\nI‚Äôm excited to share some key insights about how to get the most out of this.\n\n\n\nMost people have no clue how 01\\-preview works.\n\nFirst of all, it is not just a ‚Äúthinking‚Äù model.\n\nYou need to understand a little bit about how it works before you can take full advantage of it.\n\nIf you don‚Äôt have a paid Medium account you can read for free [**here**](https://readmedium.com/openai-01-preview-secrets-99-of-people-dont-know-b0c5e4bb4f76?sk=12140ffad09d922bc00a8a4aa312a286).\n\nüëâ Sign up to our free 5\\-Day email course to grow üöÄ and earnüí≤in the AI age\n\n## How does OpenAI 01\\-preview work?\n\n01\\-preview is not really a new model.\n\nIt combines other models and a ‚Äúsystem prompt‚Äù that tells it to iterate several times before a response comes out.\n\nAll other models work by providing the first response the model comes up with.\n\n01\\-preview is designed to plan and experiment before a final answer comes out.\n\nAn example will help.\n\n> Imagine you tell GPT\\-4o to write a coherent paragraph that is exactly 80 words long, and has the word ‚Äútomato‚Äù as the 4th word, the 19th word, and the 72nd word.\n\nGPT\\-4o (and all other models) will fail at this task because it is too difficult to just spit out the first answer that comes to mind.\n\nThis type of question needs experimentation.\n\nThink if you were given the same task.\n\nYou need to ‚Äúplay around‚Äù with this task to try to fit the word ‚Äútomato‚Äù in those spots in a way that makes sense.\n\nYou can‚Äôt just start writing and see what happens.\n\nYou will realize that you need to change some sentences around, and words around, in order to fit the word ‚Äútomato‚Äù in there.\n\nAlso, when you get near 80 words, you need to plan how to stop at exactly that number. You might wish to go back and delete an unnecessary word from the first sentence for example.\n\nThe reason 01\\-preview can do this type of thing is the way it ‚Äúthinks‚Äù.\n\nIt will first break the problem down and say something like, ‚ÄúCome up with a plan to solve this problem‚Äù.\n\nThen it will write an approximate first guess (probably using GPT\\-4o)\n\nThen it will say to itself, ‚ÄúRe\\-read the question and see if you can make any tweaks or adjustments‚Äù.\n\nThen it will say, ‚Äúdo a double\\-check to see if your response is perfect. If it is, display it, if it is not, keep tweaking.‚Äù\n\nThen it will say, ‚ÄúRepeat this process until your answer is 100% perfect. Always remember to double\\-check your final answer before displaying it‚Äù.\n\nFor example, the first sentence of the first response might be this.\n\n‚ÄúSandy picked a red tomato from her garden.‚Äù\n\nThen 01\\-preview would change it to, ‚ÄúSandy picked a tomato from her garden‚Äù.\n\nThis way, it would successfully move the word tomato from the 5th word to the 4th word.\n\nIt would keep making tweaks by having an internal conversation with itself.\n\n## How to get the most out of 01\\-preview?\n\nNow that you have an idea about how 01\\-preview ‚Äúthinks‚Äù, you can start to understand how to get the most out of it.\n\nYou need to divide your own questions into ones that require ‚Äúthinking‚Äù and ones that don‚Äôt.\n\nMany questions don‚Äôt require ‚Äúthinking‚Äù from the models.\n\nFor example, if you tell it to write you a funny story about a girl named Sandy who has a tomato garden, then you don‚Äôt need to use 01\\-preview.\n\n**Why not?**\n\nBecause there are few constraints.\n\nThere are many ways to do this. It is essentially open\\-ended.\n\nThe story doesn‚Äôt need to have a certain length.\n\nThe model can just start writing, throw in a joke or 2, and be done with it.\n\nIt won‚Äôt need to go back to the first sentence and count the number of words or anything.\n\nThe point is this:\n\nIf you are asking the model for something specific that would be difficult to do in one try without experimenting, then you should use 01\\-preview.\n\nIf you are asking for something open\\-ended, then use the other models.\n\nYou need to use 01\\-preview sparingly because you are only given a limited number of queries.\n\nIt will always be more limited than other models because it uses far more resources than other models.\n\nThe good news is that 01\\-preview will make far fewer mistakes than other models.\n\nAlso, it will be able to answer questions that previous models failed at.\n\nNow is a better time than ever to learn how to leverage AI to grow your business and earn more money.\n\nI am teaching how to use this in my AI Growth Hacking course.\n\nI‚Äôll also be incorporating this model to make the custom AI Agents and chatbots I build even more accurate.\n\nThis will make AI agent builders like [**Stammer**](https://stammer.ai/?via=andrew) even more powerful.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-confirms-the-arrival-of-gpt-5-poised-to-bring-huge-improvements-to-artificial-intelligence-e3b858e79c2a","frontmatter":{"title":"OpenAI Confirms the Arrival of GPT-5, Poised to Bring Huge Improvements to Artificial Intelligence‚Ä¶","meta_title":"OpenAI Confirms the Arrival of GPT-5, Poised to Bring Huge Improvements to Artificial Intelligence‚Ä¶","description":"A netizen posted a GPT5 countdown post on x, saying that it was a conclusion drawn from clues from various platforms. The comment section‚Ä¶","date":"2024-11-01T03:58:58.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8J_opnaERs-wrq2YRKIxdQ.png","categories":["Natural Language Processing","Generative AI","Technology"],"author":"Rifx.Online","tags":["GPT-5","natural","language","efficiency","personalization"],"draft":false,"slug":"blog/openai-confirms-the-arrival-of-gpt-5-poised-to-bring-huge-improvements-to-artificial-intelligence-e3b858e79c2a"},"content":"\n\n\n\nA netizen posted a GPT5 countdown post on x, saying that it was a conclusion drawn from clues from various platforms. The comment section has reached a climax with all kinds of opinions coming out.\n\n\n\n**Cause 1** : OpenAI website GPT5 leak\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EBDLAv3rOyCjshGBpVRI7A.png)\n\n**Cause 2** : The article ‚ÄúOpenAI Launches Better GPT5 Chatbot‚Äù published by BusinessInsider, a well\\-known American financial business insider website. Since the website is a paid website, you can search for the title if you are interested. Some content is pasted below:\n\nThe generative AI company, led by Sam Altman, is on track to launch GPT\\-5 sometime in the middle of the year, possibly in the summer, according to two people familiar with the company. Some enterprise customers recently received demos of the latest model and its related enhancements to its ChatGPT tool, according to another person familiar with the process. Business Insider has confirmed the identities of these people, who asked to remain anonymous so they could speak freely.\n\nBased on the discussions on X and other platforms, it is very likely that a new version of the model will be launched on June 6, but it is not certain whether it will be GPT 4\\.5 or GPT5\\.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rhApTugfrMVBB6PhMvK4rg.png)\n\nAll of us waiting for **GPT5**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eB6j2S_dPbjQ2-sV2N1fwA.jpeg)\n\n\n## What to Expect from GPT\\-5\n\nWhile details remain scarce, the excitement surrounding GPT\\-5 is driven by expectations of significant improvements in AI capabilities. Here are some potential advancements that have been speculated:\n\n* Enhanced Natural Language Understanding: GPT\\-5 is expected to have an even deeper understanding of context, nuances, and subtleties in human language, making interactions more fluid and natural.\n* Increased Efficiency: With each iteration, OpenAI has made strides in reducing latency and improving the efficiency of its models. GPT\\-5 is anticipated to continue this trend, providing faster and more accurate responses.\n* Broader Knowledge Base: By incorporating more diverse and extensive datasets, GPT\\-5 could offer more comprehensive and reliable information across a wider range of topics.\n* Advanced Personalization: The new model might include enhanced personalization features, allowing it to better adapt to individual user preferences and needs.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7xCG5iy53LLQCTnmzxs_3g.jpeg)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-gpt-5-ph-d-level-intelligence-expected-by-2025-50a86c3aad86","frontmatter":{"title":"OpenAI GPT-5: Ph.D.-Level Intelligence Expected by 2025","meta_title":"OpenAI GPT-5: Ph.D.-Level Intelligence Expected by 2025","description":"After months of speculation, OpenAI has finally unveiled details about the highly anticipated GPT-5. Initially expected in 2024, its‚Ä¶","date":"2024-11-01T03:59:56.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OasnWeS5mgAX_0hIpirO5Q.jpeg","categories":["Machine Learning","Ethics","Data Science"],"author":"Rifx.Online","tags":["GPT-5","Ph.D.","intelligence","ethics","privacy"],"draft":false,"slug":"blog/openai-gpt-5-ph-d-level-intelligence-expected-by-2025-50a86c3aad86"},"content":"\n\n\n\n\n\nAfter months of speculation, OpenAI has finally unveiled details about the highly anticipated GPT\\-5\\. Initially expected in 2024, its release has been postponed to late 2025 or early 2026\\. Mira Murati, OpenAI‚Äôs CTO, shared insights in an interview with Dartmouth Engineering about the capabilities and potential of this new version. Here‚Äôs everything you need to know.\n\n\n## A Quantum Leap in Intelligence\n\nMurati compares previous versions of GPT to different levels of human intelligence. GPT\\-3 is akin to a young child, while [**GPT\\-4**](https://www.geekmetaverse.com/gpt-4-unveils-its-secrets-a-combination-of-8-smaller-models/) is comparable to a high school student. The new GPT\\-5 promises to reach a ‚ÄúPh.D.\\-level intelligence for specific tasks.‚Äù This advancement is not only exciting but also raises questions about the future of artificial intelligence.\n\n\n## Evolution of GPT: From Child to Ph.D.\n\nComparing these versions to stages of human education helps us grasp these advancements better. GPT\\-3, with its ability to generate coherent and useful text, opened many doors. GPT\\-4 improved these skills, demonstrating superior performance in more complex tasks. Now, GPT\\-5 aims to take this to an entirely new level, with advanced reasoning and memory capabilities.\n\n\n## Specialized Intelligence\n\nPh.D.\\-level intelligence doesn‚Äôt mean [**GPT\\-5**](https://www.geekmetaverse.com/openai-ceo-confirms-that-gpt-5-is-already-in-development/) can do everything perfectly. Murati clarified that these abilities will be task\\-specific. This suggests that while AI might surpass humans in certain fields, it will still have limitations in others. This specialized focus could lead to highly precise and useful applications in areas like scientific research and complex data analysis.\n\n\n## Potential and Future Applications\n\nThe development of GPT\\-5 opens a range of possibilities across different sectors. From education to medicine, and research to technology, the applications are vast.\n\n\n### Education and Training\n\nAn [**AI**](https://www.geekmetaverse.com/apple-updates-ai-takes-center-stage-with-siri-integration-chatgpt-partnership-and-elon-musk-concerns/) capable of reaching Ph.D. levels could radically transform education. Personalized tutoring systems could provide support to students in complex areas, enhancing understanding and academic performance.\n\n\n### Medicine and Healthcare\n\nIn medicine, an AI with such capabilities could assist in diagnosing rare diseases, developing personalized treatments, and managing large volumes of clinical data, significantly advancing medical care.\n\n\n### Research and Development\n\nResearchers could greatly benefit from an AI that can analyze large datasets, identify patterns, and generate hypotheses, accelerating the pace of scientific and technological discoveries.\n\n\n## Challenges and Ethical Considerations\n\nDespite the promising applications, the development of such advanced AI also brings significant ethical challenges. Over\\-reliance on AI for critical tasks could lead to issues if not managed properly.\n\n\n### Privacy and Security\n\nData privacy and cybersecurity will be crucial topics. Ensuring AI systems are not misused and that sensitive data is adequately protected will be a priority.\n\n\n### Employment Impact\n\nThe impact on employment is also a concern. Automating specialized tasks could displace certain professionals, necessitating proactive measures to address these socioeconomic implications.\n\n\n### Conclusion\n\nThe delay in GPT\\-5‚Äôs release may be disappointing for some, but its advanced capabilities generate significant anticipation. If OpenAI meets its goals, we could be looking at a revolutionary tool that transforms multiple industries and changes how we interact with technology.\n\n\n### FAQs\n\n**1\\. What is GPT\\-5?**\n\nGPT\\-5 is the upcoming version of OpenAI‚Äôs Generative Pre\\-trained Transformer (GPT) series, promising Ph.D.\\-level intelligence for specific tasks.\n\n**2\\. When is GPT\\-5 expected to be released?**\n\nThe release of GPT\\-5 has been postponed to late 2025 or early 2026\\.\n\n**3\\. How does GPT\\-5 compare to previous versions?**\n\nGPT\\-3 is akin to a young child in intelligence, while GPT\\-4 compares to a high school student. GPT\\-5 aims to achieve Ph.D.\\-level intelligence for specific tasks, offering advanced reasoning and memory capabilities.\n\n**4\\. What kind of tasks will GPT\\-5 be able to perform?**\n\nGPT\\-5 will be specialized in certain tasks, excelling in specific fields like scientific research, complex data analysis, education, and healthcare.\n\n**5\\. Will GPT\\-5 be perfect at everything?**\n\nNo, GPT\\-5‚Äôs Ph.D.\\-level intelligence will be task\\-specific, meaning it will excel in certain areas but still have limitations in others.\n\n**6\\. What are the potential applications of GPT\\-5?**\n\nPotential applications include personalized tutoring in education, assistance in diagnosing diseases and developing treatments in healthcare, and aiding researchers in analyzing large datasets and generating hypotheses.\n\n**7\\. What are the ethical considerations associated with GPT\\-5?**\n\nEthical considerations include ensuring data privacy and cybersecurity, managing the socio\\-economic impact of job displacement due to automation, and preventing misuse of advanced AI systems.\n\n**8\\. How will GPT\\-5 impact data privacy and security?**\n\nEnsuring the protection of sensitive data and preventing the misuse of AI systems will be crucial. Measures will need to be implemented to safeguard data privacy and security.\n\n**9\\. What is the potential impact of GPT\\-5 on employment?**\n\nThe automation of specialized tasks by GPT\\-5 could displace certain professionals, necessitating proactive measures to mitigate these socio\\-economic impacts.\n\n**10\\. Why was the release of GPT\\-5 delayed?**\n\nThe delay allows OpenAI to refine and enhance GPT\\-5‚Äôs capabilities to ensure it meets the high expectations for its advanced intelligence and specialized applications.\n\n**11\\. How can GPT\\-5 transform education?**\n\nGPT\\-5 could revolutionize education by providing personalized tutoring systems that support students in complex subjects, improving comprehension and academic performance.\n\n**12\\. What advancements could GPT\\-5 bring to the medical field?**\n\nIn medicine, GPT\\-5 could aid in diagnosing rare diseases, developing personalized treatments, and managing vast amounts of clinical data, leading to significant advancements in medical care.\n\nOriginal post: [https://www.geekmetaverse.com/openai\\-gpt\\-5\\-ph\\-d\\-level\\-intelligence\\-2025/](https://www.geekmetaverse.com/openai-gpt-5-ph-d-level-intelligence-2025/)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-just-built-her-in-real-life-17769d993e11","frontmatter":{"title":"Users Will Fall in Love With OpenAI‚Äôs New GPT-4o Model. Literally.","meta_title":"Users Will Fall in Love With OpenAI‚Äôs New GPT-4o Model. Literally.","description":"The company‚Äôs new GPT-4o can understand and mimic human speech and emotion","date":"2024-11-01T04:08:40.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-bTsggApvkUHAq57YhSd-A.png","categories":["Generative AI","Chatbots","Natural Language Processing"],"author":"Rifx.Online","tags":["GPT-4o","speech","emotions","multilingual","conversational"],"draft":false,"slug":"blog/openai-just-built-her-in-real-life-17769d993e11"},"content":"\n\n\n\n\n## The company‚Äôs new GPT\\-4o can understand and mimic human speech and emotion\n\n\n\nIn the iconic 2013 film *Her*, the protagonist develops an intense relationship ‚Äî which morphs into a love affair ‚Äî with a voice\\-enabled AI system.\n\nThe AI in *Her* is everything that today‚Äôs voice\\-enabled systems are not: emotive, funny, and able to intuit the subtleties of human conversation.\n\nIn a major [announcement this morning](https://www.youtube.com/live/DQacCB9tDaw?app=desktop&si=jvKW7jFDwFvOMBBk), OpenAI announced the release of a new version of its ChatGPT system that natively integrates speech, transcription, and intelligence into a single model.\n\nIt‚Äôs powerful, intuitive, and disturbingly human\\-like. Essentially, OpenAI has built a real\\-life version of *Her*.\n\n\n## A Bad Conversationalist\n\nChatGPT has had voice capabilities for months now. Even today, you can open the ChatGPT app on your phone, press the headphones icon, and converse with the system using your voice.\n\nThe problem, though, was that ChatGPT was a terrible conversationalist.\n\nEssentially, ChatGPT‚Äôs voice capabilities were a hack created by splicing together three different models.\n\nWhen you would speak to the system, it would first use a transcription model to turn your voice into text. It would then feed that text into its intelligence model ‚Äî basically, the same system that underpins GPT\\-4\\.\n\nThe intelligence system would generate text, which ChatGPT would feed back into a text\\-to\\-speech system to create a computerized voice that would respond to you.\n\nThis made the system nominally conversational, but actually speaking with it was clunky and awkward.\n\nAll the extra steps of sending content between different models meant that the system was laggy. In my own testing, I found it often took 3 to 5 seconds between speaking to the system and getting a response back.\n\nHuman conversation relies on subtleties that [unfold over milliseconds](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8794835/#:~:text=The%20modal%20conversational%20response%20time,deliberative%20conscious%20control%20(22).). A system that takes up to five seconds to respond to speech feels clunky and robotic.\n\nThe previous system also lacked many fundamental aspects of human speech.\n\nFor example, you couldn‚Äôt interrupt it; you had to wait for it to finish speaking before you could respond.\n\nSpeaking with it often felt like talking to one of those un\\-interruptable people who blabbers on about a random topic with no awareness of the other people in the room. You often felt like bring up the Oscars‚Äô orchestra in a desperate attempt to get the system to stop talking.\n\nIt was also constrained by its inability to interpret emotion in voices or to accurately mimic human emotion in its own responses.\n\nHumans are excellent at reading between the lines, partially because we can [pick up on subtle emotive cues in the speaker‚Äôs voice.](https://pressbooks.lib.jmu.edu/communicationintherealworldjmu/chapter/non-verbal-communication/)\n\nIf I ask my friend, ‚ÄúHow was your day?‚Äù and they respond, ‚ÄúIt was fine,‚Äù but they insert a subtle pause between ‚Äúwas‚Äù and ‚Äúfine‚Äù (or there‚Äôs a hint of exasperation in the final word), I‚Äôd know that they actually had a challenging day, and I should ask some follow\\-up questions.\n\nChatGPT couldn‚Äôt do these things, which made speaking to it feel like communicating with some kind of alien intelligence, not a human.\n\nIn short, the previous system fell squarely into the uncanny valley. It was good enough at conversing and had a convincing enough voice that parts of the conversation could feel human\\-like.\n\nBut the weird pauses, lack of emotive understanding, and lag ultimately shattered the illusion, making it come off as more unsettling than useful.\n\nI tried using the previous system with my six\\-year\\-old son. He was so creeped out by it that he wouldn‚Äôt let me switch the audio back on again.\n\n\n## OpenAI‚Äôs Revoluntary New Model\n\nToday, OpenAI is changing all of that. In their [announcement this morning](https://www.youtube.com/live/DQacCB9tDaw?app=desktop&si=jvKW7jFDwFvOMBBk), the company revealed that they are releasing a new model, GPT\\-4o.\n\nGPT\\-4o natively integrates speech recognition, speech generation, and intelligence into a single system.\n\nThat means that the spaghetti code system integrating three different models to simulate conversation is gone. Instead, the new version of ChatGPT will be able to **take in speech, process it instantly, and respond with realistically generated speech of its own.**\n\nFor users, this will enable several new capabilities that OpenAI CEO Sam Altman [described as ‚Äúlike magic.‚Äù](https://twitter.com/sama/status/1788989777452408943)\n\nFor one, you‚Äôll be able to converse with ChatGPT much more naturally. Instead of having to type your questions and follow\\-ups into an interface, you‚Äôll be able to speak with the app as if you‚Äôre talking to a friend.\n\nIn several live demos, OpenAI‚Äôs engineers showed how the system can listen to a user and respond with an intelligent result within milliseconds.\n\nAgain, those speeds are possible because the new model doesn‚Äôt need to waste time switching modalities ‚Äî it can process voice and respond with its own voice in a single step, instead of resorting to multiple lower\\-level models.\n\nGPT\\-4o can also interpret and create emotion.\n\nIn one demo, an OpenAI staff member asked the system to lead him through a breathing exercise.\n\nHe then pretended to hyperventilate, and ChatGPT ‚Äî sensing the speed with which he was breathing and the apparent panic in his voice ‚Äî urged him to slow down and take deeper breaths.\n\nThe system also appears capable of modulating the emotion in its own responses. In another demo, the staff member asked GPT\\-4o to read a bedtime story in an increasingly dramatic voice.\n\nIt obliged, ultimately sounding like a middle school theater kid horrifically overacting a scene!\n\nBecause the new system is also integrated with GPT\\-4‚Äôs vision capabilities, it can perform functions like interpreting the emotions on a person‚Äôs face.\n\nThis increased level of emotional intelligence will likely make the system a much better conversationalist.\n\nOther new capabilities will help, too. Users can interrupt GPT\\-4o mid\\-sentence.\n\nDuring their demos, OpenAI staff members frequently interrupted the model when it started to go on tangents, as one might interrupt a friend to start responding to a real\\-life question.\n\n\n## Huge Potential\n\nThe demos this morning were lighthearted and funny. But one can quickly see how a model that can easily interpret, quickly process, and realistically create emotive human speech could be incredibly powerful.\n\nSeveral times during the demo, ChatGPT responded in ways that reminded me of the fictional AI from *Her*.\n\nChatGPT appeared to laugh at itself, become embarrassed when OpenAI staff members complimented it, and perhaps even throw in a flirty line here and there.\n\nSeveral (purportedly) unscripted interactions also revealed some of the deeper capabilities that better conversation could unlock.\n\nBased on an audience question, OpenAI‚Äôs staff members demonstrated how the system could listen to speech in Italian and quickly and accurately translate it into English speech, and vice versa.\n\n\n\n\n\n\n\nOne can easily imagine how such a capability could make multi\\-lingual interactions incredibly simple, essentially eliminating language barriers (and perhaps, human translators).\n\nA doctor, for example, could pull up ChatGPT and use it to quickly speak with a patient in any language. While traveling, you could pull up the app on your phone and use it as a free and instantaneous translator to ask someone for directions or to make a purchase in a store.\n\nAdding the vision capabilities, one could even show ChatGPT a foreign restaurant menu, ask for a translation of certain items, tell it when you like to eat at home, and ask it to recommend some dishes you might want to order (or avoid.)\n\nI can also see how quickly the new system could venture into *Her* territory. OpenAI still doesn‚Äôt allow the kinds of NSFW interactions that happened in the movie.\n\nBut GPT\\-4o‚Äôs ability to understand and mimic emotion ‚Äî coupled with its powerful, often uncanny abilities to produce its own convincing human emotional speed ‚Äî is striking.\n\nListening to the demos, I‚Äôm certain that people will fall in love with this system, just as the protagonist did in *Her*. It‚Äôs that good.\n\n\n## Will it get used?\n\nAll of this is amazing on paper. It‚Äôs unclear, however, how many users actually want a fully emotive AI voice companion.\n\nMost people I work with use ChatGPT not as a conversational companion, but for utilitarian purposes.\n\nI‚Äôve seen colleagues leverage the system for boring and mundane tasks like writing the landing page copy for a webinar, turning out a quick response to an email from their landlord, or writing the first draft of a blog post.\n\nNone of these utilitarian functions really require conversation. It‚Äôs unclear whether being able to speak these kinds of requests to an AI would be useful.\n\nThe real test, then, is not necessarily how capable OpenAI‚Äôs new system is, but **how well they integrate it into places where people are already interacting with computers via their voices.**\n\nRealistically, I can‚Äôt see many users sitting down at work and conversing with AI.\n\nBut if OpenAI integrates GPT\\-4o into voice interfaces on cell phones, in cars, or on smart devices like the Amazon Echo, I could easily see the system‚Äôs emotive capabilities becoming much more useful.\n\nEven if people don‚Äôt want to speak with ChatGPT very much, the new capabilities of a natively multimodal audio and vision model will be incredibly powerful for developers who build applications on top of OpenAI‚Äôs existing API.\n\nIn their announcement, OpenAI said that GPT\\-4o will be available through their existing developer interfaces. The system will also be 50% cheaper than previous models of GPT\\-4\\.\n\nThose changes alone are massive. Whether or not the speech element really takes off, the intelligence that powers it will also make hundreds of existing GPT\\-4\\-powered applications smarter, faster, better, and cheaper to operate.\n\nThe conversational elements of the new system, in other words, might turn out to be a cool gimmick. But the underlying impact will be subtler and broader.\n\nI‚Äôm excited to see how real\\-life users interact with GPT\\-4o. Will they be creeped out? Amazed? Wooed?\n\nBut I‚Äôm even more excited to fire up my Python IDE and add GPT\\-4o into the applications I‚Äôve already built using OpenAI‚Äôs tools.\n\nSpeaking to a machine is cool. But a natively multimodal AI model that understands human emotions, and that I can summon with a few lines of Python code, for cheap? That could truly change the world.\n\n**I‚Äôve tested thousands of ChatGPT prompts over the last year. As a full\\-time creator, there are a handful I come back to every day that fit with the ethical uses I mention in this article. I compiled them into a free guide, *7 Enormously Useful ChatGPT Prompts For Creators.* [Grab a copy today!](https://no-frills-influencer.ck.page/6a100e8fe4)**\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-realtime-api-voice-mode-getting-started-on-colab-39b93edcaa6a","frontmatter":{"title":"OpenAI Realtime API (Voice Mode), Getting Started on Colab","meta_title":"OpenAI Realtime API (Voice Mode), Getting Started on Colab","description":"Everything you need to know, and a hands-on introduction to OpenAI‚Äôs voice mode API that you can run on Colab.","date":"2024-11-08T00:23:32.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_-d5zsWWQEzVLZxABTSFWQ.png","categories":["Programming","Voice Assistants","Technology/WebAPI"],"author":"Rifx.Online","tags":["OpenAI","Realtime","API","GPT-4o","Colab"],"draft":false,"slug":"blog/openai-realtime-api-voice-mode-getting-started-on-colab-39b93edcaa6a"},"content":"\n\n\n\nEverything you need to know, and a hands\\-on introduction to OpenAI‚Äôs voice mode API that you can run on Colab.\n\n\n\nThe latest development from OpenAI brings us the **Realtime API**, designed to allow developers to create **fast, seamless speech\\-to\\-speech experiences** within their apps. This API aims to streamline the development of multimodal conversational features, making it much easier to build natural, real\\-time voice interactions.\n\nI**n this blog post,** I‚Äôll cover the **main questions** around this new API, including\n\n* what is Realtime API,\n* How to access it,\n* Its limitations and pricing,\n* and provide a **Colab tutorial** on how to get started.\n\n\n## What is the Realtime API?\n\nThe **Realtime API** by OpenAI is a public beta feature that enables paid developers to incorporate real\\-time voice interaction in their apps. It‚Äôs a multimodal API capable of transforming **audio inputs to speech responses**, using the advanced **GPT\\-4o** model for this purpose. Essentially, it allows for **low\\-latency conversations** similar to a natural human interaction, similar to the functionality seen in ChatGPT‚Äôs Advanced Voice Mode.\n\nPreviously, developers had to stitch together multiple models for **speech recognition, text processing, and text\\-to\\-speech generation**. The Realtime API does this all in a single API call, resulting in fewer delays, richer responses, and more consistent handling of accents and emphasis.\n\nThe **Chat Completions API** also introduces audio input and output, but it doesn‚Äôt offer the low\\-latency experience of the Realtime API. Thus, for experiences like language learning or voice\\-enabled assistants, Realtime API is the preferred choice.\n\n\n## Access and Limitations\n\nAccess to the **Realtime API** is currently available as a **public beta** for paid developers.\n\n**Although it is said that access is limited in Europe, I was able to use it through my tier 5 OpenAI account.**\n\nThe API uses a **WebSocket** connection, which ensures a smooth streaming experience for both audio inputs and outputs.\n\nFor now, there are **limitations** to note:\n\n* **Session Rate Limits**: The API is rate limited to approximately **100 simultaneous sessions** for Tier 5 developers. Lower tiers have smaller capacity. As of Octobre 2024, the API is limited 2M tokens per minutes.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XpAB6WRseRb0iY-edE94xw.png)\n\n* **Capabilities**: Initially, only **voice modality** is supported, but OpenAI plans to add more like **video** and **vision** over time.\n* **Availability**: Full audio capabilities are in the beta phase, with **future SDK integration** planned for Python and Node.js.\n\n\n## Pricing of the Realtime API\n\nThe **pricing** structure for the Realtime API is divided into both **text tokens** and **audio tokens**:\n\n* **Audio Input**: $100 per 1 million tokens (approx. **$0\\.06 per minute**).\n* **Audio Output**: $200 per 1 million tokens (approx. **$0\\.24 per minute**).\n* **Text Input**: $5 per 1 million tokens.\n* **Text Output**: $20 per 1 million tokens.\n\nThe pricing makes it affordable for developers to create robust **speech\\-to\\-speech** experiences, though audio features are significantly more expensive than text\\-based interactions. This is important to keep in mind when scaling an app with voice features.\n\nIt is still slightly more expensive than outsourcing it to some countries, but we can expect a significant drop in prices over the next six months.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ocwFDXEt8X7KD_k6)\n\n\n## Building with the Realtime API in Google Colab\n\nHere‚Äôs a basic **Colab guide** to help you get started with uploading a file, sending a request to the Realtime API, and generating audio responses.\n\nIn this demo, we chose to upload a stream of audio chunks to mimic a conversation.\n\n**Full Colab Code**: [link here](https://colab.research.google.com/drive/1-bj_LH7Gv2bbTJopbo7Hk_AIyDAuqeEQ?usp=sharing), simply add your ‚Äúopenai‚Äù key to Colab‚Äôs secrets and run the colab.\n\n\n### Step 1: Setting Up Google Colab and Dependencies\n\n* Start a new **Google Colab** notebook.\n* Install the necessary libraries such as **requests** and **pydub** for managing audio files.\n\n\n```python\n#Setup\n!pip install websockets pydub --quiet \n\nimport base64\nimport numpy as np\nimport soundfile as sf\nimport json\nimport websockets\nfrom google.colab import files\nfrom pydub import AudioSegment\nfrom tqdm import tqdm\nimport io\n```\n\n### Step 2: Uploading Your Audio File\n\nIn Colab, you can use the `files` module from **google.colab** to upload audio files.\n\n\n```python\n#Upload audio\ndef upload_audio():\n    uploaded = files.upload()  \n    for file_name in uploaded.keys():\n        return file_name\n\naudio_file = upload_audio()\n```\n\n### Step 3: Sending a Request to the Realtime API\n\n* Format the audio file properly before sending it to OpenAI.\n* Establish a WebSocket connection to stream the audio file.\n* Use `tqdm` to display the progress of the upload stream.\n* The function returns the full set of events (including responses) for later processing to generate the output audio. It also returns the transcript of the model‚Äôs response.\n\n\n```python\n#Helper functions\n## Function to convert Float32Array to PCM16 format\ndef float_to_pcm16(float32_array):\n    return np.clip(float32_array * 32767, -32768, 32767).astype(np.int16).tobytes()\n\n## Function to split audio into base64-encoded PCM16 chunks\ndef float32_to_base64_chunks(float32_array, chunk_size=32000):\n    pcm16_data = float_to_pcm16(float32_array)\n    for i in range(0, len(pcm16_data), chunk_size):\n        yield base64.b64encode(pcm16_data[i:i+chunk_size]).decode('utf-8')\n\n## WebSocket connection and streaming audio with text prompt\n## Main function to call OpenAI Realtime API\nasync def stream_audio_to_realtime_api(audio_file, text_prompt, openai_key, verbose = False):\n    data, samplerate = sf.read(audio_file, dtype='float32')\n    if data.ndim > 1:\n        data = data[:, 0]\n    if samplerate != 24000:\n        raise ValueError(f\"Audio must be sampled at 24kHz, but it is {samplerate}Hz\")\n\n    url = \"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01\"\n    headers = {\"Authorization\": \"Bearer \" + openai_key, \"OpenAI-Beta\": \"realtime=v1\"}\n\n    async with websockets.connect(url, extra_headers=headers) as ws:\n        await ws.send(json.dumps({\n            \"type\": \"conversation.item.create\",\n            \"item\": {\"type\": \"message\", \"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": text_prompt}]}\n        }))\n\n        with tqdm(total=(len(float_to_pcm16(data)) + 32000 - 1) // 32000, desc=\"Sending Audio Chunks\") as pbar:\n            for chunk in float32_to_base64_chunks(data):\n                await ws.send(json.dumps({\"type\": \"input_audio_buffer.append\", \"audio\": chunk}))\n                pbar.update(1)\n\n        await ws.send(json.dumps({\"type\": \"input_audio_buffer.commit\"}))\n        await ws.send(json.dumps({\"type\": \"response.create\"}))\n\n        all_events = []\n        while True:\n            response = await ws.recv()\n            event = json.loads(response)\n            all_events.append(event)\n            if verbose:\n                print(event)\n            if event[\"type\"] == \"response.output_item.done\" and \"item\" in event and \"content\" in event[\"item\"]:\n                for content in event[\"item\"][\"content\"]:\n                    if content[\"type\"] == \"audio\" and \"transcript\" in content:\n                        transcript = content[\"transcript\"]\n                        break\n            if event[\"type\"] == \"rate_limits.updated\":\n                break\n\n        return all_events, transcript\n```\n\n```python\n#Add a prompt and call OpenAI Realtime API\ntext_prompt = \"Summarize this audio content\"\n\nevents, transcript = await stream_audio_to_realtime_api(\n    audio_file, \n    text_prompt, \n    openai_key, \n    verbose = False \n#to display OpenAI's response as they arrive, use verbose = True\n    ) \n```\n\n### Step 4: Generating Audio Responses\n\n* Once you receive the response, generate the audio.\n* Choose a file name and save the file.\n* You will then be able to download the file.\n\n\n```python\n## Function to decode and concatenate audio chunks into a full audio file\ndef generate_audio_from_chunks(audio_chunks, output_filename=None):\n    # Concatenate the base64-encoded audio chunks from the 'delta' field\n    full_audio_base64 = ''.join(audio_chunks)\n\n    # Decode the concatenated base64 string to raw PCM16 audio bytes\n    audio_bytes = base64.b64decode(full_audio_base64)\n\n    # Load the bytes as a pydub AudioSegment (assuming 24kHz, 1 channel, PCM16)\n    audio_segment = AudioSegment.from_raw(\n        io.BytesIO(audio_bytes), \n        sample_width=2, \n        frame_rate=24000, \n        channels=1)\n\n    # Optionally save the audio to a file\n    if output_filename:\n        audio_segment.export(output_filename, format=\"wav\")\n        print(f\"Audio saved to {output_filename}\")\n\n    return audio_segment\n```\n\n```python\n#Extract audio chunks from the collected events\naudio_output_chunks = [event['delta'] for event in events if event['type'] == 'response.audio.delta']\n\n## Generate the full audio from the collected chunks\ngenerated_audio = generate_audio_from_chunks(audio_output_chunks, output_filename=\"output_audioo.wav\")\n```\n\n## Conclusion\n\nWith the above steps, you can integrate OpenAI‚Äôs Realtime API into a Colab notebook, enabling seamless voice instructions.\n\nThis guide should give you a solid foundation for experimenting with real\\-time audio\\-to\\-audio interactions and building innovative voice\\-driven applications.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-rolls-out-searchgpt-to-more-users-33024ff3132c","frontmatter":{"title":"OpenAI Rolls Out SearchGPT To More Users","meta_title":"OpenAI Rolls Out SearchGPT To More Users","description":"ChatGPT got a huge user interface redesign with support for SearchGPT‚Ää‚Äî‚Ääit now resembles search engines like Google and Perplexity.","date":"2024-11-01T03:57:02.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BW6Qt6PMwHwlYRljAIBQWg.jpeg","categories":["Chatbots","Technology/Web","SearchGPT"],"author":"Rifx.Online","tags":["SearchGPT","ChatGPT","web","search","publishers"],"draft":false,"slug":"blog/openai-rolls-out-searchgpt-to-more-users-33024ff3132c"},"content":"\n\n\n\n\n\n**Have you noticed OpenAI‚Äôs latest redesign of ChatGPT?**\n\nIf you‚Äôve logged in recently, you might have spotted two major changes.\n\n* First, there‚Äôs the new [**Canvas**](https://generativeai.pub/openai-rolls-out-canvas-in-chatgpt-a-brand-new-writing-and-coding-interface-7b57a3ec582a)feature that automatically opens a new interface on the right side. This addition lets you work on longer documents without having to scroll up and down through the chat. It‚Äôs a small but handy update.\n* Second, the **prompt field** has moved up and now sits in the center of the screen.\n\nTake a look at the latest user interface below:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KsYMU9ffVlKsmHzKIOKH8g.png)\n\nHave you noticed the resemblance of this new layout to Google and Perplexity AI? ChatGPT now looks like a search engine.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xFKErUHnfbJunaKi4NvM9A.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PgSwS14lkUtZe7Ra9oLCrg.png)\n\nNow when you hit the ‚Äò/‚Äô key on your keyboard, you can toggle a new ‚ÄúSearch‚Äù feature that lets ChatGPT access the web.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*oYxvVvsuUuc_PM0PXRmN7A.png)\n\nLet‚Äôs break down what this all means.\n\n\n## What is the Search Feature in ChatGPT?\n\n[SearchGPT](https://generativeai.pub/openai-announces-search-gpt-is-this-the-google-killer-5919ba31f95b) allows ChatGPT to access real\\-time web data. Similar to how Perplexity works, it uses a large language model that searches the web for you, gives you immediate answers, and includes the sources it pulls from.\n\nThe feature was initially made accessible to 10,000 users and added a waitlist form for those who wanted to get early access.\n\nOpenAI has partnered with well\\-known publishers like **The Wall Street Journal, The Associated Press, Vox Media, and Time** to make sure users receive credible, trustworthy information.\n\n\n> ‚ÄúAI search is going to become one of the key ways that people navigate the internet, and it‚Äôs crucial, in these early days, that the technology is built in a way that values, respects, and protects journalism and publishers. We look forward to partnering with OpenAI in the process, and creating a new way for readers to discover The Atlantic.‚Äù ‚Äî Nicholas Thompson, CEO of The Atlantic\n\nWhen you ask SearchGPT a question, it doesn‚Äôt just pull information from random sources. Each response comes with **clear, in\\-line attribution and links**, so you know exactly where the information is coming from.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uchpKOXqZCG55HSNkaOOZQ.png)\n\nYou can even dive deeper by clicking on the source links that appear below the searched sites dropdown, giving you more ways to explore the topic.\n\n\n## How to Access SearchGPT\n\nAccessing SearchGPT is super simple. When you‚Äôre in ChatGPT, press the **‚Äò/‚Äô** key and select the Search option from the menu.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xNfm-6zPFzdXGL2A0D92YQ.png)\n\nIt works much like any other search engine: you ask your question, and within seconds, SearchGPT provides an answer, complete with sources.\n\nYou can even ask follow\\-up questions to dig deeper into the topic. This creates a conversational search experience, much more interactive than scrolling through traditional search results.\n\n\n## SearchGPT vs. Perplexity vs. Google\n\nSo how does SearchGPT compare to **Perplexity AI** and **Google**?\n\n**SearchGPT** is built to give you concise, sourced answers. Each answer has a link to the original source, and you can click on it to verify the information. It‚Äôs ideal for real\\-time answers and quick fact\\-checking.\n\nPlus, with follow\\-up questions, you can refine your query without starting over. This conversational nature makes it feel like you‚Äôre talking to a super\\-advanced version of Google that remembers what you‚Äôve been asking.\n\n**Perplexity**, on the other hand, is a more academic\\-style search engine. It emphasizes scholarly articles and detailed research, which can be useful for more in\\-depth queries. Perplexity is often preferred for research\\-heavy tasks where you need deeper sources\n\n**Google**, of course, is still the giant in the room. Despite their recent efforts to integrate generative AI into search results, they haven‚Äôt quite nailed the seamless experience that users want.\n\nGoogle‚Äôs generative search rollout was clunky and received a lot of backlash due to errors and irrelevant responses. But Google‚Äôs breadth of information and infrastructure are still unmatched.\n\n\n## Is This the End of Google?\n\nGoogle isn‚Äôt going anywhere soon. The tech giant still controls over 90% of the search market. They‚Äôve been at this for decades, and their search algorithms are constantly evolving.\n\nHowever, with AI search engines like SearchGPT gaining ground, Google is under pressure to step up its game. OpenAI‚Äôs move to partner with publishers for credible sources is a smart strategy that could chip away at Google‚Äôs dominance.\n\nThis focus on verified results means that when you use SearchGPT, you‚Äôre less likely to run into hallucinated answers ‚Äî something that AI\\-driven tools have struggled with in the past.\n\nAlso, Google is still the default for most people. It has the advantage of being everywhere ‚Äî from your phone‚Äôs browser to your smart speaker. SearchGPT is still in its early stages and would need time to gain that level of trust from users.\n\n\n## SearchGPT Isn‚Äôt There Yet\n\nI‚Äôve been testing SearchGPT in the past couple of hours and here are some of my observations:\n\n* **Quality of the answer:** One major downside is that SearchGPT‚Äôs answer quality doesn‚Äôt quite match the depth or precision of Perplexity Pro. Although it‚Äôs comparable to the base version of Perplexity, users who rely on it for more complex or nuanced queries will notice a difference.\n* **Slow response:** Another pain point is speed. When using SearchGPT, the time it takes to process a query and return an answer can feel excruciatingly slow. This delay disrupts the flow of interaction, particularly when you‚Äôre in the middle of a deep dive into a topic.\n* **Lack of contextual understanding:** In some cases, it fails to recognize the continuity of a conversation. If you ask a follow\\-up question, instead of understanding it in the context of your previous query, the model often treats it as a fresh, standalone question.\n* **No follow up suggestions:** Unlike Perplexity, which often suggests follow\\-up questions to help you refine your search, SearchGPT doesn‚Äôt offer this feature. This lack of guidance leaves users to figure out how to best phrase or narrow down their queries on their own.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vfXxpgENLyenLY2l33PKiw.png)\n\nHere‚Äôs another weird workflow I noticed while using the search feature: If you switch the language model from GPT\\-4o to ‚ÄúChatGPT o1\\-preview,‚Äù the search indicator remains but does not actually search the web for results.\n\nIt returns results from its domain knowledge, which isn‚Äôt what the users expect.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YcI-UuEmmFTQPUlO6mjpxA.png)\n\nThe correct behavior should be to disable the *search* function once the user switches to ‚ÄúChatGPT o1\\-preview‚Äù because this model does not have the capability to search the web.\n\n\n## Final Thoughts\n\nI‚Äôm really glad OpenAI has finally rolled out SearchGPT. I‚Äôve been wanting to test it out ever since they announced it in July 2024\\.\n\nIn its current state, SearchGPT is a good first step for OpenAI into the world of AI\\-powered search, but it‚Äôs not quite ready to become anyone‚Äôs go\\-to tool for complex, real\\-time queries.\n\nThe accuracy, speed, and ability to handle conversational context just aren‚Äôt there yet. For now, if you need deep insights or faster results, tools like Perplexity Pro or Google remain the better options.\n\nFurther reading:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5ejBBgbZaE8pGmpW.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories.\n\nSubscribe to our [newsletter](https://www.generativeaipub.com/) and [YouTube](https://www.youtube.com/@generativeaipub) channel to stay updated with the latest news and updates on generative AI. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*TnRFuKk-2Dj_KCAP.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openai-searchgpt-chatgpt-with-internet-and-browsing-tools-023ddca7cb44","frontmatter":{"title":"OpenAI SearchGPT: ChatGPT with Internet and browsing tools","meta_title":"OpenAI SearchGPT: ChatGPT with Internet and browsing tools","description":"A Better Alternative for Perplexity and Google Search","date":"2024-11-08T00:28:30.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*N_EtjjOxkx6QsKRLx5f_cQ.png","categories":["Technology/Web","Data Science","SearchGPT"],"author":"Rifx.Online","tags":["SearchGPT","filtering","citations","recommendations","customization"],"draft":false,"slug":"blog/openai-searchgpt-chatgpt-with-internet-and-browsing-tools-023ddca7cb44"},"content":"\n\n\n\n\n### A Better Alternative for Perplexity and Google Search\n\n\n\nAnd the much\\-anticipated product by OpenAI, SearchGPT is out last night boasting some major features, taking it a step ahead of Perplexity, their arch\\-rivals.\n\n\n\n\n\n\n\nAs announced by OpenAI, SearchGPT is a lot more than just ChatGPT with the internet.\n\nIt is an AI web browser in itself\n\nTalking about a few key features:\n\n* **Advanced Filtering**: Set filters for specific dates, sources, or content types (e.g., peer\\-reviewed articles only, government sites, etc).\n* **Context\\-Aware Summaries**: Generate summaries, key takeaways, or insights tailored to particular fields, like medicine or finance.\n* **Citation Generation**: Automatically format and provide citations in academic styles (APA, MLA).\n* **Multi\\-Step Queries**: Handle complex, layered questions across multiple sources in a single search.\n* **Data Analytics Integration**: Directly pull and analyze data for insights (e.g., trend analysis). SearchGPT could connect to specialized databases, allowing access to specific fields (like medical journals, legal case databases, or proprietary business analytics).\n* **Personalized Recommendations**: Suggest relevant sources, articles, or updates based on your search history. This includes **Pre\\-set Templates or Personas**: For example, a research\\-focused ‚ÄúSearchGPT‚Äù could be set up to retrieve scientific data and offer academic citations directly.\n\n\n### Was ChatGPT not able to access the internet before?\n\nIt does (for premium members). But now, these capabilities are more advanced. To check out how a general web search is different from SearchGPT, I tried asking ChatGPT itself (free version) to search the internet for a query:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ORjGLDBqKDWiPANHlxSdqw.png)\n\nThen, I asked how this search was done.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NlzDed3nHdJ636aLt75DCg.png)\n\nNext up,\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eeDPQHQA62yaMK_KkSL0kQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ZcsmVgau0SaavN01yHbdKw.png)\n\nSo, as you can read, SearchGPT is not just a mere web browsing tool, but a lot more. Unfortunately, OpenAI has made SearchGPT available for Pro users and only to the waitlist users. If you‚Äôve access, you must have received this mail yesterday\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WfO0Xl4VQwRxNNkC1GQpOw.png)\n\nBelow are some screen grabs from SearchGPT\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8bbGpwbsRzo6xQhNDPb3Jw.png)\n\nAs you can see, it provides trending topics as suggestions while searching, similar to a web browser.\n\nTry checking out the weather today\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*gbtr-QFQw4BnhqrWPvH4RQ.png)\n\nAnd can even restrict it to just check specific websites like ‚Äúcite just government sites‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eq_Xf4JkD4XV85KE5376VA.png)\n\nAll the citations can be explored at the bottom together for your results\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wUTEae5yYh_j-oaq6HyP9Q.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Quruyw07__p3qoJ_KhmHAA.png)\n\n\n## SearchGPT vs Perplexity. Which is better?\n\nA tough question to answer, at least for now. A few points to highlight are\n\n1. Perplexity is free, SearchGPT is not!\n2. SearchGPT is faster. But I assume this is because of lesser traffic right now.\n3. Perplexity is simpler, and also, has the early mover advantage\n4. Perplexity, being in the space for a long time, is more reliable compared to SearchGPT\n5. SearchGPT provides more customizations and is not just LLM with the internet.\n\nTo be honest, I‚Äôm always in favour of free stuff hence will prefer Perplexity any day. Though, given SearchGPT‚Äôs early response, the tool is pretty good and worth trying out.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/openais-leaked-gpt2-model-has-everyone-stunned-6337904c2ecf","frontmatter":{"title":"OpenAI‚Äôs ‚ÄòLeaked‚Äô GPT2 Model Has Everyone Stunned.","meta_title":"OpenAI‚Äôs ‚ÄòLeaked‚Äô GPT2 Model Has Everyone Stunned.","description":"On-Purpose leak?","date":"2024-11-01T04:07:40.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-G0yfSjGPdNw02NZ","categories":["Chatbots","Generative AI","Natural Language Processing"],"author":"Rifx.Online","tags":["GPT-2","Chatbot","Inference","JSON","AlphaGo"],"draft":false,"slug":"blog/openais-leaked-gpt2-model-has-everyone-stunned-6337904c2ecf"},"content":"\n\n\n\n\n### On\\-Purpose leak?\n\n\n\nThe influence that OpenAI has on the AI industry can‚Äôt be understated. Every move or decision makes headlines automatically‚Ä¶ even if they don‚Äôt actually announce the thing.\n\nA few days ago, a model many of us played with that has since been deleted has the entire AI industry fascinated. Named ‚Äúgpt2\\-chatbot‚Äù it was accessible for a few days in the ‚ÄòDirect Chat‚Äô function in [lmsys.org](https://chat.lmsys.org/).\n\n*But why so much fuss?*\n\nWell, because this model is unlike anything we have ever seen. **It‚Äôs on a completely different level.**\n\nFor this reason, many believe it has been the unofficial teaser of **ChatGPT\\-4\\.5** or even **GPT\\-5**. Or, even more exciting, using the number ‚Äò2‚Äô as a signal that a **new GPT generation of long\\-inference models is approaching**.\n\nEven Sam Altman, CEO of OpenAI, couldn‚Äôt resist the temptation to acknowledge its existence and tease us in the process:\n\n\n\n\n\n\n\nSo, *how good is this model, and what on Earth is it?*\n\n\n> You are probably sick of AI newsletters talking about how this or that \\*\\*just\\*\\* happened. And these newsletters abound because coarsely talking about events and things that already took place is easy, **but the value provided is limited and the hype exaggerated.**\n\n\n> However, newsletters talking about what **will** happen are a rare sight. If you‚Äôre into easy\\-to\\-understand insights looking into the future of AI before anyone else does, **TheTechOasis** newsletter might be perfect for you.\n\n\n> üèùÔ∏èüèùÔ∏è Subscribe today below:\n\n\n## A Teaser of What‚Äôs to Come\n\nWith every passing day, it‚Äôs clear that OpenAI‚Äôs next model will be a leap in reasoning and complex problem\\-solving.\n\nAnd to prove how this new mysterious model might be it, here are just a few examples of the prowess of this mysterious model that could signal that the boat has landed in that port:\n\n\n> All examples below are considered **hard or outright impossible** for the current state\\-of\\-the\\-art models.\n\nFor starters, It solved a math\\-olympiad problem in zero\\-shot mode (without being provided with auxiliary examples to support the resolution):\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*oNPg_hTGc0OP90n9)\n\nI can‚Äôt even start to explain how crazy the previous example is, it‚Äôs absolutely impossible to get such an answer from the current state\\-of\\-the\\-art models.\n\n[It‚Äôs also absolutely superb at parsing JSONs](https://twitter.com/skirano/status/1785035706173214888), a fundamental skill for LLM integration with APIs and other web\\-based tools.\n\nAlso, it completely obliterates GPT\\-4 at complex drawing tasks like [drawing SVG files based on code](https://twitter.com/decentricity/status/1785049191003361778) or **unicorns using ASCII code (below)**, humiliating **Claude 3 Opus**, the current state\\-of\\-the\\-art, in the process:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5A0EcRU91ZYAwVAc)\n\nAdditionally, although this very well could have been a hallucination, **the model claimed to me that it was trained by OpenAI and based on a GPT\\-4 variant.**\n\nOf course, after such a demonstration of power, **many suggest that ‚Äúgpt2\\-chatbot‚Äù might even be the famous Q\\* model**.\n\nBut instead of simply giving in to the different fanciful options people have claimed this is, let‚Äôs take a more sensible approach and see what OpenAI itself has been hinting at through their research for months (and years).\n\n\n## The Power of Long Inference\n\nFor several months, experts in the space like [Demis Hassabis](https://www.youtube.com/watch?v=eqXfhejDeqA&t=2s) or [Andrej Karpathy](https://youtu.be/c3b-JASoPi0?si=fZWoSpLuSmua8YMR&t=1481) have discussed how LLMs alone simply aren‚Äôt it, and that we need ‚Äòsomething else‚Äô to really take them to the next step.\n\nIn both cases, they refer to achieving the equivalent of ‚ÄòAlphaGo but in LLMs‚Äô, which is indirectly referring to:\n\n* **Self\\-improvement** and\n* **test\\-time computation** LLMs\n\n*But what do they mean by that?*\n\n\n### A Giant Step for AI\n\nAlphaGo is history of AI. It was the first model that unequivocally surpassed human might in the game of **Go**, a Korean board game.\n\nIt used **Monte Carlo Tree Search**, a search algorithm, to explore the realm of possible moves for any given step in the game, being able to go beyond the current action and predict what the opposing player would do.\n\n\n> Some of you might remember **Deep Blue** too, the chess machine that barely beat Gary Kasparov in the second game in their series back in 1997 after losing the first game.\n\n\n> However, while Deep Blue could be beaten, AlphaGo was invincible.\n\n*But how?*\n\n\n### Self\\-improving to go Superhuman\n\nThe key element that made AlphaGo superior was how it was trained, **by playing against lesser versions of itself to create a self\\-improvement loop.**\n\nIt consistently played against itself, gradually improving its ELO to 3\\.739, almost at the level of today‚Äôs best Go player.\n\n\n> In 2017, AlphaZero, an improved version, achieved a 5\\.018 ELO, completely superhuman and unbeatable.\n\nIn other words, with AlphaGo humans had achieved, for the first time, a way to train a model by self\\-improvement, allowing it to achieve superhuman capacities **as it no longer relied on imitating humans to learn.**\n\nIn case you‚Äôre wondering, this is not the case for LLMs.\n\nCurrent LLMs are completely chained to human\\-level performance, as all data and training are inherently human\\-dependent (to the point that [the alignment phase](https://thewhitebox.ai/llms-the-backbones-of-frontier-ai/), the part of the training process where LLMs are modeled to improve their safety levels and avoid offensive responses, **is strictly executed using ‚Äòhuman preferences‚Äô**).\n\n\n> On a side note, [Meta recently proposed Self\\-Rewarding Models](https://arxiv.org/pdf/2401.10020v1) that could self\\-improve with their own responses. However, it‚Äôs unclear whether this feedback loop really can make LLMs superhuman.\n\nBut even though it still feels hard to believe that ‚Äúgpt2\\-chatbot‚Äù has been trained through self\\-improvement, **we have plenty of reasons to believe it‚Äôs the first successful implementation of what OpenAI has been working on for years: test\\-time computation**.\n\n\n### The Arrival of test\\-time computation models\n\nOver the years, several research papers by OpenAI have hinted at this idea of skewing models into ‚Äòheavy inference‚Äô.\n\nFor example, back in 2021, [they presented the notion of using ‚Äòverifiers‚Äô](https://arxiv.org/pdf/2110.14168) at inference to improve the model‚Äôs responses when working with Math.\n\nThe idea was to train an auxiliary model that would evaluate in real\\-time several responses the model gave, choosing the best one (which was then served to the user).\n\nThis, combined with some sort of tree search algorithm like the one used by AlphaGo, with examples like Google Deepmind‚Äôs [Tree\\-of\\-Thought research](https://arxiv.org/pdf/2305.10601) for LLMs, and you could eventually create an LLM that, before answering, explores the ‚Äòrealm of possible responses‚Äô, **carefully filtering and selecting the best path toward the solution.**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pHWwOA66fxpKbl-z)\n\nThis idea, although presented by OpenAI back in 2021, has become pretty popular these days, [with cross\\-effort research by Microsoft and Google applying it to train next\\-generation verifiers](https://arxiv.org/pdf/2402.06457), and with Google even managing to create a model, [Alphacode](https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf), that executed this kind of architecture to great success, **reaching the 85% percentile among competitive programmers, the best humans at it.**\n\n*And why does this new generation of LLMs have so much potential?*\n\nWell, **because they approach problem\\-solving in a very similar way to how humans do**, through the exercise of deliberate and extensive thought to solve a given task.\n\nBottom line, think of ‚Äòsearch\\+LLM‚Äô models as AI systems that allocate a much higher degree of compute (akin to human thought) to the actual runtime of the model so that, instead of having to guess the correct solution immediately, they are, simply put, ‚Äògiven more time to think‚Äô.\n\nBut OpenAI has gone further.\n\n\n### PRM Models for Improved Maths Execution\n\nBack in May last year, they released the paper [Let‚Äôs Verify Step\\-by\\-Step](https://arxiv.org/pdf/2305.20050), with the participation of the man himself Ilya Sutskever, Chief Scientist at OpenAI, and some of the researchers from the original verifier paper like Karl Cobbe.\n\nThe idea here is to modify the reward model used during the alignment phase of the model.\n\n[Although I recommend checking this article for a full guide on LLM training](https://thewhitebox.ai/llms-the-backbones-of-frontier-ai/), the last step in the process of creating products like ChatGPT is the use of Reinforcement Learning from Human Feedback, or RLHF.\n\nThe idea is for the model to improve its decision\\-making. Thus, we train an auxiliary reward model (which is essentially an almost identical copy of the model being trained) that learns to rank the results of the trained model according to human preferences.\n\n*The issue?*\n\nWell, most reward models today are **ORMs, or Outcome\\-Supervised Reward Models**. In layman‚Äôs terms, to evaluate the degree of correctness or the model‚Äôs prediction, they look at it globally, disregarding the entire ‚Äòthought process‚Äô.\n\nOn the other hand, **PRMs, or Process\\-Supervised Reward Models, evaluate every single step in the response of the model**. Consequently, they ‚Äòforce‚Äô the model to pay close attention and effort to every single step of the process, which is crucial in situations like solving a maths equation like the one below:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8JC6sZl5UFfl3WorliQy-A.png)\n\nHowever, this is a very, very expensive process as the preference data requires heavy human crafting so that the supervisory signal can be applied. Consequently, every single training example has dozens or more rewards to measure.\n\nTherefore, ‚Äúgpt2\\-chatbot‚Äù might have included some sort of variation of the reward training considering how proficient it is at generating plans and executing complex problem\\-solving.\n\n\n## Impossible not to Get Excited\n\nConsidering gpt2\\-chatbot‚Äôs insane performance, and keeping in mind OpenAI‚Äôs recent research and [leaks](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/), we might have a pretty nice idea by now of what on Earth this thing is.\n\nWhat we know for sure is that we are soon going to be faced with a completely different beast, one that will take AI‚Äôs impact to the next level.\n\n* *Have we finally reached the milestone for LLMs to go beyond human\\-level performance as we did with AlphaGo?*\n* *Is the age of long inference, aka the conquest of System 2 thinking by AI, upon us?*\n\nProbably not. However, it‚Äôs hard not to feel highly optimistic for the insane developments we are about to witness over the following months.\n\nIn the meantime, I guess we will have to wait to get those answers. But not for long.\n\n\n> On a final note, if you have enjoyed this article, I share similar thoughts in a more comprehensive and simplified manner for free on my [LinkedIn](https://www.linkedin.com/in/ignacio-de-gregorio-noblejas/).\n\n\n> If preferable, you can connect with me through [X](https://twitter.com/TheTechOasis1).\n\n\n> Looking forward to connecting with you.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/overcoming-llm-challenges-in-healthcare-practical-strategies-for-development-in-production-04c617954b9a","frontmatter":{"title":"Overcoming LLM Challenges in Healthcare: Practical Strategies for Development in Production","meta_title":"Overcoming LLM Challenges in Healthcare: Practical Strategies for Development in Production","description":"An article on the most common LLM development challenges I‚Äôve encountered, effective mitigation strategies, and a career-defining interview‚Ä¶","date":"2024-11-08T00:20:35.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Vak28ygruWKySsH0doGoYg.png","categories":["Health","Generative AI","Machine Learning"],"author":"Rifx.Online","tags":["LLMs","healthcare","hallucinations","validation","monitoring"],"draft":false,"slug":"blog/overcoming-llm-challenges-in-healthcare-practical-strategies-for-development-in-production-04c617954b9a"},"content":"\n\n### Generative AI\n\n\n\n\n\n### An article on the most common LLM development challenges I‚Äôve encountered, effective mitigation strategies, and a career\\-defining interview mistake\n\n\n## Introduction\n\nI‚Äôve always been the type to dive deep into a subject and specialize to obsession. When I graduated from my master‚Äôs in data science, the obsession I had was with computer vision; specifically, computer vision to apply towards neuroscience or mental health applications. I was set on becoming a ‚Äúcomputer vision engineer‚Äù (but ‚Äúmachine learning engineer‚Äù would be okay too) in the mental health field, despite my mentors urging me to broaden my scope and get my foot in the door. I silenced my own wary voices, convinced that the right team would recognize my ‚Äúexpertise‚Äù.\n\n\n\nLuckily, my theory seemed to work; I landed interviews with several mental health companies. But then came one of my biggest interview mistakes. In the final round for my top choice ‚Äî a company I loved ‚Äî I made an error that still makes me internally cringe when I reflect. The role was NLP\\-focused, working with text data, but I couldn‚Äôt help expressing my interest in imaging data. *Cries in recollection.* I vividly recall the interviewer‚Äôs expression transforming from one of excitement to one of concern the moment I asked about imaging data availability, as I was still drawn to computer vision. Later that day, I received a polite rejection: they loved my passion but needed someone fully committed to NLP.\n\nIronically, I soon joined another mental health company and shifted fully to NLP work, creating anxiety and depression symptom detectors that improved clinical care and developing recommendation systems that boosted content discoverability by 12%. Fast\\-forward a few years, and I‚Äôm now the NLP/LLM data scientist on my team, with 6 information extraction tasks, 5 classification tasks, and 5 conditional summarization tasks deployed across 15\\+ hospitals and five clients.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-VOHDQd88fCyRqoY9bR3hQ.png)\n\nA couple of weeks ago, I was asked to present ‚ÄúLLM development 101‚Äù to my larger data team. Initially, imposter syndrome crept in ‚Äî *what could I share for 45 minutes on LLM development?* But as I created my slides, I realized how much I had to say and grew excited about sharing the depth of knowledge I‚Äôve learned. This excitement led to the article you‚Äôre reading right now. In this article, I‚Äôll walk through some common challenges I‚Äôve encountered with LLMs in production and the strategies that have helped me solve them.\n\n\n## 1\\. Output Format Errors\n\nThis is surprisingly probably the most frequent issue I encounter. Output format reliability can vary significantly depending on the model I‚Äôm working with. For example, GPT\\-4 Turbo generally provides consistent JSON outputs, but GPT\\-4o tends to be less reliable in this regard. With GPT\\-4o, I‚Äôve encountered everything from lists and strings to incomplete dictionaries when a structured JSON output was explicitly requested. If these format issues aren‚Äôt caught and the model isn‚Äôt re\\-run, I risk having incomplete data coverage.\n\n\n### Impact of Format Errors\n\nInconsistent output formats can have a significant impact on downstream processes. If the data structure is incorrect, it could lead to failures in subsequent processing steps, skew reporting accuracy, or even result in incomplete insights if left undetected. In high\\-stakes fields like healthcare, where my work applies, incomplete or mis\\-structured data can have real implications, making format consistency essential.\n\n\n### Mitigation\n\nTo handle this, I‚Äôve implemented **format\\-checking logic** that **validates the output structure**. If it‚Äôs incorrect, I re\\-run the model until it matches the expected format. Additionally, I use **logging** to capture format\\-related errors. Re\\-running the model, however, comes with trade\\-offs, such as increased latency and higher API costs. I establish thresholds for re\\-running based on the criticality of the data coverage and cost limitations. If re\\-running isn‚Äôt feasible, I sometimes apply post\\-processing to ‚Äúrepair‚Äù the output structure, though this approach carries its own risks of introducing errors or inconsistencies.\n\nTo illustrate this approach, here‚Äôs a sample code snippet that requests patient data in JSON format with specific keys like `\"name\"`, `\"age\"`, and `\"insurance\"`. This code demonstrates a method to verify that the model‚Äôs response includes all required fields and adheres to the expected structure. By implementing retry logic, the code aims to ensure data consistency, reducing the risks associated with format errors in critical workflows.\n\n\n```python\ndef get_llm_response(prompt: str, required_keys: Set[str], retries: int = 3) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Calls the language model to get a response in JSON format. If the response \n    is not in the expected JSON format or lacks required keys, retries the call \n    up to `retries` times.\n    Parameters:\n        prompt (str): The prompt sent to the language model.\n        required_keys (Set[str]): A set of required keys that must be present in the JSON response.\n        retries (int): The maximum number of retries if the output format is invalid.\n    Returns:\n        Optional[Dict[str, Any]]: Parsed JSON response if successful; None if retries are exhausted.\n    \"\"\"\n    \n    for attempt in range(retries):\n        try:\n            response = openai.Completion.create(\n                model=\"gpt-4o\",\n                prompt=prompt,\n                max_tokens=100,\n                temperature=0.7\n            )\n            \n            # Attempt to parse the response as JSON\n            response_text = response.choices[0].text.strip()\n            parsed_response = json.loads(response_text)\n            \n            # Check if parsed_response is in the expected structure and contains required keys\n            if isinstance(parsed_response, dict) and required_keys.issubset(parsed_response.keys()):\n                return parsed_response\n            else:\n                print(f\"Attempt {attempt + 1}: Output format invalid or missing required keys, retrying...\")\n        except (json.JSONDecodeError, KeyError) as e:\n            print(f\"Attempt {attempt + 1}: Error parsing JSON - {str(e)}, retrying...\")\n    print(\"Max retries exceeded: Unable to get valid JSON output with required keys.\")\n    return None\n\n```\n\n## 2\\. Hallucinations\n\nHallucinations happen when the model invents information that sounds plausible but isn‚Äôt actually there. For instance, when I‚Äôm trying to pull quotes from source text, sometimes the model decides to ‚Äúget creative‚Äù and produces similar\\-sounding but completely fabricated phrases. In fields where accuracy is crucial, like healthcare, small hallucinations can lead to large issues.\n\n\n### Mitigation\n\nI address hallucinations by implementing post\\-processing logic to validate that, for any information extraction tasks, the context pulled matches the source text exactly. To ensure that minor variations don‚Äôt lead to missed matches, I standardize the text by stripping punctuation and converting everything to lowercase when comparing the source and retrieved text. Additionally, several other strategies help minimize hallucinations. For instance, **chain\\-of\\-thought prompting**, where the model explains each step of its reasoning, can produce more grounded outputs and reduce the likelihood of inaccurate output. In high\\-stakes applications (such as healthcare use cases), **human\\-in\\-the\\-loop checks** are important as an extra layer of review, helping catch hallucinations that automated processes might miss. Lastly, prompts that emphasize factual accuracy, such as instructing the model to ‚Äúonly use exact phrases from the source,‚Äù can guide the model toward more precise responses.\n\n\n## 3\\. Outdated Information\n\nOutdated information can be challenging to manage, especially in applications where accuracy and timeliness are essential. Sometimes, a model might retrieve information from older sections of a document and surface it as if it‚Äôs current. With Retrieval\\-Augmented Generation (RAG), this issue can become even more complex, as RAG retrieves content based solely on relevance rather than timeliness or specific document sections. The absence of section labels or timestamps means RAG may pull from parts of a document that seem relevant without discerning if they‚Äôre outdated, which risks mixing older and current information. Another challenge with using a vector database is that if we store entire documents, we can‚Äôt easily remove specific sections without clearly defined labels, making it hard to filter out irrelevant information effectively.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*k9btdwyCCAb9qp92gB0PwA.png)\n\n\n### Mitigation\n\nTo address this, I specify ‚Äúcurrent‚Äù or ‚Äúmost recent‚Äù data directly in the prompt and use preprocessing steps to remove any outdated sections before passing data to the model. This extra preprocessing step ensures that only the latest, most relevant information is retained, helping the model focus on providing timely and accurate responses. This step not only ensures more accurate outputs, but it also reduces the cost of the call. By implementing these filters in advance, I can maintain consistency and relevance in the model‚Äôs outputs.\n\n\n## 4\\. Over\\-Reliance and Ethics\n\nAs much as I would love for the work I do to be used and useful, my biggest fear is that users would trust the model predictions a bit too much ‚Äî especially in the healthcare space, where generative AI is often producing summaries or extracting specific patient details, not just making predictions. Experts may hold differing views on certain definitions, so diversity and dialogue is important to reach a consensus. Over\\-reliance on these predictions, could lead care teams to limit these conversations and overlook errors they might otherwise examine more closely.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*6-0mq8Svxh8ATuyT)\n\n\n### Mitigation\n\nI prioritize educating the team on the model‚Äôs limitations, including its tendency for errors, and encourage them to see AI as a complement to human expertise. In healthcare, where nuance is critical, human\\-in\\-the\\-loop oversight is essential for high\\-impact cases, allowing experts to review AI outputs and reduce risks from over\\-reliance. This collaborative approach allows AI to amplify expert insights, maintaining the reliability and ethical integrity that high\\-stakes applications demand.\n\n\n## 5\\. Rapid Model Deprecation\n\nWith the rapid pace of development in AI, model and API versions are updated frequently, and it‚Äôs common for versions to be deprecated faster than expected. If you‚Äôve ever had a workflow break unexpectedly because a model version was retired, you‚Äôll know how disruptive this can be. This has happened several times in the past year, requiring us to quickly re\\-do analyses to ensure the newer model versions still perform as expected.\n\n\n### Mitigation\n\nMake it a priority to do regular check\\-ins to monitor model versions and stay ahead of deprecation warnings. This proactive approach would enable us to plan transitions in advance, saving the last\\-minute scramble. While it‚Äôs a small step, it makes a significant difference in maintaining smooth operations.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GK08JY3dcRUS4r6Z0x6EmA.png)\n\n\n## 6\\. Rate Limiting with APIs\n\nAPI rate limits are a subtle but significant challenge, especially when working with high volumes of requests. Hitting a rate cap can create delays, slow down real\\-time workflows, or even halt entire processes. In cases where we‚Äôre processing time\\-sensitive data, reaching the limit can be highly disruptive, as workflows come to an unexpected stop. This is especially problematic in healthcare settings, where timing can directly impact operations and patient care.\n\n\n### Mitigation\n\nTo mitigate this, we‚Äôve implemented a proactive approach by tracking API usage patterns to identify peak times and reduce non\\-essential calls. By staggering requests and batching calls, I can distribute the load more evenly and avoid exceeding limits. In situations where demand is high and rate limits are consistently reached, requesting additional quota from the provider can offer a practical solution. Balancing usage has been essential, and understanding our peak times and usage patterns ahead of time has proven crucial for maintaining a stable, uninterrupted workflow.\n\n\n## Concluding Remarks\n\nThese are just six of the common issues I‚Äôve faced while working with LLMs. I didn‚Äôt expect to find myself here, but taking a step back to reflect, I realize how much expertise I‚Äôve developed in this space ‚Äî and I‚Äôm incredibly excited to continue to share these learnings in upcoming articles. I‚Äôd love to hear from others about the challenges they‚Äôve encountered and the mitigation strategies or workarounds they‚Äôve found effective, whether related to these issues or new ones entirely. I hope these insights are helpful and spark further conversation around best practices in this quickly evolving field (where model versions and API versions deprecate a little too quickly).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/qwen-new-release-the-king-of-coder-is-qwen2-5-coder-32b-8b96d442b280","frontmatter":{"title":"Qwen New Release: The King of Coder is Qwen2.5 coder 32B!","meta_title":"Qwen New Release: The King of Coder is Qwen2.5 coder 32B!","description":"The article introduces Qwen2.5-Coder-32B-Instruct, a new AI coding model that outperforms existing open-source models, including GPT-4o, according to benchmark scores. It operates efficiently on a single GPU, achieving 32 tokens per second. The model is available under the Apache 2.0 license and is supported by Ollama for easy deployment. Smaller models are also available for users with limited computing resources. The integration of Qwen models with OpenWebUI enhances usability for daily tasks.","date":"2024-11-14T03:32:00.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OzrZMolY75t_cdux5UGtIg.png","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["Qwen2.5","Coder","32B","Instruct","GPU"],"draft":false,"slug":"blog/qwen-new-release-the-king-of-coder-is-qwen2-5-coder-32b-8b96d442b280"},"content":"\nGreat new everyone! Meet Qwen2\\.5\\-Coder\\-32B\\-Instruct: the latest AI model that‚Äôs taking the code world by storm!\n\n\n\nMost of these models are released under the Apache 2\\.0 license .Benchmark scores are through the roof:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aHeNvfOvcpME0qzy6EQexQ.jpeg)\n\nAs we can see, it‚Äôs the best among open source models and even beats the GPT\\-4o.\n\nOllama has already provided its support for several model series.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rV1xrpRXUjTFFoKwSsfeOg.png)\n\nSo it‚Äôs easy to run it.\n\n```python\nollama run qwen2.5-coder:32b\n```\n\nThe performance of the 32B (Q4 format) on one single GPU 3090 can be found from following screenshot:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MVQ0srQhRxX4Ifo3IqU6og.png)\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jtH3ixeeOQGfyDzmO4Ni3A.png)\n\nIt‚Äôs **32 tokens/s**! super fast. I am very happy and impressed.\n\nBesides the 32B model, the smaller models have shown impressive performance in terms of model size. If you do not have enough computing power, try some of the smaller models. For example, I tried the 14B model on the new Mac Mini with M4 processor and 16GB RAM.\n\nIn addition to benchmark scores, the cursor can now be integrated with the latest Qwen models, including Qwen 2\\.5\\-Coder\\-32B\\-Instruct \\& OpenWebUI.\n\nBelow is a screenshot of using Qwen 2\\.5\\-Coder\\-32B\\-Instruct(Ollama) with OpenWebUI:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*q-Pq3snVhkBs3e_Oxj4_Xw.png)\n\nI can‚Äôt wait to use it for my day to day works!\n\n\n"},{"lang":"en","group":"blog","slug":"blog/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84","frontmatter":{"title":"Qwen2.5 1.5b: the future of Mobile AI?","meta_title":"Qwen2.5 1.5b: the future of Mobile AI?","description":"Local Testing and Evaluation of Alibaba Cloud‚Äôs Latest LLM. With llama-cpp-python and a DIY prompt catalog.","date":"2024-10-30T12:57:39.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*awb56jkdXobA-Ip6d-QHRA.png","categories":["Natural Language Processing","Programming","Technology/Web"],"author":"Rifx.Online","tags":["Qwen2.5","NLP","summarization","retrieval","prompts"],"draft":false,"slug":"blog/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84"},"content":"\n### Local Testing and Evaluation of Alibaba Cloud‚Äôs Latest LLM. With llama\\-cpp\\-python and a DIY prompt catalog.\n\n\n\nIn part one we explored together the innovations from Alibaba Cloud‚Äôs team with the release of the Qwen2\\.5 models family.\n\nIn Generative AI benchmarks are now the main *oracle*: the validity of a new LLM needs to pass several verdicts. The more benchmark records you break, the better you are.\n\nIt is the way to win the SOTA race\n\nWell, I disagree. Even though for the AI advancement we need milestones and better performances, still the user experience and the personal point of view cannot be just put aside as irrelevant.\n\nI believe that exploring some frequently used NLP tasks, and putting aside the chat experience, we must focus on the quality of the replies. And we are the only benchmark required. Our user experience is the best indicator to understand if a model is good or not. The model must be reliable enough to be used in an automated workflow.\n\nBy the way, I already run what I decided to call [RBYF ‚Äî Revised Benchmarks with You as a Feedback](https://open.substack.com/pub/thepoorgpuguy/p/rbyf-is-here-revised-benchmarks-with?r=i78xo&utm_campaign=post&utm_medium=web) on the claimed amazing Llama3\\.2‚Äì1B\\-instruct‚Ä¶ and Qwen2\\.5‚Äì1\\.5b is so much better!\n\nSo in this article, as promised, we will verify with our own eyes how good is this model for every day use.\n\nBack to us‚Ä¶ Let‚Äôs get started!\n\n## Requirements\n\nHere we are going to build a minimal text interface to be able to run the model, test different tasks and wait for user feedback to evaluate it.\n\nThe requirements are minimal, but I suggest you to create a new project directory and a virtual environment.\n\nCreate a `venv` (python 3\\.11\\+ is required): I tested it on my Mini\\-PC running Windows 11\\.\n\n```python\n## create the virtual environment\npython -m venv venv\n## activate the venv\nvenv\\Scripts\\activate\n## Install the dependencies \npip install llama-cpp-python==0.3.0 tiktoken\n```\n\nWe need to download the GGUF file from the official qwen repository on Hugging Face [https://huggingface.co/Qwen/Qwen2\\.5\\-1\\.5B\\-Instruct\\-GGUF](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF): I used the `qwen2.5-1.5b-instruct-q5_k_m.gguf` version.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YtQJb_xyq_xcF40yRWPcZA.png)\n\nWe are all set!\n\nNote: if you want to add a different Backend support of a GPU accelerator, you can follow [the instructions in the repo](https://github.com/abetlen/llama-cpp-python#supported-backends). I used, for example, the Vulkan support so before the pip install I added the environment variable\n\n```python\n## Vulkan support - for Windows\n$env:CMAKE_ARGS = \"-DGGML_VULKAN=on\"\n```\n\n## The Code ‚Äî a main app and a library\n\nTo keep the code at minimum, I decided to extend some functionalities using an external library. Well, it is a Do It Yourself library, so there are no secrets here.\n\nYou can find all the details in my article here:\n\nAnd to speed it up you can directly [download the file from here](https://github.com/fabiomatricardi/YouAreTheBenchmark/raw/main/QWEN2.5-1.5B/promptLibv2Qwen.py): it contains a version 2 of the `promptLib` discussed in the mentioned above article (and it is called `promptLibv2Qwen.py`, with few fine tuning of the prompt specifically tailored for the `Qwen2.5-1.5B-instruct` model.\n\nSave the file in the main directory, and create a new file called `main.py`\n\n```python\n## Chat with an intelligent assistant in your terminal  \n## MODEL: https://huggingface.co/Qwen\n## qwen2.5-1.5b-instruct-q5_k_m.gguf\nimport sys\nfrom time import sleep\nimport warnings\nwarnings.filterwarnings(action='ignore')\nimport datetime\nfrom promptLibv2Qwen import countTokens, writehistory, createCatalog\nfrom promptLibv2Qwen import genRANstring, createStats\nimport argparse\n### PREPARING FINAL DATASET\npd_id = []\npd_task = []\npd_vote = []\npd_remarks = []\n####################Add GPU argument in the parser###################################\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-g\", \"--gpu\", type=int, default=0,nargs='?',\n                    help=\"The number of layers to load on GPU\")\nargs = parser.parse_args()\nif args.gpu == None:\n   ngpu_layers = 0 \nelse:\n    ngpu_layers = args.gpu\nprint(f'Selected GPU: offloading {ngpu_layers} layers...')   \n####################INITIALIZE THE MODEL###################################\nstops = ['<!im_end|>']\ntasks = createCatalog()\nmodelname = 'qwen2.5-1.5b-instruct-q5_k_m.gguf'\n## create THE LOG FILE \ncoded5 = genRANstring(5)\nlogfile = f'logs/Qwen2.5-1.5B-it_CPP_{coded5}_log.txt'\ncsvfile = f'logs/Qwen2.5-1.5B-it_CPP_{coded5}.csv'\nlogfilename = logfile\n#Write in the history the first 2 sessions\nwritehistory(logfilename,f'{str(datetime.datetime.now())}\\n\\nYour own LocalGPT with üíª {modelname}\\n---\\nüß†ü´°: You are a helpful assistant.')  \nwritehistory(logfilename,f'üíª: How can I assist you today in writing?')\n```\n\nHere we are only doing preparations: we import the libraries, including our own personal `promptLibv2Qwen` and also `argparse`. I wanted to try something new: [argparse](https://realpython.com/command-line-interfaces-python-argparse/) is a python library intended for terminal python program where you are reading multiple arguments from the command line.\n\nIn this case here we have only one argument (and no parameters) with th flag `-g` or even `--gpu`. When you run the python code with this argument we will set the number of GPU layers to the maximum (but you can change it yourself).\n\nThen we set some global variables, used across the entire code: the tasks, our prompt collection, the stop words and the log filename.\n\n> NOTE: all the logs are saved into a subdirectory called `logs`‚Ä¶ so make sure to create one.\n\nWe are also preparing all the relevant information to store them into a dataset and then save it at the end int a CSV file (for easily creating a performance matrix)\n\n```python\n### PREPARING FINAL DATASET\npd_id = []\npd_task = []\npd_vote = []\npd_remarks = []\n```\n\nWe then load the model into RAM (no GPU) or the VRAM (with GPU) using Llama\\-CPP\\-python.\n\n```python\n## LOAD THE MODEL\nprint(\"\\033[95;3;6m\")\nprint(\"1. Waiting 10 seconds for the API to load...\")\nfrom llama_cpp import Llama\nllm = Llama(\n            model_path='models/qwen2.5-1.5b-instruct-q5_k_m.gguf',\n            n_gpu_layers=ngpu_layers,\n            temperature=0.1,\n            n_ctx=8192,\n            max_tokens=1500,\n            repeat_penalty=1.178,\n            stop=stops,\n            verbose=False,\n            )\nprint(f\"2. Model {modelname} loaded with LlamaCPP...\")\nprint(\"\\033[0m\")  #reset all\nhistory = []\nprint(\"\\033[92;1m\")\nprint(f'üìùLogfile: {logfilename}')\n```\n\nBy the way, you can find all the code in my GitHub Repository:\n\nThe next one is a one\\-shot warm up inference: the model neural network is going to be activated for the first time, so think about it like a warm\\-up lap.\n\nDon‚Äôt be scared, I will explain the code\n\n```python\n##################### ALIGNMENT FIRST GENERATION ##############################################\nquestion = 'Explain the plot of Cinderella in a sentence.'\ntest = [\n    {\"role\": \"user\", \"content\": question}\n]\nprint('Question:', question)\nstart = datetime.datetime.now()\nprint(\"üíª > \", end=\"\", flush=True)\nfull_response = \"\"\nfisrtround = 0\nfor chunk in llm.create_chat_completion(\n    messages=test,\n    temperature=0.25,\n    repeat_penalty= 1.31,\n    stop=stops,\n    max_tokens=1500,\n    stream=True,):\n    try:\n        if chunk[\"choices\"][0][\"delta\"][\"content\"]:\n            if fisrtround==0:\n                print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]\n                ttftoken = datetime.datetime.now() - start  \n                fisrtround = 1\n            else:\n                print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]                            \n    except:\n        pass      \ndelta = datetime.datetime.now() - start\noutput = full_response\nprint('')\nprint(\"\\033[91;1m\")\nrating = input('Rate from 0 (BAD) to 5 (VERY GOOD) the quality of generation> ')\nprint(\"\\033[92;1m\")\nstats = createStats(delta,question,output,rating,logfilename,'Alignment Generation',ttftoken)\nprint(stats)\nwritehistory(logfilename,f'''üë®‚Äçüíª . {question}\nüíª > {output}\n{stats}\n''')\n```\n\nWe set the first user question and put into a well known chat format dictionary. Then we start our timer (useful for speed, token counts etc‚Ä¶).\n\nWe call the inference with the method `create_chat_completion()` that allows us to accept the prompts in chat format and stream the output one token at the time.\n\nBecause of the first reply from the model does not contain any output tokens (but only statistics) we use the try/except statement. Furthermore, since I want to know when the first token is generated, we raise a flag and stop temporary our time count saving the information inside the `ttftoken` variable.\n\nAt the end of the streaming we count the delta time from start, and wait the user to provide his/her personal feedback on the generated output: giving a mark from 0 to 5 and adding comments related to the compliance with the instruction prompt and user intent.\n\nWe use our internal library called `createStats()` to print all the statistics of the generation, and save them in our log file. The output of the function will be something like this:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8znYCqpisviXvYgrzjWF5w.png)\n\n## Prompt catalog ‚Äî what we want to test\n\nI wrote here about my habit. I have a catalog of prompts that covers many of the main language tasks used in chat\\-bots, like summarization, short summarization, casual chat, RAG, truthful RAG and so on.\n\nThe idea is to be able to load the model in 5 minutes, and start evaluating each task. At the end of every generation the user is prompted to give a mark (a score from 0 to 5\\) and leave any comments if required.\n\nThis is crucial: not all the models are alike, and small/big adjustments to the wording in the prompts are always required.\n\nSo back to the code‚Ä¶ Because the previous one was only a warm\\-up, now it will start the real while loop, iterating over the entire prompt catalog. See the workflow here below‚Ä¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*EL0Q97Du6HwtcYQZ.png)\n\nThere are only few changes in the code, and I will point them out, so bear with me.\n\n```python\n############################# AUTOMATIC PROMPTING EVALUATION  11 TURNS #################################\nid =1\nfor items in tasks:\n    fisrtround = 0\n    task = items[\"task\"]\n    prompt = items[\"prompt\"]\n    test = []\n    print(f'NLP TAKS>>> {task}')\n    print(\"\\033[91;1m\")  #red\n    print(prompt)\n    test.append({\"role\": \"user\", \"content\": prompt})\n    print(\"\\033[92;1m\")\n    full_response = \"\"\n    start = datetime.datetime.now()\n    print(\"üíª > \", end=\"\", flush=True)\n    for chunk in llm.create_chat_completion(\n        messages=test,\n        temperature=0.15,\n        repeat_penalty= 1.31,\n        stop=stops,\n        max_tokens=1500,\n        stream=True,):\n        try:\n            if chunk[\"choices\"][0][\"delta\"][\"content\"]:\n                if fisrtround==0:\n                    print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                    full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]\n                    ttftoken = datetime.datetime.now() - start  \n                    fisrtround = 1\n                else:\n                    print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                    full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]                            \n        except:\n            pass      \n    delta = datetime.datetime.now() - start\n    print('')\n    print(\"\\033[91;1m\")\n    rating = input('Rate from 0 (BAD) to 5 (VERY GOOD) the quality of generation> ')\n    print(\"\\033[92;1m\")\n    stats = createStats(delta,prompt,full_response,rating,logfilename,task,ttftoken)\n    print(stats)\n    writehistory(logfilename,f'''üë®‚Äçüíª > {prompt}\nüíª > {full_response}\n{stats}\n''')\n    pd_id.append(id)\n    pd_task.append(task)\n    pd_vote.append(rating[:2])\n    pd_remarks.append(rating[2:])\n    id += 1\n## create dataframe and save to csv\nzipped = list(zip(pd_id,pd_task,pd_vote,pd_remarks))\nimport pandas as pdd\ndf = pdd.DataFrame(zipped, columns=['#', 'TASK', 'VOTE','REMARKS'])\n#saving the DataFrame as a CSV file \ndf_csv_data = df.to_csv(csvfile, index = False, encoding='utf-8') \nprint('\\nCSV String:\\n', df_csv_data)  \n```\n\nThe main changes are only in the first lines:\n\n```python\nfor items in tasks:\n    fisrtround = 0\n    task = items[\"task\"]\n    prompt = items[\"prompt\"]\n```\n\nIf you read the article about the `promptLib` you shouldn‚Äôt be surprised: but if you are new, here we are iterating over a list of dictionaries with the following structure:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rGcKJWNzSUrcu4wi.png)\n\nSo for each items in the catalog (means a pair of tasks and prompts) we extract the task description and the prompt for the task.\n\n```python\ntest.append({\"role\": \"user\", \"content\": prompt})\n```\n\nThen we create the chat template message in a temporary list called `test` and pass it to the `create_chat_template()` method for generation.\n\nEverything else is the same.\n\nSave the file, and with the `venv` activated run:\n\n```python\npython main.py\n## if you are using the GPU python main.py -g\n```\n\nThis will get you something like the below example‚Ä¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MhhQu4lLjtU__Wjf0dSWBg.gif)\n\nNote that at the end of the entire Prompt Catalog a *csv* file is created with the summary of all the tasks!\n\n## Test Overview\n\nI run them with several Small Language Models, from [Qwen2‚Äì1\\.5B\\-instruct](https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF), to [Gemma2‚Äì2B\\-instruct](https://huggingface.co/bartowski/gemma-2-2b-it-GGUF), with [Llama3\\.2‚Äì1B\\-instruct](https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF) and finally the new [Qwen2\\.5‚Äì1\\.5B\\-instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF).\n\nWhile I was [quite disappointed by Llama3\\.2‚Äì1B\\-instruct](https://generativeai.pub/llama3-2-1b-instruct-is-ok-but-not-good-enough-28f88046b63e), I have been amazed by the good job done by the new [Qwen2\\.5‚Äì1\\.5B\\-instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF).\n\nAt the end of every generation the user is asked to evaluate the results with a mark from 0 to 5\\. **In this case the user is me‚Ä¶**\n\nThis kind of qualitative analysis is indeed poor, so every mark does have a description, and the user can add comments (‚Äúsome wrong information‚Äù, ‚Äúmaybe better change the wording in the prompt‚Äù )\n\nHere the qualitative matrix with a description\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eBdPfZtfr99MsvLh6tt42w.png)\n\n## The good and the bad ‚Äî details\n\nSummarization was amazing. Listing the main topics over a log text was also very good.\n\nThe RAG tasks were quite fast (even on my mini\\-PC) and truthful RAG (ask questions out of the context) was on spot.\n\nSo really good.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DuV3LJep_PuDqiCcAMb6Cg.png)\n\nThere were also few shortcomings: even with a temperature of only `0.15` I got some made up information in the summarize in two sentences task. And this is not good.\n\n> I expect this can be fixed with a little prompt tuning, or with a temperature at `0`.\n\nAnother fact is that the creative writing was quite bad: for the test I used some fixed Generation Parameters.\n\n```python\n        temperature=0.15,\n        repeat_penalty= 1.31,\n```\n\nProbably for creative writing, with Qwen2\\.5‚Äì1\\.5B\\-instruct, we should use an higher `repeat_penalty` and also a higher `temperature`.\n\nAs a side note I have to say that also the reflection prompt was not that bad at all! The opening/closure of the tags was not maintained (so not easy to put this into a pipeline or workflow) but the overall flow of the generation and the ‚ÄúChain of Thought‚Äù reasoning process was fairly good.\n\n```python\n<thinking>\nThe importance of using Generative Artificial Intelligence (AI) in \nteaching cannot be overstated, as this technology has immense potential \nnot only within current educational practices but also towards shaping a \nmore innovative approach to lifelong learning.\n</thinking>\n\n**Chain Of Thought:**\n1. **Understanding the Impact**: AI can automate repetitive tasks and provide \npersonalized feedback for students based on their performance data \n(e.g., through chatbots or adaptive assessments).\n2. **Enhancing Learning Experience**: By integrating Generative AI, \nteachers could create more engaging lessons that cater to diverse learning \nstyles.\n3. **Improving Student Outcomes**: Personalized instruction can lead to \nbetter understanding and retention of knowledge for students.\n\n**Reflection:**\n- The integration of generational technology in education is crucial as \nit aligns with the evolving needs of learners who are increasingly digital \nnatives, requiring a pedagogical approach that incorporates these technologies.\n</thinking>\n\n<output>\nTeachers should learn how Generative AI can be used to enhance their teaching \nmethods and improve student outcomes. This includes understanding its \ncapabilities for automating tasks like grading or creating personalized \nlearning paths.\n\n**Learning Path:**\n1. **Foundation Courses in Education Technology**: Start with courses \nthat provide an overview of educational technology, including the basics \nof digital tools.\n2. **AI Fundamentals Course (Coursera)** - Learn about AI concepts and \nhow they can be applied to education through Coursera's free online \ncourse on Artificial Intelligence for Educators.\n\n3. **Specialized Courses in Generative Learning**: Enroll in courses \nthat focus specifically on generational learning, such as \"Generative Design\" \nor similar specialized programs offered by universities like MIT.\n4. **Professional Development Workshops and Conferences** - Attend \nworkshops focused on integrating AI into teaching practices at local \neducational conferences.\n\n5. **Online Communities for Educators (e.g., Edmodo)**: Join online \ncommunities where educators discuss the use of generative technology \nin education, share resources, or ask questions about implementation.\n6. **Certification Programs**: Consider obtaining certifications that \nrecognize your knowledge and skills related to AI integration into teaching \npractices through organizations like Google's \"AI for Educators\" program.\n\nBy following this learning path, teachers can not only enhance their own \nprofessional development but also contribute positively towards the future \nof education by incorporating generative technology effectively.\n</output>\n```\n\nI think that for the size of this Small Language Model, the result is not bad at all!\n\n## Comparing Qwen2\\.5 with Llama3\\.2\n\nEven though this is only coming from my personal evaluation, I want to share it with you.\n\nBoth models are designed to be used on mobile devices, but the performance is quite different. Look here below:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*T6vLgvOKdkotlV1K5x6-QQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DuV3LJep_PuDqiCcAMb6Cg.png)\n\nFirst of all, the overall score difference is huge (41 for Llama3\\.2, 57 for Qwen2\\.5\\).\n\nSecondly if you think about what you may ask on a mobile device, in terms of language tasks, is to have a smooth chatting experience (task 4\\), good summarization (tasks five to 7\\) and some creative writing (task 11 and 13\\).\n\nIn terms of speed, running the model only on CPU, with a very limited mini\\-PC, **I got an average inference speed of 14 t/s.**\n\n## Conclusions\n\nIn the past three months since Qwen2‚Äôs release, numerous developers have built new models on the Qwen2 language models, providing valuable feedback to the entire community, but also to Alibaba Cloud.\n\n> During this period, we have focused on creating smarter and more knowledgeable language models. Today, we are excited to introduce the latest addition to the Qwen family: Qwen2\\.5\n\nTheir claims come with facts about the new family of models:\n\n* Dense, **easy\\-to\\-use**, decoder\\-only language models, available in 0\\.5B, 1\\.5B, 3B, 7B, 14B, 32B, and 72B sizes, and base and instruct variants.\n* Pretrained on our latest large\\-scale dataset, encompassing up to 18T tokens.\n* Significant improvements in **instruction following**\n* More **resilient to the diversity of system prompts**, enhancing role\\-play implementation and condition\\-setting for chatbots.\n* **Context length support up to 128K** tokens and can generate up to 8K tokens.\n* Multilingual support for over 29 languages\n\nIn my extensive (but certainly limited to one shot prompts and on few NLP tasks) tests I could see with my very own eyes that the claims were based on a good quality training dataset and curated fine tuning.\n\nThis model can perform extremely good on mobile devices!\n\n\n"},{"lang":"en","group":"blog","slug":"blog/qwen2-5-coder-32b-instruct-a-best-coding-model-a-complete-step-by-step-guide-and-performance-b8a33ec2547f","frontmatter":{"title":"Qwen2.5-Coder 32B Instruct: A Best Coding Model-A Complete Step-by-Step Guide and Performance‚Ä¶","meta_title":"Qwen2.5-Coder 32B Instruct: A Best Coding Model-A Complete Step-by-Step Guide and Performance‚Ä¶","description":"The article presents a comprehensive guide to the **Qwen2.5-Coder-32B-Instruct** model, highlighting its advanced coding capabilities and performance metrics. It emphasizes the model's powerful code generation, repair, and reasoning skills, which rival those of established models like GPT-4o. The guide outlines the model's diverse range, supporting over 40 programming languages and various sizes, catering to different developer needs. It includes practical examples for installation and usage, demonstrating the model‚Äôs effectiveness in real-world applications such as coding assistants and educational tools. The article concludes by affirming the model's role in enhancing AI-powered coding tasks.","date":"2024-11-14T03:29:09.000Z","image":"https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zjZmLCEX5URAc1wxTGnBRQ.png","categories":["Programming","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["Qwen2.5","Coder","programming","languages","repair"],"draft":false,"slug":"blog/qwen2-5-coder-32b-instruct-a-best-coding-model-a-complete-step-by-step-guide-and-performance-b8a33ec2547f"},"content":"\n# Qwen2.5-Coder 32B Instruct: A Best Coding Model-A Complete Step-by-Step Guide and Performance Evaluation for Developers\n\n\nPhoto By Author\n\n# Introduction\n\nIn the ever-evolving landscape of AI-powered programming tools, large language models (LLMs) have dramatically transformed the way developers write, debug, and optimize code. Today, we are thrilled to explore the **Qwen2.5-Coder** series, an open-source marvel that promises to set new standards in the realm of code generation and AI coding assistants. The latest release in this family, **Qwen2.5-Coder-32B-Instruct**, has redefined the state-of-the-art (SOTA) performance in open-source coding models, rivaling the capabilities of established models like **GPT-4o**. Let‚Äôs dive deeper into what makes Qwen2.5-Coder so ‚ÄúPowerful‚Äù, ‚ÄúDiverse‚Äù, and ‚ÄúPractical‚Äù.\n\nIn this comprehensive guide, we‚Äôll explore the core capabilities of the **Qwen2.5-Coder-32B** model. We‚Äôll demonstrate how to use it with the `transformers` library, test its coding abilities and highlight its practical applications.\n\n# Why Qwen2.5-Coder?\n\n## Key Highlights\n\n1. **Powerful**: The flagship **Qwen2.5-Coder-32B** model matches the coding prowess of GPT-4 on major coding benchmarks, while also excelling in general and mathematical skills.\n2. **Diverse**: The release covers multiple model sizes (0.5B, 1.5B, 3B, 7B, 14B, 32B), offering flexibility for different resource constraints.\n3. **Practical**: Designed for real-world applications, including code assistants and artifact generation. The models are licensed under **Apache 2.0**, ensuring freedom to use and modify for both commercial and research purposes.\n\n# The Qwen2.5-Coder Series: A Game-Changer for Open Code LLMs\n\nThe **Qwen2.5-Coder** series is dedicated to pushing the boundaries of open-source code generation. With a focus on flexibility and scalability, this release includes models in a range of sizes: **0.5B, 1.5B, 3B, 7B, 14B,** and the flagship **32B** version. These models cater to various developer needs, from lightweight, resource-efficient models to high-capacity, feature-rich models suitable for demanding applications.\n\n## 1. Powerful: Setting New Benchmarks in Code Generation\n\nQwen2.5-Coder-32B-Instruct stands as the flagship model, boasting a range of capabilities that have earned it the title of the **current SOTA open-source code model**. It excels in:\n\n* **Code Generation**: On popular benchmarks like **EvalPlus, LiveCodeBench,** and **BigCodeBench**, it matches the performance of GPT-4o, offering precise code generation across a multitude of scenarios.\n* **Code Repair**: Fixing broken or inefficient code is crucial in software development. On the **Aider benchmark**, which tests code repair skills, Qwen2.5-Coder-32B-Instruct scored an impressive **73.7**, rivaling GPT-4o‚Äôs prowess.\n* **Code Reasoning**: The ability to understand and reason through code execution paths is critical for debugging and optimizing complex software. This model‚Äôs capabilities extend beyond mere generation ‚Äî it excels at **predicting inputs and outputs**, making it an invaluable tool for software engineers.\n\n![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-g1ZGa0p2kKsQK4iD7q7cg.png)\nSource: (https://qwenlm.github.io/blog/qwen2.5-coder-family/)\n\n## 2. Diverse: Supporting Multiple Programming Languages and Rich Model Sizes\n\nThe versatility of Qwen2.5-Coder is evident in its support for over **40 programming languages**, including niche languages like **Haskell** and **Racket**. This broad support is backed by meticulous data cleaning and balanced training, ensuring the model performs optimally across different coding environments.\n\n* **Multi-language Code Repair**: Its proficiency extends to code repair in unfamiliar languages, which can significantly reduce the learning curve for developers exploring new technologies.\n* **Model Size Flexibility**: The Qwen2.5-Coder series offers models across six sizes, ensuring developers with varying resource constraints can find a model suited to their needs. The **scaling law** philosophy that underpins these models means that performance correlates positively with model size, giving developers the flexibility to choose the right balance between performance and computational resources.\n\n# Performance Insights: Evaluating Qwen2.5-Coder Models\n\n## 1. Instruct vs. Base Models\n\nQwen2.5-Coder is available in both **Base** and **Instruct** versions:\n\n* **Base models** are designed for developers who want a raw model to fine-tune for their specific applications.\n* **Instruct models** come pre-aligned and are optimized for interactive and conversational use cases, making them ideal for chat-based code assistants.\n\n## 2. Benchmark Comparisons: Leading the Pack\n\nAcross various core benchmarks:\n\n* **MBPP-3shot** was chosen to evaluate Base models, providing a robust metric to gauge their code comprehension and synthesis capabilities.\n* The **LiveCodeBench** questions set was used to evaluate Instruct models, focusing on their adaptability to new and unseen coding problems.\n\nThe results? **Qwen2.5-Coder consistently outperforms other open-source models**, proving that scaling up to larger sizes indeed correlates with better performance.\n\n# Hands-On Guide: Using Qwen2.5-Coder-3B for Code Generation with Transformers\n\nIn this hands-on tutorial, we will demonstrate how to use the **Qwen2.5-Coder-3B** model from the `transformers` library to generate code. This model is part of the **Qwen2.5-Coder series**, which is designed to excel in code generation, repair, and reasoning. By the end of this tutorial, you'll see how to integrate this powerful open-source model into your own projects for a range of code-related tasks.\n\n## Prerequisites\n\nBefore diving into the code, make sure you have the following installed:\n\n```\npip install torch transformers\n```\n\nAdditionally, ensure you have access to a GPU-enabled environment if you want to leverage the model‚Äôs performance optimally.\n\n## Step 1: Import Required Libraries\n\nWe‚Äôll start by importing the necessary components from the `transformers` library:\n\n```\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n```\n\nStep 2: Load the Model and Tokenizer\n\nIn this step, we load the ***Qwen2.5-Coder-32B-Instruct*** model and its corresponding tokenizer. The `device_map=\"auto\"` option will automatically allocate the model to your available GPU or CPU.\n\n> ***Qwen2.5-Coder has released models in various sizes ‚Äî 0.5B-Instruct, 1.5B-Instruct, 3B-Instruct, 7B-Instruct, 14B-Instruct, and 32B-Instruct ‚Äî on Hugging Face. If you want to run them locally, choose the model that best fits your GPU capacity. These models are also available on Ollama, so you can use them within the Ollama environment. If you‚Äôre interested in an Ollama tutorial, feel free to let me know in the comments!***\n\n```\nmodel_name = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n\n# Load the model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n```\n\n## Step 3: Writing a Chat Template Function\n\nThe Qwen2.5-Coder model is designed to handle conversation-like prompts using a chat template. The following helper function sets up the input prompt in a way that aligns with the model‚Äôs expectations:\n\n```\ndef generate_response(model, tokenizer, prompt):\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n    # Prepare the chat input\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    # Tokenize and prepare inputs\n    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n    # Generate response\n    generated_ids = model.generate(\n        **model_inputs,\n        max_new_tokens=512\n    )\n    # Remove prompt tokens from output\n    generated_ids = [\n        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n    ]\n  \n    # Decode and return the generated text\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    return response\n```\n\n## Step 4: Testing the Model with Code Generation\n\nLet‚Äôs run some examples to see how well the Qwen2.5-Coder-32B model performs in generating Python and Java code. We will test it with three different programming prompts.\n\n## Test 1: Quick Sort Algorithm\n\n**Prompt**: ‚ÄúWrite a quick sort algorithm.‚Äù\n\n```\nprompt_1 = \"write a quick sort algorithm.\"\nresponse_1 = generate_response(model, tokenizer, prompt_1)\nprint(response_1)\n```\n\nOutput:\n\nCertainly! Here's a simple implementation of the Quick Sort algorithm in Python:\n\n```python\ndef quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    return quick_sort(left) + middle + quick_sort(right)\n\n# Example usage:\narr = [3, 6, 8, 10, 1, 2, 1]\nprint(quick_sort(arr))\n```\n\nThis code defines a `quick_sort` function that takes an array as input and returns a sorted version of the array using the Quick Sort algorithm. The function works by selecting a pivot element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted. The base case for the recursion is when the array has one or no elements, in which case it is already sorted.\n\nYou can use this code as a starting point and modify it according to your specific needs. Let me know if you have any further questions or if you need help with anything else!<|fim_middle|>\n\n\n## Test 2: Factorial of a Number\n\n**Prompt**: ‚ÄúWrite a Python program to find a factorial of a number.‚Äù\n\n\nprompt_2 = \"Write a python program to find a factorial of a number.\"\nresponse_2 = generate_response(model, tokenizer, prompt_2)\nprint(response_2)\n\n```\nOutput:\n```\n\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\nCertainly! Here's a Python program that calculates the factorial of a number:\n\n```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n - 1)\n\n# Example usage\nnumber = int(input(\"Enter a number: \"))\nresult = factorial(number)\nprint(f\"The factorial of {number} is {result}\")\n```\n\nThis program defines a recursive function `factorial` that calculates the factorial of a given number `n`. It uses the base case `n == 0` to return 1, and for other values of `n`, it recursively calls itself with `n - 1` until it reaches the base case. Finally, the program prompts the user to enter a number and displays the factorial of that number.\n\n```\n## Test 3: Formatting Numbers with Commas\n\n**Prompt**: ‚ÄúWrite a Python function named ‚Äòformat\\_number‚Äô that takes a non-negative number as its only parameter. Your function should convert the number to a string and add commas as a thousand separators.‚Äù\n```\n\nprompt_3 = \"\"\"Write a python function named 'format_number' that takes a non-negative number as its only parameter.\nYour function should convert the number to a string and add commas as a thousand separators.\nFor example, calling format_number(1000000) should return '1,000,000'.\"\"\"\nresponse_3 = generate_response(model, tokenizer, prompt_3)\nprint(response_3)\n\n```\nOutput:\n```\n\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\nCertainly! Here's a Python function that accomplishes this task:\n\n```python\ndef format_number(num):\n    # Convert the number to a string\n    num_str = str(num)\n  \n    # Initialize an empty string to store the formatted number\n    formatted_num = ''\n  \n    # Initialize a counter for the number of digits\n    digit_count = 0\n  \n    # Iterate over the digits in reverse order\n    for i in range(len(num_str) - 1, -1, -1):\n        # Add the current digit to the formatted number\n        formatted_num = num_str[i] + formatted_num\n      \n        # Increment the digit count\n        digit_count += 1\n      \n        # If the digit count is a multiple of 3, add a comma\n        if digit_count % 3 == 0 and i != 0:\n            formatted_num = ',' + formatted_num\n  \n    return formatted_num\n```\n\nYou can test the function with the following code:\n\n```python\nprint(format_number(1000000))  # Output: '1,000,000'\nprint(format_number(123456789))  # Output: '123,456,789'\nprint(format_number(1234567890))  # Output: '1,234,567,890'\n```\n\nThis function works by iterating over the digits of the number in reverse order, adding each digit to the formatted number and adding a comma every third digit. The function then returns the formatted number as a string.\n\n```\n## Test 4: Java Implement a Stack Using Arrays\n\n**Prompt**: ‚ÄúWrite a Java program, Implement a Stack Using Arrays‚Äù\n```\n\nprompt_4 = \"\"\"Write a Java program, Implement a Stack Using Arrays.\"\"\"\nresponse_4 = generate_response(model, tokenizer, prompt_3)\nprint(response_4)\n\n```\nOutput:\n```\n\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\nCertainly! Here's a simple Java program that implements a stack using arrays:\n\n```java\npublic class StackUsingArrays {\n    private int[] stackArray;\n    private int top;\n    private int capacity;\n\n    public StackUsingArrays(int size) {\n        stackArray = new int[size];\n        top = -1;\n        capacity = size;\n    }\n\n    public void push(int item) {\n        if (isFull()) {\n            System.out.println(\"Stack is full. Cannot push item: \" + item);\n        } else {\n            top++;\n            stackArray[top] = item;\n            System.out.println(\"Pushed item: \" + item);\n        }\n    }\n\n    public int pop() {\n        if (isEmpty()) {\n            System.out.println(\"Stack is empty. Cannot pop item.\");\n            return -1;\n        } else {\n            int item = stackArray[top];\n            top--;\n            return item;\n        }\n    }\n\n    public boolean isEmpty() {\n        return top == -1;\n    }\n\n    public boolean isFull() {\n        return top == capacity - 1;\n    }\n\n    public static void main(String[] args) {\n        StackUsingArrays stack = new StackUsingArrays(5);\n\n        stack.push(10);\n        stack.push(20);\n        stack.push(30);\n\n        System.out.println(\"Popped item: \" + stack.pop());\n        System.out.println(\"Popped item: \" + stack.pop());\n\n        stack.push(40);\n        stack.push(50);\n\n        System.out.println(\"Popped item: \" + stack.pop());\n        System.out.println(\"Popped item: \" + stack.pop());\n        System.out.println(\"Popped item: \" + stack.pop());\n    }\n}\n```\n\nThis program defines a `StackUsingArrays` class that uses an array to implement a stack. The `push` method adds an item to the top of the stack, and the `pop` method removes and returns the item at the top of the stack. The `isEmpty` and `isFull` methods check if the stack is empty or full, respectively. The `main` method demonstrates how to use the stack by pushing and popping items.\n\n```\n## Test 5: Simple classification algorithm\n\n**Prompt**: ‚ÄúWrite a Python code to run a simple classification algorithm using Sklearn‚Äù\n```\n\nprompt_5 = \"\"\"Write a Python code to run a simple classification algorithm using Sklearn\"\"\"\nresponse_5 = generate_response(model, tokenizer, prompt_3)\nprint(response_5)\n\n```\nOutput:\n```\n\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\nCertainly! Here's a simple example of a classification algorithm using the `sklearn` library in Python:\n\n```python\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Generate some sample data\nnp.random.seed(42)\nX = np.random.rand(100, 2)  # 100 samples, 2 features\ny = np.random.choice([0, 1], size=100)  # Binary classification\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a logistic regression model\nmodel = LogisticRegression()\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Calculate the accuracy of the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n```\n\nThis code generates some sample data, splits it into training and testing sets, trains a logistic regression model, makes predictions on the test set, and calculates the accuracy of the model. Feel free to modify the code to suit your specific needs.\n\n```\nMore details:\n\n[Qwen/Qwen2.5-Coder-32B-Instruct ¬∑ Hugging FaceWe're on a journey to advance and democratize artificial intelligence through open source and open science.huggingface.co](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)\n\n[qwen2.5-coder:32bThe latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and‚Ä¶ollama.com](https://ollama.com/library/qwen2.5-coder:32b)\n\n# Step 5: Analyzing the Model‚Äôs Performance\n\nFrom our tests, the ***Qwen2.5-Coder-32B-Instruct*** model demonstrates:\n\n* **Strong code generation capabilities**, producing efficient, human-readable solutions for classic coding problems.\n* **Understanding of Python syntax and best practices**, especially when it comes to using Pythonic solutions like list comprehensions and formatted strings.\n* **Flexibility** in adapting to a variety of prompts, which is essential for real-world programming assistant use cases.\n\n# Potential Use Cases\n\nGiven its performance, the Qwen2.5-Coder model can be effectively used in various scenarios, such as:\n\n* **Coding assistants**: Integration into IDEs or text editors to help developers write code faster.\n* **Automated code reviews**: Assisting in identifying bugs, optimizing code, and suggesting improvements.\n* **Educational tools**: Helping students learn to code by generating example solutions and explanations.\n\n# Conclusion\n\nThe **Qwen2.5-Coder** series, particularly the **32B model**, offers a powerful and versatile tool for developers, researchers, and organizations looking to leverage AI for code-related tasks. Its strong performance on benchmarks like EvalPlus, Aider, and McEval proves its competitive edge in code generation, repair, and reasoning.\n\nBy open-sourcing these models, Alibaba Cloud is paving the way for a future where AI-powered coding assistants are accessible to everyone. Whether you‚Äôre a developer looking to automate repetitive tasks or a student aiming to learn new programming concepts, Qwen2.5-Coder is a reliable tool to add to your arsenal.\n```\n\n```\n\n```\n\n\n\n"},{"lang":"en","group":"blog","slug":"blog/qwen2-5-coder-cosmos-tokenizer-opencoder-and-new-sentencetransformers-great-times-for-open-ffcacf2b29cd","frontmatter":{"title":"Qwen2.5-Coder, Cosmos Tokenizer, OpenCoder, and New SentenceTransformers: Great Times for Open‚Ä¶","meta_title":"Qwen2.5-Coder, Cosmos Tokenizer, OpenCoder, and New SentenceTransformers: Great Times for Open‚Ä¶","description":"The article discusses significant advancements in open-source technology, highlighting four key projects: the Qwen2.5-Coder series, Cosmos Tokenizer, OpenCoder, and SentenceTransformers. Qwen2.5-Coder offers a competitive alternative to GPT-4 in code generation and debugging, while Cosmos Tokenizer enhances image and video compression using neural tokenizers. OpenCoder, trained on 2.5 trillion tokens, provides comprehensive resources for code model development. Lastly, SentenceTransformers achieves a 4x CPU inference speedup via OpenVINO's quantization, optimizing NLP tasks. These developments underscore the ongoing evolution and practical applications of open-source tools in AI and coding.","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*IZdOavxT_8SRCxrg","categories":["Programming","Technology","Natural Language Processing"],"author":"Rifx.Online","tags":["Qwen2.5-Coder","Cosmos","OpenCoder","SentenceTransformers","OpenVINO"],"draft":false,"slug":"blog/qwen2-5-coder-cosmos-tokenizer-opencoder-and-new-sentencetransformers-great-times-for-open-ffcacf2b29cd"},"content":"\n\n\n\nI want to highlight some standout open\\-source advancements that have really caught my eye:\n\n* **Qwen2\\.5\\-Coder Series**: An open\\-source code LLM that‚Äôs giving GPT\\-4 a run for its money.\n* **Cosmos Tokenizer**: An advanced suite of neural tokenizers for efficient image and video compression.\n* **OpenCoder**: A fully open\\-source code LLM trained on an astonishing 2\\.5 trillion tokens.\n* **Massive CPU Speedup in SentenceTransformers**: A 4x speed boost on CPU inference using OpenVINO‚Äôs int8 static quantization.\n\nLet‚Äôs dive in!\n\n\n## Qwen2\\.5\\-Coder Series: Open\\-Sourcing a SOTA Code LLM Rivaling GPT\\-4\n\nAlibaba Cloud announced the open\\-source release of the Qwen2\\.5\\-Coder series ‚Äî models that are **Powerful**, **Diverse**, and **Practical** ‚Äî dedicated to propelling the evolution of open code large language models (LLMs).\n\nThe flagship model, **Qwen2\\.5\\-Coder\\-32B\\-Instruct**, sets a new benchmark as the state\\-of\\-the\\-art (SOTA) open\\-source code model, matching the coding capabilities of GPT\\-4\\. It excels in general\\-purpose and mathematical reasoning.\n\n\n\nExpanding upon previous releases of 1\\.5B and 7B models, they introduced four additional model sizes: 0\\.5B, 3B, 14B, and 32B. Qwen2\\.5\\-Coder now accommodates a wide spectrum of developer requirements, covering six mainstream model sizes.\n\nThey have also explored the applicability of Qwen2\\.5\\-Coder in real\\-world scenarios, including code assistants and artifact generation.\n\nPractical examples highlight the model‚Äôs potential in enhancing developer productivity and code quality.\n\n**Benchmark Achievements**\n\n* **Code Generation**: The Qwen2\\.5\\-Coder\\-32B\\-Instruct model achieves top\\-tier performance on popular code generation benchmarks such as EvalPlus, LiveCodeBench, and BigCodeBench.\n* **Code Repair**: Recognizing the importance of debugging in software development, Qwen2\\.5\\-Coder\\-32B\\-Instruct excels in code repair tasks. Scoring 73\\.7 on the Aider benchmark, it performs comparably to GPT\\-4, aiding developers in efficiently fixing code errors.\n* **Code Reasoning**: The model exhibits advanced code reasoning abilities, learning code execution processes and accurately predicting inputs and outputs. Building upon the impressive performance of Qwen2\\.5\\-Coder\\-7B\\-Instruct, the 32B model further elevates reasoning capabilities.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fzH6YE-yl_GrEXwz)\n\n* **Multi\\-Language Support**: Qwen2\\.5\\-Coder\\-32B\\-Instruct is proficient in over 40 programming languages. It scores 65\\.9 on McEval, showing remarkable performance in languages like Haskell and Racket, thanks to unique data cleaning and balancing strategies during pre\\-training.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rhyc0T3UZp_2x0r2)\n\nYou can find more info on [github](https://proxy.rifx.online/https://github.com/QwenLM/Qwen2.5-Coder).\n\n\n## Cosmos Tokenizer: Advanced Neural Tokenizers for Efficient Image and Video Compression\n\nThe **Cosmos Tokenizer** is a comprehensive suite of neural tokenizers designed for images and videos.\n\nYou can now convert raw visual data into efficient, compressed representations.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*v8k8jLbZ4LYFRUBc.jpg)\n\nBy discovering latent spaces through unsupervised learning, these tokenizers facilitate large\\-scale model training and reduce computational demands during inference.\n\n**Types of Tokenizers**:\n\n* **Continuous Tokenizers**: Map visual data to continuous embeddings, suitable for models sampling from continuous distributions like Stable Diffusion.\n* **Discrete Tokenizers**: Map visual data to quantized indices, used in models like VideoPoet that rely on cross\\-entropy loss for training.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*a6Hvj8hXJUpOAp9Ber781g.png)\n\n**Key Features**:\n\n* **High Compression with Quality Preservation**: Balances significant compression rates with high\\-quality reconstruction, preserving essential visual details in the latent space.\n* **Lightweight Temporally Causal Architecture**: Utilizes causal temporal convolution and attention layers to maintain the chronological order of video frames, enabling seamless tokenization for both images and videos.\n* **Training on Diverse Data**: Trained on high\\-resolution images and long videos across various aspect ratios and categories, making it agnostic to temporal length during inference.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lBO1omEzlr18SPB1zF-vMw.png)\n\n**Performance Highlights**:\n\n* **Superior Compression Rates**: Offers remarkable compression capabilities with speeds up to **12x faster** than previous methods.\n* **High\\-Quality Reconstruction**: Delivers significant gains in Peak Signal\\-to\\-Noise Ratio (PSNR), outperforming existing methods by over **\\+4 dB** on the DAVIS video dataset.\n* **Efficient Tokenization**: Capable of encoding up to **8\\-second 1080p** and **10\\-second 720p** videos on NVIDIA A100 GPUs with 80GB memory.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uYQttZw-MDOCK3oxxLcHbw.png)\n\n**Evaluation and Resources**:\n\n* **TokenBench Dataset** is a new dataset curated for standardizing video tokenizer evaluation, covering categories like robotics, driving, and sports.\n* **Public Availability**: Pretrained models with spatial compressions of 8x and 16x, and temporal compressions of 4x and 8x, are available at [GitHub ‚Äî NVIDIA/Cosmos\\-Tokenizer](https://proxy.rifx.online/https://github.com/NVIDIA/Cosmos-Tokenizer).\n\nMore information on [NVIDIA‚Äôs official blog post](https://proxy.rifx.online/https://research.nvidia.com/labs/dir/cosmos-tokenizer/).\n\n\n> *Thank you for taking your time to be here!*\n\n\n> *If you are enjoying the post, please take a moment to [**follow us on Medium**](https://proxy.rifx.online/https://medium.com/@datadrifters/subscribe), clap this article 50 times and leave a comment.*\n\n\n> *We are also running a cohort\\-based training **[for building full\\-stack GenAI SaaS applications](https://proxy.rifx.online/https://forms.gle/8mfFH4wjhF7BbtRY9)**, would be happy to see you inside too!*\n\n\n## OpenCoder: A Fully Open\\-Source Code LLM Trained on 2\\.5T Tokens\n\n**OpenCoder** introduces a new family of open\\-source code language models, including base and chat models at **1\\.5B** and **8B** parameter scales.\n\nSupporting both English and Chinese languages, OpenCoder is trained from scratch on an extensive dataset of **2\\.5 trillion tokens**, comprising 90% raw code and 10% code\\-related web data.\n\nThe model reaches performance levels comparable to leading code LLMs.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5rd863dHI-W_2ei7.png)\n\n**Key Contributions**:\n\n* The team provides model weights, inference code, training data, data processing pipelines, and detailed training protocols, empowering researchers and practitioners to build upon and innovate.\n* They also introduced **RefineCode dataset**, a high\\-quality, reproducible code pre\\-training corpus containing **960 billion tokens** across **607 programming languages**.\n\nMore information on [official announcement](https://proxy.rifx.online/https://opencoder-llm.github.io/).\n\n\n## SentenceTransformers Accelerates CPU Inference with 4x Speed Boost\n\nThe latest release of **SentenceTransformers** introduces significant performance enhancements, delivering up to a **4x speedup** on CPU inference using **OpenVINO‚Äôs int8 static quantization**.\n\nThis update optimizes both training and inference workflows for developers working with large\\-scale natural language processing tasks.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Pd9ESPxjKHaHVgV15pCQig.png)\n\n**Key Enhancements**:\n\n* **OpenVINO int8 Static Quantization**: Leveraging OpenVINO‚Äôs quantization techniques, the model achieves superior inference speeds with minimal loss in accuracy. This optimization outperforms existing backends, enhancing deployment efficiency on CPU architectures.\n* **Prompt\\-Based Training**: Supports training with prompts, offering a straightforward method for performance boosts without additional computational overhead.\n* **Convenient Evaluation on NanoBEIR**: Facilitates quicker assessments of model performance using NanoBEIR, a subset of the robust Information Retrieval benchmark BEIR.\n* **PEFT Compatibility**: Now supports **Parameter\\-Efficient Fine\\-Tuning (PEFT)** by allowing easy addition and loading of adapters, enabling more efficient model customization.\n\nYou can find more info on [github](https://proxy.rifx.online/https://github.com/UKPLab/sentence-transformers/releases/tag/v3.3.0).\n\n\n## Bonus Content : Building with AI\n\nAnd don‚Äôt forget to have a look at some practitioner resources that we published recently:\n\nThank you for stopping by, and being an integral part of our community.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/rag-llm-and-pdf-conversion-to-markdown-text-with-pymupdf-03af00259b5d","frontmatter":{"title":"RAG/LLM and PDF: Conversion to Markdown Text with PyMuPDF","meta_title":"RAG/LLM and PDF: Conversion to Markdown Text with PyMuPDF","description":"Data feeding in markdown text format increases generated text quality","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*swPjVuudAhsoRiiw3Ee32w.png","categories":["Programming","Technology","Technology/Web"],"author":"Rifx.Online","tags":["markdown","PyMuPDF","LLM","RAG","PDF"],"draft":false,"slug":"blog/rag-llm-and-pdf-conversion-to-markdown-text-with-pymupdf-03af00259b5d"},"content":"\n\n\n\n\n### Data feeding in markdown text format increases generated text quality\n\n\n\n\n## Introduction\n\nIn the context of **Large Language Models (LLMs)** and **Retrieval-Augmented Generation (RAG)** environments, data feeding in **markdown text format** holds **significant importance**. Here are some detailed considerations.\n\n**LLMs** are powerful language models that can generate coherent and contextually relevant text. However, they may sometimes produce responses that lack factual accuracy or context. By incorporating retrieval-based methods (like RAG), we can enhance the quality of generated text.\n\n**RAG** enables the integration of **external data** ‚Äî previously absent in the LLM‚Äôs training data ‚Äî into the text generation process. This inclusion mitigates ‚Äúhallucination issues‚Äô‚Äô and enhances the relevance of text responses.\n\n\n## Why Markdown for LLM?\n\n**Markdown** is a lightweight markup language that allows users to format plain text using simple syntax. It is widely used for creating structured documents, especially on platforms like GitHub, Jupyter notebooks, and various content management systems. When feeding data into an LLM or RAG system, using markdown format provides several benefits:\n\n1. **Structured Content**: Markdown allows you to organize information into headings, lists, tables, and other structured elements. This structure aids in better understanding and context preservation.\n2. **Rich Text**: Markdown supports basic formatting such as bold, italics, links, and code blocks. Including rich text in the input data enhances the context for the language model.\n3. **Embedding Links and References**: Markdown lets you embed hyperlinks, footnotes, and references. In RAG scenarios, this can be crucial for referring to external sources or providing additional context.\n4. **Ease of Authoring**: Markdown is human-readable and easy to write. Authors can create content efficiently without complex formatting tools.\n5. **Chunking**: Essential for RAG systems, chunking (otherwise known as ‚Äúsplitting‚Äù) breaks down extensive documents for easier processing. With PyMuPDF data extraction available in MD format we support chunking to keep text with common context together. **Importantly, PyMuPDF extraction in MD format allows for [Level 3 chunking](https://readmedium.com/five-levels-of-chunking-strategies-in-rag-notes-from-gregs-video-7b735895694d#b123)**.\n\nIn summary, using markdown text format in LLM and RAG environments ensures more accurate and relevant results because it supplies richer data structures and more relevant data chunk loads to your LLM.\n\n\n## PyMuPDF Support for Markdown Conversion of a PDF\n\nSince its inception, PyMuPDF has been able to extract text, images, vector graphics and, since August 2023, tables from PDF pages. Each of these object types has its own extraction method: there is one for text, and yet others for tables, images and vector graphics. To meet the requirements of RAG, we merged these disparate extractions to produce one common, unified **Markdown** string which consistently represents the page‚Äôs content as a whole.\n\nAll this is implemented as [one Python script](https://github.com/pymupdf/RAG/blob/main/helpers/pymupdf_rag.py). It can be imported as a module by some other script, or be invoked as a line command in a terminal window like this:\n\n`$ python pymupdf_rag.py input.pdf [-pages PAGES]`\n\nIt will produce a text file (called `input.md`) in **Markdown** format. The optional parameter `PAGES` allows restricting the conversion to a subset of the PDF‚Äôs total pages. If omitted, the full PDF is processed.\n\n\n## Markdown Creation Details\n\n\n### Selecting Pages to Consider\n\nThe ‚Äú`-pages`‚Äù parameter is a string consisting of desired page numbers (1-based) to consider for markdown conversion. Multiple page number specifications can be given, separated by commas. Each specification either is one integer or two integers separated by a ‚Äú`-`‚Äù hyphen, specifying a range of pages. Here is an example:\n\n‚Äú`-pages 1‚Äì10,15,20-N`‚Äù\n\nThis would include pages 1 through 10, 15 and pages 20 through the end of the file (capital ‚ÄúN‚Äù is treated as the number of the last page).\n\n\n### Identifying Headers\n\nUpon invocation, the program examines all text on the given pages and finds the most frequently used font size. This value (and all smaller font sizes) is assumed to represent **body text**. Larger font sizes are assumed to represent **header text**.\n\nDepending on their relative position in the font size hierarchy, header text will be prefixed with one or more markdown header `#`-tag characters.\n\n\n### Identifying the Processing Mode per Page Area\n\nAll text on each page will first be classified as being either **standard** text or **table** text. Then the page content will be extracted from top to bottom converting everything to markdown format.\n\nThis is best explained by an example:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*u5fv2aAIvDaaAd6H.png)\n\nThis page shows content, that represents typical situations:\n\n* Two tables, having partly overlapping vertical positions. One table has no headers, the other one has **external** column headers.\n* There is a **title** line and **headers** at multiple levels.\n* The **body text** contains a variety of styling details like **bold**, *italic* and `inline code`.\n* Ordered and unordered lists.\n* Code snippet.\n\nLayout analysis will determine three areas and select the appropriate processing modes: **(1)** text, **(2)** table, **(3)** text.\n\nThe generated Markdown text reflects the above faithfully ‚Äî as much as at all possible in this format.\n\nFor an example, let us look at the output for the table with external headers:\n\n\n```python\n|Column1|Column2|\n\n|---|---|\n\n|Cell (0, 0)|Cell (0, 1)|\n\n|Cell (1, 0)|Cell (1, 1)|\n\n|Cell (2, 0)|Cell (2, 1)|\n```\nThis is GitHub-compatible format with the minimum possible token size ‚Äî an important aspect for keeping feeds into RAG systems small.\n\n**Column borders** are indicated by the ‚Äú`|`‚Äù character. A text line is assumed to be a **table header** if it is followed by a line of the form ‚Äú`|---|---| ‚Ä¶`‚Äù. The full **table definition** must be preceded and followed by at least one empty line.\n\nPlease note that for technical reasons markdown tables must have a header and thus will choose the first table row if no external header is available.\n\nTo confirm overall fidelity, here is how a Markdown parser processes the full page:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Ge83uj7FiM4T6XFn)\n\n\n## Invoking the Markdown Converter Programmatically\n\nInstead of executing a program in the command line, Markdown conversion can also be requested by a program:\n\n\n```python\nimport fitz\nfrom pymupdf_rag import to_markdown  # import Markdown converter\n\ndoc = fitz.open(‚Äúinput.pdf‚Äù)  # open input PDF\n\n## define desired pages: this corresponds ‚Äú-pages 1-10,15,20-N‚Äù\npage_list = list(range(9)) + [14] + list(range(19, len(doc) ‚Äì 1))\n\n## get markdown string for all pages\nmd_text = to_markdown(doc, pages=page_list)\n\n## write markdown string to some file\noutput = open(‚Äúout-markdown.md‚Äù, ‚Äúw‚Äù)\noutput.write(md_text)\noutput.close()\n```\n\n## Conclusion\n\nBy integrating PyMuPDF‚Äôs extraction methods, the content of PDF pages will be faithfully converted to markdown text that can be used as input for RAG chatbots.\n\nRemember, the key to a successful RAG chatbot lies in the quality and completeness of information it can access.\n\nPyMuPDF-enabled markdown extraction ensures that this information from PDFs is not only possible but straightforward, showcasing the library‚Äôs strength and developer-friendliness. Happy coding!\n\n\n### Source Code\n\n* [RAG/helpers/pymupdf\\_rag.py (github.com)](https://github.com/pymupdf/RAG/blob/main/helpers/pymupdf_rag.py)\n\n\n### References\n\n* [5 Levels of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n\n\n### Related Blogs\n\n* [Building a RAG Chatbot GUI with the ChatGPT API and PyMuPDF](https://readmedium.com/building-a-rag-chatbot-gui-with-the-chatgpt-api-and-pymupdf-9ea8c7fc4ab5)\n* [Creating a RAG Chatbot with ChatGPT and PyMUPDF](https://readmedium.com/creating-a-rag-chatbot-with-chatgpt-and-pymupdf-f6c30907ae27)\n* [RAG/LLM and PDF: Enhanced Text Extraction](https://readmedium.com/rag-llm-and-pdf-enhanced-text-extraction-5c5194c3885c)\n\n"},{"lang":"en","group":"blog","slug":"blog/ragate-adaptive-rag-for-conversational-ai-94b5ca469b7d","frontmatter":{"title":"RAGate: Adaptive RAG for Conversational AI","meta_title":"RAGate: Adaptive RAG for Conversational AI","description":"RAGate is an adaptive mechanism for conversational AI that optimally balances the use of internal and external knowledge, enhancing response quality and engagement. By evaluating when to retrieve external information versus relying on built-in knowledge, RAGate addresses the limitations of traditional RAG systems, such as over-reliance on external sources and increased latency. The paper outlines the implementation of RAGate, including its variants and evaluation methods, emphasizing its potential to improve user interactions across various industries by delivering more relevant and personalized responses.","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8wzI-5BRV1-br0e3MBVD2g.png","categories":["Chatbots","Natural Language Processing","Machine Learning"],"author":"Rifx.Online","tags":["RAGate","conversational","retrieval","latency","personalization"],"draft":false,"slug":"blog/ragate-adaptive-rag-for-conversational-ai-94b5ca469b7d"},"content":"\n\n\n\nBuilding Conversational AI systems is hard!!!\n\nIt‚Äôs feasible but also **complex, time\\-consuming, and resource\\-intensive**.\n\nThe challenge lies in designing systems that can understand and generate human\\-like responses and ensuring that these systems engage users effectively, adapting to the nuances of conversation.\n\nThe very popular **RAG (Retrieval\\-Augmented Generation)** has revolutionized conversational AI by seamlessly integrating external knowledge with LLM‚Äôs internal knowledge. By using RAG with your business data, your customers can ask questions about their data in natural language, facilitating a seamless interaction.\n\n**However, there is a caveat:** While using RAG, it becomes clear that not every query needs an answer sourced from ‚Äúexternal knowledge.‚Äù Over\\-reliance on external sources can disrupt genuine engagement. It‚Äôs like having a conversation with someone and, for every question, reaching for a book to craft your response, even though you already have a deeper understanding of the topic. Even worse, you can‚Äôt find any book on the topic and end up responding with ‚ÄúI don‚Äôt know,‚Äù despite having internal knowledge that could provide a more insightful answer.\n\nClearly, while using RAG, a mechanism is needed to determine when to utilize ‚Äúexternal knowledge‚Äù versus ‚Äúinternal knowledge‚Äù at the inference time.\n\nEnter **RAGate** ‚Äî a binary switch designed to dynamically evaluate when to utilize external knowledge and when to rely on internal insights. Introduced by Xi Wang, Procheta Sen, Ruizhe Li, and Emine Yilmaz, and published in July 2024, [**ArXiv**](https://proxy.rifx.online/https://arxiv.org/abs/2407.21712) **(Adaptive Retrieval\\-Augmented Generation for Conversational Systems).**\n\nLet‚Äôs learn more with examples.\n\n\n## What is Conversational AI, really?\n\n**Conversation** is the exchange of thoughts, emotions, and information between individuals, adapting to tone, context, and subtle cues that guide the interaction. Humans are naturally suited for conversation due to qualities like emotional intelligence, socialization, and cultural exposure, which help us understand nuances and adapt to different social contexts.\n\n**Conversational AI** aims to replicate this human\\-like interaction by using technology to understand and generate natural, contextually appropriate, and engaging responses. It adapts to user inputs, making the interaction fluid and dynamic, like a conversation between humans.\n\n\n## What is External Knowledge and Internal Knowledge of AI systems?\n\nIn the opening paragraph, I mentioned two key terms ‚Äî External Knowledge and Internal Knowledge. Let‚Äôs take a moment to clarify these concepts, as understanding them will make learning about RAGate much easier.\n\n**External knowledge** encompasses information not inherent to the AI model but retrieved from outside sources. The sources include databases like structured data repositories, APIs, unstructured knowledgebases like guides, FAQs, and web sources. The primary role of external knowledge is to provide factual, up\\-to\\-date, and contextually relevant information that enhances the accuracy and comprehensiveness of the AI‚Äôs responses.\n\n**Internal knowledge** refers to the built\\-in\\-knowledge and processing capabilities embedded within the AI model based on its training data. The sources include pre\\-trained knowledge from diverse datasets, including language patterns, grammar, shared facts, and general world knowledge, contextual awareness from memory of past interactions, and AI‚Äôs semantic understanding and comprehension abilities.\n\n\n## RAG and Guardrails ‚Äî powerful duo, but with limitations!\n\nRAG combines two powerful elements: (1\\) The natural language processing abilities of large language models (LLMs) to interpret and generate human\\-like text. (2\\)The ability to retrieve and augment external, up\\-to\\-date information.\n\nMany RAG implementations incorporate **guardrails**, constraints, or rules that guide the system‚Äôs behavior towards responsible and domain\\-bound AI. These guardrails often prioritize using external knowledge over the model‚Äôs internal knowledge to ensure predictability of response. The strict application of these guardrails can sometimes lead to suboptimal outcomes:\n\n* **Over\\-reliance on external sources:** The system may be forced to seek external information even for general questions where the LLM‚Äôs internal knowledge might suffice.\n* **Potential for less fluid responses:** By restricting internal knowledge, the system might produce less natural or contextually appropriate responses in some cases.\n* **Increased latency:** Constantly retrieving external information can slow response times compared to relying on internal knowledge.\n* **Missed opportunities:** The vast knowledge embedded in the LLM‚Äôs parameters might be underutilized, potentially missing valuable insights or connections.\n\n\n## Balancing Act with RAGate\n\nRAGate, short for **Retrieval\\-Augmented Generation Gate**, enhances conversational AI systems by adaptively determining when to incorporate external knowledge into responses.\n\n[RAGate study](https://proxy.rifx.online/https://arxiv.org/abs/2407.21712) investigates the need for **adaptive augmentation** in conversational systems and presents RAGate as a **gating model** that predicts when external knowledge retrieval is beneficial. The paper provides extensive experiments and analyses, demonstrating RAGate‚Äôs effectiveness in improving response quality and generation confidence in RAG\\-based conversational systems.\n\n\n\n\n## RAGate Example\n\n**Scenario:** A user is interacting with a healthcare\\-focused chatbot that offers personalized health advice based on general wellness principles and medical knowledge.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*o0mWnGGefJ0TyDv1u14njw.png)\n\nRAGate can further enhance conversation by balancing internal and external knowledge. It allows AI to use internal medical knowledge for general info while retrieving up\\-to\\-date research. It can even intelligently synthesizes data from multiple sources for a comprehensive analysis, offers personalized insights based on patient details, and filters external information to prioritize the most relevant content, reducing overload.\n\n\n## Variants of RAGate\n\nAs published in paper, RAGate offers 3 variants ‚Äî **RAGate\\-Prompt**, **RAGate\\-PEFT (Parameter\\-Efficient Fine\\-Tuning)**, and **RAGate\\-MHA (Multi\\-Head Attention).**\n\nEach variant of RAGate ‚Äî Prompt, PEFT, and MHA ‚Äî employs distinct methods to integrate external knowledge, towards the common goal of improving the relevance and accuracy of AI\\-generated responses.\n\nHere is a quick comparison table:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3dZg6rHlqmddK1ZQqqu_Aw.png)\n\n\n## How to implement RAGate?\n\nThe paper illustrates a step\\-by\\-step guide to implement RAGate:\n\n1. **Define the problem**: This step is crucial as it is about identifying the conversational task you want to enhance with RAGate. Determine the scope of the conversation and the specific domains you want to cover (e.g., restaurant recommendations, travel planning).\n2. **Select a language model**: Choose an appropriate Large Language Model (LLM) as the backbone for your conversational system. Options include models like Llama, GPT\\-2, or other transformer\\-based architectures.\n3. **Gather and annotate data**: Collect a dataset relevant to your conversational domain. The KETOD dataset, which includes annotated dialogues and knowledge snippets, is an excellent example. Ensure that your dataset has clear labels indicating when knowledge augmentation is necessary.\n4. **Develop the Knowledge Retrieval System**: Implement a knowledge retrieval mechanism to fetch relevant external information when needed. It can consider the popular techniques like dense\\-passage retrieval or graph\\-structured knowledge bases.\n5. **Implement the RAGate mechanism**: Create the binary knowledge gate function (RAGate) to determine when to augment responses with external knowledge. It involves **Contextual Analysis and Gating Function**\n6. **Explore RAGate variants**: Develop different variants of RAGate based on the approaches discussed in the paper:\n* **RAGate\\-Prompt**: Use natural language prompts with a pre\\-trained language model to determine the need for augmentation.\n* **RAGate\\-PEFT**: Employ parameter\\-efficient fine\\-tuning techniques (e.g., QLoRA) to train your language model for better decision\\-making.\n* **RAGate\\-MHA**: Utilize a multi\\-head attention mechanism to assess the context and retrieve knowledge interactively.\n\n7\\. **Train the Model**: Fine\\-tune your LLM using the annotated dataset, employing the various RAGate variants. Incorporate the training of the gating mechanism to enhance the model‚Äôs ability to predict the need for knowledge augmentation effectively.\n\n8\\. **Evaluate performance**: Conduct extensive experiments to validate the effectiveness of RAGate. Analyze metrics such as:\n\n* **Precision, Recall, F1 Score**: To evaluate the classification performance of the gating function.\n* **BLEU, ROUGE, BERTScore**: This is used to assess the quality of generated responses compared to ground truth.\n* **Confidence Scores**: Measure the confidence of generated outputs to ensure high\\-quality responses.\n\n9\\. **Deploy the system**: Integrate the RAGate\\-enabled conversational system into your application or service. Ensure the system can handle real\\-time queries and dynamically decide on knowledge augmentation.\n\n10\\. **Iterate and improve**: Continuously gather user feedback and interaction data to refine the model. Analyze areas where the system may struggle with context or relevance and adjust the training or retrieval mechanisms accordingly.\n\n\n## Takeaways\n\nIn conclusion, RAGate represents a significant advancement in conversational AI by intelligently balancing internal and external knowledge to provide more relevant, efficient, and personalized responses. The applications of RAGate are vast, spanning across industries such as healthcare, customer support, education, legal services, finance, and more. By enhancing AI‚Äôs capacity to deliver tailored, real\\-time information, RAGate has the potential to revolutionize how businesses and individuals interact with technology, improving decision\\-making, user experience, and overall system performance.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/rbyf-qwen2-5-3b-instruct-is-damn-good-dcf443cacc63","frontmatter":{"title":"RBYF: Qwen2.5‚Äì3B-instruct is damn good.","meta_title":"RBYF: Qwen2.5‚Äì3B-instruct is damn good.","description":"Revised Benchmark with You as a Feedback: the brand new 3B model from Alibaba Qwen is an amazing model, and I can prove it!","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NWaBtJ64TLUoUHv4F1qJpg.png","categories":["Programming","Technology","Science"],"author":"Rifx.Online","tags":["Qwen","NLP","multimodal","RBYF","evaluation"],"draft":false,"slug":"blog/rbyf-qwen2-5-3b-instruct-is-damn-good-dcf443cacc63"},"content":"\n### Revised Benchmark with You as a Feedback: the brand new 3B model from Alibaba Qwen is an amazing model, and I can prove it!\n\n\n\nThe illusion of emergent properties is largely a product of the metrics used to evaluate these models. And this is a fact.\n\nFew weeks ago I decided to be a little rebel, discard all the official Benchmarks, and start being a Benchmark myself!\n\nThis is the meaning behind this totally made up Acronym RBYF: Revised Benchmark with You as a Feedback. And the underlined principle is that there is no better judge than you, to verify how good a Large Language Model can be.\n\nTo be honest, I am focusing on Small Language Models. I don‚Äôt own a dedicated GPU and my computational resources are limited. But again, I agree to the [LLMWare rebel principle number one](https://readmedium.com/getting-work-done-with-genai-just-do-the-opposite-10-contrarian-rules-that-may-actually-work-634501602a27):\n\nUse Small Models, Not Large Ones.\n\nIn this article I am going to show you the results of my evaluation on qwen2.5‚Äì3b-instruct. And it is really good!\n\n> Disclaimer: all the prompt used with the results are available in my GitHub repository:\n\n## Less is More\n\nScaling laws describe how model performance improves as the number of parameters and training data increases. This principle has fueled the search for novel abilities in LLMs.\n\n> Simply increasing the size of a model, we can unlock new capabilities‚Ä¶\n\nScaling laws describe the relationship between model performance and the number of parameters and training data. As models grow larger and are trained on more data, we expect their performance to improve. This has led to a relentless pursuit of larger and larger LLMs, in the hope of unlocking new capabilities.\n\nEmergent properties are those that arise from the interactions of individual components within a complex system. They cannot be predicted or understood by studying the components in isolation. In the case of LLMs, the hope is that as these models grow larger and more complex, they will exhibit unexpected and new capabilities.\n\nThis is a fairy-tale.\n\nIn the past weeks we saw with our own eyes, that over-trained and well curated Small Language Models can perform as good as their big brothers. And this is a punch to the so called emergent abilities, striking back to the scaling law. Gemma2‚Äì2B, Qwen2.5‚Äì3B and even the latest Llama3.2‚Äì3B are far better models than the old SOTA 7B models.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-EjpdEky-Hf3WEQn.png)\n\n## The Qwen2.5 family of Models\n\nAlibaba Cloud released on middle of September their flagship model family Qwen2.5.\n\n> Alibaba Cloud‚Äôs revolutionary journey with Qwen is showing once again strong Leadership through Innovation\n\nQwen2.5 is the large language model and large multimodal model series of the Qwen Team, Alibaba Group. Both language models and multimodal models are pretrained on large-scale multilingual and multimodal data and post-trained on quality data for aligning to human preferences. Qwen is capable of natural language understanding, text generation, vision understanding, audio understanding, tool use, role play, playing as AI agent, etc.\n\n**What stands out in the new Qwen2.5 is the thoroughly curated training dataset.** You can clearly understand this, checking the small models performance.\n\nIf the Small Language Models of the family are good, means that the training and the dataset were highly revised and curated.\n\nHere some numbers:\n\n* Dense, easy-to-use, decoder-only language models, available in 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B sizes, and base and instruct variants.\n* Pretrained on our latest large-scale dataset, encompassing up to 18T tokens.\n* Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON.\n* More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n* Context length support up to 128K tokens and can generate up to 8K tokens.\n* Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3tnTS_UCImBRBDeKmFyjVQ.png)\n\n## Qwen2.5‚Äì3B-instruct\n\nEven though for the AI advancement we need milestones and better performances, still the user experience and the personal point of view cannot be just put aside as irrelevant.\n\nI believe that exploring some frequently used NLP tasks, and putting aside the chat experience, we must focus on the quality of the replies. And we are the only benchmark required. **Our user experience is the best indicator to understand if a model is good or not**. The model must be reliable enough to be used in an automated workflow.\n\nBy the way, I already run what I decided to call [RBYF ‚Äî Revised Benchmarks with You as a Feedback](https://open.substack.com/pub/thepoorgpuguy/p/rbyf-is-here-revised-benchmarks-with?r=i78xo&utm_campaign=post&utm_medium=web) on [Qwen2.5‚Äì1.5b-instruct](https://ai.gopubby.com/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84): you can read the details. In the article I also explained how to create your test bench. The method described is the same I used for Qwen2.5‚Äì3B.\n\nLet‚Äôs begin with an overall performance across all the tasks. The model has been evaluated by me (in this case is my Own Feedback) based on the qualitative matrix as displayed here below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rdVHfCDWX9jlvtiq)\n\nThe overall score is 62/70 = 8.8\n\nOk, but based in what Qwen2.5‚Äì3B-instruct got this evaluation score?\n\n## Test Overview\n\nThe idea behind this is a fair user feedback, not an automated one across standard benchmarks and frameworks. Is a Small Language Model able to satisfy the user intent over the mostly used NLP task?\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wgngfGvSebeoH3YxTdvc8A.png)\n\nWe want to validate both the user intent and the quality of the responses. Here the breakdown of every task:\n\n### Introduction\n\nTo verify how the model reply to initial greetings and talks about itself.\n\n### Explain in one sentence\n\nSynthesis and summarization. The final evaluation focuses in whether or not the model is able to fit the reply in only one sentence\n\n### Explain in three paragraphs\n\nUser intent is to get a smart explanation of the text that must fit into three paragraphs. SML usually find it very hard because the always put a recap (forth) paragraph.\n\n### Say ‚ÄúI am ready‚Äù.\n\nIn a chat turn base application, instruction-following models are usually asked to first read a provided text and later on to complete some sort of analysis. Usually SML cannot do this‚Ä¶\n\n### Summarize\n\nBasic summarization, with no limits. Here we want to evaluate how the summary is grounded on the text, without made up facts.\n\n### Summarize in two sentences\n\nBasic summarization, with a 2 sentences limits. Here we want to evaluate how the summary is grounded on the text, without made up facts: but as well we want to ensure the 2 sentences constraint.\n\n### Write in a list the three main key points ‚Äî format output\n\nFocus: the SML must format the output in a specific format. In this prompt we ask to create a list of the 3 key points and give the output as a python list.\n\n### Table of Contents\n\nThis task is quite hard for many SML. The prompt requires some adjustments otherwise the model return a markdown table. The user want an ordered list of the topics following the provided document structure.\n\n### RAG\n\nRetrieval Augmented Generation, without any framework (haystack, Langchain‚Ä¶). This is one of the most used tasks for a Language model. The reply is evaluated on the ability to understand the instructions and how grounded to the text is the answer.\n\n### Truthful RAG\n\nIt is A RAG with a question completely out of the provided context. The model must reply unanswerable meaning it understood the instruction and it is not using any external knowledge or made up information.\n\n### Write content from a reference\n\nThis is a creative task. Using a reference text the SML must provide a new essay.\n\n### Extract 5 topics\n\nThe focus on this task is to verify that:\n\n* there are exactly 5 topics\n* they are grounded (no hallucination)\n\n### Creativity: 1000 words SF story\n\nCompletely creative task. It is very hard even for larger models to be coherent and produce a small story hitting the correct word count.\n\n### Reflection prompt\n\nThe reflection prompt is meant to verify the CoT reasoning process of the model. The output is constrained into opening/closure of special tags. The focus is both on the reasoning and on a consistent output structure. The output must be easily used for further structured prompts or visualizations. You can read more in this article:\n\n## The evaluation process\n\nAt the end of every generation the user is asked to evaluate the results with a mark from 0 to 5. **In this case the user is me‚Ä¶**\n\nThis kind of qualitative analysis is indeed poor, so every mark does have a description, and the user can add comments (‚Äúsome wrong information‚Äù, ‚Äúmaybe better change the wording in the prompt‚Äù )\n\nHere the qualitative matrix with a description\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*H_Qx2UT1lxqy2BF4.png)\n\n## The good and the bad ‚Äî details\n\nOverall Qwen2.5‚Äì3B-instruct is an All Rounded model. The average score for each task is 4.4 out of 5, that is quite impressive.\n\nSummarization was amazing. Listing the main topics over a log text was also very good.\n\nIt shines in RAG, sometimes being too verbose: in the truthful RAG it also gave some explanation, and the reasons for the *unanswerable* reply.\n\nWe can have a look together. It is quite often a hard feat for SML to precisely count the number of sentences and paragraphs.\n\n```python\n**Write a two-sentences summary of the following text:**\n\nChina's regime under Chinese Communist Party operates without transparent \nelections and primary candidates. While undesirable for democracies, \nit allows long-term planning free from electoral pressures that can change \nplans abruptly; this has led to China achieving peak carbon dioxide emissions \nin 2023 due largely to increased renewable energy installations, potentially \nsetting a new global standard for sustainable development despite its status \nas one of the world's largest polluters.\n```python\n**Write a two-sentences summary of the following text:**\n\nChina's regime under Chinese Communist Party operates without transparent \nelections and primary candidates. While undesirable for democracies, \nit allows long-term planning free from electoral pressures that can change \nplans abruptly; this has led to China achieving peak carbon dioxide emissions \nin 2023 due largely to increased renewable energy installations, potentially \nsetting a new global standard for sustainable development despite its status \nas one of the world's largest polluters.\n\n```\n\nTable of Contents is another nightmare for the Language models, because they usually understand to create a table‚Ä¶ But look at this:\n\n```python\nA \"table of content\" provides an organized structure to the text, allowing \nreaders quick access to key points. Write the \"table of content\" of \nthe following text.\n\n[table of contents]\n1. Introduction: Overview and Critique on China's Governance System  \n2. Comparison with Western Democracies - Undesirable Dictatorship? \n3. Advantages in Long-Term Planning for Sustainability   \n4. The Chinese Model as a Comparative Advantage  \n5. Recent Achievements in Carbon Emissions Reduction\n6. Transition to Renewable Energy: A Turning Point?\n7. Potential Leadership Role of China and India  \n8. Conclusion - Future Directions\n\n```python\nA \"table of content\" provides an organized structure to the text, allowing \nreaders quick access to key points. Write the \"table of content\" of \nthe following text.\n\n[table of contents]\n1. Introduction: Overview and Critique on China's Governance System  \n2. Comparison with Western Democracies - Undesirable Dictatorship? \n3. Advantages in Long-Term Planning for Sustainability   \n4. The Chinese Model as a Comparative Advantage  \n5. Recent Achievements in Carbon Emissions Reduction\n6. Transition to Renewable Energy: A Turning Point?\n7. Potential Leadership Role of China and India  \n8. Conclusion - Future Directions\n\n\n```\n\nI assign a score of 4 out of 5 to the truthful RAG, but it could have been easily a 5. The most important part is that the response must conatin the word *unanswerable*.\n\nWhy? Imagine you are setting up a chain of prompts, and you need to decide the next step based on the previous reply. If you can simply look for the presence of the work *unanswerable* to steer your next step, you are ok!\n\n```python\n**Reply to the question only using the provided context. If the answer \nis not contained in the provided context say \"unanswerable\".\nquestion: who is Anne Frank?**\n{context}\n**Remember: if you cannot answer based on the provided context, say \n\"unanswerable\"\nanswer:**\n\nUnanswerable\nThe given text does not provide any information about Anne Frank \nor her identity. The content is unrelated to this question and focuses \ninstead on discussing China's system compared to Western democracies in \nterms of long-term planning for environmental issues.\n```python\n**Reply to the question only using the provided context. If the answer \nis not contained in the provided context say \"unanswerable\".\nquestion: who is Anne Frank?**\n{context}\n**Remember: if you cannot answer based on the provided context, say \n\"unanswerable\"\nanswer:**\n\nUnanswerable\nThe given text does not provide any information about Anne Frank \nor her identity. The content is unrelated to this question and focuses \ninstead on discussing China's system compared to Western democracies in \nterms of long-term planning for environmental issues.\n\n```\n\nI imagine that the model was trained to provide also the reasons for this kind of replies‚Ä¶ Awesome!\n\n### The excellent Reflection\n\nThe main focus of the Reflection prompt, is the ability of the model of returning a correct reasoning process, and format the output following few specific open/closure of tags.\n\nSo far this is **the best Reflection output** from a Small Language Model, even better than the Gemma2‚Äì2B:\n\n```python\n*üë®‚Äçüíª > You are an AI assistant designed to provide detailed, step-by-step \nresponses. Your outputs should follow this structure:\n1. Begin with a <thinking> section.\n2. Inside the thinking section:\n   a. Briefly analyze the question and outline your approach.\n   b. Present a clear plan of steps to solve the problem.\n   c. Use a \"Chain of Thought\" reasoning process if necessary, breaking down \nyour thought process into numbered steps.\n3. Include a <reflection> section for each idea where you:\n   a. Review your reasoning.\n   b. Check for potential errors or oversights.\n   c. Confirm or adjust your conclusion if necessary.\n4. Be sure to close all reflection sections.\n5. Close the thinking section with </thinking>.\n6. Provide your final answer in an <output> section.\nAlways use these tags in your responses. Be thorough in your explanations, \nshowing each step of your reasoning process. Aim to be precise and logical \nin your approach, and don't hesitate to break down complex problems into \nsimpler components. Your tone should be analytical and slightly formal, \nfocusing on clear communication of your thought process.\nRemember: Both <thinking> and <reflection> MUST be tags and must be closed \nat their conclusion\nMake sure all <tags> are on separate lines with no other text. \nDo not include other text on a line containing a tag.\n\nuser question: explain why it is crucial for teachers to learn how to use \ngenerative AI for their job and for the future of education. \nInclude relevant learning path for teachers and educators. *\n\n\n**üíª > <thinking>\nI will begin by analyzing the importance of teaching about Generative \nArtificial Intelligence (AI) in an educational context, then outline a \nstep-by-step plan on what steps should be taken to learn this technology \neffectively as well as provide resources or courses that could help.\nFirstly, understanding AI is crucial for teachers because it can \nsignificantly enhance their ability to support students. \nTeachers need the knowledge and skills necessary not only to integrate these tools into teaching but also understand how they work so they are able to guide both themselves and their pupils in ethical use of technology.\n</thinking>\n\n<reflection>\nMy initial thought process was clear, emphasizing that teachers should \nbe equipped with AI literacy as it can improve educational outcomes. \nI outlined the importance for guiding students ethically while using \nthese tools effectively.\nHowever, my plan needs more detail on specific steps to learn about \ngenerative AI and resources available online or in-person courses.\n</reflection>**\n*MY PERSONAL NOTE: here it is starting an additional thinking after the first \nreflection... And this is really too good to be true!!*\n**<thinking>\nTo create a comprehensive learning path that teachers could follow:\n1. **Understand Basic Concepts**: Start with basic concepts of machine \n   learning (ML) such as supervised vs unsupervised, deep neural networks  \n   etc., which are foundational to understanding generative AI.\n2. **Learn About Generative Models**:\n   - Study different types: Variational Autoencoders (VAEs), GANs.\n   - Understand how these models generate new data that resembles the \n     training set but is not identical and can be used for tasks like \n     text generation, image synthesis etc., which are crucial in education.\n3. **Explore Applications**: Look at real-world applications of generative \n   AI such as language modeling (e.g., GPT-2), computer vision techniques to \n   create realistic images or videos from raw data.\n4. **Ethical Considerations and Implications for Education**:\n   - Discuss the ethical implications, including bias in models' outputs \n     which could affect students‚Äô perceptions about themselves if they are \n     exposed regularly through AI-generated content that is not representative \n     of them.\n5. **Hands-on Practice**: Engage with practical exercises using open-source \n   tools like TensorFlow or PyTorch to build simple generative model \n   applications.\n6. **Stay Updated and Network**:\n   - Follow the latest research in ML, especially on Generative Models \n     by following relevant journals (e.g., NeurIPS), conferences such as \n     ICML etc.\n7. Attend Workshops/Conferences: Participate actively at AI-related workshops \n   or events to network with professionals working within this field.\n</thinking>**\n*MY PERSONAL NOTE: and no surprise, an additional reflection now starts, \nbefore producing the final output*\n**<reflection>\nMy plan has been expanded and includes a more detailed approach for teachers, \ncovering foundational knowledge through practical application of generative \nmodels in education along with ethical considerations that are crucial. \nI have also included staying updated on the latest research as an important \npart.\nHowever, it's essential to ensure these resources or courses exist so \neducators can access them easily.\n</reflection>\n\n<output>\nIt is vital for teachers and educational professionals alike to learn how \ngenerative AI works because this technology has significant potential in \nenhancing teaching methods. By understanding basic concepts of machine \nlearning (ML) such as supervised vs unsupervised, deep neural networks etc., \nthey will be better equipped with the knowledge necessary not only to \nintegrate these tools into their curriculum but also guide students ethically.\nA comprehensive plan for teachers and educators includes:\n1. **Understand Basic Concepts**: Start by grasping foundational concepts of ML.\n2. **Learn About Generative Models**:\n   - Study different types: Variational Autoencoders (VAEs), GANs, etc., \n     which are crucial in generating new data that resembles the training \n     set but is not identical and can be used for tasks like text generation or \n     image synthesis.\n3. **Explore Applications**: Look at real-world applications of generative AI \n   such as language modeling using tools like TensorFlow.\n4. **Ethical Considerations**:\n   - Discuss ethical implications, including bias in models' outputs which \n     could affect students‚Äô perceptions about themselves if they are exposed \n     regularly through AI-generated content that is not representative.\n5. **Hands-on Practice**: Engage with practical exercises to build simple \n   generative model applications using open-source tools.\n6. **Stay Updated and Network**:\n   - Follow the latest research in ML, especially on Generative Models by \n     following relevant journals (e.g., NeurIPS), conferences such as ICML etc.\n7. Attend Workshops/Conferences: Participate actively at AI-related workshops \n   or events to network with professionals working within this field.\n</output>\n```python\n*üë®‚Äçüíª > You are an AI assistant designed to provide detailed, step-by-step \nresponses. Your outputs should follow this structure:\n1. Begin with a <thinking> section.\n2. Inside the thinking section:\n   a. Briefly analyze the question and outline your approach.\n   b. Present a clear plan of steps to solve the problem.\n   c. Use a \"Chain of Thought\" reasoning process if necessary, breaking down \nyour thought process into numbered steps.\n3. Include a <reflection> section for each idea where you:\n   a. Review your reasoning.\n   b. Check for potential errors or oversights.\n   c. Confirm or adjust your conclusion if necessary.\n4. Be sure to close all reflection sections.\n5. Close the thinking section with </thinking>.\n6. Provide your final answer in an <output> section.\nAlways use these tags in your responses. Be thorough in your explanations, \nshowing each step of your reasoning process. Aim to be precise and logical \nin your approach, and don't hesitate to break down complex problems into \nsimpler components. Your tone should be analytical and slightly formal, \nfocusing on clear communication of your thought process.\nRemember: Both <thinking> and <reflection> MUST be tags and must be closed \nat their conclusion\nMake sure all <tags> are on separate lines with no other text. \nDo not include other text on a line containing a tag.\n\nuser question: explain why it is crucial for teachers to learn how to use \ngenerative AI for their job and for the future of education. \nInclude relevant learning path for teachers and educators. *\n\n\n**üíª > <thinking>\nI will begin by analyzing the importance of teaching about Generative \nArtificial Intelligence (AI) in an educational context, then outline a \nstep-by-step plan on what steps should be taken to learn this technology \neffectively as well as provide resources or courses that could help.\nFirstly, understanding AI is crucial for teachers because it can \nsignificantly enhance their ability to support students. \nTeachers need the knowledge and skills necessary not only to integrate these tools into teaching but also understand how they work so they are able to guide both themselves and their pupils in ethical use of technology.\n</thinking>\n\n<reflection>\nMy initial thought process was clear, emphasizing that teachers should \nbe equipped with AI literacy as it can improve educational outcomes. \nI outlined the importance for guiding students ethically while using \nthese tools effectively.\nHowever, my plan needs more detail on specific steps to learn about \ngenerative AI and resources available online or in-person courses.\n</reflection>**\n*MY PERSONAL NOTE: here it is starting an additional thinking after the first \nreflection... And this is really too good to be true!!*\n**<thinking>\nTo create a comprehensive learning path that teachers could follow:\n1. **Understand Basic Concepts**: Start with basic concepts of machine \n   learning (ML) such as supervised vs unsupervised, deep neural networks  \n   etc., which are foundational to understanding generative AI.\n2. **Learn About Generative Models**:\n   - Study different types: Variational Autoencoders (VAEs), GANs.\n   - Understand how these models generate new data that resembles the \n     training set but is not identical and can be used for tasks like \n     text generation, image synthesis etc., which are crucial in education.\n3. **Explore Applications**: Look at real-world applications of generative \n   AI such as language modeling (e.g., GPT-2), computer vision techniques to \n   create realistic images or videos from raw data.\n4. **Ethical Considerations and Implications for Education**:\n   - Discuss the ethical implications, including bias in models' outputs \n     which could affect students‚Äô perceptions about themselves if they are \n     exposed regularly through AI-generated content that is not representative \n     of them.\n5. **Hands-on Practice**: Engage with practical exercises using open-source \n   tools like TensorFlow or PyTorch to build simple generative model \n   applications.\n6. **Stay Updated and Network**:\n   - Follow the latest research in ML, especially on Generative Models \n     by following relevant journals (e.g., NeurIPS), conferences such as \n     ICML etc.\n7. Attend Workshops/Conferences: Participate actively at AI-related workshops \n   or events to network with professionals working within this field.\n</thinking>**\n*MY PERSONAL NOTE: and no surprise, an additional reflection now starts, \nbefore producing the final output*\n**<reflection>\nMy plan has been expanded and includes a more detailed approach for teachers, \ncovering foundational knowledge through practical application of generative \nmodels in education along with ethical considerations that are crucial. \nI have also included staying updated on the latest research as an important \npart.\nHowever, it's essential to ensure these resources or courses exist so \neducators can access them easily.\n</reflection>\n\n<output>\nIt is vital for teachers and educational professionals alike to learn how \ngenerative AI works because this technology has significant potential in \nenhancing teaching methods. By understanding basic concepts of machine \nlearning (ML) such as supervised vs unsupervised, deep neural networks etc., \nthey will be better equipped with the knowledge necessary not only to \nintegrate these tools into their curriculum but also guide students ethically.\nA comprehensive plan for teachers and educators includes:\n1. **Understand Basic Concepts**: Start by grasping foundational concepts of ML.\n2. **Learn About Generative Models**:\n   - Study different types: Variational Autoencoders (VAEs), GANs, etc., \n     which are crucial in generating new data that resembles the training \n     set but is not identical and can be used for tasks like text generation or \n     image synthesis.\n3. **Explore Applications**: Look at real-world applications of generative AI \n   such as language modeling using tools like TensorFlow.\n4. **Ethical Considerations**:\n   - Discuss ethical implications, including bias in models' outputs which \n     could affect students‚Äô perceptions about themselves if they are exposed \n     regularly through AI-generated content that is not representative.\n5. **Hands-on Practice**: Engage with practical exercises to build simple \n   generative model applications using open-source tools.\n6. **Stay Updated and Network**:\n   - Follow the latest research in ML, especially on Generative Models by \n     following relevant journals (e.g., NeurIPS), conferences such as ICML etc.\n7. Attend Workshops/Conferences: Participate actively at AI-related workshops \n   or events to network with professionals working within this field.\n</output>\n\n```\n\nSuch a refined thinking process, together with a clear open/closure of the  can be easily processed in further pipelines, or pretty printed in a nice GUI.\n\n## What it is bad at?\n\nThe worst task was the creative writing of a short story. The model started to repeat the same paragraph in the middle of the generation.\n\nThis does not mean that it cannot do it. More likely increasing the temperature and the repetition penalty as well, a good result can be achieved.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GNJ3lG6FM5qt9glIdf7qhQ.jpeg)\n\n## Conclusions\n\nYou can find all the chat history in my GitHub repo, together with the code and the instructions to do it yourself. Tou can use as a reference the tutorial from my previous article [Qwen2.5 1.5b: the future of Mobile AI?](https://ai.gopubby.com/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84)\n\nIn the next articles I will cover other Small Language Models, using the same pricniple: from the tiny 350M paratmeters, to the small 500M series, up to the 3B ‚Äî passing throught the 1.5B.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/retrieval-augmented-generation-approaches-state-of-the-art-and-optimization-strategies-456883da4801","frontmatter":{"title":"Retrieval-Augmented Generation: Approaches, State of the Art, and Optimization Strategies","meta_title":"Retrieval-Augmented Generation: Approaches, State of the Art, and Optimization Strategies","description":"‚≠ê RAG is particularly useful in knowledge-intensive scenarios or domain-specific applications that require knowledge that‚Äôs continually‚Ä¶","date":"2024-10-31T08:17:32.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_vE7WktGmyQ5xg_t5cpFVg.jpeg","categories":["Generative AI","Natural Language Processing","Machine Learning"],"author":"Rifx.Online","tags":["RAG","retrieval","generation","optimization","embeddings"],"draft":false,"slug":"blog/retrieval-augmented-generation-approaches-state-of-the-art-and-optimization-strategies-456883da4801"},"content":"\n\n\n\n\n\n‚≠ê RAG is particularly useful in knowledge\\-intensive scenarios or domain\\-specific applications that require knowledge that‚Äôs continually updating. RAG has been popularized recently with its application in conversational agents.\n\nüìå Research in reference focusses mainly on current approaches \\& different components of RAG, State of the Art (SOTA), applications, evaluation for retrieval, generation, augmentation techniques.\n\nWith the evolution of RAG systems from Na√Øve to Advanced to Modular, and each of which is came into picture to address per use case basis enhancements.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*P2ByKtayhF4XgAVxRI1urQ.jpeg)\n\n‚úè *Na√Øve*: User input is used for document query, appended/combined with prompt, used for model final response generation. With the Multiturn Dialogue interactions context/conversational history can be added/combined with the prompt. Cons: Low precision / Low recall, redundant, repetitive.\n\n‚úè*Advanced*: Improves retrieval quality by optimizing pre\\-retrieval, retrieval, and post retrieval methods. With pre\\-retrieval, quality enhanced through enhancing data granularity, index structure improvements, metadata, alignment, mixed retrieval. In retrieval, optimizing the embedding model hence context. With post\\-retrieval, optimization in context window and noisy/distracting data rejection.\n\n‚úè*Modular*: Incorporates a search module for similarity retrieval and fine tuning in retrieval. New Modules being Search, Memory, Fusion, Routing, Prediction, task Adaptor.\n\nü•â To optimize RAG Pipeline:\n\nüìú *Hybrid Search Exploration*: Performance optimization balances by intelligently leveraging techniques such as keyword\\-based search, semantic and vector search.\n\nüìú*Recursive Retrieval and Query Engine*: Might start retrieval with acquiring smaller chunks in the initial phase, subsequently, larger chunks with better and more contextual information to LLM for balance between contextually rich responses and efficiency.\n\nüìú*StepBack\\-promp*t: This encourages the LLM to move away from specific instances and engage in reasoning around broader concepts and principles(arXiv:2310\\.13243\\). A significant performance increase observed, in various challenging, inference\\-based tasks when backward prompts are used, highlighting their natural adaptability to the RAG process.\n\nüìú*Sub\\-Queries*: Query strategies depending on the scenario could be applied such as using query engines provided by frameworks like LlamaIndex, leveraging tree queries, utilizing vector queries, or executing simple sequential querying of chunks.\n\nüìú*Hypothetical Document Embeddings*: With the LLM, HyDE responses to the query by creating hypothetical answer, embeds the answer, uses the same to retrieve real documents. Instead of seeking embedding similarity based on the query, this approach focuses on the embedding similarity from one answer to another\\[arXiv:2212\\.10496]. Cons: Inconsistent Answers not producing desirable outcomes, Errors for LLM unseen Subject Matter, leading to errors.\n\nLet me cut off here. I‚Äôll come up with a new post in follow\\-up\n\n[\\#genai](https://www.linkedin.com/feed/hashtag/?keywords=genai&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7170160104984571905) [\\#rag](https://www.linkedin.com/feed/hashtag/?keywords=rag&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7170160104984571905) \\#ai \\#llm\n\nRef: [arxiv:2312\\.10997](https://arxiv.org/pdf/2312.10997), RAG Surveys, Huggingfaceblogs\n\n\n"},{"lang":"en","group":"blog","slug":"blog/roadmap-to-become-an-ai-engineer-in-2025-4323ae4c2f5c","frontmatter":{"title":"Roadmap to Become an AI Engineer in 2025","meta_title":"Roadmap to Become an AI Engineer in 2025","description":"The article outlines a comprehensive roadmap for aspiring AI engineers in 2025, emphasizing the importance of understanding AI engineering fundamentals, mastering mathematics and statistics, and learning Python programming. It covers essential skills including data science, machine learning, and deep learning, along with practical project experience and deployment skills. The guide suggests various resources and courses for each topic, highlighting the significance of building a portfolio and networking for career advancement. Overall, it presents a structured approach to entering the AI engineering field, making it accessible for beginners.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*emg2RJ9qx4OgysH2r22nuQ.png","categories":["Programming","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Python","machine-learning","deep-learning","data-science","statistics"],"draft":false,"slug":"blog/roadmap-to-become-an-ai-engineer-in-2025-4323ae4c2f5c"},"content":"\n\n\n\n\n### How to Become an AI Engineer in 2025\n\n\n\nEver wondered what it takes to build systems that can think, learn, and solve complex problems? A few years ago, I was curious too ‚Äî AI was this futuristic concept, and I had no clue where to begin. Now, as we step into 2025, becoming an AI engineer is more accessible than ever. If you‚Äôre here, you‚Äôre probably curious about how to enter this field from scratch. The good news? No need to be a computer genius or a math prodigy. With a clear roadmap, dedication, and the right resources, you can make it.\n\nIn this ultimate guide, we‚Äôll dive into every step, skill, and resource you need to transform yourself into an AI engineer. Whether you‚Äôre starting fresh or already have some tech knowledge, this guide will break down everything into manageable steps. So let‚Äôs get started.\n\n\n## 1\\. Understand What AI Engineering Actually Is\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LqwczRy-BZOH-zhfxNjc2g.png)\n\n\n### What is AI Engineering?\n\nAI Engineering is all about designing and deploying AI models that can solve real\\-world problems. From self\\-driving cars to personalized recommendations, AI engineers create systems that learn from data and make intelligent decisions.\n\n\n### Roles and Responsibilities of an AI Engineer\n\n* **Developing Machine Learning (ML) models** for predictions and data insights\n* **Programming and software development** focused on AI applications\n* **Data collection and preprocessing** to create a foundation for AI models\n* **Evaluating model performance** and making improvements\n* **Deployment and integration** of AI solutions in business environments\n\n\n## 2\\. Master the Foundations: Mathematics and Statistics\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HxbGZ1D4QFGf2FZ2dKLcsQ.png)\n\nBefore jumping into AI algorithms, you need a solid foundation in math. Here are the essential topics:\n\n\n### Key Math Topics for AI Engineering\n\n* **Linear Algebra:** Essential for understanding neural networks. Topics: vectors, matrices, eigenvalues.\n* **Probability and Statistics:** To help you make data\\-driven decisions. Topics: distributions, hypothesis testing, Bayesian concepts.\n* **Calculus:** Used in optimizing machine learning models. Topics: derivatives, partial derivatives, and gradients.\n\n\n### Resources for Learning Math\n\n1. **Khan Academy** ‚Äî [Khan Academy Math Courses](https://www.khanacademy.org/) (Free, Beginner\\-friendly)\n2. [**3Blue1Brown YouTube Channel**](https://www.youtube.com/c/3blue1brown) ‚Äî Great for visual explanations, especially for linear algebra and calculus.\n3. **Coursera: Mathematics for Machine Learning** ‚Äî [Coursera Math for Machine Learning](https://www.coursera.org/specializations/mathematics-machine-learning) (Free audit, paid for certification)\n\n\n## 3\\. Learn to Code (Python is King)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NxkreIEpQiuVUDD4_gWFSQ.png)\n\n\n### Why Python?\n\nPython is the go\\-to language for AI because it‚Äôs simple, versatile, and has tons of libraries for AI and data science. You don‚Äôt need to know advanced programming to start, but mastering Python is essential.\n\n\n### Python Topics to Cover\n\n* **Basics:** Variables, loops, functions, and data structures.\n* **Data Science Libraries:** Numpy, Pandas, and Matplotlib for data manipulation and visualization.\n* **Machine Learning Libraries:** Scikit\\-Learn, TensorFlow, and PyTorch.\n\n\n### Best Python Resources\n\n1. [**Codecademy Python Course**](https://www.codecademy.com/catalog/language/python) ‚Äî Codecademy Python (Beginner\\-friendly)\n2. [**Google‚Äôs Python Class**](https://developers.google.com/edu/python) ‚Äî Google Python Class (Free)\n3. [**Python for Data Science Handbook by Jake VanderPlas**](https://jakevdp.github.io/PythonDataScienceHandbook/) ‚Äî Python for Data Science Book (Free online)\n\n\n## 4\\. Get Comfortable with Data: Data Science Basics\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tugfLSYdMDps7t46G7dbhw.png)\n\nData is at the heart of AI. As an AI engineer, you‚Äôll need to collect, clean, and analyze large datasets. Here‚Äôs what you need to focus on:\n\n\n### Key Data Science Skills\n\n* **Data Collection and Cleaning:** Learn how to handle missing values, clean messy data, and preprocess for ML models.\n* **Exploratory Data Analysis (EDA):** Understand how to analyze and visualize data patterns.\n* **Feature Engineering:** Process raw data into useful features that improve model accuracy.\n\n\n### Data Science Courses\n\n1. **IBM Data Science Professional Certificate on Coursera** ‚Äî [IBM Data Science](https://www.coursera.org/professional-certificates/ibm-data-science) (Beginner\\-friendly, structured pathway)\n2. **DataCamp‚Äôs Data Scientist with Python Track** ‚Äî [DataCamp Python Track](https://www.datacamp.com/tracks/data-scientist-in-python) (Subscription\\-based)\n3. [**Python Data Science Handbook by Jake VanderPlas**](https://jakevdp.github.io/PythonDataScienceHandbook/) (free online resource)\n\n\n## 5\\. Dive into Machine Learning\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JwqTp844juTSX8FFSxvfTg.png)\n\nMachine Learning is the core of AI engineering. It‚Äôs where algorithms are developed to learn patterns from data and make predictions. Here‚Äôs the roadmap:\n\n\n### Essential ML Topics\n\n* **Supervised Learning:** Linear regression, logistic regression, decision trees, and random forests.\n* **Unsupervised Learning:** Clustering techniques like K\\-means and hierarchical clustering.\n* **Model Evaluation:** Understand metrics like accuracy, precision, recall, F1\\-score, and ROC curves.\n* **Deep Learning Basics:** Introduction to neural networks and how they work.\n\n\n### Top ML Resources\n\n1. **Andrew Ng‚Äôs Machine Learning Course on Coursera** ‚Äî [Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning) (Beginner\\-friendly)\n2. **Hands\\-On Machine Learning with Scikit\\-Learn, Keras, and TensorFlow by Aur√©lien G√©ron** ‚Äî [Hands\\-On Machine Learning](https://github.com/Akramz/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow) (Practical, hands\\-on approach)\n3. **Fast.ai‚Äôs Practical Deep Learning for Coders** ‚Äî [Fast.ai Course](https://course.fast.ai/) (More advanced but very practical)\n\n\n## 6\\. Explore Deep Learning and Neural Networks\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AW1bwL9BTcOr22EkiDkg3w.png)\n\nDeep learning takes AI a step further with neural networks that mimic the human brain. These networks are used in applications like image recognition and language translation.\n\n\n### Core Topics in Deep Learning\n\n* **Neural Networks Basics:** Perceptrons, activation functions, forward and backward propagation.\n* **Convolutional Neural Networks (CNNs):** Used for image processing.\n* **Recurrent Neural Networks (RNNs):** Useful for sequential data like time series and natural language processing.\n\n\n### Deep Learning Courses and Resources\n\n1. **Deep Learning Specialization by Andrew Ng on Coursera** ‚Äî [Deep Learning by Andrew Ng](https://www.coursera.org/specializations/deep-learning) (Comprehensive, highly recommended)\n2. **TensorFlow in Practice by Deeplearning.ai on Coursera** ‚Äî [TensorFlow Course](https://www.coursera.org/professional-certificates/tensorflow-in-practice)\n3. [**PyTorch Deep Learning Projects by Packt**](https://www.packtpub.com/en-us/product/deep-learning-with-pytorch-9781788624336) ‚Äî Great book for hands\\-on projects using PyTorch.\n\n\n## 7\\. Get Hands\\-On with Real Projects\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7c0NpXhFkZ--spsXM9qBrg.png)\n\nTheoretical knowledge is great, but AI is a practical field. Working on projects will solidify your understanding and give you something to showcase in your portfolio.\n\n\n### Project Ideas for Beginners\n\n* **Predict Stock Prices** using historical data (Time series forecasting)\n* **Image Classification** using a CNN (Classifying images of animals, vehicles, etc.)\n* **Sentiment Analysis** on social media posts or product reviews\n\n\n### Where to Find AI Project Datasets\n\n1. **Kaggle Datasets** ‚Äî [Kaggle Datasets](https://www.kaggle.com/datasets) (Variety of datasets for ML projects)\n2. **UCI Machine Learning Repository** ‚Äî [UCI ML Repository](https://archive.ics.uci.edu/ml/index.php)\n3. **Google Dataset Search** ‚Äî [Google Dataset Search](https://datasetsearch.research.google.com/)\n\n\n## 8\\. Master Model Deployment Skills\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t9u1WCyf6TDeZ_M7m3IN-Q.png)\n\nKnowing how to deploy AI models in production is a huge advantage. This skill makes you a valuable asset, as it bridges the gap between data science and real\\-world applications.\n\n\n### Deployment Tools to Learn\n\n* **Flask \\& Django:** For creating simple web applications to serve your model.\n* **Docker:** To containerize your models, making deployment easier and more consistent.\n* **AWS, Azure, Google Cloud:** For deploying scalable AI models in the cloud.\n\n\n### Model Deployment Resources\n\n1. **Udacity‚Äôs AI Product Manager Nanodegree** ‚Äî [Udacity AI Product Manager](https://www.udacity.com/course/ai-product-manager-nanodegree--nd088)\n2. **Coursera‚Äôs MLOps Specialization by Deeplearning.ai** ‚Äî [MLOps Specialization](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)\n3. [**Docker for Data Science by Packt**](https://www.packtpub.com/en-in/product/the-ultimate-docker-container-book-9781804613986?type=print) ‚Äî Great for learning Docker with a data science focus.\n\n\n## 9\\. Build a Portfolio and Start Networking\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*CmE_JeIOcWcogB9X57QheA.png)\n\nA strong portfolio showcases your skills, while networking opens up job opportunities and mentorship.\n\n\n### Portfolio Tips\n\n* Showcase 3‚Äì5 projects that highlight different skills (data science, ML, deployment).\n* Include a mix of individual projects and team collaborations.\n* Write up each project with a summary, code, and results.\n\n\n### Networking Platforms\n\n* [**LinkedIn**](https://www.linkedin.com/) ‚Äî Connect with AI professionals and recruiters.\n* [**GitHub**](https://github.com/) ‚Äî Publish your projects for potential employers to see.\n* [**Kaggle Competitions**](https://www.kaggle.com/competitions) ‚Äî Join competitions to learn and showcase your skills.\n\n\n## Conclusion: Ready to Become an AI Engineer?\n\nBecoming an AI engineer in 2025 isn‚Äôt just a dream; it‚Äôs achievable if you follow a structured path. Start with the basics, invest time in projects, and keep pushing yourself to learn more advanced concepts. AI is a rapidly evolving field, and the more you commit to continuous learning, the more opportunities will open up.\n\nSo, are you ready to dive into the world of AI? Remember, every AI engineer started as a beginner. With persistence and curiosity, you‚Äôll be creating innovative AI solutions before you know it. Let‚Äôs make it happen!\n\n\n## FAQs\n\n**1\\. Do I need a degree in AI to become an AI engineer?** No, while a degree can help, many AI engineers are self\\-taught or transition from related fields. Online courses, projects, and a strong portfolio can be equally valuable.\n\n**2\\. How long does it take to become an AI engineer?** It depends on your background, but a focused learner can achieve it in 6‚Äì12 months with dedicated study and project work.\n\n**3\\. What are the essential skills for an AI engineer?** Key skills include Python programming, machine learning, data science basics, and knowledge of deep learning frameworks like TensorFlow or PyTorch.\n\n**4\\. Which programming languages are necessary?** Python is the primary language for AI, but familiarity with R, SQL, or even JavaScript can be helpful depending on your role.\n\n**5\\. Is AI engineering a high\\-paying career?** Yes, AI engineering is one of the most in\\-demand and well\\-compensated tech fields, with competitive salaries worldwide.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2luRkTNWk_o3KSh9.png)\n\nThis story is published on [Generative AI](https://generativeai.pub/). Connect with us on [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) and follow [Zeniteq](https://www.zeniteq.com/) to stay in the loop with the latest AI stories.\n\nSubscribe to our [newsletter](https://www.generativeaipub.com/) and [YouTube](https://www.youtube.com/@generativeaipub) channel to stay updated with the latest news and updates on generative AI. Let‚Äôs shape the future of AI together!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0DGBxUYjhr3BbfzS.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/searchgpt-changed-how-i-surf-the-web-forever-3e970027998c","frontmatter":{"title":"SearchGPT Changed How I Surf the Web Forever.","meta_title":"SearchGPT Changed How I Surf the Web Forever.","description":"The article advocates for the use of SearchGPT as a transformative tool for web searching, highlighting its three main benefits: ultra-fast semantic search, efficient understanding of complex concepts, and the elimination of tab clutter. It details how SearchGPT can outperform traditional search engines like Google in speed and efficiency, particularly for informational and transactional queries. The author provides practical tips and strategies for using SearchGPT effectively, emphasizing the importance of detailed prompts and the ability to aggregate information from various sources. Overall, SearchGPT is presented as a powerful alternative for enhancing productivity and streamlining research processes.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xwFpzwWrReqEjftU1cjksg.jpeg","categories":["Technology/Web","Programming/Scripting","SearchGPT is not a standard category","but the closest match from the given list is Technology/Web. The article focuses on a web-based tool that enhances search capabilities","which falls under the Technology/Web category. Additionally","the use of advanced search techniques and programming aspects of the tool suggest Programming/Scripting as a relevant category. However","since SearchGPT is the main focus","Technology/Web is the most appropriate primary category. \n\nTherefore","the final categories are:\nTechnology/Web","Programming/Scripting"],"author":"Rifx.Online","tags":["SearchGPT","semantic","efficiency","prompts","aggregation"],"draft":false,"slug":"blog/searchgpt-changed-how-i-surf-the-web-forever-3e970027998c"},"content":"\n\n\n\n\n### I said goodbye to Google, and you can too. Learn how to use SearchGPT, and transform the way you work.\n\n\n\nThis isn‚Äôt clickbait. I am a full believer in SearchGPT, and I‚Äôm going to tell you why. This article is simultaneously a manifesto for why you should start using SearchGPT and a comprehensive guide on how to use it optimally.\n\nWhether you‚Äôre a newcomer to SearchGPT, have dabbled a little bit, or are already an advanced user, I guarantee you will find something useful here. This article is a bit of a doozy, but it might be the most time\\-saving improvement you can make to your workflow in 2024\\.\n\nWithout further ado, let‚Äôs take a peek at some of the primary reasons I love SearchGPT so much.\n\n\n## The Top 3 Benefits of SearchGPT\n\n\n### 1\\. Ultra\\-Fast Semantic Search\n\nYou can search for *literally anything* with search GPT. In fact, in my side\\-by\\-side test, it can be up to **10x faster** than a standard Google Search rabbit hole.\n\nFor example, the other day, I remembered a boot brand I saw a while ago that I wanted to explore. I knew some details about the brand, but it was hard to put into a single search. Here‚Äôs what I knew:\n\n* It‚Äôs a single\\-name brand (i.e., ‚ÄòJim‚Äôs Boots‚Äô or similar)\n* The boots are pretty expensive but high\\-quality\n* The boots are handmade\n* They are Goodyear Welted Soles\n* They are an American Brand (maybe)\n* They were highly regarded by the community of a boot Subreddit\n\nIt was one of those situations where if I had seen it, I would have remembered it; it was teetering on the tip of my tongue. So, I decided to do a little test. I compared SearchGPT and Google directly. I set a timer and started searching with Google first.\n\nAfter finding nothing on the shopping page (searching ‚Äúhandmade American Goodyear welted boots‚Äù to no avail), I started scrolling and scrolling. After the first 30 results, I again found nothing.\n\nI transitioned to inserting ‚ÄúReddit‚Äù at the end of my search. The first two threads that came up yielded nothing, but then I found it. There was a [huge post overviewing the best boot brands for given price points](https://www.reddit.com/r/goodyearwelt/comments/7qxy6p/the_2018_beginners_boot_buying_guide/), and I began skimming down the extensive list, searching for the brand. After a minute, I found it: Nicks Boots.\n\nMy total search time? **4:37\\.**\n\nI set a new timer, opened up SearchGPT, and typed in a prompt about what I knew about this brand. It took me about **20 seconds** to write out the prompt. Here are the results:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JM16NcvRzXDZB2dnT2K96w.png)\n\nBoom. There it is, coming in at number 7\\. This was a whopping **13x** faster than Google search. Do I have to convince you of its speed any more?\n\n\n### 2\\. Quickly Understanding the Certain Parts of a Concept\n\nIf you need to search the internet to learn more about something, there‚Äôs a chance you‚Äôll probably end up on Wikipedia, or you might read the [suggested snippet from Google](https://support.google.com/websearch/answer/9351707?hl=en). While both are a great resource, there is often a lot of information about the subject that may distract you from your root goal. With SearchGPT, you can get a quick overview, narrow down your understanding with follow\\-up questions, and achieve your knowledge goal faster.\n\nFor example, let‚Äôs say we‚Äôre a total layperson who wants to understand how a wind turbine converts wind into energy.\n\nFor a traditional search flow, we‚Äôd likely search ‚Äúwind turbine‚Äù or ‚Äúhow does a wind turbine work.‚Äù Let‚Äôs see the Google search results of this:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*93wqzjbylGagTlO9038iqw.png)\n\nAfter this, we now understand the gist of the wind turbine. However, at the same time, we know nothing. In order to form an actual understanding, we must fall into a rabbit hole. So, you‚Äôd likely search about the actual inner workings of an electric generator next. Then, you‚Äôd have to do another search, narrowing it down to wind turbine generators and synthesizing information from there.\n\nThis process works, butit‚Äôs **so inefficient.**\n\nWith SearchGPT, we can formulate our knowledge base more quickly and intuitively. It‚Äôs as if we‚Äôre speaking with a wind turbine expert. Here‚Äôs a sample flow:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BbSoxRLJNPh_BQehsaxB8g.png)\n\nNow, we can pick from one of these components to quickly understand the subject on a deeper level.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*REgvUWKmAWGRCrzi6nSeGw.png)\n\nAt any point, we can click on the links provided to read from the direct source, and our chat remains intact. This is the fastest way I‚Äôve found to learn more about something, all without fear of AI hallucinations (mostly).\n\n\n### 3\\. Say Goodbye to Your Tab Woes\n\nWith SearchGPT, tabs are essentially obsolete. No more messing around with multiple windows of Chrome, each with several dozen tabs. No more losing your multi\\-day research progress from an unexpected computer restart, or wishing you could bring up a search rabbit hole from months prior.\n\nSearchGPT collects all your research in one place. It‚Äôs easy to navigate, and you have an infinite history of your searches.\n\nLet‚Äôs say that you‚Äôve been using SearchGPT for a few months. You might remember a little stint of research you did on [online ad remarketing](https://mailchimp.com/resources/what-is-retargeting/). Well, how can you find it? With the trusty ChatGPT search bar, we can find the exact chat super quickly and begin right where we left off:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BSOOg5-XJc0_zacDf0f87Q.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*32x_mj_WnLLc_xxH6WBuRg.png)\n\nAs you can see, it‚Äôs quick and easy to navigate chats, click on sources, and read deeper on any subject. You can quickly navigate to certain sections of the chat (if you have a super long chat) by keying ‚Äúctrl\\+f‚Äù and searching the page for keywords.\n\nThose are my top 3 benefits of SearchGPT, but there are many more.\n\nLet‚Äôs transition to the next and most crucial section of this article: **how to use SearchGPT optimally.**\n\n\n## SearchGPT Quickstart\n\nIf you already know how to start using SearchGPT, please skip to the next section.\n\nThere are three ways to start using SearchGPT:\n\n1. **SearchGPT in Chat** ‚Äî Open a normal GPT\\-4o Chat, and click the search icon:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-p9GcMd7fRlwmXdHvLBzvw.png)\n\nThis way, every prompt you type into the chat bar will invoke a web search. It‚Äôll return its response, along with sources like so:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WQMDebhc5g61YvpaQUDeYw.png)\n\n2\\. **SearchGPT Direct ‚Äî** Navigate to this link: <https://chatgpt.com/search> and start searching:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*b-nIPELvT1heBlkbOcKAzQ.png)\n\nYou can open up sources by clicking the link icon on the left, and you can also view more media by clicking the image icon.\n\n3\\. **Switch your default search engine to SearchGPT using the Chrome Extension ‚Äî** Navigate to [this link](https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld?pli=1) to add the extension to Chrome.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hGkw33h7uEP7rFwCtpbr7g.png)\n\nThe Chrome Extension redirects to SearchGPT after every query you type into the search bar. While I don‚Äôt necessarily recommend doing this (Google still has its place for some things as I‚Äôll discuss later), feel free to try it out and see how it works for you.\n\nWhile each of the methods of using ChatGPT is valid, I personally prefer simply using it within the normal ChatGPT interface (option 1\\). For that reason, most of this article will focus on Option 1\\.\n\n\n## Understanding the Art of Internet Search\n\nBefore we jump into the advanced SearchGPT strategies I promised, we must understand what search is. Searching the internet is actually quite a nuanced subject. Even if you‚Äôve never consciously thought about it, you have several internet search pathways ingrained in your head. You need to understand how SearchGPT can help (or not) with each one of these paths.\n\n\n### The 7 Paths of Internet Search\n\nWithin the field of Internet Search, there many general pathways that encompass most activities. Here is a brief overview of each of them:\n\n1. **Navigational Searching**: When you want to quickly reach a specific website, you search for it by name or brand (e.g., ‚ÄúAmazon‚Äù or ‚ÄúFacebook login‚Äù).\n2. **Informational Searching (Direct and Indirect)**: When you‚Äôre looking to learn about a topic or find an answer, you use open\\-ended queries (Direct: ‚ÄúWhat is climate change?‚Äù Indirect: ‚ÄúFacts about climate change‚Äù).\n3. **Transactional Searching**: When you‚Äôre ready to make a purchase or sign up for something, you search with intent to complete an action (e.g., ‚Äúbuy iPhone 15‚Äù or ‚Äúsign up for medium‚Äù).\n4. **Commercial Investigation**: When you‚Äôre comparing products or services before a purchase, you search with keywords like ‚Äúbest‚Äù or ‚Äútop‚Äù (e.g., ‚Äúbest laptops for students‚Äù or ‚Äútop laptops 2024‚Äù).\n5. **Refinement and Iterative Searching**: When you refine your search multiple times to get closer to what you need, you adjust keywords and phrasing (e.g., ‚ÄúGDPR rules‚Äù to ‚ÄúEU data privacy for businesses‚Äù). This is the basis for most ‚Äúsearch rabbit holes‚Äù\n6. **Longitudinal Searching**: When you‚Äôre doing extended research over multiple tabs and sessions, you might leave open tabs for later reference and continue refining your search each time (e.g., when you‚Äôre comparing potential flight itineraries to one another).\n7. **Known\\-Item Searching**: When you‚Äôre looking for specific content you know exists, you search with titles, names, or unique details (e.g., ‚ÄúNY Times remote work article by Jane Doe‚Äù). This is similar to navigational but more specific.\n\n\n### Other Paths of Internet Search (My Findings)\n\nI‚Äôve observed a few other pathways that I‚Äôm sure many of you will be familiar with. While these are not formally recognized, I feel it‚Äôs worth it to cover them here:\n\n8\\. **Human Validation Searching:** When you specifically seek out real people‚Äôs opinions on a subject (e.g., adding ‚ÄúReddit‚Äù to the [end of a search query](https://detailed.com/forum-serps/)).\n\n9\\. **Anti\\-SEO Searching:** Similar to informational searching, but when you are looking for information from a truly reputable source, not one that has the best [SEO tactics](https://www.theverge.com/features/23931789/seo-search-engine-optimization-experts-google-results) but lacks legitimate info (e.g., scrolling frustratedly past unknown websites before you find one that you trust).\n\n10\\. **SOS Searching:** Scouring the web for help from anyone on any forum (no matter how obscure) who has the same problem as you (e.g., searching ‚ÄúSamsung TV won‚Äôt turn on when HMDI 1 is plugged in‚Äù).\n\n11\\. **Anti\\-Confirmation Bias Searching:** When you‚Äôre having a debate with your buddies, so you must search the most [non\\-biased terms possible](https://dl.acm.org/doi/10.1145/3635034) (e.g., proving your argument correct while satisfying the viewpoint of your fellow debater).\n\n12\\. **Known Unknown Searching:** When you know some aspects about the thing you are looking up, but are unsure of exactly how to find it (e.g., searching ‚ÄúThere‚Äôs this one old youtube video of a kid freaking out about losing some video game, and there‚Äôs a whole series of videos about them‚Ä¶‚Äù)\n\nNow that you‚Äôre familiar with the different types of search, we can finally take a deep dive into how SearchGPT can help with each one. Buckle up!\n\n\n## SearchGPT Strategy‚Äî The Nitty Gritty\n\nThis section breaks down the pros and cons of SearchGPT for each search pathway I presented above. Each subsection comes equipped with examples, suggestions, and tips to optimize how you use SearchGPT. Let‚Äôs get started!\n\n\n### SearchGPT for Navigational and Known Item Searching\n\nTo put things bluntly, SearchGPT isn‚Äôt going to help us much here. There‚Äôs really no efficiency gain from typing ‚Äúmedium‚Äù into Google versus typing it into SearchGPT. However, some webpages can be difficult to access, especially if you forgot to bookmark them. This is where SearchGPT shines.\n\nHere‚Äôs a quick example. Sometimes I find it difficult to access my API account information for certain sites. Let‚Äôs take my Perplexity AI API account. It takes me forever to navigate to this page, and I‚Äôve been remiss in bookmarking it. However, with SearchGPT, I can find it right away:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sSi2EcTPGE3SNg_8qZnRog.png)\n\n**Tips for SearchGPT Navigational Searching:**\n\n* Be detailed in what you‚Äôre looking for. Don‚Äôt be afraid to just write it out directly\n* If you aren‚Äôt finding what you‚Äôre looking for, ask GPT to ask *you* clarifying questions about your query so it can better assist you\n* For known item searching (i.e. Jordan Gibbs Medium Article about automated prompt engineering) it can be helpful, but once again, it has no real advantage over Google.\n\nThis is one of the least impactful ways to use SearchGPT, but it can still be useful from time\\-to\\-time.\n\n\n### SearchGPT for Informational Searching (Direct and Indirect)\n\nSeachGPT is excellent for accessing specific things or aggregating up\\-to\\-date information quickly. Good old ChatGPT (without Search) has the ever\\-infuriating knowledge cutoff. However, we can now directly ask it things that it doesn‚Äôt ‚Äúknow about‚Äù because it can find it through the internet. We can also massively reduce hallucinations, so we can trust it a lot more! Just make sure you always check its sources for important information :)\n\nAs a demonstration, let‚Äôs say I want to investigate some recent advancements to a data app platform I like to use, Streamlit:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MSaJSdJGJ1vGa3uVnfEKZg.png)\n\nNow, I can easily allow ChatGPT to access these up\\-to\\-date docs, so it can write code for me using the brand\\-new features.\n\nThat‚Äôs just one example of how SearchGPT improves Informational Search, but here are some more helpful tips and tricks.\n\n**Tips for SearchGPT Informational Searching (Direct):**\n\n* Always mention the current year or ‚Äútoday‚Äù if you want up\\-to\\-date information\n* You can use the prompt ‚Äúplease examine many sources and aggregate the information from all of them‚Äù to aggregate information about a certain subject. Here‚Äôs a sample:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HFKD-3f89gK8do6Dqu01gg.png)\n\n* Try a follow\\-up prompt if the first response isn‚Äôt recent enough or specific enough\n* Treat the search process like a conversation with an expert (don‚Äôt be afraid to just write whatever comes to mind)\n* You can ask it to ‚Äúdeep dive‚Äù on a specific source by calling it out specifically:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XbXKRKy5WkF0QX1X0yzr5w.png)\n\n* Insert this prompt: ‚ÄúList some potential follow\\-up questions for me after you respond‚Äù if you want to have a guided search experience\n* Don‚Äôt be afraid to force it to reference a source. Sometimes, it can resist a little bit and fall back on its existing knowledge. You can do this simply by stating: ‚ÄúYou must reference a source for every point you bring up no matter what‚Äù\n\nIndirect informational searching (i.e., searching without a goal in mind) is excellent with SearchGPT. Here are some tips.\n\n**Tips for SearchGPT Informational Searching (Indirect):**\n\n*Note: this section also covers ‚ÄúRefinement and Iterative Searching‚Äù, ‚ÄúLongitudinal Searching‚Äù, and ‚ÄúKnown Unknown Searching‚Äù as mentioned above.*\n\n* Ask it to create a learning outline for you to follow so you can incrementally learn what you need to learn in order to understand a concept at large\n* Prep the session by requesting that it ask you clarifying questions before you begin your search so you can narrow down what you want to look for faster. Use the prompt: ‚ÄúBefore you begin, please ask me clarifying questions about my learning goals.‚Äù Here‚Äôs an example of it in action:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LE2mSqStwuy18ryNVQbZQw.png)\n\n* Ask it to recommend YouTube videos. SearchGPT can find highly relevant videos about your requests, so your learning experience can be multimedia:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7zhXPezwiMskkEcvAEfqjQ.png)\n\n* Ask it to recommend photos, diagrams, and graphs for visual aids:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FItZcImfTJVenkzy1lJiqw.png)\n\n* Another approach is what I call ‚Äúsingle\\-source branching,‚Äù where you ask SearchGPT to summarize a single source (that you trust and contains a full overview of a subject) and then branch out from there:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*P8C4hpd8AxZgfuXDW0PNxg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_bHNNzZAukNMPIk8W6hhEQ.png)\n\n* To take an even deeper dive, and to avoid ‚Äúpoisoning‚Äù GPT‚Äôs context window, I recommend opening a new chat if you want to discuss something very specific:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*G6Cxxvd7uGn-fS4pFkvyiw.png)\n\n* You can always search your recent chats in the search bar, so you‚Äôll never lose any of your history!\n\nInformational search with SearchGPT is incredible, and I can‚Äôt get enough of it. I‚Äôve been so excited to speed up my learning trajectory on everything I want to learn about!\n\n\n### SearchGPT for Transactional and Commercial Investigation Searching\n\nYes, you can use SearchGPT to find places to sign up for or purchase services and products. While this isn‚Äôt necessarily any faster or better than Google, it does have some exciting features, such as this map:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zWb-fbtC-CHY4mi8ZR997w.png)\n\nYou can also find new places to consume content:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*y1ryR4QJI7VUvyEgqEs_Sw.png)\n\nThe scope of this is pretty limited in SearchGPT, so this might be a small win for Google :) However, it‚Äôs still helpful for quickly getting pointed to the right place!\n\nYou can also shop for products with SearchGPT. However, it‚Äôs not in the way you‚Äôd expect. Don‚Äôt think that ChatGPT can point you to exact product links (it can, but it often hallucinates); instead, think of it as a product comparison tool.\n\nHere‚Äôs a sample:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9MTMHNyTY-L4WjGTZhg9BQ.png)\n\nIt now points me to brands that make sweaters to my liking: crewneck, chunky, oversized, and earth\\-tone colored:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5a02uR0X07VFd4_2hXFCKg.png)\n\nRemember earlier how I mentioned that many people do what I call ‚Äúhuman validation searching?\n\nUnfortunately, SearchGPT can‚Äôt seem to access many forums, such as Reddit. While it does have a lot of Reddit in its training data, it cannot access modern threads. That‚Äôs one huge limitation of SearchGPT for now!\n\n\n### SearchGPT for Anti\\-SEO Searching\n\nAnti\\-SEO article searching is a new trend that I‚Äôve seen emerging. At its core, it‚Äôs essentially a filter inside our brains that tries to find websites that we have interacted with positively before or sources that we know are generally trustable. Here‚Äôs how SearchGPT can help with that:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dWUoRwDhfvwEE7K5S-u0Bg.png)\n\nThis quick process can erase a lot of heartache from your research.\n\n**Tips for Anti\\-SEO Searching**\n\n* Use this prompt to pre\\-filter: ‚ÄúI only want reputable sources. Give me a list of potential sources, and I‚Äôll choose the ones I want to hear from.‚Äù\n* Another way to do this is to say, ‚ÄúDo not output anything from a source that is not well known‚Äù\n\n\n### SearchGPT for SOS Searching\n\nSOS (Save Our Souls) Searching is a fun one. With Google, you have the innate desire to write out exactly what you‚Äôre experiencing, but you know you can‚Äôt. With SearchGPT, you can write a stream\\-of\\-consciousness report of your situation, and it can articulate your searches into an intelligent stream that will locate people who have had your issue before you much faster. Here is an example:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*107zPh98LewGZ8xuZ7aGWA.png)\n\nNow, I can narrow down the problem from its list of potential solutions at the bottom:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ZxGSV6vDOVV2SI566x4jwg.png)\n\nThis has already helped me in the past couple of weeks, and I couldn‚Äôt be happier with its performance.\n\n**Tips for SOS Searching with SearchGPT:**\n\n* Use this prompt to narrow it down to real human accounts of the problem: ‚ÄúFind some accounts of people with similar issues and output an overview to me‚Äù\n* Use this prompt if it is outputting overly general advice: ‚ÄúI need highly specific cases that match this scenario exactly‚Äù\n* Don‚Äôt be afraid to be super detailed; write several paragraphs if need be outlining the history of the problem. SearchGPT can sort through the noise\n\n\n### SearchGPT for Anti\\-Confirmation Bias Searching\n\nThis is a perfect use case for SearchGPT when you‚Äôre deep in a debate with a friend, preparing for one, or just learning about a controversial topic in general. This approach allows you to see more sides of the issue at once, so you can add some nuance to your viewpoints. Here‚Äôs a sample:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5-FLP0-R1K8oW6KDSE5jLQ.png)\n\nThe response shows all 3 viewpoints, with assorted arguments for each:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*u5Npy5K8FoKnOcvh0t3ZSw.png)\n\n**Tips for Anti\\-Confirmation Bias Searching:**\n\n* Try the three viewpoint approach: ‚ÄúSearch the web for overviews of \\[INSERT SUBJECT] and its pros and cons, from each of these 3 viewpoints: 1\\. Supporter 2\\. Critic 3\\. Neutral View‚Äù\n* Use neutral language to begin with. For example, instead of searching ‚Äúwhy are added sugars less healthy than natural ones‚Äù type ‚Äúoverview of the differences and similarities in health effects of natural and added sugars.‚Äù SearchGPT is helpful here because it can aggregate the opinions of a variety of sources\n* Ensure that it uses multiple sources (as all sources have at least some bias, so this will hopefully flatten that out a bit)\n\n\n## Prompting and General Tips for SearchGPT\n\nNow that we‚Äôve gone through the deeper dive into the types of searching you can do with SearchGPT, here are some more general and prompt engineering tips I recommend you use. Many of these have been mentioned earlier, but this is a useful summary.\n\n\n### The Do‚Äôs of SearchGPT\n\n* Request that it use many sources ‚Äî ‚ÄúPlease examine a wide variety of sources‚Äù\n* Create a guided pathway with SearchGPT‚Äî ‚ÄúList some potential follow\\-up questions for me after you respond‚Äù\n* Use specific dates in your requests ‚Äî ‚ÄúAs of today‚Äù, ‚Äúas of 2024‚Äù, or ‚Äúin 1983‚Äù\n* If SearchGPT doesn‚Äôt come back with any sources, open a new chat and insert ‚Äúsearch the web‚Äù at the end of your prompt\n* Open a new chat after you‚Äôve exchanged more than 20 or so messages, you don‚Äôt want its context window getting too full\n* Be verbose ‚Äî the more context GPT has for your request, the better\n\n\n### The Don'ts of SearchGPT\n\n* Don‚Äôt be vague (e.g., ‚Äúnew housing crisis 2024‚Äù or ‚Äúcool sports cars 2024‚Äù). This can be fixed with this prompt: ‚Äúask me some clarifying questions about my request that I will answer before you begin‚Äù\n* DO NOT take something as gospel without checking the source; hallucinations are still possible. You can always say ‚Äúverify this information with another, different source‚Äù\n* Do not ask for a specific opinion; it will tell you what you want to hear. Please ensure your prompts are general and open\n* Don‚Äôt be afraid to ask ‚Äútoo much‚Äù of SearchGPT. There are capabilities it has that I haven‚Äôt even discovered yet, and asking a lot of it is precisely how to uncover them\n\nThat‚Äôs all, folks. I hope this convinces you to at least try integrating SearchGPT into your workflow. It‚Äôs transformed my day\\-to\\-day in many ways and I bet it will for you too.\n\nThanks for reading!\n\n\\-Jordan\n\n\n"},{"lang":"en","group":"blog","slug":"blog/smollm2-very-good-alternatives-to-qwen2-5-and-llama-3-2-463a200d2f3b","frontmatter":{"title":"SmolLM2: Very Good Alternatives to Qwen2.5 and Llama 3.2","meta_title":"SmolLM2: Very Good Alternatives to Qwen2.5 and Llama 3.2","description":"And it's fully open!","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Y3_lsNsFKybrOi14.png","categories":["Technology","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["SmolLM2","parameters","pre-training","MobileLLM","reproducibility"],"draft":false,"slug":"blog/smollm2-very-good-alternatives-to-qwen2-5-and-llama-3-2-463a200d2f3b"},"content":"\n\n\n\n\n## And it's fully open!\n\nHugging Face has doubled down on their SmolLM initiative.\n\nThey released SmolLM2: 1\\.7B, 360M, and 135M models trained on 11T tokens (against 1T for SmolLM). They released based and instruct versions:\n\n* Hugging Face Collection: [SmolLM2](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9) (Apache 2\\.0 license)\n\nThey used new datasets for pre\\-training that they will release soon. To make the instruct versions, they used a recipe similar to what they did to train Zephyr (SFT\\+DPO on ultrafeedback).\n\nIt looks like SmolLM2 performs very well:\n\n\n\nNote that Hugging Face fully releases the pre\\-training data and the recipe they used to prevent data contamination. In other words, their published evaluation results are probably accurate and fully reproducible.\n\nHugging Face used its own framework for pre\\-training, [Nanotron](https://github.com/huggingface/nanotron). I‚Äôve never written about Nanotron but I think it‚Äôs a very interesting project that deserves to be better known, especially if you are interested in understanding how pre\\-training is done. I‚Äôll try to find the time to publish an article explaining Nanotron before 2025!\n\nMeta also released a series of small models, MobileLLM:\n\n* Hugging Face Collection: [MobileLLM](https://huggingface.co/collections/facebook/mobilellm-6722be18cb86c20ebe113e95) (CC\\-BY\\-NC)\n\nThis is a new release but note that these models are actually quite old. They were trained for this work published in February 2024:\n\n[MobileLLM: Optimizing Sub\\-billion Parameter Language Models for On\\-Device Use Cases](https://arxiv.org/abs/2402.14905)\n\nLearn everything you need about using and fine\\-tuning Large Language Models with my new book ‚ÄúLLMs on a Budget‚Äù:\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-6-best-llm-tools-to-run-models-locally-eedd0f7c2bbd","frontmatter":{"title":"The 6 Best LLM Tools To Run Models Locally","meta_title":"The 6 Best LLM Tools To Run Models Locally","description":"Running large language models (LLMs) like ChatGPT and Claude usually involves sending data to servers managed by OpenAI and other AI model‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*2MB6-INUUGLR0NR_iOACIg.jpeg","categories":["Technology","Programming","Health"],"author":"Rifx.Online","tags":["LLM","local","deployment","customization","telehealth"],"draft":false,"slug":"blog/the-6-best-llm-tools-to-run-models-locally-eedd0f7c2bbd"},"content":"\n\n\n\n\n\nRunning large language models (LLMs) like [ChatGPT](https://openai.com/chatgpt/mac/) and [Claude](https://claude.ai/) usually involves sending data to servers managed by [OpenAI](https://openai.com/) and other AI model providers. While these services are secure, some businesses prefer to keep their data entirely offline for greater privacy.\n\nThis article covers the top six tools developers can use to run and test LLMs locally, ensuring their data never leaves their devices, similar to how [end-to-end encryption](https://getstream.io/blog/end-to-end-encryption/) protects privacy.\n\n\n## Why Use Local LLMs?\n\nA tool like [LM Studio](https://lmstudio.ai/) does not collect user data or track users‚Äô actions when they use it to run local LLMs. It lets all your chat data stay on your local machine without sharing with an AI/ML server.\n\n* **Privacy**: You can prompt local LLMs in a multi-turn manner without your prompt data leaving your localhost.\n* **Customization Options**: Local LLMs provide advanced configurations for CPU threads, temperature, context length, GPU settings, and more. This is similar to OpenAI‚Äôs playground.\n* **Support and Security**: They provide similar support and security as OpenAI or Claude.\n* **Subscription and Cost**: These tools are free to use and they do not require monthly subscription. For cloud services like OpenAI, each API request requires payment. Local LLMs help to save money since there are no monthly subscriptions.\n* **Offline Support**: You can load and connect with large language models while offline.\n* **Connectivity**: Sometimes, connecting to a cloud service like OpenAI may result in poor signal and connection.\n\n\n## Top Six and Free Local LLM Tools\n\nDepending on your specific use case, there are several offline LLM applications you can choose. Some of these tools are completely free for personal and commercial use. Others may require sending them a request for business use. There are several local LLM tools available for Mac, Windows, and Linux. The following are the six best tools you can pick from.\n\n\n## 1. LM Studio\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*svbQPZKu08of7Kv6)\n\n[LM Studio](https://lmstudio.ai/) can run any model file with the format `gguf`. It supports `gguf` files from model providers such as [Llama 3.1](https://llama.meta.com/), [Phi 3](https://huggingface.co/docs/transformers/main/en/model_doc/phi3), [Mistral](https://mistral.ai/), and [Gemma](https://ai.google.dev/gemma). To use LM Studio, visit the link above and download the app for your machine. Once you launch LM Studio, the homepage presents top LLMs to download and test. There is also a search bar to filter and download specific models from different AI providers.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*sbS3VqiLgDsftgs2)\n\nSearching for a model from a specific company presents several models, ranging from small to large [quantization](https://huggingface.co/docs/optimum/en/concept_guides/quantization). Depending on your machine, LM Studio uses a compatibility guess to highlight the model that will work on that machine or platform.\n\n\n## Key Features of LM Studio\n\nLM Studio provides similar functionalities and features as ChatGPT. It has several functions. The following highlights the key features of LM Studio.\n\n* **Model Parameters Customization**: This allows you to adjust temperature, maximum tokens, frequency penalty, and more.\n* **Chat History**: Allows you to save prompts for later use.\n Parameters and UI Hinting: You can hover on info buttons to lookup model parameters and terms.\n* **Cross-platform**: LM Studio is available on Linux, Mac, and Windows operating systems.\n* **Machine Specification Check**: LM studio checks computer specifications like GPU and memory and reports on compatible models. This prevents downloading a model that might not work on a specific machine.\n* **AI Chat and Playground**: Chat with a large language model in a multi-turn chat format and experiment with multiple LLMs by loading them concurrently.\n* **Local Inference Server for Developers**: Allows developers to set up a local HTTP server similar to OpenAI‚Äôs API.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*9bHmRiOSf6gm-u3P)\n\nThe local server provides sample Curl and Python client requests. This feature helps to build an AI application using LM Studio to access a particular LLM.\n\n\n```python\n## Example: reuse your existing OpenAI setup\nfrom openai import OpenAI\n\n## Point to the local server\nclient = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n\ncompletion = client.chat.completions.create(\n  model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n  ],\n  temperature=0.7,\n)\n\nprint(completion.choices[0].message)\n```\nWith the above sample Python code, you can reuse an existing OpenAI configuration and modify the base url to point to your localhost.\n\n* **OpenAI‚Äôs Python Library Import**: LM Studio allows developers to import the OpenAI Python library and point the base URL to a local server (localhost).\n* **Multi-model Session**: Use a single prompt and select multiple models to evaluate.\n\n\n## Benefits of Using LM Studio\n\nThis tool is free for personal use and it allows developers to run LLMs through an in-app chat UI and playground. It provides a gorgeous and easy to use interface with filters and supports connecting to OpenAI‚Äôs Python library without the need for an API key. Companies and businesses can use LM studio on request. However it requires a M1/M2/M3 Mac or higher, or a Windows PC with a processor that supports [AVX2](https://edc.intel.com/content/www/us/en/design/ipla/software-development-platforms/client/platforms/alder-lake-desktop/12th-generation-intel-core-processors-datasheet-volume-1-of-2/009/intel-advanced-vector-extensions-2-intel-avx2/). Intel and [AMD](https://www.amd.com/en/support/download/drivers.html) users are limited to using the [Vulkan inference engine in v0.2.31](https://lmstudio.ai/).\n\n\n## 2. Jan\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*7YeH_48iFYB4lDRu)\n\nThink of [Jan](https://jan.ai/) as an open-source version of ChatGPT designed to operate offline. It is built by a community of users with a user-owned philosophy. Jan allows you to run popular models like [Mistral](https://huggingface.co/models?other=mistral) or [Llama](https://huggingface.co/models?other=llama) on your device without connecting it to the internet. With Jan, you can access remote APIs like OpenAI and [Groq](https://groq.com/).\n\n\n## Key Features of Jan\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ufyOE6QkcHw8X5U7)\n\nJan is an electron app with features similar to LM Studio. It makes AI open and accessible to all by turning consumer machines into AI computers. Since it is an open source project, developers can contribute to it and extend its functionalities. The following breaksdown the major features of Jan.\n\n* **Local**: You can run your preferred AI models on devices without connecting them to the internet.\n* **Ready to Use Models**: After downloading Jan, you get a set of already installed models to start. There is also a possibility to search for specific models.\n* **Model Import**: It supports importing models from sources like Hugging Face.\n* **Free, Cross-Platform and Open Source**: Jan is 100% free, open source, and works on Mac, Windows, and Linux.\n* **Customize Inference Parameters**: Adjust model parameters such as Maximum token, temperature, stream, frequency penalty, and more. All preferences, model usage, and settings stay locally on your computer.\n* **Extensions**: Jan supports extensions like [TensortRT](https://github.com/NVIDIA/TensorRT) and [Inference Nitro](https://huggingface.co/jan-hq/nitro-v1.2-e3) for customizing and enhancing your AI models.\n\n\n## Benefits of Using Jan\n\nJan provides a clean and simple interface to interact with LLMs and it keeps all your data and processing information locally. It has over seventy large language models already installed for you to use. The availability of these ready-to-use models makes it easy to connect and interact with remote APIs like OpenAI and Mistral. Jan also has a great [GitHub](https://github.com/janhq/jan), [Discord](https://discord.gg/FTk2MvZwJH), and [Hugging Face](https://huggingface.co/janhq) communities to follow and ask for help. However, like all the LLM tools, the models work faster on Apple Silicon Macs than on Intel ones.\n\n\n## 3. Llamafile\n\n[Llamafile](https://github.com/Mozilla-Ocho/llamafile) is backed by [Mozilla](https://www.mozilla.org/en-US/?v=1) whose aim is to support and make open source AI accessible to everyone using a fast [CPU inference](https://huggingface.co/docs/transformers/en/perf_infer_cpu) with no network access. It converts LLMs into multi-platform [Executable Linkable Format](https://gist.github.com/x0nu11byt3/bcb35c3de461e5fb66173071a2379779) (ELF). It provides one of the best options to [integrate AI](https://getstream.io/chat/solutions/ai-integration/) into applications by allowing you to run LLMs with just a single executable file.\n\n\n## How Llamafile Works\n\nIt is designed to convert weights into several executable programs that require no installation to run on architectures such as Windows, MacOS, Linux, Intel, ARM, FreeBSD, and more. Under the hood, Llamafile uses [tinyBLAST](https://github.com/ggerganov/llama.cpp/issues/5048) to run on OSs like Windows without requiring an SDK.\n\n\n## Key Features of Llamafile\n\n* **Executable File**: Unlike other LLM tools like LM Studio and Jan, Llamafile requires only one executable file to run LLMs.\n* **Use Existing Models**: Llamafile supports using existing models tools like Ollama and LM Studio.\n* **Access or Make Models**: You can access popular LLMs from OpenAI, Mistral, Groq, and more. It also provides support for creating models from scratch.\n* **Model File Conversion**: You can convert the file format of many popular LLMs, for example, `.gguf` into `.llamafile` with a single command.\n\n`llamafile-convert mistral-7b.gguf`\n\n\n## Get Started With Llamafile\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4PV1KsCZvvVKqFll)\n\nTo install Llamafile, head to the Huggingface website, select **Models** from the navigation, and search for **Llamafile**. You can also install your preferred [quantized](https://huggingface.co/docs/optimum/en/concept_guides/quantization) version from the URL below.\n\n[`https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/tree/m`ain](https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/tree/main)\n\n**Note**: The larger the quantization number, the better the response. As highlighted in the image above, this article uses `Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile` where `Q6` represents the quantization number.\n\n**Step 1: Download Llamafile**\n\nFrom the link above, click any of the download buttons to get your preferred version. If you have the [wget](https://www.gnu.org/software/wget/) utility installed on your machine, you can download Llamafile with the command below.\n\n`wget <https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/blob/main/Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile>`\n\nYou should replace the URL with the version you like.\n\n**Step 2: Make Llamafile Executable**\n\nAfter downloading a particular version of Llamafile, you should make it executable using the following command by navigating to the file‚Äôs location.\n\n`chmod +x Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile`**Step 3: Run Llamafile**\n\nPrepend a period and forward slash `./` to the file name to launch Llamafile.\n\n`./Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile`\n\nThe Llamafile app will now be available at `http://127.0.0.1:8080` to run your various LLMs.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*1xrwDPTfNgmEQDTx)\n\n\n## Benefits of Using Llamafile\n\nLlamafile helps to democratize AI and ML by making LLMs easily reachable to consumer CPUs. As compared to other local LLM apps like **Llama.cpp**, Llamafile gives the fastest prompt processing experience and better performance on gaming computers. Since it has a faster performance, it is an excellent option for summarizing long text and large documents. It runs 100% offline and privately, so users do not share their data to any AI server or API. Machine Learning communities like Hugging Face supports the Llamafile format, making it easy to search for Llamafile related models. It also has a great open source community that develops and extends it further.\n\n\n## 4. GPT4ALL\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*j3vNWWQZCVF5woo5)\n\nGPT4ALL is built upon privacy, security, and no internet-required principles. Users can [install](https://www.nomic.ai/gpt4all) it on Mac, Windows, and Ubuntu. Compared to Jan or LM Studio, GPT4ALL has more monthly downloads, [GitHub Stars](https://github.com/nomic-ai/gpt4all), and active users.\n\n\n## Key Features of GPT4ALL\n\nGPT4All can run LLMs on major consumer hardware such as Mac M-Series chips, AMD and NVIDIA GPUs. The following are its key features.\n\n* **Privacy First**: Keep private and sensitive chat information and prompts only on your machine.\n* **No Internet Required**: It works completely offline.\n* **Models Exploration**: This feature allows developers to browse and download different kinds of LLMs to experiment with. You can select about 1000 open-source language models from popular options like LLama, Mistral, and more.\n* **Local Documents**: You can let your local LLM access your sensitive data with local documents like `.pdf` and `.txt` without data leaving your device and without a network.\n* **Customization options**: It provides several [chatbot](https://getstream.io/blog/llm-chatbot-docs/) adjustment options like temperature, batch size, context length, etc.\n* **Enterprise Edition**: GPT4ALL provides an enterprise package with security, support, and per-device licenses to bring local AI to businesses.\n\n\n## Get Started With GPT4All\n\nTo start using GPT4All to run LLMs locally, [Download](https://www.nomic.ai/gpt4all) the required version for your operating system.\n\n\n## Benefits of Using GPT4ALL\n\nWith the exception of Ollama, GPT4ALL has the most significant number of GitHub contributors and about 250000 monthly active users (according to <https://www.nomic.ai/gpt4all>) and compared to its competitors. The app collects anonymous user data about usage analytics and chat sharing. However, users have the options to opt in or out. Using GPT4ALL, developers benefit from its large user base, GitHub, and Discord communities.\n\n\n## 5. Ollama\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*STAonWgWIsY6cgDR)\n\nUsing [Ollama](https://ollama.com/), you can easily create local chatbots without connecting to an API like OpenAI. Since everything runs locally, you do not need to pay for any subscription or API calls.\n\n\n## Key Features of Ollama\n\n* **Model Customization**: Ollama allows you to convert `.gguf` model files and run them with `ollama run modelname`.\n* **Model Library**: Ollama has a large collection of models to try at [ollama.com/library](https://ollama.com/library).\n* **Import Models**: Ollama supports importing models from [PyTorch](https://pytorch.org/).\n* **Community Integrations**: Ollama integrates seamlessly into web and desktop applications like, [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI), [HTML UI](https://github.com/rtcfirefly/ollama-ui), [Dify.ai](https://github.com/rtcfirefly/ollama-ui), and [more](https://github.com/ollama/ollama?tab=readme-ov-file#community-integrations).\n* **Database Connection**: Ollama supports several [data platforms](https://github.com/mindsdb/mindsdb/blob/main/mindsdb/integrations/handlers/ollama_handler/README.md).\n* **Mobile Integration**: A SwiftUI app like [Enchanted](https://github.com/AugustDev/enchanted) brings Ollama to iOS, macOS, and visionOS. [Maid](https://github.com/Mobile-Artificial-Intelligence/maid) is also a cross-platform Flutter app that interfaces with `.gguf`model files locally.\n\n\n## Get Started With Ollama\n\nTo use Ollama for the first time, visit <https://ollama.com> and download the version for your machine. You can install it on Mac, Linux, or Windows. Once you install Ollama, you can check its detailed information in Terminal with the following command.\n\n`ollama`\n\nTo run a particular LLM, you should download it with:\n\n`ollama pull modelname`, where `modelname` is the name of the model you want to install. Checkout Ollama on [GitHub](https://github.com/ollama/ollama) for some example models to download. The `pull` command is also used for updating a model. Once it is used, only the difference will be fetched.\n\nAfter downloading for example, `llama3.1`, running `ollama run llama3.1` in the command line launches the model.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aglZm6h0BU6GAYkSl04XWA.gif)\n\nIn the above example, we prompt the `llama3.1` model to solve a Physics work and energy question.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*dNNQYpz1s2tz1pcn)\n\n\n## Benefits of Using Ollama\n\nOllama has over 200 contributors on GitHub with active updates. It has the largest number of contributors and is more extendable among the other open-source LLM tools discussed above.\n\n\n## 6. LLaMa.cpp\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*KhsAUquhDZAHghxK)\n\n[LLaMa.cpp](https://github.com/ggerganov/llama.cpp) is the underlying backend technology (inference engine) that powers local LLM tools like Ollama and many others. Llama.cpp supports significant large language model inferences with minimal configuration and excellent local performance on various hardware. It can also run in the cloud.\n\n\n## Key Features of LLaMa.cpp\n\n* **Setup**: It has a minimal setup. You install it with a single command.\n* **Performance**: It performs very well on various hardware locally and in the cloud.\n* **Supported Models**: It supports popular and major LLMs like [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1), [Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral), [DBRX](https://huggingface.co/databricks/dbrx-instruct), [Falcon](https://huggingface.co/models?search=tiiuae/falcon), and [many others](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#description).\n* **Frontend AI Tools**: LLaMa.cpp supports open-source LLM UI tools like [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT), [iohub/collama](https://github.com/iohub/coLLaMA), etc.\n\n\n## Get Started With LLaMa.cpp\n\nTo run your first local large language model with llama.cpp, you should install it with:\n\n`brew install llama.cpp`\n\nNext, download the model you want to run from Hugging Face or any other source. For example, download the model below from Hugging Face and save it somewhere on your machine.\n\n[`https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.g`guf](https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf)\n\nUsing your preferred command line tool like Terminal, `cd` into the location of the `.gguf` model file you just downloaded and run the following commands.\n\n\n```python\nllama-cli --color \\ \n-m Mistral-7B-Instruct-v0.3.Q4_K_M.ggufb \\ \n-p \"Write a short intro about SwiftUI\"\n```\nIn summary, you first invoke the LLaMa CLI tool and set color and other flags. The `-m` flag specifies the path of the model you want to use. The `-p` flag specifies the prompt you wish to use to instruct the model.\n\nAfter running the above command, you will see the result in the following preview.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4Al-j50vXUXLUfvxzBt6aw.gif)\n\n\n## Local LLMs Use Cases\n\nRunning LLMs locally can help developers who want to understand their performance and how they work in detail. Local LLMs can query private documents and technical papers so that information about these documents does not leave the devices used to query them to any cloud AI APIs. Local LLMs are useful in no-internet locations and places where network reception is poor.\n\nIn a [telehealth setting](https://getstream.io/blog/telemedicine-app-development/), local LLMs can sort patient documents without having to upload them to any AI API provider due to privacy concerns.\n\n\n## Evaluating LLMs‚Äô Performance To Run Locally\n\nKnowing the performance of a large language model before using it locally is essential for getting the required responses. There are several ways you can determine the performance of a particular LLM. Here are a few ways.\n\n* **Training**: What dataset is the model trained on?\n* **Fine-tuning**: To what extent can the model be customized to perform a specialized task or can it be fine-tuned to for a specific domain?.\n* **Academic Research**: Does the LLM have an academic research paper?\n\nTo answer the above questions, you can check excellent resources like [Hugging Face](https://huggingface.co/datasets) and [Arxiv.org](https://arxiv.org/). Also, [Open LLm Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) and [LMSYS Chatbot Arena](https://chat.lmsys.org/?arena) provide detailed information and benchmarks for varieties of LLMs.\n\n\n## Local LLM Tools Conclusion\n\nAs discussed in this article, several motives exist for choosing and using large language models locally. You can fine-tune a model to perform a specialized task in a [telemedicine app](https://getstream.io/chat/solutions/healthcare/) if you do not wish to send your dataset over the internet to an AI API provider. Many open-source Graphic User Interface (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude. You also discovered the various powerful command-line LLM applications like Ollama and LLaMa.cpp that help you run and test models locally and without an internet connection. Check out Stream‚Äôs [AI Chatbot](https://getstream.io/chat/solutions/ai-integration/) solution to integrate an AI chat into your app and visit all the related links to learn more.\n\n*Originally published at [https://getstream.io](https://getstream.io/blog/best-local-llm-tools/).*\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-best-conversational-ai-virtual-health-care-assistants-for-aging-adults-fc65bcfb9cf4","frontmatter":{"title":"The Best Conversational AI Virtual Health Care Assistant for Aging Adults","meta_title":"The Best Conversational AI Virtual Health Care Assistant for Aging Adults","description":"Virtual Health Care Assistants, such as MiiHealth.ai, are transforming healthcare for aging adults, particularly those living alone. These AI-driven companions assist with medication management, provide 24/7 support, monitor health conditions, and offer personalized fitness advice. They also help alleviate loneliness by engaging users in conversation. MiiHealth.ai stands out for its user-friendly interface, tailored services, and emotional support, making it an essential tool for promoting independence and well-being among seniors.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PBuPT38hZv61TFXQzJZ_3w.jpeg","categories":["Health","Chatbots","Autonomous Systems"],"author":"Rifx.Online","tags":["Virtual","Healthcare","Assistants","Medication","Monitoring"],"draft":false,"slug":"blog/the-best-conversational-ai-virtual-health-care-assistants-for-aging-adults-fc65bcfb9cf4"},"content":"\n\n\n\nLooking after our health becomes even more difficult as we grow older, and this is even worse for seniors who live alone. Although managing medications, doctors visits, and overall health becomes a challenge for many ageing Americans. But how would you like if you had a companion ‚Äî a person who would help you take pills on time, call you if you felt lonely, and even ask how you were? This is the magic of Virtual Health Care Assistants, and they‚Äôre revolutionizing health care for aging people.\n\nCompanies like [**MiiHealth.ai**](https://miihealth.ai/) are at the forefront of creating the intelligent, AI driven companions that help seniors with their health issues and connecting them with their loved ones. Now let‚Äôs find out how these Virtual Health Care Assistants are changing the lives of the elderly persons who are living alone and why they are thus fast becoming indispensable when it comes to caregiving for the elderly.\n\n\n## What Exactly is a Virtual Health Care Assistant?\n\nVirtual Health Care Assistant is a conversational agent that is specifically intended to assist people to deal with their health care issues. These assistants can interact with users and provide health information, pill‚Äôs schedules and provide comfort when the patient is overwhelmed. They can do things such as checking a patient‚Äôs blood pressure, recommended exercises or even just chat with the patient, all via voice control or SMS.\n\n\n\nTo anybody facing the difficult task of aging single, these assistants are not only high\\-tech gadgets but real life partners when it comes to health and well being any time of the day or night. For a Senior needing to receive a short note or a SOS call, a [**Virtual Health Care Assistant**](https://miihealth.ai/) can be helpful.\n\n\n## Why Virtual Health Care Assistants Are a Game\\-Changer for Aging Adults\n\nBeing single and enjoying ones seniority comes with especial difficulties that seniors face especially in USA. From handling intricate health schedules to coping with loneliness, the family‚Äôs assistance requirement is higher than before. A Virtual Health Care Assistant can provide that support in several impactful ways:\n\n**1\\. Medications Organized and Track**\n\nPeople with ER, as with any other chronic illness, require effective management of medications for optimal results. Not taking a dose at the right time or taking a wrong medication may lead to terrible results. As a Health Care Assistant in virtual Delivery, one can be able to remind the seniors to take their medications, hence they stick to the required schedules. They are as follows: generic ones that can be adjusted based on the person‚Äôs schedule and dosage of specific medication.\n\nBesides reminders, these Assistant AI can assist in observing the side effects of taken medications and attendance of the symptoms which can ease the caring for elderly people and their relatives. For instance, when a senior is taking antihypertensive or diabetic pills, the assistant can quiz them concerning their health and recommend the time to monitor blood pressure.\n\n**2\\. 24/7 Availability \\& Support**\n\nOne of the traits that many people love about a Virtual Health Care Assistant is that it is always around: day or night. This is particularly the case for seniors who might feel lonely or anxious as well as during unpleasant hours when core caregivers are perhaps asleep. From explaining a recent change to providing a conversation with when there is nothing else to talk about these assistants are there to assist.\n\nFinancial dependency is especially significant for elderly citizens who have no one or nothing else they can turn to at specific hour of each day. Besides, these assistants can answer a number of questions, addressing even health issues, simple or complicated, without the need to book an appointment or get an assistant‚Äôs help.\n\n**3\\. Emergency Alerts Health Monitoring**\n\nVirtual Health Care Assistants are also advantageous in that they can keep track of a senior‚Äôs condition at all times and react to a crisis. For instance, most of the AI assistants can incorporate with tracking devices such as wristbands or watches monitor pulse rates, blood pressure, and even falls. It will also enable an assistant to communicate with other people if the senior falls or develops the signs of an illness.\n\nIt is especially important for older adults who may not be able to get assistance at the times closest to or right during the time of the emergency. Whether one stumbles and falls, if there is an abnormal health check or one feels uncomfortable, the assistant is there as extra security.\n\n**4\\. Exclusive Health Information \\& Fitness Advices**\n\nHealth requirements for any two people are unique, and a Virtual Health Care Assistant can offer assistance suited to these requirements. To seniors it could mean suggesting which exercises are not very strenuous on the joints or suggesting what sort of foods would be good for a certain disease such as diabetes or heart ailment.\n\nUnlike regular programs that need constant reinstallation, these assistants are programmed to master from the user thus making them smarter as time progresses. They remain flexible to achieve what a senior wants, monitor his/her improvement and even provide advice concerning the person‚Äôs condition.\n\n**5\\. The major way of alleviating loneliness and enhancing mental health.**\n\nMay also be involve loneliness that is prevalent in the older adults and its impacts it on individuals‚Äô health. A Virtual Health Care Assistant can be designed to also offer some form of companionship to seniors, when lonely they can engage the Virtual Health Assistant in a conversation. Thus, the assistant is not a replacement for social interaction with others, though the tool can respond to simple messages, tell the jokes, and encourage the user.\n\nCertain assistants are built to help seniors build meaningful interactions with friends and family, or participate in virtual events. First, AI tools provide social companionship; seniors need to feel that they are accepted and loved in order to be healthy.\n\n\n## Why MiiHealth.ai is a Top Choice for Seniors\n\nWhen considering employing a Virtual Health Care Assistant, then MiiHealth.ai is easy to use, technology\\-driven and can handle senior clients‚Äô needs. Here are some reasons why MiiHealth.ai is a top choice for older adults:\n\n* **Simple \\& Intuitive Interface**: It is noteworthy that the creation of MiiHealth software is friendly for a user. The elders are also not required to possess tremendous technical know\\-how so as to operate the platform. This means that the voice command system affords it easy usage even to a person with low technological literacy.\n* **Tailored to Seniors‚Äô Needs:** MiiHealth.ai differs from other organizations in that it offers services regarding the health of the aging population with the understanding that its services must be individualized. It is flexible for all its users; it can notify one about the time to take a medicine, and it could inform another about the right time to exercise.\n* **Emotional Support:** Besides, meeting the physical needs, the MiiHealth.ai has an emotional and social component to alleviate the feelings of loneliness that many seniors, who live alone, experience.\n* **Comprehensive Health Monitoring:** Connecting to wearable health devices, MiiHealth.ai regularly controls a senior‚Äôs vital indicators and notifies when necessary.\n\n\n## Conclusion\n\nSimilarly for elderly Americans, being single does not necessarily mean lacking the care to sustain a healthy and happy life or deal with an illness. In that regards Virtual Health Care Assistants such us MiiHealth.ai provide people with highly effective tool that allows accessing the best of AI technologies as well as highly individualized healthcare support.\n\nIn terms of administering medications and issuing emergency alerts through to company and providing conversation and advice on well\\-being, these assistants are changing the face of health care for the elderly. Whether for education, support or companionship, Virtual Health Care Assistants bring the care to older adults as they ensure they remain independent, connected and well.\n\nIf you or someone in your family needs reliable and caring personal assistant for health related issues you should familiarize yourself with [MiiHealth.ai](http://miihealth.ai). It is a ready way towards a better and fulfilled life for seniors who reside alone.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-focus-is-shifting-from-ai-agents-to-ai-agent-tool-use-a84fc061eec8","frontmatter":{"title":"The Focus Is Shifting From AI Agents To AI Agent Tool Use","meta_title":"The Focus Is Shifting From AI Agents To AI Agent Tool Use","description":"The article discusses the evolving focus in AI development from creating autonomous AI agents to enhancing the tools they utilize. Key advancements include AI agents like OpenAIs upcoming Operator, which will perform tasks on users computers through GUI navigation. Anthropic has also released a reference implementation for AI agents that interact with virtual environments, showcasing tools for GUI interactions, command-line operations, and file manipulation. These developments emphasize the importance of tool access in augmenting the capabilities of AI agents.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7IELtMakzcc68bdb4usXBQ.png","categories":["Programming","Technology","Autonomous Systems"],"author":"Rifx.Online","tags":["Operator","GUI","Navigation","Command","File"],"draft":false,"slug":"blog/the-focus-is-shifting-from-ai-agents-to-ai-agent-tool-use-a84fc061eec8"},"content":"\n\n\n\n\n\n\n### The focus regarding AI Agents is shifting from simply developing autonomous AI Agents to enhancing the tools available to them, which directly affects their power and flexibility.\n\nThe functionality and reach of AI Agents depend heavily on tool access, with tools described in natural language and activated through the agent‚Äôs internal reasoning.\n\nDesktops and other user\\-specific environments offer the rich context that agents need to perform tasks effectively, making them ideal operational spaces.\n\n\n## ‚ú®‚ú® Follow me on LinkedIn ‚ú®‚ú®\n\n\n## Introduction\n\nAs models become utilities, tool\\-enabled frameworks and environments are emerging as key, with leading AI companies like OpenAI and Anthropic exploring AI Agents that use computer GUI navigation to accomplish complex tasks.\n\nAlso recently announced, OpenAI is gearing up to release an **AI Agent**, *Operator*, which will perform tasks autonomously on a user‚Äôs computer, like coding and booking travel, available as a research preview in January.\n\nThis release aligns with an industry\\-wide shift toward more capable **Agentic Tools** that manage multi\\-step workflows with minimal oversight.\n\nOther major players are also launching agent tools capable of real\\-time computer navigation, reflecting a strategic move to enhance AI Agent capabilities through tool access rather than simply improving model power.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*q7YvQLqfVdhV3bZM2oflDQ.png)\n\n\n## Anthropic Computer Use\n\nAnthropic has made available a [reference implementation](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) that includes everything you will need to get started quickly with computer use.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vD4T4Bo2-JcH535TOc46BQ.png)\n\nThe image above shows the AI Agent running on my desktop, I had to install Docker in my MacBook and deploy the docker image onto my machine.\n\nThe script shown below is all you need to deploy the instance and have it up and running.\n\n\n```python\nexport ANTHROPIC_API_KEY=%your_api_key%\ndocker run \\\n    -e ANTHROPIC_API_KEY=<Your Anthropic API Key Goes Here> \\\n    -v $HOME/.anthropic:/home/computeruse/.anthropic \\\n    -p 5900:5900 \\\n    -p 8501:8501 \\\n    -p 6080:6080 \\\n    -p 8080:8080 \\\n    -it ghcr.io/anthropics/anthropic-quickstarts:computer-use-demo-latest\n```\nBelow is a screenshot of the terminal window from where I run the file‚Ä¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mTu4gGEwnFbQYqJ-YGYqIA.png)\n\nThe implementation consists of:\n\n* A [containerised environment](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/Dockerfile) suitable for computer use with Claude\n* Implementations of [the computer use tools](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/computer_use_demo/tools)\n* An [agent loop](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/computer_use_demo/loop.py) that interacts with the Anthropic API and executes the computer use tools\n* A web interface to interact with the container, agent loop, and tools.\n\n\n## Anthropic AI Agent Detail\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*euT2ZTmjVV5cTK-j8i4fgg.png)\n\nThe Anthropic **AI Agent** has access to three main **tools/functions** that allow me to interact with the Ubuntu virtual machine environment:\n\n\n### computer function:\n\n* This is the primary interface to interact with the GUI environment\n* Allows the AI Agent to perform mouse and keyboard actions like:\n* Moving the cursor (`mouse_move`)\n* Clicking (`left_click`, `right_click`, `middle_click`, `double_click`)\n* Typing text (`type`)\n* Pressing keyboard combinations (`key`)\n* Taking screenshots (`screenshot`)\n* The display resolution is set to 1024x768\n* Display number is :1\n* The AI Agent needs to check coordinates via screenshots before clicking elements\n\n\n### bash function:\n\n* Gives AI Agent access to a bash shell to run commands\n* State persists across commands\n* Can install packages via apt and pip\n* Can run background processes\n* For GUI applications, needs DISPLAY\\=:1 environment variable set\n\n\n### str\\_replace\\_editor function:\n\n* File manipulation tool that allows:\n* Viewing files and directories (`view`)\n* Creating new files (`create`)\n* Replacing text in files (`str_replace`)\n* Inserting text at specific lines (`insert`)\n* Undoing edits (`undo_edit`)\n* Maintains state across operations\n\n\n## Important Constraints\n\n* Cannot create accounts on social media/communication platforms\n* Cannot handle CAPTCHA/reCAPTCHA without user assistance\n* Cannot agree to Terms of Service without user direction\n* Cannot post comments/reactions on social media\n* Cannot access voter registration or election infrastructure data\n\nThe system is running on an aarch64 architecture Ubuntu VM, and I ran it via a Docker container on my laptop.\n\nThe tools provide the AI Agent with a controlled but flexible way to interact with the virtual environment, combining GUI interactions, command\\-line operations, and file manipulation capabilities.\n\nMy environment is freshly initialised for each session, but maintains state within a session across tool invocations.\n\nThe AI Agent can use the internet through Firefox and install additional software as needed through the package management system.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4env1UkoKOZ-3zmF.png)\n\n[***Chief Evangelist***](https://www.linkedin.com/in/cobusgreyling/) ***@*** *[Kore.ai](https://blog.kore.ai/cobus-greyling) \\| I‚Äôm passionate about exploring the intersection of AI and language. From Language Models, AI Agents to Agentic Applications, Development Frameworks \\& Data\\-Centric Productivity Tools, I share insights and ideas on how these technologies are shaping the future.*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4env1UkoKOZ-3zmF.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4env1UkoKOZ-3zmF.png)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-future-of-chatgpt-explained-everything-will-change-in-the-next-5-years-4bfd46ddca0b","frontmatter":{"title":"The Future of ChatGPT Explained: Everything Will Change in the Next 5 Years","meta_title":"The Future of ChatGPT Explained: Everything Will Change in the Next 5 Years","description":"OpenAI has outlined a five-step roadmap for the evolution of ChatGPT towards achieving Artificial General Intelligence (AGI). The stages include: 1) Chatbots, which focus on conversational AI; 2) Reasoners, capable of solving complex problems; 3) Agents, which can independently make decisions; 4) Innovators, collaborating with humans for innovation; and 5) Organizations, functioning as fully autonomous entities. Currently, OpenAI is between Levels 1 and 2, aiming to reach AGI within five years, with significant advancements expected by 2025.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nCVwPhWiFZ_0lglxT4pDAw.jpeg","categories":["Chatbots","Artificial General Intelligence","Reasoners"],"author":"Rifx.Online","tags":["Chatbots","Reasoners","Agents","Innovators","Organizations"],"draft":false,"slug":"blog/the-future-of-chatgpt-explained-everything-will-change-in-the-next-5-years-4bfd46ddca0b"},"content":"\n\n\n\n\n## This Could Take Artificial Intelligence Really, Really Far‚Ä¶\n\n\n\nOpenAI has laid out a **clear vision** for the evolution of ChatGPT, recently unveiling a **five\\-step roadmap** to reach what they call **Artificial General Intelligence** (AGI).\n\nAGI represents a theoretical AI system capable of **learning**, **understanding**, and **performing any intellectual task** at a human level, all autonomously and adaptively.\n\nIt‚Äôs a groundbreaking vision, but reaching this ambitious goal requires moving through **five critical stages**:\n\n\n## Level 1: Chatbots\n\nThe first level, where we currently find systems like ChatGPT, is centered on **conversational AI**. At this stage, AI can interact naturally with humans, handling various dialogues with impressive fluency and coherence.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ObzqCLMIIqpU9RK-TbTrfQ.png)\n\n\n## Level 2: Reasoners\n\nAt this next stage, AI systems will be able to **tackle complex problems** involving advanced math and logic. We‚Äôre already seeing glimpses of this with ChatGPT‚Äôs latest version, ‚Äúo1\\-preview,‚Äù marking a bridge between Levels 1 and 2, known as the ‚Äúreasoning‚Äù phase.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*B42LqC8ZDSaSYPX4yd3_Ng.png)\n\n\n## Level 3: Agents\n\nThis is the level where AI begins making decisions and executing tasks **independently**, without the need for human oversight. Imagine an AI that not only assists but initiates and completes tasks **on its own** ‚Äî this is the dream for future iterations of ChatGPT.\n\n\n## Level 4: Innovators\n\nOnce AI reaches the ‚ÄúInnovators‚Äù level, it will have the ability to drive and contribute to innovation **alongside humans actively**. At this point, AI won‚Äôt just follow human instructions; it‚Äôll collaborate and bring new ideas to the table.\n\n\n## Level 5: Organizations\n\nAt the final level, AI will have the capacity to operate as an entire organization ‚Äî capable of performing tasks **as if it were a team of skilled humans**. This future version of AI would function like **a fully autonomous business entity**, handling everything from strategy to execution.\n\n\n## So, Where Are We Now?\n\nOpenAI currently sits between Levels 1 and 2\\. According to Sam Altman, CEO of OpenAI, the company aims to reach AGI within roughly five years.\n\nThe next major milestone will likely come with the arrival of ‚Äúreasoners,‚Äù possibly as early as 2025 with the anticipated release of **GPT\\-5**, which is expected to achieve **the intellectual level of a PhD in numerous fields**.\n\nThanks for reading!\n\n**P.S.** Want a cool trick (like, magician\\-level) to simplify your prompt writing?\n\nI‚Äôve got exactly **what you need**! üëá\n\nNick\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-most-ambitious-ai-crypto-project-ever-is-here-ab3f6d85afd1","frontmatter":{"title":"The Most Ambitious AI Crypto Project Ever is Here","meta_title":"The Most Ambitious AI Crypto Project Ever is Here","description":"The article discusses an ambitious project by Near to train a decentralized open-source large language model (LLM) with 1.4 trillion parameters, significantly larger than existing models. This initiative aims to combine AI and blockchain technologies, allowing individuals to own and benefit from the AI model they help train. The project seeks to raise $160 million through crowdfunding and utilizes innovative distributed training methods to overcome challenges of synchronization and communication in a decentralized environment. The integration of blockchain is crucial for ensuring transparency and trust in the ownership and rewards associated with the models usage. However, concerns about the feasibility of such a large-scale model and the efficiency of blockchain technology remain.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uiBwsWl8grXKJCJaGtH7kw.png","categories":["Technology","Machine Learning","Blockchain"],"author":"Rifx.Online","tags":["blockchain","parameters","crowdfunding","synchronization","transparency"],"draft":false,"slug":"blog/the-most-ambitious-ai-crypto-project-ever-is-here-ab3f6d85afd1"},"content":"\n\n\n\n\n### AI \\& Blockchains: A Match Made in Heaven, or a Scam?\n\n\n\nOne of the founding fathers of modern AI wants to use the blockchain to train the world's largest open\\-source Large Language Model (LLM), almost four times larger than Llama 3\\.1 405B, generally considered the best open LLM.\n\nAnd before you dismiss this headline as scammy hype, please be aware that the person who stated this goal is none other than ***Illia Polosukhin***, one of the researchers behind the ‚ÄúAttention is All you Need‚Äù paper, the seminal piece that led to our current AI revolution.\n\nSo, *what is exactly what they want to do? And what‚Äôs the role of the blockchain in all this?*\n\nRead on to learn how the worlds of AI and Crypto will irremediably merge and about the project that could finally make an AI model that is owned by the people.\n\n\n> You are probably sick of AI newsletters that simply explain what happened. That‚Äô easy and anyone can do it, which is why there are so many.\n\n\n> But explaining why it matters is another story. That requires knowledge, investigation, and deep thought‚Ä¶ all attributes of the people who engage weekly with **TheTechOasis**, the newsletter that aims to answer the most pressing questions in AI.\n\n\n> üèùÔ∏èüèùÔ∏è Subscribe today below:\n\n\n## Owning AI\n\nWith Trump‚Äôs win, Crypto has entered an improvised bull cycle, [taking Bitcoin eerily close to the $100k per coin mark](https://coinmarketcap.com/currencies/bitcoin/) and reaching new all\\-time highs.\n\n\n### The Near Project\n\nUnder Trump, blockchain companies have good reason to be optimistic about the future. One of these companies is Near, which is trying to bridge the worlds of Crypto and AI.\n\nI won‚Äôt go into more detail about this project because I don‚Äôt want you to feel I‚Äôm sponsoring it (I do not own NEAR coins). However, they‚Äôve recently started a great, ambitious goal I deeply align with:\n\nTraining the largest open\\-source model ever, crowdfunded by individuals, and owned by them.\n\nSpecifically, **they want to train a 1\\.4 trillion\\-parameter model**, one that would rival the size of models like GPT\\-4 and be 3\\.5 times larger than the largest open\\-source (or dare I say, open\\-weight) LLM in the world, Meta‚Äôs Llama 3\\.1 405B, which is also considered the best open model today.\n\nTo achieve this, **they expect to have to crowdfund a sizeable amount of $160 million**, funded through the acquisition of $NEAR coins, a cryptocurrency that, as of today, [has a market value of $6\\.6 billion](https://coinmarketcap.com/currencies/near-protocol/).\n\nHowever, the real issue isn‚Äôt size, but the fact they want to train this model in a decentralized manner through poorly\\-communicated hardware. In layman‚Äôs terms, they don‚Äôt intend to train this model in a [140 MegaWatt data center with 100,000 GPUs](https://readmedium.com/putting-the-worlds-largest-ai-supercomputer-into-perspective-60afde9bc653) like the one Elon Musk owns in Memphis, Tennessee, but training it on a global scale.\n\nFor someone familiar with how these models are trained, this is as ambitious as one can be in AI today.\n\n*But why?*\n\n\n### The Importance of Time\n\nYou may have heard the crazy numbers regarding AI training and inference, but these numbers are just a fraction of what‚Äôs coming.\n\n* [Elon Musk has 100,000 NVIDIA H100 GPUs](https://readmedium.com/putting-the-worlds-largest-ai-supercomputer-into-perspective-60afde9bc653) in one location and intends to double the compute power to 200,000 H100 equivalents in the next months.\n* All Hyperscalers (Microsoft, Amazon, Meta, Google, or Oracle) are reaching or have [reached deals with nuclear power plants](https://www.technologyreview.com/2024/09/26/1104516/three-mile-island-microsoft/) or Small Modular Reactor companies to build nuclear power generation to power their data centers and avoid the excessive lead times of transmission lines and electrical transformers\n* [A Hyperscaler pitched North Dakota Governor Doug Burgum about building a **5‚Äì10 GigaWatt data center**](https://thetechoasis.beehiiv.com/p/understanding-ai-s-big-picture). For reference, the latter data center would have more compute capacity than [Microsoft‚Äôs entire Azure cloud (5 GW)](https://www.datacenterdynamics.com/en/news/microsoft-to-double-new-data-center-capacity-this-year-report/), and consume enough power to provide electricity to **8\\.3 million US homes at the average US household consumption value of 10,500 KWh/year**.\n\nAnd the list goes on. *But why?*\n\n**The reason is time**. To train a model, you send it data, force it to sample a prediction, and measure how good that prediction was. Based on that error signal, we then update the model's parameters so that the prediction error falls over time.\n\nThe issue with this process is two\\-fold:\n\n* The models are huge, meaning that each time we have to update parameters, we are updating potentially trillions of them.\n* The data sets are also huge, meaning the amount of parameter updates is unfathomably large.\n\nThis leads to training runs that take, if executed sequentially, forever. Luckily, as most frontier AI models today are basically matrix multiplications on steroids, a very similar mathematical computation to rendering pixels on a computer screen, the original goal of GPUs, we can use this hardware to train these models.\n\nCrucially, GPUs are meant to parallelize computation, meaning that we can parallelize the training of these models extensively ([although not fully due to Amdahl‚Äôs Law](https://thetechoasis.beehiiv.com/p/understanding-ai-s-big-picture)).\n\nThis is why models like [Llama 3\\.1 405B were trained on a 24,000 GPU cluster](https://arxiv.org/pdf/2407.21783) and why models like the new Grok from xAI and [Llama 4 from Meta](https://www.tomshardware.com/tech-industry/artificial-intelligence/meta-is-using-more-than-100-000-nvidia-h100-ai-gpus-to-train-llama-4-mark-zuckerberg-says-that-llama-4-is-being-trained-on-a-cluster-bigger-than-anything-that-ive-seen) are being trained in 100,000\\-plus GPU clusters.\n\nOk, I get these models need a lot of GPUs working simultaneously to get trained. *But how do they do it?*\n\n\n### The essence of distributed training\n\nIn distributed training, instead of training one single model and updating it by sending all the data to that instance, we build replicas, identical versions of the model, each assigned to a given GPU pod (a pod is a group of tightly connected and collocated GPUs).\n\nThen, we batch the training set, and set the batches to the different pods. Of course, that means that each replica receives different training data and, thus, learns different things.\n\nConsequently, **every certain time the GPU pods need to synchronize**, sharing their learnings with the other pods, meaning that, after this synchronous stage, all model replicas have the exact same parameter values (as each model replica is actually updated with the average learning value, so that all model replicas learn the same after each batch training step).\n\nWhile all this seems well and good, this synchronization is a big issue because these synchronous updates mean all pods are basically stalled for the duration of the synchronization, **pulling us dangerously close to making the training run too long (these trainings take literally months)**.\n\nAnd to make matters worse, Near wants to do this in low\\-bandwidth form, meaning that the communication channels between the GPU pods will be slow.\n\nThus, *how can they do this, and what role will the blockchain play?* Luckily, we kind of know the answer to both in much more detail than what you would expect.\n\n\n## Toward Decentralized AI\n\nLuckily for Near, they aren‚Äôt the only ones thinking about decentralized AI (although Near adds the blockchain; we see how they‚Äôll do it later), as at the time of writing, **the world‚Äôs largest decentralized training run is taking place as you read this piece**.\n\n\n### The Prime Framework\n\nPrime Intellect is a company working toward the vision of training massive LLMs in a decentralized manner, aiming to train ***Intellect\\-1***, a 10\\-billion parameter model, in a fully decentralized way.\n\nIn other words, the training run is distributed across several GPUs, **which are owned by independent parties**, potentially separated across continents, and connected through low\\-bandwidth networks.\n\n\n> You can watch the progress and the different parties involved [through this app](https://app.primeintellect.ai/intelligence?utm_source=thetechoasis.beehiiv.com&utm_medium=newsletter&utm_campaign=should-ai-s-kill-openai-s-swarm-the-future-of-ai-training&_bhlid=8eadb6cf7d24b545a761f9ac3f7126a45ac2b579).\n\nThis gives us great insight into how Near will achieve its mission of training the largest open\\-source AI model ever.\n\nAs you may have guessed from the previous section, the main bottleneck in AI training is the synchronous update. According to Amdahl‚Äôs Law, **parallelization can be an exercise of diminishing returns if a certain point in the training can‚Äôt be parallelized**.\n\nTherefore, as you increase parallelization, the time\\-saving improvements become incremental, as we can‚Äôt reduce the synchronization time.\n\n\n> In case you‚Äôre wondering, synchronization can‚Äôt be performed asynchronously (each pod updating its parameter values independently) as model convergence becomes impossible (at least for our current knowledge).\n\nKnowing this, Prime Intellect has put into practice several techniques that Near will surely capitalize on:\n\n* **Synchronization every hundreds of steps**.\n\nInstead of synchronizing the GPU pods in every parameter update, each pod carries its ‚Äòpseudo\\-gradients‚Äô (accumulating its learnings across several local training time steps), and every 100 of these timesteps, it shares its learnings with the rest.\n\nSimply put, as learning sharing is the main bottleneck to training performance, we minimize the number of times GPU pods communicate.\n\n* **Quantization of communication payload**.\n\nThe number of times you communicate across pods isn‚Äôt the only thing that affects time; the amount of shared information matters, too. Thus, we quantize the learnings so that information travels in a compressed form, making it faster.\n\nThis reduces communication requirements by 400x. In standard form, synchronization takes up to 40 minutes. With this quantization, it takes less than a minute.\n\n\n> **What is quantization?** In a nutshell, we take the information we want to store (or share, as in this case) and reduce the per\\-parameter precision (instead of ‚Äò1\\.023293,‚Äô that number travels as a ‚Äò1‚Äô) of the optimizer states (the states that carry what each model replica is learning).\n\n\n> **Think of this is as compressing the data into a zip file before sending it so the size of the sent packet is smaller and, thus, faster to send.**\n\n\n> However, while the original numbers can be recovered (dequantization), it incurs some precision loss, which can affect performance. However, [Prime Intellect claims they did not appreciate any performance loss](https://www.primeintellect.ai/blog/intellect-1) despite the massive time savings.\n\n* **Dynamic global groups**\n\nOne of the biggest issues of decentralized model training is unreliability; both the network and, above all, the workers (GPUs) may break and fail. Also, **you want to incentivize this dynamism**, so that people can jointly enter the training run and log off when desired.\n\nFor this, the Prime framework has **dynamic global groups** that ensure workers can on\\-ramp and off\\-ramp without impacting the overall training run.\n\nFurthermore, the framework includes other techniques like asynchronous checkpointing that I won‚Äôt go into for the sake of length but that you can [read in full detail here](https://www.primeintellect.ai/blog/intellect-1).\n\nBut we still haven‚Äôt answered the key question: *Where does the blockchain fit in all this?*\n\n\n## An Exciting Future Ahead\n\nOver the next four years, you will see blockchains in everything.\n\nYes, the *‚Äò{Insert something that works just fine} but now it‚Äôs decentralized‚Äô* type of slogans are coming back into our lives.\n\nWhile many of these new use cases will be pointless, blockchains do have a clear raison d‚Äô√™tre that makes them very valuable when used when necessary, not for the sake of saying you‚Äôre using a blockchain.\n\n\n### It‚Äôs‚Ä¶ a ledger\n\nBlockchains are decentralized ledgers. They store transaction information between two peers in blocks of transactions connected sequentially (hence the name).\n\n**This is a big deal because their decentralized nature makes this ledger almost impossible to tamper with**. True blockchains (which there aren‚Äôt that many today that meet this standard) are immutable and definite, the unequivocal source of truth that a transaction took place at some point.\n\nImportantly, they are ‚Äòtrustless,‚Äô meaning that cryptography, not centralized entities like banks, guarantees the untampered nature of the ledger.\n\n\n> The reason why they are so hard to tamper with is, you guessed it, their decentralized nature. The global network of nodes that secure the blockchain all have an exact copy of the network, updated every time a new block is added.\n\n\n> Therefore, to introduce tampered transactions, you would need to own a majority amount of these nodes, be that through investing huge amounts of compute in proof\\-of\\-work blockchains like Bitcoin (extremely costly), hacking a majority of the nodes (again, extremely costly) or by owning majority stakes in the blockchain‚Äôs cryptocurrency in proof\\-of\\-stake blockchains like Ethereum (again, extremely costly).\n\nLong story short, the value of blockchains is to make the act of tampering them a very, very bad idea economically speaking, one that is just simply not worth it.\n\nHence, their value is the idea that not only they are great sources of truth, providing trust to transaction making, but they are also exempt of centralized powers that may be incentivized to tamper them.\n\n*And how does that fit into AI?* Here‚Äôs where all comes full circle.\n\n\n### Owned AI Needs the Blockchain\n\nThe idea behind training a decentralized AI model is that the people who participate in training that model (be that with compute or with money) are rewarded for it.\n\nThus, the goal of this 1\\.4 trillion parameter model is that its inferences (the usage) will be paid back to its funders.\n\nAnd here‚Äôs where the blockchain comes in, as undeniable proof that *‚ÄòJane Doe from Nebraska‚Äô* paid $1,000 to fund this training or for *‚ÄòJohn Doe from Japan‚Äô* to prove they provided 100 hours of GPU compute into the training and, thus, both are rightful receptors of the benefits of that model‚Äôs inferences (every time the model runs, you get paid).\n\nNow, you may ask: Could a centralized entity manage this?\n\nFor sure, but the whole point of blockchains is to prevent the need for that central entity to exist in the first place and ensure that no one fully controls who owns what or how much you get paid.\n\nNow, all things considered, *is this vision actually possible today?*\n\n\n### Does Feasibility Meet Vision?\n\nIt‚Äôs very easy for anyone to align with Near's vision of AI, especially considering the people behind this project.\n\nEnvisioning a future where decentralized economies rise around AI to ensure people are paid for their data, content, compute, or expertise and get unequivocally and objectively rewarded for it is a vision anyone can empathize with.\n\nHowever, **a 1\\.4 trillion parameter model appears simply too large based on current standards**. As mentioned, *Intellect\\-1*, the largest known model being trained that way, **is 140 times smaller than what *Near* intends to build**.\n\nThe other concern is with the blockchain. For instance, one of the biggest lies regarding NFTs was that blockchains only stored that an NFT transaction took place, **but the NFT was stored ‚Äòoff\\-chain.‚Äô** Sadly, the truth was that only the data that is stored in the blockchain is fully protected, so the actual piece of ‚Äòart‚Äô was largely unprotected and easily clonable.\n\nHowever, blockchains are notoriously inefficient, meaning that the fewer data you have to store ‚Äòon\\-chain,‚Äô the better, making them very impractical.\n\nThus, if neither the model, nor the data, nor the compute used to train a model will be stored in the blockchain, *what‚Äôs the point?*\n\nLuckily, there‚Äôs a solution: zero\\-knowledge proofs, which I won‚Äôt go into today for the sake of length, may appear as the key enabler to guarantee that an event, even if it isn‚Äôt stored on\\-chain, really happened.\n\nThrough zk\\-proofs, someone could prove that the compute they claim to have dedicated to the training actually happened or that they truly funded the training run, by storing a registry of that transaction with a zk\\-proof attached that proves with a very high certainty that something that happened off\\-chain actually happened.\n\nThus, by just storing the zk\\-proof, we can guarantee that even off\\-chain data can be trusted. *The issue?* Zk\\-proofs aren‚Äôt ready yet due to their extensive compute requirements.\n\nHowever, one point still stands: If you truly believe AI can be decentralized, you have to trust blockchains are legit.\n\n*But how does this type of announcement make you feel? Are you excited about what the synergy between Crypto and AI has to offer?*\n\n*Or do you still think of a ‚Äòscam‚Äô whenever you see a blockchain mentioned?* If that‚Äôs the case, I don‚Äôt blame you, but if you manage to abstract yourself from Crypto‚Äôs countless scams, you‚Äôll realize this technology will play a vital role in AI.\n\nAnd if Near is right, that will be sooner than expected.\n\n\n> **For business inquiries on AI strategy or analysis, reach out at nacho@thewhitebox.ai**\n\n\n> If you have enjoyed this article, I share similar thoughts in a more comprehensive and simplified manner for free on my [LinkedIn](https://www.linkedin.com/in/ignacio-de-gregorio-noblejas/).\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-quest-for-production-quality-graph-rag-easy-to-start-hard-to-finish-46ca404cee3d","frontmatter":{"title":"The Quest for Production-Quality Graph RAG: Easy to Start, Hard to Finish","meta_title":"The Quest for Production-Quality Graph RAG: Easy to Start, Hard to Finish","description":"Overcoming the challenges of productionizing graph RAG","date":"2024-11-01T03:56:04.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RMudHNmBOgXM1Mubj1UTkw.jpeg","categories":["Programming","Data Science","Generative AI"],"author":"Rifx.Online","tags":["graph","RAG","production","uncertainty","optimization"],"draft":false,"slug":"blog/the-quest-for-production-quality-graph-rag-easy-to-start-hard-to-finish-46ca404cee3d"},"content":"\n\n\n\n\n### Overcoming the challenges of productionizing graph RAG\n\n\n\nWhen I read the recent article in VentureBeat about how Glean [just secured over $260 million in its latest funding round](https://venturebeat.com/data-infrastructure/how-to-take-advantage-of-a-generative-tool-fueling-gleans-260m-raise-graph-rag/), I had two immediate gut feelings. First, it was satisfying to see this very public example of graph RAG living up to its potential as a powerful, valuable technology that connects people with knowledge more efficiently than ever. Second, it felt surprising but validating to read:\n\n\n> One of the world‚Äôs largest ride\\-sharing companies experienced its benefits firsthand. After dedicating an entire team of engineers to develop a similar in\\-house solution, they ultimately decided to transition to Glean‚Äôs platform.\n\n\n> ‚ÄúWithin a month, they were seeing twice the usage on the Glean platform because the results were there,‚Äù says Matt Kixmoeller, CMO at Glean.\n\nAlthough I was surprised to read about the failure in a news article, struggling to bring graph RAG into production is what I would expect, based on my experience as well as the experiences of coworkers and customers. I‚Äôm not saying that I expect large tech companies to fail at building their own graph RAG system. **I merely expect that most folks will struggle to build out and productionize graph RAG ‚Äî even if they already have a very successful proof\\-of\\-concept.**\n\nI wrote a [high\\-level reaction to the VentureBeat article in The New Stack](https://bit.ly/4fjIlgJ), and in this article, I‚Äôd like to dive deeper into why graph RAG can be so hard to get right. First, I‚Äôll note how easy it has become, using the latest tools, to get started with graph RAG. Then, I‚Äôll dig into some of the specific challenges of graph RAG that can make it so difficult to bring from R\\&D into production. Finally, I‚Äôll share some tips on how to maximize your chances of success with graph RAG.\n\n\n## Getting started with graph RAG is easy\n\nSo if a big ride\\-sharing company couldn‚Äôt build their own platform effectively, then why would I say that it‚Äôs easy to implement graph RAG yourself?\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*l6EiwfjeUGLjVlYeiY1lqA.jpeg)\n\nWell, first of all, technologies supporting RAG and graph RAG have come a long way in the past year. Twelve months ago, most enterprises hadn‚Äôt even heard of retrieval\\-augmented generation. Now, not only is RAG support [a key feature of the best AI\\-building tools like LangChain](https://python.langchain.com/docs/tutorials/rag/), but just about every major player in the AI space has a RAG tutorial, and [there is even a Coursera course](https://www.coursera.org/projects/introduction-to-rag). There is no shortage of quick entry points for trying RAG.\n\nMicrosoft may not have been the first to do graph RAG, but they gave the concept a big push with a [research blog post earlier this year](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/), and they continue to work on related tech.\n\nHere on Medium, there is also a nice conceptual introduction, with some technical details, [from a gen AI engineer at Google](https://towardsdatascience.com/graph-rag-a-conceptual-introduction-41cd0d431375). And, in Towards Data Science, there is a recent and very thorough [how\\-to article on building a graph RAG system](https://towardsdatascience.com/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759) and testing on a dataset of scientific publications.\n\nAn established name in traditional graph databases and analytics, Neo4j, added vector capabilities to their flagship graph DB product in response to the recent gen AI revolution, and they have an excellent platform of tools for projects that require sophisticated graph analytics and deep graph algorithms in addition to standard graph RAG capabilities. They also have a [Getting Started With Graph RAG](https://neo4j.com/developer-blog/graphrag-ecosystem-tools/) guide.\n\nOn the other hand, [you don‚Äôt even need a graph DB to do graph RAG](https://bit.ly/3YD5NAd). Many folks who are new to graph RAG believe that they need to deploy a specialized graph DB, but this is not necessary, and in fact may simply complicate your tech stack.\n\nMy employer, DataStax, also has a [Guide to Graph RAG](https://bit.ly/4862Lrl).\n\nAnd, of course, the two most popular gen AI application composition frameworks, [LangChain](https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/) and [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/cookbooks/GraphRAG_v1/), each have their own graph RAG introductions. And there‚Äôs [a DataCamp article](https://www.datacamp.com/tutorial/knowledge-graph-rag) that uses both.\n\nWith all of the tools and tutorials available, getting started with graph RAG is the easy part‚Ä¶\n\n\n## ‚Ä¶but bringing graph RAG into production is hard\n\nThis is a very old story in data science: a new software methodology, technology, or tool solves some imposing problem in a research context, but industry struggles to build it into products that deliver value on a daily basis. It‚Äôs not just an issue of effort and proficiency in software development ‚Äî even the biggest, best, and brightest teams might not be able to overcome the uncertainty, unpredictability, and uncontrollability of real\\-world data involved in solving real\\-world problems.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OklHNrhsNHZF6qzeRUSd_w.jpeg)\n\nUncertainty is an inherent part of building and using data\\-centric systems, which almost always have some elements of stochasticity, probability, or unbounded inputs. And, uncertainty can be even greater when inputs and outputs are unstructured, which is the case with natural language inputs and outputs of LLMs and other GenAI applications.\n\nFolks who want to try graph RAG typically already have an existing RAG application that performs well for simple use cases, but fails on some of the more complex use cases and prompts requiring multiple pieces of information across a knowledge base, potentially in different documents, contexts, formats, or even data stores. When all of the information needed to answer a question is in the knowledge base, but the RAG system isn‚Äôt finding it, it seems like a failure. And from a user experience (UX) perspective, it is ‚Äî the correct answer wasn‚Äôt given.\n\nBut that doesn‚Äôt necessarily mean there is a ‚Äúproblem‚Äù with the RAG system, which might be performing exactly as it was designed. If there isn‚Äôt a problem or a bug, but we still aren‚Äôt getting the responses we want, that must mean that we are expecting the RAG system to have a capability it simply doesn‚Äôt have.\n\nBefore we look at why specifically graph RAG is hard to bring into production, let‚Äôs take a look at the problem we‚Äôre trying to solve.\n\n\n## The main challenge that graph RAG addresses\n\nBecause plain RAG systems (without knowledge graphs) retrieve documents based solely on vector search, only documents that are most semantically similar to the query can be retrieved. Documents that are not semantically similar at all ‚Äî or not quite similar enough ‚Äî are left out and are not generally made available to the LLM generating a response to the prompt at query time.\n\nWhen the documents we need to answer a question in a prompt are not all semantically similar to the prompt, one or more of them is often missed by a RAG system. This can happen when answering the question requires a mix of generalized and specialized documents or terms, and when documents are detail\\-dense in the sense that some very important details for this specific prompt are buried in the middle of related details that aren‚Äôt as relevant to this prompt. See [this article for an example of RAG missing documents](https://bit.ly/3BKZAJv) because two related concepts (‚ÄúSpace Needle‚Äù and ‚ÄúLower Queen Anne neighborhood‚Äù in this case) are not semantically similar, and [see this article for an example of important details getting buried](https://bit.ly/4ffhrqi) in detail\\-dense documents because vector embeddings are ‚Äúlossy‚Äù.\n\nWhen we see retrieval ‚Äúfailing‚Äù to find the right documents, it can be tempting to try to make vector search better or more tailored to our use case. But this would require fiddling with embeddings, and embeddings are complicated, messy, expensive to calculate, and even more expensive to fine\\-tune. Besides, that wouldn‚Äôt even be the best way to solve the problem.\n\nFor example, looking at the example linked above, would we really want to use an embedding algorithm that puts the text ‚ÄúSpace Needle‚Äù and ‚ÄúLower Queen Anne neighborhood‚Äù close together in semantic vector space? No, fine\\-tuning or finding an embedding algorithm that puts those two terms very close together in semantic space would likely have some unexpected and undesired side effects.\n\nIt is better not to try to force a semantic model to do a job that geographical or tourism information would be much better suited for. If I were a travel or tourism company who relied on knowing which neighborhood such landmarks are in, I would rather build a database that knows these things with certainty ‚Äî a task that is much easier than making semantic vector search do the same task‚Ä¶ without complete certainty.\n\nSo, the main issue here is that we have concepts and information that we know are related in some way, but not in semantic vector space. Some other (non\\-vector) source of information is telling us that there are connections among the wide variety of concepts we are working with. The task of building a graph RAG application is to effectively capture these connections between concepts into a knowledge graph, and to use the graph connections to retrieve more relevant documents for responding to a prompt.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*flPVNMUm83oc7H9Lt7U5AA.jpeg)\n\nTo summarize the issue that we‚Äôre trying to tackle with graph RAG: there exists semi\\-structured, non\\-semantic information connecting many of the concepts that appear in my unstructured documents ‚Äî and I would like to use this connection information to complement semantic vector search in order to retrieve documents that are best suited to answer prompts and questions within my use cases. We simply want to make retrieval better, and we want to use some external information or external logic to accomplish that, instead of relying solely on semantic vector search to connect prompts with documents,\n\n\n## Guiding principles for integrating graph with RAG\n\nConsidering the above motivation ‚Äî to use ‚Äúexternal‚Äù information to make document connections that semantic search misses ‚Äî there are some guiding principles that we can keep in mind while building and testing a graph RAG application:\n\n1. The graph should contain high\\-quality, meaningful concepts and connections\n2. Concepts and connections should be relevant to prompts within the set of use cases\n3. Graph connections should complement, not replace, vector search\n4. The usefulness of one\\- and two\\-step graph connections should be prioritized; relying on more than three steps to make connections should be reserved only for specialized use cases.\n\nPerhaps in a future article, we will dig into the nuances and potential impacts of following these principles, but for now, I‚Äôll just note that this list is intended to jointly increase explainability, prevent over\\-complexity, and maximize efficiency of both building and using a graph RAG system.\n\nFollowing these principles along with other core principles from software engineering and data science can increase your chances of successfully building a useful and powerful graph RAG app, but there are certainly pitfalls along the way, which we outline in the next section.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*twgres708JPQHa1uZrkwDA.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5U0k4GoHTFiQhKM2a6xdMA.jpeg)\n\n\n## Reasons that your graph RAG app might not make it into production\n\nAnyone who has spent a lot of time building software around data, complex algorithms, statistics, and human users probably understands that there is a lot of uncertainty in building a system like graph RAG. Unexpected things can happen during data prep and loading, while building a knowledge graph, while querying and traversing the graph, during results compilation and prompt construction, and at virtually any other point in the workflow.\n\nAbove, we discussed how it‚Äôs easy to implement graph RAG to get preliminary results, but it can be hard to get good results, much less production\\-quality results. Next, we look at a few potential issues that you might encounter when building and testing a graph RAG application.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1J9hwwZDuYZ3WNrxCl_cOA.jpeg)\n\n\n### Graph RAG isn‚Äôt doing much better than plain RAG\n\nIf the performance of your graph RAG system is about the same as with plain RAG, there can be any number of causes. Generally speaking, this seems to imply that the graph is not adding value to the system, but this could be caused by a low\\-quality knowledge graph, under\\-utilization of the graph, sub\\-optimal parameter settings, or many others. Or, there may not be a problem at all; vector search may be doing an excellent job of finding the right documents, and a graph simply isn‚Äôt needed.\n\nWhat to look at:\n\n* Do you have example prompts that plain RAG doesn‚Äôt handle well, but you would expect graph RAG to succeed? Can you ‚Äúdebug‚Äù on these prompts and see what is happening under the hood?\n* Does the knowledge graph contain meaningful connections that semantic search may not make? Can you find examples of concept pairs connected in the graph whose associated documents are far apart in vector space? The KG should be making meaningful connections between ‚Äúfar away‚Äù docs.\n\n\n### You (still) see hallucinations\n\nIf you‚Äôre seeing hallucinations with graph RAG that you didn‚Äôt see with plain RAG, I would suspect a bug or a bad parameter setting somewhere. If you are seeing a similar level of hallucinations, this sounds like a general problem beyond the graph aspects.\n\nWhat to look at:\n\n* Does your document set contain the correct responses to the prompts that elicited hallucinations? Is vector search finding these documents?\n* Are the correct responses from the retrieved documents properly inserted into the context of the prompt that is passed to the LLM?\n\n\n### The graph is ‚Äútoo big‚Äù\n\nWhen your knowledge graph is ‚Äútoo big‚Äù or too dense, two main types of problems can occur. First, there could be issues with scaling, which I discuss below. Second, graph traversal could result in ‚Äútoo many‚Äù documents, which must then be re\\-ranked and filtered. If the re\\-ranking and filtering strategy doesn‚Äôt play well with the retrieval and graph traversal elements, you could end up filtering out important documents immediately after your graph just discovered them.\n\nWhat to look at:\n\n* How many documents are returned after graph traversal, and how many are re\\-ranked or filtered out? Does it look like documents found via strong graph connections are surviving filtering?\n* Did you build a knowledge graph filled with meaningful connections that suit your use cases? In the graph, can you find many concepts or connections that are too generic or irrelevant for your use cases? How much of your knowledge graph is made up of low\\-quality information?\n\n\n### The graph is ‚Äútoo small‚Äù\n\nPer above, if the graph is ‚Äútoo big‚Äù, it might be filled with low\\-quality connections. And if the graph is ‚Äútoo small‚Äù, I would hope that the connections there are meaningful, which is good, but missing connections come in two main types. The first is caused by a bug in the graph construction process. The second is caused by graph construction that was not designed for it. Data in a different contexts or different formats may be processed differently by different graph\\-construction methods.\n\nWhat to look at:\n\n* Did you build your knowledge graph using an LLM with entity/keyword extraction? Are you capturing all of the meaningful entities from every document, or is the LLM limiting its output?\n* In your documents, what are some concepts and connections that you would expect to be in the knowledge graph, but seem to be missing? When and how do you expect them to be added to the graph? Why aren‚Äôt they actually being added to the graph?\n\n\n### You can‚Äôt find the ‚Äúhappy medium‚Äù graph\n\nDo you feel like you can build a graph that is ‚Äútoo big‚Äù or one that is ‚Äútoo small‚Äù, but you can‚Äôt build something in the middle?\n\nWhat to look at:\n\n* What parameters or methods are you changing to go from small to big or back again? Should these be affecting graph quality this much? Can you study some graph elements that appear or disappear unexpectedly, depending on which graph construction settings you‚Äôre using?\n* Also see relevant tips in ‚Äúbig‚Äù and ‚Äúsmall‚Äù sections above.\n\n\n### Your implementation requires new software or increased deployment complexity\n\nThis is a classic Data Science problem: build really cool and cutting\\-edge methods, only to see development teams refuse or struggle to bring the code from your notebooks into the production stack. Sticking to the most popular, best supported, and largely open\\-source tools can make it easier to get to production, especially if your organization is already using those tools elsewhere.\n\nWhat to look at:\n\n* Does your implementation require creating a new data store for graphs? You [probably don‚Äôt need a graph DB](https://www.datastax.com/blog/knowledge-graphs-for-rag-without-a-graphdb), and might be able to use your production vector store for graphs as well.\n* Are you using some of the most popular open\\-source tools for building AI applications, like LangChain? These can reduce code complexity, make the app more portable, and expand potential integrations and further development.\n\n\n### Your implementation doesn‚Äôt scale\n\nThe article [Scaling Knowledge Graphs by Eliminating Edges](https://thenewstack.io/scaling-knowledge-graphs-by-eliminating-edges/) in *The New Stack* shows one way to make graph RAG very scalable. Like above, the most popular, best supported, and largely open\\-source tools are usually the best path to painless scaling, but it‚Äôs not always easy.\n\nWhat to look at:\n\n* Which part isn‚Äôt scaling? Graph traversal, re\\-ranking, results compilation, or something else? See ‚ÄúThe graph is too big‚Äù above for more tips.\n* Do you have a particular component that isn‚Äôt scaling well? Sometimes using an in\\-memory graph library like ‚Äònetworkx‚Äô ‚Äî \\-or even a graph DB ‚Äî to do complex graph operations can cause a resource bottleneck. You may want to [switch to a more scalable option for graph operations](https://bit.ly/3YD5NAd).\n* Are you using parallel API calls to handle most of the heavy lifting, or are you trying to do complex or costly computations inside the main app logic?\n\n\n## Finding success with graph RAG in production\n\nThe key to creating a successful graph RAG system lies in constructing a knowledge graph and traversal logic that complement semantic vector retrieval, not replacing or competing with it. The graph design should aim to connect the right nodes, knowledge, entities, and documents at the right time, enabling the assembly of the appropriate documents to produce the most helpful and actionable query response.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*orXW5uw-geBo-WVtZUxWXQ.jpeg)\n\nWith respect to Glean, it should be noted that an internal document dataset is a perfect use case for graph RAG. A knowledge graph can connect people, projects, products, customers, meetings, locations, etc ‚Äî and all of these are somewhat limited in number by the size of the organization and the work it does. Building and managing a graph of thousands of employees is much more tractable than, for example, trying to do the same with all of the people mentioned on Wikipedia or in a large database of financial or legal documents. So, possibly the first great decision that Glean made was to find a great use case for graph RAG to tackle.\n\nOne often understated aspect of graph RAG systems is the quality and reliability of the input data and the pipelines that get it there. This has more to do with data engineering and traditional software development than AI. In previous tech paradigms, connecting different data systems was challenging due to incompatible data types and access methods. Now, AI and LLMs enable the integration of disparate sources of unstructured data, allowing for the consolidation of data from various origins into a single RAG system. This integration capability enables LLMs to process and make sense of unstructured data from various sources, such as internal web pages, wikis, code repositories, databases, Google Docs, and chat logs. Simply connecting all of this information together and making it accessible from a single interface can be a big win.\n\n\n## The way forward\n\nConstruction of graph RAG systems for any use case involves leveraging foundational components such as data stores for vectors and graphs, embeddings, and LLMs, enhanced by open\\-source orchestration tools like LangChain and LlamaIndex. These tools facilitate the development of robust, scalable, and efficient systems, promising a future where companies achieve substantial success by optimizing knowledge work through automation and streamlining.\n\nThe public success of knowledge graphs and graph RAG systems, particularly by companies like Glean, showcases how effective these technologies are for internal use cases, creating value by making the organization more efficient. However, the broader application potential for external, enterprise and consumer\\-facing products remains largely untapped, presenting many opportunities for other companies to explore.\n\nIt is perhaps notable that we have been in what is called the ‚ÄúInformation Age‚Äù for at least 30 years, and it is only in the past year or two that we have really started to put together the building blocks for connecting all of this information across sources, across ideas, across documents, and across concepts, so that our software systems can make the same types of reasoning, logic, and judgment that we as humans use as a daily part of our knowledge work. Some people are calling this the ‚ÄúIntelligence Age‚Äù.\n\nWhile initially focusing on simple, straightforward decisions, AI‚Äôs trajectory is set towards managing more complex scenarios, dramatically improving efficiency in both time and cost. This exciting evolution positions many AI applications ‚Äî including graph RAG ‚Äî as pivotal in transforming how knowledge is interconnected and utilized in a wide variety of contexts.\n\nTo get started with graph RAG now, or to learn more, take a look at the [DataStax guide to graph RAG](https://bit.ly/4862Lrl).\n\n*by Brian Godsey, Ph.D. ([LinkedIn](https://bit.ly/4enqFRa)) ‚Äî mathematician, data scientist and engineer // AI and ML products at [DataStax](https://bit.ly/3NpPujA) // Wrote the book [Think Like a Data Scientist](https://bit.ly/4f5uVES)*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Il1GrFN6fYN7e_ovExRGPw.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wQvZDIlkOvrYZnbwl0bEPQ.jpeg)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-real-reason-openai-abandoned-next-js-for-remix-a4b2622ee9b2","frontmatter":{"title":"The Real Reason OpenAI Abandoned Next.js for Remix","meta_title":"The Real Reason OpenAI Abandoned Next.js for Remix","description":"The surprising reasons behind OpenAI‚Äôs move and what it means for the future of web development","date":"2024-11-08T00:25:31.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*bf8ao0JjEiMka6dJqp-hxg.jpeg","categories":["Technology/Web","Programming","Web Development"],"author":"Rifx.Online","tags":["Remix","Next.js","client-side","rendering","scalability"],"draft":false,"slug":"blog/the-real-reason-openai-abandoned-next-js-for-remix-a4b2622ee9b2"},"content":"\n### The surprising reasons behind OpenAI‚Äôs move and what it means for the future of web development\n\n\n\n## Introduction to the Transition\n\nOpenAI recently caused a stir in the developer community by moving from Next.js to Remix.\n\nThis unexpected switch left many questioning the rationale behind such a significant change.\n\nBut **can you blame them?**\n\nHere is **what most devs think** of NextJS based on [this](https://www.reddit.com/r/nextjs/comments/1f92jdv/chatgptcom_switched_from_nextjs_to_remix/) reddit discussion:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GCrb_aGjh1nticKNeHh9Bg.png)\n\nThat‚Äôs rough.\n\nBut I also asked builders on X,\n\nand they had different opinions when it came to working on smaller projects:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YmN2pTYaCFXFzb3AMjfoqQ.png)\n\n## Let‚Äôs get to the bottom of this\n\nThis exploration isn‚Äôt just about understanding OpenAI‚Äôs decision but also about **what this could mean for other developers** and the broader tech landscape.\n\nTo understand the rationale, I spent hours analyzing the codebase and tools.\n\nHere are the insights I gained.\n\n## Technical Insights on the Switch\n\nUnderstanding the technical aspects of this transition is key to understanding why OpenAI favored Remix.\n\nWe examined their application architecture to identify the core differences between Next.js and Remix.\n\n### Client Rendering vs. Server Rendering\n\nOpenAI‚Äôs application focuses on **client\\-side rendering**, where most processing occurs in the user‚Äôs browser.\n\nThis reduces the need for server\\-rendered HTML.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*50dv8sWPbwFp85fQu_dodQ.png)\n\n**Remix** is ideal for these scenarios because it effectively manages client\\-side applications. This choice ensures OpenAI‚Äôs users have a smoother, more responsive experience.\n\n### Initial Page Load Process\n\nWhen a user visits the ChatGPT site, **preloaded JavaScript and meta tags** are involved in the initial page load.\n\nThis optimizes the client\\-side rendering process. **Remix** excels in managing these elements, ensuring a smooth and fast initial load.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*65VlHo5RQObk-YGzBlkx3w.png)\n\n## Why This Matters\n\n### Improved User Experience\n\nBy preloading essential scripts and data, users encounter less delay and a more responsive interface from the moment they access the site.\n\n### Efficient Loading\n\nRemix‚Äôs capability to handle these preloaded elements means reduced waiting times and an overall faster browsing experience.\n\nBy leveraging these features,\n\n*OpenAI can deliver a more seamless and enjoyable experience for its users right from the start.*\n\n## Diving Deeper On The Key Features of Remix Utilized by OpenAI\n\nOpenAI leverages several key features of Remix to enhance their application.\n\n### Preloading Strategies\n\nRemix preloads essential data and assets, reducing loading times and enhancing performance.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GPH2ZGhT_yfrQYpR2Xhvug.png)\n\nThis strategy ensures that users receive a seamless experience right from the start.\n\n### Data Management with Loaders\n\nRemix‚Äôs loader API efficiently gathers all necessary data for the initial render, embedding it directly into the HTML.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PmCiQNkAJlu2MSFEtpydiw.png)\n\nThis approach eliminates the need for additional client\\-side data fetching, speeding up the rendering process.\n\n## Benefits and Implications of the Move\n\nSwitching to Remix offers several advantages for OpenAI, from performance gains to future development prospects.\n\n### Performance Improvements\n\nBy adopting Remix, OpenAI achieves faster initial load times and smoother client\\-side navigation.\n\nThese performance enhancements contribute to a more responsive and user\\-friendly application.\n\n### Future Prospects with Remix\n\nThe flexibility and efficiency of Remix position OpenAI for future growth and innovation.\n\nAs Remix continues to evolve, OpenAI can leverage its advanced features to stay ahead in the competitive landscape of web development.\n\n### Why This Matters\n\n**Improved User Experience**: Users benefit from quicker page loads and a more fluid browsing experience.\n\n**Efficient Development**: Remix‚Äôs capabilities streamline development processes, allowing OpenAI to innovate more rapidly.\n\n**Scalability**: The architecture of Remix supports future enhancements and scaling, ensuring long\\-term viability.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/the-rise-of-the-ai-agent-product-manager-and-ai-agent-engineer-0905f1d30cce","frontmatter":{"title":"The Rise of the AI Agent Product Manager and AI Agent Engineer","meta_title":"The Rise of the AI Agent Product Manager and AI Agent Engineer","description":"Imagine a future where Generative AI doesn‚Äôt just respond to queries but proactively solves complex problems across every facet of‚Ä¶","date":"2024-11-04T12:33:53.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dlJ0a49_lRAPR1tTPs898w.png","categories":["Generative AI","Ethics","Technology"],"author":"Rifx.Online","tags":["Generative","Product","Manager","Engineer","Ethics"],"draft":false,"slug":"blog/the-rise-of-the-ai-agent-product-manager-and-ai-agent-engineer-0905f1d30cce"},"content":"\n\n\n\n\n\nImagine a future where Generative AI doesn‚Äôt just respond to queries but proactively solves complex problems across every facet of business. This isn‚Äôt science fiction; it‚Äôs the rapidly approaching reality of Generative AI agents. These agents are poised to revolutionize companies‚Äô operations and inspire a new wave of innovation, from streamlining supply chains to optimizing product development and transforming customer interactions.\n\nHaving spent over a year building Generative AI applications and agents, I‚Äôve seen firsthand how these technologies can profoundly reshape business processes. AI‚Äôs potential is immense, from support agents that handle customer queries with unprecedented efficiency to autonomous agents that drive business operations and decision\\-making. These agents are not merely enhancing existing processes but enabling new ways of working.\n\nFor example, picture an agent that doesn‚Äôt just schedule meetings but understands the context of your work, suggests the most impactful attendees, prepares briefing documents, and even proposes agenda items based on recent company developments. Or consider an agent in manufacturing that doesn‚Äôt just monitor production lines but predicts maintenance needs, optimizes resource allocation in real\\-time, and collaborates with design teams to suggest product improvements based on production data.\n\nThis AI\\-driven transformation is creating a need for two pivotal roles: the **AI Agent Product Manager** and **the AI Agent Engineer**. These specialists are not just the architects and builders of our AI\\-augmented future, but integral parts of a collaborative team, working at the intersection of business strategy and cutting\\-edge technology.\n\n\n## Introducing the New Roles\n\nThe **AI Agent Product Manager** is a visionary who identifies opportunities for agents to create value, designs their capabilities, and ensures they align with business goals and user needs. They act as translators between the world of business and AI possibilities, orchestrating AI innovation.\n\n**The AI Agent Engineer**, on the other hand, is the technical wizard who brings these agents to life. They design robust architectures, create sophisticated prompts, and ensure the agents are grounded in company data and processes by seamlessly integrating them with various systems and data sources.\n\nSince we are still in the early stages of this technology cycle, these professionals are usually found at specialized AI consultancies or companies developing agent\\-building products like Salesforce. This allows them to bring best practices and industry innovations to each new project.\n\n\n## The AI Agent Product Manager: Orchestrating AI Innovation\n\nAs an Agent Product Manager, you may work on different use cases, such as a sales agent one month and an HR agent the next. Let‚Äôs dive into what your role might look like:\n\nAs an Agent Product Manager, lets say you‚Äôre tasked with developing an agent for a multinational manufacturing firm. Your first step is to lead a series of workshops with executives from various departments ‚Äî operations, design, sales, and customer service. You‚Äôre not just looking for incremental improvements; you‚Äôre hunting for transformative opportunities, and you do this by fostering collaboration and understanding across the organization.\n\nThrough these discussions, you identify a game\\-changing possibility: an agent that can bridge customer feedback, product design, and manufacturing processes. This Agent would analyze customer reviews and support tickets, identify trending issues or desired features, and automatically generate design modification proposals. It would then simulate these changes‚Äô impact on manufacturing processes and costs.\n\nAs a product manager for agents, one of your primary responsibilities will be to map out the agents‚Äô journeys. It involves defining each step from the initial interaction to the final outcome, ensuring that everything aligns with the business goals. You will need to identify the key interactions the Agent will have, understand the context of these interactions, and determine the objectives each journey should achieve. You will also need to consider critical questions such as: How will the Agent prioritize customer feedback? How can it effectively present design suggestions to the engineering team? And what ethical considerations must be addressed when AI influences product decisions?\n\nYou‚Äôll work closely with stakeholders to define success metrics. For example, you may decide that the Agent should aim to reduce the time from identifying a product issue to implementing a fix by 50% while also increasing customer satisfaction scores.\n\nAs the project progresses, you ensure the agent delivers real business value. You might review both simulated and actual conversations between the AI and design teams, tweaking the Agent‚Äôs communication style to better resonate with engineers. Or you could pore over data on how the Agent‚Äôs suggestions have impacted product quality and customer satisfaction, looking for ways to improve its performance further.\n\nThroughout this process, you‚Äôre not just thinking about the Agent‚Äôs current capabilities but its future potential. How could this Agent evolve to react to customer feedback and predict future market trends? Could it someday participate in brainstorming sessions with the product team, offering data\\-driven insights to fuel innovation?\n\nYour Agent Product Manager role puts you at the forefront of business transformation. You‚Äôre not just implementing a new tool; you‚Äôre reshaping how entire organizations think, innovate, and operate in the age of AI.\n\n\n## The AI Agent Engineer: Crafting Intelligent and Reliable Systems\n\nNow, let‚Äôs switch gears and step into the role of an Agent Engineer on this same project:\n\nYour challenge is to create an agent that can understand customer feedback, translate it into actionable design insights, and interface with manufacturing systems. This is no small feat ‚Äî it requires a deep understanding of large language models, sophisticated prompt engineering, and robust system integration.\n\nYou begin by selecting an appropriate large language model as the foundation for your Agent. However, your real work lies in designing a comprehensive agent architecture that can reliably perform across many conversation journeys.\n\nAs an Agent Engineer, one of your primary focuses is creating and refining the Agent‚Äôs prompt structure. You craft intricate prompts that effectively guide the model‚Äôs behavior, ensuring it consistently provides relevant and accurate responses across various scenarios. This could involve developing a hierarchical prompt system that can handle everything from supervising multiple agents to navigating various journeys.\n\nYou will spend significant time evaluating agent behavior and output, refining the prompts and flows, and publishing a new version. You may even design and implement a rigorous testing framework that simulates thousands of potential conversation trajectories. Your goal is to ensure that the Agent‚Äôs response is deterministic and aligns with the desired outcome for any given input.\n\nFor instance, you might create a suite of test cases that cover various types of customer feedback, from simple product issues to complex feature requests. You then methodically work through these cases, analyzing the Agent‚Äôs responses and iterating on the prompt structure and decision\\-making logic to improve performance.\n\nWhen you encounter edge cases where the Agent‚Äôs behavior is inconsistent or suboptimal, you don‚Äôt simply tweak the prompt. Instead, you dive deep into the Agent‚Äôs decision\\-making process, adjusting the underlying logic and prompt structure to address these issues systematically.\n\nIntegration remains a crucial part of your role. You‚Äôre designing APIs that allow the Agent to pull data from customer support databases, access product design files, and input data into manufacturing planning systems. But beyond just connecting systems, you‚Äôre focused on ensuring the Agent can make intelligent decisions based on this integrated data.\n\nEthics and safety continue to be critical concerns. You implement robust safeguards and oversight mechanisms to ensure the AI doesn‚Äôt suggest design changes that could compromise product safety. You also build features for explainability, so the AI can always show its reasoning for any suggestion, which is crucial for building trust with the engineers and designers working with the Agent.\n\nYour role as an Agent Engineer involves creating a functional AI system and crafting an intelligent agent that can reliably and consistently drive innovation and efficiency across the entire product development and manufacturing process. This complex challenge puts you at the forefront of AI technology, shaping the future of how businesses operate in the AI age.\n\n\n## Ethical Considerations and the Power of Collaboration\n\nAs agents become more integral to businesses, Agent Product Manager and Agent Engineer roles will only grow in importance. These roles are not just about technical prowess or strategic insight ‚Äî they demand a deep commitment to ethical considerations. As these agents influence significant business decisions, the professionals behind them must ensure that these systems are transparent, fair, and aligned with broader societal values.\n\nThe success of this agent relies heavily on the seamless collaboration between the Product Manager and Engineer. Together, you‚Äôll iterate on the Agent‚Äôs capabilities, troubleshoot issues, and push the boundaries of what‚Äôs possible.\n\n\n## Comparing the Roles: Agent Product Manager vs. Agent Engineer\n\nHere‚Äôs a summary comparison table to emphasize the differences between the Agent Product Manager and the Agent Engineer:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*T26nkBI-wID26X2NrE2SSQ.jpeg)\n\nKey Takeaways:\n\n* **Agent Product Manager:** This position focuses on the strategic and business aspects of agents, ensuring they deliver value and align with company goals.\n* **Agent Engineer:** This position concentrates on technical implementation, ensuring agents function reliably and integrate seamlessly with existing systems.\n\n\n## The Future is Yours: Rise to the Challenge\n\nAs AI expands its influence, Agent Product Manager and Agent Engineer roles will be at the forefront of this technological revolution. Whether you‚Äôre defining the strategy for an AI\\-driven business transformation or designing the intricate systems that power intelligent agents, you‚Äôll be shaping the future of business.\n\nThese roles require a unique blend of skills: strategic thinking, technical expertise, creativity, and a deep understanding of business and AI. They offer the chance to work on cutting\\-edge technology while driving tangible business impact.\n\nSo, future Agent Product Managers and Engineers, are you ready to rise to the challenge? The AI\\-augmented future is waiting for your expertise and vision. Whether you‚Äôre drawn to the strategic aspects of product management or the technical intricacies of agent engineering, there‚Äôs a place for you in this exciting new field. The question is not if AI will transform business, but how ‚Äî and you could be the one to decide.\n\n\n"},{"lang":"en","group":"blog","slug":"blog/top-25-generative-ai-terminologies-you-must-know-6a3bb0300988","frontmatter":{"title":"Top 25 Generative AI Terminologies You Must Know","meta_title":"Top 25 Generative AI Terminologies You Must Know","description":"The article presents a comprehensive guide to 25 essential terminologies in generative AI, aimed at enhancing understanding among professionals in technology and related fields. Key concepts include Generative Models, Transformers, GANs, Autoencoders, and various learning paradigms such as Zero-Shot and Few-Shot Learning. Each term is defined with examples and resources for deeper exploration, emphasizing the importance of mastering these concepts for effective engagement in AI projects and discussions. The guide serves as a foundational tool for both newcomers and those seeking to update their knowledge in the rapidly evolving generative AI landscape.","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*swCl2YJj6wfAc9J3v6AqTg.png","categories":["Generative AI","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Generative","Transformers","GANs","Autoencoders","Zero-Shot"],"draft":false,"slug":"blog/top-25-generative-ai-terminologies-you-must-know-6a3bb0300988"},"content":"\n\n\n\n*Master the Key Concepts to Excel in Generative AI with Clear Explanations, Real\\-World Applications, and In\\-Depth Resources*\n\n\n\nGenerative AI is indeed a critical technology across industries; therefore, understanding generative AI‚Äôs core concepts is crucial for any professional in tech and beyond. The following comprehensive guide covers the top 25 must\\-know generative AI terminologies that will provide you with lucid definitions, practical examples, and other resources that will deepen your knowledge. Whether preparing for interviews, working on AI projects, or keeping yourself abreast of the goings\\-on in this fast\\-changing field, mastering these terms provides you with a strong basis in generative AI.\n\n\n## 1\\. Generative Model\n\n* **Definition**: A type of AI model that generates new data points from learned patterns.\n* **Example**: Generative Pre\\-trained Transformers(GPT) generate human\\-like text based on input prompts.\n* **Learn More**: [Introduction to Generative Models](https://proxy.rifx.online/https://www.datacamp.com/blog/what-is-a-generative-model)\n\n\n## 2\\. Transformer\n\n* **Definition**: A neural network architecture that uses self\\-attention mechanisms to process and generate sequences, like text or images.\n* **Example**: BERT is a Transformer model used for tasks like question\\-answering and text classification.\n* **Learn More**: [Understanding Transformers](https://proxy.rifx.online/https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power)\n\n\n## 3\\. Latent Space\n\n* **Definition**: A multi\\-dimensional space where generative models map data, allowing them to learn and generate variations.\n* **Example**: In image generation, similar images are positioned near each other in the latent space.\n* **Learn More**: [Exploring Latent Space in AI](https://proxy.rifx.online/https://www.perplexity.ai/page/latent-space-101-what-it-is-an-mwXuxYfzS_.J4e_uFvOskg)\n\n\n## 4\\. GAN (Generative Adversarial Network)\n\n* **Definition**: A type of AI that pits two neural networks, a generator and a discriminator, against each other to create realistic data.\n* **Example**: GANs generate realistic\\-looking faces that do not belong to real people.\n* **Learn More**: [What Are GANs and How Do They Work?](https://proxy.rifx.online/https://aws.amazon.com/what-is/gan/#:~:text=A%20generative%20adversarial%20network%20(GAN,from%20a%20database%20of%20songs.)\n\n\n## 5\\. Autoencoder\n\n* **Definition**: A neural network that learns to compress and reconstruct data, often used for tasks like dimensionality reduction and denoising.\n* **Example**: Autoencoders are used to remove noise from corrupted images.\n* **Learn More**: [Introduction to Autoencoders](https://proxy.rifx.online/https://towardsdatascience.com/introduction-to-autoencoders-7a47cf4ef14b)\n\n\n## 6\\. Diffusion Models\n\n* **Definition**: Models that learn to reverse a noise addition process to generate detailed and coherent data from noise.\n* **Example**: Diffusion models are used in DALL\\-E 2 to generate high\\-quality images from random noise.\n* **Learn More**: [Understanding Diffusion Models](https://proxy.rifx.online/https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)\n\n\n## 7\\. Prompt Engineering\n\n* **Definition**: The process of crafting input prompts to optimize the output generated by a model.\n* **Example**: Modifying the input prompt in GPT\\-4 to generate more concise summaries.\n* **Learn More**: [A Guide to Prompt Engineering](https://proxy.rifx.online/https://www.datacamp.com/tutorial/a-beginners-guide-to-chatgpt-prompt-engineering)\n\n\n## 8\\. Zero\\-Shot Learning\n\n* **Definition**: The ability of a model to perform tasks it was not explicitly trained for, by leveraging knowledge from other tasks.\n* **Example**: GPT\\-3 can perform translation without being specifically trained on translation datasets.\n* **Learn More**: [What is Zero\\-Shot Learning?](https://proxy.rifx.online/https://www.ibm.com/topics/zero-shot-learning)\n\n\n## 9\\. Few\\-Shot Learning\n\n* **Definition**: A model‚Äôs ability to learn tasks with only a few examples, minimizing the need for extensive training data.\n* **Example**: GPT\\-3 can be fine\\-tuned to write in a specific style with minimal input samples.\n* **Learn More**: [Few\\-Shot Learning Explained](https://proxy.rifx.online/https://www.ibm.com/topics/few-shot-learning#:~:text=IBM-,What%20is%20few%2Dshot%20learning%3F,suitable%20training%20data%20is%20scarce.)\n\n\n## 10\\. Reinforcement Learning\n\n* **Definition**: A learning paradigm where an AI agent learns to make decisions by interacting with an environment to maximize cumulative rewards.\n* **Example**: AlphaGo uses reinforcement learning to master the game of Go by playing millions of games against itself.\n* **Learn More**: [Reinforcement Learning for Generative AI](https://proxy.rifx.online/https://dl.acm.org/doi/pdf/10.1613/jair.1.15278)\n\n\n## 11\\. Variational Autoencoder (VAE)\n\n* **Definition**: A type of autoencoder that learns to generate new data by introducing randomness to its latent space representations.\n* **Example**: VAEs are used to generate new faces and smoothly transition between different facial features.\n* **Learn More**: [VAEs and Their Applications](https://proxy.rifx.online/https://www.datacamp.com/tutorial/variational-autoencoders)\n\n\n## 12\\. Self\\-Supervised Learning\n\n* **Definition**: A learning technique where the model generates its own labels from the data, reducing reliance on labelled datasets.\n* **Example**: BERT uses self\\-supervised learning by masking words in sentences and predicting them during training.\n* **Learn More**: [What is Self\\-Supervised Learning?](https://proxy.rifx.online/https://www.ibm.com/topics/self-supervised-learning)\n\n\n## 13\\. Tokenization\n\n* **Definition**: The process of splitting text into smaller units, such as words or subwords, for easier processing by models.\n* **Example**: Text input is tokenized into words before being fed into GPT\\-4 for processing.\n* **Learn More**: [Tokenization in NLP](https://proxy.rifx.online/https://www.datacamp.com/blog/what-is-tokenization)\n\n\n## 14\\. Beam Search\n\n* **Definition**: A search algorithm that expands multiple potential sequences of tokens to generate the most likely sequence during decoding.\n* **Example**: Beam search is used in machine translation to generate coherent text outputs.\n* **Learn More**: [Beam Search Explained](https://proxy.rifx.online/https://www.width.ai/post/what-is-beam-search)\n\n\n## 15\\. Transfer Learning\n\n* **Definition**: The process of using a pre\\-trained model on one task and fine\\-tuning it for another, often with less data.\n* **Example**: Fine\\-tuning BERT on sentiment analysis tasks after pre\\-training on general language tasks.\n* **Learn More**: [What is Transfer Learning?](https://proxy.rifx.online/https://aws.amazon.com/what-is/transfer-learning/)\n\n\n## 16\\. Language Model\n\n* **Definition**: A model that predicts the probability of word sequences in natural language, helping generate or understand text.\n* **Example**: GPT\\-4 is a language model capable of generating coherent text for a wide range of applications.\n* **Learn More**: [Introduction to Language Models](https://proxy.rifx.online/https://developers.google.com/machine-learning/resources/intro-llms)\n\n\n## 17\\. Bias in AI\n\n* **Definition**: The tendency of AI systems to produce results that favour or discriminate against certain groups due to biased training data or algorithms.\n* **Example**: Gender bias in AI\\-powered hiring systems trained on biased historical data.\n* **Learn More**: [Understanding Bias in AI](https://proxy.rifx.online/https://www.ibm.com/topics/ai-bias)\n\n\n## 18\\. GPT (Generative Pre\\-trained Transformer)\n\n* **Definition**: A large\\-scale language model that generates human\\-like text based on pre\\-training and fine\\-tuning on extensive text corpora.\n* **Example**: GPT\\-4 generates essays, stories, and detailed responses to user queries.\n* **Learn More**: [How GPT Works](https://proxy.rifx.online/https://tecknoworks.com/how-gpt-works-and-its-core-mechanics/)\n\n\n## 19\\. Perplexity\n\n* **Definition**: A metric that measures how well a language model predicts a given sequence of words, with lower perplexity indicating better performance.\n* **Example**: Comparing the perplexity of GPT\\-3 and GPT\\-4 to assess their text generation quality.\n* **Learn More**: [Perplexity in Language Models](https://proxy.rifx.online/https://huggingface.co/docs/transformers/en/perplexity)\n\n\n## 20\\. Natural Language Processing (NLP)\n\n* **Definition**: A field of AI focused on the interaction between computers and humans through natural language, encompassing tasks like translation and sentiment analysis.\n* **Example**: NLP models are used to perform sentiment analysis on customer reviews.\n* **Learn More**: [Introduction to NLP](https://proxy.rifx.online/https://towardsdatascience.com/a-gentle-introduction-to-natural-language-processing-e716ed3c0863)\n\n\n## 21\\. Neural Network\n\n* **Definition**: A computing system inspired by the human brain‚Äôs network of neurons, consisting of layers of interconnected nodes for tasks like image recognition and language processing.\n* **Example**: Convolutional Neural Networks (CNNs) are used to recognize objects in images.\n* **Learn More**: [What are Neural Networks?](https://proxy.rifx.online/https://www.ibm.com/topics/neural-networks)\n\n\n## 22\\. Training Data\n\n* **Definition**: Data used to train AI models by allowing them to learn from examples, improving their ability to recognize patterns and make predictions.\n* **Example**: Large image datasets like ImageNet are used to train AI models for image classification tasks.\n* **Learn More**: [Training Data in AI](https://proxy.rifx.online/https://www.oracle.com/artificial-intelligence/ai-model-training/)\n\n\n## 23\\. Attention Mechanism\n\n* **Definition**: A method in neural networks that helps models focus on the most relevant parts of an input sequence, improving performance in tasks like machine translation and text generation.\n* **Example**: Attention mechanisms allow a model to focus on important words in a sentence when translating between languages.\n* **Learn More**: [What is the Attention Mechanism?](https://proxy.rifx.online/https://machinelearningmastery.com/the-attention-mechanism-from-scratch/)\n\n\n## 24\\. Epoch\n\n* **Definition**: One complete pass through the entire training dataset during the training of a machine learning model.\n* **Example**: Training a neural network for 10 epochs to ensure it properly learns without overfitting.\n* **Learn More**: [Understanding Epochs in Machine Learning](https://proxy.rifx.online/https://www.geeksforgeeks.org/epoch-in-machine-learning/)\n\n\n## 25\\. Multimodal AI\n\n* **Definition**: AI that can process and generate data from multiple modalities (e.g., text, images, and audio) simultaneously.\n* **Example**: CLIP processes both images and text to generate captions for images.\n* **Learn More**: [What is Multimodal AI?](https://proxy.rifx.online/https://www.techtarget.com/searchenterpriseai/definition/multimodal-AI)\n\nKeep in mind that mastery in generative AI is achieved step by step. As you go through the concepts, make sure to explore each one of them through the resources provided, participate in discussions, and try applying what you have learned to your projects. The interaction with these resources and conversations will help you understand the terminology of the language and its use in the real world.\n\nThanks for reading! If you found this guide helpful, please share it with others who might be looking to enhance their generative AI understanding. We learn together and apply these concepts better because of it.\n\nIf you have any thoughts, questions, or even additional resource suggestions you think might be helpful to share, please drop them in the comments section below.\n\nHappy exploring the world of Generative AI!\n\n*Connect with me through [linktr.ee](https://proxy.rifx.online/https://linktr.ee/tharunkumarreddypolu) to know more!*\n\n\n## In Plain English üöÄ\n\n*Thank you for being a part of the [**In Plain English**](https://proxy.rifx.online/https://plainenglish.io/) community! Before you go:*\n\n* Be sure to **clap** and **follow** the writer Ô∏èüëè**Ô∏èÔ∏è**\n* Follow us: [**X**](https://proxy.rifx.online/https://x.com/inPlainEngHQ) \\| [**LinkedIn**](https://proxy.rifx.online/https://www.linkedin.com/company/inplainenglish/) \\| [**YouTube**](https://proxy.rifx.online/https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \\| [**Discord**](https://proxy.rifx.online/https://discord.gg/in-plain-english-709094664682340443) \\| [**Newsletter**](https://proxy.rifx.online/https://newsletter.plainenglish.io/) \\| [**Podcast**](https://proxy.rifx.online/https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)\n* [**Create a free AI\\-powered blog on Differ.**](https://proxy.rifx.online/https://differ.blog/)\n* More content at [**PlainEnglish.io**](https://proxy.rifx.online/https://plainenglish.io/)\n\n"},{"lang":"en","group":"blog","slug":"blog/top-5-ai-tools-for-ios-developers-5ee9f39558ac","frontmatter":{"title":"Top 5 AI Tools for iOS Developers","meta_title":"Top 5 AI Tools for iOS Developers","description":"The article outlines the top five AI tools for iOS developers to enhance workflow efficiency. Key tools include Cursor/VSCode, which offers advanced code completion and refactoring features; the GitHub Copilot Xcode extension for AI-assisted editing within Xcode; Swift Assist, a predictive completion tool; and web interfaces like ChatGPT and Claude for iterative coding. Alex Sidebar is mentioned as a new Xcode extension, while AIProxy is highlighted for securely integrating AI APIs. The article emphasizes the importance of these tools in improving coding speed and accuracy for iOS developers.","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*6Hs8174FgiwTv87e.jpg","categories":["Programming","Technology/Web","Generative AI"],"author":"Rifx.Online","tags":["Cursor","VSCode","GitHub","Copilot","Swift"],"draft":false,"slug":"blog/top-5-ai-tools-for-ios-developers-5ee9f39558ac"},"content":"\n### To improve your workflow speed \\& efficiency\n\n\n\nWhile there are a lot of big AI talks, I want to get you back on earth. Whether you‚Äôre already using AI\\-assisted tools for coding or you feel like this is just a big load of bullshit‚Ä¶ this article with a clickbait title is probably for you.\n\nWhile you can probably already find a lot of literature about what and how to use various tools to improve your skills, efficiency, and accuracy with AI, it‚Äôs a tad more complicated for us iOS developers. Because we rely on Xcode and its toolchain to build our app, it‚Äôs simply harder for us to go without Xcode. And not all the tools I‚Äôll list and explain in the following paragraphs are about skipping Xcode.\n\n## 1\\. Cursor / VSCode\n\nObviously, this is the top of the list. Unless you were hibernating under a rock, you probably heard about VSCode. Working with it on a Swift project is not a novelty. GitHub Copilot, built\\-in VSCode, allows you to code at the speed of light without doing much of anything in terms of setup. They recently integrated more Copilot features within VSCode, and it‚Äôs getting closer to Cursor. On top of tab completion, you can now also have inline chat \\+ code generation inline.\n\nCursor is a fork of VSCode, and their Cursor Tab completion feature is, in my experience, faster and more accurate than VSCode.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pQ4SuReyicAiBCG3.gif)\n\nThey also do something that saved me countless hours: smart / AI\\-assisted refactoring. This is probably one of the best features worth the Cursor subscription alone.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JlzVJ6o18sulIUEeo_p5sg.gif)\n\nAnd it‚Äôs not only for refactoring; it‚Äôs simply in smart edition after changing a line. Cursor will show a ‚Äútab‚Äù indicator, which means it has a proposed change for a part of the code that is probably related to what you just edited. Just press tab to cascade changes, and it can go on and on. Tab tab tab.\n\nOnce you get into the flow, you‚Äôll see how efficient you can be. My flow is just coding as usual, but faster because I have to write much less code. The more you code with it, the more it learns your project, coding style, etc‚Ä¶ It might appear a bit off at the beginning, but trust me, give it time.\n\nYou can also generate code with the inline chat:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*pVzU2MZ0vNFQ6-dRaWPy-w.gif)\n\nIt‚Äôs useful when you need a specific algorithm or have all the context within your existing code but need to write some tedious parts. It works quite well and can save a lot of time too. Don‚Äôt forget to review the produced code :)\n\nTo get started on it for iOS development specifically, I encourage you to read two of my other stories:\n\nOne about how to set it up, install the correct extensions, etc‚Ä¶\n\nAnd another one is about switching your Xcode project from group\\-based to folder\\-based so you can freely create/delete/move files within VSCode/Cursor without touching the .xcodeproj / Xcode at all.\n\nThis is just scratching the surface for iOS development with Cursor/VScode. But you should get started today!\n\n## 2\\. GitHub Copilot Xcode extension\n\nThis one is a recently released extension, it was initially a project by [Intitni](https://proxy.rifx.online/https://github.com/intitni/CopilotForXcode), but it seems that GitHub forked/acquired it and made it the official extension for Copilot \\+ Xcode. And so far, while the UX is not perfect (understandable as they have to work with accessibility/windows API), it‚Äôs much better than Apple (local) Xcode models.\n\nAnd lucky you, I already wrote about it:\n\nIf you‚Äôre not ready to switch to another editor than Xcode, but still want to use efficient AI\\-assisted code editing, this extension is for you!\n\n## 3\\. Swift Assist\n\nWhile Xcode already has a built\\-in local model for Predictive code completion (only available on Apple Silicon Mac from Xcode 16\\), Apple teased something else at the WWDC:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-mlY8GyGh3VPVhyg3TmLYw.png)\n\nSwift Assist\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XJnlRo8mqrAMZEVEL64ufg.gif)\n\nIt seems like the chat \\+ code generation from Cursor I‚Äôve demoed above. It should be able to generate code from your comments. But for now, it‚Äôs vaporware. Xcode 16\\.2 beta 2 mentioned it, but we still can‚Äôt test it.\n\nMaybe it‚Äôll be available in a later version of Xcode 16\\.2 beta, so I can‚Äôt wait to test and write about it!\n\n## 4\\. ChatGPT/Claude/Perplexity web interface\n\nSometimes, nothing is better than going back to the basics. While those code editors use Anthropic and OpenAI models and their own, it‚Äôs good to not forget that using their web interface is also an invaluable tool in today's landscape.\n\n### ChatGPT \\+ Canvas\n\nOpenAI‚Äôs ChatGPT has evolved quite a bit in the last few months. The recent release of o1\\-preview with reasoning and canvas allows for some good coding sessions right within the ChatGPT web interface.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WUraNCcZMrCRrHMilgzl-Q.png)\n\nCanvas is a mini code editor built on the ChatGPT Web interface and lets you quickly iterate on code and ideas. You can use the chat to make incremental changes, and there are also some other tools to comment on the code, do inline changes, convert it to another language etc‚Ä¶\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ab7PdMLJwacZtVsET2YYmA.gif)\n\nWhile this will not allow you to build a full application, it‚Äôs a great tool for quickly iterating on code ideas outside of your standard editor.\n\n### Claude Artifacts\n\nThis is similar to ChatGPT Canvas, but has some other features, like previewing (obviously not with Swift/SwiftUI) and working with multiple files at once.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*2iverELFSGqnJzklPK0cYg.png)\n\n## 5\\. Alex Sidebar\n\nThis is a new contender! The premise is simple, because Xcode is closed source and the extension API is quite limited, why not build around Xcode?\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vZgn_FjH0FW53c7qZ4DZAg.png)\n\nI‚Äôm not a fan of the UX, but it offers most of the Cursor features as an Xcode side panel built like as a window. There are various shortcuts \\+ code completions \\+ chat. You should definitely give it a go to see if it improve your workflow!\n\n## 6\\. AIProxy\n\nBonus as the (3\\) Swift Assist is not really ‚Ä¶. available\n\nThis not a tool for coding, but a tool for builders. When integrating an AI API in your iOS app, you‚Äôll most probably need add an API key to your project. But as we all know (right!), you should not have it client side. If you do so, it‚Äôs easy for almost anyone to get dump your API key and use your AI credits on your behalf.\n\nEnter [AIProxy](https://proxy.rifx.online/https://www.aiproxy.pro/), they have an open source SDK, it‚Äôs easy to integrate and they support all the AI providers your need.\n\nIf you don‚Äôt feel like building a backend to proxy your AI calls, this is the right tool for you!\n\n\n"},{"lang":"en","group":"blog","slug":"blog/top-8-leading-ai-use-cases-revolutionizing-business-in-2025-837e4a98f6a3","frontmatter":{"title":"Top 8 Leading AI Use Cases Revolutionizing Business in 2025","meta_title":"Top 8 Leading AI Use Cases Revolutionizing Business in 2025","description":"Artificial Intelligence (AI) is poised to significantly transform business operations by 2025, serving as a key driver of innovation and efficiency across various industries. Key applications include predictive analytics for informed decision-making, AI-powered customer support systems, personalized marketing through recommendation engines, and intelligent automation to streamline processes. AI enhances supply chain management, fraud detection, workforce management, and financial planning by leveraging machine learning and real-time data analysis. Businesses that effectively integrate AI technologies will gain a competitive edge, although challenges such as data privacy and ethical concerns remain.","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Na9Wc3PuYCxWOCSBWc4HtQ.png","categories":["Technology","Predictive Analytics","Machine Learning"],"author":"Rifx.Online","tags":["predictive","analytics","automation","recommendation","machine-learning"],"draft":false,"slug":"blog/top-8-leading-ai-use-cases-revolutionizing-business-in-2025-837e4a98f6a3"},"content":"\n\n\n\n\n### Explore key AI applications driving business success.\n\nArtificial Intelligence (AI) is increasingly shaping the future of business, with its influence expanding across industries. In 2025, AI will not just be a tool for innovation but a critical driver of business transformation. From customer support to predictive analytics, AI has made significant strides in improving efficiency, reducing costs, and fostering new growth opportunities. As AI continues to evolve, businesses are increasingly relying on it to streamline operations, enhance decision\\-making, and create personalized customer experiences.\n\n\n\nThe rapid advancement of [***AI technologies***](https://www.blockchainappfactory.com/ai-development-company) is unlocking unprecedented possibilities for businesses. Companies are harnessing the power of machine learning, natural language processing, and automation to stay competitive in an ever\\-changing market landscape. These developments are particularly evident in areas such as supply chain optimization, personalized marketing, and human resource management. As AI adoption grows, its integration into core business processes will become even more crucial for organizations aiming to thrive in 2025 and beyond.\n\n\n## Understanding Artificial Intelligence\n\nAI (Artificial Intelligence) is a branch of computer science that aims to create machines or systems capable of performing tasks that would normally require human intelligence. These tasks include things like understanding language, recognizing patterns, solving problems, and making decisions. AI can be broadly categorized into two types:\n\n1. **Narrow AI (Weak AI):** This type of AI is designed to perform a specific task. Examples include voice assistants like Siri or Alexa, facial recognition systems, and recommendation algorithms used by streaming services like Netflix or Spotify. Narrow AI does not possess general intelligence and is limited to the tasks for which it was programmed.\n2. **General AI (Strong AI):** This is a more advanced form of AI that has the ability to understand, learn, and apply intelligence in a wide range of activities, similar to the way humans think and reason. General AI remains largely theoretical at this point and does not yet exist.\n\n**Key Technologies and Concepts in AI:**\n\n* **Machine Learning (ML):** A subset of AI that focuses on building algorithms that allow machines to learn from data and improve over time. In ML, the system is trained on large datasets and uses this information to make predictions or decisions without being explicitly programmed.\n* **Deep Learning:** A subset of machine learning that uses neural networks with many layers (called deep neural networks). Deep learning is particularly useful in complex tasks like image and speech recognition, natural language processing, and autonomous driving.\n* **Natural Language Processing (NLP):** This involves teaching machines to understand, interpret, and respond to human language in a way that is both meaningful and relevant. NLP is behind technologies like chatbots, virtual assistants, and language translation apps.\n* **Computer Vision:** A field of AI that allows machines to interpret and understand the visual world. Computer vision is used in applications like facial recognition, object detection, and self\\-driving cars.\n* **Reinforcement Learning:** A type of machine learning where an AI agent learns how to behave in an environment by performing actions and receiving feedback in the form of rewards or penalties.\n\n\n## Top 10 Game\\-Changing AI Use Cases Transforming 2024\n\n\n## 1\\. Predictive Analytics for Strategic Decision\\-Making\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fgshMkMhuWL7ZEDo9MIR_w.png)\n\nPredictive analytics uses statistical algorithms, machine learning models, and data mining to forecast future outcomes based on historical data. It allows businesses to answer critical questions like ‚ÄúWhat is likely to happen?‚Äù by drawing from past patterns to inform future scenarios.\n\n\n### Key Use Cases in Strategic Decision\\-Making\n\n* **Demand Forecasting**: Retailers, manufacturers, and service providers use predictive analytics to forecast demand, helping them manage inventory, reduce waste, and avoid stockouts or overproduction. For example, retailers can plan for seasonal surges, and manufacturers can adjust production schedules based on anticipated needs.\n* **Risk Assessment and Management**: Predictive models identify risk factors in real\\-time, making it easier for businesses to manage financial, operational, and even reputational risks. In finance, predictive analytics can flag potential default risks, while in supply chains, it can forecast disruptions.\n* **Customer Behavior Prediction**: By analyzing past interactions, AI can predict customer behavior, enabling companies to better understand customer preferences, buying cycles, and potential churn. This helps tailor offerings and timing, maximizing customer lifetime value.\n\n\n### Benefits of Predictive Analytics for Strategy\n\n* **Improved Accuracy in Decision\\-Making**: Predictive models provide evidence\\-based insights, increasing confidence in strategic decisions by reducing reliance on intuition.\n* **Proactive Problem\\-Solving**: Instead of reacting to issues as they arise, businesses can anticipate them. This enables proactive measures in areas like risk mitigation, resource allocation, and workforce planning.\n* **Competitive Advantage**: Companies that harness predictive analytics can make faster and smarter decisions than competitors, gaining a strategic edge.\n\n\n### Tools and Technologies in Predictive Analytics\n\n* **Data Collection and Preparation**: Tools like Google BigQuery and Apache Hadoop collect and preprocess data from various sources.\n* **Model Building and Optimization**: Platforms such as TensorFlow, SAS, and IBM Watson allow businesses to create and test predictive models, fine\\-tuning them for accuracy and reliability.\n* **Deployment and Monitoring**: After model development, tools like DataRobot or Amazon SageMaker facilitate deployment, allowing continuous monitoring and updating for real\\-time accuracy.\n\n\n## 2\\. AI\\-Powered Customer Support and Chatbots\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dTt_KxOtAb-qGThAvEOQsg.png)\n\nAI\\-driven customer support systems leverage machine learning and NLP to understand, interpret, and respond to customer queries. These tools analyze user input, detect intent, and offer relevant responses or guide users through a series of actions, automating the response process and reducing wait times.\n\n\n### Key Use Cases of AI\\-Powered Customer Support and Chatbots\n\n* **24/7 Customer Service**: Chatbots can handle customer inquiries around the clock, providing immediate assistance and reducing the need for customers to wait for human agents during off\\-hours.\n* **Lead Qualification and Nurturing**: For sales\\-driven teams, chatbots can qualify leads by asking pre\\-programmed questions, collecting key details, and directing high\\-potential leads to human agents.\n* **Personalized Customer Experiences**: Using customer data, AI\\-driven chatbots can personalize responses based on user history, previous interactions, and behavior, offering a tailored experience that enhances engagement.\n* **Feedback Collection and Sentiment Analysis**: AI chatbots can gather feedback during and after interactions, gauging customer satisfaction levels. Sentiment analysis can be applied to detect satisfaction or frustration, helping businesses refine their services.\n\n\n### Benefits of AI\\-Powered Customer Support and Chatbots\n\n* **Enhanced Efficiency and Cost Savings**: By automating repetitive inquiries, AI reduces the workload on human agents, enabling them to focus on complex issues and lowering operational costs.\n* **Scalability**: AI\\-driven customer support scales effortlessly, allowing businesses to handle surges in customer inquiries during peak times without additional staff.\n* **Faster Response Times**: AI chatbots can process and respond instantly, significantly reducing wait times and improving the customer experience.\n\n\n### Popular AI\\-Powered Customer Support and Chatbot Platforms\n\n* **Zendesk Chat and Support**: Combines chatbots with ticketing systems to manage complex customer support processes.\n* **Intercom**: An AI\\-driven customer messaging platform that supports sales and customer engagement through live chat and automated responses.\n* **Drift**: Known for its lead qualification features, Drift uses conversational AI to engage website visitors and convert them into qualified leads.\n\n\n## 3\\. Personalized Marketing and Recommendation Engines\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*24ZIbZ6OOV0UGFoW3OOxtg.png)\n\nAI\\-based recommendation engines use algorithms and machine learning to analyze user data, identify patterns, and make predictions. By combining data on past behavior with real\\-time interactions, these engines can provide highly targeted recommendations that align with user interests. The most common techniques include:\n\n* **Collaborative Filtering**: Identifies items or content that similar users have enjoyed and recommends them.\n* **Content\\-Based Filtering**: Suggests items with similar attributes to those previously shown interest in.\n* **Hybrid Models**: Combine collaborative and content\\-based filtering for more accurate and diverse recommendations.\n\n\n### Key Use Cases of Personalized Marketing and Recommendation Engines\n\n* **E\\-commerce Product Recommendations**: Online retailers suggest items based on previous purchases or browsing history, which increases the likelihood of conversion and boosts sales.\n* **Content and Media Personalization**: Streaming platforms like Netflix and Spotify use recommendation engines to suggest movies, shows, or songs, enhancing user engagement and retention.\n* **Targeted Email Campaigns**: AI personalizes email content by including product suggestions, special offers, and content relevant to each recipient‚Äôs behavior, increasing open and click\\-through rates.\n* **Dynamic Web Content**: AI\\-driven engines adjust website content in real\\-time based on visitor behavior, presenting users with promotions, articles, or products that match their interests.\n\n\n### Benefits of Personalized Marketing and Recommendation Engines\n\n* **Enhanced Customer Engagement**: Personalized recommendations increase user interaction by providing relevant options, reducing the time customers spend searching.\n* **Increased Conversion Rates**: When users see products or content that closely match their interests, they‚Äôre more likely to make a purchase or engage with the content.\n* **Improved Customer Loyalty and Retention**: By making customers feel understood, brands foster a stronger connection, encouraging repeat visits and brand loyalty.\n\n\n### Top Tools for Personalized Marketing and Recommendation Engines\n\n* **Amazon Personalize**: Amazon‚Äôs tool leverages machine learning to provide real\\-time recommendations and personalized content.\n* **Salesforce Einstein**: A robust AI\\-powered suite for customer relationship management (CRM) that enables personalized recommendations across multiple customer touchpoints.\n* **Algolia Recommend**: A recommendation engine that enables personalized experiences in e\\-commerce, media, and other digital environments.\n\n\n### Real\\-World Examples of Recommendation Engines in Action\n\n* **Retail**: E\\-commerce platforms like Amazon and Walmart recommend items based on user behavior, cross\\-selling and upselling items to increase order value.\n* **Streaming Services**: Netflix‚Äôs recommendation engine analyzes viewing habits to suggest content, creating a seamless and engaging viewing experience.\n* **Travel and Hospitality**: Companies like Airbnb and Expedia suggest travel destinations, accommodations, and activities tailored to users‚Äô preferences, making travel planning more relevant and efficient.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qlu4M1HEcB3VNAm2o3FI6w.png)\n\n\n## 4\\. Intelligent Automation and RPA (Robotic Process Automation)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Bbnm4Snzk0vrhKOxLwZ_uQ.png)\n\nIntelligent automation, driven by RPA (Robotic Process Automation) and advanced AI, is transforming business operations by automating repetitive tasks, enhancing productivity, and reducing errors. Unlike traditional automation, which focuses on simple rule\\-based tasks, intelligent automation combines AI, machine learning, and RPA to handle complex workflows that require adaptability and decision\\-making. Here‚Äôs a look at how intelligent automation and RPA are changing the business landscape:\n\n\n### What is Intelligent Automation and RPA?\n\n* **Robotic Process Automation (RPA)** uses software robots or ‚Äúbots‚Äù to automate high\\-volume, repetitive tasks such as data entry, form filling, and report generation. RPA operates based on pre\\-set rules and doesn‚Äôt require cognitive decision\\-making.\n* **Intelligent Automation** integrates RPA with AI capabilities, like natural language processing (NLP) and machine learning, to manage tasks that require a higher level of reasoning and adaptability. This fusion enables bots to make contextual decisions, adapt to new data, and handle unstructured information.\n\n\n### Key Use Cases for Intelligent Automation and RPA\n\n* **Invoice Processing and Accounts Payable**: RPA can scan invoices, extract data, cross\\-check it with purchase orders, and enter it into the accounting system, reducing manual workload and improving accuracy.\n* **Customer Onboarding in Financial Services**: Intelligent automation helps banks and insurance companies streamline onboarding by automating document verification, background checks, and data entry, enhancing compliance and reducing onboarding times.\n* **Order Processing and Fulfillment**: RPA can automate order processing by pulling data from order forms, checking inventory, and initiating shipment processes, speeding up fulfillment and minimizing errors.\n* **Employee Onboarding and HR Management**: Bots can manage routine HR tasks like onboarding, scheduling interviews, and updating employee records, allowing HR teams to focus on strategic initiatives.\n\n\n### Benefits of Intelligent Automation and RPA\n\n* **Cost Savings and Efficiency**: Automation reduces the need for manual intervention, allowing companies to save on labor costs and reallocate resources toward higher\\-value tasks.\n* **Reduced Errors and Enhanced Compliance**: Bots perform tasks with high accuracy, reducing human errors, especially in data\\-intensive fields like finance and healthcare. Automated workflows also support compliance by documenting processes and ensuring regulations are followed.\n* **Scalability**: RPA allows businesses to easily scale operations by deploying more bots during peak periods without the need to hire additional staff, providing flexibility in resource management.\n\n\n### Popular RPA and Intelligent Automation Tools\n\n* **UiPath**: A widely\\-used RPA platform known for its ease of use and strong integration with machine learning tools for intelligent automation.\n* **Automation Anywhere**: Offers both RPA and cognitive automation capabilities, making it suitable for complex workflows that require decision\\-making.\n* **Blue Prism**: Focuses on secure RPA deployment, ideal for industries with high security and compliance needs, such as banking and healthcare.\n\n\n### Real\\-World Examples of Intelligent Automation in Action\n\n* **Telecoms**: Companies like AT\\&T use RPA to automate customer service inquiries, bill processing, and network monitoring, improving service response times and operational efficiency.\n* **Retail**: Retailers use RPA to streamline supply chain operations, from order fulfillment to inventory management, helping to reduce operational costs and improve customer satisfaction.\n* **Healthcare**: Hospitals and healthcare providers implement RPA to handle patient data management, appointment scheduling, and claims processing, freeing up medical staff for patient care.\n\n\n## 4\\. Fraud Detection and Security Enhancement\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cFol51alN3qozxSH0rU0Bw.png)\n\nAI fraud detection systems use machine learning algorithms to analyze vast amounts of data, identify unusual patterns, and flag suspicious activity. Key techniques include:\n\n* **Anomaly Detection**: Identifies deviations from normal behavior, such as unusual transactions or account activity, which may indicate fraud.\n* **Behavioral Analysis**: Studies user behavior to establish a baseline and detect anomalies based on how users typically interact with the system.\n* **Predictive Modeling**: Combines historical data with machine learning models to predict the likelihood of fraudulent events and trigger alerts before fraud occurs.\n\n\n### Key Use Cases of Fraud Detection and Security Enhancement\n\n* **Financial Services**: Banks use AI to monitor transactions in real\\-time, flagging potentially fraudulent activity, such as unusual account transfers or withdrawals, and blocking them until verification is completed.\n* **Insurance Claims Processing**: Insurance companies leverage AI to detect fraudulent claims by analyzing claim patterns, identifying duplicates, and spotting inconsistencies in submitted documents.\n* **E\\-commerce and Retail**: Retailers use fraud detection algorithms to identify fraudulent purchases, stolen credit card transactions, and account takeovers to protect consumers and the business.\n* **Identity Verification and Access Control**: AI strengthens security by verifying identities through biometric authentication (such as facial recognition and fingerprint analysis) and preventing unauthorized access.\n\n\n### Benefits of AI in Fraud Detection and Security\n\n* **Real\\-Time Threat Detection**: AI allows for immediate threat detection and response, preventing fraud before it escalates and minimizing financial losses.\n* **Reduced False Positives**: By learning user patterns, AI can reduce the number of false positives that often accompany traditional fraud detection systems, ensuring genuine transactions aren‚Äôt unnecessarily flagged.\n* **Improved Adaptability to New Threats**: AI systems continuously learn from new data, allowing them to adapt to evolving fraud tactics, whereas rule\\-based systems may become outdated.\n\n\n### Top Tools and Platforms for AI\\-Powered Fraud Detection\n\n* **Darktrace**: Uses AI to detect, investigate, and respond to cyber threats, leveraging machine learning to understand and protect organizational networks in real time.\n* **Splunk**: A security information and event management (SIEM) tool that combines AI\\-driven analytics with real\\-time monitoring to detect and respond to anomalies across various systems.\n* **Feedzai**: A platform designed for financial institutions that uses machine learning to monitor transactions, prevent fraud, and ensure compliance with regulatory requirements.\n\n\n### Real\\-World Examples of Fraud Detection and Security Enhancement\n\n* **Banking**: Many banks now use AI\\-driven systems to detect credit card fraud, unusual transactions, and account takeovers, significantly reducing financial losses from fraudulent activities.\n* **Healthcare**: AI is used to detect fraudulent medical billing and identity theft, saving healthcare providers and insurers millions by identifying patterns of abuse in claims processing.\n* **Online Platforms**: Social media and online marketplaces use AI to detect and prevent account takeovers, phishing, and spam, protecting users from various security threats.\n\n\n## 5\\. Supply Chain Optimization with AI\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3pWU90X3MXQMyJ8G9rQ97g.png)\n\nAI\\-driven supply chain optimization is transforming logistics and supply chain management by improving efficiency, reducing costs, and enhancing transparency across each stage of the supply chain. From demand forecasting to inventory management, AI enables businesses to make data\\-driven decisions and respond proactively to disruptions. Here‚Äôs a deep dive into how AI is revolutionizing supply chain management and optimizing operations:\n\n\n### How AI Optimizes the Supply Chain\n\nAI tools use machine learning, predictive analytics, and real\\-time data analysis to streamline various aspects of the supply chain. By analyzing historical data, tracking real\\-time information, and predicting future trends, AI algorithms can optimize procurement, production, distribution, and logistics processes. Key approaches include:\n\n* **Predictive Analytics**: Anticipates future demands based on historical data, seasonal trends, and market factors.\n* **Machine Learning for Demand Forecasting**: Uses data on past sales, customer behavior, and external factors to generate accurate demand forecasts.\n* **Real\\-Time Monitoring and IoT Integration**: Tracks goods in real time through IoT sensors, allowing for improved visibility and rapid response to issues.\n\n\n### Key Use Cases for AI in Supply Chain Optimization\n\n* **Demand Forecasting and Planning**: AI\\-driven demand forecasting allows companies to predict customer demand more accurately, ensuring optimal stock levels and reducing instances of overstock or stockouts.\n* **Inventory Management and Optimization**: AI helps companies maintain the right inventory levels by predicting inventory needs, optimizing reordering schedules, and minimizing excess stock.\n* **Route Optimization for Logistics**: AI algorithms consider traffic, weather, and fuel costs to determine the most efficient routes, saving time and reducing transportation expenses.\n* **Supplier Risk Management**: AI enables businesses to assess supplier reliability and performance, predict risks related to supplier delays, and mitigate these risks through proactive strategies.\n* **Quality Control and Predictive Maintenance**: AI and IoT sensors can identify patterns in manufacturing equipment, predicting maintenance needs and reducing downtime, which in turn improves product quality and reduces wastage.\n\n\n### Benefits of AI\\-Driven Supply Chain Optimization\n\n* **Cost Reduction**: By improving route efficiency, inventory accuracy, and demand forecasting, AI minimizes operational costs across the supply chain.\n* **Enhanced Decision\\-Making**: AI provides real\\-time insights and forecasts, allowing decision\\-makers to respond swiftly to changes in demand, supplier performance, or logistics challenges.\n* **Greater Resilience and Flexibility**: AI\\-powered systems can adapt to unexpected disruptions, such as supplier issues or demand surges, maintaining service levels even during periods of uncertainty.\n* **Sustainability**: By reducing waste, optimizing routes, and preventing overproduction, AI contributes to sustainability goals, reducing a business‚Äôs environmental impact.\n\n\n### Top Tools and Platforms for AI\\-Driven Supply Chain Optimization\n\n* **SAP Integrated Business Planning (IBP)**: Combines machine learning with supply chain planning tools, enabling real\\-time demand forecasting and inventory optimization.\n* **Llamasoft (by Coupa)**: Uses advanced analytics for network design, inventory optimization, and demand forecasting, focusing on both strategic and operational supply chain planning.\n* **ClearMetal (by Project44\\)**: Offers real\\-time supply chain visibility and predictive analytics, enabling companies to track shipments, analyze trends, and optimize logistics routes.\n\n\n## 6\\. AI\\-Driven Product Development and Design\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rcCCXcQq85tiFEe2M1gvzA.png)\n\nAI\\-driven product development and design is transforming how companies conceptualize, create, and bring products to market. By leveraging machine learning, generative design, and predictive analytics, AI empowers teams to innovate faster, enhance product quality, and respond effectively to changing customer needs. Here‚Äôs a comprehensive look at how AI is revolutionizing product development and design:\n\n\n### How AI is Used in Product Development and Design\n\nAI optimizes every stage of the product lifecycle, from ideation to design, prototyping, and testing. Using advanced algorithms and data analysis, AI\\-driven systems can generate product concepts, identify design flaws, and even suggest improvements. Key AI approaches include:\n\n* **Generative Design**: AI generates design options based on predefined parameters, such as material type, weight, and durability, allowing designers to explore a wider range of possibilities.\n* **Predictive Analytics for Customer Insights**: Machine learning algorithms analyze customer data and market trends to predict what features or designs will resonate with users, enhancing product\\-market fit.\n* **Natural Language Processing (NLP)**: NLP allows teams to analyze customer feedback, reviews, and social media for insights that inform product improvements and new feature ideas.\n\n\n### Key Use Cases of AI in Product Development and Design\n\n* **Concept Generation and Design Exploration**: AI assists designers by generating multiple design alternatives based on specific constraints. For example, in the automotive industry, AI can produce aerodynamic designs that improve fuel efficiency.\n* **Prototyping and Rapid Iteration**: AI\\-driven tools enable quick virtual prototyping, reducing the need for physical models and allowing rapid testing of design variations.\n* **Quality Assurance and Testing**: AI algorithms analyze product data to detect flaws early, predict potential failures, and suggest modifications, improving quality and reducing costs associated with recalls.\n* **Customer\\-Centric Product Customization**: AI\\-powered platforms allow companies to create products tailored to individual customers by analyzing preferences and generating personalized features or recommendations.\n* **Cost Optimization**: AI identifies cost\\-saving opportunities in materials, manufacturing processes, and supply chains without compromising product quality, enhancing profitability.\n\n\n### Benefits of AI\\-Driven Product Development and Design\n\n* **Accelerated Time to Market**: AI reduces the time needed for product design, prototyping, and testing, allowing companies to bring products to market faster and capitalize on emerging trends.\n* **Enhanced Innovation and Creativity**: Generative design and data\\-driven insights inspire new ideas, enabling designers to create more innovative, user\\-centered products.\n* **Improved Product Quality**: AI identifies potential design flaws early, improving product quality and reliability, which results in higher customer satisfaction.\n* **Reduced Development Costs**: By minimizing the need for physical prototypes and streamlining the design process, AI helps lower overall development costs and resources.\n\n\n### Top Tools for AI\\-Driven Product Development and Design\n\n* **Autodesk‚Äôs Fusion 360 with Generative Design**: Offers generative design tools for creating optimized structures and lightweight designs, commonly used in automotive, aerospace, and industrial design.\n* **SolidWorks with AI Plugins**: Integrates AI\\-powered modules for rapid prototyping, material optimization, and design validation.\n* **Canva AI Design Tools**: Uses AI to generate layout suggestions, optimize color palettes, and suggest design templates, making it ideal for digital content and branding.\n\n\n### Real\\-World Examples of AI in Product Development\n\n* **Automotive and Aerospace**: Companies like Airbus use AI\\-powered generative design to create lightweight, aerodynamic components that reduce fuel consumption and improve sustainability.\n* **Consumer Electronics**: Tech giants use AI to identify feature preferences, enabling the creation of custom features, like battery\\-saving modes or personalized settings, based on user data.\n* **Fashion and Apparel**: Brands use AI to design custom\\-fit clothing based on body measurements, as well as analyze color and style trends to predict future demand, helping brands reduce unsold inventory.\n\n\n## 7\\. Workforce and Talent Management with AI\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-zSlQl-pe5KJ2DuACUEeeA.png)\n\nAI integrates machine learning, natural language processing, and data analytics to improve various aspects of workforce management, including recruitment, performance management, training, and employee engagement. Key areas of AI application include:\n\n* **Recruitment and Talent Acquisition**: AI automates the screening process, analyzing resumes and applications to match candidates with the best\\-fit roles based on their skills, experience, and potential.\n* **Employee Training and Development**: AI systems deliver personalized learning experiences, recommending courses and training programs based on employee performance, career goals, and interests.\n* **Performance Monitoring and Feedback**: AI provides real\\-time insights into employee performance and engagement, offering continuous feedback to help improve productivity and identify areas for growth.\n* **Workforce Planning and Analytics**: AI analyzes workforce trends, performance data, and market conditions to help organizations plan and optimize their staffing needs.\n\n\n### Key Use Cases of AI in Workforce and Talent Management\n\n* **AI\\-Powered Recruitment**: AI algorithms automate resume parsing, candidate ranking, and initial interview assessments, ensuring faster, bias\\-free recruitment processes and a better candidate experience.\n* **Chatbots for Employee Queries**: AI chatbots assist employees with HR\\-related questions, such as benefits, payroll, and company policies, improving HR service efficiency and freeing up HR staff for more complex tasks.\n* **Personalized Employee Development**: AI\\-driven learning management systems (LMS) analyze employee performance and learning preferences, recommending tailored development paths, courses, and certifications to enhance skills.\n* **Sentiment Analysis for Employee Engagement**: AI analyzes employee feedback, surveys, and communication patterns to gauge morale, identify potential issues, and provide insights into improving workplace culture and engagement.\n* **Workforce Optimization**: AI tools analyze workforce data to help HR managers optimize scheduling, shift patterns, and resource allocation, improving productivity and employee satisfaction while reducing costs.\n\n\n### Benefits of AI in Workforce and Talent Management\n\n* **Increased Efficiency**: AI automates routine HR tasks like resume screening, scheduling interviews, and answering employee queries, saving time for HR professionals to focus on strategic decision\\-making.\n* **Enhanced Decision\\-Making**: AI\\-powered analytics provide HR managers with actionable insights, allowing them to make more informed decisions regarding hiring, promotions, and resource allocation.\n* **Improved Talent Acquisition**: AI helps identify the best candidates faster by eliminating bias in recruitment, improving diversity, and ensuring a better fit between candidates and roles.\n* **Personalized Employee Experience**: AI\\-driven tools offer personalized career development and training programs, improving employee satisfaction and retention by aligning individual goals with organizational objectives.\n* **Proactive Retention Strategies**: By analyzing employee sentiment and performance data, AI can predict potential turnover, allowing HR to intervene early with retention strategies.\n\n\n### Top Tools for AI in Workforce and Talent Management\n\n* **HireVue**: AI\\-powered video interviewing platform that analyzes candidates‚Äô responses, tone, and facial expressions to assess qualifications, personality, and fit for a role.\n* **Workday**: A human capital management software that leverages AI for recruitment, performance management, talent development, and workforce planning, helping businesses make data\\-driven HR decisions.\n* **Ultimate Software**: Offers AI tools for payroll, employee engagement, and performance management, enhancing HR efficiency and providing actionable insights into employee performance and sentiment.\n* **Pymetrics**: Uses AI to match candidates with roles based on cognitive and emotional abilities, helping companies improve diversity and reduce hiring bias.\n\n\n### Real\\-World Examples of AI in Workforce and Talent Management\n\n* **Recruitment at Unilever**: Unilever uses AI\\-powered tools to automate candidate sourcing, screening, and interviews, improving speed and reducing unconscious bias in the hiring process.\n* **Performance Management at IBM**: IBM‚Äôs AI\\-driven performance management system analyzes employee data and provides personalized feedback, helping managers track employee performance and identify development opportunities.\n* **Employee Engagement at Accenture**: Accenture uses AI\\-powered sentiment analysis to monitor employee engagement, gather feedback, and develop strategies to improve workplace culture.\n\n\n## 8\\. AI in Financial Planning and Forecasting\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*2QSFmYDlYv1eqjTXRWApNw.png)\n\nAI leverages large volumes of financial data and advanced algorithms to create more accurate, dynamic, and reliable financial models. By automating repetitive tasks, improving predictive accuracy, and providing actionable insights, AI is helping organizations make smarter financial decisions. Key AI applications include:\n\n* **Predictive Analytics**: AI predicts future financial performance by analyzing historical data, identifying trends, and assessing market conditions. This enables more accurate forecasting and budgeting.\n* **Real\\-Time Financial Monitoring**: AI\\-driven tools provide real\\-time tracking of financial data, helping businesses quickly detect anomalies, forecast cash flow, and monitor budget adherence.\n* **Scenario Planning**: AI can simulate different economic conditions or business scenarios, helping financial planners assess the impact of various strategies and decisions on the company‚Äôs bottom line.\n\n\n### Key Use Cases of AI in Financial Planning and Forecasting\n\n* **Budgeting and Cash Flow Forecasting**: AI tools analyze past financial data, customer behavior, and market conditions to generate cash flow projections, ensuring businesses have sufficient liquidity and can plan for future expenses.\n* **Revenue Forecasting**: AI models can predict future revenues based on historical performance, seasonal trends, and customer behavior, enabling companies to allocate resources more effectively.\n* **Expense Management and Optimization**: AI identifies areas where costs can be reduced or optimized by analyzing spending patterns and suggesting cost\\-saving measures.\n* **Credit Risk Assessment**: AI\\-powered credit scoring models analyze a broad range of financial and non\\-financial data, providing more accurate risk assessments for lenders, investors, and businesses.\n* **Investment Analysis and Portfolio Management**: AI tools analyze vast amounts of market data to identify investment opportunities, assess portfolio performance, and optimize asset allocation.\n\n\n### Benefits of AI in Financial Planning and Forecasting\n\n* **Improved Accuracy**: AI algorithms process large datasets and recognize patterns that humans may miss, leading to more accurate financial forecasts, predictions, and budgets.\n* **Faster Decision\\-Making**: AI speeds up financial analysis, enabling faster decision\\-making and more agile responses to market changes, cash flow needs, or unexpected financial events.\n* **Increased Efficiency**: By automating routine tasks such as data entry, analysis, and report generation, AI frees up time for financial professionals to focus on strategic decision\\-making and scenario planning.\n* **Risk Management**: AI‚Äôs ability to analyze vast amounts of data helps identify potential risks and financial challenges early, allowing companies to take proactive measures to mitigate them.\n* **Enhanced Strategic Insights**: AI provides deeper insights into financial data, offering recommendations on cost\\-saving opportunities, revenue growth strategies, and overall financial health.\n\n\n### Top Tools for AI in Financial Planning and Forecasting\n\n* **Adaptive Insights**: A cloud\\-based financial planning tool that uses AI to help businesses forecast and model financial scenarios, track performance, and adjust plans based on real\\-time data.\n* **Anaplan**: AI\\-powered software that provides integrated financial planning, budgeting, and forecasting solutions, allowing businesses to connect financial data and optimize decision\\-making.\n* **Planful (formerly Host Analytics)**: An AI\\-driven platform for financial planning, analysis, and forecasting, offering powerful modeling, budgeting, and reporting capabilities for finance teams.\n* **Kensho**: An AI\\-powered analytics tool used by financial institutions to enhance forecasting, risk assessment, and financial planning by analyzing vast amounts of financial data and providing predictive insights.\n* **Xero**: A cloud\\-based accounting platform with AI\\-driven features that assist businesses with real\\-time cash flow tracking, forecasting, and financial reporting.\n\n\n### Real\\-World Examples of AI in Financial Planning and Forecasting\n\n* **Corporate Budgeting at Vodafone**: Vodafone uses AI to improve its financial planning process by automating budget creation, optimizing cash flow forecasting, and providing deeper insights into cost allocation across global operations.\n* **Revenue Forecasting at Netflix**: Netflix leverages AI to analyze customer data and predict subscriber growth, helping the company plan its financial strategy and allocate resources effectively across various content production and marketing efforts.\n* **Investment Management at BlackRock**: BlackRock employs AI and machine learning algorithms to manage investment portfolios and optimize asset allocation, providing clients with more accurate and data\\-driven investment strategies.\n\n\n## Conclusion\n\nAs we move into 2025, AI is set to be the backbone of many successful businesses. By automating repetitive tasks, enhancing customer experience, and providing data\\-driven insights, AI empowers organizations to make smarter, faster decisions. AI‚Äôs role in predictive analytics, cybersecurity, and personalized marketing will continue to drive innovation and allow businesses to meet changing consumer demands more effectively.\n\nThe future of business lies in the [**integration of AI technologies**](https://www.blockchainappfactory.com/ai-development-company), and those who embrace these advancements will be at the forefront of their industries. While there are challenges to adopting AI, such as concerns around data privacy and job displacement, the benefits far outweigh the risks. With the right strategies in place, businesses can harness AI‚Äôs full potential to thrive in the competitive landscape of 2025\\.\n\n\n## FAQs\n\n1. **What are the top AI use cases for businesses in 2025?**\nIn 2025, AI will be used for predictive analytics, personalized marketing, automation, fraud detection, customer support chatbots, and supply chain optimization.\n2. **How can AI improve customer experience?**\nAI can enhance customer experience through personalized recommendations, AI\\-powered chatbots for instant support, and predictive tools that anticipate customer needs.\n3. **Is AI likely to replace human workers in business?**\nAI is more likely to augment human workers by automating repetitive tasks, allowing employees to focus on higher\\-level decision\\-making and creative work.\n4. **What industries benefit the most from AI in 2025?**\nIndustries like finance, healthcare, retail, manufacturing, and logistics are expected to see significant benefits from AI, including improved efficiency and cost savings.\n5. **What are the challenges businesses face when adopting AI?**\nBusinesses may face challenges related to data privacy, integration with existing systems, high initial investment, and ensuring AI systems are used ethically.\n\n"},{"lang":"en","group":"blog","slug":"blog/unified-memory-across-chatgpt-claude-perplexity-24809dc56717","frontmatter":{"title":"Unified Memory Across ChatGPT, Claude, Perplexity","meta_title":"Unified Memory Across ChatGPT, Claude, Perplexity","description":"You‚Äôll definitely love this one, especially if you‚Äôre already locked in with Claude, ChatGPT and Perplexity.","date":"2024-11-08T00:24:33.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qrHnDS6YODZuVXZ4eeWZrQ.png","categories":["Chatbots","Programming/Scripting","Technology/Web"],"author":"Rifx.Online","tags":["Mem0","Chrome","extension","context","memory"],"draft":false,"slug":"blog/unified-memory-across-chatgpt-claude-perplexity-24809dc56717"},"content":"\nYou‚Äôll definitely love this one, especially if you‚Äôre already locked in with Claude, ChatGPT and Perplexity.\n\nInteracting with different AI assistants can sometimes feel a bit disjointed.\n\nYou have to repeat the same context over and over when switching between ChatGPT, Claude, Perplexity, and others.\n\nWouldn‚Äôt be great if all could share one universal memory to enhance the context?\n\nI found this awesome Chrome extension, and it‚Äôs been a total life saver for me.\n\nImagine having a seamless conversation where the context carries over, no matter which AI you‚Äôre chatting with.\n\nSounds cool, doesn‚Äôt it?\n\n\n\n### The Big Problem It Solves\n\nBefore I dive into it, how are we even keeping LLMs updated with the latest knowledge?\n\nThere are a few traditional ways to tackle this:\n\n1. **Retrieval\\-Based Methods**: These pull information from a knowledge base. They‚Äôre powerful but can get messy with redundant data and the hassle of managing an ever\\-growing repository.\n2. **Model Editing**: This tweaks the model to adapt to new facts. It works for simple, single\\-sentence updates but struggles with longer, more complex information.\n3. **Long Context Methods**: These cram all the knowledge into the model‚Äôs context. It‚Äôs like overloading the model with data, which isn‚Äôt practical because the context length is limited.\n\nAll these methods have their downsides, especially when we need up\\-to\\-date, seamless interactions across different AI platforms.\n\n### Enter Mem0: Intelligent Memory Retrieval for AI Assistants\n\nMem0 sidesteps these issues by creating a universal memory layer that works across multiple AI assistants.\n\nHere‚Äôs what it brings to the table:\n\n* **Universal Memory Layer**: Share context effortlessly across ChatGPT, Claude, Perplexity, and more. No more repeating yourself!\n* **Smart Context Detection**: It automatically picks up relevant information from your conversations, so you don‚Äôt have to manually input anything.\n* **Intelligent Memory Retrieval**: Mem0 brings up the right memories at the right time, making your interactions smoother.\n* **One\\-Click Sync with ChatGPT**: If you‚Äôve been using ChatGPT, you can sync your existing memories with just one click.\n* **Memory Dashboard**: A handy place to manage all your memories in one spot.\n\nFor example, if you start a conversation with Claude:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QQAJPzQp2tjBFgi-9InG1Q.png)\n\nIt will extract key information and add it to memory.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MtctEzunD72Tw_dOOCOnyA.png)\n\nThen the next time you ask a relevant question:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*r0WyCIHGvmiGm0GZ6xR1pw.png)\n\nIt will add the relevant context:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PTEhFUJ4nrhQbeZXIAnD6A.png)\n\nbut here‚Äôs what more interesting.\n\nIf you open Perplexity and ask another question:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*54BKW9BQWwCDdXdAg0U-mA.png)\n\nIt will get the memory across different applications and enhance the context:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FD6MwGtL8WpovUH3o1Vw3g.png)\n\nWhich is pretty cool!\n\nIf you open ChatGPT and ask a question:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qLmDZh5NofuArxzS4OnDIQ.png)\n\nSimilarly, it will bring relevant information from memory and enhance the context.\n\nAs you work more with it, it will collect key information and save you lots of typing while you interact with Claude, Perplexity and ChatGPT.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MqgEr6hi5cHzHRuTqODzuA.png)\n\nYou can also add new information to memory:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Xo6jLLIGKqxvYR9SivuMhQ.png)\n\n### How to Get Started\n\nInstalling Mem0 is super easy:\n\n1. [**Add the extension to Chrome**](https://chromewebstore.google.com/detail/mem0/onihkkbipkfeijkadecaafbgagkhglop?hl=en-GB)\n\n**2\\. Sign In**:\n\n* After it‚Äôs installed, you‚Äôll see the Mem0 icon in your toolbar.\n* Click it and sign in with Google.\n\n**4\\. Start Chatting**:\n\n* Use any of the supported AI assistants.\n* For ChatGPT and Perplexity, just chat as you normally would.\n* On Claude, click the Mem0 button or use the shortcut `^ + M`.\n\nOne of the best things about Mem0 is that it‚Äôs completely free. There are:\n\n* **No usage limits**\n* **No ads**\n* **All features included**\n\n\n"},{"lang":"en","group":"blog","slug":"blog/unlocking-mixture-of-experts-moe-llm-your-moe-model-can-be-embedding-model-for-free-f192b9c07a5f","frontmatter":{"title":"Unlocking Mixture-of-Experts (MoE) LLM¬†: Your MoE model can be embedding model for free","meta_title":"Unlocking Mixture-of-Experts (MoE) LLM¬†: Your MoE model can be embedding model for free","description":"Mixture-of-experts (MoE) LLM can be used as an embedding model for free.","date":"2024-11-04T12:30:57.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mB6VhEyAvxAxGbLDG_6hTw.png","categories":["Machine Learning","Natural Language Processing","Data Science"],"author":"Rifx.Online","tags":["Mixture-of-Experts","MoE","embedding","MoEE","BERTopic"],"draft":false,"slug":"blog/unlocking-mixture-of-experts-moe-llm-your-moe-model-can-be-embedding-model-for-free-f192b9c07a5f"},"content":"\n### Mixture\\-of\\-experts (MoE) LLM can be used as an embedding model for free.\n\n\n\nI recently found an interesting paper titled ‚ÄúYour Mixture\\-of\\-Experts LLM is Secretly an Embedding Model for Free.‚Äù \\[1] A recent LLM architecture trend is a decoder model, which is unsuitable for an embedding model because of their attention method. However, the authors revealed that Mixture\\-of\\-Experts (MoE) LLMs can perform as an embedding model to apply a diverse class of embedding\\-focused tasks without any further fine\\-tuning. In this blog, firstly, let‚Äôs recap MoE, and I will introduce how it works and its practical implementation.\n\n## Table of Contents\n\n1. What is Mixture-of-Experts (MoE)?\n2. How MoE works as an embedding model?\n3. Practical implementation : Leverage MoEE with BERTopic\n\n## 1\\. What is Mixture\\-of\\-Experts (MoE) ?\n\nMixture\\-of\\-Experts (MoE) is an architecture with multiple subnetworks called ‚Äúexperts,‚Äù each specializing in different tasks or aspects of data. One of MoE‚Äôs advantages is that it enables AI models to be pretrained with less computation than the same or larger models while maintaining or increasing quality. So, if we have a limited budget, we can achieve a better model using MoE than the dense, similar\\-size conventional model. For recent success, Mixtral 8 x 7B outperforms the LLaMA 2 70B for many evaluation datasets.\n\nFrom now on, let‚Äôs examine the architecture of MoE. Recent successful MoEs use the transformer model, so I will focus on the popular MoE architecture for the transformer. MoE has mainly two components described below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Dia_c08PJnFeeIc9lxwtGQ.png)\n\n* **MoE layers**\n\nMoE replaces the feed\\-forward network (FFN) layers with MoE layers in the transformer architecture. Each MoE layer has some experts (Ex. 4 experts in the above illustration), and each expert is composed of the simple FFN layer. Note that other components in the transformer, such as the self\\-attention layer, share the same weights. Therefore, the number of weights of MoE is not straightforward. For example, the Mixtral 8 x 7B weight is not 8 x 7 \\= 56B but 47B because the other layers besides MoE layers share the same weights.\n\n* **Gating network**\n\nA gating network or router is a crucial component in MoE. It takes input tokens and selects the most relevant experts for each token. For instance, in the above illustration, the left side of the router chooses the second expert to process the word ‚Äúmore‚Äù token. Meanwhile, the router determines the first expert to process the word ‚ÄúParameters‚Äù token. Generally, a gating network chooses the top\\-k experts relevant to the given token and sends the token to chosen experts; for example, Mixtral 8 x 7B chooses top\\-2 experts.\n\nHow can we choose the top\\-k experts? We use the softmax function to calculate the expert‚Äôs importance probabilities and keep top\\-k probability experts, as shown below. I extracted the gating part of the above illustration.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qX9H2KKtjntVuiE8yFstMQ.png)\n\nA gating network has its weight. We apply the softmax function to the result of the dot\\-product between the input word token and the weight of a gating network, then get the probability of how much the expert is relevant to the given token. Based on the probability, we can select top\\-k relevant experts. MoE, which has this type of gating network, is called sparse MoE.\n\nThese are the fundamental knowledge needed to understand how MoE works as an embedding model. For further understanding, I recommend reading [this blog](https://huggingface.co/blog/moe) \\[2]. Now, let‚Äôs dive into how MoE actually works as an embedding model.\n\n## 2\\. How MoE works as an embedding model?\n\n### Quick recap about embeddings\n\nBefore diving into the theme of this section, let‚Äôs quickly recap about embeddings. Recently, embedding has been the internal representation of input data in deep learning models, and it has semantics and condensed data information. We usually extract the last hidden state of the neural network as an embedding, as shown below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kSHFTEejKiSI51taKZCO9A.png)\n\nWe typically use encoder\\-based models to extract embeddings because they can capture semantics with bi\\-directional attention compared to decoder\\-only models. Decoder\\-only models often use causal attention to interact with only the previous word tokens; thus, they cannot capture the rich semantics, such as contextualized information, like encoder\\-decoder models.\n\n### How MoE works as an embedding model?\n\nIt was a common belief that the decoder model could not be used for embedding extraction. However, the authors found that the routing weight in the MoE provides complementary information to the decoder embedding. The routing weight in each layer reflects the reasoning choice on the input token, so it contains the input‚Äôs semantic information that hidden state‚Äôs embedding may lost. In the mathematical formula, we can describe it as:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*n6wGCMqAhjBAfLFV47ML1g.png)\n\n*g* is the softmax function and *H* means the hidden state. We concatenate all the MoE layer‚Äôs routing weights to avoid losing model‚Äôs reasoning choice.\n\nTo fully utilize the routing weights and decoder embedding, the authors proposed a method called MoE Embedding (MoEE) to form a more comprehensive embedding representation. There are two types of MoEE. One method is a concatenation\\-based combination, described below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uVmcV-lM83XL7HoYbYjt7w.png)\n\nThis method is simple, and we just concatenate routing weights and decoder embedding. The authors call this method as MoEE(concat). It can preserve the distinct information captured by each routing weight while allowing downstream tasks to leverage the combined representation.\n\nThe other method is weighted sum integration. It performs a weighted sum of the similarity scores calculated from routing weights and hidden state (HS) embedding, denoted as MoEE (sum). This method is used for tasks that compare two sentences, such as semantic textual similarity.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kyJxWW9zdgRyNr2jmO4LlQ.png)\n\nùõÇ is a hyperparameter to control the contribution of the routing weights. After calculating the similarity score for each pair, we compute the rank correlation, such as Spearman‚Äôs rank correlation, between the calculated similarity score and the ground truth similarity.\n\nFor practical usage, I think that the MoEE(concat) is easy to use. Moreover, the authors leverage the PromptEOL technique \\[4] to enhance MoEE. This technique prompts the following template to constrain LLMs in predicting semantic information in the next token.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S9BASj9JkQe-i4fqmbopWg.png)\n\nNow, here is the performance table across MTEB tasks.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7LxkEMR2DFlncypF6_T7Vw.png)\n\nMoEE with PromptEOL can work better than supervised and self\\-supervised methods. Note that this leaderboard is not the latest one, so this result is not SOTA. The value of this method is that we can obtain decent results for embedding tasks, and it can be used without any further training.\n\nWe have covered how MoEE works so far. In the next section, we will implement MoEE with BERTopic and cluster sentences.\n\n## 3\\. Practical implementation : Leverage MoEE with BERTopic\n\nIn this section, we extract embeddings from pre\\-trained MoE LLM and leverage them with [BERTopic](https://maartengr.github.io/BERTopic/index.html) using a 20\\-news\\-group dataset \\[5]. For your information, BERTopic is a convenient topic modeling library beyond conventional statistical topic modeling. It leverages embeddings from Transformer to make topic clustering, so I think it is suitable for checking the capability. First of all, let‚Äôs prepare an environment.\n\n### Environment setup\n\nI used a conda environment with Python 3\\.10\\. I experimented on Ubuntu 20\\.04 with cuda 12\\.4, 16 GB VRAM. You may need 32 GB RAM for downloading model weights.\n\n```python\nconda create -n moee python=3.10 -y\nconda activate moee\n```\n\nNext, we need to install the libraries below via pip.\n\n```python\npip install transformers torch bitsandbytes bertopic accelerate\n```\n\nMoE models need generally high VRAM because we need to load the entire model to our VRAM in advance. Therefore, we require using bitsandbytes, which is a quantization package, to save VRAM memory.\n\nWe need to clone the official GitHub repository.\n\n```python\ngit clone https://github.com/tianyi-lab/MoE-Embedding.git\n```\n\nAll preparation is done. Now, let‚Äôs implement topic clustring with BERTopic using MoEE.\n\n### Leverage MoEE with BERTopic\n\nNow, we will use MoEE as an embedding model for BERTopic and try topic clustering. The original repository allows us to use small MoE models, such as Qwen\\-1\\.5\\-MoE\\-A2\\.7B or OLMoE\\-1B\\-7B. In this blog, I will use OLMoE\\-1B\\-7B, which is affordable for running inference on 16 GB VRAM. Firstly, we need to load OLMoE\\-1B\\-7B.\n\n```python\nkwargs = {\n        \"base_model\": 'allenai/OLMoE-1B-7B-0924',\n        \"normalized\": False,\n        \"torch_dtype\": torch.bfloat16,\n        \"mode\": \"embedding\",\n        \"pooling_method\": \"mean\",\n        \"attn_implementation\": \"sdpa\",\n        \"attn\": \"bbcc\",\n    }\n\nconfig = {\n    'embed_method': 'prompteol',\n    'emb_info': 'MoEE'\n    }\n\nembedding_model = MOEE(model_name_or_path='allenai/OLMoE-1B-7B-0924', **kwargs)\n```\n\nNext, we need to calculate embeddings of 20\\-news\\-group dataset to pass BERTopic. (I will attach full code later.)\n\n```python\nfrom sklearn.datasets import fetch_20newsgroups\n\ndocs = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))['data']\n\ndataset = MyDataset(docs)\ndataloader = DataLoader(dataset=dataset, batch_size=8)\nembeddings = None\n\nfor batch in tqdm(dataloader):\n    with torch.no_grad():    \n        embedding = embedding_model.encode(batch, **config)\n      \n        if embeddings is None:\n            embeddings = embedding[0]\n        else:\n            embeddings = np.vstack((embeddings, embedding[0]))\n  \n    torch.cuda.empty_cache()\n```\n\nTo calculate embeddings in advance, we use torch.utils.data.DataLoader for an iterator, and encode each batched document. Note that we must pass embeddings as np.asarray type to the BERTopic.\n\nWhen you want to use your own MoE models, you must implement to get the routing weights from each MoE layer. For the hidden state embedding, we can utilize the HuggingFace transformer function. We only need to pass the output\\_hidden\\_states\\=True argument when inference.\n\nNow, we can run topic modeling.\n\n```python\n## Step 2 - Reduce dimensionality\numap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n\n## Step 3 - Cluster reduced embeddings\nhdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n\n## Step 4 - Tokenize topics\nvectorizer_model = CountVectorizer(stop_words=\"english\")\n\n## Step 5 - Create topic representation\nctfidf_model = ClassTfidfTransformer()\n\n## Step 6 - (Optional) Fine-tune topic representations with \n## a `bertopic.representation` model\nrepresentation_model = KeyBERTInspired()\n\n## All steps together\ntopic_model = BERTopic(\n  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n  ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n  representation_model=representation_model # Step 6 - (Optional) Fine-tune topic representations\n)\n\n## topic modeling using BERTopic model\ntopics, probs = topic_model.fit_transform(docs, embeddings)\n```\n\nWe got 42 topics by the default setting; some samples are shown below. Even though I picked up topics randomly, it can capture the semantics very well.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VIaKHU-PSuTPzOUKDFbwOw.png)\n\nMoreover, here is the topic cluster visualization.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KYAUOe2qEAv-ihq2S2dM0A.png)\n\nPlease look at the red circle in the topic cluster visualization. This red circle refers to topic 0, which is related to the computer. Closer topics are also associated with mechanic words, such as graphics, digital, and printers.\n\nThis method shows us that we can get decent embeddings without any training. Although there is still room to improve the quality to be equivalent to the SOTA\\-supervised models, this paper‚Äôs finding is a good step for further improvement of the embedding extracting method without training.\n\nHere is my entire code. You need to put this file into the top of the MoE\\-Embedding directory.\n\n## References\n\n\\[1] Ziyue Li, Tianyi Zhou, [YOUR MIXTURE\\-OF\\-EXPERTS LLM IS SECRETLY AN EMBEDDING MODEL FOR FREE](https://arxiv.org/pdf/2410.10814) (2024\\), *Arxiv*\n\n\\[2] Omar S., et.al., [Mixture of Experts Explained](https://huggingface.co/blog/moe) (2023\\), Hugging Face\n\n\\[3] William Fedus, Barret Zoph., et.al., [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961) (2021\\), *Arxiv*\n\n\\[4] Ting Jiang, et.al., [Scaling Sentence Embeddings with Large Language Models](https://arxiv.org/pdf/2307.16645) (2023\\), *Arxiv*\n\n\\[5] [20 News groups](http://qwone.com/~jason/20Newsgroups/)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/using-llama-3-for-building-ai-agents-7e74f79d1ccc","frontmatter":{"title":"Using Llama 3 for Building AI Agents","meta_title":"Using Llama 3 for Building AI Agents","description":"Comprehensive guide to building AI Agents with Llama 3 function calling capabilities.","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EWGo-7t4Kl6l82rB2-ZK9Q.png","categories":["Programming","Generative AI","Chatbots"],"author":"Rifx.Online","tags":["Llama","Gradio","RAG","metadata","indexing"],"draft":false,"slug":"blog/using-llama-3-for-building-ai-agents-7e74f79d1ccc"},"content":"\n\n\n\n\n### Comprehensive guide to building AI Agents with Llama 3 function calling capabilities.\n\n\n\n\n### Introduction\n\nImagine you want to buy something. You visit an e\\-commerce website and use the search option to find what you want. Maybe you have multiple items to buy, so the process isn‚Äôt very efficient. Now consider this scenario: open an application, describe what you want in plain English, and press enter. You don't have to worry about searching and price comparisons because the application handles it automatically for you. Pretty cool, right? That‚Äôs exactly what we‚Äôll build in this tutorial.\n\nLet‚Äôs look at some examples first.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ikbr1ozv37PIB2meVfCCfA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AZPn3_KCDRV0pAszd3vLmA.png)\n\nAlright, let‚Äôs bring life to this application. We‚Äôre going to use Meta‚Äôs Llama 3 model with function calling capability. However, this can also be accomplished using the 3\\.1 models. According to [Meta‚Äôs announcement](https://ai.meta.com/blog/meta-llama-3-1/), the 3\\.1 models can use tools and functions more effectively.\n\n\n> These are multilingual and have a significantly longer context length of 128K, state\\-of\\-the\\-art tool use, and overall stronger reasoning capabilities\n\nI will use Groq Cloud, specifically their model for this article. The initial workflow of this application should consist of an embedding model, a retriever, and two major tools for handling user purchase interests and cost\\-related concerns. In summary, we need something similar to what we've described in the diagram below.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EZVySX3GD2O07fzEPwLcbQ.png)\n\nNow we have to use an LLM orchestration framework. For that, I am picking my all\\-time favorite, [Haystack](https://haystack.deepset.ai/).\n\nOkay, we got what we need. Let‚Äôs jump into the actual work!\n\n\n### Loading and indexing data\n\nSince we have an RAG pipeline, we should build a document indexing service as the first step. For this demo, I am going to use the in\\-memory vector database that Haystack offers. Please note that each document in our vector database contains,\n\n* Content ‚Äî Which we used to perform a similarity search\n* Id ‚Äî Unique identifier\n* Price ‚Äî Product price\n* URL ‚Äî Product URL\n\nWhen our RAG pipeline is invoked, the Content field is used for vector search. All other fields are included as metadata. It‚Äôs crucial to preserve this metadata as it‚Äôs essential for front\\-end presentation to the user.\n\nLet‚Äôs see how we can implement that.\n\n\n```python\nfrom haystack import Pipeline, Document\nfrom haystack.document_stores.in_memory import InMemoryDocumentStore\nfrom haystack.components.writers import DocumentWriter\nfrom haystack.components.embedders import SentenceTransformersDocumentEmbedder\nfrom haystack.components.generators import OpenAIGenerator\nfrom haystack.utils import Secret\nfrom haystack.components.generators.chat import OpenAIChatGenerator\nfrom haystack.components.builders import PromptBuilder\nfrom haystack.components.embedders import SentenceTransformersTextEmbedder\nfrom haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\nfrom haystack.dataclasses import ChatMessage\nimport pandas as pd\n\n## Load product data from CSV\ndf = pd.read_csv(\"product_sample.csv\")\n\n## Initialize an in-memory document store\ndocument_store = InMemoryDocumentStore()\n\n## Convert the product data into Haystack Document objects\ndocuments = [\n    Document(\n        content=item.product_name, \n        meta={\n            \"id\": item.uniq_id, \n            \"price\": item.selling_price, \n            \"url\": item.product_url\n        }\n    ) for item in df.itertuples()\n]\n\n## Create a pipeline for indexing the documents\nindexing_pipeline = Pipeline()\n\n## Add a document embedder to the pipeline using Sentence Transformers model\nindexing_pipeline.add_component(\n    instance=SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"), name=\"doc_embedder\"\n)\n\n## Add a document writer to the pipeline to store documents in the document store\nindexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"doc_writer\")\n\n## Connect the embedder's output to the writer's input\nindexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n\n## Run the indexing pipeline to process and store the documents\nindexing_pipeline.run({\"doc_embedder\": {\"documents\": documents}})\n```\nGreat, we‚Äôve completed the first step of our AI agent application. Now it‚Äôs time to build the product identifier tool. To better understand the primary task of the product identifier, let‚Äôs consider the example below.\n\n\n> User Query: I want to buy a camping boot, a charcoal and google pixel 9 back cover. Let‚Äôs understand our ideal workflow for the product identifier function.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kXGYjlMi4pQcqIKpmUZLRQ.png)\n\nFirst, we need to create a tool for analyzing user queries and identifying user\\-interested products. We can build such a tool using code snippets below.\n\n\n### Building User Query Analyzer\n\n\n```python\ntemplate = \"\"\"\nUnderstand the user query and list of products the user is interested in and return product names as list.\nYou should always return a Python list. Do not return any explanation.\n\nExamples:\nQuestion: I am interested in camping boots, charcoal and disposable rain jacket.\nAnswer: [\"camping_boots\",\"charcoal\",\"disposable_rain_jacket\"]\n\nQuestion: Need a laptop, wireless mouse, and noise-cancelling headphones for work.\nAnswer: [\"laptop\",\"wireless_mouse\",\"noise_cancelling_headphones\"]\n\nQuestion: {{ question }}\nAnswer:\n\"\"\"\n\nproduct_identifier = Pipeline()\n\nproduct_identifier.add_component(\"prompt_builder\", PromptBuilder(template=template))\nproduct_identifier.add_component(\"llm\", generator())\n\nproduct_identifier.connect(\"prompt_builder\", \"llm\")\n```\nOkay, now we have completed half of our first function, now it‚Äôs time to complete the function by adding the RAG pipeline.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JyxINdc8Wz-qAg_PCAkLbA.png)\n\n\n### Creating RAG Pipeline\n\n\n```python\ntemplate = \"\"\"\nReturn product name, price, and url as a python dictionary. \nYou should always return a Python dictionary with keys price, name and url for single product.\nYou should always return a Python list of dictionaries with keys price, name and url for multiple products.\nDo not return any explanation.\n\nLegitimate Response Schema:\n{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"}\nLegitimate Response Schema for multiple products:\n[{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"},{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"}]\n\nContext:\n{% for document in documents %}\n    product_price: {{ document.meta['price'] }}\n    product_url: {{ document.meta['url'] }}\n    product_id: {{ document.meta['id'] }}\n    product_name: {{ document.content }}\n{% endfor %}\nQuestion: {{ question }}\nAnswer:\n\"\"\"\n\nrag_pipe = Pipeline()\nrag_pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\nrag_pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))\nrag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\nrag_pipe.add_component(\"llm\", generator())\n\nrag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\nrag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\nrag_pipe.connect(\"prompt_builder\", \"llm\")\n```\nAfter this stage, we have completed both RAG and Query Analyzer pipelines. Now it‚Äôs time to convert this into a tool. For that, we can use a regular function declaration, as shown below. Creating a tool for the Agent is just like creating a Python function. In case you have a question like\n\n\n> How is it possible for the Agent to invoke this function?\n\nThe solution is straightforward: by leveraging a model\\-specific tool schema, which we plan to incorporate in a future step. For now, it‚Äôs time to create a wrapper function that uses both the query analyzer and RAG pipeline.\n\nLet‚Äôs clarify the objectives of this function.\n\n**Objective 1:** Identify all products the user is interested in and return them as a list. **Objective 2:** For each identified product, retrieve up to five products from the database along with their metadata.\n\n\n### Finalizing Product Identifier Function\n\n\n```python\ndef product_identifier_func(query: str):\n    \"\"\"\n    Identifies products based on a given query and retrieves relevant details for each identified product.\n\n    Parameters:\n    query (str): The query string used to identify products.\n\n    Returns:\n    dict: A dictionary where the keys are product names and the values are details of each product. If no products are found, returns \"No product found\".\n    \"\"\"\n    product_understanding = product_identifier.run({\"prompt_builder\": {\"question\": query}})\n\n    try:\n        product_list = literal_eval(product_understanding[\"llm\"][\"replies\"][0])\n    except:\n        return \"No product found\"\n\n    results = {}\n\n    for product in product_list:\n        response = rag_pipe.run({\"embedder\": {\"text\": product}, \"prompt_builder\": {\"question\": product}})\n        try:\n            results[product] = literal_eval(response[\"llm\"][\"replies\"][0])\n        except:\n            results[product] = {}\n    \n    return results\n```\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HWRTdWvvcw2MZP4uoaQdeQ.png)\n\nWith that, we have completed our first tool for the agent. Let‚Äôs see whether it works as expected.\n\n\n```python\nquery = \"I want crossbow and woodstock puzzle\"\n#execute function\nproduct_identifier_func(query)\n\n## {'crossbow': {'name': 'DB Longboards CoreFlex Crossbow 41\" Bamboo Fiberglass '\n##                        'Longboard Complete',\n##                'price': 237.68,\n##                'url': 'https://www.amazon.com/DB-Longboards-CoreFlex-Fiberglass-Longboard/dp/B07KMVJJK7'},\n##  'woodstock_puzzle': {'name': 'Woodstock- Collage 500 pc Puzzle',\n##                       'price': 17.49,\n##                       'url': 'https://www.amazon.com/Woodstock-Collage-500-pc-Puzzle/dp/B07MX21WWX'}}\n```\nIt worked!! However, it‚Äôs worth noting the return output schema. You can see the general schema below.\n\n\n```python\n{\n    \"product_key\": {\n        \"name\": \"string\",\n        \"price\": \"float\",\n        \"url\": \"string\"\n    }\n}\n```\nThat‚Äôs exactly what we have advised the model to produce in the RAG pipeline. As a next step, let‚Äôs build an optional tool called `find_budget_friendly_option`.\n\n\n```python\ndef find_budget_friendly_option(selected_product_details):\n    \"\"\"\n    Finds the most budget-friendly option for each category of products.\n\n    Parameters:\n    selected_product_details (dict): A dictionary where the keys are product categories and the values are lists of product details. Each product detail is expected to be a dictionary containing a 'price' key.\n\n    Returns:\n    dict: A dictionary where the keys are product categories and the values are the most budget-friendly product details for each category.\n    \"\"\"\n    budget_friendly_options = {}\n    \n    for category, items in selected_product_details.items():\n        if isinstance(items, list):\n            lowest_price_item = min(items, key=lambda x: x['price'])\n        else:\n            lowest_price_item = items\n        \n        budget_friendly_options[category] = lowest_price_item\n    \n    return budget_friendly_options\n```\nOkay, let's focus on the most crucial aspect of this application, which is enabling the agent to use these functions as needed. As we previously talked about, this is achievable through a model\\-specific tool schema. Therefore, we need to locate the tool schema specific to the selected model. Fortunately, it's mentioned in the model card [here](https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use). We need to adjust that to fit our use case.\n\n\n### Finalizing Chat Template\n\n\n```python\nchat_template = '''<|start_header_id|>system<|end_header_id|>\n\nYou are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n<tool_call>\n{\"name\": <function-name>,\"arguments\": <args-dict>}\n</tool_call>\n\nHere are the available tools:\n<tools>\n    {\n        \"name\": \"product_identifier_func\",\n        \"description\": \"To understand user interested products and its details\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to use in the search. Infer this from the user's message. It should be a question or a statement\"\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    {\n        \"name\": \"find_budget_friendly_option\",\n        \"description\": \"Get the most cost-friendly option. If selected_product_details has morethan one key this should return most cost-friendly options\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"selected_product_details\": {\n                    \"type\": \"dict\",\n                    \"description\": \"Input data is a dictionary where each key is a category name, and its value is either a single dictionary with 'price', 'name', and 'url' keys or a list of such dictionaries; example: {'category1': [{'price': 10.5, 'name': 'item1', 'url': 'http://example.com/item1'}, {'price': 8.99, 'name': 'item2', 'url': 'http://example.com/item2'}], 'category2': {'price': 15.0, 'name': 'item3', 'url': 'http://example.com/item3'}}\"\n                }\n            },\n            \"required\": [\"selected_product_details\"]\n        }\n    }\n</tools><|eot_id|><|start_header_id|>user<|end_header_id|>\n\nI need to buy a crossbow<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n<tool_call>\n{\"id\":\"call_deok\",\"name\":\"product_identifier_func\",\"arguments\":{\"query\":\"I need to buy a crossbow\"}}\n</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n\n<tool_response>\n{\"id\":\"call_deok\",\"result\":{'crossbow': {'price': 237.68,'name': 'crossbow','url': 'https://www.amazon.com/crossbow/dp/B07KMVJJK7'}}}\n</tool_response><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n'''\n```\nNow there are only a few steps left. Before doing anything, let‚Äôs test our agent.\n\n\n```python\n### Testing agent\nmessages = [\n    ChatMessage.from_system(\n        chat_template\n    ),\n    ChatMessage.from_user(\"I need to buy a crossbow for my child and Pok√©mon for myself.\"),\n]\n\nchat_generator = get_chat_generator()\nresponse = chat_generator.run(messages=messages)\npprint(response)\n\n### response\n{'replies': [ChatMessage(content='<tool_call>\\n'\n                                 '{\"id\": 0, \"name\": \"product_identifier_func\", '\n                                 '\"arguments\": {\"query\": \"I need to buy a '\n                                 'crossbow for my child\"}}\\n'\n                                 '</tool_call>\\n'\n                                 '<tool_call>\\n'\n                                 '{\"id\": 1, \"name\": \"product_identifier_func\", '\n                                 '\"arguments\": {\"query\": \"I need to buy a '\n                                 'Pokemon for myself\"}}\\n'\n                                 '</tool_call>',\n                         role=<ChatRole.ASSISTANT: 'assistant'>,\n                         name=None,\n                         meta={'finish_reason': 'stop',\n                               'index': 0,\n                               'model': 'llama3-groq-70b-8192-tool-use-preview',\n                               'usage': {'completion_time': 0.217823967,\n                                         'completion_tokens': 70,\n                                         'prompt_time': 0.041348261,\n                                         'prompt_tokens': 561,\n                                         'total_time': 0.259172228,\n                                         'total_tokens': 631}})]}\n```\nWith that, we have completed about 90% of our work.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nYVXcgpm3RZ3g5h5d4UK_A.png)\n\nOne thing you may have noticed in the above response is that the XML tag `<tool_call>` encloses tool calls. Thus, we need to develop a mechanism to extract the tool\\_call object.\n\n\n```python\ndef extract_tool_calls(tool_calls_str):\n    json_objects = re.findall(r'<tool_call>(.*?)</tool_call>', tool_calls_str, re.DOTALL)\n    \n    result_list = [json.loads(obj) for obj in json_objects]\n    \n    return result_list\n\navailable_functions = {\n    \"product_identifier_func\": product_identifier_func, \n    \"find_budget_friendly_option\": find_budget_friendly_option\n    }\n```\nWith this step completed, we can directly access the agent‚Äôs response when it calls a tool. Now the only thing pending is to get the tool call object and execute the function accordingly. Let‚Äôs complete that piece too.\n\n\n```python\nmessages.append(ChatMessage.from_user(message))\nresponse = chat_generator.run(messages=messages)\n\nif response and \"<tool_call>\" in response[\"replies\"][0].content:\n    function_calls = extract_tool_calls(response[\"replies\"][0].content)\n    for function_call in function_calls:\n        # Parse function calling information\n        function_name = function_call[\"name\"]\n        function_args = function_call[\"arguments\"]\n\n        # Find the corresponding function and call it with the given arguments\n        function_to_call = available_functions[function_name]\n        function_response = function_to_call(**function_args)\n\n        # Append function response to the messages list using `ChatMessage.from_function`\n        messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\n        response = chat_generator.run(messages=messages)\n```\nNow it‚Äôs time to join each component together and build a proper chat application. I am going to use Gradio for that purpose.\n\n\n```python\nimport gradio as gr\n\nmessages = [ChatMessage.from_system(chat_template)]\nchat_generator = get_chat_generator()\n\ndef chatbot_with_fc(message, messages):\n    messages.append(ChatMessage.from_user(message))\n    response = chat_generator.run(messages=messages)\n\n    while True:\n        if response and \"<tool_call>\" in response[\"replies\"][0].content:\n            function_calls = extract_tool_calls(response[\"replies\"][0].content)\n            for function_call in function_calls:\n                # Parse function calling information\n                function_name = function_call[\"name\"]\n                function_args = function_call[\"arguments\"]\n\n                # Find the corresponding function and call it with the given arguments\n                function_to_call = available_functions[function_name]\n                function_response = function_to_call(**function_args)\n\n                # Append function response to the messages list using `ChatMessage.from_function`\n                messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\n                response = chat_generator.run(messages=messages)\n\n        # Regular Conversation\n        else:\n            messages.append(response[\"replies\"][0])\n            break\n    return response[\"replies\"][0].content\n\n\ndef chatbot_interface(user_input, state):\n    response_content = chatbot_with_fc(user_input, state)\n    return response_content, state\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# AI Purchase Assistant\")\n    gr.Markdown(\"Ask me about products you want to buy!\")\n    \n    state = gr.State(value=messages)\n    \n    with gr.Row():\n        user_input = gr.Textbox(label=\"Your message:\")\n        response_output = gr.Markdown(label=\"Response:\")\n    \n    user_input.submit(chatbot_interface, [user_input, state], [response_output, state])\n    gr.Button(\"Send\").click(chatbot_interface, [user_input, state], [response_output, state])\n\n\ndemo.launch()\n```\nThat‚Äôs it! We have built the Llama 3\\-based AI Agent ü§ñ with function calling capability. You can access the full code from this [GitHub repo](https://github.com/Ransaka/ai-agents-with-llama3). Thanks for reading.\n\nAccess to the dataset used in this article is available through [this](https://www.kaggle.com/datasets/promptcloud/amazon-product-dataset-2020) Kaggle link (Under CC0: Public Domain).\n\n\n### Conclusion\n\nWhen constructing an AI agent\\-based system, it's important to consider the time required to complete a task and the number of API calls (tokens) used for each task. One of the major challenges is reducing hallucination in the system, which is an active area of research. Therefore, there are no set rules for building LLMs and agent systems. It's necessary to work patiently and strategically to ensure the AI agent, the LLM, is functioning correctly.\n\n*All images, unless otherwise noted, are by the author.*\n\n\n### Reference:\n\n[https://docs.together.ai/docs/llama\\-3\\-function\\-calling](https://docs.together.ai/docs/llama-3-function-calling)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557","frontmatter":{"title":"Visualize your RAG Data‚Ää‚Äî‚ÄäEvaluate your  Retrieval-Augmented Generation System with Ragas","meta_title":"Visualize your RAG Data‚Ää‚Äî‚ÄäEvaluate your  Retrieval-Augmented Generation System with Ragas","description":"How to use UMAP dimensionality reduction for Embeddings to show multiple evaluation Questions and their relationships to source documents‚Ä¶","date":"2024-11-04T12:35:56.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*peWTe1A-MqeROT_Jdof_Cw.gif","categories":["Natural Language Processing","Generative AI","Data Science"],"author":"Rifx.Online","tags":["RAG","UMAP","embeddings","evaluation","visualization"],"draft":false,"slug":"blog/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557"},"content":"\n\n\n\n\n### How to use UMAP dimensionality reduction for Embeddings to show multiple evaluation Questions and their relationships to source documents with Ragas, OpenAI, Langchain and ChromaDB\n\nRetrieval\\-Augmented Generation (RAG) adds a retrieval step to the workflow of an LLM, enabling it to query relevant data from additional sources like private documents when responding to questions and queries \\[1]. This workflow does not require costly training or fine\\-tuning of LLMs on the additional documents. The documents are split into snippets, which are then indexed, often using a compact ML\\-generated vector representation (embedding). Snippets with similar content will be in proximity to each other in this embedding space.\n\nThe RAG application projects the user\\-provided questions into the embedding space to retrieve relevant document snippets based on their distance to the question. The LLM can use the retrieved information to answer the query and to substantiate its conclusion by presenting the snippets as references.\n\n\n\nThe evaluation of a RAG application is challenging \\[2]. Different approaches exist: on one hand, there are methods where the answer as ground truth must be provided by the developer; on the other hand, the answer (and the question) can also be generated by another LLM. One of the largest open\\-source systems for LLM\\-supported answering is Ragas \\[4](Retrieval\\-Augmented Generation Assessment), which provides\n\n* Methods for generating test data based on the documents and\n* Evaluations based on different metrics for evaluating retrieval and generation steps one\\-by\\-one and end\\-to\\-end.\n\nIn this article, you will learn\n\n* How to briefly build a RAG system for Formula One (see the previous article [Visualize your RAG Data ‚Äî EDA for Retrieval\\-Augmented Generation](https://readmedium.com/visualize-your-rag-data-eda-for-retrieval-augmented-generation-0701ee98768f) for detailed descriptions)\n* Generate questions and answers\n* Evaluate the RAG system with [Ragas](https://github.com/explodinggradients/ragas)\n* Most importantly how to visualize the results with [Renumics Spotlight](https://github.com/Renumics/spotlight) and interpret the results.\n\nThe code is available at Github\n\n\n## Get your environment ready\n\nStart a notebook and install the required python packages\n\n\n```python\n!pip install langchain langchain-openai chromadb renumics-spotlight\n%env OPENAI_API_KEY=<your-api-key>\n```\nThis tutorial uses the following python packages:\n\n* [**Langchain**](https://github.com/langchain-ai/langchain): A framework to integrate language models and RAG components, making the setup process smoother.\n* [**Renumics\\-Spotlight**](https://github.com/Renumics/spotlight): A visualization tool to interactively explore unstructured ML datasets.\n* [**Ragas**](https://github.com/explodinggradients/ragas): a framework that helps you evaluate your RAG pipelines\n\n*Disclaimer: The author of this article is also one of the developers of Spotlight.*\n\n\n## Prepare documents and embeddings for the dataset\n\nYou can use your own RAG Application, skip to the next part to learn how to evaluate, extract and visualize.\n\nOr you can use the RAG application from the [last article](https://readmedium.com/visualize-your-rag-data-eda-for-retrieval-augmented-generation-0701ee98768f) with [our prepared dataset of all Formula One articles of Wikipedia](https://spotlightpublic.blob.core.windows.net/docs-data/rag_demo/docs.zip). There you can also insert your own Documents into a ‚Äòdocs/‚Äô subfolder.\n\n\n> This dataset is based on articles from [Wikipedia](https://www.wikipedia.org/) and is licensed under the Creative Commons Attribution\\-ShareAlike License. The original articles and a list of authors can be found on the respective Wikipedia pages.\n\nNow you can use Langchain‚Äôs `DirectoryLoader` to load all files from the docs subdirectory and split the documents in snippets using the `RecursiveCharacterTextSpliter`. With `OpenAIEmbeddings` you can create embeddings and store them in a `ChromaDB` as vector store. For the Chain itself you can use LangChains `ChatOpenAI` and a `ChatPromptTemplate`.\n\nThe [linked code](https://github.com/Renumics/rag-demo/blob/main/notebooks/visualize_rag_tutorial_qs.ipynb) for this article contains all necessary steps and you can find a detailed description of all steps above in [the last article](https://readmedium.com/visualize-your-rag-data-eda-for-retrieval-augmented-generation-0701ee98768f).\n\nOne important point is, that you should use a hash function to create ids for snippets in `ChromaDB`. This allows to find the embeddings in the db if you only have the document with its content and metadata. This makes it possible to skip documents that already exist in the database.\n\n\n```python\nimport hashlib\nimport json\nfrom langchain_core.documents import Document\n\ndef stable_hash_meta(doc: Document) -> str:\n    \"\"\"\n    Stable hash document based on its metadata.\n    \"\"\"\n    return hashlib.sha1(json.dumps(doc.metadata, sort_keys=True).encode()).hexdigest()\n\n...\nsplits = text_splitter.split_documents(docs)\nsplits_ids = [\n    {\"doc\": split, \"id\": stable_hash_meta(split.metadata)} for split in splits\n]\n\nexisting_ids = docs_vectorstore.get()[\"ids\"]\nnew_splits_ids = [split for split in splits_ids if split[\"id\"] not in existing_ids]\n\ndocs_vectorstore.add_documents(\n    documents=[split[\"doc\"] for split in new_splits_ids],\n    ids=[split[\"id\"] for split in new_splits_ids],\n)\ndocs_vectorstore.persist()\n```\n\n## Evaluation Questions\n\nFor a common topic like Formula One, one can also use ChatGPT directly to generate general questions. In this article, four methods of question generation are used:\n\n* **GPT4**: 30 questions were generated using ChatGPT 4 with the following prompt ‚ÄúWrite 30 question about Formula one‚Äù\n‚Äì Random Example: ‚ÄúWhich Formula 1 team is known for its prancing horse logo?‚Äù\n* **GPT3\\.5:** Another 199 question were generated with ChatGPT 3\\.5 with the following prompt ‚ÄúWrite 100 question about Formula one‚Äù and repeating ‚ÄúThanks, write another 100 please‚Äù\n‚Äì Example: ‚Äú‚ÄùWhich driver won the inaugural Formula One World Championship in 1950?‚Äù\n* **Ragas\\_GPT4**: 113 questions were generated using Ragas. Ragas utilizes the documents again and its own embedding model to construct a vector database, which is then used to generate questions with GPT4\\.\n‚Äì Example: ‚ÄúCan you tell me more about the performance of the Jordan 198 Formula One car in the 1998 World Championship?‚Äù\n* **Rags\\_GPT3\\.5**: 226 additional questions were generated with Ragas ‚Äî here we use GPT3\\.5\n‚Äì Example: ‚ÄúWhat incident occurred at the 2014 Belgian Grand Prix that led to Hamilton‚Äôs retirement from the race?‚Äù\n\n\n```python\nfrom ragas.testset import TestsetGenerator\n\ngenerator = TestsetGenerator.from_default(\n    openai_generator_llm=\"gpt-3.5-turbo-16k\", \n    openai_filter_llm=\"gpt-3.5-turbo-16k\"\n)\n\ntestset_ragas_gpt35 = generator.generate(docs, 100)\n```\nThe questions and answers were not reviewed or modified in any way. All questions are combined in a single dataframe with the columns `id`, `question`, `ground_truth`, `question_by` and `answer`.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*R_74K0-_SJXyTxq6ovAcWg.png)\n\nNext, the questions will be posed to the RAG system. For over 500 questions, this can take some time and incur costs. If you ask the questions row\\-by\\-row, you can pause and continue the process or recover from a crash without losing the results so far:\n\n\n```python\nfor i, row in df_questions_answers.iterrows():\n    if row[\"answer\"] is None or pd.isnull(row[\"answer\"]):\n        response = rag_chain.invoke(row[\"question\"])\n\n        df_questions_answers.loc[df_questions_answers.index[i], \"answer\"] = response[\n            \"answer\"\n        ]\n        df_questions_answers.loc[df_questions_answers.index[i], \"source_documents\"] = [\n            stable_hash_meta(source_document.metadata)\n            for source_document in response[\"source_documents\"]\n        ]\n\n```\nNot only is the answer stored but also the source IDs of the retrieved document snippets, and their text content as context:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*umlKv7Qf9SSLzRslT2r0Qw.png)\n\nAdditionally, the embeddings for all questions are generated and stored in the dataframe as well. This allows for visualizing them alongside the documents.\n\n\n## Evaluation with Ragas\n\n[Ragas](https://github.com/explodinggradients/ragas) provides metrics for evaluating each component of your RAG pipeline in isolation and end\\-to\\-end metrics for overall performance:\n\n1. **Context Precision:** Uses the `question` and retrieved `contexts` to measure the signal\\-to\\-noise ratio.\n2. **Context Relevancy:** Measures the relevance of the retrieved context to the question, calculated using the `question` and `contexts`.\n3. **Context Recall:** Based on the `ground truth` and `contexts` to check if all relevant information for the answer is retrieved.\n4. **Faithfulness:** Utilizes the `contexts` and `answer` to measure how factually accurate the generated answer is.\n5. **Answer Relevance:** Computed using the `question` and `answer` to assess the relevance of the generated answer to the question (does not consider factuality).\n6. **Answer Semantic Similarity:** Evaluated using the `ground truth` and `answer` to assess the semantic resemblance between the generated and the correct answer.\n7. **Answer Correctness:** Relies on the `ground truth` and `answer` to measure the accuracy and alignment of the generated answer with the correct one.\n8. **Aspect Critique:** Involves analyzing the `answer` to evaluate submissions based on predefined or custom aspects such as correctness or harmfulness.\n\nFor now, we focus on the end\\-to\\-end metric of answer correctness. The column names and content in the dataframe are copied and adapted to meet the naming and formatting requirements according to the Ragas API:\n\n\n```python\n## prepare the dataframe for evaluation\ndf_qa_eval = df_questions_answers.copy()\n\n\n## adapt the ground truth to the ragas naming and format\ndf_qa_eval.rename(columns={\"ground_truth\": \"ground_truths\"}, inplace=True)\ndf_qa_eval[\"ground_truths\"] = [\n    [gt] if not isinstance(gt, list) else gt for gt in df_qa_eval[\"ground_truths\"]\n]\n```\nThis again can take some time and even more money than just querying your RAG system. Let‚Äôs apply the evaluation row\\-by\\-row to be able to recover from a crash without losing the results so far:\n\n\n```python\n## evaluate the answer correctness if not already done\nfields = [\"question\", \"answer\", \"contexts\", \"ground_truths\"]\nfor i, row in df_qa_eval.iterrows():\n    if row[\"answer_correctness\"] is None or pd.isnull(row[\"answer_correctness\"]):\n        evaluation_result = evaluate(\n            Dataset.from_pandas(df_qa_eval.iloc[i : i + 1][fields]),\n            [answer_correctness],\n        )\n        df_qa_eval.loc[i, \"answer_correctness\"] = evaluation_result[\n            \"answer_correctness\"\n        ]\n\n```\nAfterwards, you can store the results in the `df_questions_answer` dataframe:\n\n\n```python\ndf_questions_answers[\"answer_correctness\"] = df_qa_eval[\"answer_correctness\"]\n```\n\n## Prepare visualization\n\nTo include the document snippets in the visualization, we add references from documents to questions that used the document as a source. Additionally, the count of questions referencing a document is stored:\n\n\n```python\n## Explode 'source_documents' so each document ID is in its own row alongside the question ID\ndf_questions_exploded = df_qa_eval.explode(\"source_documents\")\n\n## Group by exploded 'source_documents' (document IDs) and aggregate\nagg = (\n    df_questions_exploded.groupby(\"source_documents\")\n    .agg(\n        num_questions=(\"id\", \"count\"),  # Count of questions referencing the document\n        question_ids=(\n            \"id\",\n            lambda x: list(x),\n        ),  # List of question IDs referencing the document\n    )\n    .reset_index()\n    .rename(columns={\"source_documents\": \"id\"})\n)\n\n## Merge the aggregated information back into df_documents\ndf_documents_agg = pd.merge(df_docs, agg, on=\"id\", how=\"left\")\n\n## Use apply to replace NaN values with empty lists for 'question_ids'\ndf_documents_agg[\"question_ids\"] = df_documents_agg[\"question_ids\"].apply(\n    lambda x: x if isinstance(x, list) else []\n)\n## Replace NaN values in 'num_questions' with 0\ndf_documents_agg[\"num_questions\"] = df_documents_agg[\"num_questions\"].fillna(0)\n```\nNow concatenate the dataframe of questions with the dataframe of the documents\n\n\n```python\ndf = pd.concat([df_qa_eval, df_documents_agg], axis=0)\n```\nAdditionally, let‚Äôs prepare some different UMAP \\[3] mappings. You could do much the same in the Spotlight GUI later, but doing it upfront can save time.\n\n* umap\\_all: UMAP with fit and transform applied on all document and question embeddings\n* umap\\_questions: UMAP with fit applied on questions embeddings only and transform applied on both\n* umap\\_docs: UMAP with fit applied on document embeddings only and transform applied on both\n\nWe prepare each of the UMAP transformations like this:\n\n\n```python\numap = UMAP(n_neighbors=20, min_dist=0.15, metric=\"cosine\", random_state=42).fit\numap_all = umap.transform(df[\"embedding\"].values.tolist())\ndf[\"umap\"] = umap_all.tolist()\n\n```\nAnother interesting metric for each of the document snippets is the distance between its embeddings and the embeddings of the nearest question\n\n\n```python\nquestion_embeddings = np.array(df[df[\"question\"].notna()][\"embedding\"].tolist())\ndf[\"nearest_question_dist\"] = [  # brute force, could be optimized using ChromaDB\n    np.min([np.linalg.norm(np.array(doc_emb) - question_embeddings)])\n    for doc_emb in df[\"embedding\"].values\n]\n```\nThis metric can be helpful to find documents that are not referenced by questions.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YTRUXZmd0iX8kyPIdUUnlg.png)\n\n\n## Visualize results\n\nIf you skipped the previous steps, you can download the dataframe and load it with:\n\n\n```python\nimport pandas as pd\ndf = pd.read_parquet(\"df_f1_rag_docs_and_questions.parquet\")\n```\nand start [Renumics Spotlight](https://github.com/Renumics/spotlight) to visualize it with:\n\n\n```python\nfrom renumics import spotlight\n\nspotlight.show(df)\nspotlight.show(\n    df,\n    layout=\"/home/markus/Downloads/layout_rag_1.json\",\n    dtype={x: Embedding for x in df.keys() if \"umap\" in x},\n)\n```\nIt will open a new brwoser window:\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IMbva0pP8RAVhoY4dVbjLg.png)\n\nOn the top left side, you can see a **table of all questions and all document** snippets. You can use the ‚Äúvisible columns‚Äù button to control which columns of the dataframe are shown in the table. It is useful to create a filter directly that selects only the questions to be able to turn the questions on and off in the visualizations: Select all questions and and then create a filter using the ‚ÄúCreate filter from selected row‚Äù button.\n\nTo the right of the table, the `answer correctness` **is displayed as a metric** across all questions. Below there are two **histograms**; the left one shows the distribution of `answer correctness` divided into the different methods of question generation. The right one shows the distribution of methods of question generation. Here, it is advisable to create a filter for the questions using the filter button to display only the selected rows (the questions) if needed.\n\nOn the right side, there are **two similarity maps.** The first one uses the `umap_questions` column and shows the questions and documents based on the transformation applied only to the questions. It is helpful for viewing the distribution of questions independently from the associated documents because this approach allows analysts to identify patterns or clusters within the questions themselves.\n\nThe second similarity map shows the questions and documents based on the transformation applied only to the documents (`umap_docs`). It is useful for viewing the questions in the context of their associated documents. A similarity map that simultaneously transforms questions and documents has proven to be less helpful with a larger number of questions, as more or fewer questions get clustered together and tend to be separated from the documents. Therefore, this representation is omitted here.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1wZrAj60hiw1T3RVnCuBtA.png)\n\n\n### Document Embedding Similarity Map: Observations\n\nIn the similarity map `umap_docs`, you can identify areas in the embedding space of the documents that have no neighboring questions. It is even better recognized when selecting `nearest_question_dist` for coloring.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cMGNPnnBa9Bn7BJ05SzxBw.png)\n\nSome clusters can be identified, including snippets that contain only headings or tabular data containing only numbers page by page, whose meaning is lost during splitting. Additionally, many Wikipedia\\-specific text additions that contain no relevant information, such as links to other languages or editing notes, form clusters with no neighboring questions.\n\nRemoving the noise in form of Wikipedia\\-related text is very simple when using the Wikipedia API. It is probably not particularly necessary, as it mainly costs some space ‚Äî it is not expected that the RAG result will be particularly worsened by it. However, data contained in large tables are hardly captured by the RAG system and it could ne benifical to extract these using advanced pre\\-processing methods for Table Extraction and to connect them to the RAG system.\n\nAnother point that you can observe in the `umap_docs` similarity map is how the questions from different sources are distributed.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IH7z3J4yUmU0C_SruxnDkg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*K4bADgDmSAr5t4t4r9VImQ.png)\n\nThe questions that were directly generated by ChatGPT (GPT\\-3\\.5, GPT\\-4\\) are located in a more confined area in the center, whereas the questions generated with ragas based on the documents cover a larger area.\n\n\n### Answer correctness histogram\n\nThe histogram can be used as a starting point to get an initial impression of the global statistics of the data. Overall, across all questions, the `answer correctness` is 0\\.45\\. For the questions created without ragas, it is 0\\.36, and for questions with ragas, it is 0\\.52\\. It was expected that the system would perform better for questions generated by ragas, as these questions are based on the available data, whereas the questions directly generated by ChatGPT could come from all the data with which ChatGPT was trained.\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GsLBsg7uwTrw-AzvO4BHmw.png)\n\nA quick, random manual review of some of the questions/answers and ground truth shows that in the interval of`answer correctness`0\\.3‚Äì0\\.4, most questions were still correctly answered according to the ground truth. In the interval 0\\.2‚Äì0\\.3, many incorrect answers are present. In the interval 0\\.1‚Äì0\\.2, most answers are incorrect. Notably, almost all questions in this range came from GPT\\-3\\.5\\. The two questions in this interval generated with GPT\\-4 were answered correctly even though they received an `answer correctness` of below 0\\.2\\.\n\n\n### Questions Embedding Similarity Map: Observations\n\nThe Questions Embedding Similarity Map can be helpful to dig deeper into `answer correctness` by examining clusters of similar questions that may cause similar problems.\n\n* **Cluster ‚ÄúTerm for driver/process/cars‚Äù:** average `answer correctness` 0\\.23: Answers often not precise enough. E.g., Chassis tuning vs. Chassis flexing or brake tuning vs. brake bias adjustment. It is questionable whether these types of questions are suitable for evaluating the system, as it seems very difficult to judge the answers.\n* **Cluster ‚ÄúTerms for fuel strategy:‚Äù** average `answer correctness`0\\.44, similar to the global`answer correctness`.\n* **Cluster ‚ÄúNames of tracks‚Äù:** average `answer correctness` 0\\.49, similar to the global `answer correctnes`.\n* **Cluster ‚ÄúWho holds the record for‚Ä¶‚Äù**: average `answer correctness` 0\\.44, similar to the global `answer correctness`.\n* **Cluster ‚ÄúWin championship with‚Ä¶‚Äù**: average `answer correctnes` 0\\.26 ‚Äî looks challenging. Questions with many conditions, e.g., ‚ÄúWho is the only driver to win the Formula One World Championship with a British racing license, driving for an Italian team with an American engine.‚Äù Extended RAG methods like Multi Query might help improve here.\n* **Cluster ‚ÄúWho is the only driver to win‚Ä¶ with a car bearing the number \\<number\\>‚Äù**: average `answer correctness` 0\\.23 ‚Äî looks like GPT\\-3\\.5 was lazy here, repeating the same question with different numbers, even though most ground truth entries are wrong!\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Yc03cpSEFlJoZSBPIpMkiQ.png)\n\n\n## Conclusion\n\nIn conclusion, utilizing UMAP\\-based visualizations offers a interesting approach to dig deeper than just analyzing global metrics. The document embedding similarity map gives a good overview, illustrating the clustering of similar documents and their relation to evaluation questions. The question similarity map reveals patterns that allow the differentiation and analysis of questions in conjunction with quality metrics to enable insight generation. Follow the Visualize results section to apply the visualization on your evaluation strategy ‚Äî what insights will you uncover?\n\n*I am a professional with expertise in creating advanced software solutions for the interactive exploration of unstructured data. I write about unstructured data and use powerful visualization tools to analyze and make informed decisions.*\n\n\n## References\n\n\\[1] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, Haofen Wang: [Retrieval\\-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997) (2024\\), arxiv\n\n\\[2] Yixuan Tang, Yi Yang: [MultiHop\\-RAG: Benchmarking Retrieval\\-Augmented Generation for Multi\\-Hop Queries](https://arxiv.org/abs/2401.15391) (2021\\), arXiv\n\n\\[3] Leland McInnes, John Healy, James Melville: [UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction](https://arxiv.org/abs/1802.03426) (2018\\), arXiv\n\n\\[4] Shahul Es, Jithin James, Luis Espinosa\\-Anke, Steven Schockaert: [RAGAS: Automated Evaluation of Retrieval Augmented Generation](https://arxiv.org/abs/2309.15217) (2023\\), arXiv\n\n\n"},{"lang":"en","group":"blog","slug":"blog/whats-new-with-claude-sonnet-3-5-claude-3-5-haiku-c1f62a2d2c72","frontmatter":{"title":"What‚Äôs new with Claude Sonnet 3.5 & Claude 3.5 Haiku?","meta_title":"What‚Äôs new with Claude Sonnet 3.5 & Claude 3.5 Haiku?","description":"And is it worth checking out?","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*CEMTDlHlMUX66-eoMcSOzg.png","categories":["Natural Language Processing","Programming","Technology/Web"],"author":"Rifx.Online","tags":["language","models","interaction","automation","latency"],"draft":false,"slug":"blog/whats-new-with-claude-sonnet-3-5-claude-3-5-haiku-c1f62a2d2c72"},"content":"\n\n\n\n\n\n\n### First off, what is Claude?\n\nClaude is a language model created by [Anthropic](https://proxy.rifx.online/https://www.anthropic.com/) and it‚Äôs designed to help with tasks like answering questions, summarizing information and generating text ‚Äî similar to ChatGPT. The cool thing about Claude is that it‚Äôs built to be safer and more aligned with human intentions, making it less likely to produce harmful or misleading content.\n\n\n### Wait‚Ä¶ wasn‚Äôt Claude 3\\.5 Sonnet out already?\n\nHaha yes, while there haven‚Äôt been any changes to the name there are a lot of exciting updates to this new version of Claude 3\\.5 Sonnet and Claude Haiku that was released on October 22nd, 2024\\.\n\nThese new models are faster and better at tasks like debugging code and transcribing text from images, which makes them especially useful for industries like retail and logistics.\n\n*If you prefer to discuss these new changes and see how you can implement them into your project, [click here to schedule a free call with us](https://proxy.rifx.online/https://calendly.com/woyera-ai/)!*\n\n\n### Let‚Äôs dive in and see what‚Äôs new!\n\n\n## Human\\-Computer Interaction\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*p1anQynliN8ihnT8X2VYqw.gif)\n\nOne of the biggest updates with Claude 3\\.5 Sonnet is its ability to interact with computers in a more human\\-like way.\n\nIt can now navigate screens, click buttons, and type, which opens up some really interesting possibilities for automating tasks or even helping out in real\\-time workflows.\n\nKeep in mind that this feature is still in public beta, but it‚Äôs already showing a lot of promise, especially for robotic process automation (RPA).\n\n\n## Enhanced Coding Support\n\nClaude can assist throughout the entire software development process from designing, debugging, and optimizing code ‚Äî making it a valuable asset for anyone in tech.\n\n\n## Improved Chatbots\n\nClaude‚Äôs natural tone and advanced reasoning make it perfect for building more responsive and engaging chatbots.\n\nIt can handle complex conversations and even connect with various systems to streamline tasks which make it a great fit for customer service, technical support and more.\n\n\n## Visual Data Extraction\n\nOne standout feature is Claude‚Äôs ability to analyze visual data. It can interpret and pull information from charts, graphs, and diagrams with ease.\n\n\n## Knowledge Q\\&A\n\nClaude 3\\.5 Sonnet is also great for answering detailed questions using large datasets, knowledge bases, or code repositories. With a bigger context window it‚Äôs a reliable option for businesses that need quick, accurate information.\n\n\n## Availability and Pricing\n\nClaude 3\\.5 is available as an API on Anthropic API, Amazon Bedrock, and Google Cloud‚Äôs Vertex AI. For the API, pricing starts at **$3 per million input tokens** and **$15 per million output tokens.**\n\nOr you can simply use it on the web through [claude.ai](https://proxy.rifx.online/https://claude.ai/login?returnTo=%2F%3F). You can create an account for Free and then plans will be $20/month for Pro, $25/month for Team or [Enterprise.](https://proxy.rifx.online/https://www.anthropic.com/pricing)\n\n\n## Safety and Trust\n\nAnthropic has put a lot of effort into making Claude 3\\.5 Sonnet safe to use. The model has gone through extensive testing to ensure it can handle sensitive content responsibly without compromising on performance.\n\nThis focus on safety helps protect against issues like inappropriate content and ensures Claude is suitable for a wide range of applications.\n\n\n## Use Cases\n\nWhether you‚Äôre a developer, business owner, or just curious about AI, Claude 3\\.5 Sonnet has a lot to offer.\n\n\n### Automating repetitive tasks\n\nA customer service team can use Claude to handle repetitive backend tasks like updating customer orders or processing refunds. Claude‚Äôs ability to navigate screens and click buttons can save hours of manual work.\n\n\n### Chatbots\n\nA healthcare provider can build a chatbot with Claude to handle patient interactions such as booking appointments, answering medical FAQs, or guiding patients through symptom checks. All while maintaining a natural \\& conversational tone.\n\n\n### Visual data\n\nFinancial analysts can use Claude to analyze quarterly earnings reports that include a lot of charts and graphs. Claude can quickly extract insights and summarize key trends.\n\n\n### Knowledge Q\\&A\n\nA tech company can use Claude to manage an internal knowledge base. Developers could ask detailed questions about existing code repositories or troubleshooting steps and Claude would provide quick \\& reliable answers.\n\n\n## What about Claude 3\\.5 Haiku?\n\nClaude 3\\.5 Haiku is Anthropic‚Äôs fastest AI model and offers better performance without raising costs or slowing down. It‚Äôs stronger at tasks like coding and beats out models like Claude 3 Opus and GPT\\-4o in benchmarks.\n\nThe model is designed with low latency, meaning it responds quickly, making it perfect for real\\-time apps, personalized tasks like analyzing purchase history, and other data\\-heavy projects. It‚Äôll be available later this month on APIs like Amazon Bedrock and Google Cloud, starting as a text\\-only model with image support coming soon.\n\n\n## So, how does Claude compare to ChatGPT?\n\nWhen comparing **Claude 3\\.5** and **ChatGPT**, both are advanced AI models designed to tackle similar tasks like answering questions, generating text, and assisting with coding, but they have distinct differences that might cater to different needs.\n\nClaude 3\\.5 is built with a strong emphasis on **safety**, reducing the risk of harmful or misleading outputs. While ChatGPT also prioritizes safety, Claude‚Äôs design places extra focus on this area.\n\nIn terms of **speed**, Claude 3\\.5 Haiku offers faster response times, making it ideal for real\\-time applications. ChatGPT is also quick, but may experience slight delays on more complex tasks.\n\nFor **coding**, both models perform well. Claude 3\\.5 Sonnet stands out in recent benchmarks for debugging and code generation, while ChatGPT remains a reliable option for coding help and explanations.\n\nA key difference is **real\\-world interaction**. Claude 3\\.5 can navigate screens and automate tasks, a feature ChatGPT does not yet offer.\n\nIn **pricing**, ChatGPT has a widely available free version, while Claude offers flexible pricing with its API and cloud platforms.\n\nClaude‚Äôs focus on safety, low latency, and advanced real\\-world interactions make it a good fit for more specialized applications. Meanwhile ChatGPT‚Äôs versatility, wide availability, and strong coding support make it a great general\\-purpose tool.\n\nUltimately, the choice between the two depends on what you‚Äôre looking for but both models offer strong capabilities with their unique strengths.\n\n\n## Conclusion\n\nThe best way to learn about a new tool is to try it out yourself! You can use Claude 3\\.5 Sonnet for enhancing coding, chatbots, data analysis and much more.\n\nLet us know what you will use Claude for.\n\n*If you ever have a custom chatbot or app you need to build, [click here to have a quick call with us.](https://proxy.rifx.online/https://calendly.com/woyera-ai/)*\n\n\n"},{"lang":"en","group":"blog","slug":"blog/why-embedding-matters-when-building-a-non-english-rag-system-multilingual-embeddings-1e3434ea6180","frontmatter":{"title":"Why embedding matters when building a non-English RAG system‚Ää‚Äî‚ÄäMultilingual embeddings","meta_title":"Why embedding matters when building a non-English RAG system‚Ää‚Äî‚ÄäMultilingual embeddings","description":"Discover why multilingual embeddings are crucial for RAG systems, with a detailed comparison of English vs. multilingual models in Dutch.","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*QvODAYxqisUTrt4V.png","categories":["Natural Language Processing","Machine Learning","Multilingual"],"author":"Rifx.Online","tags":["embeddings","multilingual","RAG","Cohere","Dutch"],"draft":false,"slug":"blog/why-embedding-matters-when-building-a-non-english-rag-system-multilingual-embeddings-1e3434ea6180"},"content":"\n\n\n\n\n## Why Embeddings are Key\n\nEmbeddings are a cornerstone of modern generative AI, silently driving the functionality of many systems we interact with daily. At their simplest, embeddings are **numerical representations of text** ‚Äî effectively transforming words, sentences, or even entire documents into numbers. These numbers are far from random; they‚Äôre carefully designed to capture the meaning and relationships within the text. For instance, the embeddings for ‚Äúdog‚Äù and ‚Äúpuppy‚Äù would be closer together in the numerical space than the embedding for ‚Äúcar,‚Äù reflecting their **semantic similarity**. This ability to encode meaning into a measurable form is what makes embeddings indispensable for tasks like search, recommendation systems, and advanced AI applications such as **Retrieval\\-Augmented Generation (RAG)**.\n\n\n\nThis transformation into numbers allows AI to compare and understand text in a meaningful way. When working with massive amounts of data, as is often the case in RAG systems, embeddings become essential. These systems combine the power of embeddings with specialized storage solutions called **vector databases**. Unlike traditional databases that search for exact matches, vector databases are optimized to find the closest matches based on meaning. This capability enables RAG systems to retrieve the most relevant information from vast knowledge bases and use it to generate precise, contextually informed responses. By bridging raw data and intelligent retrieval, embeddings and vector databases together form the backbone of RAG systems‚Äô success.\n\n\n## The Challenge of Multilingual Systems\n\nBuilding RAG systems that work well in English is already a complex task, but extending them to other languages introduces a whole new set of challenges. English embeddings are often highly optimized because of the abundance of training data and the simplicity of the language‚Äôs structure. However, using these English\\-trained embeddings for other languages can lead to significant inaccuracies. Different languages come with their own nuances, grammar, and cultural contexts, which standard embedding models trained predominantly on English text often fail to capture. While some multilingual embedding models exist to bridge this gap, they are not all equally effective across languages, particularly for those with limited training data or unique linguistic features. This makes it difficult to build RAG systems that are as accurate and reliable for non\\-English languages as they are for English.\n\n\n### Why Are English Embeddings More Accurate?\n\n1. **Abundance of High\\-Quality Training Data**\nEnglish dominates the digital landscape, with an unparalleled volume of high\\-quality content available for training. Datasets like Wikipedia, books, research papers, and social media are much richer in English than in other languages. In contrast, many languages, especially low\\-resource ones, lack diverse and standardized datasets, which limits the quality of embeddings trained on them.\n2. **Model Optimization Bias**\nNLP models like BERT and GPT were initially developed and optimized for English, often prioritizing it even in multilingual versions. Multilingual models balance learning across many languages within the same parameter space, which can dilute performance for less\\-represented languages in favor of dominant ones like English.\n3. **Linguistic Complexity and Diversity**\nEnglish has relatively simple morphology compared to many other languages. For instance, word forms in English tend to remain consistent (e.g., ‚Äúrun‚Äù and ‚Äúrunning‚Äù), while languages like Turkish or Finnish have highly inflected forms, where a single root word can have dozens of variations. Additionally, languages with different syntax or word order, such as Japanese (Subject\\-Object\\-Verb) or Arabic (flexible word order), pose extra challenges for models optimized for English\\-like structures.\n4. **Semantic and Cultural Alignment**\nCapturing semantic meaning across languages is far from straightforward. Words and phrases often carry nuanced meanings that don‚Äôt translate directly. For example, the English word ‚Äúlove‚Äù has multiple culturally distinct equivalents in other languages (e.g., ‚Äúamor‚Äù in Spanish, ‚Äúeros‚Äù or ‚Äúagape‚Äù in Greek). Embeddings that fail to account for these differences struggle with multilingual alignment.\n5. **Benchmarking and Evaluation Bias**\nMany benchmarking datasets and evaluation methods are designed with English in mind. This English\\-centric focus can artificially inflate the perceived performance of models in English while masking their limitations in other languages.\n\n\n### The Impact on RAG Systems\n\nWhen embeddings fail to handle the complexity of other languages, the consequences for RAG systems can be significant. Retrieval results often become less relevant or even outright wrong, as the embeddings may struggle to capture the nuanced meaning of non\\-English queries. This doesn‚Äôt just impact accuracy ‚Äî it also undermines user trust and the overall utility of the system. Crucial text chunks may be missed during retrieval, preventing the system from accessing the information it needs to generate accurate and contextually relevant responses.\n\nFor a multilingual RAG system to perform well, it requires embeddings that can align semantically across languages while accounting for their unique structural and cultural intricacies. Investing in high\\-quality multilingual embeddings and fine\\-tuning them for specific languages or tasks is essential. This ensures that RAG systems can meet the needs of users in any language ‚Äî not just English.\n\nBut how well do different embeddings actually perform in a non\\-English context? To explore this, we‚Äôll compare an English embedding model with a multilingual embedding model using a Dutch dataset. This test will reveal how different approaches to embeddings impact retrieval accuracy and the quality of the generated responses in a multilingual RAG system.\n\n\n## Comparing Embedding Models for a Dutch RAG System\n\nTo understand how different embedding models handle a non\\-English language like Dutch, we‚Äôll compare two models available on Amazon Bedrock: **Cohere Embed English v3** and **Cohere Embed Multilingual v3**. These models represent different approaches to embeddings ‚Äî one optimized exclusively for English and the other designed for multilingual tasks. The table below summarizes their key attributes:\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*pBhIHfOsb-McrjHKvtq4Xw.png)\n\n\n### Build Embeddings\n\nTo evaluate the performance of the embedding models, we will build a local vectorstore using the LangChain framework. For this evaluation, we will use a guideline for firefighters written in Dutch as our dataset. This document contains technical and procedural information, making it a realistic and challenging use case for semantic retrieval in a non\\-English language. Below is the cleaned and streamlined code for creating a local vectorstore and indexing document chunks. We‚Äôll use this setup to test two embedding models: **Cohere Embed English v3** and **Cohere Embed Multilingual v3**.\n\n\n```python\nimport os\nfrom langchain_community.document_loaders import DirectoryLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain_aws import BedrockEmbeddings\nimport boto3\n\n## Step 1: Load documents\nloader = DirectoryLoader('data', glob=\"**/*.pdf\")  # Adjust 'data' to your document directory\ndocuments = loader.load()\n\nprint(f\"You have {len(documents)} documents\")\nprint(f\"Document 1 contains {len(documents[0].page_content)} characters\")\n\n## Step 2: Split documents into smaller chunks\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\nchunks = text_splitter.split_documents(documents)\n\nprint(f\"You have {len(chunks)} chunks\")\nprint(f\"The first chunk is {len(chunks[0].page_content)} characters long\")\n\n## Step 3: Set up Bedrock embeddings\nbedrock_client = boto3.client(\"bedrock-runtime\", region_name='us-east-1')\nbedrock_embeddings = BedrockEmbeddings(model_id=\"cohere.embed-multilingual-v3\", client=bedrock_client)\n\n## Step 4: Build the FAISS vectorstore\nvectorstore = FAISS.from_documents(chunks, bedrock_embeddings)\n\n## Save the vectorstore locally for reuse\nvectorstore.save_local(\"faiss_cohere_multilingual\")\n```\n\n## How This Code Works\n\n1. **Document Loading**:\nThe code loads all PDF files from the `data` directory. You can adjust the file path and format to match your dataset.\n2. **Text Splitting**:\nDocuments are split into smaller chunks of 400 characters with a 50\\-character overlap to improve retrieval accuracy. This ensures each chunk remains contextually meaningful.\n3. **Embedding Models**:\nThe `BedrockEmbeddings` class initializes the embedding model. You can replace the `model_id` to test **Cohere Embed English v3 or Cohere Embed Multilingual v3**.\n4. **Local Vectorstore**:\nThe FAISS library is used to create an in\\-memory vectorstore from the document chunks. This allows for fast similarity searches and can be saved locally for reuse.\n\nTo test all models, replace the `model_id` in the `BedrockEmbeddings` initialization with the appropriate model:\n\n* `\"cohere.embed-english-v3\"` for Cohere English.\n* `\"cohere.embed-multilingual-v3\"` for Cohere Multilingual.\n\n\n### Evaluating the Embedding Models\n\nTo evaluate the performance of the embedding models, we will ask the question: **‚ÄúWelke rangen zijn er bij de brandweer?‚Äù**, which translates to **‚ÄúWhich ranks exist within the fire department?‚Äù**. This question was chosen because our document only uses the term **‚Äúhi√´rarchie‚Äù**, which in Dutch has a similar semantic meaning to **‚Äúrangen‚Äù**. However, in English, ‚Äúhierarchy‚Äù and ‚Äúranks‚Äù do not share semantic similarity.\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6N3C8C500hMQ3GNNkuu21A.png)\n\nThis distinction is crucial for our test. We expect the **Cohere Embed English v3** model to struggle with this query, as it relies on English semantics where the terms are unrelated. On the other hand, the **Cohere Embed Multilingual v3** model, which is trained to understand Dutch semantics, should retrieve the correct information from the document, demonstrating its ability to handle semantic nuances in non\\-English languages.\n\nBy asking this question, we aim to highlight how semantic alignment affects retrieval performance in a Dutch RAG system. This test will provide a clear comparison of the models‚Äô ability to handle non\\-English queries and retrieve relevant information. The results will showcase the importance of multilingual embeddings for achieving accurate retrieval in non\\-English contexts.\n\nTo implement and test this setup, we can use the following code. This script demonstrates how to query the vectorstore and utilize a RAG chain to combine the embeddings with a language model for answering questions. Note that when testing different embeddings (e.g., **Cohere Embed English v3** vs. **Cohere Embed Multilingual v3**), you need to ensure that the vectorstore is built using the corresponding embedding model. Replace the vectorstore with the one indexed using the embedding model you want to test for accurate results.\n\n\n```python\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain_aws import ChatBedrock\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\ninstructions = \"\"\"Je bent een brandweer expert. Beantwoord de vraag, maak gebruik van de context\"\"\"\n\nhuman = \"\"\"\nDit is de context: {context}\nDit is de vraag: {question}\n\"\"\"\n\nprompt = ChatPromptTemplate(\n    messages=[\n        SystemMessagePromptTemplate.from_template(instructions),\n        HumanMessagePromptTemplate.from_template(human), #User query will go here\n    ],\n    input_variables=['context','question'], # context provided by retriever and question by the user\n)\nmodel = ChatOpenAI(\n    model=\"gpt-4\",  # or \"gpt-3.5-turbo\" based on your needs\n    temperature=0,\n    max_tokens=512\n)\n\n## Function to merge text chunks\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\n## RAG chain\nrag_chain = (\n        {\"context\": vectorstore.as_retriever(k=10) | format_docs, \"question\": RunnablePassthrough()}\n        | prompt\n        | model\n        | StrOutputParser()\n)\n\nrag_chain.invoke(\"Welke rangen zijn er bij de brandweer?\")\n```\n\n## Results of the Embedding Models\n\nTo evaluate the performance of the two embedding models, we asked the question: **‚ÄúWelke rangen zijn er bij de brandweer?‚Äù** (translated: ‚ÄúWhich ranks exist within the fire department?‚Äù). Below are the responses generated by each model:\n\n\n### Cohere Embed English v3\n\n**Response**:*‚ÄúDe tekst geeft geen specifieke informatie over de verschillende rangen binnen de brandweer. Echter, in veel brandweerorganisaties zijn er verschillende rangen zoals brandweerman, luitenant, kapitein, bataljonschef, assistent\\-chef en brandweerchef. De specifieke rangen kunnen vari√´ren afhankelijk van het land en de specifieke organisatie.‚Äù*\n\n**Analysis**:The response is generic and doesn‚Äôt rely on the provided context from the Dutch document. This is expected, as the English embedding model struggles to connect the semantic similarity between ‚Äúhi√´rarchie‚Äù (used in the document) and ‚Äúrangen‚Äù (used in the query). Consequently, it defaults to general knowledge about fire department ranks.\n\n\n### Cohere Embed Multilingual v3\n\n**Response**:*‚ÄúBinnen de brandweer zijn er verschillende rangen. Deze zijn onderverdeeld in het basiskader en het middenkader. In het basiskader hebben we de B01 brandweerman en de B02 korporaal. In het middenkader, dat bestaat uit onderofficieren, hebben we de M01 sergeant en de M02 adjudant. Deze rangen worden aangeduid op het diensttenue, het uitgaanstenue en op de interventiekledij.‚Äù*\n\n**Analysis**:This response is highly relevant and accurately retrieves information from the document. The multilingual embedding model successfully identifies the semantic relationship between ‚Äúhi√´rarchie‚Äù (context) and ‚Äúrangen‚Äù (query). It provides a detailed answer directly based on the content of the document, demonstrating its ability to handle Dutch\\-specific semantics effectively.\n\n\n### Key Takeaways\n\n* **Cohere Embed English v3**: The English model failed to retrieve relevant context from the Dutch document due to a lack of semantic alignment between the query and the document‚Äôs terminology. This highlights the limitations of using English\\-specific embeddings for non\\-English tasks.\n* **Cohere Embed Multilingual v3**: The multilingual model excelled in this test, retrieving and leveraging contextually relevant information from the Dutch document. This demonstrates the importance of multilingual embeddings for achieving accurate retrieval and answering non\\-English queries effectively.\n\n\n## Conclusion\n\nThis evaluation highlights a critical insight for anyone building Retrieval\\-Augmented Generation (RAG) systems for non\\-English languages: **embeddings matter**, especially when the task demands nuanced understanding across languages. The stark contrast in performance between the Cohere Embed English v3 and Cohere Embed Multilingual v3 models illustrates the limitations of English\\-specific embeddings in non\\-English contexts and the immense value of multilingual models.\n\nWhen tasked with answering a query in Dutch, the multilingual model excelled, retrieving accurate and contextually rich information directly from the document. Meanwhile, the English embedding model defaulted to generic, unrelated knowledge, demonstrating its inability to bridge the semantic gap between the query and the document‚Äôs content.\n\nFor organizations developing AI systems in a global, multilingual landscape, this test reinforces the importance of choosing the right embedding models for the task at hand. Multilingual embeddings are not just a ‚Äúnice\\-to\\-have‚Äù feature; they are essential for ensuring accuracy, relevance, and user trust in non\\-English applications.\n\nAs generative AI continues to expand its reach, embracing language diversity through better embeddings will be key to delivering meaningful and impactful solutions worldwide. By prioritizing multilingual capabilities, businesses can create systems that are not only smarter but also more inclusive ‚Äî empowering users across languages and cultures.\n\n***Follow me for more AI deep dives!***\n\n[Medium](https://proxy.rifx.online/https://medium.com/@lorevanoudenhove), [Instagram](https://proxy.rifx.online/https://www.instagram.com/lorevanoudenhove.ai/), [YouTube](https://proxy.rifx.online/https://www.youtube.com/channel/UCVyOJS1VV7FxPsStK65pHcA), [Pairrot](https://proxy.rifx.online/https://www.pairrot.eu/)\n\n\n"},{"lang":"en","group":"blog","slug":"blog/will-bolt-new-ai-will-replace-v0-dev-129a3366eb44","frontmatter":{"title":"Will Bolt.new AI will replace v0.dev","meta_title":"Will Bolt.new AI will replace v0.dev","description":"Will Bolt.new AI will replace v0.dev","date":"2024-11-13T01:22:35.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*g5S8PyYqR87bdyGhb77rRw.png","categories":["Programming","Technology/Web","Data Science"],"author":"Rifx.Online","tags":["Bolt.new","v0.dev","web","components","layouts"],"draft":false,"slug":"blog/will-bolt-new-ai-will-replace-v0-dev-129a3366eb44"},"content":"\n### AI Tools\n\n> **Not a Member? Read for FREE [here](https://proxy.rifx.online/https://tarzzotech.medium.com/129a3366eb44?source=friends_link&sk=385b6b2e482ae9d16ef8f99fe083b8ae).**\n\n\n\nThe world of web development is witnessing rapid growth with multiple AI tools in the market. These new AI tools help developers generate web components and complex code structures through natural language prompts. These tools provide better code quality and reduce time in writing manual code.\n\nRecently there was a new tool **bolt.new** came into the market which looks similar to v0\\.dev. With the arrival of Bolt.new, a question arises: ***Will this new AI platform replace v0\\.dev, or do these tools serve different purposes altogether?***\n\nIn this post, I will share my experience of using the tool for some time. I mainly talk about the key differences between **v0\\.dev** and **Bolt.new**, comparing their strengths, use cases, and outputs. By examining real\\-world examples, we‚Äôll determine whether **Bolt.new** poses a legitimate threat to **v0\\.dev**, or if both tools have their place in a developer‚Äôs toolkit.\n\nIn my previous blog, I explained all the details and my thoughts about v0\\.dev, so check it [**here**](https://proxy.rifx.online/https://tarzzotech.medium.com/4191292876b3?source=friends_link&sk=9730b35a75771953d0541e459c8adeaa). I don't want to share the repeated content here as well. Let's see here about **bolt.new** and comparison with **v0\\.dev.**\n\n## Overview of Bolt.new\n\n**Bolt.new** has made waves as a newer AI\\-powered platform with ambitions to go beyond just front\\-end components. While **v0\\.dev** is focused on generating smaller components, Bolt.new aims to deliver more complex solutions, such as full\\-page layouts or even multi\\-step workflows that span both the front\\-end and back\\-end.\n\n**Key Features of Bolt.new:**\n\n* **Full Layouts:** **Bolt.new** can generate full\\-page layouts, including headers, footers, sidebars, and main content areas.\n* **Versatile Code Generation:** Beyond web components, **Bolt.new** can produce server\\-side scripts, database configurations, and other elements essential for building full\\-stack applications.\n* **Enhanced Customization:** While V0\\.dev focuses on individual components, **Bolt.new** offers flexibility across larger scopes, allowing developers to generate fully functional layouts or structures.\n\n## Comparing V0\\.dev and Bolt.new\n\nWhile both tools offer impressive features, they cater to different aspects of the development process.\n\n* **v0\\.dev** focuses on individual web components that can be easily customized and integrated into front\\-end codebases. It‚Äôs ideal for developers needing quick solutions for buttons, cards, or forms that work across frameworks like React or Vue.\n* **Bolt.new**, in contrast, takes a more comprehensive approach, allowing developers to generate full\\-page layouts or even back\\-end configurations. This makes it a more versatile option for projects that require multiple types of code beyond just front\\-end components.\n\n## Example Comparison:\n\nHere we start to compare these tools from small components to full pages.\n\n### Creating a Button Component\n\n**Prompt:** ‚ÄúGenerate a responsive navigation bar with dropdown menus and a search bar.‚Äù\n\n**v0\\.dev**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8-1NaJb_msK1OLv7MHbOjw.gif)\n\n**bolt.new**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WsRSUU5brIql4uBb7wFkAg.gif)\n\n**v0\\.dev** created a button element with basic styling and a hover effect that changes the background color and text style when hovered.\n\n**Bolt.new** created a button with a hover effect and JavaScript code that triggers an alert box when clicked, including inline JavaScript and basic CSS styling.\n\n### Creating a Navigation Bar\n\n**Prompt:** ‚ÄúGenerate a responsive navigation bar with dropdown menus and a search bar.‚Äù\n\n**v0\\.dev**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sOJ0EveSOVKtJJltLGiVCA.gif)\n\n**bolt.new**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aGCWfH5ULTTFb-FS-kT-7w.gif)\n\nBoth tools have generated the Navbar a little similarly. But **bolt.new** has generated a little better than **v0\\.dev**.\n\n### Creating a Website.\n\n**Prompt:** ‚ÄúGenerate a full page layout with a sticky header, footer, collapsible sidebar, and main content area designed for blog posts.‚Äù\n\n**v0\\.dev**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kwEXDG3tb1CiHetZr5W03Q.png)\n\n**bolt.new**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HxKnFJQf--e-E1fh8yyxVw.png)\n\nThe output from the **bolt.new** is speechless.\n\n## Finally, Will Bolt.new Replace v0\\.dev?\n\nGiven the broader scope of Bolt.new, it might seem like it could overshadow v0\\.dev. However, the two platforms are likely to coexist, each offering value for different stages of the development process.\n\n**v0\\.dev** is unmatched in its ability to generate specific, high\\-quality web components quickly. It‚Äôs perfect for front\\-end developers who need reusable, responsive components that are ready to integrate into their projects with minimal fuss.\n\n**Bolt.new**, while offering more flexibility, is not necessarily a replacement for v0\\.dev. Its broader range of functionality appeals to developers who need full layouts or code structures that span both the front end and back end.\n\n## Conclusion\n\nBoth v0\\.dev and Bolt.new are powerful AI tools, each with unique strengths. While Bolt.new‚Äôs versatility makes it a strong contender for developers looking to generate more complex code, v0\\.dev remains a go\\-to tool for developers who want quick, customizable components.\n\nUltimately, the question of whether Bolt.new will replace v0\\.dev? It‚Äôs unlikely. These platforms cater to distinct needs. v0\\.dev shines in generating specific, reusable components with ease. Bolt.new offers broader functionality for complex layouts. So, which tool do you think will dominate in the future of AI AI\\-assisted development, or will they continue to complement each other? The answer depends on the developer's need on which you are working.\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/10-creative-ways-to-use-chatgpt-search-the-web-feature-7f145c5cfa30","frontmatter":{"title":"‰ΩøÁî® ChatGPT ÊêúÁ¥¢ÁΩëÁªúÂäüËÉΩÁöÑ 10 ÁßçÂàõÊÑèÊñπÊ≥ï","meta_title":"‰ΩøÁî® ChatGPT ÊêúÁ¥¢ÁΩëÁªúÂäüËÉΩÁöÑ 10 ÁßçÂàõÊÑèÊñπÊ≥ï","description":"ChatGPT ÁöÑ‚ÄúÊêúÁ¥¢ÁΩëÁªú‚ÄùÂäüËÉΩ‰∏∫Áî®Êà∑Êèê‰æõ‰∫ÜÂ§öÁßçÂàõÊñ∞ÁöÑ‰ΩøÁî®ÊñπÂºèÔºåÂåÖÊã¨ÂÖ≥Ê≥®Êó∂‰∫ãÊñ∞Èóª„ÄÅËßÑÂàíÊóÖË°åË°åÁ®ã„ÄÅÂèëÁé∞Êñ∞È£üË∞±„ÄÅÁõëÊµãÂ∏ÇÂú∫Ë∂ãÂäø„ÄÅËé∑ÂèñÂÆûÊó∂Êï∞ÊçÆ„ÄÅÊü•ÊâæÊú¨Âú∞Ê¥ªÂä®„ÄÅÊØîËæÉ‰∫ßÂìÅ„ÄÅ‰∫ÜËß£Êñ∞ÂÖ¥ÊäÄÊúØ„ÄÅËé∑ÂèñÁ©∫Ê∞îË¥®ÈáèÊõ¥Êñ∞ÂíåÊé¢Á¥¢ÊïôËÇ≤ËµÑÊ∫ê„ÄÇËØ•ÂäüËÉΩËÉΩÂ§üÂ∏ÆÂä©Áî®Êà∑Ëé∑ÂèñÊúÄÊñ∞‰ø°ÊÅØÔºåÊèêÂçá‰ø°ÊÅØÊ£ÄÁ¥¢ÁöÑÊïàÁéáÔºåÈÄÇÁî®‰∫éÂ§öÁßçÈúÄÊ±Ç„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*S4RtWt6Ouspx4nnl","categories":["Chatbots","Technology/Web","Education"],"author":"Rifx.Online","tags":["ChatGPT","search","web","real-time","information"],"draft":false,"slug":"blog/10-creative-ways-to-use-chatgpt-search-the-web-feature-7f145c5cfa30"},"content":"\n\n\n### ‰æãÂ¶ÇÔºåÊèêÁ§∫ÂíåËæìÂá∫\n\n\n\n‰Ω†Áü•ÈÅìÂèØ‰ª•‰ΩøÁî® ChatGPT ÁöÑ‚ÄúÊêúÁ¥¢ÁΩëÁªú‚ÄùÂäüËÉΩÊù•ÂÆåÊàêËÆ∏Â§ö‰ªªÂä°ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂü∫Êú¨ÁöÑÁΩëÁªúÊêúÁ¥¢ÂêóÔºü\n\nÂØπ‰∫éÈÇ£‰∫õ‰∏çÁü•ÈÅìÁöÑ‰∫∫ÔºåChatGPT Êñ∞ÁöÑ‚ÄúÊêúÁ¥¢ÁΩëÁªú‚ÄùÂäüËÉΩÊèê‰æõÂÆûÊó∂‰ø°ÊÅØ„ÄÇ\n\nÊà™Ëá≥Êí∞ÂÜôÊ≠§Â∏ñÊó∂ÔºåËØ•ÂäüËÉΩ‰ªÖÂØπ‰ΩøÁî® ChatGPT 4o Âíå 4o-mini ÁöÑ‰ªòË¥π‰ºöÂëòÂºÄÊîæ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uyESPHmmvzSJjZmgpn_Oww.png)\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∫õ‰ΩøÁî®Ê≠§ÂäüËÉΩÁöÑÂàõÊÑèÊñπÂºèÔºö\n\n## 1\\. ÂÖ≥Ê≥®Êó∂‰∫ãÊñ∞ÈóªÔºö\n\nÂ¶ÇÊûúÊÇ®ÂØπÊúÄÊñ∞ÁöÑÊñ∞ÈóªÂíå‰∫ã‰ª∂ÊÑüÂÖ¥Ë∂£Ôºå‰ΩÜÊ≤°ÊúâÊó∂Èó¥ÂéªÊêúÁ¥¢ÂíåÂØªÊâæÊúÄ‰Ω≥‰ø°ÊÅØÔºåËøô‰∏™ÂäüËÉΩÈÄÇÂêàÊÇ®„ÄÇ\n\nÁé∞Âú®Ôºå‰ΩøÁî® ChatGPT ÁöÑÊêúÁ¥¢ÁΩëÈ°µÂäüËÉΩÔºåÊÇ®ÂèØ‰ª•ÈöèÊó∂Êé•Êî∂ÊúÄÊñ∞Êñ∞Èóª„ÄÅ‰ΩìËÇ≤ÊØîÂàÜÂíåËÇ°Â∏ÇÊõ¥Êñ∞ÁöÑÊëòË¶Å„ÄÇ\n\n**Á§∫‰æã**Ôºö‚Äî ‚Äú***‰ªäÂ§©ÁßëÊäÄÈ¢ÜÂüüÁöÑÊúÄÊñ∞Êñ∞ÈóªÊòØ‰ªÄ‰πàÔºü***‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OQFEyg8WFckOQcM5cKyRww.png)\n\n## 2\\. ËÆ°ÂàíÊóÖË°åË°åÁ®ãÔºö\n\nÊÇ®ÂñúÊ¨¢‰∏∫ÊúÄ‰Ω≥Êó∂Èó¥ÂíåÈ¢ÑÁÆóÁÆ°ÁêÜËßÑÂàíÊóÖË°åÂêóÔºüÈÇ£‰πàÊÇ®‰ºöÂèëÁé∞Ëøô‰∏™Ë°åÁ®ãËßÑÂàíÂäüËÉΩÈùûÂ∏∏ÊúâÂ∏ÆÂä©„ÄÇ\n\nÁé∞Âú®ÊÇ®ÂèØ‰ª•Ëé∑ÂèñÊúâÂÖ≥ÊóÖË°åÁõÆÁöÑÂú∞ÁöÑÊúÄÊñ∞‰ø°ÊÅØÔºåÂåÖÊã¨Â§©Ê∞îÈ¢ÑÊä•„ÄÅÂΩìÂú∞Ê¥ªÂä®‰ª•ÂèäÊúÄ‰Ω≥Ë¥≠Áâ©ÂíåÁî®È§êÂú∞ÁÇπ„ÄÇ\n\n**Á§∫‰æãÔºö ‚Äî ‚Äú*Ëøô‰∏™Âë®Êú´Â∑¥ÈªéÁöÑ‰∏ªË¶ÅÊôØÁÇπÊúâÂì™‰∫õÔºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BLm4PoTaxrXkBMoB56jg8g.png)\n\n## 3\\. ÂèëÁé∞Êñ∞È£üË∞±Ôºö\n\nÂ¶ÇÊûú‰Ω†ÂñúÊ¨¢Â∞ùËØïÊñ∞È£üÁâ©Âπ∂‰∏îÁÉ≠Áà±ÁÉπÈ•™ÔºåËøô‰∏™ÊñπÊ≥ïÈùûÂ∏∏ÈÄÇÂêà‰Ω†„ÄÇ\n\n‰Ω†ÂèØ‰ª•Âú® ChatGPT ‰∏≠‰ΩøÁî®‚ÄúÊêúÁ¥¢ÁΩëÁªú‚ÄùÊù•Ê†πÊçÆÊó•ÊúüÊàñÂú∞ÁÇπÊâæÂà∞ÊµÅË°åÁöÑÈ£üË∞±ÊàñÁÉπÈ•™ÊäÄÂ∑ß„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*Ëøô‰∏™ÊúàÊúâ‰ªÄ‰πàÂèóÊ¨¢ËøéÁöÑÁîúÁÇπÈ£üË∞±Ôºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iSrMCgwjdOw4xOSC51LglA.png)\n\n## 4\\. ÁõëÊµãÂ∏ÇÂú∫Ë∂ãÂäøÔºö\n\nÂ¶ÇÊûúÊÇ®ÂñúÊ¨¢ÈòÖËØªÊàñ‰øùÊåÅÂØπÊüê‰∏ÄÁü•ËØÜÈ¢ÜÂüüÁöÑÊõ¥Êñ∞ÔºåÈÇ£‰πàËøô‰∏™ÂäüËÉΩÈÄÇÂêàÊÇ®„ÄÇ\n\nÁé∞Âú®ÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®ÊêúÁ¥¢ÁΩëÁªúÂäüËÉΩË∑üË∏™‰ªª‰ΩïË°å‰∏öË∂ãÂäø„ÄÇ\n\n**Á§∫‰æãÔºö ‚Äî ‚Äú*Â§™Èò≥ËÉΩÁöÑÊúÄÊñ∞ÂèëÂ±ïÊòØ‰ªÄ‰πàÔºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*M-Y7hXRYMXGs_V6iHOm7lQ.png)\n\n## 5\\. ËÆøÈóÆÂÆûÊó∂Êï∞ÊçÆÔºö\n\nÊÉ≥Áü•ÈÅì‰ªäÂ§©‰ºö‰∏ãÈõ®ÂêóÔºü\n\nÊàñËÄÖÊÉ≥Áü•ÈÅìÊúÄÊñ∞ÁöÑÊØîÂàÜÂç¥Êó†Ê≥ïËßÇÁúãÁé∞Âú∫Áõ¥Êí≠ÁöÑ‰ΩìËÇ≤ÊØîËµõÔºü\n\nÁé∞Âú®ÊÇ®ÂèØ‰ª•Ëé∑ÂèñÂÆûÊó∂Êï∞ÊçÆÔºå‰æãÂ¶ÇÂ§©Ê∞îÊõ¥Êñ∞„ÄÅËÇ°Á•®‰ª∑Ê†ºÊàñ‰ΩìËÇ≤ÊØîÂàÜ„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*Á∫ΩÁ∫¶Â∏ÇÂΩìÂâçÁöÑÂ§©Ê∞îÊÄé‰πàÊ†∑Ôºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TwPSdHgHdaKmipspoyldsg.png)\n\n## 6\\. Êü•ÊâæÊú¨Âú∞Ê¥ªÂä®Ôºö\n\nËøôÈáåÁöÑÂ§ñÂêëÂûã‰∫∫‰ºöÂñúÊ¨¢Ëøô‰∏™ÂäüËÉΩ„ÄÇ\n\nÁé∞Âú®ÊÇ®ÂèØ‰ª•ÂèëÁé∞ÊÇ®ÊâÄÂú®Âú∞Âå∫Ê≠£Âú®ÂèëÁîüÁöÑÊ¥ªÂä®ÔºåÂπ∂‰∏îÂÆÉËøò‰ºöÊèê‰æõÁõ¥Êé•ÈìæÊé•Âà∞ÁΩëÁ´ôÔºåÊÇ®ÂèØ‰ª•Âú®ÂÖ∂‰∏≠‰∫ÜËß£Êõ¥Â§öÁªÜËäÇÂπ∂È¢ÑËÆ¢Á•®„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*Ëøô‰∏™Âë®Êú´Âú®ÊÇâÂ∞ºÊúâÂì™‰∫õÊ¥ªÂä®Ôºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MgSawNL8kSTohGsIU0ajrA.png)\n\n## 7\\. ÊØîËæÉ‰∫ßÂìÅÔºö\n\nÊÉ≥Ë¥≠‰π∞Êñ∞‰∫ßÂìÅÂêóÔºüÊÉ≥Áü•ÈÅìÂÆÉÁöÑ‰ºòÁº∫ÁÇπÔºü\n\nÊàñËÄÖÊÇ®ÂèØËÉΩÊÉ≥ÊØîËæÉÂá†‰∏™‰∫ßÂìÅÔºå‰ª•ÂÜ≥ÂÆöÂÖ∂‰∏≠ÊúÄÂ•ΩÁöÑ„ÄÇ\n\nÁé∞Âú®ÊÇ®ÂèØ‰ª•‰ΩøÁî®ÊêúÁ¥¢ÁΩëÁªúÂäüËÉΩÊù•ÊØîËæÉ‰∫ßÂìÅÊàñÊúçÂä°„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*ÊØîËæÉ‰ªäÂπ¥ÂèëÂ∏ÉÁöÑÊúÄÊñ∞Êô∫ËÉΩÊâãÊú∫„ÄÇ*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HvzNuBcc6kWNSZA7Sj2hUg.png)\n\n## 8\\. ‰∫ÜËß£Êñ∞ÂÖ¥ÊäÄÊúØÔºö\n\nÂ¶ÇÊûú‰Ω†ÊÉ≥Âú®Êñ∞ÂÖ¥ÊäÄÊúØÈ¢ÜÂüü‰øùÊåÅÊõ¥Êñ∞ÔºåËøô‰∏™ÈÄÇÂêà‰Ω†„ÄÇ\n\n‰ΩøÁî®‚ÄúÊêúÁ¥¢ÁΩëÁªú‚ÄùÂäüËÉΩÔºåÁé∞Âú®‰Ω†ÂèØ‰ª•‰∫ÜËß£Êñ∞ÊäÄÊúØÁöÑÊúÄÊñ∞Âä®ÊÄÅ„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*‰∫∫Â∑•Êô∫ËÉΩÁöÑÊúÄÊñ∞ËøõÂ±ïÊòØ‰ªÄ‰πàÔºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VwySsjMn59nvqxHUWm1AtA.png)\n\n## 9\\. Ëé∑ÂèñÁ©∫Ê∞îË¥®ÈáèÊõ¥Êñ∞Ôºö\n\nËøôÊòØ ChatGPT ‰ΩçÁΩÆÂíåÊó∂Èó¥ÊÑüÁü•ÊêúÁ¥¢ÁªìÊûúÁöÑÂè¶‰∏Ä‰∏™ÈÖ∑ÁÇ´Áî®Ê≥ï„ÄÇ\n\nÁé∞Âú®ÊÇ®ÂèØ‰ª•Ê£ÄÊü•‰ªª‰ΩïÂú∞ÁÇπÁöÑÁ©∫Ê∞îË¥®ÈáèÊåáÊï∞„ÄÇ‰ΩøÁî®Ê≠§ÂäüËÉΩ‰∫ÜËß£Ê±°ÊüìÊ∞¥Âπ≥„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*Áé∞Âú®Á∫ΩÁ∫¶ÁöÑ AQI ÊòØÂ§öÂ∞ëÔºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6C_VcWft52zoR57XzEMo-A.png)\n\n## 10\\. Êé¢Á¥¢ÊïôËÇ≤ËµÑÊ∫êÔºö\n\nÂ¶ÇÊûúÊÇ®ÂñúÊ¨¢ÈÄöËøáËßÇÁúãËØæÁ®ãÊù•Â≠¶‰π†Êüê‰∏™‰∏ªÈ¢òÔºåÈÇ£‰πàËøôÂ∞ÜÂØπÊÇ®Â∏ÆÂä©ÂæàÂ§ß„ÄÇ\n\nÊÇ®ÂèØ‰ª•‰ΩøÁî®ÊêúÁ¥¢ÂäüËÉΩÊü•ÊâæÊÑüÂÖ¥Ë∂£‰∏ªÈ¢òÁöÑÊúÄÊñ∞ÊñáÁ´†ÊàñËØæÁ®ã„ÄÇ\n\n**Á§∫‰æãÔºö‚Äî ‚Äú*ÊúâÂì™‰∫õÊúÄÊñ∞ÁöÑÊï∞ÊçÆÁßëÂ≠¶Âú®Á∫øËØæÁ®ãÂèØÁî®Ôºü*‚Äù**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tPq8Lve_M_1sNhqfkqtwyg.png)\n\n‰ΩøÁî® ChatGPT ÁöÑÁΩëÁªúÊêúÁ¥¢ÂäüËÉΩÔºåÊÇ®ÂèØ‰ª•‰ª•Â§öÁßç‰∏çÂêåÊñπÂºèËÆøÈóÆÊúÄÊñ∞ÂíåÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ËøòÂèëÁé∞‰∫Ü‰∏Ä‰∫õÊñ∞ÁöÑÂíå‰∏çÂêåÁöÑÂÆûÊó∂ÊêúÁ¥¢Áî®Ê≥ïÔºåËØ∑Âú®ËØÑËÆ∫‰∏≠ÂëäËØâÊàë„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/10-must-learn-skills-to-stay-ahead-in-ai-and-tech-42f4140713b1","frontmatter":{"title":"Âú®‰∫∫Â∑•Êô∫ËÉΩÂíåÊäÄÊúØÈ¢ÜÂüü‰øùÊåÅÈ¢ÜÂÖàÂú∞‰ΩçÁöÑ 10 È°πÂøÖÂ≠¶ÊäÄËÉΩ üìö","meta_title":"Âú®‰∫∫Â∑•Êô∫ËÉΩÂíåÊäÄÊúØÈ¢ÜÂüü‰øùÊåÅÈ¢ÜÂÖàÂú∞‰ΩçÁöÑ 10 È°πÂøÖÂ≠¶ÊäÄËÉΩ üìö","description":"Âú®‰∫∫Â∑•Êô∫ËÉΩÂíåÁßëÊäÄÈ¢ÜÂüüÔºåÊåÅÁª≠ÊèêÂçáÊäÄËÉΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÊú¨ÊñáÂàóÂá∫‰∫Ü10‰∏™ÂÖ≥ÈîÆËØæÁ®ãÔºåÂåÖÊã¨ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ„ÄÅË∞ÉËØïÊäÄÊúØ„ÄÅAI‰∫ßÂìÅË∂ãÂäø„ÄÅÊ≥ïÂæãÈ¢ÜÂüüÁöÑÊèêÁ§∫Â∑•Á®ãÁ≠âÔºåÊó®Âú®Â∏ÆÂä©‰∏ì‰∏ö‰∫∫Â£´ÊéåÊè°Êñ∞ÊäÄÊúØÔºå‰øùÊåÅÁ´û‰∫âÂäõ„ÄÇËøô‰∫õËØæÁ®ãÊ∂µÁõñ‰ªéÂü∫Á°ÄÂà∞‰∏ì‰∏öÁöÑÂ§öÁßçÁü•ËØÜÔºåÈÄÇÂêà‰∏çÂêåËÉåÊôØÁöÑÂ≠¶‰π†ËÄÖÔºåÊé®Âä®ËÅå‰∏öÂèëÂ±ïÂíåÂàõÊñ∞„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*uKN-KrOhsDhRrAjL","categories":["Technology","Generative AI","Data Science"],"author":"Rifx.Online","tags":["generative","debugging","recommendations","fundamentals","competitive"],"draft":false,"slug":"blog/10-must-learn-skills-to-stay-ahead-in-ai-and-tech-42f4140713b1"},"content":"\n\n\n\n\nÂú®‰∫∫Â∑•Êô∫ËÉΩÂíåÁßëÊäÄËøôÊ†∑‰∏Ä‰∏™Âä®ÊÄÅÁöÑË°å‰∏ö‰∏≠Ôºå‰øùÊåÅÈ¢ÜÂÖàÊÑèÂë≥ÁùÄ‰∏çÊñ≠ÊèêÂçá‰Ω†ÁöÑÊäÄËÉΩ„ÄÇÊó†ËÆ∫‰Ω†ÊòØÂ∏åÊúõÊ∑±ÂÖ•‰∫ÜËß£‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÊÄßËÉΩ„ÄÅÊéåÊè°Êï∞ÊçÆÂàÜÊûêÔºåËøòÊòØÂ∏åÊúõÈÄöËøá‰∫∫Â∑•Êô∫ËÉΩËΩ¨Âèò‰º†ÁªüÈ¢ÜÂüüÂ¶ÇÊ≥ïÂæãÔºåËøô‰∫õËØæÁ®ãÈÉΩÊòØ‰Ω†ÊàêÂäüÁöÑÊç∑ÂæÑ„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á≤æÂøÉÁ≠ñÂàíÁöÑÈ´ò‰ª∑ÂÄºËØæÁ®ãÂàóË°®ÔºåÂèØ‰ª•Âä©Âäõ‰Ω†ÁöÑËÅå‰∏öÂèëÂ±ïÔºåÂπ∂ËÆ©‰Ω†ÂßãÁªàÂ§Ñ‰∫éÂàõÊñ∞ÁöÑÂâçÊ≤ø„ÄÇ\n\n## 1\\. ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁÆÄ‰ªã\n\n* **ËØæÁ®ã**: [ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁÆÄ‰ªã](https://genai.works/courses/introduction-to-generative-ai-english)\n* **Êèê‰æõËÄÖ**: Google Cloud\n* **‰∏∫‰ªÄ‰πàË¶ÅÂèÇÂä†**: ‰∫ÜËß£ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÂü∫Êú¨ÂéüÁêÜÂèäÂÖ∂Â¶Ç‰ΩïÂΩ±ÂìçÂêÑ‰∏™Ë°å‰∏ö„ÄÇÈùûÂ∏∏ÈÄÇÂêàÂ∏åÊúõÊéåÊè°‰∫∫Â∑•Êô∫ËÉΩÂèòÈù©ÊΩúÂäõÁöÑ‰ªª‰Ωï‰∫∫„ÄÇ\n\n## 2\\. Ë∞ÉËØïÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩ\n\n* **ËØæÁ®ã**: [Ë∞ÉËØïÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩ](https://genai.works/courses/evaluating-and-debugging-generative-ai)\n* **Êèê‰æõËÄÖ**: DeepLearning AI\n* **‰∏∫‰ªÄ‰πàÈÄâÊã©ÂÆÉ**: Â≠¶‰π†ÊéíÈô§ÊïÖÈöúÂíå‰ºòÂåñÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåÁ°Æ‰øùÂÆÉ‰ª¨ÂèØÈù†‰∏îÈ´òÊïàÂú∞ËøêË°å„ÄÇÂØπ‰∫éÂ∏åÊúõÂæÆË∞ÉÊ®°Âûã‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁªìÊûúÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∏ì‰∏ö‰∫∫Â£´ËÄåË®ÄÔºåËøôÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑ„ÄÇ\n\n## 3\\. È°∂Á∫ß AI ÊîØÊåÅÁöÑ‰∫ßÂìÅ\n\n* **ËØæÁ®ã**: [È°∂Á∫ß AI ÊîØÊåÅÁöÑ‰∫ßÂìÅ](https://genai.works/courses/top-100-best-selling-products-ai)\n* **Êèê‰æõËÄÖ**: ÂØÜÊ≠áÊ†πÂ§ßÂ≠¶\n* **‰∏∫‰ªÄ‰πàÂèÇÂä†**: ‰∫ÜËß£ AI È©±Âä®‰∫ßÂìÅÁöÑÊúÄÊñ∞Ë∂ãÂäøÔºåÂ∏ÆÂä©ÊÇ®ÁêÜËß£Ë°å‰∏öÁöÑÂèëÂ±ïÊñπÂêë‰ª•ÂèäÂ∏ÇÂú∫‰∏ä‰∏ªÂØºÁöÑÂàõÊñ∞„ÄÇ\n\n## 4\\. Âü∫‰∫éÂêëÈáèÊï∞ÊçÆÂ∫ìÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊé®Ëçê\n\n* **ËØæÁ®ã**: [Âü∫‰∫éÂêëÈáèÊï∞ÊçÆÂ∫ìÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊé®Ëçê](https://genai.works/courses/vector-database-projects-ai-recommendation-systems)\n* **Êèê‰æõËÄÖ**: IBM\n* **‰∏∫‰ªÄ‰πàÂ≠¶‰π†**: ‰ΩøÁî®ÂêëÈáèÊï∞ÊçÆÂ∫ìÂºÄÂèëÊô∫ËÉΩÊé®ËçêÁ≥ªÁªüÔºåËøôÊòØÂú®ÊäÄÊúØ„ÄÅÁîµÂ≠êÂïÜÂä°ÂíåÂ™í‰Ωì‰∏≠ÊûÑÂª∫‰∏™ÊÄßÂåñÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®‰ΩìÈ™åÁöÑÈáçË¶ÅÊäÄËÉΩ„ÄÇ\n\n## 5\\. AI for Software Teams\n\n* **ËØæÁ®ã**: [Âõ¢ÈòüËΩØ‰ª∂Â∑•Á®ã‰∏éAI](https://genai.works/courses/team-software-engineering-with-ai)\n* **Êèê‰æõËÄÖ**: DeepLearning AI\n* **ÈÄâÊã©ÂéüÂõ†**: Êú¨ËØæÁ®ã‰ΩøËΩØ‰ª∂Âõ¢ÈòüËÉΩÂ§üÂà©Áî®AIÂ∑•ÂÖ∑ÊèêÈ´òÂçè‰ΩúÊïàÁéáÔºå‰ΩøÂõ¢ÈòüÂêà‰ΩúÊõ¥Âä†È´òÊïàÔºåÊäÄÊúØÈ°πÁõÆÊõ¥Âä†ÊàêÂäü„ÄÇ\n\n## 6\\. ÊäÄÊúØÊîØÊåÅÂü∫Á°Ä\n\n* **ËØæÁ®ã**: [ÊäÄÊúØÊîØÊåÅÂü∫Á°Ä](https://genai.works/courses/technical-support-fundamentals)\n* **Êèê‰æõËÄÖ**: Google\n* **‰∏∫‰ªÄ‰πàÈÄâÊã©ÂÆÉ**: ÂØπ‰∫éÂ∏åÊúõÂª∫Á´ãÊïÖÈöúÊéíÈô§ÊäÄËÉΩÁöÑ‰ªª‰Ωï‰∫∫Êù•ËØ¥ÔºåËøôÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑËØæÁ®ãÔºå‰∏∫ÊäÄÊúØÊîØÊåÅËßíËâ≤ÂíåITÂü∫Á°ÄËÆæÊñΩÁÆ°ÁêÜÂ•†ÂÆö‰∫ÜÂü∫Á°Ä„ÄÇ\n\n## 7\\. Ê≥ïÂæãÁöÑÊèêÁ§∫Â∑•Á®ã\n\n* **ËØæÁ®ã**: [Ê≥ïÂæãÁöÑ‰∏ì‰∏öÂåñÊèêÁ§∫Â∑•Á®ã](https://genai.works/courses/specialization-prompt-engineering-for-law)\n* **Êèê‰æõËÄÖ**: ËåÉÂæ∑ÊØîÂ∞îÁâπÂ§ßÂ≠¶\n* **‰∏∫‰ªÄ‰πàÈÄâÊã©ÂÆÉ**: Âà©Áî®‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÊèêÁ§∫Â∑•Á®ãÔºåÂèòÈù©Ê≥ïÂæãÈ¢ÜÂüü„ÄÇËØ•ËØæÁ®ãÈùûÂ∏∏ÈÄÇÂêàÂ∏åÊúõÈÄöËøáÊäÄÊúØÂàõÊñ∞ÂíåÁÆÄÂåñÂ∑•‰ΩúÊµÅÁ®ãÁöÑÊ≥ïÂæã‰∏ì‰∏ö‰∫∫Â£´„ÄÇ\n\n## 8\\. ‰ΩøÁî® Excel ÂáÜÂ§áÊï∞ÊçÆËøõË°åÂàÜÊûê\n\n* **ËØæÁ®ã**: [‰ΩøÁî® Excel ÂáÜÂ§áÊï∞ÊçÆËøõË°åÂàÜÊûê](https://genai.works/courses/preparing-data-for-analysis-using-microsoft-excel)\n* **Êèê‰æõËÄÖ**: Microsoft\n* **‰∏∫‰ªÄ‰πàÂ≠¶‰π†**: ÊîπÂñÑÊÇ®ÁöÑÊï∞ÊçÆÂàÜÊûêÂ∑•‰ΩúÊµÅÁ®ãÔºåÊèêÈ´òÊÇ®ÁöÑ Excel ÊäÄËÉΩÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞ÂáÜÂ§áÊï∞ÊçÆÔºåËøôÂØπÂàùÁ∫ßÂíåÈ´òÁ∫ßÊï∞ÊçÆÁßëÂ≠¶ËÅå‰ΩçÈÉΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n## 9\\. ITÂÆâÂÖ®ÔºöÊäµÂæ°Êï∞Â≠óÈªëÊöóËâ∫ÊúØ\n\n* **ËØæÁ®ã**: [ITÂÆâÂÖ®Âü∫Á°Ä](https://lnkd.in/dTY2Vbih)\n* **Êèê‰æõËÄÖ**: Google\n* **‰∏∫‰ªÄ‰πàË¶ÅÂèÇÂä†**: Â≠¶‰π†‰øùÊä§ÊÇ®ÁöÑÊï∞Â≠óËµÑ‰∫ßÂπ∂‰∫ÜËß£ÁΩëÁªúÂÆâÂÖ®ÁöÑÂü∫Á°ÄÁü•ËØÜ„ÄÇÊú¨ËØæÁ®ãÊ∂µÁõñ‰∫ÜÊäµÂæ°ÁΩëÁªúÂ®ÅËÉÅÁöÑÂÖ≥ÈîÆÊäÄËÉΩ„ÄÇ\n\n## 10\\. Python‰∏≠ÁöÑÊï∞ÊçÆÁªìÊûÑ\n\n* **ËØæÁ®ã**: [Python‰∏≠ÁöÑÊï∞ÊçÆÁªìÊûÑ](https://genai.works/courses/data-structures-in-python)\n* **Êèê‰æõËÄÖ**: ÂØÜÊ≠áÊ†πÂ§ßÂ≠¶\n* **‰∏∫‰ªÄ‰πàÂ≠¶‰π†**: ÈÄöËøáÊ∑±ÂÖ•ÁêÜËß£Python‰∏≠ÁöÑÊï∞ÊçÆÁªìÊûÑÊù•Â¢ûÂº∫ÊÇ®ÁöÑÁºñÁ†ÅÊäÄËÉΩÔºåËøôÊòØËΩØ‰ª∂ÂºÄÂèë‰∫∫ÂëòÂíåÊï∞ÊçÆÁßëÂ≠¶ÂÆ∂ÂøÖÂ§áÁöÑÊäÄËÉΩ„ÄÇ\n\n## ‚úîÔ∏è Âä†ÂÖ• \\#BuildwithAI ÈªëÂÆ¢È©¨ÊãâÊùæ 2024\n\n* **ÂèÇ‰∏éÊñπÂºè**: [ÈªëÂÆ¢È©¨ÊãâÊùæÈìæÊé•](https://lnkd.in/dsapprp4)\n* **‰∏∫‰ªÄ‰πàÂä†ÂÖ•**: ÈÄöËøáÊµãËØï‰Ω†ÁöÑÊäÄËÉΩÔºå‰∏éÂøóÂêåÈÅìÂêàÁöÑ‰∫∫Âêà‰ΩúÔºå‰ΩøÁî® AI Ëß£ÂÜ≥ÂÆûÈôÖÈóÆÈ¢ò„ÄÇËøôÊòØÂ∫îÁî®‰Ω†ÊâÄÂ≠¶Áü•ËØÜÂíåÂ±ïÁ§∫‰Ω†‰∏ì‰∏öÊäÄËÉΩÁöÑÂÆåÁæéÊñπÂºè„ÄÇ\n\n## ÁªìËÆ∫\n\n*ÁßëÊäÄÈ¢ÜÂüü‰∏çÊñ≠ÂèëÂ±ïÔºåÊéåÊè°Ëøô‰∫õÂü∫Êú¨ÊäÄËÉΩÂ∞ÜÂ∏ÆÂä©‰Ω†‰øùÊåÅÁ´û‰∫âÂäõ„ÄÇ‰ªé‰∫∫Â∑•Êô∫ËÉΩÂíåÊï∞ÊçÆÁªìÊûÑÁöÑÂü∫Á°ÄËØæÁ®ãÂà∞Ê≥ïÂæãÂ∑•‰Ωú‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁ≠â‰∏ì‰∏öÈ¢ÜÂüüÔºåËøô‰∫õËØæÁ®ãÊ∂µÁõñ‰∫ÜÂπøÊ≥õÁöÑÁü•ËØÜÔºåÂ∞Ü‰∏∫‰Ω†ÁöÑÊú™Êù•ÂÅöÂ•ΩÂáÜÂ§á„ÄÇÁ´ãÂç≥Ê≥®ÂÜåÔºåÊâ©Â±ï‰Ω†ÁöÑ‰∏ì‰∏öÁü•ËØÜÔºåÂºÄÂßãÂú®‰∫∫Â∑•Êô∫ËÉΩÂíåÁßëÊäÄÈ¢ÜÂüü‰∫ßÁîüÂΩ±ÂìçÔºÅ*\n\nÁ•ù‰Ω†Â≠¶‰π†ÊÑâÂø´ÔºåÂàõÊñ∞‰∏çÊñ≠ÔºÅ üöÄ\n\nÂ¶ÇÊûú‰Ω†Â∏åÊúõ‰Ω†ÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∫ßÂìÅË¢´Â±ïÁ§∫ÔºåÊ¨¢ËøéÈÄöËøáÊàë‰ª¨ÁöÑ [**Linkedin È°µÈù¢**](https://www.linkedin.com/company/genai-works/)** ËÅîÁ≥ªÊàë‰ª¨„ÄÇ**\n\nÂÖ≥Ê≥®Êàë‰ª¨ÁöÑÂÆòÊñπ [**Instagram**](https://www.instagram.com/generativeai_official/?igsh=Zjc3NGU5N2ticzZ6)„ÄÅ[**TikTok**](https://www.tiktok.com/@generative_ai_official?_t=8kqDA0pyrC6&_r=1) Âíå [**YouTube**](https://www.youtube.com/@generative.ai.official)ÔºåËé∑ÂèñÊØèÊó•‰∫∫Â∑•Êô∫ËÉΩÂÜÖÂÆπ„ÄÇ\n\nÁé∞Âú®ÊâÄÊúâÂàùÂàõÂÖ¨Âè∏ÂíåÂºÄÂèëËÄÖÈÉΩÂèØ‰ª•ÂÖçË¥πÊ≥®ÂÜå‰ªñ‰ª¨ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®/È°πÁõÆÔºÅ [**https://genai.works/sign\\-up**](https://genai.works/sign-up)\n\nÈòÖËØªÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊñ∞ÈóªÔºåÂπ∂Âú®Êàë‰ª¨ÁöÑ [**ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊØèÊó•ÈÄöËÆØ**](https://newsletter.genai.works/subscribe) ‰∏≠ÊâæÂà∞ÂÆûÁî®ÁöÑÂ§áÂøòÂçï„ÄÇ\n\n**Âø´ÈÄü‰∫ãÂÆûÔºö** 5\\+M ÂÖ≥Ê≥®ËÄÖ \\| 2\\.6M\\+ ÈÄöËÆØËÆ¢ÈòÖËÄÖ„ÄÇÊúÄÂ§ß‰∏îÂ¢ûÈïøÊúÄÂø´ÁöÑ [**LinkedIn ‰∫∫Â∑•Êô∫ËÉΩÁ§æÂå∫**](https://www.linkedin.com/company/genai-works/)ÔºåÁî±Ë°å‰∏öÂÜÖÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∏ìÂÆ∂ÂàõÁ´ãÂíåÊîØÊåÅ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/5-ai-projects-you-can-build-this-weekend-with-node-js-76e0ee51cc72","frontmatter":{"title":"Êú¨Âë®Êú´ÊÇ®ÂèØ‰ª•ÊûÑÂª∫ÁöÑ 5 ‰∏™‰∫∫Â∑•Êô∫ËÉΩÈ°πÁõÆÔºà‰ΩøÁî® Node.jsÔºâ","meta_title":"Êú¨Âë®Êú´ÊÇ®ÂèØ‰ª•ÊûÑÂª∫ÁöÑ 5 ‰∏™‰∫∫Â∑•Êô∫ËÉΩÈ°πÁõÆÔºà‰ΩøÁî® Node.jsÔºâ","description":"Êú¨Êñá‰ªãÁªç‰∫Ü‰∫î‰∏™ÈÄÇÂêàÂàùÂ≠¶ËÄÖÂú®Âë®Êú´‰ΩøÁî® Node.js ÊûÑÂª∫ÁöÑ AI È°πÁõÆÔºåÂåÖÊã¨ÂÆ¢Êà∑ÊîØÊåÅËÅäÂ§©Êú∫Âô®‰∫∫„ÄÅÂõæÂÉèËØÜÂà´Â∫îÁî®„ÄÅÁ§æ‰∫§Â™í‰ΩìÊÉÖÊÑüÂàÜÊûêÂ∑•ÂÖ∑„ÄÅËØ≠Èü≥ÂëΩ‰ª§Â∫îÁî®Á®ãÂ∫èÂíå‰∏™ÊÄßÂåñÁîµÂΩ±Êé®ËçêÁ≥ªÁªü„ÄÇËøô‰∫õÈ°πÁõÆÊó®Âú®ÊèêÂçáÁºñÁ†ÅÊäÄËÉΩÂπ∂‰∫ÜËß£‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆûÈôÖÂ∫îÁî®ÔºåÈÄÇÂêàÂ∏åÊúõ‰∫≤Ëá™Êé¢Á¥¢ AI ÁöÑÂºÄÂèëËÄÖ„ÄÇÊØè‰∏™È°πÁõÆÈÉΩÊèê‰æõ‰∫ÜÊâÄÈúÄÁöÑÊäÄÊúØÊ†àÂíåÂ∑•ÂÖ∑ÔºåÈºìÂä±ÂºÄÂèëËÄÖÊ†πÊçÆ‰∏™‰∫∫ÂàõÊÑèËøõË°åË∞ÉÊï¥„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*x9ezYQZawlG0DRV6","categories":["Programming/Scripting","Natural Language Processing","Computer Vision"],"author":"Rifx.Online","tags":["Node.js","chatbot","image","sentiment","recommender"],"draft":false,"slug":"blog/5-ai-projects-you-can-build-this-weekend-with-node-js-76e0ee51cc72"},"content":"\n5 ‰∏™ÈÄÇÂêàÂú®Âë®Êú´Áî® Node.js ÊûÑÂª∫ÁöÑ‰ª§‰∫∫ÂÖ¥Â•ãÁöÑ AI È°πÁõÆÔºàÈùûÂ∏∏ÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºâ\n\n\n\n‰Ω†ÊòØÂê¶ÂØπÊûÑÂª∫ AI È°πÁõÆÊÑüÂÖ¥Ë∂£Ôºå‰ΩÜÊó∂Èó¥‰∏çÂ§üÔºü\n\nÂè™ÈúÄ Node.js Âíå‰∏Ä‰∏™Âë®Êú´Ôºå‰Ω†Â∞±ÂèØ‰ª•ÊäïÂÖ•Âà∞Âä®ÊâãÂÆûË∑µÁöÑ AI È°πÁõÆ‰∏≠ÔºåËøô‰∫õÈ°πÁõÆÂ∞ÜÊèêÂçá‰Ω†ÁöÑÁºñÁ†ÅÊäÄËÉΩÔºåÂπ∂ËÆ©‰Ω†‰∫ÜËß£‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆûÈôÖÂ∫îÁî®„ÄÇ\n\nËøô‰∫õÈÄÇÂêàÂàùÂ≠¶ËÄÖÁöÑÈ°πÁõÆÂ∞ÜÊåáÂØº‰Ω†ËÆæÁΩÆËÅäÂ§©Êú∫Âô®‰∫∫„ÄÅÂõæÂÉèËØÜÂà´„ÄÅÊÉÖÊÑüÂàÜÊûêÁ≠â„ÄÇ\n\nÊâÄ‰ª•ÔºåÊãøËµ∑‰Ω†ÁöÑÁ¨îËÆ∞Êú¨ÁîµËÑëÔºåÂáÜÂ§áÂ•ΩÁî®Ëøô‰∫î‰∏™‰ª§‰∫∫ÂÖ¥Â•ãÁöÑ AI È°πÁõÆÊù•ÁºñÁ†ÅÂêßÔºÅ\n\n### 1\\. ÂÆ¢Êà∑ÊîØÊåÅËÅäÂ§©Êú∫Âô®‰∫∫ ü§ñ\n\nËÅäÂ§©Êú∫Âô®‰∫∫ÊòØÊé¢Á¥¢Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâÁöÑÁÉ≠Èó®ÊñπÂºèÔºå‰ΩøÁî® Node.jsÔºåÊÇ®ÂèØ‰ª•ËÆæÁΩÆ‰∏Ä‰∏™Âü∫Êú¨ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫Êù•Â§ÑÁêÜÂÆ¢Êà∑Âí®ËØ¢Âπ∂Êèê‰æõÁ≠îÊ°à„ÄÇ\n\n**‰∏∫‰ªÄ‰πàË¶ÅÊûÑÂª∫Ëøô‰∏™È°πÁõÆÔºü**ÂàõÂª∫ËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•ËÆ©ÊÇ®‰∫ÜËß£ NLP ÂíåÂÆûÊó∂ÊúçÂä°Âô®‰∫§‰∫íÁöÑÂü∫Á°ÄÁü•ËØÜÔºåËøôÂú® AI ÂºÄÂèë‰∏≠ÊòØÈùûÂ∏∏ÂÆùË¥µÁöÑÊäÄËÉΩ„ÄÇ\n\n**ÊÇ®ÈúÄË¶ÅÁöÑÔºö**\n\n* **Node.js Âíå Express** Áî®‰∫é [ËÆæÁΩÆÊúçÂä°Âô®](https://expressjs.com/)\n* **Dialogflow**ÔºàÁî± Google Êèê‰æõÔºâÊàñ [**ChatGPT API**](https://platform.openai.com/docs/api-reference/introduction) Áî®‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ\n* **Socket.io** Áî®‰∫éÂÆûÊó∂ËÅäÂ§©ÂäüËÉΩ\n\n## 2. ‰ΩøÁî® Node.js ÊûÑÂª∫ AI È©±Âä®ÁöÑÂõæÂÉèËØÜÂà´Â∫îÁî® \n\nËØ•È°πÁõÆÊ∂âÂèäÂàõÂª∫‰∏Ä‰∏™ÂõæÂÉèËØÜÂà´Â∫îÁî®ÔºåËÉΩÂ§üËØÜÂà´ÁÖßÁâá‰∏≠ÁöÑÁâ©‰Ωì„ÄÅÂä®Áâ©ÊàñÊñáÊú¨„ÄÇ\n\nÈÄöËøá‰ΩøÁî® AI È©±Âä®ÁöÑÂõæÂÉèËØÜÂà´ APIÔºåÊÇ®Â∞ÜËÉΩÂ§üÂú®‰∏çÊ∑±ÂÖ•Â§çÊùÇÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÊÉÖÂÜµ‰∏ãËøõË°åËÆ°ÁÆóÊú∫ËßÜËßâÂ∑•‰Ωú„ÄÇ\n\n**‰∏∫‰ªÄ‰πàË¶ÅÊûÑÂª∫Ëøô‰∏™È°πÁõÆÔºü**ÂõæÂÉèËØÜÂà´ÊòØ AI ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜÔºåËøô‰∏™È°πÁõÆÂ∞Ü‰∏∫ÊÇ®Êèê‰æõËÆ°ÁÆóÊú∫ËßÜËßâÂíå Node.js Êñá‰ª∂Â§ÑÁêÜÁöÑÂÆûË∑µÁªèÈ™å„ÄÇ\n\n**ÊÇ®ÈúÄË¶ÅÂáÜÂ§áÔºö**\n\n* **Node.js Âíå Express** Áî®‰∫éÂêéÁ´ØÊúçÂä°Âô®ËÆæÁΩÆ\n* **Google Cloud Vision** Êàñ [**Microsoft Azure Computer Vision API**](https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/) Áî®‰∫éÂõæÂÉèÂàÜÊûê\n* **Multer** Áî®‰∫é [Â§ÑÁêÜÊñá‰ª∂‰∏ä‰º†](https://www.npmjs.com/package/multer)\n\n```javascript\n// Á§∫‰æã‰ª£Á†Å\nconst express = require('express');\nconst multer = require('multer');\nconst app = express();\nconst upload = multer({ dest: 'uploads/' });\n\napp.post('/upload', upload.single('image'), (req, res) => {\n    res.send('Êñá‰ª∂‰∏ä‰º†ÊàêÂäü');\n});\n\napp.listen(3000, () => {\n    console.log('ÊúçÂä°Âô®Ê≠£Âú®ËøêË°åÂú® http://localhost:3000');\n});\n```\n\n## 3\\. Á§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠êÊÉÖÊÑüÂàÜÊûêÂ∑•ÂÖ∑ üìä\n\nÊÉÖÊÑüÂàÜÊûêÂ∑•ÂÖ∑ÂèØ‰ª•ËÆ©ÊÇ®ÂàÜÊûêÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠ê„ÄÅËØÑËÆ∫ÊàñÂÆ¢Êà∑ÂèçÈ¶àÁöÑËØ≠Ë∞É„ÄÇ\n\n‰ΩøÁî® Node.js ÂíåÊÉÖÊÑüÂàÜÊûê APIÔºåÊÇ®ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™Â∑•ÂÖ∑ÔºåÂ∞ÜÊñáÊú¨ËØÑÂÆö‰∏∫ÁßØÊûÅ„ÄÅÊ∂àÊûÅÊàñ‰∏≠ÊÄß„ÄÇ\n\n**‰∏∫‰ªÄ‰πàË¶ÅÊûÑÂª∫Ëøô‰∏™È°πÁõÆÔºü**Ëøô‰∏™È°πÁõÆÈùûÂ∏∏ÈÄÇÂêàÂ≠¶‰π†Â¶Ç‰ΩïÂ§ÑÁêÜÊñáÊú¨Êï∞ÊçÆÂíåËß£ËØªÊÉÖÊÑüÔºåËøôÂú®Á§æ‰∫§Â™í‰ΩìÁõëÊéßÂíåÂÆ¢Êà∑ÂèçÈ¶àÂàÜÊûê‰∏≠Ë¢´ÂπøÊ≥õ‰ΩøÁî®„ÄÇ\n\n**ÊÇ®ÈúÄË¶ÅÁöÑÂ∑•ÂÖ∑Ôºö**\n\n* **Node.js Âíå Express** Áî®‰∫éÊúçÂä°Âô®ËÆæÁΩÆ\n* [**Natural**](https://github.com/NaturalNode/natural) Êàñ **Aylien API** Áî®‰∫éÊÉÖÊÑüÂàÜÊûê\n* **HTML/CSS** Áî®‰∫éÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑ [Áî®Êà∑ÁïåÈù¢](https://developer.mozilla.org/en-US/docs/Learn/HTML)\n\n## 4\\. ÂºÄÂèë‰∏Ä‰∏™ËØ≠Èü≥ÂëΩ‰ª§Â∫îÁî®Á®ãÂ∫è‰∏éËØ≠Èü≥ËØÜÂà´ üéôÔ∏è\n\nÂàõÂª∫‰∏Ä‰∏™ÁêÜËß£Âü∫Êú¨ËØ≠Èü≥ÂëΩ‰ª§ÁöÑÂ∫îÁî®Á®ãÂ∫èÔºåËøôÊòØËØ≠Èü≥ÊøÄÊ¥ªËÆæÂ§áÊàñÊô∫ËÉΩÂÆ∂Â±ÖÁ≥ªÁªüÁöÑÂü∫Êú¨ÂäüËÉΩ„ÄÇ\n\nÈÄöËøáÁªìÂêà Node.js ÂíåËØ≠Èü≥ËØÜÂà´ APIÔºåÊÇ®ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂ∫îÁî®Á®ãÂ∫èÔºåËØÜÂà´ÂëΩ‰ª§Âπ∂ÂÅöÂá∫ÂìçÂ∫î„ÄÇ\n\n**‰∏∫‰ªÄ‰πàË¶ÅÊûÑÂª∫Ëøô‰∏™È°πÁõÆÔºü**ËØ≠Èü≥ËØÜÂà´ÂèòÂæóË∂äÊù•Ë∂äÊôÆÈÅçÔºåËøô‰∏™È°πÁõÆËÆ©ÊÇ®ÊúâÊú∫‰ºöÊé¢Á¥¢ËØ≠Èü≥ÊéßÂà∂ÁöÑ‰∫§‰∫íÔºåËøôÂú®Áâ©ËÅîÁΩëÂíå‰ª•Êó†ÈöúÁ¢ç‰∏∫ÈáçÁÇπÁöÑÂ∫îÁî®‰∏≠ÈùûÂ∏∏Êúâ‰ª∑ÂÄº„ÄÇ\n\n**ÊÇ®ÈúÄË¶ÅÁöÑÔºö**\n\n* **Node.js Âíå Express** Áî®‰∫é [ÂêéÁ´ØÊúçÂä°Âô®](https://expressjs.com/)\n* [**Web Speech API**](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) Áî®‰∫éÂü∫‰∫éÊµèËßàÂô®ÁöÑËØ≠Èü≥ËØÜÂà´\n* **Socket.io** Áî®‰∫éÂÆûÊó∂ÂëΩ‰ª§ÂìçÂ∫î\n\n## 5\\. ‰ΩøÁî® Node.js ËÆæËÆ°‰∏™ÊÄßÂåñÁîµÂΩ±Êé®ËçêÁ≥ªÁªü üé¨\n\n‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÊÇ®ÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÂÅèÂ•ΩÊûÑÂª∫‰∏™ÊÄßÂåñÁöÑÁîµÂΩ±Êé®ËçêÁ≥ªÁªü„ÄÇËØ•È°πÁõÆ‰ΩøÁî®ÂçèÂêåËøáÊª§Êù•Âª∫ËÆÆ‰∏éÁî®Êà∑È´òÂ∫¶ËØÑ‰ª∑ÁöÑÁîµÂΩ±Áõ∏‰ººÁöÑÁîµÂΩ±„ÄÇ\n\n**‰∏∫‰ªÄ‰πàË¶ÅÊûÑÂª∫Ëøô‰∏™È°πÁõÆÔºü**ÁîµÂΩ±Êé®ËçêÁ≥ªÁªüÊòØÂçèÂêåËøáÊª§ÂíåÊé®ËçêÁÆóÊ≥ïÁöÑÁªù‰Ω≥ÂÖ•Èó®ÔºåËøô‰∫õÁÆóÊ≥ïÂú®ÊµÅÂ™í‰ΩìÊúçÂä°ÂíåÁîµÂ≠êÂïÜÂä°‰∏≠ÂπøÊ≥õ‰ΩøÁî®„ÄÇ\n\n**ÊÇ®ÈúÄË¶ÅÂáÜÂ§áÁöÑÂÜÖÂÆπÔºö**\n\n* **Node.js Âíå Express** Áî®‰∫éÊúçÂä°Âô®ËÆæÁΩÆ\n* **ÂçèÂêåËøáÊª§ÁÆóÊ≥ï**Ôºà‰æãÂ¶ÇÔºå[‰ΩôÂº¶Áõ∏‰ººÂ∫¶](https://en.wikipedia.org/wiki/Cosine_similarity) Êàñ [KNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)ÔºâÁî®‰∫éÊé®ËçêÈÄªËæë\n* **TMDb API** Áî®‰∫éËÆøÈóÆÂ§ßÂûãÁîµÂΩ±Êï∞ÊçÆÂ∫ì\n\n## ÁªìËÆ∫\n\nËøô‰∫î‰∏™ AI È°πÁõÆÈùûÂ∏∏ÈÄÇÂêà‰ªª‰ΩïÂ∏åÊúõÂú®‰∏Ä‰∏™Âë®Êú´‰∫≤Ëá™Êé¢Á¥¢ AI ÁöÑ‰∫∫„ÄÇ\n\n‰ªéÊûÑÂª∫ËÅäÂ§©Êú∫Âô®‰∫∫Âà∞ÂàõÂª∫ÁîµÂΩ±Êé®ËçêÁ≥ªÁªüÔºåÊÇ®Â∞ÜËé∑ÂæóÂü∫Á°ÄÁöÑ AI ÊäÄËÉΩÔºåÂêåÊó∂Â¢ûÂº∫ÊÇ®ÁöÑ Node.js ‰∏ì‰∏öÁü•ËØÜ„ÄÇ\n\nÊØè‰∏™È°πÁõÆÈÉΩÈ´òÂ∫¶ÂèØÂÆöÂà∂ÔºåÂõ†Ê≠§Âú®ÊÇ®ËøõÂ±ïÁöÑËøáÁ®ã‰∏≠ÔºåÊ¨¢ËøéÊ†πÊçÆÊÇ®ÁöÑÁã¨ÁâπÊÉ≥Ê≥ïËøõË°åË∞ÉÊï¥„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öÊïôÁ®ãÂíåËµÑÊ∫êÔºåËØ∑ [ËÆ¢ÈòÖÊàë‰ª¨ÁöÑÈ¢ëÈÅì](https://www.youtube.com/@codemarketi)ÔºåÂπ∂ÂèäÊó∂‰∫ÜËß£ÊúÄÊñ∞ÁöÑ AI Âíå Node.js È°πÁõÆÂàõÊÑè„ÄÇ\n\nÁ•ùÊÇ®ÁºñÁ†ÅÊÑâÂø´ÔºÅ üöÄ\n\n## Áõ∏ÂÖ≥ÂçöÂÆ¢ÊñáÁ´†Êé®Ëçê\n\n* [https://readmedium.com/how\\-ai\\-tools\\-like\\-claude\\-vercel\\-and\\-more\\-are\\-transforming\\-software\\-development\\-b8d79b0de943](https://readmedium.com/how-ai-tools-like-claude-vercel-and-more-are-transforming-software-development-b8d79b0de943)\n* [https://readmedium.com/six\\-ai\\-powered\\-passive\\-income\\-ways\\-to\\-make\\-350\\-per\\-day\\-990d1e334d16](https://readmedium.com/six-ai-powered-passive-income-ways-to-make-350-per-day-990d1e334d16)\n* [https://readmedium.com/as\\-a\\-developer\\-here\\-are\\-5\\-websites\\-youll\\-love\\-e7518b24c85d](https://readmedium.com/as-a-developer-here-are-5-websites-youll-love-e7518b24c85d)\n* [https://readmedium.com/5\\-useful\\-chatgpt\\-tricks\\-thatll\\-blow\\-your\\-mind\\-in\\-2025\\-12e10a81f4d5](https://readmedium.com/5-useful-chatgpt-tricks-thatll-blow-your-mind-in-2025-12e10a81f4d5)\n\n## Áî®ÁÆÄÂçïËã±ËØ≠Ë°®Ëææ üöÄ\n\n*ÊÑüË∞¢ÊÇ®Êàê‰∏∫ [**In Plain English**](https://plainenglish.io/) Á§æÂå∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºÅÂú®ÊÇ®Á¶ªÂºÄ‰πãÂâçÔºö*\n\n* ËØ∑Âä°ÂøÖ **ÁÇπËµû** Âíå **ÂÖ≥Ê≥®** ‰ΩúËÄÖ Ô∏èüëè**Ô∏èÔ∏è**\n* ÂÖ≥Ê≥®Êàë‰ª¨Ôºö [**X**](https://x.com/inPlainEngHQ) \\| [**LinkedIn**](https://www.linkedin.com/company/inplainenglish/) \\| [**YouTube**](https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \\| [**Discord**](https://discord.gg/in-plain-english-709094664682340443) \\| [**Newsletter**](https://newsletter.plainenglish.io/) \\| [**Podcast**](https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)\n* [**Âú® Differ ÂàõÂª∫‰∏Ä‰∏™ÂÖçË¥πÁöÑ AI È©±Âä®ÂçöÂÆ¢„ÄÇ**](https://differ.blog/)\n* Êõ¥Â§öÂÜÖÂÆπËØ∑ËÆøÈóÆ [**PlainEnglish.io**](https://plainenglish.io/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/50-generative-ai-use-cases-across-10-industries-96f621fefac2","frontmatter":{"title":"2024 Âπ¥ 10 ‰∏™Ë°å‰∏öÁöÑ 50 Â§ö‰∏™ÊúÄ‰Ω≥ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®Ê°à‰æã","meta_title":"2024 Âπ¥ 10 ‰∏™Ë°å‰∏öÁöÑ 50 Â§ö‰∏™ÊúÄ‰Ω≥ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®Ê°à‰æã","description":"ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÔºàGen AIÔºâÂú®2024Âπ¥Ë¢´ËßÜ‰∏∫Êé®Âä®ÂêÑË°å‰∏öËΩ¨ÂûãÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºåËÉΩÂ§üËá™Âä®ÂåñÂ§çÊùÇ‰ªªÂä°ÔºåÊèêÂçá‰ºÅ‰∏öÊïàÁéáÂíåÂÆ¢Êà∑‰ΩìÈ™å„ÄÇÊñáÁ´†Êé¢ËÆ®‰∫ÜÂçÅÂ§ßË°å‰∏ö‰∏≠50‰∏™Gen AIÂ∫îÁî®Ê°à‰æãÔºåÊ∂µÁõñËê•ÈîÄ„ÄÅÈîÄÂîÆ„ÄÅ‰∫∫ÂäõËµÑÊ∫ê„ÄÅÂÆ¢Êà∑ÊúçÂä°„ÄÅË¥¢Âä°„ÄÅÁîµÂ≠êÂïÜÂä°„ÄÅÊàøÂú∞‰∫ß„ÄÅÊïôËÇ≤„ÄÅÂà∂ÈÄ†ÂíåÈõ∂ÂîÆÁ≠âÈ¢ÜÂüüÔºåÂº∫Ë∞ÉÂÖ∂Âú®ÂÜÖÂÆπÁîüÊàê„ÄÅ‰∏™ÊÄßÂåñÊúçÂä°ÂíåÊï∞ÊçÆÂàÜÊûêÁ≠âÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇÂÆûÊñΩGen AIÈúÄË¶ÅËØÜÂà´Áî®‰æã„ÄÅÈÄâÊã©Â∑•ÂÖ∑„ÄÅÊï∞ÊçÆÂáÜÂ§á„ÄÅËØïÁÇπËØÑ‰º∞ÂíåÊåÅÁª≠‰ºòÂåñÔºå‰ª•Á°Æ‰øù‰ºÅ‰∏öÂú®Êï∞Â≠óÂåñÁéØÂ¢É‰∏≠‰øùÊåÅÁ´û‰∫âÂäõ„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PeQAto1_Mwovo11vsArGIA.jpeg","categories":["Generative AI","Technology","Marketing"],"author":"Rifx.Online","tags":["Generative","Automation","Personalization","Efficiency","Innovation"],"draft":false,"slug":"blog/50-generative-ai-use-cases-across-10-industries-96f621fefac2"},"content":"\n\n\n\n\nÂ±ïÊúõ2024Âπ¥ÔºåÁîüÊàêÂºèAIÔºàGen AIÔºâÊ≠£Êó•ÁõäË¢´ËßÜ‰∏∫Êé®Âä®ÂêÑË°å‰∏öËΩ¨ÂûãÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇËøô‰∏ÄÊºîÂèòÊ†áÂøóÁùÄ‰º†ÁªüAIÂú®È¢ÑÊµãÂíåÂàÜÊûêËßíËâ≤‰∏äÁöÑËΩ¨ÂèòÔºåËΩ¨ÂêëGen AIÁöÑÂàõÈÄ†ÊÄßËÉΩÂäõÔºå‰Ωø‰ºÅ‰∏öËÉΩÂ§üËá™Âä®ÂåñÂ§çÊùÇ‰ªªÂä°Ôºå‰øÉËøõÂàõÊñ∞ÔºåÂπ∂Êèê‰æõÈ´òÂ∫¶‰∏™ÊÄßÂåñÁöÑÂÆ¢Êà∑‰ΩìÈ™å„ÄÇÊ†πÊçÆÊúÄËøëÁöÑÂàÜÊûêÔºåÊäïËµÑ‰∫éAIÁöÑ‰ºÅ‰∏öÊïàÁéáÊèêÂçáÂèØËææ30%ÔºåËÄåÂÆûÊñΩGen AIÁöÑ‰ºÅ‰∏öÂàôËøõ‰∏ÄÊ≠•‰ºòÂåñ‰∫Ü‰ªñ‰ª¨ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÂíåÊàêÊûú„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ®‰∫ÜÂçÅÂ§ßÈ¢ÜÂÖàË°å‰∏ö‰∏≠50Â§ö‰∏™ÂÖ∑ÊúâÂΩ±ÂìçÂäõÁöÑGen AIÂ∫îÁî®Ê°à‰æãÔºåÈáçÁÇπÂÖ≥Ê≥®Â∏ÆÂä©Â∏åÊúõÂºÄÂèëGen AI‰ª•ÊèêÈ´òËøêËê•ÊïàÁéá„ÄÅÂÆ¢Êà∑ÂèÇ‰∏éÂ∫¶ÂíåÁ´û‰∫â‰ºòÂäøÁöÑ‰ºÅ‰∏ö„ÄÇ\n\n### ‰ªÄ‰πàÊòØÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÔºü\n\n\n> ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊòØ‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºå‰∏ìÊ≥®‰∫éÈÄöËøáÂ≠¶‰π†Áé∞ÊúâÊï∞ÊçÆ‰∏≠ÁöÑÊ®°ÂºèÊù•ÂàõÂª∫Êñ∞ÂÜÖÂÆπ‚Äî‚ÄîÊó†ËÆ∫ÊòØÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ëËøòÊòØËßÜÈ¢ë„ÄÇ‰∏é‰∏ªË¶ÅÂü∫‰∫éÊï∞ÊçÆËøõË°åÈ¢ÑÊµãÊàñÂàÜÁ±ªÁöÑ‰º†Áªü‰∫∫Â∑•Êô∫ËÉΩ‰∏çÂêåÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêÂéüÂàõËæìÂá∫„ÄÇÂÆÉ‰æùËµñ‰∫éÁîüÊàêÂØπÊäóÁΩëÁªúÔºàGANsÔºâÂíåÂü∫‰∫éÂèòÊç¢Âô®ÁöÑÊû∂ÊûÑÔºåÂ¶ÇGPTÔºåËÉΩÂ§üÂÆûÁé∞‰ªéÂàõÊÑèÂÜÖÂÆπÁîü‰∫ßÂà∞ÂÆûÊó∂ÂÆ¢Êà∑‰∫íÂä®ÁöÑÂ§öÁßçÂäüËÉΩ„ÄÇ\n\n### ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂØπÂïÜ‰∏öÁöÑÂÖ≥ÈîÆ‰ºòÂäø\n\n1. **ÂàõÈÄ†Âäõ‰∏éÂàõÊñ∞**ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêË∂ÖË∂ä‰∫∫Á±ªÂàõÈÄ†ÂäõÁöÑÁã¨ÁâπÂÜÖÂÆπÂíåÂàõÊÑèÔºåÊé®Âä®Ëê•ÈîÄ„ÄÅËÆæËÆ°Âíå‰∫ßÂìÅÂºÄÂèëÁ≠âÊñ∞Ê¶ÇÂøµÈ©±Âä®ÊàêÂäüÁöÑË°å‰∏ö„ÄÇ\n2. **ÊèêÂçáÊïàÁéá**ÔºöËá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°ÔºåÂ¶ÇÂÜÖÂÆπÁîüÊàêÂíåÂàùÊ≠•ÂÆ¢Êà∑‰∫íÂä®Ôºå‰Ωø‰ºÅ‰∏öËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊàòÁï•ÊÄßÂíåÈ´òÂ±ÇÊ¨°ÁöÑÂ∑•‰Ωú„ÄÇ\n3. **ÊàêÊú¨ËäÇÁ∫¶**ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂáèÂ∞ëÂØπ‰∫∫Â∑•Âä≥Âä®ÁöÑ‰æùËµñÔºåÂ§ÑÁêÜÂÜÖÂÆπÂàõ‰Ωú„ÄÅÊï∞ÊçÆÂàÜÊûêÂíåÂÆ¢Êà∑ÊúçÂä°Á≠â‰ªªÂä°Ôºå‰ªéËÄåÂÆûÁé∞ÊòæËëóÁöÑËäÇÁúÅ„ÄÇ\n4. **Â§ßËßÑÊ®°‰∏™ÊÄßÂåñ**ÔºöÂà©Áî®Êï∞ÊçÆÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊèê‰æõÂÆöÂà∂Âåñ‰ΩìÈ™åÔºåÊèêÈ´òÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ÂíåÂø†ËØöÂ∫¶„ÄÇ\n5. **Êï∞ÊçÆÈ©±Âä®ÁöÑÊ¥ûÂØü**ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩËÉΩÂ§üÂ§ÑÁêÜÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÊèêÂèñÂèØÊìç‰ΩúÁöÑÊ¥ûÂØüÔºåÊîØÊåÅÂÆûÊó∂ÁöÑÊòéÊô∫ÂÜ≥Á≠ñ„ÄÇ\n\n[**‰∏∫ÂïÜ‰∏öÊûÑÂª∫ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ**](https://www.blockchainappfactory.com/generative-ai-solutions?utm_source=medium&utm_medium=blog&utm_campaign=elavarasan)ÂèØ‰ª•Êé®Âä®ÂàõÊñ∞„ÄÅ‰ºòÂåñËøêËê•ÂíåÊèêÂçáÂÆ¢Êà∑‰ΩìÈ™å„ÄÇÂú®Êó•ÁõäÊï∞Â≠óÂåñÁöÑ‰∏ñÁïå‰∏≠ÔºåËøôÊòØ‰øùÊåÅÁ´û‰∫âÂäõÁöÑÂº∫Â§ßÂ∑•ÂÖ∑„ÄÇ\n\n## 2024Âπ¥ÂçÅÂ§ßË°å‰∏öÁöÑÁîüÊàêÂºèAIÂ∫îÁî®Ê°à‰æã\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TG-tfTwA58FNjHv5so8fXg.png)\n\n### 1\\. Ëê•ÈîÄ\n\nÂú®2024Âπ¥ÔºåËê•ÈîÄ‰∫∫ÂëòÂà©Áî®Gen AI‰ºòÂåñÊ¥ªÂä®„ÄÅ‰∏™ÊÄßÂåñÊé®ÂπøÂíåÂ§ßËßÑÊ®°ÁîüÊàêÂÜÖÂÆπ„ÄÇÈÄöËøáËá™Âä®ÂåñÈáçÂ§çÊÄß‰ªªÂä°ÔºåËê•ÈîÄÂõ¢ÈòüÂèØ‰ª•‰∏ìÊ≥®‰∫éÊàòÁï•ÂíåÂàõÊÑè„ÄÇ\n\n* **ÂÜÖÂÆπ‰ºòÂåñ**ÔºöGen AIÂàÜÊûêÊêúÁ¥¢Ë∂ãÂäøÂíåÂèó‰ºóÂÅèÂ•ΩÔºåÊé®ËçêËÉΩÂ§üÊèêÂçáÂèÇ‰∏éÂ∫¶ÂíåÂèØËßÅÊÄßÁöÑ‰∏ªÈ¢ò„ÄÅÂÖ≥ÈîÆËØçÂíåÊ†ºÂºè„ÄÇ\n* **Â§ßËßÑÊ®°ÂÜÖÂÆπÂàõ‰Ωú**ÔºöËê•ÈîÄÊú∫ÊûÑ‰ΩøÁî®Gen AIÂø´ÈÄüÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÂÜÖÂÆπÁ±ªÂûã‚Äî‚Äî‰ªéÂçöÂÆ¢ÊñáÁ´†Âà∞Á§æ‰∫§Â™í‰ΩìÊõ¥Êñ∞‚Äî‚ÄîÁ°Æ‰øùÂèäÊó∂„ÄÅÈ´òË¥®ÈáèÁöÑËæìÂá∫„ÄÇ\n* **Ëá™Âä®ÂåñÁ§æ‰∫§Â™í‰ΩìÁÆ°ÁêÜ**ÔºöÂ∞èÂûã‰ºÅ‰∏öÂà©Áî®Gen AIÁÆ°ÁêÜÂ∏ñÂ≠ê„ÄÅÂõûÂ∫îÂÆ¢Êà∑ËØ¢ÈóÆÔºåÂπ∂ÂàÜÊûêÂèÇ‰∏éÂ∫¶ÔºåËÄåÊó†ÈúÄÂ∫ûÂ§ßÁöÑÂõ¢Èòü„ÄÇ\n* **‰∏™ÊÄßÂåñÊ¥ªÂä®**ÔºöAIÂØπÂèó‰ºóËøõË°åÁªÜÂàÜÔºåÂà∂‰Ωú‰∏é‰∏™Âà´ÂÆ¢Êà∑ÂÅèÂ•ΩÁõ∏Â•ëÂêàÁöÑÂÆöÂà∂ÁîµÂ≠êÈÇÆ‰ª∂ÂíåÂπøÂëäÂÜÖÂÆπ„ÄÇ\n* **A/BÊµãËØïÂíåÊ¥ªÂä®‰ºòÂåñ**ÔºöAIËá™Âä®ÊµãËØïÂêÑÁßçÂÜÖÂÆπÁâàÊú¨ÔºåÂàÜÊûêÂÆûÊó∂ÁªìÊûúÔºå‰ª•ÂæÆË∞ÉÊ¥ªÂä®‰ª•ËææÂà∞ÊúÄÂ§ßÊïàÊûú„ÄÇ\n\n### 2\\. ÈîÄÂîÆ\n\nÈîÄÂîÆÂõ¢ÈòüÈááÁî® Gen AI Êù•ÁÆÄÂåñÊµÅÁ®ã„ÄÅÁÆ°ÁêÜÊΩúÂú®ÂÆ¢Êà∑Âπ∂Ëá™Âä®ÁîüÊàêÊèêÊ°àÔºå‰ªéËÄåÊèêÈ´òËΩ¨ÂåñÁéáÂíåÊïàÁéá„ÄÇ\n\n* **ÊΩúÂú®ÂÆ¢Êà∑ËØÑÂàÜÂíå‰ºòÂÖàÁ∫ßÊéíÂ∫è**ÔºöAI Ê†πÊçÆËΩ¨ÂåñÂèØËÉΩÊÄß‰∏∫ÊΩúÂú®ÂÆ¢Êà∑ÂàÜÈÖçÂàÜÊï∞ÔºåÂÆûÁé∞ÊúâÈíàÂØπÊÄßÂíåÈ´òÊïàÁöÑÂ§ñÂ±ï„ÄÇ\n* **Ëá™Âä®ÂåñÊèêÊ°àÁîüÊàê**ÔºöGen AI Ê†πÊçÆÂÆ¢Êà∑ÈúÄÊ±ÇËçâÊãüÂÆöÂà∂ÊèêÊ°àÔºåÂáèÂ∞ëÂáÜÂ§áÊó∂Èó¥Âπ∂ÊèêÂçáÊèêÊ°àË¥®Èáè„ÄÇ\n* **ËôöÊãüÈîÄÂîÆÂä©Êâã**ÔºöAI Âú®ÂÆ¢Êà∑‰ºöËÆÆ‰∏≠ÂçèÂä©ÈîÄÂîÆ‰ª£Ë°®ËøõË°åÊó•Á®ãÂÆâÊéí„ÄÅË∑üËøõÂíåÂÆûÊó∂Êï∞ÊçÆÊ¥ûÂØü„ÄÇ\n* **È¢ÑÊµãÊÄßÈîÄÂîÆÂàÜÊûê**ÔºöÈÄöËøáÂàÜÊûêÂéÜÂè≤Êï∞ÊçÆÔºåGen AI È¢ÑÊµãÊú™Êù•Ë∂ãÂäøÂíåÂÆ¢Êà∑Ë°å‰∏∫ÔºåÊîØÊåÅÊï∞ÊçÆÈ©±Âä®ÁöÑÈîÄÂîÆÁ≠ñÁï•„ÄÇ\n* **Áî®‰∫éÂàùÊ≠•Êé•Ëß¶ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫**ÔºöAI ËÅäÂ§©Êú∫Âô®‰∫∫‰∏éÊΩúÂú®ÂÆ¢Êà∑‰∫íÂä®ÔºåÂõûÁ≠îÈóÆÈ¢òÂπ∂ÂØπÊΩúÂú®ÂÆ¢Êà∑ËøõË°åËµÑÊ†ºÂÆ°Ê†∏ÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËΩ¨‰∫§ÁªôÈîÄÂîÆ‰∫∫Âëò„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7yN87soNCoYQe6Qk2oIenw.png)\n\n### 3\\. ‰∫∫ÂäõËµÑÊ∫ê\n\nÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂ∏ÆÂä©‰∫∫ÂäõËµÑÊ∫êÂõ¢ÈòüËá™Âä®Âåñ‰ªªÂä°Ôºå‰ªéÊãõËÅòÂíåÂÖ•ËÅåÂà∞ÂëòÂ∑•ÂèÇ‰∏éÂàÜÊûêÔºåÊúâÂä©‰∫éÊîπÂñÑÊãõËÅòÂíåÁïô‰ªª„ÄÇ\n\n* **Ëá™Âä®ÂåñÁÆÄÂéÜÁ≠õÈÄâ**ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊ†πÊçÆÊåáÂÆöÊ†áÂáÜÂÆ°Êü•ÁÆÄÂéÜÔºåËØÜÂà´ÊúÄ‰Ω≥ÂÄôÈÄâ‰∫∫Ôºå‰ªéËÄåËäÇÁúÅÂàùÊ≠•Á≠õÈÄâÁöÑÊó∂Èó¥„ÄÇ\n* **ÂëòÂ∑•ÂÖ•ËÅåÂçèÂä©**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑ‰ª£ÁêÜÂ∏ÆÂä©Êñ∞ÂëòÂ∑•ÂÆåÊàêÂÖ•ËÅåÔºåÁ°Æ‰øùÈ°∫Âà©Êï¥ÂêàÂπ∂ÂáèÂ∞ë‰∫∫Â∑•‰∫∫ÂäõËµÑÊ∫ê‰ªªÂä°„ÄÇ\n* **ÂèçÈ¶àÊÉÖÊÑüÂàÜÊûê**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂàÜÊûêÂëòÂ∑•ÂèçÈ¶àÔºå‰ª•ËØÜÂà´Ë∂ãÂäøÂπ∂Êé®ËçêÊîπËøõÊé™ÊñΩÔºå‰ªéËÄåÊèêÂçáÂ∑•‰ΩúÊª°ÊÑèÂ∫¶„ÄÇ\n* **‰∏™ÊÄßÂåñÂ≠¶‰π†ÂíåÂèëÂ±ïËÆ°Âàí**Ôºö‰∫∫Â∑•Êô∫ËÉΩËØÑ‰º∞ÊäÄËÉΩÂπ∂Âª∫ËÆÆÈíàÂØπÊÄßÁöÑÂüπËÆ≠Ôºå‰ª•‰øÉËøõÂëòÂ∑•ÊàêÈïø„ÄÇ\n* **Áïô‰ªªÁöÑÂä≥Âä®ÂäõÂàÜÊûê**ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÈ¢ÑÊµãÁ¶ªËÅåÁéáÂπ∂ËØÜÂà´ÂΩ±ÂìçÂõ†Á¥†Ôºå‰Ωø‰∫∫ÂäõËµÑÊ∫êËÉΩÂ§ü‰∏ªÂä®Â∫îÂØπÁïô‰ªªÈóÆÈ¢ò„ÄÇ\n\n### 4\\. ÂÆ¢Êà∑ÊúçÂä°\n\nGen AI ÈÄöËøáÂ§ÑÁêÜÂí®ËØ¢„ÄÅÊèê‰æõÂÆûÊó∂Â∏ÆÂä©ÂíåËá™Âä®ÂåñÁ•®Âä°Ëß£ÂÜ≥Êù•Â¢ûÂº∫ÂÆ¢Êà∑ÊîØÊåÅ„ÄÇ\n\n* **AI È©±Âä®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫**ÔºöGen AI ËÅäÂ§©Êú∫Âô®‰∫∫ÂõûÁ≠îÂ∏∏ËßÑÈóÆÈ¢òÔºåÂáèÂ∞ëÂìçÂ∫îÊó∂Èó¥ÔºåÊèêÈ´òÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ\n* **ÂèçÈ¶àÊÉÖÊÑüÂàÜÊûê**ÔºöAI ÂàÜÊûêËØÑËÆ∫ÂíåÂèçÈ¶à‰ª•ËØÑ‰º∞ÊÉÖÊÑüÔºåÂ∏ÆÂä©‰ºÅ‰∏ö‰∫ÜËß£ÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ\n* **Ëá™Âä®ÂåñÁ•®Âä°‰ºòÂÖàÁ∫ßÊéíÂ∫è**ÔºöGen AI ÂØπÊîØÊåÅÁ•®Âä°ËøõË°åÊéíÂ∫èÔºå‰ºòÂÖàÂ§ÑÁêÜÁ¥ßÊÄ•ÈóÆÈ¢ò‰ª•Âä†Âø´Ëß£ÂÜ≥ÈÄüÂ∫¶„ÄÇ\n* **Áü•ËØÜÂ∫ì‰ºòÂåñ**ÔºöAI Ê†πÊçÆÂ∏∏ËßÅÂí®ËØ¢‰∏çÊñ≠Êõ¥Êñ∞Áü•ËØÜÂ∫ìÔºåÊèêÈ´òËá™Âä©ÊúçÂä°ËÉΩÂäõ„ÄÇ\n* **ËôöÊãüÂÆ¢Êà∑Âä©ÁêÜ**ÔºöAI Ê†πÊçÆÂÆ¢Êà∑ÂÅèÂ•ΩÂíåÂéÜÂè≤Êèê‰æõÈáèË∫´ÂÆöÂà∂ÁöÑÊé®ËçêÔºåÂ¢ûÂº∫ÊîØÊåÅ„ÄÇ\n\n### 5\\. Ë¥¢Âä°‰∏é‰ºöËÆ°\n\nGen AI Ê≠£Âú®ÈÄöËøáËá™Âä®ÂåñÂèëÁ•®Â§ÑÁêÜ„ÄÅË¥¢Âä°È¢ÑÊµãÂíåÁ°Æ‰øùÁ®éÂä°ÂêàËßÑÊù•Èù©Êñ∞Ë¥¢Âä°È¢ÜÂüü„ÄÇ\n\n* **Ëá™Âä®ÂåñÂèëÁ•®Â§ÑÁêÜ**ÔºöAI Â§ÑÁêÜÂèëÁ•®ÔºåÂáèÂ∞ëÈîôËØØÂπ∂Âä†Âø´‰ªòÊ¨æÂë®Êúü„ÄÇ\n* **Ë¥¢Âä°È¢ÑÊµã**ÔºöÈÄöËøáÂàÜÊûêÂéÜÂè≤Êï∞ÊçÆÔºåGen AI ÊèêÈ´ò‰∫ÜÈ¢ÑÁÆóÂíåË¥¢Âä°ËßÑÂàíÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n* **Ë¥πÁî®ÁÆ°ÁêÜ**ÔºöAI ÈÄöËøáÂàÜÁ±ªÂíåÂàÜÊûêË¥πÁî®Êù•ËØÜÂà´ËäÇÁúÅÊàêÊú¨ÁöÑÊú∫‰ºö„ÄÇ\n* **Á®éÂä°ÂêàËßÑ**ÔºöGen AI ÂáÜÂ§áÁ®éÂä°Êñá‰ª∂ÔºåÊúÄÂ∞èÂåñÈîôËØØÂπ∂Á°Æ‰øùÂêàËßÑ„ÄÇ\n* **ÂÆûÊó∂Ë¥¢Âä°Êä•Âëä**ÔºöAI ÁîüÊàêË¥¢Âä°Ê¥ûÂØüÔºå‰øÉËøõÁÅµÊ¥ªÁöÑÊï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ„ÄÇ\n\n### 6\\. ÁîµÂ≠êÂïÜÂä°\n\nÂú®ÁîµÂ≠êÂïÜÂä°‰∏≠ÔºåGen AI ÊèêÂçá‰∫ÜÂÆ¢Êà∑‰ΩìÈ™åÔºå‰ºòÂåñ‰∫ÜÂ∫ìÂ≠òÔºåÂπ∂Ê£ÄÊµãÊ¨∫ËØàÔºåÊîØÊåÅ‰∏öÂä°Â¢ûÈïø„ÄÇ\n\n* **‰∏™ÊÄßÂåñ‰∫ßÂìÅÊé®Ëçê**ÔºöAI ÂàÜÊûêË°å‰∏∫‰ª•Êèê‰æõ‰∏™ÊÄßÂåñÁöÑ‰∫ßÂìÅÂª∫ËÆÆÔºå‰ªéËÄåÊèêÈ´òËΩ¨ÂåñÁéá„ÄÇ\n* **Âä®ÊÄÅÂÆö‰ª∑Á≠ñÁï•**ÔºöAI Ê†πÊçÆÂ∏ÇÂú∫Ë∂ãÂäø„ÄÅÈúÄÊ±ÇÂíåÁ´û‰∫âÂØπÊâãÂÆö‰ª∑ÂÆûÊó∂Ë∞ÉÊï¥‰ª∑Ê†º„ÄÇ\n* **Â∫ìÂ≠òÈ¢ÑÊµã**ÔºöAI È¢ÑÊµãÂ∫ìÂ≠òÈúÄÊ±ÇÔºåÈò≤Ê≠¢ËøáÂâ©ÊàñÁº∫Ë¥ßÔºåÊèêÈ´ò‰æõÂ∫îÈìæÊïàÁéá„ÄÇ\n* **ÂÆ¢Êà∑ÊóÖÁ®ãÊò†Â∞Ñ**ÔºöAI ÂàõÂª∫ËØ¶ÁªÜÁöÑÊóÖÁ®ãÂú∞ÂõæÔºåÊåáÂØºÁîµÂ≠êÂïÜÂä°Á≠ñÁï•„ÄÇ\n* **Ê¨∫ËØàÊ£ÄÊµã‰∏éÈ¢ÑÈò≤**ÔºöGen AI Ê£ÄÊµãÂºÇÂ∏∏‰∫§ÊòìÊ®°ÂºèÔºå‰øùÊä§‰ºÅ‰∏öÂíåÂÆ¢Êà∑ÂÖçÂèóÊ¨∫ËØà„ÄÇ\n\n### 7\\. ÊàøÂú∞‰∫ß\n\nÊàøÂú∞‰∫ßÂÖ¨Âè∏‰ΩøÁî® Gen AI ËøõË°åÁâ©‰∏öËØÑ‰º∞„ÄÅËôöÊãüÂØºËßàÂíåÂÆ¢Êà∑ÂÖ≥Á≥ªÁÆ°ÁêÜ‰ºòÂåñÔºå‰ªéËÄåÁÆÄÂåñÊìç‰ΩúÂπ∂ÊîπÂñÑÂÜ≥Á≠ñ„ÄÇ\n\n* **Ëá™Âä®ÂåñÁâ©‰∏öËØÑ‰º∞**ÔºöAI Ê®°ÂûãÂàÜÊûêÂ∏ÇÂú∫Êï∞ÊçÆÔºåÊèê‰æõÂáÜÁ°ÆÁöÑËØÑ‰º∞‰ª•‰æøÊõ¥Â•ΩÁöÑÂÜ≥Á≠ñ„ÄÇ\n* **ËôöÊãüÁâ©‰∏öÂØºËßà**ÔºöAI ÂàõÂª∫ËôöÊãüÂØºËßàÔºå‰ΩøËøúÁ®ãÊàñÂõΩÈôÖ‰π∞ÂÆ∂ËÉΩÂ§üËÆøÈóÆÊàøÊ∫ê„ÄÇ\n* **È¢ÑÊµãÂ∏ÇÂú∫ÂàÜÊûê**ÔºöAI È¢ÑÊµãÂ∏ÇÂú∫Ë∂ãÂäøÔºå‰∏∫ÊäïËµÑÂÜ≥Á≠ñÊèê‰æõÊåáÂØº„ÄÇ\n* **ÁßüËµÅÁÆ°ÁêÜËá™Âä®Âåñ**ÔºöAI ÁÆ°ÁêÜÁª≠Á∫¶ÂíåÂêàËßÑÔºåÂáèÂ∞ëË°åÊîø‰ªªÂä°„ÄÇ\n* **Â¢ûÂº∫ÂÆ¢Êà∑ÂÖ≥Á≥ªÁÆ°ÁêÜ**ÔºöAI Êèê‰æõÂÆ¢Êà∑ÂÅèÂ•ΩÁöÑÊ¥ûÂØüÔºåÊîØÊåÅÈáèË∫´ÂÆöÂà∂ÁöÑ‰∫íÂä®„ÄÇ\n\n### 8\\. ÊïôËÇ≤\n\nÂú®ÊïôËÇ≤È¢ÜÂüüÔºåÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂÆöÂà∂Â≠¶‰π†‰ΩìÈ™åÔºåÊîØÊåÅËØæÁ®ãÂºÄÂèëÔºåÂπ∂ÂçèÂä©ËØÑÂàÜÔºåÊèêÈ´òÂ≠¶‰π†ÊàêÊûú„ÄÇ\n\n* **‰∏™ÊÄßÂåñÂ≠¶‰π†Ë∑ØÂæÑ**Ôºö‰∫∫Â∑•Êô∫ËÉΩÊ†πÊçÆÂ≠¶ÁîüÁöÑ‰ºòÂäøÂíåÂä£ÂäøÂàõÂª∫ÂÆöÂà∂Â≠¶‰π†Ë∑ØÂæÑ„ÄÇ\n* **Ëá™Âä®ËØÑÂàÜ**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂ∏ÆÂä©ÊïôËÇ≤Â∑•‰ΩúËÄÖËøõË°åËØÑÂàÜÔºå‰ΩøÂ≠¶ÁîüËÉΩÂ§üÊõ¥Âø´Âú∞Ëé∑ÂæóÂèçÈ¶à„ÄÇ\n* **ËØæÁ®ãÊ¥ûÂØü**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂàÜÊûêÁª©ÊïàÊï∞ÊçÆ‰ª•ÊåáÂØºËØæÁ®ãË∞ÉÊï¥„ÄÇ\n* **ËôöÊãüËæÖÂØº**Ôºö‰∫∫Â∑•Êô∫ËÉΩËæÖÂØºÂëòÊèê‰æõËµÑÊ∫êÂπ∂ÂõûÁ≠îÂ≠¶ÁîüËØæÂ§ñÈóÆÈ¢ò„ÄÇ\n* **Â≠¶ÁîüÂèÇ‰∏éÂàÜÊûê**Ôºö‰∫∫Â∑•Êô∫ËÉΩÊ†áËÆ∞ÊúâÈ£éÈô©ÁöÑÂ≠¶ÁîüÔºåÊîØÊåÅÂèäÊó∂Âπ≤È¢Ñ„ÄÇ\n\n### 9\\. Âà∂ÈÄ†\n\nÂà∂ÈÄ†‰∏öÂèóÁõä‰∫éÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÈ¢ÑÊµãÊÄßÁª¥Êä§„ÄÅË¥®ÈáèÊéßÂà∂ÂíåÂä≥Âä®ÂäõË∞ÉÂ∫¶ÔºåÊèêÈ´ò‰∫ÜÊïàÁéáÔºåÂáèÂ∞ë‰∫ÜÂÅúÊú∫Êó∂Èó¥„ÄÇ\n\n* **È¢ÑÊµãÊÄßÁª¥Êä§**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈ¢ÑÊµãËÆæÂ§áÈóÆÈ¢òÔºåÂáèÂ∞ëËÆ°ÂàíÂ§ñÁª¥Êä§ÂíåÂÅúÊú∫Êó∂Èó¥„ÄÇ\n* **‰æõÂ∫îÈìæ‰ºòÂåñ**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈ¢ÑÊµãÂ∫ìÂ≠òÈúÄÊ±ÇÔºåÁÆÄÂåñÊìç‰ΩúÂπ∂Èôç‰ΩéÊàêÊú¨„ÄÇ\n* **Ëá™Âä®ÂåñË¥®ÈáèÊéßÂà∂**ÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂÆûÊó∂Ê£ÄÊµãÁº∫Èô∑ÔºåÊèêÈ´ò‰∫ßÂìÅË¥®Èáè„ÄÇ\n* **Âä≥Âä®ÂäõË∞ÉÂ∫¶**Ôºö‰∫∫Â∑•Êô∫ËÉΩÊ†πÊçÆÈúÄÊ±Ç‰ºòÂåñÁè≠Ê¨°ÔºåÁ°Æ‰øùÈ´òÊïàÁöÑ‰∫∫ÂëòÈÖçÁΩÆ„ÄÇ\n* **‰∫ßÂìÅËÆæËÆ°ËæÖÂä©**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈÄöËøáÂàÜÊûêÂ∏ÇÂú∫ÂíåÊ∂àË¥πËÄÖË∂ãÂäøÊù•ÊåáÂØºËÆæËÆ°ÂÜ≥Á≠ñ„ÄÇ\n\n### 10\\. Èõ∂ÂîÆ\n\nÈõ∂ÂîÆÂïÜÂà©Áî®ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩ‰∫ÜËß£ÂÆ¢Êà∑Ë°å‰∏∫Ôºå‰∏™ÊÄßÂåñÂ∫óÂÜÖ‰ΩìÈ™åÔºåÂπ∂‰ºòÂåñÂ∫ìÂ≠òÔºå‰ªéËÄåÊèêÂçáÊª°ÊÑèÂ∫¶ÂíåÈîÄÂîÆÈ¢ù„ÄÇ\n\n* **ÂÆ¢Êà∑Ë°å‰∏∫ÂàÜÊûê**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂàÜÊûêË¥≠Áâ©‰π†ÊÉØÔºåÊåáÂØºÂïÜÂìÅÈôàÂàóÂíåËê•ÈîÄÂ∑•‰Ωú„ÄÇ\n* **Â¢ûÂº∫ÁöÑÂ∫óÂÜÖ‰ΩìÈ™å**ÔºöÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂ∫îÁî®Á®ãÂ∫èÊèê‰æõ‰∏™ÊÄßÂåñÁöÑÂ∫óÂÜÖÊé®ËçêÂíåÂ∏ÆÂä©„ÄÇ\n* **Â∫ìÂ≠òÈ¢ÑÊµã**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈ¢ÑÊµãÂ∫ìÂ≠òÈúÄÊ±ÇÔºåÈò≤Ê≠¢ËøáÂâ©ÊàñÁº∫Ë¥ß„ÄÇ\n* **Âø†ËØöÂ∫¶ËÆ°Âàí‰ºòÂåñ**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂÆöÂà∂Âø†ËØöÂ∫¶ËÆ°ÂàíÔºåÊèêÈ´òÂèÇ‰∏éÂ∫¶ÂíåÂÆ¢Êà∑ÁïôÂ≠òÁéá„ÄÇ\n* **Ëá™Âä®ÁªìË¥¶**ÔºöÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÁªìË¥¶Á≥ªÁªüÊèêÂçá‰æøÂà©ÊÄßÔºåÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥„ÄÇ\n\n### ‰∏∫ÊÇ®ÁöÑ‰∏öÂä°ÂÆûÊñΩÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ\n\n1. **ËØÜÂà´Áî®‰æã**ÔºöÂÆö‰πâ‰∏é‰∏öÂä°ÁõÆÊ†á‰∏ÄËá¥ÁöÑÂÖ∑‰ΩìÁî®‰æãÔºå‰ªéÂÜÖÂÆπÁîüÊàêÂà∞‰∏™ÊÄßÂåñËê•ÈîÄ„ÄÇ\n2. **ÈÄâÊã©ÂêàÈÄÇÁöÑÂ∑•ÂÖ∑**ÔºöËØÑ‰º∞ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑ÁöÑËÉΩÂäõ„ÄÅÈõÜÊàêÊÄßÂíåÂèØÊâ©Â±ïÊÄßÔºå‰ª•Á°Æ‰øù‰∏é‰∏öÂä°ÈúÄÊ±Ç‰∏ÄËá¥„ÄÇ\n3. **Êï∞ÊçÆÂáÜÂ§áÂíåÊ®°ÂûãËÆ≠ÁªÉ**ÔºöÊ∏ÖÁêÜ„ÄÅÁªÑÁªáÂíåÂáÜÂ§áÊï∞ÊçÆÔºåÂõ†‰∏∫È´òË¥®ÈáèÁöÑÊï∞ÊçÆÂØπÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n4. **ËØïÁÇπÂíåËØÑ‰º∞**ÔºöËøêË°åËØïÁÇπÈ°πÁõÆ‰ª•ÊµãËØïÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁöÑÂΩ±ÂìçÔºåÊî∂ÈõÜËßÅËß£ÔºåÂπ∂Ê†πÊçÆÈúÄË¶Å‰ºòÂåñËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n5. **ÊåÅÁª≠‰ºòÂåñ**ÔºöÁõëÊéßËæìÂá∫ÔºåÊî∂ÈõÜÂèçÈ¶àÔºåÂπ∂ËøõË°åÂøÖË¶ÅÁöÑË∞ÉÊï¥‰ª•ÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ\n6. **ËÄÉËôë‰º¶ÁêÜÂΩ±Âìç**ÔºöÂÆûÊñΩÊîøÁ≠ñ‰ª•Ëß£ÂÜ≥‰º¶ÁêÜÈóÆÈ¢òÔºåÂåÖÊã¨Êï∞ÊçÆÈöêÁßÅ„ÄÅÂÅèËßÅÂíåË¥üË¥£‰ªªÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰ΩøÁî®„ÄÇ\n\n### ÁªìËÆ∫\n\nÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®2024Âπ¥ÊîπÂèòÂêÑË°åÂêÑ‰∏öÔºå‰ªéÂ¢ûÂº∫ÂÆ¢Êà∑ÂèÇ‰∏éÂ∫¶Âà∞Êé®Âä®ÈáëËûç„ÄÅËê•ÈîÄÂíåÂà∂ÈÄ†‰∏öÁöÑÊïàÁéá„ÄÇÂØπ‰∫éÂáÜÂ§áÈááÁî®ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰ºÅ‰∏öÊù•ËØ¥ÔºåÊàòÁï•ÊÄßÁöÑÊñπÊ≥ïÊòØÂÆûÁé∞ÂÖ∂Â•ΩÂ§ÑÁöÑÂÖ≥ÈîÆÔºå‰ªéËá™Âä®ÂåñÊµÅÁ®ãÂà∞‰∏™ÊÄßÂåñÂÆ¢Êà∑‰ΩìÈ™å„ÄÇÈÄöËøáÁêÜËß£ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊΩúÂäõÔºå‰ºÅ‰∏öÂèØ‰ª•Âà©Áî®ÂÖ∂ËÉΩÂäõÔºåÂú®ÂΩì‰ªäÂø´ÈÄüÂèëÂ±ïÁöÑÊï∞Â≠óÁéØÂ¢É‰∏≠‰øùÊåÅÁ´û‰∫âÂäõ„ÄÅÂàõÊñ∞ÊÄßÂíåÈ´òÊïàÊÄß„ÄÇ\n\n## Áî®ÁÆÄÂçïËã±ËØ≠Ë°®Ëææ üöÄ\n\n*ÊÑüË∞¢ÊÇ®Êàê‰∏∫ [**In Plain English**](https://plainenglish.io/) Á§æÂå∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºÅÂú®ÊÇ®Á¶ªÂºÄ‰πãÂâçÔºö*\n\n* ËØ∑Âä°ÂøÖ **ÁÇπËµû** Âíå **ÂÖ≥Ê≥®** ‰ΩúËÄÖ Ô∏èüëè**Ô∏èÔ∏è**\n* ÂÖ≥Ê≥®Êàë‰ª¨Ôºö [**X**](https://x.com/inPlainEngHQ) \\| [**LinkedIn**](https://www.linkedin.com/company/inplainenglish/) \\| [**YouTube**](https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \\| [**Discord**](https://discord.gg/in-plain-english-709094664682340443) \\| [**Newsletter**](https://newsletter.plainenglish.io/) \\| [**Podcast**](https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)\n* [**Âú® Differ ‰∏äÂàõÂª∫‰∏Ä‰∏™ÂÖçË¥πÁöÑ AI È©±Âä®ÂçöÂÆ¢„ÄÇ**](https://differ.blog/)\n* Êõ¥Â§öÂÜÖÂÆπËØ∑ËÆøÈóÆ [**PlainEnglish.io**](https://plainenglish.io/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/a-month-with-cursor-and-claude-dev-my-thoughts-5c41ae0d4467","frontmatter":{"title":"‰∏é Cursor Âíå Claude-Dev ÂÖ±Â∫¶ÁöÑ‰∏Ä‰∏™ÊúàÔºöÊàëÁöÑÊÉ≥Ê≥ï","meta_title":"‰∏é Cursor Âíå Claude-Dev ÂÖ±Â∫¶ÁöÑ‰∏Ä‰∏™ÊúàÔºöÊàëÁöÑÊÉ≥Ê≥ï","description":"ÊàëÊúÄËøë‰∏ÄÁõ¥Âú®‰ΩøÁî®‰∏§‰∏™Êñ∞Â∑•ÂÖ∑ - Cursor Âíå Claude-Dev - Ëøô‰∏§‰∏™Â∑•ÂÖ∑ÈÉΩÂºïËµ∑‰∫ÜÂºÄÂèë‰∫∫ÂëòÁöÑÂπøÊ≥õÂÖ≥Ê≥®‚Ä¶‚Ä¶","date":"2024-11-04T12:32:52.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*i28vK12LJ6XTpSwrKiamwA.png","categories":["Programming","Technology","Generative AI"],"author":"Rifx.Online","tags":["Cursor","Claude-Dev","Cline","autocomplete","debugging"],"draft":false,"slug":"blog/a-month-with-cursor-and-claude-dev-my-thoughts-5c41ae0d4467"},"content":"\n\n\nÊàëÊúÄËøëÂú®‰ΩøÁî®‰∏§‰∏™Êñ∞Â∑•ÂÖ∑‚Äî‚Äî **Cursor** Âíå **Claude\\-Dev** ‚Äî‚ÄîËøô‰∏§‰∏™Â∑•ÂÖ∑Âú®ÂºÄÂèëËÄÖÁ§æÂå∫‰∏≠ÈÉΩÂºïËµ∑‰∫ÜÁõ∏ÂΩìÂ§öÁöÑÂÖ≥Ê≥®„ÄÇÂÆÉ‰ª¨ÈÉΩÊòØÈÄöËøá AI È©±Âä®ÁöÑÂä©ÊâãÊù•ÊèêÈ´òÁºñÁ†ÅÁöÑÈÄüÂ∫¶ÂíåÁõ¥ËßÇÊÄßÔºå‰ΩÜÂÆÉ‰ª¨ÈááÂèñ‰∫Ü‰∏çÂêåÁöÑÊñπÊ≥ïÔºåÂπ∂ÂêÑËá™ÊúâËá™Â∑±ÁöÑ‰ºòÁº∫ÁÇπ„ÄÇÂú®‰ΩøÁî®Ëøô‰∏§ËÄÖÂ§ßÁ∫¶‰∏Ä‰∏™ÊúàÂêéÔºåÊàëËßâÂæóÊòØÊó∂ÂÄôÂùê‰∏ãÊù•ÂèçÊÄù‰∏Ä‰∏ãÂÆÉ‰ª¨ÁöÑ‰ºòÂäøÂíå‰ªçÈúÄÊîπËøõÁöÑÂú∞Êñπ„ÄÇ\n\nËÆ©Êàë‰ª¨‰ªé Cursor ÂºÄÂßã„ÄÇ\n\n## Cursor: ÁÜüÊÇâ‰ΩÜÊõ¥Âø´ÈÄü\n\nCursor ÊòØ VSCode ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåÂ¶ÇÊûú‰Ω†ÂíåÊàë‰∏ÄÊ†∑Â∑≤ÁªèÊòØ VSCode Áî®Êà∑ÔºåÈÇ£‰πà‰ΩøÁî®Ëµ∑Êù•Â∞±ÈùûÂ∏∏ÁÆÄÂçï„ÄÇÊàë‰∏çÈúÄË¶Å‰ªéÂ§¥ÂºÄÂßãÈáçÂª∫ÊàëÁöÑÁéØÂ¢ÉÔºå‰πü‰∏çÈúÄË¶ÅÂ§ÑÁêÜËÆæÁΩÆÈîÆÁªëÂÆö„ÄÇÊâÄÊúâÂú® VSCode ‰∏≠ÊúâÊïàÁöÑÂäüËÉΩÂú® Cursor ‰∏≠ÂºÄÁÆ±Âç≥Áî®‚Äî‚ÄîÊàëÁöÑÊâ©Â±ï„ÄÅËÆæÁΩÆÂíåÈîÆÊò†Â∞ÑÈÉΩÊØ´Êó†ÈóÆÈ¢òÂú∞ËΩ¨ÁßªËøáÊù•„ÄÇËøáÊ∏°Âá†‰πéÊòØÊó†ÁºùÁöÑÔºåÂîØ‰∏ÄÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÂå∫Âà´ÊòØÔºöAI Ëá™Âä®Ë°•ÂÖ®ÈÄüÂ∫¶Êõ¥Âø´„ÄÇÂÆûÈôÖ‰∏äÔºå**Ê†πÊçÆÊàëÁöÑÁªèÈ™å**ÔºåÂÆÉÁöÑÈÄüÂ∫¶Â§ßÁ∫¶ÊòØ GitHub Copilot ÁöÑ 10 ÂÄç„ÄÇ\n\nÁé∞Âú®Ôºå‚Äú10 ÂÄçÊõ¥Âø´‚ÄùÂπ∂‰∏çÊòØÊàë‰ªéÂü∫ÂáÜÊµãËØï‰∏≠ÂæóÂá∫ÁöÑÊï∞Â≠ó‚Äî‚ÄîËøôÂè™ÊòØÊàë‰ΩøÁî®‰∏ÄÊÆµÊó∂Èó¥ÂêéÁöÑÊÑüËßâ„ÄÇÂΩì‰Ω†Âú®ÁºñÂÜô‰ª£Á†ÅÊó∂ÔºåCursor È¢ÑÊµã‰Ω†ÁöÑ‰∏ã‰∏ÄÊ≠•Âä®‰ΩúÊó∂ÔºåÂπ∂‰∏ç‰ºöËÆ©‰Ω†ÊÑüËßâ AI Âú®ÊªûÂêéÊàñËøΩËµ∂„ÄÇÁõ∏ÂèçÔºåÂÆÉ‰∏é‰Ω†ÂêåÊ≠•ÔºåËøôÊúâÂä©‰∫é‰øùÊåÅ‰Ω†ÁöÑÂ∑•‰ΩúÁä∂ÊÄÅ„ÄÇÊàëÊÉäËÆ∂‰∫éÂΩìÊàë‰∏çÂÜçÁ≠âÂæÖ Copilot Ëµ∂‰∏äÊàñÊåâ‰∏âÊ¨° tab ‰ªÖ‰ªÖ‰∏∫‰∫ÜÂæóÂà∞ÊàëÊÉ≥Ë¶ÅÁöÑÂª∫ËÆÆÊó∂ÔºåÊàëÁöÑÁîü‰∫ßÂäõÊèêÂçá‰∫ÜÂ§öÂ∞ë„ÄÇ\n\nCursor ËøòÊúâ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂäüËÉΩÔºåÂÆÉÂµåÂÖ•Âπ∂Á¥¢Âºï‰Ω†ÁöÑÊï¥‰∏™È°πÁõÆÔºå‰ΩøÁêÜËß£Êñá‰ª∂‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇÂΩì‰Ω†Êõ¥Êñ∞‰∏Ä‰∏™Êñá‰ª∂Êó∂ÔºåÁ¥¢Âºï‰πü‰ºöÈöè‰πãÊõ¥Êñ∞ÔºåËøôÊÑèÂë≥ÁùÄ AI ÂØπ‰Ω†ÁöÑ‰ª£Á†ÅÂ∫ìÂêÑ‰∏™ÈÉ®ÂàÜÂ¶Ç‰ΩïÁªìÂêàÊúâ‰∫ÜÊõ¥Â•ΩÁöÑÁêÜËß£„ÄÇÂ¶ÇÊûú‰Ω†Âú®‰∏Ä‰∏™Â§ßÂûã‰ª£Á†ÅÂ∫ì‰∏≠Â∑•‰ΩúÔºåÂ§ö‰∏™Êñá‰ª∂Áõ∏‰∫í‰æùËµñÔºåËøô‰∏ÄÁÇπÈùûÂ∏∏ÊúâÁî®„ÄÇ\n\n## Áº∫ÁÇπ\n\nËØùËôΩÂ¶ÇÊ≠§ÔºåCursor ‰∏≠‰∏Ä‰∫õÊúÄ‰Ω≥ÂäüËÉΩÊòØÈúÄË¶ÅËÆ¢ÈòÖÊâçËÉΩ‰ΩøÁî®ÁöÑ„ÄÇÊàëÈÄöÂ∏∏‰∏çÂèçÂØπ‰∏∫Â¢ûÂä†ÁúüÂÆû‰ª∑ÂÄºÁöÑÂ∑•ÂÖ∑‰ªòË¥πÔºå‰ΩÜÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàëÊúâÁÇπÂ§±ÊúõÔºåÂõ†‰∏∫ÊúÄÊúâË∂£ÁöÑ AI ÂäüËÉΩ‚Äî‚ÄîÂ¶ÇÂ§öÊñá‰ª∂ÁºñËæë‚Äî‚ÄîÂ±û‰∫éÈ´òÁ∫ßÁâàÊú¨„ÄÇÂØπ‰∫é‰∏Ä‰∏™‰ªçÁÑ∂Áõ∏ÂØπËæÉÊñ∞ÁöÑÂ∑•ÂÖ∑ÔºåÊàëÊÉ≥Áü•ÈÅìËøáÊó©ÈôêÂà∂Ëøô‰∫õÂäüËÉΩÊòØÂê¶‰ºöÈôêÂà∂ÂÖ∂ÈááÁî®ÔºåÂ∞§ÂÖ∂ËÄÉËôëÂà∞Â∑≤ÁªèÊúâÂæàÂ§öÂºÄÂèëËÄÖÂú®‰∏∫ GitHub Copilot ‰ªòË¥π„ÄÇ\n\nÊàëÂú®‰ΩøÁî® Cursor Êó∂ÈÅáÂà∞ÁöÑÂè¶‰∏Ä‰∏™ÈóÆÈ¢òÊòØÔºåËôΩÁÑ∂ÂÆÉÂú®Âø´ÈÄü„ÄÅÂ∞èÂûã‰ªªÂä°ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®Â§ÑÁêÜÊõ¥Â§çÊùÇÁöÑÈóÆÈ¢òÊó∂Áº∫‰πèÊàëÊâÄÈúÄÁöÑ‰∏Ä‰∫õÁÅµÊ¥ªÊÄß„ÄÇÂÆÉÈùûÂ∏∏ÈÄÇÂêàÂø´ÈÄü‰ª£Á†ÅÂª∫ËÆÆÂíåÈáçÊûÑÔºå‰ΩÜÂΩìÊàëÈúÄË¶ÅËÉΩÂ§üÂ§ÑÁêÜÊõ¥Â§çÊùÇ‰ªªÂä°ÁöÑÂ∑•ÂÖ∑Êó∂ÔºåÊØîÂ¶ÇËØªÂèñÊó•ÂøóÊàñÊâßË°åÊûÑÂª∫ÂëΩ‰ª§ÔºåÊàëÂèëÁé∞Ëá™Â∑±Âú®ÂØªÊâæÂÖ∂‰ªñÂ∑•ÂÖ∑„ÄÇ\n\n## Claude\\-Dev: ÂºÄÊ∫êÁöÑÈªëÈ©¨\n\nËøôÂ∞±ÊòØ**Claude\\-DevÔºàÁé∞Âú®Áß∞‰∏∫ClineÔºâ**ÁöÑÁî®Ê≠¶‰πãÂú∞„ÄÇClaude\\-DevÊòØ‰∏Ä‰∏™ÈíàÂØπVSCodeÁöÑÂºÄÊ∫êÊâ©Â±ïÔºåËôΩÁÑ∂ÂÆÉÁöÑÊâìÁ£®Á®ãÂ∫¶‰∏çÂ¶ÇCursorÔºå‰ΩÜÂÆÉÊ≠£Âú®ËøÖÈÄüÂèëÂ±ï‚Äî‚ÄîÂú®Êüê‰∫õÊñπÈù¢ÔºåÂÆÉÊõ¥‰∏∫Âº∫Â§ß„ÄÇClaude\\-DevÊúÄÂºï‰∫∫Ê≥®ÁõÆÁöÑÂú∞ÊñπÂú®‰∫éÔºåÂÆÉ‰ºº‰πé‰∏ç‰ªÖ‰ªÖÊòØÊèê‰æõ‰ª£Á†ÅÁâáÊÆµÁöÑÂª∫ËÆÆ„ÄÇÂÆÉÊòØ‰∏Ä‰∏™ÂèØ‰ª•**‰∏éÊÇ®ÁöÑÁéØÂ¢ÉËøõË°åÊõ¥Ê∑±Â±ÇÊ¨°‰∫íÂä®**ÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n‰æãÂ¶ÇÔºåClaude\\-DevÂèØ‰ª•ËØªÂèñÊÇ®ÁöÑÁªàÁ´ØÊó•ÂøóÔºåÁêÜËß£‰ª£Á†ÅÊ£ÄÊü•ÈîôËØØÔºåÁîöËá≥ËøêË°å‰ªªÊÑèÁöÑCLIÂëΩ‰ª§„ÄÇËøôÊÑèÂë≥ÁùÄÂ¶ÇÊûúÊÇ®ÈóÆÂÆÉ‰∏∫‰ªÄ‰πàÊÇ®ÁöÑÈ°πÁõÆÊó†Ê≥ïÊûÑÂª∫ÔºåÂÆÉ‰∏ç‰ªÖ‰ºöÊèê‰æõÂª∫ËÆÆ‚Äî‚ÄîÂÆÉÂÆûÈôÖ‰∏ä‰ºöÂéªÊü•ÁúãÁõ∏ÂÖ≥Êñá‰ª∂ÔºåÂºÑÊ∏ÖÊ•öÊÇ®Ê≠£Âú®‰ΩøÁî®‰ªÄ‰πàÁ±ªÂûãÁöÑÈ°πÁõÆÔºàNode„ÄÅReact„ÄÅPythonÁ≠âÔºâÔºåÂπ∂Â∞ùËØï‰∏∫ÊÇ®ÊûÑÂª∫ÂÆÉ„ÄÇÂ¶ÇÊûúÂá∫Áé∞ÈîôËØØÔºåÂÆÉ‰ºöËØªÂèñÊó•ÂøóÔºåÂ∞ùËØïËØäÊñ≠ÈóÆÈ¢òÔºåÁîöËá≥Âú®ÈúÄË¶ÅÊó∂Â∫îÁî®‰øÆÂ§ç„ÄÇ\n\n‰∏çËøáÔºåÂÆÉÂπ∂‰∏çÂÆåÁæé„ÄÇÊ†πÊçÆÊàëÁöÑÁªèÈ™åÔºåClaude\\-DevÂú®ÁºñËæëÊó∂ÁöÑÈÄüÂ∫¶‰∏çÂ¶ÇCursor„ÄÇËøôÂÖ∂‰∏≠‰∏Ä‰∏™ÂéüÂõ†ÊòØÂÆÉÈáçÂÜôÊï¥‰∏™Êñá‰ª∂ÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖÊõ¥Êñ∞ÈúÄË¶ÅÊõ¥ÊîπÁöÑÈÉ®ÂàÜ„ÄÇËøô‰ºöÂØºËá¥ÈÄüÂ∫¶ÂèòÊÖ¢ÔºåÂ¶ÇÊûúÊÇ®‰∏∫API‰ª§Áâå‰ªòË¥πÔºàÊÇ®ÈúÄË¶ÅÊèê‰æõË¶Å‰ΩøÁî®ÁöÑLLMÁöÑAPIÂØÜÈí•ÔºâÔºåÂÆÉÊ∂àËÄóËøô‰∫õ‰ª§ÁâåÁöÑÈÄüÂ∫¶ÊØîÂ∫îÊúâÁöÑË¶ÅÂø´„ÄÇÊàë‰∏ÄÁõ¥Âú®ËÄÉËôë‰∏∫Ëøô‰∏™È°πÁõÆË¥°ÁåÆ‰ª£Á†ÅÔºå‰øÆÂ§çËøô‰∏™ÈóÆÈ¢òÔºå‰ΩøÂÖ∂ÈÄöËøáËØ∏Â¶Ç`sed`ÁöÑShellÂëΩ‰ª§‰ªÖÊõ¥Êñ∞ÂøÖË¶ÅÁöÑË°å„ÄÇ\n\nÊàëÂèëÁé∞ÁöÑ‰∏Ä‰∏™ÁâπÂà´ÊúâË∂£ÁöÑÂäüËÉΩÊòØClaude\\-DevÂ¶Ç‰Ωï‰ΩøÁî®PuppeteerÊù•ÂèØËßÜÂåñÊµãËØïÂíåÊõ¥Êñ∞ÊÇ®ÁöÑÂâçÁ´Ø„ÄÇÊÇ®ÂèØ‰ª•ÁªôÂÆÉ‰∏ÄÂº†ÁΩëÁ´ôÁöÑÊà™ÂõæÔºåÂÆÉ‰ºöÂ∞ÜÂÖ∂‰∏éÊÇ®ÁöÑÂ∫îÁî®ËøõË°åÊØîËæÉÔºåËø≠‰ª£Áõ¥Âà∞ÊÇ®ÁöÑÂâçÁ´ØËææÂà∞ÊÇ®ÊÉ≥Ë¶ÅÁöÑÂ§ñËßÇ„ÄÇËøô‰∏™ËøáÁ®ãÂπ∂‰∏çÊòØÊúÄÂø´ÁöÑÔºå‰ΩÜÂÆÉÂú®Â§ÑÁêÜCSSÊñπÈù¢Âá∫Â•áÂú∞‰ºòÁßÄ‚Äî‚ÄîÂØπÊàëËÄåË®ÄÔºåËøôÈÄöÂ∏∏ÊòØ‰∏Ä‰∏™ËÄóÊó∂ÁöÑÁéØËäÇ„ÄÇ\n\n## ÂÆÉÁöÑ‰∏çË∂≥‰πãÂ§Ñ\n\nClaude\\-Dev Êó†ÁñëÊòØ‰∏Ä‰∏™ÈÄÇÂêàÈÇ£‰∫õ‰πê‰∫éÂ∞ùËØï‰ªçÁÑ∂Êúâ‰∫õÁ≤óÁ≥ôÂ∑•ÂÖ∑ÁöÑ‰∫∫ÁöÑÂ∑•ÂÖ∑„ÄÇ‰∏éÊÑüËßâÊõ¥ÂÉèÊòØÂ∑≤ÁªèÂáÜÂ§áÂ•ΩÊäïÂÖ•‰ΩøÁî®ÁöÑÁ≤æËá¥‰∫ßÂìÅÁöÑ Cursor ‰∏çÂêåÔºåClaude\\-Dev Êõ¥ÂÉèÊòØ‰∏Ä‰∏™Ê≠£Âú®ÁßØÊûÅÂºÄÂèëÁöÑÂº∫Â§ßÂ∑•ÂÖ∑„ÄÇÂÆÉÂπ∂‰∏çÊÄªÊòØËÉΩÂú®Á¨¨‰∏ÄÊ¨°Â∞±ÂÅöÂà∞Ê≠£Á°ÆÔºåËÄå‰∏îÈÄüÂ∫¶‰πüÊØîÊàëÂ∏åÊúõÁöÑË¶ÅÊÖ¢Ôºå‰ΩÜÂÆÉÂú®‰∏çÊñ≠ÊîπËøõ„ÄÇÂÆÉÊòØÂºÄÊ∫êÁöÑÔºå‰∏ªË¶ÅÁî±‰∏Ä‰∏™‰∫∫ÂºÄÂèëÔºåËøô‰ΩøÂæóÂÆÉÁöÑÂàõÊñ∞ÈÄüÂ∫¶Êõ¥Âä†‰ª§‰∫∫Âç∞Ë±°Ê∑±Âàª„ÄÇ\n\n## ÈÇ£‰πà‰Ω†Â∫îËØ•‰ΩøÁî®Âì™‰∏™Ôºü\n\nÂ¶ÇÊûú‰Ω†Ê≠£Âú®ÂØªÊâæ‰∏Ä‰∏™Á≤æËá¥„ÄÅÂø´ÈÄüÁöÑ‰ΩìÈ™åÔºå‰∏ìÊ≥®‰∫éÈÄüÂ∫¶ÂíåÂø´ÈÄüÂª∫ËÆÆÔºå**Cursor** ÂèØËÉΩÊòØÊõ¥Â•ΩÁöÑÈÄâÊã©„ÄÇÂÆÉÊÑüËßâÁÅµÊïèÔºåËÉΩÂ§ü‰∏éÁé∞ÊúâÁöÑ VSCode ËÆæÁΩÆÈõÜÊàêÔºåÂπ∂‰∏îÂèØ‰ª•‰øùÊåÅ‰Ω†ÁöÑÂ∑•‰ΩúÊµÅ‚Äî‚ÄîÁõ¥Âà∞‰Ω†ÈÅáÂà∞‰ªòË¥πÂ¢ô„ÄÇ‰ΩÜÊòØÂ¶ÇÊûú‰Ω†ÂØπÊ≠§Ê≤°ÊúâÈóÆÈ¢òÔºåÂπ∂‰∏î‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÂäüËÉΩÔºåCursor ÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂ∑•ÂÖ∑„ÄÇ\n\nÂè¶‰∏ÄÊñπÈù¢ÔºåÂ¶ÇÊûú‰Ω†ÊÉ≥Ë¶ÅÁöÑ‰∏ç‰ªÖ‰ªÖÊòØËá™Âä®Ë°•ÂÖ®‰ª£Á†ÅÁöÑÂäüËÉΩ‚Äî‚ÄîËÄåÊòØËÉΩÁúüÊ≠£Â∏ÆÂä©Ë∞ÉËØï„ÄÅÊûÑÂª∫ÂíåËø≠‰ª£‰Ω†ÁöÑÈ°πÁõÆÁöÑ‰∏úË•øÔºå**Claude-Dev** Êõ¥ÈÄÇÂêà‰Ω†„ÄÇÂÆÉÊõ¥ÁÅµÊ¥ªÔºå‰ΩÜ‰πüÁ®çÂæÆÊÖ¢‰∏Ä‰∫õÔºåËæπÁºòÂ§ÑÁêÜÂæó‰∏çÂ§üÁ≤æÁªÜ„ÄÇÂ¶ÇÊûú‰Ω†ÊÑøÊÑèÂ∞ùËØïÂπ∂‰∏îËÉΩÂ§üÂøçÂèó‰∏Ä‰∫õÂ∞èÁº∫Èô∑ÔºåÂÆÉÊèê‰æõÁöÑÂäüËÉΩÊòØ Cursor ÁõÆÂâçÊâÄ‰∏çÂÖ∑Â§áÁöÑ„ÄÇ\n\nÂØπÊàëÊù•ËØ¥Ôºå**Claude-Dev** ËÉúÂá∫Ôºå‰∏ªË¶ÅÊòØÂõ†‰∏∫ÂÆÉ‰∏éÊàëÁöÑÂ∑•‰ΩúÊµÅÁ®ãÁöÑÊ∑±Â∫¶ÈõÜÊàê„ÄÇËÉΩÂ§üËØªÂèñÊó•Âøó„ÄÅËøêË°åÂëΩ‰ª§Âπ∂Ëø≠‰ª£Áõ¥Âà∞ÈóÆÈ¢òËß£ÂÜ≥ÊòØÊó†‰ª∑ÁöÑÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊàëÂ§ÑÁêÜ‰∏çÁÜüÊÇâÁöÑ‰ª£Á†ÅÂ∫ìÊó∂„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂΩìÊàëÈúÄË¶ÅÂø´ÈÄüË°åÂä®ËÄå‰∏çÊÉ≥Á≠âÂæÖ AI Â§ÑÁêÜÂëΩ‰ª§Êó∂ÔºåÊàë‰ªçÁÑ∂‰ºö‰ΩøÁî® **Cursor**„ÄÇ\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nCursor Âíå Claude-Dev ÈÉΩÊèê‰æõ‰∫ÜÁã¨ÁâπÁöÑ‰ºòÂäøÔºåÊàëËÆ§‰∏∫Êàë‰ª¨Âè™ÊòØÂú®Êé¢Á¥¢ AI È©±Âä®ÁöÑÁºñÁ†ÅÂ∑•ÂÖ∑ÊâÄËÉΩÂÅöÁöÑ‰∫ãÊÉÖÁöÑË°®Èù¢„ÄÇËøôÈáåÊúâÂæàÂ§ßÁöÑÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÈöèÁùÄËøô‰∫õÂ∑•ÂÖ∑ÁöÑ‰∏çÊñ≠ÂèëÂ±ï„ÄÇÊàëÂæàÊúüÂæÖÁúãÂà∞ÂÆÉ‰ª¨ÁöÑÊú™Êù•ÔºåÂπ∂Â∞ÜÁªßÁª≠Â∞ùËØïËøô‰∏§ËÄÖÔºåÁúãÁúãÂÆÉ‰ª¨Â¶Ç‰ΩïËûçÂÖ•ÊàëÁöÑÂºÄÂèëÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\nÂêåÊó∂ÔºåÊàëÂª∫ËÆÆ‰Ω†Ëá™Â∑±Â∞ùËØï‰∏Ä‰∏ãËøô‰∏§ËÄÖ„ÄÇÊØè‰∏™Â∑•ÂÖ∑ÈÉΩÊúâÂÖ∂‰ºòÁÇπÔºå‰Ω†ÂèØËÉΩ‰ºöÂèëÁé∞ÂÖ∂‰∏≠‰∏Ä‰∏™Êõ¥ÈÄÇÂêà‰Ω†ÁöÑÈ£éÊ†ºÔºåÂÖ∑‰ΩìÂèñÂÜ≥‰∫é‰Ω†Ê≠£Âú®Â§ÑÁêÜÁöÑÂÜÖÂÆπ„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/a-new-risings-red-star-qwen2-5-is-here-0dffe0fb09ad","frontmatter":{"title":"Êñ∞Â¥õËµ∑Á∫¢ÊòüÔºöQwen2.5Êù•‰∫Ü","meta_title":"Êñ∞Â¥õËµ∑Á∫¢ÊòüÔºöQwen2.5Êù•‰∫Ü","description":"‰∏ÄËµ∑Áî®pythonÂíållama-cppÊµãËØï‰∏Ä‰∏ãÈòøÈáå‰∫ëÊñ∞ÁîüÁöÑÁîüÊàêÂºèAI Qwen2.5","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zU-XtqK2oMLkvscgxavjdw.png","categories":["Programming","Technology","Education"],"author":"Rifx.Online","tags":["Qwen2.5","multimodal","instruction-following","text-generation","multilingual"],"draft":false,"slug":"blog/a-new-risings-red-star-qwen2-5-is-here-0dffe0fb09ad"},"content":"\n\n\n### ‰∏ÄËµ∑ÊµãËØïÊñ∞ÁîüÁöÑÈòøÈáå‰∫ëÁîüÊàêÂºèAI Qwen2.5Ôºå‰ΩøÁî®PythonÂíållama-cpp\n\n\n\nÂú®Ê≤°ÊúâÂ§™Â§öÂÆ£‰º†ÂíåÈ¢ÑÊúüÂÖ¨ÂëäÁöÑÊÉÖÂÜµ‰∏ãÔºåÈòøÈáå‰∫ë‰∫é9Êúà19Êó•ÂèëÂ∏É‰∫Ü‰ªñ‰ª¨ÁöÑÊóóËà∞Ê®°ÂûãÁ≥ªÂàóQwen2.5„ÄÇ\n\nÈòøÈáå‰∫ëÂú®Qwen‰∏äÁöÑÈù©ÂëΩÊÄßÊóÖÁ®ãÂÜçÊ¨°Â±ïÁ§∫‰∫ÜÈÄöËøáÂàõÊñ∞ÁöÑÂº∫Â§ßÈ¢ÜÂØºÂäõ„ÄÇ\n\nÊÄé‰πàÂÅöÁöÑÔºüÂÆÉ‰ª¨Êúâ‰ªÄ‰πàÁâπÂà´‰πãÂ§ÑÔºüÊàë‰ª¨Â∫îËØ•ÊúüÂæÖ‰ªÄ‰πàÔºü\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Êñ∞Ê®°ÂûãÂπ∂Ê£ÄÊü•ÂÖ∂ÊÄßËÉΩ„ÄÇ‰Ωú‰∏∫ÂêéÁª≠ÔºåÂú®‰∏ã‰∏ÄÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®`llama-cpp-python`ÂíåÈáèÂåñÁâàÊú¨ÁöÑqwen2.5‚Äì1.5b-instructÔºåÂØπÊ®°ÂûãËøõË°å13È°πNLP‰ªªÂä°ÁöÑÊµãËØï„ÄÇ\n\n‰∫ãÂÆû‰∏äÔºåÊàëÁõ∏‰ø°Êàë‰ª¨ÊòØÊúÄ‰Ω≥ÁöÑÂü∫ÂáÜÂ∑•ÂÖ∑ÔºåËÉΩÂ§üÂÖ®Èù¢ËØÑ‰º∞‰∏Ä‰∏™Ê®°ÂûãÊòØÂê¶ÈÄÇÂêàÊàë‰ª¨ÔºÅ\n\nÁé∞Âú®ÔºåÊàë‰ª¨Â∞ÜË¶ÜÁõñ‰ª•‰∏ãÂÜÖÂÆπÔºö\n\n\n```python\n- Qwen2.5 family innovation\n- Declared scope, use cases and models\n- Qwen2.5: a party of Foundation models\n- Expanding Reach through Open-Source Contributions\n- Bridging Industries through cutting-edge AI solutions\n- 13 Tasks to prove it worth \n- Future outlook: continued Open-Sourcing\n```\nËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£ÔºÅ \n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OeQ5qeOzCdl8LPJOZZgTIw.png)\n\n## Qwen2.5ÂÆ∂ÊóèÂàõÊñ∞\n\nQwenÊòØÈòøÈáåÂ∑¥Â∑¥ÈõÜÂõ¢QwenÂõ¢ÈòüÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÁ≥ªÂàó„ÄÇÂ∞±Âú®Êò®Â§©ÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ∑≤ÂçáÁ∫ß‰∏∫Qwen2.5„ÄÇ\n\nËØ≠Ë®ÄÊ®°ÂûãÂíåÂ§öÊ®°ÊÄÅÊ®°ÂûãÂùáÂú®Â§ßËßÑÊ®°Â§öËØ≠Ë®ÄÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂Âú®È´òË¥®ÈáèÊï∞ÊçÆ‰∏äËøõË°åÂêéËÆ≠ÁªÉÔºå‰ª•‰∏é‰∫∫Á±ªÂÅèÂ•ΩÂØπÈΩê„ÄÇQwenËÉΩÂ§üËøõË°åËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£„ÄÅÊñáÊú¨ÁîüÊàê„ÄÅËßÜËßâÁêÜËß£„ÄÅÈü≥È¢ëÁêÜËß£„ÄÅÂ∑•ÂÖ∑‰ΩøÁî®„ÄÅËßíËâ≤ÊâÆÊºî„ÄÅ‰Ωú‰∏∫AI‰ª£ÁêÜÁ≠â„ÄÇ\n\nÈöèÁùÄQwen2.5ÁöÑÂèëÂ∏É‰ª•ÂèäÈ¢ùÂ§ñÂºÄÊ∫êÊ®°ÂûãÁöÑÂèëÂ∏ÉÔºåÈòøÈáå‰∫ëÁªßÁª≠‰øùÊåÅÂÖ∂È¢ÜÂØºÂú∞‰ΩçÔºå‰ª•Êª°Ë∂≥‰ºÅ‰∏öÁî®Êà∑Êó•ÁõäÂ¢ûÈïøÁöÑAIÈúÄÊ±Ç„ÄÇËá™ÂéªÂπ¥ÂÖ≠Êúà‰ª•Êù•ÔºåQwenÂÆ∂ÊóèÈÄöËøáModel StudioÂú®Ê∂àË¥πÁîµÂ≠ê„ÄÅÊ±ΩËΩ¶„ÄÅÊ∏∏ÊàèÁ≠âÂ§ö‰∏™Ë°å‰∏öÂê∏Âºï‰∫ÜË∂ÖËøá90,000‰∏™ÈÉ®ÁΩ≤„ÄÇ\n\nQwenËøòÈÄöËøáÂú®Hugging FaceÁ≠âÂπ≥Âè∞‰∏äÊé®Âá∫Êñ∞Ê®°ÂûãÔºåÂ¶ÇQwen1.5‚Äì110BÂíåCodeQwen1.5‚Äì7BÔºåÊâ©Â§ß‰∫ÜÂÖ∂ÂΩ±ÂìçÂäõÔºåÂ±ïÁ§∫‰∫ÜÈòøÈáåÂ∑¥Â∑¥ÂØπÂºÄÊ∫êAIÂºÄÂèëÁöÑÊâøËØ∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*A4pEOgsLK2PAFtiaGQx1Qw.png)\n\n## Â£∞ÊòéÁöÑËåÉÂõ¥„ÄÅÁî®‰æãÂíåÊ®°Âûã\n\nÂú® Qwen2 ÂèëÂ∏ÉÁöÑËøáÂéª‰∏â‰∏™ÊúàÈáåÔºå‰ºóÂ§öÂºÄÂèëËÄÖÂú® Qwen2 ËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä‰∏äÊûÑÂª∫‰∫ÜÊñ∞ÁöÑÊ®°ÂûãÔºå‰∏∫Êï¥‰∏™Á§æÂå∫‰ª•ÂèäÈòøÈáå‰∫ëÊèê‰æõ‰∫ÜÂÆùË¥µÁöÑÂèçÈ¶à„ÄÇ\n\n> Âú®Ê≠§ÊúüÈó¥ÔºåÊàë‰ª¨‰∏ìÊ≥®‰∫éÂàõÂª∫Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥Áü•ËØÜ‰∏∞ÂØåÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇ‰ªäÂ§©ÔºåÊàë‰ª¨ÂæàÈ´òÂÖ¥Âú∞‰ªãÁªç Qwen ÂÆ∂ÊóèÁöÑÊúÄÊñ∞ÊàêÂëòÔºöQwen2.5„ÄÇ\n\n‰ªñ‰ª¨ÁöÑÂ£∞Êòé‰º¥ÈöèÁùÄÊúâÂÖ≥Êñ∞Ê®°ÂûãÂÆ∂ÊóèÁöÑ‰∫ãÂÆûÔºö\n\n* ÂØÜÈõÜÂûã„ÄÅÊòì‰∫é‰ΩøÁî®ÁöÑ‰ªÖËß£Á†ÅÂô®ËØ≠Ë®ÄÊ®°ÂûãÔºåÊèê‰æõ 0.5B„ÄÅ1.5B„ÄÅ3B„ÄÅ7B„ÄÅ14B„ÄÅ32B Âíå 72B Â∞∫ÂØ∏Ôºå‰ª•ÂèäÂü∫Á°ÄÂíåÊåá‰ª§Âèò‰Ωì„ÄÇ\n* Âú®Êàë‰ª¨ÊúÄÊñ∞ÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÊ∂µÁõñÂ§öËææ 18T ÁöÑÊ†áËÆ∞„ÄÇ\n* Âú®ÈÅµÂæ™Êåá‰ª§„ÄÅÁîüÊàêÈïøÊñáÊú¨ÔºàË∂ÖËøá 8K Ê†áËÆ∞Ôºâ„ÄÅÁêÜËß£ÁªìÊûÑÂåñÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåË°®Ê†ºÔºâ‰ª•ÂèäÁîüÊàêÁªìÊûÑÂåñËæìÂá∫ÔºàÂ∞§ÂÖ∂ÊòØ JSONÔºâÊñπÈù¢ÊúâÊòæËëóÊîπËøõ„ÄÇ\n* ÂØπÁ≥ªÁªüÊèêÁ§∫ÁöÑÂ§öÊ†∑ÊÄßÊõ¥ÂÖ∑ÈüßÊÄßÔºåÂ¢ûÂº∫‰∫ÜËßíËâ≤ÊâÆÊºîÂÆûÁé∞ÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊù°‰ª∂ËÆæÁΩÆ„ÄÇ\n* ÊîØÊåÅÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÂèØËææ 128K Ê†áËÆ∞ÔºåÂπ∂‰∏îÂèØ‰ª•ÁîüÊàêÂ§öËææ 8K Ê†áËÆ∞„ÄÇ\n* ÊîØÊåÅË∂ÖËøá 29 ÁßçËØ≠Ë®ÄÁöÑÂ§öËØ≠Ë®ÄÂäüËÉΩÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊ≥ïÊñá„ÄÅË•øÁè≠ÁâôÊñá„ÄÅËë°ËêÑÁâôÊñá„ÄÅÂæ∑Êñá„ÄÅÊÑèÂ§ßÂà©Êñá„ÄÅ‰øÑÊñá„ÄÅÊó•Êñá„ÄÅÈü©Êñá„ÄÅË∂äÂçóÊñá„ÄÅÊ≥∞Êñá„ÄÅÈòøÊãâ‰ºØÊñáÁ≠â„ÄÇ\n\n## Qwen2.5ÔºöÂü∫Á°ÄÊ®°ÂûãÁöÑËÅö‰ºö\n\nÊ†πÊçÆ2024Âπ¥9Êúà19Êó•ÁöÑ[ÂÆòÊñπÂçöÂÆ¢Êñ∞ÈóªÁ®ø](https://qwenlm.github.io/blog/qwen2.5/)ÁöÑÂÖ¨ÂëäÔºö\n\n> ‰ªäÂ§©ÔºåÊàë‰ª¨ÂæàÈ´òÂÖ¥Âú∞‰ªãÁªçQwenÂÆ∂ÊóèÁöÑÊúÄÊñ∞ÊàêÂëòÔºö**Qwen2.5**„ÄÇÊàë‰ª¨ÂÆ£Â∏ÉËøôÂèØËÉΩÊòØÂéÜÂè≤‰∏äÊúÄÂ§ßÁöÑÂºÄÊ∫êÂèëÂ∏ÉÔºÅËÆ©Êàë‰ª¨ÂºÄÂßãÂ∫ÜÁ•ùÂêßÔºÅ\n\n> Êàë‰ª¨ÊúÄÊñ∞ÁöÑÂèëÂ∏ÉÂåÖÂê´‰∫ÜLLMs **Qwen2.5**Ôºå‰ª•ÂèäÁî®‰∫éÁºñÁ†ÅÁöÑ‰∏ìÁî®Ê®°Âûã**Qwen2.5-Coder**ÂíåÁî®‰∫éÊï∞Â≠¶ÁöÑÊ®°Âûã**Qwen2.5-Math**„ÄÇ\n\n‰∏∫‰∫ÜÂ±ïÁ§∫Qwen2.5ÁöÑËÉΩÂäõÔºåÈòøÈáå‰∫ëÂõ¢ÈòüÂØπÂÖ∂ÊúÄÂ§ßÁöÑÂºÄÊ∫êÊ®°Âûã**Qwen2.5‚Äì72B**‚Äî‚Äî‰∏Ä‰∏™72BÂèÇÊï∞ÁöÑÁ®†ÂØÜËß£Á†ÅÂô®ËØ≠Ë®ÄÊ®°Âûã‚Äî‚Äî‰∏éÈ¢ÜÂÖàÁöÑÂºÄÊ∫êÊ®°ÂûãÂ¶ÇLlama-3.1‚Äì70BÂíåMistral-Large-V2ËøõË°å‰∫ÜÂü∫ÂáÜÊµãËØï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-MMFgkkWHa307jNo.jpg)\n\nÊâÄÊúâÂºÄÊîæÊùÉÈáçÊ®°ÂûãÈÉΩÊòØÁ®†ÂØÜÁöÑËß£Á†ÅÂô®ËØ≠Ë®ÄÊ®°ÂûãÔºåÊèê‰æõÂ§öÁßçÂ∞∫ÂØ∏ÔºåÂåÖÊã¨Ôºö\n\n* Qwen2.5Ôºö0.5B„ÄÅ1.5B„ÄÅ3B„ÄÅ7B„ÄÅ14B„ÄÅ32BÂíå72B\n* Qwen2.5-CoderÔºö1.5B„ÄÅ7BÂíå32BÊ≠£Âú®ÂèëÂ∏É‰∏≠\n* Qwen2.5-MathÔºö1.5B„ÄÅ7BÂíå72B„ÄÇ\n\nÈô§‰∫Ü3BÂíå72BÂèò‰ΩìÂ§ñÔºåÊâÄÊúâËøô‰∫õÂºÄÊ∫êÊ®°ÂûãÂùáÂú®Apache 2.0ËÆ∏ÂèØËØÅ‰∏ãÂèëÂ∏É„ÄÇÊÇ®ÂèØ‰ª•Âú®ÂêÑËá™ÁöÑHugging FaceÂ∫ì‰∏≠ÊâæÂà∞ËÆ∏ÂèØËØÅÊñá‰ª∂„ÄÇ\n\n> Èô§‰∫ÜËøô‰∫õÊ®°ÂûãÂ§ñÔºåÊàë‰ª¨ËøòÈÄöËøáModel StudioÊèê‰æõÊóóËà∞ËØ≠Ë®ÄÊ®°ÂûãÁöÑAPIÔºö**Qwen-Plus**Âíå**Qwen-Turbo**ÔºåÊàë‰ª¨ÈºìÂä±ÊÇ®ËøõË°åÊé¢Á¥¢ÔºÅ\n\n‰ΩÜËøôËøò‰∏çÊòØÂÖ®ÈÉ®ÔºÅ\n\n> ‚Ä¶Êàë‰ª¨ËøòÂºÄÊ∫ê‰∫Ü**Qwen2-VL-72B**Ôºå‰∏é‰∏ä‰∏™ÊúàÁöÑÂèëÂ∏ÉÁõ∏ÊØîÔºåÂÖ∑ÊúâÊÄßËÉΩÊèêÂçá„ÄÇ\n\nÂú®**Qwen2.5**ÊñπÈù¢ÔºåÊâÄÊúâËØ≠Ë®ÄÊ®°ÂûãÂùáÂú®Êàë‰ª¨ÊúÄÊñ∞ÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÈ¢ÑËÆ≠ÁªÉÔºåÊ∂µÁõñ‰∫ÜÂ§öËææ**18‰∏á‰∫ø**‰∏™Ê†áËÆ∞„ÄÇ‰∏éQwen2Áõ∏ÊØîÔºåQwen2.5Ëé∑Âæó‰∫ÜÊòæËëóÊõ¥Â§öÁöÑÁü•ËØÜÔºàMMLUÔºö85+ÔºâÔºåÂπ∂Âú®ÁºñÁ†ÅÔºàHumanEval 85+ÔºâÂíåÊï∞Â≠¶ÔºàMATH 80+ÔºâÊñπÈù¢Â§ßÂ§ßÊèêÂçá‰∫ÜËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊñ∞Ê®°ÂûãÂú®Êåá‰ª§Ë∑üÈöè„ÄÅÁîüÊàêÈïøÊñáÊú¨ÔºàË∂ÖËøá8K‰∏™Ê†áËÆ∞Ôºâ„ÄÅÁêÜËß£ÁªìÊûÑÂåñÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåË°®Ê†ºÔºâÂíåÁîüÊàêÁªìÊûÑÂåñËæìÂá∫ÔºåÂ∞§ÂÖ∂ÊòØJSONÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÊîπÂñÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*7c7CIbl-WVjazUeE.jpeg)\n\nQwen2.5Ê®°ÂûãÈÄöÂ∏∏ÂØπÁ≥ªÁªüÊèêÁ§∫ÁöÑÂ§öÊ†∑ÊÄßÊõ¥ÂÖ∑ÈüßÊÄßÔºåÂ¢ûÂº∫‰∫ÜËßíËâ≤ÊâÆÊºîÁöÑÂÆûÊñΩÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊù°‰ª∂ËÆæÁΩÆ„ÄÇ\n\n‰∏éQwen2‰∏ÄÊ†∑ÔºåQwen2.5ËØ≠Ë®ÄÊ®°ÂûãÊîØÊåÅÂ§öËææ**128K**‰∏™Ê†áËÆ∞ÔºåÂπ∂ÂèØ‰ª•ÁîüÊàêÂ§öËææ**8K**‰∏™Ê†áËÆ∞„ÄÇÂÆÉ‰ª¨ËøòÊîØÊåÅË∂ÖËøá**29**ÁßçËØ≠Ë®ÄÁöÑÂ§öËØ≠Ë®ÄÊîØÊåÅÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊ≥ïÊñá„ÄÅË•øÁè≠ÁâôÊñá„ÄÅËë°ËêÑÁâôÊñá„ÄÅÂæ∑Êñá„ÄÅÊÑèÂ§ßÂà©Êñá„ÄÅ‰øÑÊñá„ÄÅÊó•Êñá„ÄÅÈü©Êñá„ÄÅË∂äÂçóÊñá„ÄÅÊ≥∞Êñá„ÄÅÈòøÊãâ‰ºØÊñáÁ≠â„ÄÇ\n\n### Qwen-Coder ÊòØÂÆ∂Êóè‰∏≠ÁöÑÊñ∞ÊàêÂëò\n\n‰∏ì‰∏öÁöÑ‰∏ìÂÆ∂ËØ≠Ë®ÄÊ®°ÂûãÔºåÂç≥ **Qwen2.5-Coder** Áî®‰∫éÁºñÁ†ÅÔºå**Qwen2.5-Math** Áî®‰∫éÊï∞Â≠¶ÔºåÁõ∏ËæÉ‰∫éÂÆÉ‰ª¨ÁöÑÂâçË∫´ CodeQwen1.5 Âíå Qwen2-MathÔºåËøõË°å‰∫ÜÂÆûË¥®ÊÄßÁöÑÂ¢ûÂº∫„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåQwen2.5-Coder Â∑≤Âú® **5.5 ‰∏á‰∫ø** ‰∏™‰∏é‰ª£Á†ÅÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆ‰∏äËøõË°å‰∫ÜËÆ≠ÁªÉÔºå‰ΩøÂæóÂç≥‰ΩøÊòØËæÉÂ∞èÁöÑÁºñÁ†Å‰∏ìÁî®Ê®°Âûã‰πüËÉΩÂ§üÂú®ÁºñÁ†ÅËØÑ‰º∞Âü∫ÂáÜ‰∏ä‰∏éÊõ¥Â§ßÁöÑËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÁ´û‰∫âÂäõÁöÑË°®Áé∞„ÄÇÂêåÊó∂ÔºåQwen2.5-Math ÊîØÊåÅ **‰∏≠Êñá** Âíå **Ëã±Êñá**ÔºåÂπ∂ÁªìÂêà‰∫ÜÂ§öÁßçÊé®ÁêÜÊñπÊ≥ïÔºåÂåÖÊã¨ÊÄùÁª¥ÈìæÔºàCoTÔºâ„ÄÅÊÄùÁª¥Á®ãÂ∫èÔºàPoTÔºâÂíåÂ∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜÔºàTIRÔºâ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Nvk4wrcB0SB4Tt-xbCzO6g.png)\n\n## ÈÄöËøáÂºÄÊ∫êË¥°ÁåÆÊâ©Â§ßÂΩ±ÂìçÂäõ\n\n‰Ωú‰∏∫ÊåÅÁª≠Ëá¥Âäõ‰∫éÊõ¥ÂπøÊ≥õÁ§æÂå∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÈòøÈáå‰∫ëÂú®ÂèëÂ∏ÉÂêÑÁßçËßÑÊ®°ÂíåÂèò‰ΩìÁöÑQwenÊ®°ÂûãÊñπÈù¢ËøàÂá∫‰∫ÜËøõ‰∏ÄÊ≠•ÁöÑÊ≠•‰ºê„ÄÇËøôÂåÖÊã¨Ôºö\n\n1. **Qwen 0.5‰∫øÂèÇÊï∞**ÔºåÈÄÇÁî®‰∫éÊõ¥‰º†ÁªüÂ∫îÁî®ÁöÑÂü∫Á°ÄÁâàÊú¨„ÄÇ2. ‰∏ÄÊ¨æÁ¥ßÂáë‰ΩÜÂº∫Â§ßÁöÑÊ®°ÂûãÔºå‰∏ìÈó®‰∏∫Ê∏∏ÊàèÂºÄÂèëÈáèË∫´ÂÆöÂà∂Ôºö**Qwen-VLÔºàËßÜËßâ-ËØ≠Ë®ÄÔºâ**Ôºå‰ºòÂåñ‰∫ÜÈ´òÊÄßËÉΩ„ÄÇ\n\nËøô‰∫õËøõÂ±ïÂ±ïÁ§∫‰∫ÜÈòøÈáåÂØπÂºÄÊ∫êAIÁöÑÊâøËØ∫Ôºå‰∏ç‰ªÖÂàÜ‰∫´‰∫ÜQwenÁöÑÂü∫Á°ÄÁâàÊú¨ÔºåËøòÊé®Âá∫‰∫ÜÊòæËëóÊîπËøõÂíåÊñ∞Ê®°ÂûãÔºåÁõ¥Êé•ÈíàÂØπ‰ºÅ‰∏öÈúÄÊ±ÇÔºåÂêåÊó∂Â¢ûÂº∫ÂÖ∂Âø´ÈÄüÂàõÊñ∞ÁöÑËÉΩÂäõ„ÄÇ\n\nËøô‰∏é‰∏Ä‰∏™ÊàòÁï•ÊÑøÊôØÂØÜÂàáÁõ∏ÂÖ≥ÔºåÂç≥ÊåÅÁª≠Ë¥°ÁåÆÊÉ†ÂèäÁ§æÂå∫ÊàêÂëòÂíåËá™Ë∫´ÂÆ¢Êà∑ÔºåÂ∏ÆÂä©‰ªñ‰ª¨Âú®Â§ö‰∏™Ë°å‰∏öÂØªÊ±ÇÂàõÊñ∞Â∫îÁî®„ÄÇ\n\n### ÈÄöËøáÂâçÊ≤øÁöÑ‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°àËøûÊé•ÂêÑË°å‰∏ö\n\n‰∏∫‰∫ÜÂ±ïÁ§∫QwenÂú®Áé∞ÂÆûÂú∫ÊôØ‰∏≠ÁöÑÂπøÊ≥õËÉΩÂäõÔºåÈòøÈáå‰∫ë‰∏ÄÁõ¥Â§Ñ‰∫éÂâçÊ≤øÔºö\n\n1. **Â∞èÁ±≥**ÔºöËØ•ÂÖ¨Âè∏Ê≠£Âú®Â∞ÜÈòøÈáåÁöÑÊ®°ÂûãÈõÜÊàêÂà∞‰ªñ‰ª¨ÁöÑAIÂä©ÊâãÂ∞èÁà±‰∏≠ÔºåÂπ∂Âú®Â∞èÁ±≥Êô∫ËÉΩÊâãÊú∫ÂíåÁîµÂä®Ê±ΩËΩ¶‰∏≠ÈÉ®ÁΩ≤Ôºå‰ª•ÈÄöËøáËØ≠Èü≥ÂëΩ‰ª§ÁîüÊàêËΩ¶ËΩΩÂ®±‰πêÂõæÂÉèÁ≠âÂ¢ûÂº∫ÂäüËÉΩ„ÄÇ\n\n2. **ÂÆåÁæé‰∏ñÁïåÊ∏∏Êàè**ÔºöQwenÂú®Ê∏∏ÊàèÂºÄÂèë‰∏≠ÁöÑÈõÜÊàêÂØºËá¥‰∫ÜÂàõÊñ∞Â∫îÁî®ÔºåÂåÖÊã¨ÈÄöËøáÂØπËØùÂä®ÊÄÅÊîπÂñÑÊÉÖËäÇËß£ÊûêÂíåÂÆûÊó∂ÂÜÖÂÆπÁÆ°ÁêÜ„ÄÇ\n\nÈòøÈáå‰∫ëÊ®°Âûã‰∏éÂêÑË°å‰∏ö‰πãÈó¥ÁöÑÂêà‰Ωú‰∏ç‰ªÖ‰∏∞ÂØå‰∫ÜÁî®Êà∑‰ΩìÈ™åÔºåËøò‰øÉËøõ‰∫ÜËøô‰∫õË°å‰∏öÂÜÖÊõ¥Â§ßÁöÑÂ¢ûÈïøÊú∫‰ºöÔºåÊé®Âä®‰∫ÜÊ≤°Êúâ‰∫∫Â∑•Êô∫ËÉΩËøõÊ≠•ÁöÑÊÉÖÂÜµ‰∏ãÊó†Ê≥ïÊÉ≥Ë±°ÁöÑËæπÁïå„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ku8o3rq6PHDE8xcc.png)\n\n## 13 ‰∏™ËØÅÊòéÂÖ∂‰ª∑ÂÄºÁöÑ‰ªªÂä°\n\n1.5 ‰∫øÂèÇÊï∞ÁöÑÊ®°ÂûãÂèØËÉΩÊòØËÄÉËôëÂà∞Â§çÊùÇÊÄß„ÄÅÊèêÁ§∫ÁêÜËß£ÂíåÊé®ÁêÜÈÄüÂ∫¶ÁöÑÊúÄ‰Ω≥Âèò‰Ωì„ÄÇ\n\nÊàëÂ∞ÜÂêëÊÇ®Â±ïÁ§∫Êàë‰ªÖ‰ΩøÁî® `llama-cpp-python` Âíå‰∏Ä‰∏™ÁÆÄÂçïÁªàÁ´ØÁïåÈù¢ËøõË°åÁöÑÂÜÖÈÉ®ÊµãËØï„ÄÇ\n\n‰∏∫Ê≠§ÔºåÊàëÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÊèêÁ§∫ÂàóË°®ÔºåÊ∂µÁõñ‰∫Ü‰∏ÄÁ≥ªÂàóÈÄöÂ∏∏‰ΩøÁî®ÁöÑ‰ªªÂä°ÔºåÊÇ®ÂèØ‰ª•Âú®ÊØèÊ¨°ÁîüÊàêÂêéÂàÜÈÖç‰∏Ä‰∏™ÊäïÁ•®Ôºà‰ªé 0 Âà∞ 5Ôºâ„ÄÇËøôÊòØ‰∏Ä‰∏™‰∏™‰∫∫ÁöÑ‰∫∫Â∑•Âü∫ÂáÜÊµãËØï„ÄÇ\n\n### ÈúÄÊ±Ç\n\nÂàõÂª∫‰∏Ä‰∏™ `venv`ÔºàÈúÄË¶Å Python 3.11+ÔºâÔºöÊàëÂú®ËøêË°å Windows 11 ÁöÑËø∑‰Ω†ÁîµËÑë‰∏äËøõË°å‰∫ÜÊµãËØï„ÄÇ\n\n```python\n## create the virtual environment\npython -m venv venv\n## activate the venv\nvenv\\Scripts\\activate\n## Install the dependencies \npip install llama-cpp-python==0.2.90 tiktoken\n```\nÊàë‰ª¨ÈúÄË¶Å‰ªé[ÂÆòÊñπ Qwen2.5 Hugging Face ‰ªìÂ∫ì](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF)‰∏ãËΩΩ GGUF Êñá‰ª∂„ÄÇÊàë‰ΩøÁî®ÁöÑÊòØ qwen2.5‚Äì1.5b-instruct-q5\\_k\\_m.gguf ÁâàÊú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Fa-qFsx9RTFGZmM-vxCEPQ.png)\n\nÂú®‰∏ªÈ°πÁõÆÁõÆÂΩï‰∏≠‰∏ãËΩΩÊñá‰ª∂„ÄÇÊàë‰ª¨Â∞±ÂáÜÂ§áÂ•Ω‰∫Ü„ÄÇ\n\nËøôÈáåÁî®‰∫éÂàÜÊûêÁöÑ‰ª£Á†ÅÂú®ÊàëÁöÑ GitHub ‰ªìÂ∫ì‰∏≠Ôºö\n\nÊàëÂ∞ÜÂú®‰∏ã‰∏ÄÁØáÊñáÁ´†‰∏≠Ëß£ÈáäÊï¥‰∏™‰ª£Á†ÅÂíåÁªìÊûú„ÄÇ‰øùÊåÅÂÖ≥Ê≥®ÔºÅ\n\n## Êú™Êù•Â±ïÊúõÔºöÊåÅÁª≠ÁöÑÂºÄÊ∫ê\n\nÂú®Êú™Êù•ÁöÑËÆ°Âàí‰∏≠ÔºåÈòøÈáåÂ∑¥Â∑¥ËøòË°®Ëææ‰∫Ü‰ªñ‰ª¨ÂØπÊåÅÁª≠ÂºÄÊ∫êË¥°ÁåÆÁöÑÊâøËØ∫ÔºåÈÄöËøá‰∏∫‰∏çÂêåÈ¢ÜÂüüÁöÑÂºÄÂèëËÄÖÂèëÂ∏ÉÊõ¥Â∞èÁöÑ Qwen Âèò‰Ωì„ÄÇÂÆûÈôÖ‰∏äÔºåÂú® Hugging Face Á§æÂå∫‰∏≠ÔºåËÆ∏Â§öÁî®Êà∑Â∑≤ÂºÄÂßãÈíàÂØπÁâπÂÆö‰ªªÂä°ÂØπ Qwen ËøõË°åÂæÆË∞ÉÔºöÊàëÂú®ÊàëÁöÑ NuExtract ÊñáÁ´†‰∏≠ÂÜô‰∫Ü‰∏Ä‰∏™‰æãÂ≠êÔºöËøô‰∏™Ê®°ÂûãÁ≥ªÂàóÁöÑËæÉÂ∞èÂèò‰ΩìÂü∫‰∫é Qwen2‚Äì0.5bÔºÅ\n\nËøô‰∫õ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂíåÊ®°ÂûãËøõÂ±ïÁöÑÂèëÂ±ïÊòØÂÖÖÂàÜÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ¶Ç **Qwen** Âú®ÂêÑ‰∏™Ë°å‰∏ö‰∏≠ÊΩúÂäõÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇÈöèÁùÄ Model Studio ‰∏≠Âº∫Âä≤ÁöÑÈááÁî®ÁéáÊåÅÁª≠Âø´ÈÄüÂ¢ûÈïøÔºåÊòæÁÑ∂ÈòøÈáå‰∫ë‰∏ç‰ªÖÈÄöËøáÊèê‰æõÂÖàËøõÁöÑÂ∑•ÂÖ∑ËÄå‰∏îÈÄöËøá‰øÉËøõ‰ºÅ‰∏ö‰πãÈó¥ÁöÑÂàõÊñ∞ÔºåÊàê‰∏∫‰∫ÜË°å‰∏öÁöÑÂÖàÈîãÈ¢ÜÂØºËÄÖ„ÄÇ\n\nÂú®ÊàëËøôËæπÔºåÊàëÁöÑÂ±ïÊúõÊòØÁªßÁª≠ÂØπÊñ∞Ê®°ÂûãËøõË°åÂÜÖÈÉ®ÊµãËØïÔºåÁâπÂà´ÊòØÂØπÂ∞èÂûãÊ®°ÂûãÔºåÊúÄÈ´òÂà∞ 3B„ÄÇ\n\nÂú®‰∏ã‰∏ÄÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞Ü‰∏éÊÇ®ÂàÜ‰∫´ÊàëÁöÑÊñπÊ≥ïÔºåÂ¶Ç‰ΩïËøêË°åÊ®°Âûã‰ª•ÂèäÁî®‰∫éÂçÅ‰∏â‰∏™ NLP ‰ªªÂä°ÁöÑÊèêÁ§∫Ê®°Êùø„ÄÇ\n\nÂ∏åÊúõÊÇ®ÂñúÊ¨¢ËøôÁØáÊñáÁ´†„ÄÇÂ¶ÇÊûúËøô‰∏™ÊïÖ‰∫ãÂØπÊÇ®Êúâ‰ª∑ÂÄºÔºåÂπ∂‰∏îÊÇ®ÊÉ≥Á®çÂæÆË°®Á§∫ÊîØÊåÅÔºåÊÇ®ÂèØ‰ª•Ôºö\n\n1. ‰∏∫Ëøô‰∏™ÊïÖ‰∫ãÂ§öÊ¨°ÁÇπËµû\n2. Á™ÅÂá∫Êõ¥ÂÄºÂæóËÆ∞‰ΩèÁöÑÈÉ®ÂàÜÔºàËøôÂ∞Ü‰ΩøÊÇ®Êõ¥ÂÆπÊòìÊâæÂà∞ÂÆÉ‰ª¨Ôºå‰πüËÆ©ÊàëÂÜôÂá∫Êõ¥Â•ΩÁöÑÊñáÁ´†Ôºâ\n3. **Âä†ÂÖ•ÊàëÁöÑ[ÂÆåÂÖ®ÂÖçË¥πÁöÑÊØèÂë® Substack ÈÄöËÆØ](https://thepoorgpuguy.substack.com/about)**\n4. Ê≥®ÂÜå Medium ‰ºöÂëòÔºà$5/ÊúàÂèØÈòÖËØªÊó†Èôê Medium ÊïÖ‰∫ãÔºâ\n5. Âú® Medium ‰∏äÂÖ≥Ê≥®Êàë\n6. ÈòÖËØªÊàëÁöÑÊúÄÊñ∞ÊñáÁ´† <https://medium.com/@fabio.matricardi>\n\nËøôÈáåËøòÊúâÂá†ÁØáÊñáÁ´†Êù•Êª°Ë∂≥ÊÇ®ÁöÑÂ•ΩÂ•áÂøÉÔºö\n\nÊú¨Êñá‰∏≠ÂºïÁî®ÁöÑËµÑÊ∫êÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Du7V61mEX_yIrfmF.png)\n\nÊ≠§ÊïÖ‰∫ãÂèëÂ∏ÉÂú® [Generative AI](https://generativeai.pub/)„ÄÇ‰∏éÊàë‰ª¨Âú® [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) ‰∏äËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥® [Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•‰æøÂèäÊó∂‰∫ÜËß£ÊúÄÊñ∞ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊïÖ‰∫ã„ÄÇ\n\nËÆ¢ÈòÖÊàë‰ª¨ÁöÑ [ÈÄöËÆØ](https://www.generativeaipub.com/) Âíå [YouTube](https://www.youtube.com/@generativeaipub) È¢ëÈÅìÔºåÂèäÊó∂Ëé∑ÂèñÁîüÊàêÂºè AI ÁöÑÊúÄÊñ∞Ê∂àÊÅØÂíåÊõ¥Êñ∞„ÄÇËÆ©Êàë‰ª¨ÂÖ±ÂêåÂ°ëÈÄ† AI ÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pvLAT3it1FkdhVU0.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/a-practical-guide-for-using-autogen-in-software-applications-8799185d27ee","frontmatter":{"title":"Âú®ËΩØ‰ª∂Â∫îÁî®Á®ãÂ∫è‰∏≠‰ΩøÁî® AutoGen ÁöÑÂÆûÁî®ÊåáÂçó","meta_title":"Âú®ËΩØ‰ª∂Â∫îÁî®Á®ãÂ∫è‰∏≠‰ΩøÁî® AutoGen ÁöÑÂÆûÁî®ÊåáÂçó","description":"Êõ¥Êñ∞ÔºöËôΩÁÑ∂ËøôÁØáÊñáÁ´†ÊòØ 4 ‰∏™ÊúàÂâçÂÜôÁöÑÔºå‰ΩÜ AutoGen Â∑≤ÁªèÂèëÁîü‰∫ÜÂæàÂ§ßÂèòÂåñ„ÄÇÂØπ‰∫éÂèØËÉΩÂ≠òÂú®ÁöÑ‰∏Ä‰∫õÈóÆÈ¢òÔºåÊàëÊ∑±Ë°®Ê≠âÊÑè‚Ä¶‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*yrraWH6aGNnbx8p-wfQ1OQ.jpeg","categories":["Programming","Chatbots","Autonomous Systems"],"author":"Rifx.Online","tags":["AutoGen","multi-agent","LLMs","customization","collaboration"],"draft":false,"slug":"blog/a-practical-guide-for-using-autogen-in-software-applications-8799185d27ee"},"content":"\n\n\n\n\n*Êõ¥Êñ∞ÔºöËôΩÁÑ∂ËøôÁØáÊñáÁ´†ÊòØÂú®Âõõ‰∏™ÊúàÂâçÂÜôÁöÑÔºå‰ΩÜ AutoGen Ëá™ÈÇ£Êó∂‰ª•Êù•ÂèòÂåñÂæàÂ§ß„ÄÇÂØπ‰∫éÊàë‰ª£Á†ÅÁ§∫‰æã‰∏≠ÂèØËÉΩËøáÊó∂ÁöÑÂÜÖÂÆπÔºåÊàëÊ∑±ÊÑüÊ≠âÊÑè„ÄÇ*\n\nÂ¶ÇÊûúÊÇ®ÊÉ≥‰∫ÜËß£ AutoGenÔºåÂèØ‰ª•Êü•Áúã [ÊñáÊ°£](https://microsoft.github.io/autogen/)„ÄÅ[Colab Á¨îËÆ∞Êú¨](https://microsoft.github.io/autogen/docs/Examples) Âíå [ÂçöÂÆ¢](https://microsoft.github.io/autogen/blog)„ÄÇÈùûÂ∏∏ÊÑüË∞¢ AutoGen Âõ¢ÈòüÂà∂‰Ωú‰∫Ü‰∏Ä‰∏™‰ª§‰∫∫ÊÉäÂèπÁöÑ‰∫ßÂìÅÔºå‰ΩÜËÄÅÂÆûËØ¥‚Äî‚ÄîÂú®ÈòÖËØª‰∫Ü‰ªñ‰ª¨ÁöÑÊâÄÊúâÂÜÖÂÆπÂêéÔºåÊàë‰ªçÁÑ∂‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÂú®ÁªàÁ´ØÊàñ Jupyter Notebook ‰πãÂ§ñ‰ΩøÁî® AutoGen„ÄÇ\n\nÊú¨ÊñáËØïÂõæÈÄöËøáÊèê‰æõ‰∏Ä‰∫õÊúâÁî®ÁöÑÊñπÊ≥ïÊù•Â∏ÆÂä©Â°´Ë°•Ëøô‰∏™Á©∫ÁôΩÔºå‰Ωø AutoGen Âú®ËΩØ‰ª∂Â∫îÁî®‰∏≠ÂèëÊå•‰ΩúÁî®„ÄÇ‰ª•‰∏ãÊòØÊàëÂ∞ÜË¶ÅËÆ®ËÆ∫ÁöÑ‰∏ªÈ¢òÔºö\n\n1. ‰ª£ÁêÜ‰∏ç‰ªÖÈôê‰∫éÈÄöËøáÁªàÁ´ØËøõË°åÈÄö‰ø°\n2. Ê≥®ÂÜåËá™ÂÆö‰πâÂõûÂ§ç\n3. Â¶Ç‰Ωï‰ª•ÁúüÂÆûÁöÑÊñπÂºèÂ∞ÜÁúüÂÆû‰∫∫Á±ªÁ∫≥ÂÖ•ÂØπËØù\n4. ÊÇ®ÂèØ‰ª•ÔºàÂπ∂‰∏îÂ∫îËØ•ÔºâËá™ÂÆö‰πâË∞ÅÊù•ÂèëË®Ä\n5. ÊÇ®‰∏çÂøÖ‰ΩøÁî® OpenAI\n6. ÂèØ‰ª•‰ΩøÁî®ÂáΩÊï∞ËÄå‰∏çÊòØÊâßË°å‰ª£Á†Å\n7. Â∞Ü‰ª£ÁêÜÁî®‰∫éÁªÑÁªáÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂØπËØù\n\nÊúÄÂêéÔºåÊàëÂ∞ÜËÆ®ËÆ∫‰∏∫‰ªÄ‰πàÊàëËÆ§‰∏∫ÊÇ®Â∫îËØ•È¶ñÂÖà‰ΩøÁî® AutoGen„ÄÇËÆ©Êàë‰ª¨ÂºÄÂßãÂêßÔºÅ\n\n## ‰ª£ÁêÜ‰∏ç‰ªÖÈôê‰∫éÈÄöËøáÁªàÁ´ØËøõË°åÈÄö‰ø°\n\nÊÇ®‰ºöÁúãÂà∞ÊØè‰∏™‰∫∫ÈÉΩ‰ΩøÁî®ÁªàÁ´ØÊàñ Jupyter Notebook ÊºîÁ§∫ AutoGen„ÄÇËøôÂØπ‰∫éÊºîÁ§∫Êù•ËØ¥‰∏çÈîôÔºå‰ΩÜËøô‰∫õ‰ª£ÁêÜ‰πãÈó¥ËøòÊúâÂÖ∂‰ªñ‰∫§ÊµÅÊñπÂºè„ÄÇ\n\nAutoGen Êúâ 2 ‰∏™Âü∫Êú¨Á±ªÔºö[`UserProxyAg`ent](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/user_proxy_agent.py) Âíå [`AssistantAg`ent](https://github.com/microsoft/autogen/blob/main/autogen/agentchat/assistant_agent.py)„ÄÇÂÆÉ‰ª¨ÁªßÊâø‰∫Ü [`ConversableAg`ent](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py) Á±ªÔºå‰ªÖ‰∏∫Âü∫Á±ªÊèê‰æõ‰∫ÜÂá†‰∏™‰∏çÂêåÁöÑÈªòËÆ§ÂèÇÊï∞„ÄÇ\n\nÂΩìÊÇ®ÁúãÂà∞Ëøô‰∏™ÁªèÂÖ∏‰ª£Á†ÅÁ§∫‰æãÊó∂Ôºö\n\n```python\nassistant = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config\n)\nuser_proxy = autogen.UserProxyAgent(name=\"user_proxy\")\nawait user_proxy.a_initiate_chat(\n    assistant,\n    message=\"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\",\n)\n```\nÂèëÁîüÁöÑ‰∫ãÊÉÖÊòØ `UserProxyAgent` Â∞ÜË∞ÉÁî®ÂÖ∂Ëá™Â∑±ÁöÑ `send` ÊñπÊ≥ïÔºåËøôÂ∞ÜË∞ÉÁî® `AssistantAgent` ÁöÑ [`rece`ive](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L514) ÊñπÊ≥ïÔºå‰º†ÈÄíÂéüÂßãÊ∂àÊÅØ„ÄÇÂ∞ÜÁîüÊàêÂõûÂ§çÔºàÁ®çÂêé‰ºöËØ¶ÁªÜËØ¥ÊòéÔºâÔºåÁÑ∂Âêé `AssistantAgent` Â∞ÜË∞ÉÁî®ÂÖ∂ [`s`end](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L351) ÊñπÊ≥ïÔºåËøôÂ∞ÜË∞ÉÁî® `UserProxyAgent` ÁöÑ `receive` ÊñπÊ≥ïÔºå‰æùÊ≠§Á±ªÊé®ÔºåÁõ¥Âà∞ `UserProxyAgent` Á°ÆÂÆöÂØπËØùÂ∑≤ÁªàÊ≠¢ÔºàÂèØ‰ª•ÈÄöËøá `is_termination_msg` ÂèÇÊï∞Ëá™ÂÆö‰πâÔºâ„ÄÇ\n\nÊàëÁ¨¨‰∏ÄÊ¨°‚ÄúÊÅçÁÑ∂Â§ßÊÇü‚ÄùÁöÑÊó∂ÂàªÊòØÂΩìÊàëÊÑèËØÜÂà∞Ëøô‰∫õ‰ª£ÁêÜÊòØÁ±ªÊó∂ÔºåÊàëÂèØ‰ª•ÂàõÂª∫Ëá™Â∑±ÁöÑËá™ÂÆö‰πâ‰ª£ÁêÜÁ±ªÔºåÁªßÊâø AutoGen ÁöÑ UserProxy/Assistant/Conversable Agent Á±ªÔºåÂπ∂ÈáçÂÜô‰ªª‰ΩïÈªòËÆ§ÊñπÊ≥ï„ÄÇËøô‰ΩøÂæó AutoGen ÈùûÂ∏∏ÂèØÊâ©Â±ï„ÄÇ\n\nÊàëÊúâ‰∏Ä‰∏™Áî®‰æãÔºåÈúÄË¶Å‰∏Ä‰∏™ÂèØ‰ª•ÈÄöËøáÁΩëÁ´ô‰∏äÁöÑËÅäÂ§© UI ËæìÂÖ•Ê∂àÊÅØÁöÑ‰∫∫ÔºàÁî± `UserProxyAgent` ‰ª£ÁêÜÔºâÔºåÊàëÂ∏åÊúõ `AssistantAgent` ËÉΩÂú® UI ‰∏≠ÂõûÂ§çËØ•ËÅäÂ§©ÔºåÂπ∂ËÉΩÂ§üÊé•Êî∂Êõ¥Â§öÊù•Ëá™‰∫∫Á±ªÁî®Êà∑ÁöÑÊ∂àÊÅØÔºåÂ∞±Â•ΩÂÉè‰∫∫Á±ªÂè™ÊòØËøô‰∏™ AutoGen ÂØπËØù‰∏≠ÁöÑÂè¶‰∏Ä‰∏™‰ª£ÁêÜ„ÄÇ\n\nÊàëÂèØ‰ª•ÈáçÂÜô `send` Âíå `receive` ÊñπÊ≥ïÔºàÊàñ `a_send` Âíå `a_receive`ÔºâÔºåÂπ∂ÈÄöËøá http„ÄÅwebsockets Á≠âËøõË°åÊé®ÈÄÅ/ÊãâÂèñ„ÄÇÊàëÂ∞ùËØï‰∫ÜËøô‰∏™ÔºåÂÆÉÂºÄÂßãÂ∑•‰ΩúÔºå‰ΩÜÊó†Ê≥ïÊâ©Â±ï„ÄÇËÆ©Êàë‰ª¨Â≠¶‰π†‰∏ÄÁßçÊõ¥Â•ΩÁöÑÊñπÊ≥ï„ÄÇ\n\n## Ê≥®ÂÜåËá™ÂÆö‰πâÂõûÂ§ç\n\nAutoGen ÂÖ∑Êúâ‰∏Ä‰∏™Êèí‰ª∂Á≥ªÁªüÔºåÂèØ‰ª•ËÆ©ÊÇ®Ëá™ÂÆö‰πâ‰ª£ÁêÜÁîüÊàêÂõûÂ§çÁöÑÊñπÂºè„ÄÇÊàë‰ª¨‰π†ÊÉØÁúãÂà∞ÁöÑÁ§∫‰æãÊòØ AutoGen Êü•ËØ¢ OpenAI Ëé∑ÂèñÁ≠îÊ°àÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫ÂõûÂ§çÔºå‰ΩÜÊÇ®‰πüÂèØ‰ª•ÊèíÂÖ•Ëá™Â∑±ÁöÑÊñπÊ≥ïÔºö\n\n```python\nclass WeatherAgent(AssistantAgent):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, llm_config=False, **kwargs)\n        self.register_reply(Agent, WeatherAgent.get_weather)\n\n    async def get_weather(\n        self,\n        messages: List[Dict] = [],\n        sender=None,\n        config=None,\n    ) -> Tuple[bool, Union[str, Dict, None]]:\n        last_message = messages[-1][\"content\"]\n        result = await fetch_weather(last_message)\n        return True, result\n\nasync def fetch_weather(city: str) -> str:\n    async with httpx.AsyncClient() as client:\n        result = await client.post(\n            WEATHER_API_URL,\n            json={\"city\": question},\n        )\n        return result.json()\n\nweather_assistant = WeatherAgent(name=\"weather_assistant\")\nuser_proxy = autogen.UserProxyAgent(name=\"user_proxy\")\nawait user_proxy.a_initiate_chat(assistant, message=\"Lehi\")\nprint(weather_assistant.last_message)\n```\nÂú®ËøôÈáåÔºå`register_reply` Â∞ÜÊèíÂÖ•ÊàëÁöÑËá™ÂÆö‰πâÊñπÊ≥ï‰ª•Ëé∑ÂèñÂõûÂ§çÔºåÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåËØ•ÊñπÊ≥ïÂ∞ÜÊîæÂú® `position=0`ÔºåËøôÊÑèÂë≥ÁùÄÂÆÉÂ∞ÜÊòØÂ∞ùËØïÁöÑÁ¨¨‰∏Ä‰∏™ÂõûÂ§çÊñπÊ≥ï„ÄÇËØ•ÊñπÊ≥ïÂ∫îËøîÂõû‰∏Ä‰∏™ÂÖÉÁªÑÔºåÂÖ∂‰∏≠Á¨¨‰∏Ä‰∏™È°πÁõÆÊòØ‰∏Ä‰∏™Â∏ÉÂ∞îÂÄºÔºåÊåáÁ§∫Ê≠§ÂõûÂ§çÊòØÂê¶‰∏∫Â∫î‰ΩøÁî®ÁöÑÂõûÂ§çÔºåÊàñËÄÖÊòØÂê¶Â∫îÂ∞ùËØï‰∏ã‰∏Ä‰∏™Ê≥®ÂÜåÁöÑÂõûÂ§çÔºà‰æãÂ¶ÇÔºå‰ΩøÁî® OpenAI ÁöÑÂÜÖÁΩÆÂõûÂ§çÁîüÊàê ‚Äî ÂÆåÊï¥È°∫Â∫èËØ∑ÂèÇËßÅ [Ê≠§Â§Ñ](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L145-L153)Ôºâ„ÄÇ\n\n‰∫ÜËß£ [`register_reply`](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L155) ‰ΩøÊÇ®ËÉΩÂ§üËá™ÂÆö‰πâÂõûÂ§çÁöÑÊ£ÄÁ¥¢ÊñπÂºèÔºåÂÖÅËÆ∏ÊÇ®ÂêØÂä®Â≠êÂ§ö‰ª£ÁêÜÂØπËØùÁ≠â„ÄÇ\n\n## Â¶Ç‰Ωï‰ª•ÁúüÂÆûÁöÑÊñπÂºèÂ∞ÜÁúüÂÆû‰∫∫Á±ªÁ∫≥ÂÖ•ÂØπËØù\n\nËøôÈáåÊúâ‰∏ÄÁßçÊñπÊ≥ïÔºö\n\n```python\n## user makes a POST /query { \"message\": \"What's the weather?\" }\n\n@query_blueprint.route(\"/query\", methods=[\"POST\"])\nasync def post_query():\n  message = request.form.get(\"message\")\n\n  assistant = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config\n    system_message=\"\"\"You're a helpful assistant.\n    If you need more info, ask the user for anything missing.\"\"\"\n  )\n  user_proxy = autogen.UserProxyAgent(\n    name=\"user_proxy\",\n    human_input_mode=\"NEVER\",\n    code_execution_config=False,\n    is_termination_msg=lambda message: True # Always True\n  )\n  weather_assistant = WeatherAgent(\n    name=\"weather_assistant\",\n    system_message=\"\"\"You're a helpful assistant to get the weather.\n    You fetch weather information, then return it.\"\"\"\n  )\n\n  groupchat = autogen.GroupChat(\n    agents=[assistant, user_proxy, weather_assistant],\n    messages=[]\n  )\n  manager = autogen.GroupChatManager(\n    name=\"Manager\",\n    groupchat=groupchat,\n    llm_config=llm_config,\n  )\n\n  await user_proxy.a_initiate_chat(manager, message=message)\n\n  return groupchat.messages[-1]\n```\nËøôÈáåÂèëÁîü‰∫Ü‰ªÄ‰πàÔºü\n\n1. ÊØèÂΩì‰∏ÄÊù°Ê∂àÊÅØÂèëÈÄÅÂà∞ `user_proxy` Êó∂ÔºåÂØπËØùÂ∞ÜÁªìÊùüÔºàÊàë‰ª¨Á®çÂêé‰ºöÊÅ¢Â§çÂÆÉÔºâ„ÄÇËøôÊ†∑ÂÅöÁöÑÂéüÂõ†ÊòØ‰ªÄ‰πàÔºüËøôÊÑèÂë≥ÁùÄ `user_proxy` ÂÆûÈôÖ‰∏äÂèØ‰ª•‰ª£ÁêÜÁî®Êà∑„ÄÇÂÆÉ‰∏ç‰ºöÂ∞ùËØïÂõûÁ≠îÔºåËÄåÊòØ‰ºöÁªìÊùüÂΩìÂâçÁöÑÂØπËØùÊµÅÁ®ãÔºåÂÖÅËÆ∏ÁúüÂÆûÁöÑ‰∫∫Á±ªÁî®Êà∑ÂìçÂ∫îÔºàÈÄöËøáÊÅ¢Â§çÂØπËØù ‚Äî ËßÅ‰∏ãÊñáÔºâ„ÄÇ\n2. Â¶ÇÊûúÂä©ÁêÜÈúÄË¶ÅÊõ¥Â§ö‰ø°ÊÅØÔºåÂÆÉ‰ºöËØ¢ÈóÆ user_proxyÔºåËøôÂ∞ÜÁªìÊùüÂΩìÂâçÂØπËØù„ÄÇ\n\nÂú®‰∏äËø∞‰ª£Á†Å‰∏≠ÔºåÂèØËÉΩ‰ºöÂèëÁîü‰ª•‰∏ãÊÉÖÂÜµÔºö\n\n1. user_proxy -> manager: ‚ÄúÂ§©Ê∞îÊÄé‰πàÊ†∑Ôºü‚Äù\n2. assistant -> manager: ‚ÄúÁî®Êà∑Ê≤°ÊúâÊåáÂÆöÂì™‰∏™ÂüéÂ∏Ç„ÄÇ‚Äù\n3. manager -> user_proxy : ÂØπËØùÂ∞ÜÁªìÊùü\n\nÁé∞Âú®ÔºåÂ¶ÇÊûúÁî®Êà∑ÊÉ≥Ë¶ÅÂõûÂ∫îÂπ∂ÊÅ¢Â§çÂØπËØùÔºåÊàë‰ª¨ËØ•Â¶Ç‰ΩïÂÅöÂà∞Âë¢ÔºüÊúâÂæàÂ§öÊñπÊ≥ïÂèØ‰ª•ÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåËøôÈáåÂè™ÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n```python\n## user makes a POST /query { \"message\": \"What's the weather?\" }\n## above posts returns a `history` array\n## user makes a second POST /query { \"message\": \"What's the weather?\", \"history\": history }\n\nclass ResumableGroupChatManager(GroupChatManager):\n    groupchat: GroupChat\n\n    def __init__(self, groupchat, history, **kwargs):\n        self.groupchat = groupchat\n        if history:\n            self.groupchat.messages = history\n\n        super().__init__(groupchat, **kwargs)\n\n        if history:\n            self.restore_from_history(history)\n\n    def restore_from_history(self, history) -> None:\n        for message in history:\n            # broadcast the message to all agents except the speaker.  This idea is the same way GroupChat is implemented in AutoGen for new messages, this method simply allows us to replay old messages first.\n            for agent in self.groupchat.agents:\n                if agent != self:\n                    self.send(message, agent, request_reply=False, silent=True)\n\n@query_blueprint.route(\"/query\", methods=[\"POST\"])\nasync def post_query():\n  message = request.form.get(\"message\")\n\n  assistant = autogen.AssistantAgent(\n    name=\"assistant\",\n    llm_config=llm_config\n    system_message=\"\"\"You're a helpful assistant.\n    If you need more info, ask the user for anything missing.\"\"\"\n  )\n  user_proxy = autogen.UserProxyAgent(\n    name=\"user_proxy\",\n    human_input_mode=\"NEVER\",\n    code_execution_config=False,\n    is_termination_msg=lambda message: True # Always True\n  )\n  weather_assistant = WeatherAgent(\n    name=\"weather_assistant\",\n    system_message=\"\"\"You're a helpful assistant to get the weather.\n    You fetch weather information, then return it.\"\"\"\n  )\n\n  groupchat = autogen.GroupChat(\n    agents=[assistant, user_proxy, weather_assistant],\n    messages=[]\n  )\n  manager = ResumableGroupChatManager(\n    name=\"Manager\",\n    groupchat=groupchat,\n    llm_config=llm_config,\n  )\n\n  await user_proxy.a_initiate_chat(manager, message=message)\n\n  return {\n    \"response\": groupchat.messages[-1],\n    \"history\": groupchat.messages,\n  }\n```\nÈÄöËøáËøôÁßçÊñπÊ≥ïÔºåÊÇ®ÂèØ‰ª•Â∞Ü‰∫∫Á±ªÁ∫≥ÂÖ•ÂØπËØùÔºåÂ∞±ÂÉè‰ªñ‰ª¨ÊòØÁæ§ËÅä‰∏≠ÁöÑÂè¶‰∏Ä‰∏™‰ª£ÁêÜ‰∏ÄÊ†∑„ÄÇÊØèÂΩìÂä©ÁêÜ‰ª£ÁêÜÈúÄË¶Å‰∫∫Á±ªËæìÂÖ•Êó∂ÔºåÂÆÉ‰ª¨‰ºöËØ¢ÈóÆ user_proxyÔºåuser_proxy ÁÑ∂ÂêéÁªìÊùüÂΩìÂâçÂØπËØùÔºåÂÖÅËÆ∏‰∫∫Á±ªÁî®Êà∑Áî®Êõ¥Â§ö‰ø°ÊÅØËøõË°åÂìçÂ∫îÔºåÁÑ∂ÂêéÊÅ¢Â§çÂà∞‰πãÂâçÁöÑÂØπËØù„ÄÇ\n\nËøôÁßçÊñπÊ≥ïÁöÑÂ•ΩÂ§ÑÊòØÔºö\n\n* ÂØπËØùÂèØ‰ª•ÈÄöËøáÊÇ®ÊÉ≥Ë¶ÅÁöÑ‰ªª‰ΩïÊñπÂºèÂåÖÂê´ÁúüÂÆû‰∫∫Á±ªËæìÂÖ•Ôºà‰æãÂ¶ÇÈÄöËøá http Êàñ websocketÔºâ„ÄÇ\n* Âú®Ëé∑Âèñ‰∫∫Á±ªËæìÂÖ•Êó∂ÔºåÂØπËØùË¢´ÊöÇÂÅú„ÄÇËøô‰∏∫ÂÖ∂‰ªñÂØπËØùÂíåËÆ°ÁÆóÈáäÊîæ‰∫ÜÁ∫øÁ®ã„ÄÇ\n* ÊÇ®ÂèØ‰ª•Âú®‰ºöËØù‰πãÈó¥ÊåÅ‰πÖÂåñËøô‰∫õÂØπËØù„ÄÇ\n\n## ‰Ω†ÂèØ‰ª•ÔºàÂπ∂‰∏îÂ∫îËØ•ÔºâËá™ÂÆö‰πâË∞ÅÊé•‰∏ãÊù•ÂèëË®Ä\n\nËøôÊòØ‰∏ªËßÇÁöÑÔºå‰ΩÜÊàëËÆ§‰∏∫‰Ω†Â∫îËØ•ÂßãÁªàËá™ÂÆö‰πâÂèëË®ÄËÄÖÁöÑÈÄâÊã©ÊñπÂºèÔºåÂõ†‰∏∫Ôºö\n\n1. ‰Ω†Â∞Ü‰ΩøÁî®Êõ¥Â∞ëÁöÑ‰ª§ÁâåÔºàËäÇÁúÅÈáëÈí±ÂíåÂìçÂ∫îÊó∂Èó¥Ôºâ\n2. ‰Ω†ÂèØ‰ª•Â∞ÜÂÜ≥ÂÆöË∞ÅÂèëË®ÄÁöÑÈÄªËæë‰∏éÂÆö‰πâÊØè‰∏™‰ª£ÁêÜÁ≥ªÁªüÊåá‰ª§ÁöÑÈÄªËæëÂàÜÂºÄ\n\n\n```python\nshort_role_descriptions = {\n  \"user_proxy\": \"A proxy for the user\",\n  \"weather_assistant\": \"You can get the weather\",\n  \"planner\": \"You help coordinate the plan. Your turn happens when XYZ, but skip your turn when ABC\"\n}\n\nclass CustomGroupChat(GroupChat):\n    # The default message uses the full system message, which is a long string.  We are overriding this to use a shorter message.\n    def select_speaker_msg(self, agents: List[Agent]):\n        message = f\"\"\"You are in a role play game. The following roles are available:\n        ---\n        {new_line.join([f\"{agent.name}: {short_role_descriptions[agent.name]}\" for agent in agents])}\n        ---\n\n        The role who plays next depends on the conversation.  User_Proxy will star the conversation, and typically Planner would go next.\n\n        Here are some examples\n        ---\n        ... not shown here ...\n        ---\n\n        Read the following conversation.\n        Then select the next role from {', '.join([agent.name for agent in agents])} to play. Only return the role.\"\"\"\n        return message\n```\n\n## ‰Ω†‰∏çÂøÖ‰ΩøÁî® OpenAI\n\nAutoGen Â∑≤ÁªèÊåáÂá∫Ôºå‰Ω†ÂèØ‰ª•‰ΩøÁî®ÂÖ∂‰ªñ LLMÔºåÂè™Ë¶ÅÂÆÉ‰ª¨ÊòØ‚ÄúÁ±ª‰ºº ChatGPT‚ÄùÁöÑÔºåËøôÊÑèÂë≥ÁùÄÂÆÉ‰ª¨ÁöÑ API ÂìçÂ∫î‰∏é ChatGPT API Ë∞ÉÁî®ÁöÑÂΩ¢Áä∂ÂíåÂìçÂ∫îÁõ∏‰ºº„ÄÇ\n\n‰ΩÜÊòØÔºåËØ∑ËÆ∞‰ΩèËøô‰∫õ‰ª£ÁêÜÊòØÁ±ªÔºåÂπ∂‰∏î‰Ω†ÂèØ‰ª•ÈáçÂÜôÂ§ßÂ§öÊï∞ÊñπÊ≥ïÔºü\n\nÂ∞ùËØïÈáçÂÜôÊñπÊ≥ï: [generate\\_oai\\_reply](https://github.com/microsoft/autogen/blob/40dbf31a925c725edb9124f4312c1703bf8744b0/autogen/agentchat/conversable_agent.py#L678)Ôºå‰Ω†ÂèØ‰ª•Êü•ËØ¢‰ªª‰Ωï‰Ω†ÊÉ≥Ë¶ÅÁöÑ LLM„ÄÇ\n\n## ÂáΩÊï∞ÂèØ‰ª•Áî®Êù•‰ª£ÊõøÊâßË°å‰ª£Á†Å\n\nÂΩìÊàëÂéªÊâæÊàë‰ª¨ÁöÑÂÆâÂÖ®Âõ¢ÈòüÂπ∂ËØ¥Ôºö‚ÄúÊàëÊÉ≥Âú®Kubernetes‰∏≠‰∏∫ÊàëÁöÑÊúçÂä°‰ΩøÁî®AutoGen„ÄÇÂÆÉÈúÄË¶ÅËÉΩÂ§üÊâßË°å‰ªª‰ΩïÁî±LLMÁîüÊàêÁöÑ‰ªªÊÑè‰ª£Á†Å„ÄÇ‰Ω†‰ª¨ÂØπÊ≠§Ê≤°ÈóÆÈ¢òÂêßÔºü‚Äù\n\nÂΩìÁÑ∂ÔºåÁ≠îÊ°àÊòØÊòéÁ°ÆÁöÑÔºö‰∏çÂèØ‰ª•„ÄÇ\n\nÈÇ£‰πàÔºå‰∏∫‰ªÄ‰πàÂú®Ê≤°ÊúâËá™Âä®‰ª£Á†ÅÊâßË°åËÉΩÂäõÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®AutoGenÔºü\n\nÈô§‰∫Ü‰∏ãÈù¢ÊèêÂà∞ÁöÑÂéüÂõ†‰πãÂ§ñÔºåËøòÊúâ‰∏Ä‰∏™ÂéüÂõ†ÊòØ‰Ω†ÂèØ‰ª•‰ΩøÁî®ÂáΩÊï∞Ë∞ÉÁî®Êù•ÂÆåÂÖ®ÊéßÂà∂‰ª£Á†ÅÊâßË°å„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰∏ÄÁªÑÊÉ≥Ë¶ÅÊèê‰æõÁªôAutoGenÁöÑpythonÂáΩÊï∞‚Äî‚ÄîËøô‰∫õÂáΩÊï∞ÊòØ‰Ω†ÁºñÂÜôÁöÑ„ÄÅ‰Ω†ÊéßÂà∂ÁöÑÔºåÂπ∂‰∏îÂèØ‰ª•Êé•Âèó‰∏Ä‰∫õÂÆâÂÖ®ÂèÇÊï∞‚Äî‚ÄîËøôÂê¨Ëµ∑Êù•ÊÄªÊØîÂú®‰Ω†ÁöÑÁßÅÊúâÂü∫Á°ÄËÆæÊñΩ‰∏≠ÂÖÅËÆ∏‰ªª‰Ωï‰ª£Á†ÅË¢´ÊâßË°åË¶ÅÂ•ΩÂæóÂ§ö„ÄÇ\n\n## ‰ΩøÁî®‰ª£ÁêÜËøõË°åÁªÑÁªáÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØËøõË°åÂØπËØù\n\n‰πüËÆ∏‰Ω†Âπ∂‰∏çÈúÄË¶Å‰∏Ä‰∏™Ëá™‰∏ªÁöÑÂ§ö‰ª£ÁêÜÂØπËØù„ÄÇ‰πüËÆ∏‰Ω†Âè™ÈúÄË¶ÅÂØπLLMËøõË°åÂá†Ê¨°‰∏çÂêåÁöÑË∞ÉÁî®„ÄÇ\n\nÊàë‰ªçÁÑ∂ÂñúÊ¨¢‰ªÖ‰ªÖÂá∫‰∫éÁªÑÁªáÁõÆÁöÑËÄåÊã•Êúâ‰∏çÂêå‚Äú‰ª£ÁêÜ‚ÄùÁöÑÊÉ≥Ê≥ï„ÄÇËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÁñØÁãÇÁöÑÊÉ≥Ê≥ïÔºå‰ΩÜËØ∑Ê†πÊçÆËá™Â∑±ÁöÑÊÉÖÂÜµÊù•ÁúãÂæÖÂÆÉÔºö\n\n```python\nanalyst = autogen.AssistantAgent(\n    name=\"Analyst\",\n    system_message=\"\"\"Your an analyst.  You do XYZ.\"\"\",\n    llm_config=llm_config,\n)\n\nsummarizer = autogen.AssistantAgent(\n    name=\"Summarizer\",\n    system_message=\"\"\"Your a summarizer.  You do XYZ.\"\"\",\n    llm_config=llm_config,\n)\n\nreport = \"\"\"Some long report\"\"\"\n\nanalysis = analyst.generate_oai_reply(report)[1]\nsummary = summarizer.generate_oai_reply(report)[1]\n\nprint(f\"Analysis: {analysis}\")\nprint(f\"Summary: {summary}\")\n```\n\n## ‰∏∫‰ªÄ‰πà‰ΩøÁî® AutoGenÔºü\n\n1. AutoGen ÂÖÅËÆ∏Â§ö‰∏™‰ª£ÁêÜÔºåÂÖ∑Êúâ‰∏çÂêåÁöÑÁ≥ªÁªüÊèêÁ§∫ÂíåÊåá‰ª§ÔºåÂÖ±ÂêåËß£ÂÜ≥ÈóÆÈ¢ò„ÄÇÂ∞±ÂÉèÂú®Áé∞ÂÆûÁîüÊ¥ª‰∏≠Ôºå‰∏çÂêåÁöÑËßÜËßíÂÖ±ÂêåÂêà‰Ωú‰ºöÊØîÂçï‰∏ÄÊÄùÁª¥Êõ¥Â•ΩÂú∞Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ\n2. AutoGen GroupChat ÈùûÂ∏∏Âá∫Ëâ≤„ÄÇÂÆÉÊèê‰æõ‰∫ÜÈÄöÂêëÊ≠£Á°Æ‰∏ìÂÆ∂Ôºà‰ª£ÁêÜÔºâÁöÑË∑ØÁ∫øÔºåÂπ∂ÂÖÅËÆ∏ÂØπËØùÂú®ÈóÆÈ¢òËß£ÂÜ≥‰πãÂâçËá™‰∏ªÊåÅÁª≠ËøõË°å„ÄÇÊúâ‰∫õÂØπËØùÂ∞Ü‰ªé‰ª£ÁêÜ a->b->c->d ËøõË°åÔºåËÄåÂÖ∂‰ªñÁöÑÂ∞ÜÊòØ b->a->d->c„ÄÇËøô‰ΩøÂæó AutoGen ËÉΩÂ§üÂú®‰∏çÈúÄË¶Å‰∏∫ÊØèÁßçÂú∫ÊôØÂà∂ÂÆöÊòéÁ°ÆËßÑÂàôÁöÑÊÉÖÂÜµ‰∏ãËß£ÂÜ≥ÂêÑÁßç‰∏çÂêåÁöÑÈóÆÈ¢ò„ÄÇ\n3. AutoGen ËÉΩÂ§ü‰ªéÈîôËØØ‰∏≠ÊÅ¢Â§ç„ÄÇ‰æãÂ¶ÇÔºåÊàëÂàõÂª∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫é AutoGen ÁöÑÊúçÂä°ÔºåËØ•ÊúçÂä°Âêë‰∏Ä‰∏™ API ÂèëÂá∫ËØ∑Ê±Ç„ÄÇÊúâÊó∂ÔºåAPI ËØ∑Ê±ÇÂõ†‰∏∫Êú™ËÉΩÊ≠£Á°ÆÂèëÈÄÅÊï∞ÊçÆËÄåÂá∫Èîô„ÄÇAutoGen GroupChat ‰∏çÊñ≠Â∞ùËØï‰∏çÂêåÁöÑÊñπÊ≥ïÔºåÁõ¥Âà∞ÊàêÂäü„ÄÇÊúâÊó∂ÔºåËøôÈúÄË¶Å 4 Ê¨°‰ª•‰∏äÁöÑÂ∞ùËØïÔºå‰ΩÜÊàëÁöÑ Planner ‰ª£ÁêÜÊ≤°ÊúâÊîæÂºÉ‚Äî‚ÄîÂè™ÊòØËá™‰∏ªË∞ÉÊï¥‰ª•Â§ÑÁêÜ API Â§±Ë¥•Âπ∂Â∞ùËØïÊñ∞ÊñπÊ≥ï„ÄÇ\n4. AutoGen ‰ªé‰∏ÄÂºÄÂßãÂ∞±ÊèêÂá∫‰∫ÜÂ∞Ü `UserProxyAgent` ‰∏é `AssistantAgent` ÂàÜÁ¶ªÁöÑÊ¶ÇÂøµ„ÄÇËøô‰πü‰ΩøÊàë‰ª¨ËÉΩÂ§üËÆ©Áî®Êà∑‰ª£ÁêÜÁúüÊ≠£‰∏∫Áî®Êà∑‰ª£ÁêÜÔºåÂ¶Ç‰∏äÊâÄÁ§∫„ÄÇ\n5. AutoGen ÊòØ‰∏Ä‰∏™Áª¥Êä§ËâØÂ•ΩÁöÑÂ∫ì„ÄÇÊØèÂë®‰ªñ‰ª¨ÈÉΩ‰ºöÊ∑ªÂä†‰∏Ä‰∫õÊñ∞ÂäüËÉΩ„ÄÇ\n6. AutoGen ÈùûÂ∏∏ÂèØÊâ©Â±ï„ÄÇÈÄöËøá‰ªñ‰ª¨ÊûÑÂª∫Á±ªÁöÑÊñπÂºèÔºåÊÇ®ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÂñúÂ•ΩËá™ÂÆö‰πâ‰ªª‰ΩïÂÜÖÂÆπ„ÄÇ\n7. AutoGen ËøòÊúâÂÖ∂‰ªñÊàë‰∏ç‰ΩøÁî®ÁöÑÂäüËÉΩÔºå‰ΩÜÂÖ∂‰ªñ‰∫∫ÂèØËÉΩ‰ºöËßâÂæóÂÆÉ‰ª¨ÊúâÂ∏ÆÂä©Ôºå‰æãÂ¶ÇÂ∏ÆÂä©ÊÇ®ËÆ°ÁÆóÂØπËØùÁöÑ‰ª§ÁâåÂíåÊàêÊú¨„ÄÅÁºìÂ≠òÁ≠â„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/a-robot-artist-just-made-more-money-than-you-have-in-your-entire-creative-career-13dc772ec612","frontmatter":{"title":"Êú∫Âô®‰∫∫Ëâ∫ÊúØÂÆ∂ËµöÁöÑÈí±ÊØî‰Ω†Êï¥‰∏™Âàõ‰ΩúÁîüÊ∂ØËµöÁöÑÈí±ËøòÂ§ö","meta_title":"Êú∫Âô®‰∫∫Ëâ∫ÊúØÂÆ∂ËµöÁöÑÈí±ÊØî‰Ω†Êï¥‰∏™Âàõ‰ΩúÁîüÊ∂ØËµöÁöÑÈí±ËøòÂ§ö","description":"Êú∫Âô®‰∫∫Ëâ∫ÊúØÂÆ∂ËµöÁöÑÈí±ÊØî‰Ω†Êï¥‰∏™Âàõ‰ΩúÁîüÊ∂ØËµöÁöÑÈí±ËøòÂ§ö","date":"2024-11-13T01:22:35.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XUyq2c7RZCjJD6IQXjmd6A.png","categories":["Robotics","Art","Technology/Web"],"author":"Rifx.Online","tags":["Ai-Da","Turing","Sotheby‚Äôs","painting","creativity"],"draft":false,"slug":"blog/a-robot-artist-just-made-more-money-than-you-have-in-your-entire-creative-career-13dc772ec612"},"content":"\n\n\n## Êàë‰ª¨Â∑≤ÁªèËææÂà∞‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂàõÈÄ†ÂäõÂíåÂïÜ‰∏öÁöÑÊñ∞È´òÂ∫¶\n\n\n\nÈ¶ñÂÖàÔºåÊàë‰ª¨ËÆ©ËÆ°ÁÆóÊú∫Â±èÂπïÊ†πÊçÆ‰∫∫Á±ªÂàõ‰ΩúÊù•Âàõ‰ΩúËâ∫ÊúØ„ÄÇÁé∞Âú®ÔºåÊòØ‰∏ÄÂè∞*ÁúüÊ≠£ÁöÑÊú∫Âô®‰∫∫*Âú®ËøõË°åÁªòÁîª„ÄÇ\n\nÊ≤°Èîô‚Äî‚Äî‰∏Ä‰Ωç‚ÄúË∂ÖÁé∞ÂÆû‰∏ª‰πâÊú∫Âô®‰∫∫Ëâ∫ÊúØÂÆ∂‚ÄùÂ∑≤ÁªèË¢´ËÆ≠ÁªÉÊàêËÉΩÂ§üÂú®ÁîªÂ∏É‰∏äÂÆûÈôÖÁªòÁîª„ÄÇÂÆÉÊèèÁªòÁöÑÂ∑≤ÊïÖËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÂÆ∂Ëâæ‰º¶¬∑ÂõæÁÅµÊúÄËøëÂú®ËãèÂØåÊØîÊãçÂçñ‰ºö‰∏äÊãçÂá∫‰∫Ü**130‰∏áÁæéÂÖÉ**ÁöÑÈ´ò‰ª∑„ÄÇ\n\nÊ≠£Â¶Ç*IFLScience* [Êä•ÈÅì](https://proxy.rifx.online/https://www.iflscience.com/ai-robot-artist-strikes-gold-by-selling-painting-of-alan-turing-for-13-million-76701?fbclid=IwZXh0bgNhZW0CMTEAAR0KXPj5YDHnWibf6e97UWADZMuhPwGY4f_hnJnWs7rNoHN8KvvHquLAcFc_aem_hyBhYwyjT73j6PdAeXvOng)ÁöÑÈÇ£Ê†∑ÔºåËøô‰ΩçÂêç‰∏∫Ai-DaÁöÑÊú∫Âô®‰∫∫ÊòØ‰ª•Êï∞Â≠¶ÂÆ∂ÂíåËÆ°ÁÆóÊú∫ÂÖàÈ©±ÈòøËææ¬∑Ê¥õÂ§´Ëé±ÊñØÁöÑÂêçÂ≠óÂëΩÂêçÁöÑ‚Äî‚ÄîÂú®‰∏é‰∫∫Á±ªÈÄöËøáËØ≠Ë®ÄÊ®°ÂûãÂØπËØùÂêéÔºåÈÄâÊã©‰∫ÜÂÆÉÁöÑÁªòÁîª‰∏ªÈ¢ò„ÄÇÁÑ∂ÂêéÔºåÂÆÉÁî®Êú∫Âô®‰∫∫ÊâãËáÇÂãæÂãíÂíåÁªòÂà∂‰∫ÜÂá†ÁßçÂõæÁÅµÁöÑÁâàÊú¨„ÄÇ\n\nÊ∂àÊÅØÊù•Ê∫êÁß∞ÔºåÊØèÂπÖÊàêÂìÅÁ≥ªÂàóÁöÑÊ≤πÁîª/‰∏ôÁÉØÁîªÂ§ßÁ∫¶ÈúÄË¶ÅÊú∫Âô®‰∫∫‚ÄúËâ∫ÊúØÂÆ∂‚ÄùÂÆåÊàêÂÖ≠Âà∞ÂÖ´Â∞èÊó∂„ÄÇAi-DaÊúÄÂàùÂàõ‰Ωú‰∫Ü15ÂπÖÁîª‰ΩúÔºåÁªèËøá‰∫∫Â∑•Âàõ‰ΩúËÄÖÁöÑÁ≠õÈÄâÔºåÊúÄÁªà‰∫ßÂìÅ‚ÄúÈÄöËøá3DÁ∫πÁêÜÊâìÂç∞Êú∫Â∫îÁî®‰∫éÂ§ßÁîªÂ∏É‰∏ä‚Äù„ÄÇ\n\n## ‰∫∫Â∑•Ëâ∫ÊúØÔºåÁúüÂÆûË¥¢ÂØå\n\nË¢´Áß∞‰∏∫ *A.I. God* ÁöÑ‚ÄúËâ∫ÊúØ‚ÄùÂú®ÊãçÂçñ‰∏≠Ëé∑Âæó‰∫ÜÂ§ßÁ∫¶È¢ÑÊúüÂîÆ‰ª∑ÁöÑ10ÂÄçÔºåÊúÄÁªàÁî±‰∏Ä‰ΩçÂåøÂêç‰π∞ÂÆ∂Á´ûÂæó„ÄÇ\n\nÂæàÂèØËÉΩÔºå$1.3Áôæ‰∏áË∂ÖËøá‰∫Ü‰Ω†Ëá™Â∑±Ëâ∫ÊúØ‰ΩúÂìÅÁöÑÊî∂ÂÖ•ÔºåÂÅáËÆæ‰Ω†‰∏çÊòØ‰∏Ä‰ΩçÂ∑≤ÊïÖÁöÑËâ∫ÊúØÂÅ∂ÂÉè„ÄÇÊàë‰ª¨Áü•ÈÅìÔºåÂ∞ΩÁÆ°Ëâ∫ÊúØÂÆ∂Âú®‰∏ñÊó∂ÁªèÊµéÊãÆÊçÆÔºå‰ΩÜ‰∫∫‰ª¨Ë¥≠‰π∞ÁöÑÂ∑≤ÊïÖ‰º†Â•áËâ∫ÊúØÂÆ∂ÁöÑ‰ΩúÂìÅÂæÄÂæÄ[ËÉΩÂçñÂá∫Êï∞Áôæ‰∏á](https://proxy.rifx.online/https://www.veranda.com/luxury-lifestyle/artwork/g43012775/most-expensive-paintings-in-the-world/)„ÄÇ\n\nËøôÂπ∂‰∏çÊòØÊàë‰ª¨Á¨¨‰∏ÄÊ¨°ÁúãÂà∞Êï∞Â≠óËâ∫ÊúØÂú®ÊãçÂçñ‰∏≠‰ª•ËçíË∞¨ÁöÑ‰ª∑Ê†ºÊàê‰∫§„ÄÇ\n\nÂú®2018Âπ¥Ôºå‰∏Ä‰∏™Ê≥ïÂõΩÈõÜ‰ΩìÂú®‰Ω≥Â£´ÂæóÊãçÂçñ‰ºö‰∏ä‰∏∫‰∏ÄÂπÖÂêç‰∏∫ *Edmond de Belamy, from La Famille de Belamy* ÁöÑAIËÇñÂÉèËâ∫ÊúØ‰ΩúÂìÅËé∑Âæó‰∫Ü$432,500„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JK-X4et953sOiH1tovj3ag.jpeg)\n\nÂêéÊù•Ôºå‰∏Ä‰ΩçÂêçÂè´Mike WinkelmannÁöÑËâ∫ÊúØÂÆ∂Ôºå‰ª•‚ÄúBeeple‚ÄùÈóªÂêçÔºåÂú®‰Ω≥Â£´Âæó‰ª•$6900‰∏áÁöÑ‰ª∑Ê†ºÂá∫ÂîÆ‰∫Ü‰∏ÄÂπÖÊï∞Â≠óNFTÔºàËøòËÆ∞ÂæóËøô‰∫õÂêóÔºüÔºâÔºåËøô‰Ωø‰ªñË∑ªË∫´‰∫éÊúÄÊúâ‰ª∑ÂÄºÁöÑÁé∞Â≠òËâ∫ÊúØÂÆ∂‰πãÂàó„ÄÇ*The Verge* [Ëß£Èáä](https://proxy.rifx.online/https://www.theverge.com/2021/3/11/22325054/beeple-christies-nft-sale-cost-everydays-69-million)ËØ¥ÔºåÂú®ÈÇ£Ê¨°Á™ÅÁ†¥ÊÄßÁöÑÈîÄÂîÆ‰πãÂâçÔºå‰ªñ‰ªé‰∏ÄÂπÖÂç∞Âà∑ÂìÅ‰∏≠Ëé∑ÂæóÁöÑÊúÄÈ´òÊî∂ÂÖ•‰∏∫$100„ÄÇ\n\n‰ΩÜËøôÊòØÁ¨¨‰∏ÄÊ¨°Ôºå‰∏Ä‰∏™Á±ª‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÊûÑÊÄù‰∫Ü‰∏Ä‰∏™Ê¶ÇÂøµÔºåÂπ∂ÂÆûÈôÖÂ∞ÜÈ¢úÊñôÂ∫îÁî®‰∫éÁîªÂ∏É„ÄÇ\n\nÂΩìÁÑ∂ÔºåAi-DaÂπ∂‰∏ç‰øùÁïôËøôÁ¨îÈí±‚Äî‚ÄîÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊú∫Âô®‰∫∫Âπ∂‰∏çÈúÄË¶Å‰ΩøÁî®Ë¥ßÂ∏Å„ÄÇÂÆÉÁöÑ‰∫∫Á±ªÂàõÈÄ†ËÄÖ‰ªéÈîÄÂîÆ‰∏≠Ëé∑ÂæóÁªèÊµéÂà©Áõä„ÄÇ\n\n## ÁõÆÂâç‰ªçÈúÄË¶Å‰∫∫Á±ªËæìÂÖ•\n\nËâæ‰∏π¬∑Ê¢ÖÂãíÔºàAidan MellerÔºâÔºå‰∏Ä‰ΩçËâ∫ÊúØÁªèÈîÄÂïÜÂíåÁîªÂªä‰∏ª‰ªªÔºåÊòØAi-DaÊú∫Âô®‰∫∫È°πÁõÆÁöÑË¥üË¥£‰∫∫„ÄÇIFLScienceË°®Á§∫ÔºåÂÆûÈôÖÁöÑÊú∫Âô®‰∫∫ÊòØÁî±Ëã±ÂõΩÊú∫Âô®‰∫∫ÈõÜ‰ΩìEngineered ArtsÂà∂ÈÄ†ÁöÑÔºåËØ•ÈõÜ‰ΩìËøòÊé®Âá∫‰∫ÜÂêåÊ†∑‰ª§‰∫∫ÊØõÈ™®ÊÇöÁÑ∂ÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫[Ameca](https://proxy.rifx.online/https://engineeredarts.co.uk/robot/ameca/)„ÄÇ\n\nËØ∑ËÆ∞‰ΩèÔºå‰ªçÁÑ∂ÈúÄË¶Å‰∫∫Á±ªÊù•ÊèêÁ§∫Êú∫Âô®‰∫∫„ÄÇÊ¢ÖÂãíË°®Á§∫ÔºåÊúÄÂàù‰∏éAi-DaÁöÑËÆ®ËÆ∫ÊòØÂÖ≥‰∫éÊèèÁªò‚Äú‰∏∫ÂñÑÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‚Äù„ÄÇËøòËÆ®ËÆ∫‰∫ÜÂú®È£éÊ†ºÂíåË¥®ÊÑüÊñπÈù¢Â¶Ç‰ΩïËøõË°åÁªòÁîª„ÄÇ\n\n‚ÄúÂ•πÁöÑ‰∫∫Â∑•Êô∫ËÉΩËÉΩÂäõÊòØÁî±ÁâõÊ¥•Â§ßÂ≠¶Âíå‰ºØÊòéÁø∞Â§ßÂ≠¶ÁöÑÂçöÂ£´ÁîüÂíåÊïôÊéàÂÖ±ÂêåÂºÄÂèëÁöÑÔºåÁºñÁ®ãÊòØÂõΩÈôÖÂåñÁöÑÔºå‚ÄùÁΩëÁ´ôÂÖ≥‰∫éAi-DaÊåáÂá∫„ÄÇÂÆÉË°•ÂÖÖËØ¥Ôºå‰∫∫Á±ªÂä©ÊâãÂ∏ÆÂä©ÂáÜÂ§á‰∫ÜÊâìÂç∞ÁîªÂ∏ÉÔºå‰ΩÜÊú∫Âô®‰∫∫Âú®ÂÆåÊàê‰∫ßÂìÅÊñπÈù¢Ë¥üÊúâ‰∏ªË¶ÅË¥£‰ªª„ÄÇ\n\nËøôÊòØ‰∏Ä‰∏™Ai-DaËß£ÈáäËâ∫ÊúØ‚ÄúËøáÁ®ã‚ÄùÁöÑËßÜÈ¢ëÔºö\n\n\n\n\n\n*Âç´Êä•* [Êä•ÈÅì](https://proxy.rifx.online/https://www.theguardian.com/artanddesign/2024/nov/08/alan-turing-portrait-ai-da-robot-painting-sale-price-auction)ËØ¥ÔºåËÇñÂÉèÁöÑÊüêÁßçÊäΩË±°È£éÊ†ºÂèØËÉΩÊòØÊïÖÊÑèÁöÑÔºö\n\n\n> **Ê¢ÖÂãíË°®Á§∫Ôºå‚ÄúËâ∫ÊúØ‰ΩúÂìÅÁöÑ‚ÄòÊüîÂíåËâ≤Ë∞ÉÂíåÁ†¥Á¢éÁöÑÈù¢ÈÉ®Âπ≥Èù¢‚Äô‰ºº‰πéÊöóÁ§∫‰∫Ü‚ÄòÂõæÁÅµË≠¶ÂëäÊàë‰ª¨Âú®ÁÆ°ÁêÜ‰∫∫Â∑•Êô∫ËÉΩÊó∂Â∞ÜÈù¢‰∏¥ÁöÑÊåëÊàò‚Äô„ÄÇ‚Äù**\n\nÂõæÁÅµÊòØÂØπÁöÑ„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÂú®ÂÜô‰ΩúÂíåËâ∫ÊúØ‰∏≠ÁöÑÂá∫Áé∞Â∑≤Â∏≠Âç∑ÂÖ®ÁêÉÔºå‰ªÖÂú®Âá†Âπ¥ÂâçÂ∞±Â∑≤Â¥≠Èú≤Â§¥Ëßí„ÄÇÁé∞Âú®ÔºåÊàë‰ª¨Â∑≤ÁªèËææÂà∞‰∏Ä‰∏™Êú∫Âô®‰∫∫ÂèØ‰ª•‰∏∫ÂÖ∂Ê¶ÇÂøµÂëΩ‰ª§Ë∂ÖËøá‰∏ÄÁôæ‰∏áÁæéÂÖÉÁöÑÂú∞Ê≠•„ÄÇ\n\n## ÊåëÊàòËâ∫ÊúØÁöÑÂÆö‰πâ\n\n‰ΩÜËøô‰∏ç‰ªÖ‰ªÖÊòØÂÖ≥‰∫éÈáëÈí±„ÄÇËøôÁßçËâ∫ÊúØËøõ‰∏ÄÊ≠•ÊåëÊàò‰∫ÜËâ∫ÊúØÁ©∂Á´üÊòØ‰ªÄ‰πàÔºå‰ª•ÂèäÊòØÂê¶ÈúÄË¶ÅÊã•Êúâ‰∫∫ÁöÑÊÑèËØÜÊâçËÉΩ‰∫ßÁîüÂΩ±Âìç„ÄÇ\n\nËøô‰∏™È°πÁõÆËÉåÂêéÁöÑ‰∫∫‰ª¨ËÆ§‰∏∫ Ai\\-Da Êú¨Ë∫´Â∞±ÊòØ‚ÄúÊ¶ÇÂøµËâ∫ÊúØ‚Äù„ÄÇËôΩÁÑ∂Ëøô‰∏™Êú∫Âô®‰∫∫ÊòæÁÑ∂‰∏çÊòØ‰∫∫Á±ªÔºå‰ΩÜËøòÊúâÂÖ∂‰ªñÈ°πÁõÆÊ≠£Âú®ËøõË°å‰∏≠ÔºåÂèØËÉΩÂæàÂø´‰ºöÂàõÈÄ†Âá∫ÁúãËµ∑Êù•ÁúüÂÆûÁöÑËâ∫ÊúØÂÆ∂ÔºåÊã•ÊúâÁúüÊ≠£ÁöÑ [Ê¥ªÁöÆËÇ§](https://proxy.rifx.online/https://readmedium.com/the-new-face-of-artificial-intelligence-9c900d463cf9)„ÄÇ\n\nË∞ÅÁü•ÈÅìÂë¢Ôºå‰Ω†ÂèØËÉΩÂæàÂø´Â∞±Âú®‰∏Ä‰∏™ÁîüÊ¥ªÁ¥†ÊèèËØæ‰∏ä‰∏é‰∏Ä‰ΩçÂêå‰º¥Ëâ∫ÊúØÂÆ∂‰∫§Ë∞àÔºåÁß∞Ëµû‰ªñ‰ª¨ÁöÑÊäÄËâ∫ÔºåËÄåÊ≤°ÊúâÊÑèËØÜÂà∞‰Ω†Ê≠£Âú®‰∏é‰∏Ä‰∏™Êú∫Âô®‰∫∫ÂØπËØù„ÄÇ\n\n*‰Ω†ÂØπÊ≠§Êúâ‰ΩïÁúãÊ≥ïÔºü‰Ω†ÊòØÊÑüÂà∞Âç∞Ë±°Ê∑±Âàª„ÄÅÊÑüÂà∞ÊØõÈ™®ÊÇöÁÑ∂ÔºåËøòÊòØÂØπ‰Ω†ÁöÑËâ∫ÊúØÊú™Êù•ÊÑüÂà∞ÊãÖÂøßÔºü*\n\n"},{"lang":"zh","group":"blog","slug":"blog/ai-image-generator-and-story-generation-app-using-fastapi-groq-and-replicate-706f29dc126f","frontmatter":{"title":"‰ΩøÁî® FastAPI„ÄÅGroq Âíå Replicate ÁöÑ AI ÂõæÂÉèÁîüÊàêÂô®ÂíåÊïÖ‰∫ãÁîüÊàêÂ∫îÁî®Á®ãÂ∫è","meta_title":"‰ΩøÁî® FastAPI„ÄÅGroq Âíå Replicate ÁöÑ AI ÂõæÂÉèÁîüÊàêÂô®ÂíåÊïÖ‰∫ãÁîüÊàêÂ∫îÁî®Á®ãÂ∫è","description":"È°πÁõÆ‰ªãÁªçÔºöAIÂõæÂÉèÁîüÊàêÂô®ÂíåÊïÖ‰∫ãÂàõ‰ΩúËÄÖ","date":"2024-11-08T00:21:34.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-fb-azx7fDZ-X9-PbIkiSQ.jpeg","categories":["Programming","Technology/Web","Generative AI"],"author":"Rifx.Online","tags":["FastAPI","Groq","Replicate","transcription","image-generation"],"draft":false,"slug":"blog/ai-image-generator-and-story-generation-app-using-fastapi-groq-and-replicate-706f29dc126f"},"content":"\n\n\n## È°πÁõÆ‰ªãÁªçÔºöAI ÂõæÂÉèÁîüÊàêÂô®ÂíåÊïÖ‰∫ãÂàõ‰ΩúÂ∑•ÂÖ∑\n\nAI ÂõæÂÉèÁîüÊàêÂô®ÂíåÊïÖ‰∫ãÂàõ‰ΩúÂ∑•ÂÖ∑ÊòØ‰∏Ä‰∏™ÁΩëÁªúÂ∫îÁî®Á®ãÂ∫èÔºåÂà©Áî®ÂÖàËøõÁöÑ AI ÊäÄÊúØ‰∏∫Áî®Êà∑Êèê‰æõ‰∏Ä‰∏™Âü∫‰∫éÈü≥È¢ëÊèêÁ§∫ÁîüÊàêÂõæÂÉèÂíåÊïÖ‰∫ãÁöÑ‰∫íÂä®Âπ≥Âè∞„ÄÇËØ•Â∫îÁî®Á®ãÂ∫è‰ΩøÁî® FastAPI ‰Ωú‰∏∫ÂêéÁ´ØÔºåËÉΩÂ§üÈ´òÊïàÂ§ÑÁêÜËØ∑Ê±ÇÂíåÂìçÂ∫îÔºåËÄåÂâçÁ´ØÂàôÈááÁî® HTML„ÄÅCSSÔºàDaisyUI Âíå Tailwind CSSÔºâÂíå JavaScript ÊûÑÂª∫Ôºå‰ª•Êèê‰æõÂìçÂ∫îÂºèÁî®Êà∑‰ΩìÈ™å„ÄÇËØ•Â∫îÁî®Á®ãÂ∫èÂà©Áî® llama\\-3\\.1‚Äì70b ËøõË°åÊèêÁ§∫ÁîüÊàêÔºåblack\\-forest\\-labs/flux\\-1\\.1\\-pro ËøõË°åÂõæÂÉèÁîüÊàêÔºå‰ª•Âèä llava\\-v1\\.5‚Äì7b vbision Ê®°ÂûãÈÄöËøá Groq Âíå Replicat.AI ÂàÜÂà´ËøõË°åÊïÖ‰∫ãÂàõ‰Ωú„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0h1GzVVWs_df4OWAC-P59A.jpeg)\n\n## ‰∏ªË¶ÅÁâπÁÇπÔºö\n\n1. Èü≥È¢ëÂΩïÂà∂ÂíåËΩ¨ÂΩïÔºöÁî®Êà∑ÂèØ‰ª•ÂΩïÂà∂‰ªñ‰ª¨ÁöÑËØ≠Èü≥ÊèêÁ§∫ÔºåÁÑ∂Âêé‰ΩøÁî®ËØ≠Èü≥ËØÜÂà´ÊäÄÊúØÂ∞ÜÂÖ∂ËΩ¨ÂΩï‰∏∫ÊñáÊú¨„ÄÇ\n\n2\\. ÂõæÂÉèÁîüÊàêÔºöÂü∫‰∫éËΩ¨ÂΩïÁöÑÊñáÊú¨ÔºåÂ∫îÁî®Á®ãÂ∫èÁîüÊàêËØ¶ÁªÜÁöÑÂõæÂÉèÊèêÁ§∫ÔºåÂπ∂‰ΩøÁî® Replicate API ÂàõÂª∫Áõ∏Â∫îÁöÑÂõæÂÉè„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uiSG8Ir-Wv4a1huYqWhxBg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-eRPglLlJwms8N2DCXRyXg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Mtle1K8AzjMHGxlGicFcGQ.png)\n\n3\\. ÂõæÂÉè‰∏ãËΩΩÔºöÁî®Êà∑ÂèØ‰ª•Â∞ÜÁîüÊàêÁöÑÂõæÂÉè‰∏ãËΩΩÂà∞Êú¨Âú∞ËÆæÂ§á„ÄÇ\n\n4\\. ÊïÖ‰∫ãÁîüÊàêÔºöÂ∫îÁî®Á®ãÂ∫èÂèØ‰ª•Âü∫‰∫éÂàõÂª∫ÁöÑÂõæÂÉèÁîüÊàêÂºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ãÔºå‰∏∫ËßÜËßâÂÜÖÂÆπÊèê‰æõÂèô‰∫ãËÉåÊôØ„ÄÇ\n\n5\\. Áî®Êà∑ÂèãÂ•ΩÁöÑÁïåÈù¢ÔºöÂ∫îÁî®Á®ãÂ∫èÂÖ∑ÊúâÁÆÄÊ¥ÅÁõ¥ËßÇÁöÑÁïåÈù¢Ôºå‰ΩøÁî®Êà∑ËÉΩÂ§üËΩªÊùæ‰∏éÂêÑÁßçÂäüËÉΩËøõË°å‰∫§‰∫í„ÄÇ\n\n## ‰ΩøÁî®ÁöÑÊäÄÊúØÔºö\n\n* ÂêéÁ´ØÔºöFastAPI, Groq, Replicate.ai, SpeechRecognition\n* ÂâçÁ´ØÔºöHTML, CSS (DaisyUI, Tailwind CSS), JavaScript\n* ÂõæÂÉèÂ§ÑÁêÜÔºöÁî®‰∫éÂõæÂÉèÂ§ÑÁêÜÁöÑPillow\n* ÂºÇÊ≠•Êìç‰ΩúÔºöÁî®‰∫éÈ´òÊïàÊñá‰ª∂Â§ÑÁêÜÂíåÁΩëÁªúËØ∑Ê±ÇÁöÑaiohttpÂíåaiofiles\n\nËØ•È°πÁõÆ‰Ωú‰∏∫Â∞ÜÂ§ö‰∏™AIÊúçÂä°ÈõÜÊàêÂà∞‰∏Ä‰∏™Áªü‰∏ÄÂ∫îÁî®Á®ãÂ∫è‰∏≠ÁöÑÁ§∫‰æãÔºå‰ΩøÁî®Êà∑ËÉΩÂ§üÊé¢Á¥¢AIÁîüÊàêÂÜÖÂÆπÁöÑÂàõÊÑèÂèØËÉΩÊÄß„ÄÇ\n\n## ‰ª£Á†ÅÂ∫ìËØ¶ÁªÜËØ¥ÊòéÔºö\n\n1. **ÂâçÁ´Ø (HTML/JavaScript)Ôºö**\n\n* *ËØ•Â∫îÁî®Á®ãÂ∫è‰ΩøÁî®Âçï‰∏™ HTML È°µÈù¢ (index.html)ÔºåÈááÁî®ÂìçÂ∫îÂºèËÆæËÆ°Ôºå‰ΩøÁî® DaisyUI Âíå Tailwind CSS„ÄÇ*\n* *È°µÈù¢ÂåÖÂê´Èü≥È¢ëÂΩïÂà∂„ÄÅËΩ¨ÂΩï„ÄÅÊèêÁ§∫ÁîüÊàê„ÄÅÂõæÂÉèÁîüÊàêÂíåÊïÖ‰∫ãÁîüÊàêÁöÑÈÉ®ÂàÜ„ÄÇ*\n* *JavaScript Êñá‰ª∂ (script.js) Â§ÑÁêÜÁî®Êà∑‰∫§‰∫íÂπ∂‰∏éÂêéÁ´Ø API ÈÄö‰ø°„ÄÇ*\n\n**2\\. ÂêéÁ´Ø (FastAPI) :**\n\n* *‰∏ªË¶ÅÂ∫îÁî®Á®ãÂ∫èÂÆö‰πâÂú® app/main.py ‰∏≠„ÄÇ*\n* *ÂÆÉ‰ΩøÁî® FastAPI ÂàõÂª∫‰∏Ä‰∏™ÂÖ∑ÊúâÂ§ö‰∏™Á´ØÁÇπÁöÑ Web ÊúçÂä°Âô®Ôºö*\n\n**‚Äî *a. /: Êèê‰æõ‰∏ªË¶Å HTML È°µÈù¢„ÄÇ***\n\n***‚Äî b. /transcribe:*** *Â∞ÜÈü≥È¢ëËΩ¨ÂΩï‰∏∫ÊñáÊú¨„ÄÇ*\n\n***‚Äî c. /generate\\_prompt:*** *‰ΩøÁî® Groq ÁöÑ LLM ‰ªéÊñáÊú¨ÁîüÊàêÂõæÂÉèÊèêÁ§∫„ÄÇ*\n\n***‚Äî d. /generate\\_image:*** *‰ΩøÁî® Replicate ÁöÑ Flux Ê®°ÂûãÁîüÊàêÂõæÂÉè„ÄÇ*\n\n***‚Äî e. /download\\_image:*** *‰∏ãËΩΩÂπ∂‰øùÂ≠òÁîüÊàêÁöÑÂõæÂÉè„ÄÇ*\n\n***‚Äî f. /generate\\_story\\_from\\_image:*** *Ê†πÊçÆÂõæÂÉè‰ΩøÁî® Groq ÁöÑ LLaVA Ê®°ÂûãÁîüÊàêÊïÖ‰∫ã„ÄÇ*\n\n***‚Äî g. /download/{filename}:*** *Êèê‰æõ‰∏ãËΩΩÁöÑÂõæÂÉèÊñá‰ª∂„ÄÇ*\n\n**3\\. ‰∏ªË¶ÅÂäüËÉΩÔºö**\n\n* *Èü≥È¢ëÂΩïÂà∂ÂíåËΩ¨ÂΩï*\n* *ÊñáÊú¨Âà∞ÂõæÂÉèÁöÑÊèêÁ§∫ÁîüÊàê*\n* *Ê†πÊçÆÊèêÁ§∫ÁîüÊàêÂõæÂÉè*\n* *Ê†πÊçÆÂõæÂÉèÁîüÊàêÊïÖ‰∫ã*\n* *ÂõæÂÉè‰∏ãËΩΩÂíå‰øùÂ≠ò*\n\n**4\\. Â§ñÈÉ® APIÔºö**\n\n* [Groq:](https://console.groq.com/docs/models) Áî®‰∫éÊñáÊú¨ÁîüÊàêÔºàË∞ÉÊï¥ÂêéÁöÑÊèêÁ§∫Âíå [ÊïÖ‰∫ã](https://console.groq.com/docs/vision)Ôºâ\n* [Replicate AI:](https://replicate.com/black-forest-labs/flux-1.1-pro/api) black\\-forest\\-labs/flux\\-1\\.1\\-pro Ê®°ÂûãÁî®‰∫éÂõæÂÉèÁîüÊàê\n* ÈúÄË¶ÅÂÆâË£ÖÁöÑÂøÖË¶ÅÂåÖÔºö\n\n```python\nfastapi\nuvicorn\njinja2\npython-multipart\npydantic\npython-dotenv\ngroq\nreplicate\nSpeechRecognition\npydub\naiohttp\naiofiles\nPillow\n```\n\n**ÊÇ®ÂèØ‰ª•‰ΩøÁî® pip ÂÆâË£ÖËøô‰∫õÂåÖÔºö**\n\n```python\npip install fastapi uvicorn jinja2 python-multipart pydantic python-dotenv groq replicate SpeechRecognition pydub aiohttp aiofiles Pillow\n```\n\n**ÊâßË°åËØ¥ÊòéÔºö**\n\n* ***ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö*** *Âú®Ê†πÁõÆÂΩïÂàõÂª∫‰∏Ä‰∏™ .env Êñá‰ª∂ÔºåÂÜÖÂÆπÂ¶Ç‰∏ãÔºö*\n\n```python\nGROQ_API_KEY=your_groq_api_key_here\nREPLICATE_API_TOKEN=your_replicate_api_token_here\n```\n\n*Áî®ÊÇ®ÁöÑÂÆûÈôÖ API ÂØÜÈí•ÊõøÊç¢Âç†‰ΩçÁ¨¶ÂÄº„ÄÇ*\n\n* **Á°Æ‰øùÊÇ®Â∑≤ÂáÜÂ§áÂ•ΩÊâÄÊúâÂøÖË¶ÅÁöÑÊñá‰ª∂Ôºö**\n* ‚Äî app/main.py\n* ‚Äî app/config.py\n* ‚Äî app/utils.py\n* ‚Äî templates/index.html\n* ‚Äî static/css/styles.css\n* ‚Äî static/js/script.js\n* **ËøêË°å FastAPI ÊúçÂä°Âô®Ôºö** ÂØºËà™Âà∞ÂåÖÂê´ app/main.py ÁöÑÁõÆÂΩïÂπ∂ËøêË°åÔºö\n\n```python\nuvicorn app.main:app - reload\n```\n\n* **ËÆøÈóÆÂ∫îÁî®Á®ãÂ∫èÔºö**\n* ‚Äî ÊâìÂºÄÊµèËßàÂô®Âπ∂ËΩ¨Âà∞ [http://127\\.0\\.0\\.1:8000](http://127.0.0.1:8000)\n* **‰ΩøÁî®Â∫îÁî®Á®ãÂ∫èÔºö**\n* ‚Äî a. ÁÇπÂáª‚ÄúÂºÄÂßãÂΩïÈü≥‚ÄùÂπ∂ËØ¥Âá∫ÊÇ®ÁöÑÊèêÁ§∫„ÄÇ\n* ‚Äî b. ÂÆåÊàêÂêéÁÇπÂáª‚ÄúÂÅúÊ≠¢ÂΩïÈü≥‚Äù„ÄÇ\n* ‚Äî c. Èü≥È¢ëÂ∞ÜËá™Âä®ËΩ¨ÂΩï„ÄÇ\n* ‚Äî d. ÁÇπÂáª‚ÄúÁîüÊàêÂõæÂÉèÊèêÁ§∫‚Äù‰ª•ÂàõÂª∫ËØ¶ÁªÜÊèêÁ§∫„ÄÇ\n* ‚Äî e. ÁÇπÂáª‚ÄúÁîüÊàêÂõæÂÉè‚Äù‰ª•Ê†πÊçÆÊèêÁ§∫ÂàõÂª∫ÂõæÂÉè„ÄÇ\n* ‚Äî f. ‰ΩøÁî®‚Äú‰∏ãËΩΩÂõæÂÉè‚ÄùÊåâÈíÆ‰øùÂ≠òÁîüÊàêÁöÑÂõæÂÉè„ÄÇ\n* ‚Äî g. ÁÇπÂáª‚ÄúÁîüÊàêÊïÖ‰∫ã‚Äù‰ª•Ê†πÊçÆÁîüÊàêÁöÑÂõæÂÉèÂàõÂª∫ÊïÖ‰∫ã„ÄÇ\n\nÊ≥®ÊÑèÔºöÁ°Æ‰øùÊÇ®ÊúâËâØÂ•ΩÁöÑ‰∫íËÅîÁΩëËøûÊé•ÔºåÂõ†‰∏∫ËØ•Â∫îÁî®Á®ãÂ∫è‰æùËµñÂ§ñÈÉ® API Êèê‰æõÂêÑÁßçÂäüËÉΩ„ÄÇ\n\nËØ•Â∫îÁî®Á®ãÂ∫èÂ±ïÁ§∫‰∫ÜÂêÑÁßç AI ÊäÄÊúØÁöÑÂ§çÊùÇÈõÜÊàêÔºåÂåÖÊã¨ËØ≠Èü≥ËØÜÂà´„ÄÅËØ≠Ë®ÄÊ®°ÂûãÂíåÂõæÂÉèÁîüÊàêÔºåÊâÄÊúâËøô‰∫õÈÉΩÂ∞ÅË£ÖÂú®Áî®Êà∑ÂèãÂ•ΩÁöÑ Web ÁïåÈù¢‰∏≠„ÄÇ\n\nÂ¶Ç‰∏ãÈù¢ÊâÄÁ§∫ÁöÑ FastAPI UI\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Teb1wJzGOQZ3oqaLcLJwkA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6K-nORe7ubi0MRqIRLdrFA.png)\n\n## AIÂõæÂÉèÁîüÊàêÂ∫îÁî®\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1CClu2W3yRds1Lsk1rk9Ew.png)\n\n## ËØ¥Âá∫ÊÇ®ÁöÑÊèêÁ§∫\n\n* ÂºÄÂßãÂΩïÈü≥\n* ÂÅúÊ≠¢ÂΩïÈü≥\n* ËΩ¨ÂΩïÔºàËΩ¨ÂΩïÊñáÊú¨ÔºâÔºö‰∏Ä‰ΩçÁæé‰∏ΩÁöÑÂç∞Â∫¶Ê®°ÁâπÂú®Êó∂Ë£ÖÁßÄ‰∏≠Ëµ∞‰∏ãRunway Ram\n* Ê†πÊçÆËΩ¨ÂΩïÊñáÊú¨ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÊèêÁ§∫‰ª•ÁîüÊàêÂõæÂÉè\n* ‚Äî ÁîüÊàêÁöÑÊèêÁ§∫Ôºö‚Äú*ÁîüÊàê‰∏ÄÂπÖÈ´òÂ∫¶ÈÄºÁúüÁöÑÂõæÂÉèÔºåÊèèÁªò‰∏Ä‰Ωç‰ª§‰∫∫ÊÉäËâ≥ÁöÑÂç∞Â∫¶Ê®°ÁâπÂú®Ê†áÂøóÊÄßÁöÑRunway Ram‰∏äËµ∞Âä®Ôºå‰Ωú‰∏∫È´òÁ´ØÊó∂Ë£ÖÁßÄÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇËøô‰ΩçÊ®°ÁâπÊòØ‰∏Ä‰Ωç22Â≤ÅÁöÑÂç∞Â∫¶Â•≥ÊÄßÔºåÊã•ÊúâÈïøÈïøÁöÑÈªëÂèë„ÄÅÊ∑±Ê£ïËâ≤ÁöÑÁúºÁùõÂíåÊó†ÁëïÁöÑËÇåËÇ§ÔºåË∫´Á©øÁ≤æÁæé„ÄÅÂ§çÊùÇÂà∫Áª£ÁöÑlehenga choliÔºåÈÖç‰ª•ÈáëÈì∂‰∫ÆÁâáÔºå‰º†ÁªüÂç∞Â∫¶ÊúçÈ•∞ÔºåÂπ∂Êê≠ÈÖçÈ´òË∑üÈûã„ÄÇÂ•πÁöÑÊúçË£ÖËÆæËÆ°Á≤æÁæéÔºåÂà∫Áª£ÁªÜËá¥„ÄÇÂº∫Ë∞É‰ºòÈõÖÁöÑË§∂Áö±„ÄÅÈó™‰∫ÆÁöÑÈù¢ÊñôÔºå‰ª•ÂèäÂ•π‰ºòÈõÖÁöÑÂßøÊÄÅÂíåËá™‰ø°ÁöÑÊ≠•‰ºê„ÄÇÈÖçÈ•∞ÊñπÈù¢ÔºåÂä†ÂÖ•Âçé‰∏ΩÁöÑÁè†ÂÆùÔºåÂ¶ÇÊâãÈìæ„ÄÅÈáëÊâãÈïØÂíåÈ°πÈìæÔºåË£ÖÈ•∞Âú®Â•πÁöÑÊâã„ÄÅËÑñÂ≠êÂíå‰∏Ä‰æßÁöÑÂèëÂûã‰∏ä„ÄÇÁÅØÂÖâÊïàÊûúËµ∑ÁùÄÈáçË¶Å‰ΩúÁî®ÔºåËÆæÁΩÆÊ∏©ÊöñÁöÑËàûÂè∞ËÅöÂÖâÁÅØÔºåÁ™ÅÂá∫Ê®°ÁâπÁöÑÊúçË£ÖÔºåÂπ∂Áî®ÊüîÂíåÁöÑËìùËâ≤Ë∞ÉÁÖß‰∫ÆÊï¥‰∏™ÁéØÂ¢É„ÄÇÊëÑÂΩ±ËßíÂ∫¶Â∫îÂÖ®Èù¢Â±ïÁ§∫ÊúçË£ÖÁöÑÁªÜËäÇ„ÄÇÊúüÊúõÁöÑÂú∫ÊôØËßÜËßíÊòØÊ®°ÁâπÊ≠£Èù¢ÂÖ®Ë∫´ÁÖßÔºåËµ∞ÈÅìÂë®Âõ¥Ë¢´Âº∫ÁÉàÁöÑÈáëËâ≤ÂÖâÁ∫øÁÖß‰∫ÆÔºåÂÖâÁ∫ø‰ªéÂÜÖÈÉ®Êï£ÂèëÂá∫Êù•*„ÄÇ‚Äù\n\n## ÁîüÊàêÁöÑÂõæÂÉè\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*YljCEFTIc8hslZbf.jpg)\n\n## ‰ªéÂõæÂÉèÁîüÊàêÁöÑÊïÖ‰∫ã\n\n*Ëøô‰ΩçË∫´ÁùÄÈáëÈì∂‰∫ÆÁâáÊúçË£ÖÂíåÈïøË£ôÁöÑÈÄâÁæéÁöáÂêéÁöÑÊÉäËâ≥ÊôØË±°Ë∂≥‰ª•ËÆ©‰ªª‰ΩïËßÇ‰ºóÈô∂ÈÜâ„ÄÇSashaya GnanavelÂú®ÂâçÊôØ‰∏≠ÊòæÂæóÊ†ºÂ§ñÂºï‰∫∫Ê≥®ÁõÆÔºåËá™‰ø°Âú∞Ëµ∞Âú®TÂè∞‰∏äÔºåÂê∏ÂºïÁùÄÁé∞Âú∫ËßÇ‰ºóÁöÑÁõÆÂÖâ„ÄÇÂ•πÊó∂Â∞öÁöÑÊúçË£ÖÔºåÊê≠ÈÖç‰ºòÈõÖÁöÑÁèçÁè†È°πÈìæÔºåÂê∏Âºï‰∫ÜÂú®Âú∫ÊØè‰∏Ä‰∏™‰∫∫ÁöÑÊ≥®ÊÑè„ÄÇËøô‰∏™Á≥ªÂàóÂ±ïÁ§∫‰∫ÜÈ≤úËâ≥ÁöÑËâ≤ÂΩ©ÂíåÈó™‰∫ÆÁöÑÂà∫Áª£ÔºåÂ¢ûÂä†‰∫ÜÊ¥ªÂä®ÁöÑÊï¥‰ΩìËßÜËßâÂê∏ÂºïÂäõ„ÄÇSashayaÂú®ËÅöÂÖâÁÅØ‰∏ãÁöÑËá™‰ø°‰∏éÁæé‰∏ΩÔºåÁúüÂÆûÂú∞ËØÅÊòé‰∫ÜÂ•πÂú®Êó∂Â∞öË°å‰∏öÁöÑÊâçÂçéÂíåÂ•âÁåÆ„ÄÇÂ•πÁöÑÂ¶ÜÂÆπ„ÄÅÁè†ÂÆùÂíåÁ≤æÁæéÊúçË£ÖÊâÄÂàõÈÄ†ÁöÑËÄÄÁúºÊïàÊûúÔºå‰∏∫ËÆæËÆ°ÂíåÂ∑•Ëâ∫ÁöÑÈùûÂá°Â±ïÁ§∫Â•†ÂÆö‰∫ÜËàûÂè∞„ÄÇËøô‰∏™Âºï‰∫∫Ê≥®ÁõÆÁöÑÂú∫ÊôØ encapsulates È≠îÂäõÂíåÂ•¢ÂçéÔºåËÆ©ËßÇ‰ºóÂØπËøô‰∏ÄÂàáÁöÑÁªùÁæéÊÑüÂà∞ÊÉäÂèπ„ÄÇ*\n\n## ‰ª£Á†ÅÂÆûÁé∞\n\nÂàõÂª∫ËôöÊãüÁéØÂ¢É\n\nË¶Å‰ΩøÁî® Python ÁöÑ venv Ê®°ÂùóÂàõÂª∫ËôöÊãüÁéØÂ¢ÉÔºåËØ∑ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Êìç‰ΩúÔºö\n\n* ÊâìÂºÄÁªàÁ´ØÊàñÂëΩ‰ª§ÊèêÁ§∫Á¨¶„ÄÇ\n* ÂØºËà™Âà∞ÊÇ®ÁöÑÈ°πÁõÆÁõÆÂΩïÔºàÊÇ®ÊÉ≥Ë¶ÅÂàõÂª∫ËôöÊãüÁéØÂ¢ÉÁöÑÂú∞ÊñπÔºâ„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî® cd ÂëΩ‰ª§Êõ¥ÊîπÁõÆÂΩï„ÄÇ‰æãÂ¶ÇÔºö\n\n```python\ncd path/to/your/project\n```\n\n* ÈÄöËøáËøêË°å‰ª•‰∏ãÂëΩ‰ª§ÂàõÂª∫ËôöÊãüÁéØÂ¢ÉÔºö\n\n```python\npython -m venv venv\n```\n\n* Ê≠§ÂëΩ‰ª§Â∞ÜÂú®ÊÇ®ÁöÑÈ°πÁõÆÊñá‰ª∂Â§π‰∏≠ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ venv ÁöÑÊñ∞ÁõÆÂΩïÔºåËØ•ÁõÆÂΩïÂ∞ÜÂåÖÂê´ËôöÊãüÁéØÂ¢ÉÔºàÂú® Windows ‰∏äÔºâ\n* ÊøÄÊ¥ªËôöÊãüÁéØÂ¢ÉÔºö\n\n```python\nvenv\\Scripts\\activate\n```\n\n* Êñá‰ª∂Â§πÁªìÊûÑ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*J3QJJACHVRtjrU1boxHUjA.png)\n\n* utils.py\n\n```python\nimport base64\nimport os\nfrom pydub import AudioSegment\n\ndef save_audio(audio_data):\n    # Decode the base64 audio data\n    audio_bytes = base64.b64decode(audio_data.split(\",\")[1])\n  \n    # Save the audio to a temporary file\n    temp_file = \"temp_audio.webm\"\n    with open(temp_file, \"wb\") as f:\n        f.write(audio_bytes)\n  \n    # Convert WebM to WAV\n    audio = AudioSegment.from_file(temp_file, format=\"webm\")\n    wav_file = \"temp_audio.wav\"\n    audio.export(wav_file, format=\"wav\")\n  \n    # Remove the temporary WebM file\n    os.remove(temp_file)\n  \n    return wav_file\n\ndef text_to_speech(text):\n    # Implement text-to-speech functionality if needed\n    pass\n```\n\n* main.py\n\n```python\n\"\"\"\n    1. ÈÄöËøáÈ∫¶ÂÖãÈ£éÂΩïÂà∂Èü≥È¢ë\n    2. Â∞ÜÈü≥È¢ëËΩ¨ÂΩï‰∏∫ÊñáÊú¨\n    3. ‰ΩøÁî® Groq Llama3 Ê®°ÂûãÁîüÊàêÂõæÂÉèÊèêÁ§∫\n    4. ‰ΩøÁî® Replicate.ai Flux Ê®°ÂûãÁîüÊàêÂõæÂÉè\n    5. ÊòæÁ§∫ÁîüÊàêÁöÑÂõæÂÉè\n    6. ‰∏ãËΩΩÁîüÊàêÁöÑÂõæÂÉè\n    Â∫îÁî®Á®ãÂ∫è‰ΩøÁî® DaisyUI Âíå Tailwind CSS ËøõË°åÊ†∑ÂºèËÆæÁΩÆÔºåÊèê‰æõÈªëÊöóÊ®°ÂºèÁïåÈù¢„ÄÇÂ∏ÉÂ±ÄÊòØÂìçÂ∫îÂºèÁöÑÔºåÂ∫îËØ•Âú®Ê°åÈù¢ÂíåÁßªÂä®ËÆæÂ§á‰∏äÈÉΩËÉΩËâØÂ•ΩËøêË°å„ÄÇ\nÊ≥®ÊÑèÔºöÊÇ®ÂèØËÉΩÈúÄË¶ÅÊ†πÊçÆÊÇ®‰ΩøÁî®ÁöÑÁâπÂÆö API ÂíåÊ®°Âûã‰ª•ÂèäÈÉ®ÁΩ≤ÁéØÂ¢ÉÁöÑÂÆâÂÖ®ÊÄßËÄÉËôëÊù•Ë∞ÉÊï¥‰ª£Á†ÅÁöÑÊüê‰∫õÈÉ®ÂàÜ„ÄÇ\n\n\"\"\"\nfrom fastapi import FastAPI, Request, HTTPException\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import JSONResponse, FileResponse\nfrom pydantic import BaseModel\nimport speech_recognition as sr\nfrom groq import Groq\nimport replicate\nimport os\nimport aiohttp\nimport aiofiles\nimport time\nfrom dotenv import load_dotenv\nload_dotenv()\nfrom .utils import text_to_speech, save_audio\nfrom PIL import Image\nimport io\nimport base64\nimport base64\n\n\n## Function to encode the image\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\napp = FastAPI()\n\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"templates\")\n\n## Initialize Groq client with the API key\nGROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\nif not GROQ_API_KEY:\n    raise ValueError(\"GROQ_API_KEY is not set in the environment variables\")\ngroq_client = Groq(api_key=GROQ_API_KEY)\n\nclass AudioData(BaseModel):\n    audio_data: str\n\nclass ImagePrompt(BaseModel):\n    prompt: str\n\nclass PromptRequest(BaseModel):\n    text: str\n\n## Add this new model\nclass FreeImagePrompt(BaseModel):\n    prompt: str\n    image_path: str\n\n@app.get(\"/\")\nasync def read_root(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n@app.post(\"/transcribe\")\nasync def transcribe_audio(audio_data: AudioData):\n    try:\n        # Save the audio data to a file\n        audio_file = save_audio(audio_data.audio_data)\n\n        # Transcribe the audio\n        recognizer = sr.Recognizer()\n        with sr.AudioFile(audio_file) as source:\n            audio = recognizer.record(source)\n        text = recognizer.recognize_google(audio)\n\n        return JSONResponse(content={\"text\": text})\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/generate_prompt\")\nasync def generate_prompt(prompt_request: PromptRequest):\n    try:\n        text = prompt_request.text\n        # Use Groq to generate a new prompt\n        response = groq_client.chat.completions.create(\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a creative assistant that generates prompts for realistic image generation.\"},\n                {\"role\": \"user\", \"content\": f\"Generate a detailed prompt for a realistic image based on this description: {text}.The prompt should be clear and detailed in no more than 200 words.\"}\n            ],\n            model=\"llama-3.1-70b-versatile\",\n            max_tokens=256\n        )\n        generated_prompt = response.choices[0].message.content\n        print(f\"tweaked prompt:{generated_prompt}\")\n        return JSONResponse(content={\"prompt\": generated_prompt})\n    except Exception as e:\n        print(f\"Error generating prompt: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/generate_image\")\nasync def generate_image(image_prompt: ImagePrompt):\n    try:\n        prompt = image_prompt.prompt\n        print(f\"Received prompt: {prompt}\")\n\n        # Use Replicate to generate an image\n        output = replicate.run(\n            \"black-forest-labs/flux-1.1-pro\",\n            input={\n                \"prompt\": prompt,\n                \"aspect_ratio\": \"1:1\",\n                \"output_format\": \"jpg\",\n                \"output_quality\": 80,\n                \"safety_tolerance\": 2,\n                \"prompt_upsampling\": True\n            }\n        )\n      \n        print(f\"Raw output: {output}\")\n        print(f\"Output type: {type(output)}\")\n      \n        # Convert the FileOutput object to a string\n        image_url = str(output)\n      \n        print(f\"Generated image URL: {image_url}\")\n      \n        return JSONResponse(content={\"image_url\": image_url})\n    except Exception as e:\n        print(f\"Error generating image: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/download_image\")\nasync def download_image(image_url: str):\n    try:\n        # Create Output folder if it doesn't exist\n        output_folder = \"Output\"\n        os.makedirs(output_folder, exist_ok=True)\n\n        # Generate a unique filename\n        filename = f\"generated_image_{int(time.time())}.jpg\"\n        filepath = os.path.join(output_folder, filename)\n\n        # Download the image\n        async with aiohttp.ClientSession() as session:\n            async with session.get(image_url) as resp:\n                if resp.status == 200:\n                    async with aiofiles.open(filepath, mode='wb') as f:\n                        await f.write(await resp.read())\n\n        # Return the filepath and filename\n        return JSONResponse(content={\n            \"filepath\": filepath,\n            \"filename\": filename\n        })\n    except Exception as e:\n        print(f\"Error downloading image: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\nclass StoryRequest(BaseModel):\n    filepath: str\n    filename: str\n\n@app.post(\"/generate_story_from_image\")\nasync def generate_story_from_image(content: StoryRequest):\n    try:\n        image_path = content.filepath\n        print(f\"Image path: {image_path}\")\n        # Check if the file exists\n        if not os.path.exists(image_path):\n            raise HTTPException(status_code=400, detail=\"Image file not found\")\n\n        # Getting the base64 string\n        base64_image = encode_image(image_path)\n\n        client = Groq()\n\n        chat_completion = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": \"Generate a clear,concise,meaningful and engaging cover story for a highly acclaimed leisure magazine based on the image provided. The story should keep the audience glued and engaged and the story should bewithin 200 words.\"},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                            },\n                        },\n                    ],\n                }\n            ],\n            model=\"llava-v1.5-7b-4096-preview\",\n        )\n\n        story = chat_completion.choices[0].message.content\n        print(f\"Generated story: {story}\")\n        return JSONResponse(content={\"story\": story})\n    except Exception as e:\n        print(f\"Error generating story from the image: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/download/{filename}\")\nasync def serve_file(filename: str):\n    file_path = os.path.join(\"Output\", filename)\n    return FileResponse(file_path, filename=filename)\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n* script.js\n\n```python\nlet mediaRecorder;\nlet audioChunks = [];\n\nconst startRecordingButton = document.getElementById('startRecording');\nconst stopRecordingButton = document.getElementById('stopRecording');\nconst recordingStatus = document.getElementById('recordingStatus');\nconst transcription = document.getElementById('transcription');\nconst generatePromptButton = document.getElementById('generatePrompt');\nconst generatedPrompt = document.getElementById('generatedPrompt');\nconst generateImageButton = document.getElementById('generateImage');\nconst generatedImage = document.getElementById('generatedImage');\nconst downloadLink = document.getElementById('downloadLink');\nconst generateStoryButton = document.getElementById('generateStory');\nconst generatedStory = document.getElementById('generatedStory');\n\nstartRecordingButton.addEventListener('click', startRecording);\nstopRecordingButton.addEventListener('click', stopRecording);\ngeneratePromptButton.addEventListener('click', generatePrompt);\ngenerateImageButton.addEventListener('click', generateImage);\ngenerateStoryButton.addEventListener('click', generateStory);\n\nasync function startRecording() {\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    mediaRecorder = new MediaRecorder(stream);\n\n    mediaRecorder.ondataavailable = (event) => {\n        audioChunks.push(event.data);\n    };\n\n    mediaRecorder.onstop = sendAudioToServer;\n\n    mediaRecorder.start();\n    startRecordingButton.disabled = true;\n    stopRecordingButton.disabled = false;\n    recordingStatus.textContent = 'Recording...';\n}\n\nfunction stopRecording() {\n    mediaRecorder.stop();\n    startRecordingButton.disabled = false;\n    stopRecordingButton.disabled = true;\n    recordingStatus.textContent = 'Recording stopped.';\n}\n\nasync function sendAudioToServer() {\n    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });\n    const reader = new FileReader();\n    reader.readAsDataURL(audioBlob);\n    reader.onloadend = async () => {\n        const base64Audio = reader.result;\n        const response = await fetch('/transcribe', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ audio_data: base64Audio }),\n        });\n        const data = await response.json();\n        transcription.textContent = `Transcription: ${data.text}`;\n        generatePromptButton.disabled = false;\n    };\n    audioChunks = [];\n}\n\nasync function generatePrompt() {\n    const text = transcription.textContent.replace('Transcription: ', '');\n    const response = await fetch('/generate_prompt', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ text: text }),\n    });\n    const data = await response.json();\n    generatedPrompt.textContent = `Generated Prompt: ${data.prompt}`;\n    generateImageButton.disabled = false;\n}\n\nasync function generateImage() {\n    const prompt = generatedPrompt.textContent.replace('Generated Prompt: ', '');\n    const response = await fetch('/generate_image', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ prompt: prompt }),\n    });\n    const data = await response.json();\n    generatedImage.src = data.image_url;\n  \n    // Download the image and get the filepath\n    const downloadResponse = await fetch(`/download_image?image_url=${encodeURIComponent(data.image_url)}`);\n    const downloadData = await downloadResponse.json();\n  \n    // Store the filepath and filename for later use\n    generatedImage.dataset.filepath = downloadData.filepath;\n    generatedImage.dataset.filename = downloadData.filename;\n\n    // Set up the download link\n    downloadLink.href = `/download/${downloadData.filename}`;\n    downloadLink.download = downloadData.filename;\n    downloadLink.style.display = 'inline-block';\n}\n\nasync function generateStory() {\n    const imagePath = generatedImage.dataset.filepath;\n    const filename = generatedImage.dataset.filename;\n  \n    if (!imagePath || !filename) {\n        generatedStory.textContent = \"Error: Please generate an image first.\";\n        return;\n    }\n\n    try {\n        const response = await fetch('/generate_story_from_image', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ filepath: imagePath, filename: filename }),\n        });\n        if (!response.ok) {\n            throw new Error(`HTTP error! status: ${response.status}`);\n        }\n        const data = await response.json();\n      \n        // Display the generated story\n        generatedStory.textContent = data.story;\n      \n        // Make sure the story container is visible\n        document.getElementById('storyContainer').style.display = 'block';\n    } catch (error) {\n        console.error('Error:', error);\n        generatedStory.textContent = `Error: ${error.message}`;\n    }\n}\n\n// Modify the download link click event\ndownloadLink.addEventListener('click', async (event) => {\n    event.preventDefault();\n    const response = await fetch(downloadLink.href);\n    const blob = await response.blob();\n    const url = window.URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.style.display = 'none';\n    a.href = url;\n    a.download = response.headers.get('Content-Disposition').split('filename=')[1];\n    document.body.appendChild(a);\n    a.click();\n    window.URL.revokeObjectURL(url);\n});\n```\n\n* style.css\n\n```python\nbody {\n    background-color: #1a1a2e;\n    color: #ffffff;\n}\n\n.container {\n    max-width: 1200px;\n}\n\n#imageContainer {\n    min-height: 300px;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    background-color: #16213e;\n    border-radius: 8px;\n}\n\n#generatedImage {\n    max-width: 100%;\n    max-height: 400px;\n    object-fit: contain;\n}\n```\n\n* index.html\n\n```python\n<!DOCTYPE html>\n<html lang=\"en\" data-theme=\"dark\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>AI ÂõæÂÉèÁîüÊàêÂô®</title>\n    <link href=\"https://cdn.jsdelivr.net/npm/daisyui@3.7.3/dist/full.css\" rel=\"stylesheet\" type=\"text/css\" />\n    <script src=\"https://cdn.tailwindcss.com\"></script>\n    <link rel=\"stylesheet\" href=\"{{ url_for('static', path='/css/styles.css') }}\">\n</head>\n<body>\n    <div class=\"container mx-auto px-4 py-8\">\n        <h1 class=\"text-4xl font-bold mb-8 text-center\">AI ÂõæÂÉèÁîüÊàêÂô®</h1>\n        <div class=\"grid grid-cols-1 md:grid-cols-2 gap-8\">\n            <div class=\"card bg-base-200 shadow-xl\">\n                <div class=\"card-body\">\n                    <h2 class=\"card-title mb-4\">ËØ¥Âá∫‰Ω†ÁöÑÊèêÁ§∫</h2>\n                    <button id=\"startRecording\" class=\"btn btn-primary mb-4\">ÂºÄÂßãÂΩïÈü≥</button>\n                    <button id=\"stopRecording\" class=\"btn btn-secondary mb-4\" disabled>ÂÅúÊ≠¢ÂΩïÈü≥</button>\n                    <div id=\"recordingStatus\" class=\"text-lg mb-4\"></div>\n                    <div id=\"transcription\" class=\"text-lg mb-4\"></div>\n                    <button id=\"generatePrompt\" class=\"btn btn-accent mb-4\" disabled>ÁîüÊàêÂõæÂÉèÊèêÁ§∫</button>\n                    <div id=\"generatedPrompt\" class=\"text-lg mb-4\"></div>\n                    <button id=\"generateImage\" class=\"btn btn-success\" disabled>ÁîüÊàêÂõæÂÉè</button>\n                </div>\n            </div>\n            <div class=\"card bg-base-200 shadow-xl\">\n                <div class=\"card-body\">\n                    <h2 class=\"card-title mb-4\">ÁîüÊàêÁöÑÂõæÂÉè</h2>\n                    <div id=\"imageContainer\" class=\"mb-4\">\n                        <img id=\"generatedImage\" src=\"\" alt=\"ÁîüÊàêÁöÑÂõæÂÉè\" class=\"w-full h-auto\">\n                    </div>\n                    <a id=\"downloadLink\" href=\"#\" download=\"generated_image.png\" class=\"btn btn-info\" style=\"display: none;\">‰∏ãËΩΩÂõæÂÉè</a>\n                </div>\n            </div>\n        </div>\n        <!-- Add this new section after the existing cards -->\n        <div class=\"card bg-base-200 shadow-xl mt-8\">\n            <div class=\"card-body\">\n                <h2 class=\"card-title mb-4\">‰ªéÂõæÂÉèÁîüÊàêÊïÖ‰∫ã</h2>\n                <button id=\"generateStory\" class=\"btn btn-primary mb-4\">ÁîüÊàêÊïÖ‰∫ã</button>\n                <div id=\"storyContainer\" class=\"mb-4\">\n                    <p id=\"generatedStory\" class=\"text-lg\"></p>\n                </div>\n            </div>\n        </div>\n    </div>\n    <script src=\"{{ url_for('static', path='/js/script.js') }}\"></script>\n</body>\n</html>\n```\n\n## ÁªìËÆ∫\n\nAIÂõæÂÉèÁîüÊàêÂô®ÂíåÊïÖ‰∫ãÂàõ‰ΩúÈ°πÁõÆÊàêÂäüÊï¥Âêà‰∫ÜÂêÑÁßçAIÊäÄÊúØÔºåÂàõÂª∫‰∫Ü‰∏Ä‰∏™‰∫íÂä®ÂºèWebÂ∫îÁî®Á®ãÂ∫èÔºåÂÖÅËÆ∏Áî®Êà∑Ê†πÊçÆÈü≥È¢ëÊèêÁ§∫ÁîüÊàêÂõæÂÉèÂíåÊïÖ‰∫ã„ÄÇÈÄöËøáÂà©Áî®FastAPI‰Ωú‰∏∫ÂêéÁ´ØÂíåÁé∞‰ª£ÂâçÁ´ØÊäÄÊúØÔºåËØ•Â∫îÁî®Á®ãÂ∫èÊèê‰æõ‰∫ÜÊó†ÁºùÁöÑÁî®Êà∑‰ΩìÈ™å„ÄÇ\n\n## ÂÖ≥ÈîÆË¶ÅÁÇπÔºö\n\n1. AIÊ®°ÂûãÁöÑÈõÜÊàêÔºöËØ•È°πÁõÆÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈõÜÊàêÂ§ö‰∏™AIÊ®°ÂûãÔºåÂåÖÊã¨Áî®‰∫éÊñáÊú¨ÁîüÊàêÁöÑGroqÂíåÁî®‰∫éÂõæÂÉèÁîüÊàêÁöÑReplicateÔºå‰ª•ÂàõÂª∫‰∏Ä‰∏™Â¢ûÂº∫Áî®Êà∑ÂàõÊÑèÁöÑÁªü‰∏ÄÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n2. Áî®Êà∑‰∫íÂä®ÔºöËØ•Â∫îÁî®Á®ãÂ∫èÂÖÅËÆ∏Áî®Êà∑ÈÄöËøáËØ≠Èü≥ÂëΩ‰ª§ËøõË°å‰∫íÂä®Ôºå‰ΩøÂÖ∂Êòì‰∫éËÆøÈóÆ‰∏îÁî®Êà∑ÂèãÂ•Ω„ÄÇÂΩïÈü≥„ÄÅËΩ¨ÂΩï‰ª•ÂèäÂü∫‰∫éËØ•ËæìÂÖ•ÁîüÊàêÂÜÖÂÆπÁöÑËÉΩÂäõÂ±ïÁ§∫‰∫ÜËØ≠Èü≥È©±Âä®Â∫îÁî®Á®ãÂ∫èÁöÑÊΩúÂäõ„ÄÇ\n3. Âä®ÊÄÅÂÜÖÂÆπÁîüÊàêÔºöÈÄöËøáÊ†πÊçÆÁî®Êà∑ËæìÂÖ•Âä®ÊÄÅÁîüÊàêÂõæÂÉèÂíåÊïÖ‰∫ãÔºåËØ•Â∫îÁî®Á®ãÂ∫èÁ™ÅÊòæ‰∫ÜAIÂú®ÂÜÖÂÆπÂàõ‰Ωú‰∏≠ÁöÑËÉΩÂäõÔºå‰∏∫Áî®Êà∑Êèê‰æõÁã¨Áâπ‰∏î‰∏™ÊÄßÂåñÁöÑËæìÂá∫„ÄÇ\n4. ÂìçÂ∫îÂºèËÆæËÆ°Ôºö‰ΩøÁî®DaisyUIÂíåTailwind CSSÁ°Æ‰øùÂ∫îÁî®Á®ãÂ∫èÂú®ËßÜËßâ‰∏äÂê∏Âºï‰∫∫‰∏îÂìçÂ∫îËøÖÈÄüÔºåÈÄÇÂ∫îÂêÑÁßçËÆæÂ§á‰∏äÁöÑÁî®Êà∑„ÄÇ\n5. Êú™Êù•Â¢ûÂº∫ÔºöËØ•È°πÁõÆÂèØ‰ª•ÈÄöËøáÂä†ÂÖ•È¢ùÂ§ñÂäüËÉΩËøõ‰∏ÄÊ≠•Â¢ûÂº∫Ôºå‰æãÂ¶ÇÁî®Êà∑Ë∫´‰ªΩÈ™åËØÅ„ÄÅ‰øùÂ≠òÁî®Êà∑ÁîüÊàêÁöÑÂÜÖÂÆπÔºå‰ª•ÂèäÊâ©Â±ïÁî®‰∫é‰∏çÂêåÂàõÊÑè‰ªªÂä°ÁöÑAIÊ®°ÂûãËåÉÂõ¥„ÄÇ\n\nÊÄª‰ΩìËÄåË®ÄÔºåËØ•È°πÁõÆ‰Ωú‰∏∫‰∏Ä‰∏™ÁªºÂêàÁ§∫‰æãÔºåÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÊûÑÂª∫‰∏Ä‰∏™ÁªìÂêàÈü≥È¢ëÂ§ÑÁêÜ„ÄÅÂõæÂÉèÁîüÊàêÂíåÊïÖ‰∫ãËÆ≤Ëø∞ÁöÑAIÈ©±Âä®ÁöÑÁΩëÁªúÂ∫îÁî®Á®ãÂ∫èÔºå‰∏∫ÂàõÊÑèÈ¢ÜÂüüÁöÑÂàõÊñ∞Â∫îÁî®Èì∫Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ\n\n## ÂèÇËÄÉÊñáÁåÆ\n\n* FastAPI ÊñáÊ°£: [FastAPI](https://fastapi.tiangolo.com/) ÊòØ‰∏Ä‰∏™Áé∞‰ª£ÁöÑ web Ê°ÜÊû∂ÔºåÁî®‰∫é‰ΩøÁî® Python ÊûÑÂª∫ API„ÄÇÂÆÉÊó®Âú®Êòì‰∫é‰ΩøÁî®‰∏îÂø´ÈÄü„ÄÇ\n* Pydantic: [Pydantic](https://pydantic-docs.helpmanual.io/) Áî®‰∫éÊï∞ÊçÆÈ™åËØÅÂíå‰ΩøÁî® Python Á±ªÂûãÊ≥®ÈáäÁöÑËÆæÁΩÆÁÆ°ÁêÜ„ÄÇ\n* Groq: [Groq](https://groq.com/docs/) ÊòØ‰∏Ä‰∏™ÊûÑÂª∫ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÁöÑÂπ≥Âè∞„ÄÇÂÆÉÊèê‰æõÊñáÊú¨ÁîüÊàêÂíåÂÖ∂‰ªñ AI ‰ªªÂä°ÁöÑ API„ÄÇ\n* Replicate: [Replicate](https://replicate.com/docs) ÊòØ‰∏Ä‰∏™ÂÖÅËÆ∏ÊÇ®Âú®‰∫ë‰∏≠ËøêË°åÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑÂπ≥Âè∞„ÄÇÂÆÉÊèê‰æõÂêÑÁßçÊ®°ÂûãÁöÑ APIÔºåÂåÖÊã¨ÂõæÂÉèÁîüÊàê„ÄÇ\n* SpeechRecognition: [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) ÊòØ‰∏Ä‰∏™ÊâßË°åËØ≠Èü≥ËØÜÂà´ÁöÑÂ∫ìÔºåÊîØÊåÅÂ§öÁßçÂºïÊìéÂíå API„ÄÇ\n* Pillow: [Pillow](https://pillow.readthedocs.io/en/stable/) ÊòØ Python Imaging Library (PIL) ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºå‰∏∫ÊÇ®ÁöÑ Python ‰ª£Á†ÅÊ∑ªÂä†ÂõæÂÉèÂ§ÑÁêÜËÉΩÂäõ„ÄÇ\n* JavaScript Fetch API: [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) Êèê‰æõ‰∫Ü‰∏ÄÁßçÁé∞‰ª£ÊñπÂºèÂú® JavaScript ‰∏≠ÂèëËµ∑ÁΩëÁªúËØ∑Ê±Ç„ÄÇ\n* HTML5 Èü≥È¢ë API: [HTML5 Audio API](https://developer.mozilla.org/en-US/docs/Web/API/HTMLAudioElement) ÂÖÅËÆ∏ÊÇ®Âú® web Â∫îÁî®Á®ãÂ∫è‰∏≠Êí≠ÊîæÈü≥È¢ëÊñá‰ª∂„ÄÇ\n* DaisyUI: [DaisyUI](https://daisyui.com/) ÊòØ‰∏Ä‰∏™‰∏∫ Tailwind CSS Êèê‰æõÈ¢ÑËÆæËÆ°ÁªÑ‰ª∂ÁöÑÁªÑ‰ª∂Â∫ì„ÄÇ\n* Tailwind CSS: [Tailwind CSS](https://tailwindcss.com/docs) ÊòØ‰∏Ä‰∏™ÂÆûÁî®‰ºòÂÖàÁöÑ CSS Ê°ÜÊû∂ÔºåÁî®‰∫éÂàõÂª∫Ëá™ÂÆö‰πâËÆæËÆ°ÔºåËÄåÊó†ÈúÄÁ¶ªÂºÄ HTML„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/ai-is-helping-me-manage-my-pre-diabetes-a115c1f7ed7b","frontmatter":{"title":"‰∫∫Â∑•Êô∫ËÉΩÂ∏ÆÂä©ÊàëÊéßÂà∂Á≥ñÂ∞øÁóÖÂâçÊúüÁóÖÊÉÖ","meta_title":"‰∫∫Â∑•Êô∫ËÉΩÂ∏ÆÂä©ÊàëÊéßÂà∂Á≥ñÂ∞øÁóÖÂâçÊúüÁóÖÊÉÖ","description":"ÊñáÁ´†Êé¢ËÆ®‰∫Ü‰ΩúËÄÖÂ¶Ç‰ΩïÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÊù•ÁÆ°ÁêÜÂâçÊúüÁ≥ñÂ∞øÁóÖÂíåÊéßÂà∂Ë°ÄÁ≥ñ„ÄÇ‰ΩúËÄÖÈÄöËøáÁõëÊµãÈ•ÆÈ£üÂíåË°ÄÁ≥ñÊ∞¥Âπ≥ÔºåÂà©Áî®ChatGPTÁîüÊàêÊï∞ÊçÆÂàÜÊûêÂíåÈ•ÆÈ£üÂª∫ËÆÆÔºå‰ªéËÄåÂÆûÁé∞ÂáèËÇ•ÂíåÊèêÈ´òËÉ∞Â≤õÁ¥†ÊïèÊÑüÊÄß„ÄÇ‰ΩúËÄÖÂº∫Ë∞É‰∫ÜÊäÄÊúØÂú®‰∏™‰∫∫ÂÅ•Â∫∑ÁÆ°ÁêÜ‰∏≠ÁöÑÊΩúÂäõÔºåÂπ∂ÂàÜ‰∫´‰∫ÜËá™Â∑±Âú®‰ΩøÁî®AIËøáÁ®ã‰∏≠ÂèñÂæóÁöÑÁßØÊûÅÊàêÊûúÔºåÂåÖÊã¨‰ΩìÈáçÂáèËΩªÂíåË°ÄÁ≥ñÊéßÂà∂ÁöÑÊîπÂñÑÔºåÂêåÊó∂ÊèêÈÜíËØªËÄÖÂ∫î‰∏éÂÅ•Â∫∑‰∏ì‰∏ö‰∫∫Â£´ËÆ®ËÆ∫Áõ∏ÂÖ≥ÈóÆÈ¢ò„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*oTD6Y3PWBiteGxzYcDhP-w.jpeg","categories":["Health","Chatbots","Data Science"],"author":"Rifx.Online","tags":["pre-diabetes","ChatGPT","blood-sugar","carbohydrates","weight-loss"],"draft":false,"slug":"blog/ai-is-helping-me-manage-my-pre-diabetes-a115c1f7ed7b"},"content":"\n## ÂÅ•Â∫∑ \\| Ë°ÄÁ≥ñ \\| Á≥ñÂ∞øÁóÖ\n\n\n\n## ÊàëÂ¶Ç‰ΩïÂà©Áî®ÊäÄÊúØÊéßÂà∂Ë°ÄÁ≥ñ„ÄÅÂáèËÇ•Âíå‰øùÊåÅÂÅ•Â∫∑\n\n\n\n*ÂÖçË¥£Â£∞ÊòéÔºöÊàë‰∏çÊòØÂåªÁîüÔºåÊú¨ÊñáÁöÑ‰ªª‰ΩïÈÉ®ÂàÜÈÉΩ‰∏çÂ∫îË¢´ËßÜ‰∏∫ÂåªÁñóÂª∫ËÆÆ„ÄÇÊàëÂàÜ‰∫´ÁöÑÊòØÊàëËá™Â∑±Âú®ÁÆ°ÁêÜÂáèËÇ•ÂíåÈÅøÂÖçÁ≥ñÂ∞øÁóÖÊñπÈù¢ÁöÑÊé¢Á¥¢„ÄÇ*\n\n*ÊÇ®ÊâÄÊúâÁöÑÂÅ•Â∫∑Êä§ÁêÜÈóÆÈ¢òÂíåÊåëÊàòÂ∫î‰∏éÊÇ®ÁöÑ‰∏™‰∫∫ÂÅ•Â∫∑Êä§ÁêÜ‰∏ì‰∏ö‰∫∫Â£´ËÆ®ËÆ∫„ÄÇÊú¨Êñá‰ªÖÂ∫îË¢´ËßÜ‰∏∫Â®±‰πêÂÜÖÂÆπÔºå**‰∏ç**Â∫îÁî®‰∫éÊïôËÇ≤ÊàñÂåªÁñó„ÄÇ*\n\n## Áé∞Áä∂\n\nÂ¶ÇÊûú‰Ω†‰∏ÄÁõ¥Âú®ÂÖ≥Ê≥®ÊàëÔºå‰Ω†‰ºöÁü•ÈÅìÊàëÂ§Ñ‰∫éÁ≥ñÂ∞øÁóÖÂâçÊúüÔºåÂπ∂‰∏î‰ΩìÈáçË∂ÖÊ†á„ÄÇÊúÄËøëÔºåÊàë‰∏ÄÁõ¥Âú®ËØïÂõæÂºÑÊ∏ÖÊ•öÊàëÊòØÂ¶Ç‰ΩïËµ∞Âà∞Ëøô‰∏ÄÊ≠•ÁöÑÔºå‰ª•ÂèäÊàëÊé•‰∏ãÊù•Â∫îËØ•ÂÅö‰ªÄ‰πà„ÄÇ\n\nÊàëÂÜ≥ÂÆöÁõ∏‰ø°ÊàëÊúâ‰∏ÄÁßçÈÅó‰º†ÂÄæÂêëÔºåÂØºËá¥Á≥ñÂ∞øÁóÖÁöÑÂèëÁîüÔºåËøôÊ∫ê‰∫éÊàë‰Ωú‰∏∫ÁªèÂéÜËøáÈ••ËçíÁöÑÂçó‰∫ö‰∫∫Âêé‰ª£ÁöÑËÉåÊôØ„ÄÇÊõ¥Ê∑±ÂÖ•ÁöÑÊé¢ËÆ® [Âú®ËøôÈáå](https://readmedium.com/i-finally-understand-why-im-pre-diabetic-and-obese-c9893f4c3187)„ÄÇ\n\nËøôÁßçÂÄæÂêë‰ΩøÂçó‰∫ö‰∫∫Ôºà[‰ª•ÂèäÂÖ∂‰ªñÁªèÂéÜËøáÈ••ËçíÁöÑ‰∫∫Áæ§](https://diabetesjournals.org/diabetes/article/61/9/2255/14753/Famine-Exposure-in-the-Young-and-the-Risk-of-Type)ÔºâÊõ¥ÂÆπÊòìÂèëÂ±ï‰∏∫Á≥ñÂ∞øÁóÖ„ÄÇ‰ºº‰πéÊàë‰ª¨ÁöÑÁ•ñÂÖà‰∏∫‰∫ÜÂú®ÈïøÊúüÁöÑÈ£üÁâ©Áü≠Áº∫‰∏≠ÁîüÂ≠òÔºåÂèçËÄåÈÄöËøá*ÊäëÂà∂*ËÉ∞Â≤õÁ¥†ÁöÑ‰∫ßÁîüÊù•ËøõÂåñ„ÄÇ\n\nËÉ∞Â≤õÁ¥†‰∫ßÁîüÁöÑÂèóÊçü‰ΩøÂæóË°ÄÁ≥ñÊ∞¥Âπ≥ËøúËøúË∂ÖÂá∫Ê≠£Â∏∏ËåÉÂõ¥ÔºåËôΩÁÑ∂ËøôÂèØ‰ª•Â¢ûÂä†‰ª•ËÑÇËÇ™ÂΩ¢ÂºèÂÇ®Â≠òÁöÑÈ£üÁâ©Ôºå‰ΩÜ‰πü‰ΩøÊàë‰ª¨Êõ¥ÂÆπÊòìÊÇ£‰∏äÁ≥ñÂ∞øÁóÖ„ÄÇ\n\nËøôÂØπÊàëÁöÑÁ•ñÂÖàÁîüÂ≠òÊòØÊúâÂ∏ÆÂä©ÁöÑÔºå‰ΩÜÂú®Èù¢‰∏¥È£üÁâ©‰∏∞ÁõàÁöÑÊó∂ÊúüÊó∂ÔºåËøôÁßçÁîüÂ≠òÊú∫Âà∂Âç¥Âá∫Áé∞‰∫ÜÈóÆÈ¢ò„ÄÇÊó†ËÆ∫ÊòØÂê¶ËÇ•ËÉñÔºåÊàë‰ª¨ÂèëÂ±ïÁ≥ñÂ∞øÁóÖÁöÑÂá†ÁéáËøúÈ´ò‰∫éÂá†‰πéÊâÄÊúâÂÖ∂‰ªñ‰∫∫Áæ§„ÄÇ\n\nËÄå‰∏îÔºåÂÉèÂ§ßÂ§öÊï∞Â§Ñ‰∫éÁ≥ñÂ∞øÁóÖÂâçÊúüÊàñÊÇ£Êúâ2ÂûãÁ≥ñÂ∞øÁóÖÁöÑÊÇ£ËÄÖ‰∏ÄÊ†∑ÔºåÊàë‰ª¨ÁöÑÈ•ÆÈ£ü‰∏≠‰πü‰ºöÊëÑÂÖ•ËøáÂ§öÁöÑÁ≥ñÂàÜÔºåÂèØËÉΩËøòÊúâËõãÁôΩË¥®ÂíåËÑÇËÇ™„ÄÇ\n\nÂõ†Ê≠§ÔºåÊàëÁöÑÂÅáËÆæÊòØ‚Äî‚Äî‰∏∫‰∫ÜÈÄÜËΩ¨Á≥ñÂ∞øÁóÖÂâçÊúüÔºåÊàëÈúÄË¶ÅÂú®Ëá™Â∑±ÁöÑÁîüÊ¥ª‰∏≠ÈáçÊñ∞ÂàõÈÄ†‰∫∫Â∑•È••ËçíÁöÑÊù°‰ª∂„ÄÇ\n\nÊàëÂ∞Ü‰∏çÂæó‰∏çÂáèÂ∞ë„ÄÅÂàáÈô§Âπ∂ÊîæÂºÉÈ•ÆÈ£ü‰∏≠Â§ö‰ΩôÁöÑÁ≥ñÂàÜ/Á¢≥Ê∞¥ÂåñÂêàÁâ©„ÄÅËõãÁôΩË¥®ÂíåËÑÇËÇ™ÔºåÂπ∂Âä†ÂÖ•ÈÄÇÂ∫¶ÁöÑÈîªÁÇºÔºå‰ª•‰øÉËøõÂáèËÇ•„ÄÇ\n\n## ËøõÂÖ•‰∫∫Â∑•Êô∫ËÉΩ\n\nÊàëÊØèÂ§©Êó©‰∏äÂú®Á¶ÅÈ£ü16-18Â∞èÊó∂ÂêéËÆ§ÁúüÁõëÊµãË°ÄÁ≥ñ„ÄÇËøáÂéª‰∏ÄÂë®ÔºåÊàëËßÇÂØüÂà∞Ë°ÄÁ≥ñÊ∞¥Âπ≥Âëà‰∏ãÈôçË∂ãÂäøÔºå‰ªé123 mg/dLÈôçËá≥100 mg/dL‰ª•‰∏ã„ÄÇËøô‰∏ÄÁõ¥ÊòØÊàëÁöÑÁõÆÊ†á„ÄÇ\n\nÊàëÊâÄÂÅöÁöÑÂ∞±ÊòØÂ∞ÜÊó•ÊúüÂíåËØªÊï∞ËæìÂÖ•ChatGPTÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉÁîüÊàê‰∏Ä‰∏™Ë°®Ê†º„ÄÇ‰ª•‰∏ãÊòØÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*UenRzbRpeCFUNFbVwtrxkg.png)\n\nÊàë‰ΩøÁî®ChatGPT‰ªîÁªÜË∑üË∏™‰∫ÜÊàëÁöÑÊØèÊó•Á¢≥Ê∞¥ÂåñÂêàÁâ©ÊëÑÂÖ•Èáè„ÄÇÂêåÊ†∑ÔºåÊàëÂáÜÁ°ÆÂú∞ËæìÂÖ•‰∫ÜÊàëÂêÉ‰∫Ü‰ªÄ‰πàÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉËÆ°ÁÆóÊàëÊëÑÂÖ•ÁöÑÁ¢≥Ê∞¥ÂåñÂêàÁâ©Êï∞ÈáèÔºåÂπ∂‰ª•Ë°®Ê†ºÁöÑÂΩ¢ÂºèÁªôÂá∫ÁªìÊûú„ÄÇ\n\nËØ∑Ê≥®ÊÑèÔºåÊàëÂè™Ë∑üË∏™‰∫Ü**Êàë**ÂêÉ‰∫Ü‰ªÄ‰πàÂíåÂ§öÂ∞ë„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÂÅö‰∫ÜÂÖ∂‰ΩôÁöÑÂ∑•‰Ωú„ÄÇ\n\n‰ª•‰∏ãÊòØÊàëÊò®Â§©ÁúãÂà∞ÁöÑÁªìÊûúÔºåËøôÊòØÊàë*Á¨¨‰∏ÄÊ¨°* fasting Ë°ÄÁ≥ñ‰Ωé‰∫éÊàëÁöÑÁõÆÊ†á100 mg/dLÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4YwDOMk2V7Leo5Wl4_5NGg.png)\n\nÊàëÊÉ≥Áü•ÈÅìÊàëÊëÑÂÖ•‰∫ÜÂ§öÂ∞ëÂç°Ë∑ØÈáåÔºåÊâÄ‰ª•ÊàëÁÆÄÂçïÂú∞Ë¶ÅÊ±ÇÂÆÉÊ†πÊçÆÊàëÂ∑≤ÁªèÊèê‰æõÁöÑÊï∞ÊçÆËÆ°ÁÆóÊàëÂêÉ‰∫ÜÂ§öÂ∞ëÂç°Ë∑ØÈáå„ÄÇÂÆÉÂæóÂá∫‰∫Ü‰ª•‰∏ãË°®Ê†ºÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AFAm5-SStY04-mQiCShRPg.png)\n\nÊàëÂøÖÈ°ªËØ¥‚Äî‚ÄîËøôÂ§™Ê£í‰∫Ü„ÄÇÊàë‰∏çÂÜçÈúÄË¶ÅÊâãÂä®Ë∑üË∏™ÊØè‰∏Ä‰∏™ÁªÜËäÇÔºåÂè™ÈúÄËæìÂÖ•‰∏ÄÊ¨°Êï∞ÊçÆÔºåÂ∞±ÂèØ‰ª•‰ª•‰∏çÂêåÁöÑÊñπÂºèËøõË°åÂ§ÑÁêÜ„ÄÇ\n\nÊàëËÆ°ÂàíÂú®Êú™Êù•ÊØèÂ§©Âú®ChatGPT‰∏≠ËæìÂÖ•ÊàëÁöÑÈ§êÈ£üÂíåË°ÄÁ≥ñÔºåÂπ∂ÁîüÊàêÊØèÊó•Êä•ÂëäÔºå‰ª•‰∫ÜËß£ÊàëÁöÑÈ•ÆÈ£üÂ¶Ç‰ΩïÂΩ±ÂìçÊàëÁöÑË°ÄÁ≥ñÔºåÁâπÂà´ÂÖ≥Ê≥®Á¢≥Ê∞¥ÂåñÂêàÁâ©ÊëÑÂÖ•ÈáèÂíåÈöèÂêéÁöÑ fasting Ë°ÄÁ≥ñ„ÄÇ\n\nÊ†πÊçÆËøô‰∫õÊï∞ÊçÆÔºåÊàëÂèØ‰ª•ÊâæÂá∫ÊòØ‰ªÄ‰πàÂØºËá¥ÊàëÁöÑË°ÄÁ≥ñË∂ÖËøá100 mg/dLÁöÑÁõÆÊ†áËØªÊï∞Ôºå‰ª•ÂèäÊòØ‰ªÄ‰πàËÆ©ÂÆÉ‰øùÊåÅÂú®ËåÉÂõ¥ÂÜÖ„ÄÇËøôÊòØÈíàÂØπÊàëÈúÄË¶ÅÁÆ°ÁêÜÁöÑÊÉÖÂÜµÁöÑÊúâÈíàÂØπÊÄß„ÄÅ‰∏™ÊÄßÂåñÁöÑÂ∏ÆÂä©„ÄÇÂØπÊàëÊù•ËØ¥ÔºåËøôÊïàÊûúÈùûÂ∏∏Â•Ω„ÄÇ\n\n## Ë°®Ê†ºÂπ∂‰∏çÊòØ‰∏ÄÂàá\n\nÁÑ∂ÂêéÊàëÈóÆÊàëÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰º¥‰æ£Ëøô‰∏™ÈóÆÈ¢òÔºö*‰Ω†ËÆ§‰∏∫Êàë‰ªäÂ§©ÁöÑÈ•ÆÈ£üÈÄÇÂêàÊ≠£Âú®Â∞ùËØïÂáèËÇ•ÂíåÊèêÈ´òËÉ∞Â≤õÁ¥†ÊïèÊÑüÊÄßÁöÑÂâçÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÂêóÔºü*\n\nÂÆÉËøîÂõûÁöÑÁ≠îÊ°àÂü∫‰∫éÊàëËæìÂÖ•ÁöÑÈ£üÁâ©Êï∞ÊçÆ„ÄÇËøôËÆ©ÊàëÊÑüÂà∞ÈúáÊÉä„ÄÇÂÆÉÂàÜÊûê‰∫ÜÊàëÂÖ∑‰ΩìÁöÑÈ£üÁâ©ÈÄâÊã©ÔºåÂπ∂ËøîÂõû‰∫ÜÂ§ö‰∏™ÁßØÊûÅÁöÑÊñπÈù¢Ôºå‰æãÂ¶ÇÔºö\n\n> **‰ΩéÁ¢≥Ê∞¥ÂåñÂêàÁâ©ÈÄâÊã©**Ôºö‰Ω†‰øùÊåÅ‰∫ÜÁõ∏ÂØπËæÉ‰ΩéÁöÑÁ¢≥Ê∞¥ÂåñÂêàÁâ©ÊëÑÂÖ•ÔºåËøôÂØπ‰∫éÂâçÁ≥ñÂ∞øÁóÖÁöÑË°ÄÁ≥ñÊéßÂà∂ÈùûÂ∏∏ÈáçË¶Å„ÄÇ‰Ω†ÁöÑÊÄªÁ¢≥Ê∞¥ÂåñÂêàÁâ©ÊëÑÂÖ•ÈáèÁ∫¶‰∏∫ **28.3‚Äì29.3 ÂÖã**ÔºåËøôÂú®ÈÄÇÂ∫¶‰ΩéÁ¢≥Ê∞¥ÂåñÂêàÁâ©ËåÉÂõ¥ÂÜÖ„ÄÇ\n\nÊé•ÁùÄÂÆÉÂª∫ËÆÆ‰∫Ü‰∏Ä‰∫õÊîπËøõÁöÑÈ¢ÜÂüüÔºåÂåÖÊã¨Ôºö\n\n> **Êõ¥Â§öÂÖ≥Ê≥®ÂùáË°°È•ÆÈ£ü**ÔºöËôΩÁÑ∂‰Ω†ÁöÑÈ•ÆÈ£üÊÄª‰Ωì‰∏äÊòØÂÅ•Â∫∑ÁöÑÔºå‰ΩÜ‰Ω†ÂèØËÉΩÊÉ≥Ë¶ÅÂ¢ûÂä†Êõ¥Â§öÁöÑÂ§öÊ†∑ÊÄßÂíåÂùáË°°„ÄÇ‰æãÂ¶ÇÔºåÂä†ÂÖ•ÈÄÇÈáèÁöÑ‰ΩéGIÊ∞¥ÊûúÔºàÂ¶Ç‰Ω†ÊâÄÂêÉÁöÑÊµÜÊûúÔºâ„ÄÅÂÖ®Ë∞∑Áâ©ÔºàÂ¶ÇÊûúÂèØ‰ª•ËÄêÂèóÔºâÊàñË±ÜÁ±ªÔºåÂèØËÉΩ‰ºöÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÊîπÂñÑËÉ∞Â≤õÁ¥†ÊïèÊÑüÊÄß„ÄÇ\n\nÊúÄÂêéÔºåÂÆÉÁªô‰∫ÜÊàë‰∏Ä‰∫õÊú™Êù•ÂèØ‰ª•ÈááÂèñÁöÑÂª∫ËÆÆÔºö\n\n> Áî®‰ΩéÁ¢≥Ê∞¥ÂåñÂêàÁâ©Êõø‰ª£ÂìÅÊõøÊç¢ÂÖ®ËÑÇÁâõÂ•∂„ÄÇ\n\n> Â¢ûÂä†Êõ¥Â§öÈùûÊ∑ÄÁ≤âÁ±ªËî¨ËèúÔºå‰ª•Â¢ûÂä†Á∫§Áª¥Âíå‰ΩìÁßØ„ÄÇ\n\n> ÁªßÁª≠ÂÖ≥Ê≥®ÂÅ•Â∫∑ËÑÇËÇ™ÂíåÁò¶ËõãÁôΩÔºå‰ΩÜË¶ÅÊ≥®ÊÑèÊï¥‰ΩìÁÉ≠ÈáèÊëÑÂÖ•Ôºå‰ª•Á¨¶Âêà‰Ω†ÁöÑÂáèËÇ•ÁõÆÊ†á„ÄÇ\n\n> ‰Ω†ÁöÑÈ•ÆÈ£üÈÄâÊã©Âú®ÁÆ°ÁêÜË°ÄÁ≥ñÂíå‰øÉËøõËÉ∞Â≤õÁ¥†ÊïèÊÑüÊÄßÊñπÈù¢Âü∫Êú¨ÈÄÇÂÆúÔºå‰ΩÜÁ®çÂæÆË∞ÉÊï¥ÂèØËÉΩ‰ºöËøõ‰∏ÄÊ≠•ÊîØÊåÅ‰Ω†ÁöÑÂáèËÇ•Âä™Âäõ„ÄÇ\n\n## ‰∏çË¶ÅÁõ∏‰ø°Êú∫Âô®\n\nÂ•ΩÁöÑÔºåÊàëÁü•ÈÅìËøôÊòØ‰∏ÄÂè∞Êú∫Âô®„ÄÇÊàëÁü•ÈÅìÊàë‰∏çËÉΩ‰æùËµñÂÆÉÁöÑÂª∫ËÆÆÔºå**‰Ω†‰πü‰∏çÂ∫îËØ•Ôºå‰∫≤Áà±ÁöÑËØªËÄÖ**„ÄÇ‰ΩÜÊòØÔºåÂ§©Âì™ÔºåÂÆÉÁªô‰∫ÜÊàëË∂≥Â§üÁöÑ‰ø°ÊÅØÔºå‰ª•‰æøÊàë‰∏ãÊ¨°ÂéªÁúãÂåªÁîüÊó∂ÂèØ‰ª•‰ΩøÁî®„ÄÇ\n\n‰∏çËøáÔºåÊàë‰ºöÂÆåÂÖ®ÂàáÊéâÂÖ®ËÑÇÁâõÂ•∂„ÄÇËøôÊòØÊòéÊô∫ÁöÑÂª∫ËÆÆ„ÄÇ\n\nÊàëËÆ°ÂàíÁîüÊàê‰∏Ä‰∏™Ë°ÄÁ≥ñ‰∏éÊó•ÊúüÁöÑË°®Ê†ºÔºåÂπ∂Â∏¶ÁªôÊàëÁöÑÂåªÁîüÔºåÂ¶ÇÊûúÂ•πËØ¢ÈóÆÊàëÁöÑÈ•ÆÈ£üÔºåÊàëÂèØ‰ª•ÈÄöËøá‰∏Ä‰∏™ÈìæÊé•‰∏éÂ•πÂàÜ‰∫´Êï¥‰∏™GPTËÅäÂ§©ËÆ∞ÂΩï„ÄÇËøôÊ†∑Â•πÂ∞±ÂèØ‰ª•Á°ÆÂàáÂú∞ÁúãÂà∞Êàë‰∏ÄÁõ¥Âú®ÂÅö‰ªÄ‰πà‚Äî‚ÄîÊó†ËÆ∫ÊòØÂØπÊòØÈîôÔºåÁÑ∂ÂêéÊ†πÊçÆÈúÄË¶ÅËøõË°åË∞ÉÊï¥„ÄÇ\n\nËøôÈöæÈÅì‰∏çÊòØÂ§™ÈÖ∑‰∫ÜÂêóÔºüÂæÆÁ¨ë„ÄÇ\n\n## ÁªìËÆ∫Ôºö\n\nÊàëÂØπÊòéÊô∫Âú∞‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÂÖÖÊª°ÁÉ≠ÊÉÖ„ÄÇËøôÊ¨°‰∏é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂØπËØùËÆ©ÊàëÊÑèËØÜÂà∞ÂèØ‰ª•Âà©Áî®‰∫∫Â∑•Êô∫ËÉΩÊù•ÁÆ°ÁêÜÊàë‰∏™‰∫∫ÁîüÊ¥ª‰∏≠Â§ßÈáèÈáçË¶ÅÊï∞ÊçÆÁöÑÂèØËÉΩÊÄß„ÄÇÊ≠£ÊòØÂõ†‰∏∫ÊàëÂú®‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÁõëÊµãÊàëÁöÑÈ•ÆÈ£üÂíåË°ÄÁ≥ñÔºåÊàëÊâçËÉΩÊõ¥Â•ΩÂú∞ÊéßÂà∂ÊàëÁöÑÁóÖÊÉÖ„ÄÇ\n\nÊàëËÉΩÂê¶Áî®ÈìÖÁ¨îÂíåËÆ∞‰∫ãÊú¨ÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºüÂèØ‰ª•„ÄÇ\n\n‰ΩÜËøôÂ∞ÜÈúÄË¶ÅÊõ¥Â§öÁöÑÊó∂Èó¥ÂíåÁ≤æÂäõÔºåÂπ∂‰∏î‰ºö‰∫ßÁîüÊõ¥Â§öÁöÑÊë©Êì¶„ÄÇÂêåÊó∂ÔºåÊàë‰πüÊó†Ê≥ïÂÉèÁé∞Âú®ËøôÊ†∑ËΩªÊùæÂú∞‰∏éÊÇ®ÂàÜ‰∫´ÊàëÁöÑÈ•ÆÈ£üÂíåÂâçÁ≥ñÂ∞øÁóÖÁÆ°ÁêÜÁöÑÁªÜËäÇ„ÄÇ\n\nËøòÊúâ‰∏Ä‰ª∂‰∫ã‚Äî‚ÄîÊàëÊ≤°ÊúâÊèêÂà∞ÊàëÁöÑÂáèËÇ•„ÄÇÂΩìÊàë‰∏§Âë®ÂâçÂºÄÂßãÊµãÈáè‰ΩìÈáçÊó∂ÔºåÊàëÁöÑ‰ΩìÈáçÊòØ225Á£Ö„ÄÇ‰ªäÂ§©ÊàëÁß∞ÈáçÊó∂ÊòØ219Á£Ö„ÄÇ**ÂáèÊéâÂÖ≠Á£Ö„ÄÇ**\n\nÊàëÂè™ËÉΩËØ¥ÔºåËøôÂØπÊàëÊúâÊïà„ÄÇËÄÉËôë‰∏Ä‰∏ãÂ¶Ç‰ΩïÂ∞Ü‰∫∫Â∑•Êô∫ËÉΩËûçÂÖ•Âà∞ÊÇ®ÁöÑÁîüÊ¥ª‰∏≠„ÄÇËøôÂØπÊüê‰∫õ‰∫∫Êù•ËØ¥ÂèØËÉΩ‰ºöÊÑüÂà∞ÂÆ≥ÊÄï„ÄÇÊàëÂ∑≤ÁªèÈÄÄ‰ºë‰∫ÜÔºå‰ΩÜÊàëÊâæÂà∞‰∫ÜÊñπÊ≥ï„ÄÇÊÇ®‰πüÂèØ‰ª•„ÄÇËøôÂæàÁÆÄÂçï„ÄÇÂ§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÊòØÂÖçË¥πÁöÑÔºåËÄå‰∏îÈùûÂ∏∏ÊúâÁî®„ÄÇ\n\nÊÇ®ËÆ§‰∏∫ÂèØ‰ª•‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÊù•Â∏ÆÂä©ÁÆ°ÁêÜÊÇ®ÁöÑÊÖ¢ÊÄßÂÅ•Â∫∑Áä∂ÂÜµÂêóÔºüÊàëÂæàÊÉ≥Áü•ÈÅì„ÄÇÂ¶ÇÊûúÊÇ®ÊÑøÊÑèÂ∞ùËØïÔºåÊÇ®Èù¢‰∏¥Âì™‰∫õÊåëÊàòÔºü‰πüËÆ∏Êàë‰ª¨ÂèØ‰ª•‰∏ÄËµ∑ÂÖãÊúçÂÆÉ‰ª¨„ÄÇ\n\nÂú®Ê≠§ÊúüÈó¥ÔºåÁ•ùÂ•Ω„ÄÇÁ±≥Âàá„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/ai-powered-ocr-with-phi-3-vision-128k-the-future-of-document-processing-7be80c46bd16","frontmatter":{"title":"ÈááÁî® Phi-3-Vision-128K ÁöÑ‰∫∫Â∑•Êô∫ËÉΩ OCRÔºöÊñáÊ°£Â§ÑÁêÜÁöÑÊú™Êù•","meta_title":"ÈááÁî® Phi-3-Vision-128K ÁöÑ‰∫∫Â∑•Êô∫ËÉΩ OCRÔºöÊñáÊ°£Â§ÑÁêÜÁöÑÊú™Êù•","description":"Âú®Âø´ÈÄüÂèëÂ±ïÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∏ñÁïå‰∏≠ÔºåÂ§öÊ®°ÂºèÊ®°ÂûãÊ≠£Âú®‰∏∫Êï¥ÂêàËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆËÆæÂÆöÊñ∞ÁöÑÊ†áÂáÜ‚Ä¶‚Ä¶","date":"2024-11-08T00:26:30.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BR-H6cQoyoRo6gVRqjvAyA.png","categories":["Natural Language Processing","Computer Vision","Data Science"],"author":"Rifx.Online","tags":["OCR","tokens","encoder","language","document"],"draft":false,"slug":"blog/ai-powered-ocr-with-phi-3-vision-128k-the-future-of-document-processing-7be80c46bd16"},"content":"\n\n\n\n\nÂú®Âø´ÈÄüÂèëÂ±ïÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÔºåÂ§öÊ®°ÊÄÅÊ®°ÂûãÊ≠£Âú®‰∏∫ËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆÁöÑÊï¥ÂêàËÆæÂÆöÊñ∞Ê†áÂáÜ„ÄÇÊúÄÊñ∞ÁöÑÁ™ÅÁ†¥‰πã‰∏ÄÊòØ **Phi\\-3\\-Vision\\-128K\\-Instruct**ÔºåËøôÊòØ‰∏Ä‰∏™ÊúÄÂÖàËøõÁöÑÂºÄÊîæÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊé®Âä®‰∫ÜAIÂú®Â§ÑÁêÜÂõæÂÉèÂíåÊñáÊú¨ÊñπÈù¢ÁöÑËÉΩÂäõËæπÁïå„ÄÇËØ•Ê®°Âûã‰∏ìÊ≥®‰∫éÊñáÊ°£ÊèêÂèñ„ÄÅÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´ÔºàOCRÔºâÂíå‰∏ÄËà¨ÂõæÂÉèÁêÜËß£ÔºåËÉΩÂ§üÂΩªÂ∫ïÊîπÂèòÊàë‰ª¨Â§ÑÁêÜPDF„ÄÅÂõæË°®„ÄÅË°®Ê†º‰ª•ÂèäÂÖ∂‰ªñÁªìÊûÑÂåñÊàñÂçäÁªìÊûÑÂåñÊñáÊ°£ÁöÑ‰ø°ÊÅØÊñπÂºè„ÄÇ\n\nËÆ©Êàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ®Phi\\-3\\-Vision\\-128K\\-InstructÁöÑÁªÜËäÇÔºåÊé¢Á¥¢ÂÖ∂Êû∂ÊûÑ„ÄÅÊäÄÊúØË¶ÅÊ±Ç„ÄÅË¥üË¥£‰ªªÁöÑ‰ΩøÁî®ËÄÉËôëÔºåÂπ∂‰∫ÜËß£ÂÆÉÂ¶Ç‰ΩïÁÆÄÂåñÊñáÊ°£ÊèêÂèñ„ÄÅPDFËß£ÊûêÂíåAIÈ©±Âä®ÁöÑÊï∞ÊçÆÂàÜÊûêÁ≠âÂ§çÊùÇ‰ªªÂä°„ÄÇ\n\n## ‰ªÄ‰πàÊòØ Phi\\-3\\-Vision\\-128K\\-InstructÔºü\n\nPhi\\-3\\-Vision\\-128K\\-Instruct Â±û‰∫é Phi\\-3 Ê®°ÂûãÁ≥ªÂàóÔºå‰∏ì‰∏∫Â§öÊ®°ÊÄÅÊï∞ÊçÆÂ§ÑÁêÜËÄåÊûÑÂª∫ÔºåÊîØÊåÅÊúÄÈïø **128,000 ‰∏™‰ª§Áâå** ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶„ÄÇËØ•Ê®°ÂûãÁªìÂêà‰∫ÜÊñáÊú¨ÂíåËßÜËßâÊï∞ÊçÆÔºåÈÄÇÂêàÈúÄË¶ÅÂêåÊó∂Ëß£ÈáäÊñáÊú¨ÂíåÂõæÂÉèÁöÑ‰ªªÂä°„ÄÇÂÖ∂ÂºÄÂèëÊ∂âÂèä **5000 ‰∫ø‰∏™ËÆ≠ÁªÉ‰ª§Áâå**ÔºåÁªìÂêà‰∫ÜÈ´òË¥®ÈáèÁöÑÂêàÊàêÊï∞ÊçÆÂíå‰∏•Ê†ºÁ≠õÈÄâÁöÑÂÖ¨ÂºÄÂèØÁî®Êù•Ê∫ê„ÄÇÈÄöËøáÂåÖÊã¨ **ÁõëÁù£ÂæÆË∞ÉÂíåÂÅèÂ•Ω‰ºòÂåñ** ÁöÑÁ≤æÁªÜËÆ≠ÁªÉËøáÁ®ãÔºåËØ•Ê®°ÂûãÊó®Âú®Êèê‰æõÁ≤æÁ°Æ„ÄÅÂèØÈù†ÂíåÂÆâÂÖ®ÁöÑ AI Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\nPhi\\-3\\-Vision\\-128K\\-Instruct Êã•Êúâ **42 ‰∫ø‰∏™ÂèÇÊï∞**ÔºåÂÖ∂Êû∂ÊûÑÂåÖÊã¨ÂõæÂÉèÁºñÁ†ÅÂô®„ÄÅËøûÊé•Âô®„ÄÅÊäïÂΩ±Âô®Âíå Phi\\-3 Mini ËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩøÂÖ∂Êàê‰∏∫ÂπøÊ≥õÂ∫îÁî®ÁöÑËΩªÈáèÁ∫ßËÄåÂº∫Â§ßÁöÑÈÄâÊã©„ÄÇ\n\n## Ê†∏ÂøÉÁî®‰æã\n\nËØ•Ê®°ÂûãÁöÑ‰∏ªË¶ÅÂ∫îÁî®Ë∑®Ë∂äÂ§ö‰∏™È¢ÜÂüüÔºåÁâπÂà´ÂÖ≥Ê≥®‰∫éÔºö\n\n* **ÊñáÊ°£ÊèêÂèñÂíåOCRÔºö** È´òÊïàÂú∞Â∞ÜÊñáÊú¨ÂõæÂÉèÊàñÊâ´ÊèèÊñáÊ°£ËΩ¨Êç¢‰∏∫ÂèØÁºñËæëÊ†ºÂºè„ÄÇÂÆÉÂèØ‰ª•Â§ÑÁêÜÂ§çÊùÇÁöÑÂ∏ÉÂ±ÄÔºåÂ¶ÇË°®Ê†º„ÄÅÂõæË°®ÂíåÂõæÁ§∫Ôºå‰ΩøÂÖ∂Êàê‰∏∫Êï∞Â≠óÂåñÂÆû‰ΩìÊñáÊ°£ÊàñËá™Âä®ÂåñÊï∞ÊçÆÊèêÂèñÂ∑•‰ΩúÊµÅÁöÑÂÆùË¥µÂ∑•ÂÖ∑„ÄÇ\n* **‰∏ÄËà¨ÂõæÂÉèÁêÜËß£Ôºö** Ëß£ÊûêËßÜËßâÂÜÖÂÆπ‰ª•ËØÜÂà´ÂØπË±°„ÄÅËß£ÈáäÂú∫ÊôØÂπ∂ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇ\n* **ÂÜÖÂ≠ò/ËÆ°ÁÆóÂèóÈôêÁéØÂ¢ÉÔºö** Âú®ËÆ°ÁÆóËÉΩÂäõÊàñÂÜÖÂ≠òÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ãËøêË°åAI‰ªªÂä°ÔºåËÄå‰∏çÂΩ±ÂìçÊÄßËÉΩ„ÄÇ\n* **Âª∂ËøüÂèóÈôêÂú∫ÊôØÔºö** Âú®ÂÆûÊó∂Â∫îÁî®‰∏≠ÂáèÂ∞ëÂ§ÑÁêÜÂª∂ËøüÔºå‰æãÂ¶ÇÂÆûÊó∂Êï∞ÊçÆÊµÅ„ÄÅÂü∫‰∫éËÅäÂ§©ÁöÑÂä©ÊâãÊàñÊµÅÂ™í‰ΩìÂÜÖÂÆπÂàÜÊûê„ÄÇ\n\n## Â¶Ç‰ΩïÂºÄÂßã‰ΩøÁî® Phi\\-3\\-Vision\\-128K\\-Instruct\n\nË¶Å‰ΩøÁî® Phi\\-3\\-Vision\\-128K\\-InstructÔºåÊÇ®ÈúÄË¶ÅËÆæÁΩÆÂºÄÂèëÁéØÂ¢ÉÔºåÂÆâË£ÖÊâÄÈúÄÁöÑÂ∫ìÂíåÂ∑•ÂÖ∑„ÄÇËØ•Ê®°ÂûãÈõÜÊàêÂú® Hugging Face `transformers` Â∫ìÁöÑÂºÄÂèëÁâàÊú¨ (4\\.40\\.2\\) ‰∏≠„ÄÇÂú®Ê∑±ÂÖ•‰ª£Á†ÅÁ§∫‰æã‰πãÂâçÔºåËØ∑Á°Æ‰øùÊÇ®ÁöÑ Python ÁéØÂ¢ÉÂ∑≤ÈÖçÁΩÆËøô‰∫õÂåÖÔºö\n\n```python\n## Required Packages\nflash_attn==2.5.8\nnumpy==1.24.4\nPillow==10.3.0\nRequests==2.31.0\ntorch==2.3.0\ntorchvision==0.18.0\ntransformers==4.40.2\n```\nË¶ÅÂä†ËΩΩÊ®°ÂûãÔºåÊÇ®ÂèØ‰ª•Êõ¥Êñ∞Êú¨Âú∞ÁöÑ `transformers` Â∫ìÔºåÊàñËÄÖÁõ¥Êé•‰ªéÊ∫ê‰ª£Á†ÅÂÖãÈöÜÂπ∂ÂÆâË£ÖÔºö\n\n```python\npip uninstall -y transformers && pip install git+https://github.com/huggingface/transformers\n```\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ËøõÂÖ•‰∏Ä‰∫õÂÆûÈôÖÁöÑ‰ª£Á†ÅÁâáÊÆµÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂà©Áî®Ëøô‰∏™Âº∫Â§ßÁöÑÊ®°ÂûãËøõË°å AI È©±Âä®ÁöÑÊñáÊ°£ÊèêÂèñÂíåÊñáÊú¨ÁîüÊàê„ÄÇ\n\n## Âä†ËΩΩÊ®°ÂûãÁöÑÁ§∫‰æã‰ª£Á†Å\n\nËøôÈáåÊúâ‰∏Ä‰∏™ Python Á§∫‰æãÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàùÂßãÂåñÊ®°ÂûãÂπ∂ÂºÄÂßãËøõË°åÊé®Êñ≠„ÄÇÊàë‰ª¨Â∞ÜÂà©Áî®Á±ªÂíåÂáΩÊï∞‰Ωø‰ª£Á†Å‰øùÊåÅÊï¥Ê¥ÅÂíåÊúâÂ∫èÔºö\n\n```python\nfrom PIL import Image\nimport requests\nfrom transformers import AutoModelForCausalLM, AutoProcessor\n\nclass Phi3VisionModel:\n    def __init__(self, model_id=\"microsoft/Phi-3-vision-128k-instruct\", device=\"cuda\"):\n        \"\"\"\n        ‰ΩøÁî®ÊåáÂÆöÁöÑÊ®°Âûã ID ÂíåËÆæÂ§áÂàùÂßãÂåñ Phi3VisionModel„ÄÇ\n        \n        ÂèÇÊï∞Ôºö\n            model_id (str): Êù•Ëá™ Hugging Face Ê®°ÂûãÂ∫ìÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÊ†áËØÜÁ¨¶„ÄÇ\n            device (str): Âä†ËΩΩÊ®°ÂûãÁöÑËÆæÂ§áÔºà\"cuda\" Ë°®Á§∫ GPUÔºåÊàñ \"cpu\"Ôºâ„ÄÇ\n        \"\"\"\n        self.model_id = model_id\n        self.device = device\n        self.model = self.load_model()  # Âú®ÂàùÂßãÂåñÊó∂Âä†ËΩΩÊ®°Âûã\n        self.processor = self.load_processor()  # Âú®ÂàùÂßãÂåñÊó∂Âä†ËΩΩÂ§ÑÁêÜÂô®\n    \n    def load_model(self):\n        \"\"\"\n        Âä†ËΩΩÂÖ∑ÊúâÂõ†ÊûúËØ≠Ë®ÄÂª∫Ê®°ËÉΩÂäõÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n        \n        ËøîÂõûÔºö\n            model (AutoModelForCausalLM): Âä†ËΩΩÁöÑÊ®°Âûã„ÄÇ\n        \"\"\"\n        print(\"Âä†ËΩΩÊ®°Âûã‰∏≠...\")\n        # ‰ΩøÁî®Ëá™Âä®ËÆæÂ§áÊò†Â∞ÑÂíåÊï∞ÊçÆÁ±ªÂûãË∞ÉÊï¥Âä†ËΩΩÊ®°Âûã\n        return AutoModelForCausalLM.from_pretrained(\n            self.model_id, \n            device_map=\"auto\",  # Ëá™Âä®Â∞ÜÊ®°ÂûãÊò†Â∞ÑÂà∞ÈÄÇÂΩìÁöÑËÆæÂ§á\n            torch_dtype=\"auto\",  # Ê†πÊçÆËÆæÂ§á‰ΩøÁî®ÂêàÈÄÇÁöÑ torch Êï∞ÊçÆÁ±ªÂûã\n            trust_remote_code=True,  # ÂÖÅËÆ∏ÊâßË°åËá™ÂÆö‰πâ‰ª£Á†Å‰ª•Âä†ËΩΩÊ®°Âûã\n            _attn_implementation='flash_attention_2'  # ‰ΩøÁî®‰ºòÂåñÁöÑÊ≥®ÊÑèÂäõÂÆûÁé∞\n        ).to(self.device)  # Â∞ÜÊ®°ÂûãÁßªÂä®Âà∞ÊåáÂÆöËÆæÂ§á\n    \n    def load_processor(self):\n        \"\"\"\n        Âä†ËΩΩ‰∏éÊ®°ÂûãÂÖ≥ËÅîÁöÑÂ§ÑÁêÜÂô®Ôºå‰ª•Â§ÑÁêÜËæìÂÖ•ÂíåËæìÂá∫„ÄÇ\n        \n        ËøîÂõûÔºö\n            processor (AutoProcessor): Áî®‰∫éÂ§ÑÁêÜÊñáÊú¨ÂíåÂõæÂÉèÁöÑÂä†ËΩΩÂ§ÑÁêÜÂô®„ÄÇ\n        \"\"\"\n        print(\"Âä†ËΩΩÂ§ÑÁêÜÂô®‰∏≠...\")\n        # ‰ΩøÁî® trust_remote_code=True Âä†ËΩΩÂ§ÑÁêÜÂô®Ôºå‰ª•Â§ÑÁêÜ‰ªª‰ΩïËá™ÂÆö‰πâÂ§ÑÁêÜÈÄªËæë\n        return AutoProcessor.from_pretrained(self.model_id, trust_remote_code=True)\n    \n    def predict(self, image_url, prompt):\n        \"\"\"\n        ‰ΩøÁî®Ê®°ÂûãÊ†πÊçÆÁªôÂÆöÁöÑÂõæÂÉèÂíåÊèêÁ§∫ËøõË°åÈ¢ÑÊµã„ÄÇ\n        \n        ÂèÇÊï∞Ôºö\n            image_url (str): Ë¶ÅÂ§ÑÁêÜÁöÑÂõæÂÉèÁöÑ URL„ÄÇ\n            prompt (str): ÊåáÂØºÊ®°ÂûãÁîüÊàêÁöÑÊñáÊú¨ÊèêÁ§∫„ÄÇ\n        \n        ËøîÂõûÔºö\n            response (str): Ê®°ÂûãÁîüÊàêÁöÑÂìçÂ∫î„ÄÇ\n        \"\"\"\n        # ‰ªéÊèê‰æõÁöÑ URL Âä†ËΩΩÂõæÂÉè\n        image = Image.open(requests.get(image_url, stream=True).raw)\n        \n        # ‰∏∫Ê®°ÂûãÊ†ºÂºèÂåñËæìÂÖ•ÊèêÁ§∫Ê®°Êùø\n        prompt_template = f\"<|user|>\\n<|image_1|>\\n{prompt}<|end|>\\n<|assistant|>\\n\"\n        \n        # Â§ÑÁêÜËæìÂÖ•ÔºåÂ∞ÜÊèêÁ§∫ÂíåÂõæÂÉèËΩ¨Êç¢‰∏∫Âº†ÈáèÊ†ºÂºè\n        inputs = self.processor(prompt_template, [image], return_tensors=\"pt\").to(self.device)\n        \n        # ËÆæÁΩÆÊ®°ÂûãÂìçÂ∫îÁîüÊàêÁöÑÂèÇÊï∞\n        generation_args = {\n            \"max_new_tokens\": 500,  # ÊúÄÂ§ßÁîüÊàêÁöÑ‰ª§ÁâåÊï∞\n            \"temperature\": 0.7,     # ÁîüÊàê‰∏≠ÁöÑÈááÊ†∑Ê∏©Â∫¶‰ª•Â¢ûÂä†Â§öÊ†∑ÊÄß\n            \"do_sample\": False      # Á¶ÅÁî®ÈááÊ†∑‰ª•Ëé∑ÂæóÁ°ÆÂÆöÊÄßËæìÂá∫\n        }\n        print(\"ÁîüÊàêÂìçÂ∫î‰∏≠...\")\n        # ‰ΩøÁî®Ê®°ÂûãÁîüÊàêËæìÂá∫ IDÔºåË∑≥ËøáËæìÂÖ•‰ª§Áâå\n        output_ids = self.model.generate(**inputs, **generation_args)\n        output_ids = output_ids[:, inputs['input_ids'].shape[1]:]  # ÂøΩÁï•ËæìÂá∫‰∏≠ÁöÑËæìÂÖ•ÊèêÁ§∫\n        \n        # Ëß£Á†ÅÁîüÊàêÁöÑËæìÂá∫‰ª§Áâå‰ª•Ëé∑ÂèñÂìçÂ∫îÊñáÊú¨\n        response = self.processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n        return response\n\n## ÂàùÂßãÂåñÊ®°Âûã\nphi_model = Phi3VisionModel()\n\n## Á§∫‰æãÈ¢ÑÊµã\nimage_url = \"https://example.com/sample_image.png\"  # Á§∫‰æãÂõæÂÉèÁöÑ URL\nprompt = \"‰ª• json Ê†ºÂºèÊèêÂèñÊï∞ÊçÆ„ÄÇ\"  # Ê®°ÂûãÊåáÂØºÁöÑÊèêÁ§∫\nresponse = phi_model.predict(image_url, prompt)  # ‰ªéÊ®°ÂûãËé∑ÂèñÂìçÂ∫î\n\nprint(\"ÂìçÂ∫î:\", response)  # ÊâìÂç∞ÁîüÊàêÁöÑÂìçÂ∫î\n```\n‰∏äËø∞‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ `Phi3VisionModel` Á±ªÔºåÊäΩË±°‰∫ÜÊ®°ÂûãÁöÑÂä†ËΩΩÂíå‰ΩøÁî®Ôºå‰ΩøÂÖ∂Êõ¥ÂÆπÊòìÈõÜÊàêÂà∞ÊÇ®ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏≠„ÄÇ`predict()` ÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Ëá™ÂÆö‰πâÊèêÁ§∫ËøõË°åÂü∫‰∫éÂõæÂÉèÁöÑÊé®Êñ≠„ÄÇ\n\n‰∏∫‰∫ÜÊõ¥Êñ∞ÊñáÁ´†Ôºå‰æßÈáç‰∫éÊµãËØï Phi-3-Vision-128K-Instruct Ê®°ÂûãÁöÑ OCR ËÉΩÂäõÔºåÊàë‰ª¨Â∞ÜÊ∑ªÂä†‰∏Ä‰∏™ÈÉ®ÂàÜÔºåËØ¶ÁªÜËØ¥ÊòéÊ®°ÂûãÂú®Â§ÑÁêÜÊâ´ÊèèÁöÑË∫´‰ªΩËØÅÁ≠âÂÆûÈôÖÁ§∫‰æãÊó∂ÁöÑË°®Áé∞„ÄÇ\n\n## ÊµãËØï OCR ÂäüËÉΩ‰∏éÊâ´ÊèèÁöÑË∫´‰ªΩËØÅ‰ª∂\n\n‰∏∫‰∫ÜËØÑ‰º∞ Phi\\-3\\-Vision\\-128K\\-Instruct Ê®°ÂûãÁöÑ OCR ÊÄßËÉΩÔºåÊàë‰ª¨‰ΩøÁî®Âá†Âº†ÁúüÂÆûÁöÑÊâ´ÊèèË∫´‰ªΩËØÅ‰ª∂ÂõæÂÉèËøõË°å‰∫ÜÊµãËØï„ÄÇËøô‰∫õÂõæÂÉèÂú®Ë¥®ÈáèÂíåÊ∏ÖÊô∞Â∫¶‰∏äÂêÑ‰∏çÁõ∏ÂêåÔºå‰∏∫Ê®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÁ≥ªÂàóÊåëÊàò„ÄÇÁõÆÊ†áÊòØÂ±ïÁ§∫Ê®°ÂûãÂú®ÊèêÂèñÂÖ∑Êúâ‰∏çÂêåÁâπÂæÅÁöÑÊñáÊ°£‰∏≠ÁöÑÊñáÊú¨‰ø°ÊÅØÊñπÈù¢ÁöÑË°®Áé∞ÔºåÂ¶ÇÊ®°Á≥ä„ÄÅÂ§çÊùÇËÉåÊôØÂíå‰∏çÂêåÁöÑÂ≠ó‰Ωì„ÄÇ\n\n**ÂõæÂÉè 1Ôºö** ‰∏ÄÊú¨ËôöÊûÑÁöÑ‰πåÊâòÈÇ¶Êä§ÁÖßÔºåÂåÖÂê´ËØ¶ÁªÜÁöÑÊñáÊú¨ÔºåÂåÖÊã¨‰∏™‰∫∫‰ø°ÊÅØÔºåÂ¶ÇÂßìÂêç„ÄÅÂõΩÁ±ç„ÄÅÂá∫ÁîüÂú∞„ÄÅÁ≠æÂèëÊó•ÊúüÂíåÂà∞ÊúüÊó•Êúü„ÄÇÊñáÊú¨Áï•ÊòæÈ£éÊ†ºÂåñÔºåÂ∫ïÈÉ®ÊúâÊú∫Âô®ÂèØËØªÂå∫„ÄÇÂõæÂÉèË¥®ÈáèÈ´òÔºåÊ≤°ÊúâÊòéÊòæÁöÑËÉåÊôØÂô™Â£∞„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MltpseOI3HhvCkUZMwLdEQ.png)\n\n**ËæìÂá∫Ôºö**\n\n\n```python\n{\n  \"Type/Type\": \"P\",\n  \"Country code/Code du pays\": \"UTO\",\n  \"Passport Number/N¬∞ de passeport\": \"L898902C3\",\n  \"Surname/Nom\": \"ERIKSSON\",\n  \"Given names/Pr√©noms\": \"ANNA MARIA\",\n  \"Nationality/Nationalit√©\": \"UTOPIAN\",\n  \"Date of Birth/Date de naissance\": \"12 AUGUST/AOUT 74\",\n  \"Personal No./N¬∞ personnel\": \"Z E 184226 B\",\n  \"Sex/Sexe\": \"F\",\n  \"Place of birth/Lieu de naissance\": \"ZENITH\",\n  \"Date of issue/Date de d√©livrance\": \"16 APR/AVR 07\",\n  \"Authority/Autorit√©\": \"PASSPORT OFFICE\",\n  \"Date of expiry/Date d'expiration\": \"15 APR/AVR 12\",\n  \"Holder's signature/Signature du titulaire\": \"anna maria eriksson\",\n  \"Passport/Passeport\": \"P<UTOERIKSSON<<ANNA<MARIA<<<<<<<<<<<<<<<<<<<<<<<L898902C36UT07408122F1204159ZE184226B<<<<10\"\n}\n```\n**ÂõæÂÉè 2Ôºö** ‰∏ÄÊú¨Ëç∑ÂÖ∞Êä§ÁÖßÔºåÊ∏ÖÊô∞Âú∞ÊòæÁ§∫ÊåÅÊúâ‰∫∫ÂíåÊï¥ÈΩêÊ†ºÂºèÂåñÁöÑÊñáÊú¨„ÄÇÂ≠óÊÆµÂåÖÊã¨Êä§ÁÖßÂè∑Á†Å„ÄÅÂßìÂêç„ÄÅÂá∫ÁîüÊó•Êúü„ÄÅÂõΩÁ±çÂíåÂà∞ÊúüÊó•Êúü„ÄÇËØ•Êñá‰ª∂ÂëàÁé∞Âá∫È´òÂØπÊØîÂ∫¶Ôºå‰ΩøÊñáÊú¨ÊèêÂèñÁõ∏ÂØπÁÆÄÂçï„ÄÇÂ∫ïÈÉ®ÁöÑÊú∫Âô®ÂèØËØªÂå∫ (MRZ) Êèê‰æõ‰∫Ü‰∏ÄÁßçÁªìÊûÑÂåñÁöÑÊï∞ÊçÆÊ†ºÂºèÔºåÊúâÂä©‰∫éÈ™åËØÅÊèêÂèñ‰ø°ÊÅØÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WGV4tTxI9xISmAvFs8ovNw.png)\n\n**ËæìÂá∫Ôºö**\n\n\n```python\nHere's the extracted full data from the passport in JSON format:\n\n{\n  \"passport\": {\n    \"issuingCountry\": \"Netherlands\",\n    \"issuingAuthority\": \"Koninkrijk der Nederlanden\",\n    \"passportNumber\": \"SPEC12014\",\n    \"issuingDate\": \"09 MAR 2014\",\n    \"expiryDate\": \"09 MAR 2024\",\n    \"holder\": {\n      \"gender\": \"F\",\n      \"nationality\": \"Netherlands\",\n      \"placeOfBirth\": \"SPECIMEN\",\n      \"sex\": \"WF\",\n      \"firstNames\": [\n        \"Willem\",\n        \"Lieselotte\"\n      ]\n    },\n    \"physicalDescription\": {\n      \"height\": \"1.75 m\",\n      \"hairColor\": \"gray\",\n      \"hairLength\": \"short\"\n    },\n    \"issuingOffice\": \"Burg. van Stad en Dorp\",\n    \"issuingDateAsInt\": \"14032014\",\n    \"expiryDateAsInt\": \"14032024\",\n    \"fieldsExtracted\": [\n      {\n        \"code\": \"NL\",\n        \"dateOfBirth\": \"10 MAR 1965\",\n        \"dateOfIssue\": \"09 MAR 2014\",\n        \"dateOfExpiry\": \"09 MAR 2024\",\n        \"firstNames\": [\n          \"Willem\",\n          \"Lieselotte\"\n        ],\n        \"nationality\": \"Netherlands\",\n        \"passportNumber\": \"SPEC12014\",\n        \"placeOfBirth\": \"SPECIMEN\",\n        \"sex\": \"WF\"\n      }\n    ]\n  }\n}\n```\n\n## Â∞ùËØï Phi\\-3\\-Vision\\-128K\\-Instruct\n\nÂ¶ÇÊûúÊÇ®ÊÉ≥‰∫≤Ëá™Â∞ùËØï Phi\\-3\\-Vision\\-128K\\-Instruct Ê®°ÂûãÔºåÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÈìæÊé•ËøõË°åÊé¢Á¥¢Ôºö[Âú® Azure AI ‰∏äÂ∞ùËØï Phi\\-3\\-Vision\\-128K\\-Instruct](https://ai.azure.com/explore/models/Phi-3-vision-128k-instruct/version/1/registry/azureml)„ÄÇËØ•ÈìæÊé•ÂÖÅËÆ∏ÊÇ®‰ΩìÈ™åÊ®°ÂûãÁöÑÂäüËÉΩÂπ∂ÂÆûÈ™åÂÖ∂ OCR ÂäüËÉΩ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7feNu3ZuclgAnAzbJMMSFg.png)\n\n## ÁêÜËß£Êû∂ÊûÑ‰∏éËÆ≠ÁªÉ\n\n**Phi\\-3\\-Vision\\-128K\\-Instruct** Ê®°Âûã‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°Âûã‚Äî‚ÄîÂÆÉÊòØ‰∏Ä‰∏™Â§öÊ®°ÊÄÅÂº∫ËÄÖÔºåËÉΩÂ§üÂ§ÑÁêÜËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆ„ÄÇÂÆÉÁªèÂéÜ‰∫ÜÂÖ®Èù¢ÁöÑËÆ≠ÁªÉËøáÁ®ãÔºåÂåÖÂê´ **5000‰∫ø‰∏™Ê†áËÆ∞**ÔºåÁªìÂêà‰∫ÜÊñáÊú¨ÂíåÂõæÂÉèÊï∞ÊçÆ„ÄÇÂÖ∂Êû∂ÊûÑÊï¥Âêà‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÂíåÂõæÂÉèÂ§ÑÁêÜÊ®°ÂùóÔºåÂàõÂª∫‰∫Ü‰∏Ä‰∏™ËÉΩÂ§üÁêÜËß£ **128K ‰∏™Ê†áËÆ∞** ‰∏ä‰∏ãÊñáÁöÑÁªü‰∏ÄÁ≥ªÁªüÔºåÊîØÊåÅÊõ¥ÈïøÁöÑÂØπËØùÊàñÂ§ßÈáèÂÜÖÂÆπÁöÑÊñáÊ°£„ÄÇ\n\nÂú®Âº∫Â§ßÁöÑÁ°¨‰ª∂‰∏äËÆ≠ÁªÉÔºå‰æãÂ¶Ç **512 H100 GPUs**ÔºåÂπ∂Âà©Áî® **flash attention** ÊèêÈ´òÂÜÖÂ≠òÊïàÁéáÔºåËøô‰∏™Ê®°ÂûãËÉΩÂ§üËΩªÊùæÂ§ÑÁêÜÂ§ßËßÑÊ®°‰ªªÂä°„ÄÇËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂåÖÊã¨ÂêàÊàêÊï∞ÊçÆÂíåÁªèËøáÁ≠õÈÄâÁöÑÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÔºåÂº∫Ë∞É **Êï∞Â≠¶„ÄÅÁºñÁ†Å„ÄÅÂ∏∏ËØÜÊé®ÁêÜ** Âíå **‰∏ÄËà¨Áü•ËØÜ**Ôºå‰ΩøÂÖ∂Ë∂≥Â§üÁÅµÊ¥ª‰ª•ÈÄÇÂ∫îÂêÑÁßçÂ∫îÁî®„ÄÇ\n\n## ÂÖ≥ÈîÆÂü∫ÂáÜÂíåÊÄßËÉΩ\n\nPhi\\-3\\-Vision\\-128K\\-Instruct ÁöÑÊÄßËÉΩÂ∑≤ÁªèÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ËøõË°åËØÑ‰º∞ÔºåÂåÖÊã¨ **ScienceQA**„ÄÅ**AI2D**„ÄÅ**MathVista** Âíå **TextVQA**„ÄÇÂÆÉÁöÑÂæóÂàÜÂú®ÁªìÂêàÊñáÊú¨ÂíåËßÜËßâÁöÑ‰ªªÂä°‰∏≠ÂßãÁªàË∂ÖËøáËÆ∏Â§öÁé∞ÊúâÊ®°ÂûãÔºåÁâπÂà´ÊòØÂú®‰ª•‰∏ãÈ¢ÜÂüüÔºö\n\n* **ÊñáÊ°£ÁêÜËß£**Ôºö‰ªéÂ§çÊùÇÊñáÊ°£ÔºàÂ¶Ç PDF ÊàñÂõæÂÉèÔºâ‰∏≠ÊèêÂèñÊúâÁî®‰ø°ÊÅØ„ÄÇ\n* **Ë°®Ê†ºÂíåÂõæË°®ÁêÜËß£**ÔºöÂáÜÁ°ÆËß£ËØªÂõæÂΩ¢Êï∞ÊçÆÂπ∂Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÊñáÊú¨Ëß£Èáä„ÄÇ\n\nÁâπÂà´ÊòØÔºåËØ•Ê®°ÂûãÂú® **ChartQA** ‰∏äÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ **81\\.4%**ÔºåÂú® **AI2D** ‰∏äÂèñÂæó‰∫Ü **76\\.7%**ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÁêÜËß£Êï∞ÊçÆ‰∏∞ÂØåÊñáÊ°£ÁöÑËÉΩÂäõ„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàOCRÂíåÊñáÊ°£ÊèêÂèñÂæàÈáçË¶Å\n\nÊñáÊ°£ÊèêÂèñÂíåOCRÂØπ‰∫é‰ºÅ‰∏öÂíåÁ†îÁ©∂Ëá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩøÂæóÂ∞ÜÊâìÂç∞ÊàñÊâãÂÜôÊñáÊú¨ËΩ¨Êç¢‰∏∫Êú∫Âô®ÂèØËØªÊ†ºÂºèÊàê‰∏∫ÂèØËÉΩ„ÄÇ‰ΩøÁî®ÂÉèPhi-3-Vision-128K-InstructËøôÊ†∑ÁöÑAIÊ®°ÂûãÔºåÂèØ‰ª•ÊòæËëóÁÆÄÂåñ**PDFËß£Êûê**„ÄÅ**Êï∞ÊçÆÂΩïÂÖ•Ëá™Âä®Âåñ**„ÄÅ**ÂèëÁ•®Â§ÑÁêÜ**Âíå**Ê≥ïÂæãÊñáÊ°£ÂàÜÊûê**Á≠â‰ªªÂä°„ÄÇ\n\nÊó†ËÆ∫ÊÇ®Â§ÑÁêÜÁöÑÊòØÊâ´ÊèèÊñáÊ°£„ÄÅÊà™ÂõæËøòÊòØÊãçÊëÑÁöÑÈ°µÈù¢ÔºåËØ•Ê®°ÂûãÁöÑÂ§öÊ®°ÊÄÅËÉΩÂäõÈÉΩÂèØ‰ª•Â∏ÆÂä©**Ëá™Âä®ÂåñÊï∞ÊçÆÊèêÂèñ**Ôºå‰ΩøÂÖ∂Êàê‰∏∫ÊèêÈ´òÁîü‰∫ßÂäõÂíåÂáèÂ∞ë‰∫∫Â∑•Â∑•‰ΩúÈáèÁöÑÂÆùË¥µÂ∑•ÂÖ∑„ÄÇ\n\n## Ë¥üË¥£‰ªªÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∏éÂÆâÂÖ®Êé™ÊñΩ\n\nËôΩÁÑ∂ËØ•Ê®°ÂûãÂäüËÉΩÂº∫Â§ßÔºå‰ΩÜÂºÄÂèëËÄÖÂ∫îÊ≥®ÊÑèÂÖ∂Â±ÄÈôêÊÄß„ÄÇ**ËØ≠Ë®ÄÂÅèËßÅ**„ÄÅ**ÂàªÊùøÂç∞Ë±°Âº∫Âåñ**Âíå**‰∏çÂáÜÁ°ÆÂÜÖÂÆπÁîüÊàê**ÊòØÊΩúÂú®ÈóÆÈ¢ò„ÄÇÂØπ‰∫éÈ´òÈ£éÈô©ÁöÑ‰ΩøÁî®Ê°à‰æãÔºå‰æãÂ¶Ç**ÂÅ•Â∫∑ÊàñÊ≥ïÂæãÂª∫ËÆÆ**ÔºåÈúÄË¶ÅÈ¢ùÂ§ñÁöÑ**È™åËØÅÂíåÂÜÖÂÆπËøáÊª§**Â±Ç„ÄÇ\n\n## Êú™Êù•ÊñπÂêë‰∏éÂæÆË∞É\n\nÊÉ≥Ë¶ÅÊâ©Â±ï Phi\\-3\\-Vision\\-128K\\-Instruct ÁöÑÂäüËÉΩÂêóÔºüÊîØÊåÅÂæÆË∞ÉÔºåÂèØ‰ª•‰ΩøÁî® **Phi\\-3 Cookbook** ËøõË°åÔºåËØ•ÊâãÂÜåÊèê‰æõ‰∫ÜË∞ÉÊï¥Ê®°Âûã‰ª•ÈÄÇÂ∫îÁâπÂÆö‰ªªÂä°ÁöÑÈÖçÊñπÔºå‰æãÂ¶Ç **ÊñáÊ°£ÂàÜÁ±ª**„ÄÅ**Â¢ûÂº∫ÁöÑ OCR ÂáÜÁ°ÆÊÄß** Âíå **‰∏ì‰∏öÁöÑÂõæÂÉèÁêÜËß£**„ÄÇ\n\n## ÁªìËÆ∫\n\nPhi\\-3\\-Vision\\-128K\\-Instruct ‰∏ç‰ªÖ‰ªÖÊòØÂ§öÊ®°ÊÄÅ AI ÁöÑ‰∏ÄÊ≠•ËøõÂ±ïÔºõÂÆÉÊòØËøàÂêë‰∏Ä‰∏™Êú™Êù•ÁöÑÈ£ûË∑ÉÔºåÂú®Ëøô‰∏™Êú™Êù•‰∏≠Ôºå**ÊñáÊ°£ÊèêÂèñ„ÄÅOCR Âíå AI È©±Âä®ÁöÑÂÜÖÂÆπÁîüÊàê**ÊòØÊó†Áºù‰∏îÊòì‰∫éËé∑ÂèñÁöÑ„ÄÇÂá≠ÂÄüÂπøÊ≥õÁöÑËÆ≠ÁªÉ„ÄÅÂº∫Â§ßÁöÑÊû∂ÊûÑÂíåÊ∑±ÊÄùÁÜüËôëÁöÑËÆæËÆ°ÔºåËØ•Ê®°Âûã‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üÂú®ÂêÑ‰∏™È¢ÜÂüüËΩ¨ÂèòÊï∞ÊçÆÂ§ÑÁêÜ„ÄÇ\n\nÊï¨ËØ∑ÊúüÂæÖÊõ¥Â§öÂÖ≥‰∫éÂ¶Ç‰ΩïÂ∞ÜËØ•Ê®°Âûã‰∏éÁé∞ÂÆû‰∏ñÁïåÂ∫îÁî®ÈõÜÊàêÁöÑÈ´òÁ∫ßÁ§∫‰æãÂíåÊïôÁ®ãÔºåÊàë‰ª¨Â∞ÜÊé¢Á¥¢**Â§ÑÁêÜÂ§öÁßçÊñáÊ°£Á±ªÂûã**ÂíåÂ∫îÁî®**AI È©±Âä®ÁöÑÊäÄÊúØ**‰ªéÂ§öÊ†∑ÂåñÊù•Ê∫êÊèêÂèñÊúâ‰ª∑ÂÄºÁöÑËßÅËß£„ÄÇ\n\n**AI È©±Âä®ÁöÑÊñáÊ°£ÊèêÂèñ**ÁöÑÊú™Êù•‰ªéÊú™Â¶ÇÊ≠§ÂÖâÊòéÔºÅ\n\n"},{"lang":"zh","group":"blog","slug":"blog/ai-research-agents-set-to-transform-knowledge-research-in-2025-plus-top-3-free-tools-d37197726531","frontmatter":{"title":"‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂‰ª£ÁêÜÔºö2025 Âπ¥Â∞ÜÊîπÂèòÁü•ËØÜÁ†îÁ©∂ÔºàÂ§ñÂä†‰∏âÂ§ßÂÖçË¥πÂ∑•ÂÖ∑Ôºâ","meta_title":"‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂‰ª£ÁêÜÔºö2025 Âπ¥Â∞ÜÊîπÂèòÁü•ËØÜÁ†îÁ©∂ÔºàÂ§ñÂä†‰∏âÂ§ßÂÖçË¥πÂ∑•ÂÖ∑Ôºâ","description":"È¢ÑËÆ°Âà∞2025Âπ¥ÔºåAIÁ†îÁ©∂‰ª£ÁêÜÂ∞ÜÂΩªÂ∫ïÊîπÂèòÁü•ËØÜÁ†îÁ©∂ÁöÑÊñπÂºè„ÄÇ‰∏é‰º†ÁªüAIÂ∑•ÂÖ∑‰∏çÂêåÔºåËøô‰∫õ‰ª£ÁêÜËÉΩÂ§üËá™‰∏ªÈÄÇÂ∫îÂπ∂Â§ÑÁêÜÂ§ßÈáè‰ø°ÊÅØÔºåËØÜÂà´Ê®°ÂºèÂπ∂ÁîüÊàêÊ¥ûÂØü„ÄÇÊñáÁ´†‰ªãÁªç‰∫Ü‰∏âÁßçÂÖçË¥πÂ∑•ÂÖ∑ÔºöÊñØÂù¶Á¶èÁöÑSTORM„ÄÅCustomGPT.aiÁ†îÁ©∂ÂëòÂíåGPT ResearcherÔºåÂÆÉ‰ª¨Âú®Ëá™Âä®ÂåñÁ†îÁ©∂„ÄÅÁîüÊàêÁªìÊûÑÂåñÂÜÖÂÆπÂíåÁ°Æ‰øù‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇAIÁ†îÁ©∂‰ª£ÁêÜÂ∞ÜÊèêÂçáÁ†îÁ©∂ÊïàÁéáÔºåÂ∏ÆÂä©Á†îÁ©∂ËÄÖ‰∏ìÊ≥®‰∫éÂàõÈÄ†ÊÄßÊÄùÁª¥ÔºåÂêåÊó∂Êé®Âä®Á†îÁ©∂ÁöÑÊ∞ë‰∏ªÂåñÔºå‰øÉËøõË∑®Â≠¶ÁßëÂàõÊñ∞ÂíåÂ§öÊ†∑ÂåñËßÜËßíÁöÑÂá∫Áé∞„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*8hV5Jo0eUwY01CWV","categories":["Research","Data Science","Generative AI"],"author":"Rifx.Online","tags":["agents","RAG","STORM","CustomGPT","GPT"],"draft":false,"slug":"blog/ai-research-agents-set-to-transform-knowledge-research-in-2025-plus-top-3-free-tools-d37197726531"},"content":"\n\n\n‰∫ãÊÉÖÊòØËøôÊ†∑ÁöÑÔºö‰∏Ä‰∫õÈáçÂ§ßÂèòÂåñÂç≥Â∞ÜÂä®ÊëáÁü•ËØÜÁ†îÁ©∂ÁöÑ‰∏ñÁïå„ÄÇ\n\nÂú®Ê∑±ÂÖ•Á†îÁ©∂AIÁ†îÁ©∂‰ª£ÁêÜÂπ∂Âú®ÂêÑ‰∏™Ë°å‰∏öÁúãÂà∞ÂÆÉ‰ª¨ÁöÑÂÆûÈôÖÂ∫îÁî®Âá†‰∏™ÊúàÂêéÔºåÊàëÂèØ‰ª•ËÇØÂÆöÂú∞ÂëäËØâ‰Ω†‚Äî‚ÄîÂà∞2025Âπ¥ÔºåËøô‰∫õÂ∑•ÂÖ∑‰∏ç‰ªÖ‰ªÖÊòØÊúâÁî®ÁöÑÂ∑•ÂÖ∑„ÄÇÂÆÉ‰ª¨Â∞Ü‰ªéÊ†πÊú¨‰∏äÊîπÂèòÊàë‰ª¨ËøõË°åÁü•ËØÜÁ†îÁ©∂ÁöÑÊñπÂºèÔºàÊó†ËÆ∫ÊòØËê•ÈîÄËøòÊòØÁßëÂ≠¶ÔºÅÔºâ„ÄÇ\n\n> **‰∫∫Á±ªÂú®‰∏Ä‰∏™Â∞èÊó∂ÂÜÖËÆøÈóÆ10,000‰∏™ÁΩëÁ´ôÂπ∂Á†îÁ©∂Êï∞ÊçÆÂú®Áâ©ÁêÜ‰∏äÊòØ‰∏çÂèØËÉΩÁöÑ„ÄÇÁÑ∂ËÄåÔºå‰ª£ÁêÜÂèØ‰ª•ËΩªÊùæÂÅöÂà∞Ëøô‰∏ÄÁÇπ„ÄÇ**\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜÂêë‰Ω†Â±ïÁ§∫3‰∏™‰ºöËÆ©‰Ω†Â§ßÂêÉ‰∏ÄÊÉäÁöÑÂÖçË¥πÂ∑•ÂÖ∑„ÄÇÔºàÊèêÁ§∫ÔºöËøô‰∏çÊòØChatGPTÊàñPerplexityÔºÅÔºâ\n\n\n\nÊàëÁü•ÈÅì‰Ω†Âú®ÊÉ≥‰ªÄ‰πà„ÄÇ‚ÄúÂèà‰∏ÄÁØáAIÁÇí‰ΩúÊñáÁ´†Ôºü‚Äù‰ΩÜËØ∑ÁªßÁª≠ÂÖ≥Ê≥®„ÄÇ\n\nÈ¢ÑËÆ°Â∏ÇÂú∫Â∞Ü‰ªé2024Âπ¥ÁöÑ51‰∫øÁæéÂÖÉÊøÄÂ¢ûËá≥2030Âπ¥ÁöÑ471‰∫øÁæéÂÖÉ„ÄÇËøô‰∏ç‰ªÖ‰ªÖÊòØÂ¢ûÈïø‚Äî‚ÄîËøôÊòØ‰∏ÄÂú∫Á†îÁ©∂È¢ÜÂüüÁöÑÂΩªÂ∫ïÂèòÈù©„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*uGrcW8msqlIdpBeL)\n\n## ‰ªÄ‰πà‰ΩøÂæóAIÁ†îÁ©∂‰ª£ÁêÜ‰∏é‰ºó‰∏çÂêåÔºü\n\nÈ¶ñÂÖàÔºåËøô‰∫õÂπ∂‰∏çÊòØÈúÄË¶Å‰∏çÊñ≠ÊåáÂØºÁöÑÂÖ∏ÂûãAIÂ∑•ÂÖ∑„ÄÇ‰º†ÁªüÁ≥ªÁªüÈúÄË¶Å‰∏∫ÊØè‰∏™‰ªªÂä°Êèê‰æõÊòéÁ°ÆÁöÑÊåáÁ§∫ÔºåËÄåAIÁ†îÁ©∂‰ª£ÁêÜÂ∞±ÂÉèÊã•Êúâ‰∏Ä‰∏™ËÅ™ÊòéÁöÑÁ†îÁ©∂Âä©ÁêÜÔºåËÉΩÂ§üÈöèÊú∫Â∫îÂèòÔºåÊ†πÊçÆ‰ªñ‰ª¨ÂèñÂæóÁöÑÁªìÊûúË∞ÉÊï¥Ë°å‰∏∫„ÄÇ\n\n \n\nÁúüÊ≠£ÁöÑÊ∏∏ÊàèËßÑÂàôÊîπÂèòËÄÖÔºüËøô‰∫õ‰ª£ÁêÜËÉΩÂ§üÂ§ÑÁêÜÂ§ßÈáèÁü•ËØÜÔºåÂèëÁé∞‰∫∫Á±ªÂèØËÉΩÈîôËøáÁöÑÊ®°ÂºèÔºåÂπ∂ÊØî‰ª•ÂæÄÊõ¥Âø´Âú∞ÁîüÊàêÊ¥ûÂØü„ÄÇÂà©Áî®ÂÖàËøõÁöÑ[Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâ](https://readmedium.com/build-it-or-buy-it-deployment-options-for-retrieval-augmented-generation-rag-f6d43df8212a)ÊäÄÊúØÔºåÂÆÉ‰ª¨ÂèØ‰ª•Áõ¥Êé•‰ªéÂèØ‰ø°Êù•Ê∫êÊèêÂèñ‰ø°ÊÅØÔºåÂêåÊó∂‰øùÊåÅÂáÜÁ°ÆÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*p2E-fJ63BB27lZdD)\n\n## È≠îÊ≥ïËÉåÂêéÁöÑÊäÄÊúØ\n\nËøôÈáåÁöÑÁßòÂØÜÂú®‰∫éËÉΩÂ§üÊëÑÂèñÂíåÁ†îÁ©∂Â§ßÈáèÁü•ËØÜÔºà‰æãÂ¶ÇÊ∑±Â∫¶Ë∞∑Ê≠åÁ†îÁ©∂ÔºâÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂‰∏éÂÉè gpt\\-4o Âíå o1\\ ËøôÊ†∑ÁöÑ LLMs ÁöÑÂäõÈáèÁªìÂêàËµ∑Êù•„ÄÇ\n\n‰ΩÜÁúüÊ≠£ËÆ©ÊàëÂÖ¥Â•ãÁöÑÊòØÔºöËøô‰∫õ‰ª£ÁêÜÁî± RAG Ê®°ÂûãÈ©±Âä®ÔºåÂÜÖÁΩÆÁöÑÂèçÂπªËßâÁÆóÊ≥ïÁ°Æ‰øù‰∫ÜÂáÜÁ°ÆÊÄß„ÄÇ‰∏éÈÄöÁî® AI Â∑•ÂÖ∑‰∏çÂêåÔºåÁ†îÁ©∂‰ª£ÁêÜÂùöÊåÅ‰ΩøÁî®ÁªèËøáÈ™åËØÅÁöÑ‰ø°ÊÅØÔºåÂπ∂ËÉΩÂ§üÂºïÁî®ÂÖ∂Êù•Ê∫ê‚Äî‚ÄîËøôÂØπ‰∫éÁª¥Êä§ËØö‰ø°Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n> **ÊâÄ‰ª•ÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰∏Ä‰∏™Á†îÁ©∂‰ª£ÁêÜËä± 30 ÂàÜÈíüÊó∂Èó¥ÂØπÊüê‰∏™‰∏ªÈ¢òËøõË°åÂçöÂ£´Á†îÁ©∂‚Äî‚ÄîËøôÊòØÂ§ßÂ§öÊï∞‰∫∫ÈúÄË¶ÅÂá†Â§©ÊâçËÉΩÂÆåÊàêÁöÑ‰∫ãÊÉÖ„ÄÇ**\n\n## Ëøô‰∏∫‰ªÄ‰πàÁé∞Âú®ÂæàÈáçË¶Å\n\nÊó∂Êú∫ÂÜçÂ•Ω‰∏çËøá‰∫Ü„ÄÇÁ†îÁ©∂Ê≠£Ê∑πÊ≤°Âú®Êï∞ÊçÆ‰∏≠‚Äî‚ÄîÊàë‰ª¨ÊØèÂ§©ÁîüÊàêÁöÑ‰ø°ÊÅØÊØîËøáÂéª‰∏ÄÂπ¥ËøòË¶ÅÂ§ö„ÄÇËÄåÈöèÁùÄË∞∑Ê≠åÂØπ‰ΩìÈ™å„ÄÅ‰∏ì‰∏öÊÄß„ÄÅÊùÉÂ®ÅÊÄßÂíåÂèØ‰ø°Â∫¶ÔºàEEATÔºâÁöÑÈáçËßÜÔºåÂØπÂáÜÁ°Æ„ÄÅÁªèËøáÂÖÖÂàÜÁ†îÁ©∂ÁöÑÂÜÖÂÆπÁöÑÈúÄÊ±Ç‰ªéÊú™Â¶ÇÊ≠§Ëø´Âàá„ÄÇ\n\nÊàëÊúÄËøë‰∏é‰∏Ä‰∏™Á†îÁ©∂Âõ¢Èòü‰∫§ÊµÅÔºå‰ªñ‰ª¨‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂‰ª£ÁêÜÂ∞ÜÊñáÁ´†Á†îÁ©∂Êó∂Èó¥Áº©Áü≠‰∫Ü70%„ÄÇ‰ΩÜËøô‰∏ç‰ªÖ‰ªÖÊòØÈÄüÂ∫¶ÁöÑÈóÆÈ¢ò‚Äî‚ÄîËØ•‰ª£ÁêÜÂèëÁé∞‰∫Ü‰ªñ‰ª¨Âú®ÊúÄÂàùÁÆÄÊä•‰∏≠ÂÆåÂÖ®ÈÅóÊºèÁöÑÁü•ËØÜËßÜËßí„ÄÇËÄåÊúÄÊ£íÁöÑÈÉ®ÂàÜÔºüÊâÄÊúâÂÜÖÂÆπÈÉΩÂèØ‰ª•È™åËØÅÔºåÂπ∂‰∏îÊúâÊï∞ÊçÆÊîØÊåÅ„ÄÇ\n\nÊâÄ‰ª•ÔºåÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÂ¶ÇÊûú‰Ω†ËÉΩËÆ©Áà±Âõ†ÊñØÂù¶„ÄÅÂüÉÈöÜ¬∑È©¨ÊñØÂÖã„ÄÅË¥πÊõº„ÄÅÂè≤ËíÇÂ§´¬∑‰πîÂ∏ÉÊñØ„ÄÅÁÆÄ¬∑Âè§ÈÅìÂ∞îÂíåÂ∞§Áì¶Â∞î¬∑Ëµ´ÊãâÂà©ÂÖ±ÂêåÂêà‰ΩúÂÆåÊàê‰Ω†ÁöÑÁ†îÁ©∂Êä•Âëä‚Äî‚ÄîËøôÂ∞±ÊòØ‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂‰ª£ÁêÜÊâÄËÉΩÂÆûÁé∞ÁöÑ„ÄÇ\n\n## ‰∏âÂ§ß‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂‰ª£ÁêÜÊú∫ÊûÑ\n\n## ÊñØÂù¶Á¶è STORM\n\nÊñØÂù¶Á¶èÂ§ßÂ≠¶ÁöÑ [STORM](https://storm.genie.stanford.edu/)ÔºàÈÄöËøáÊ£ÄÁ¥¢ÂíåÂ§öËßíÂ∫¶ÊèêÈóÆÂêàÊàê‰∏ªÈ¢òÂ§ßÁ∫≤ÔºâÊòØ‰∏Ä‰∏™Áî±‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÁü•ËØÜÁ≠ñÂàíÁ≥ªÁªüÔºåÊó®Âú®‰ªéÈõ∂ÂºÄÂßãÁîüÊàêÂÖ®Èù¢ÁöÑ„ÄÅÁ±ª‰ººÁª¥Âü∫ÁôæÁßëÁöÑÊñáÁ´†„ÄÇ\n\nÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÔºåSTORM ÈÄöËøáËøõË°åÂü∫‰∫é‰∫íËÅîÁΩëÁöÑÁ†îÁ©∂„ÄÅÂ∞Ü‰ø°ÊÅØÁªÑÁªáÊàêÁªìÊûÑÂåñÂ§ßÁ∫≤ÔºåÂπ∂ÁîüÊàêÂ∏¶ÊúâÂºïÁî®ÁöÑÂÆåÊï¥ÊñáÁ´†Ôºå‰ªéËÄåËá™Âä®ÂåñÁ†îÁ©∂ÂíåÂÜô‰ΩúËøáÁ®ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*axYZ2fO15FAqQpID)\n\n**‰ºòÁÇπÔºö**\n\n* **Ëá™Âä®ÂåñÁ†îÁ©∂ÂíåÂÜô‰ΩúÔºö** STORM ÈÄöËøáËá™Âä®ÂåñÁ†îÁ©∂ÂíåÂÜô‰ΩúÈò∂ÊÆµÔºåÁÆÄÂåñ‰∫ÜËØ¶ÁªÜÊñáÁ´†ÁöÑÂàõÂª∫ÔºåËäÇÁúÅ‰∫ÜÁî®Êà∑Â§ßÈáèÊó∂Èó¥ÂíåÁ≤æÂäõ„ÄÇ\n* **ÁªìÊûÑÂåñÂÜÖÂÆπÁîüÊàêÔºö** Á≥ªÁªüÁîüÊàêÊúâÁªÑÁªáÁöÑÂ§ßÁ∫≤ÂíåÁªìÊûÑËâØÂ•ΩÁöÑÊñáÁ´†ÔºåÁ°Æ‰øùÊúÄÁªàËæìÂá∫ÁöÑÊ∏ÖÊô∞ÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ\n* **ÂºÄÊ∫êÂèØËÆøÈóÆÊÄßÔºö** ‰Ωú‰∏∫‰∏Ä‰∏™ÂºÄÊ∫êÈ°πÁõÆÔºåSTORM ÂÖÅËÆ∏Áî®Êà∑Ê†πÊçÆÁâπÂÆöÈúÄÊ±ÇËá™ÂÆö‰πâÂíåË∞ÉÊï¥Â∑•ÂÖ∑Ôºå‰øÉËøõ‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Á§æÂå∫ÁöÑÂàõÊñ∞ÂíåÂêà‰Ωú„ÄÇ\n\n**Áº∫ÁÇπÔºö**\n\n* **‰æùËµñ‰∫íËÅîÁΩëÊù•Ê∫êÔºö** STORM ÂØπÂü∫‰∫é‰∫íËÅîÁΩëÁöÑÁ†îÁ©∂ÁöÑ‰æùËµñÂèØËÉΩÂØºËá¥ÂåÖÂê´ËøáÊó∂ÊàñÂÅèËßÅÁöÑ‰ø°ÊÅØÔºåÂ¶ÇÊûú‰∏çÂä†‰ª•‰ªîÁªÜÁõëÊéß„ÄÇ\n* **Ë¥®ÈáèÊéßÂà∂Ë¶ÅÊ±ÇÔºö** Â∞ΩÁÆ° STORM Ëá™Âä®Âåñ‰∫ÜÂ§ßÈÉ®ÂàÜÂÜô‰ΩúËøáÁ®ãÔºå‰ΩÜÁîüÊàêÁöÑÊñáÁ´†‰ªçÂèØËÉΩÈúÄË¶Å‰∫∫Â∑•ÂÆ°Ê†∏ÂíåÁºñËæëÔºå‰ª•Á°Æ‰øùÂáÜÁ°ÆÊÄßÂíåÁ¨¶ÂêàÁâπÂÆöÊ†áÂáÜ„ÄÇ\n* **ÊäÄÊúØËÆæÁΩÆÔºö** Âú®Êú¨Âú∞ÂÆûÁé∞ STORM ÈúÄË¶ÅÁÜüÊÇâ Git„ÄÅPython Âíå Conda Á≠âÂ∑•ÂÖ∑ÔºåËøôÂèØËÉΩÂØπÊ≤°ÊúâÊäÄÊúØËÉåÊôØÁöÑÁî®Êà∑ÊûÑÊàêÈöúÁ¢ç„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§ö‰ø°ÊÅØÂíåËÆøÈóÆ STORMÔºåËØ∑ËÆøÈóÆ [ÂÆòÊñπ GitHub ‰ªìÂ∫ì](https://github.com/stanford-oval/storm)\n\n## CustomGPT.ai Á†îÁ©∂Âëò\n\nCustomGPT.ai [Á†îÁ©∂Âëò](https://customgpt-researcher.streamlit.app/) ÊòØ‰∏Ä‰∏™‰∏ìÈó®ËÆæËÆ°ÁöÑ AI Á†îÁ©∂‰ª£ÁêÜÔºåÊó®Âú®Âü∫‰∫éÊ∑±ÂÖ•ÁöÑ Google Á†îÁ©∂ÊàñËá™ÂÆö‰πâÁü•ËØÜÂ∫ìÔºàÂ¶ÇÂÖ¨Âè∏ÁöÑ‰∏ìÊúâÊï∞ÊçÆÊàñÂÖ∂‰ªñÂèØ‰ø°Êù•Ê∫êÔºâÂàõÂª∫Ë∂ÖÈ´òË¥®ÈáèÁöÑÈïøÁØáÊñáÁ´†„ÄÇ\n\nÂà©Áî® CustomGPT ÁöÑÂèçÂπªËßâÊäÄÊúØÔºåÂÆÉÁîüÊàê‰∫ãÂÆûÂáÜÁ°ÆÁöÑÂÜÖÂÆπÔºåÂ∏¶ÊúâÂºïÁî®ÔºåÁ¨¶ÂêàÁâπÂÆöÂìÅÁâåÊåáÂçóÔºåÂπ∂Á°Æ‰øù‰∏éÁé∞ÂÆû‰∏ñÁïå‰ø°ÊÅØÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ\n\nËØ•‰ª£ÁêÜ‰ΩøÁî® o1„ÄÅgpt-4o Âíå GPT-4oÔºàËßÜËßâÔºâÁõ∏ÁªìÂêàÁöÑÊñπÂºèÔºåÂà∂‰ΩúÂåÖÂê´ÂÜÖÂµåÂõæÂÉèÂíåÈìæÊé•ÁöÑËØ¶ÁªÜÁ†îÁ©∂Êä•Âëä„ÄÇÂÖ∂Áã¨ÁâπÁöÑ‚Äú**Ê∏êËøõÂèô‰∫ã**‚ÄùÂäüËÉΩÊúâÂä©‰∫éÂàõÂª∫‰∏çÊòæÂæóÊú∫Ê¢∞ÁöÑÂèôËø∞ÔºåËÉΩÂ§üÊÑèËØÜÂà∞ÂÖàÂâçÁîüÊàêÁöÑÂÜÖÂÆπ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*UiCyTjNF3A3buKzT)\n\n**‰ºòÁÇπÔºö**\n\n* **ÂèØ‰ø°ÁöÑÂÜÖÂÆπÂàõ‰ΩúÔºö** ÈÄöËøáÊï¥ÂêàÂèØÈù†Êù•Ê∫êÁöÑÊï∞ÊçÆÔºåCustomGPT.ai ÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂáèÂ∞ë‰∫Ü‰∏çÂáÜÁ°ÆÊÄßÔºåÈùûÂ∏∏ÈÄÇÂêàÊ≥ïÂæã„ÄÅÈáëËûçÂíåÂåªÁñóÁ≠âÈúÄË¶ÅÈ´òÂÜÖÂÆπÂèØÈù†ÊÄßÁöÑË°å‰∏ö„ÄÇ\n* **ÂèçÂπªËßâÊäÄÊúØÔºö** CustomGPT.ai ÂåÖÂê´ÂÖàËøõÁöÑÁÆóÊ≥ïÔºåÈò≤Ê≠¢ÁîüÊàêÊé®ÊµãÊàñËôöÊûÑÁöÑ‰ø°ÊÅØÔºåÁ°Æ‰øùÂÜÖÂÆπ‰∏éÁªèËøáÈ™åËØÅÁöÑÊù•Ê∫êÁ¥ßÂØÜÂØπÈΩê„ÄÇ\n* **ÊâòÁÆ°Ëß£ÂÜ≥ÊñπÊ°àÔºö** ÈÄöËøáÂÖ∂Êó†‰ª£Á†ÅÁïåÈù¢ÔºåÈùûÊäÄÊúØÁ†îÁ©∂‰∫∫ÂëòÂíåËê•ÈîÄ‰∫∫ÂëòÂèØ‰ª•ËΩªÊùæËß¶ÂèëÊ∑±Â∫¶Á†îÁ©∂ÔºåËÄåÊó†ÈúÄÊ∑±ÂÖ•ÁºñÁ†ÅÁªÜËäÇ„ÄÇ\n* **SEO ‰ºòÂåñÁöÑÂÜÖÂÆπÁîüÊàêÔºö** ËØ•Â∑•ÂÖ∑ÊîØÊåÅ Google ÁöÑ EEATÔºà‰∏ì‰∏öÁü•ËØÜ„ÄÅÊùÉÂ®ÅÊÄß„ÄÅÂèØ‰ø°ËµñÊÄßÂíåÁªèÈ™åÔºâÊ†áÂáÜÔºåÂàõÂª∫Âú®ÊêúÁ¥¢ÂºïÊìé‰∏≠ÊéíÂêçËâØÂ•ΩÁöÑÂÜÖÂÆπÔºåÂº∫Ë∞ÉË¥®ÈáèÂíåÊùÉÂ®ÅÊÄß„ÄÇ\n\n**Áº∫ÁÇπÔºö**\n\n* **Èó≠Ê∫êÔºö** ËôΩÁÑ∂ CustomGPT.ai Á†îÁ©∂ÂëòÂú®ÊúâÈôêÊó∂Èó¥ÂÜÖÂÖçË¥πÔºå‰ΩÜÂÆÉÊòØ‰∏Ä‰∏™Èó≠Ê∫êÁöÑ‰∏ìÊúâÈ°πÁõÆ„ÄÇ\n* **ÁîüÊàêÊó∂Èó¥ËæÉÈïøÔºö** È´òÁ∫ßÊé®ÁêÜÂíå RAG ËÉΩÂäõÂèØËÉΩÈúÄË¶ÅÈïøËææ 20 ÂàÜÈíüÁöÑÊó∂Èó¥Êù•ÁîüÊàê‰∏ÄÁØáÊñáÁ´†ÔºåËøôÂèØËÉΩ‰∏çÈÄÇÂêàÂØªÊ±ÇÂø´ÈÄüÊàñ‰ΩéË¥®ÈáèÂÜÖÂÆπÁöÑÁî®Êà∑„ÄÇ\n* **ÂØπÈ¢ÑÁÆóÂÜÖÂÆπÈ°πÁõÆÁöÑÈÄÇÁî®ÊÄßÊúâÈôêÔºö** Áî±‰∫éÂÖ∂‰∏ìÊ≥®‰∫éË¥®ÈáèÔºåCustomGPT.ai Á†îÁ©∂Âëò‰∏çÈÄÇÂêàÈúÄË¶ÅÂø´ÈÄü„ÄÅÂªâ‰ª∑ÊàñÂü∫Êú¨ÂÜÖÂÆπÁîüÊàêÁöÑÈ°πÁõÆ„ÄÇ\n\nÊúâÂÖ≥ CustomGPT.ai Á†îÁ©∂ÂëòÂèäÂÖ∂Â∫îÁî®ÁöÑÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅÂÖçË¥πÁöÑ [Streamlit Â∫îÁî®](https://customgpt-researcher.streamlit.app/)„ÄÇ\n\n## GPT Researcher\n\nGPT Researcher ÊòØ‰∏Ä‰∏™ [Ëá™‰∏ªÊô∫ËÉΩ‰Ωì](https://github.com/assafelovic/gpt-researcher)ÔºåÊó®Âú®Âà©Áî®ÁΩëÁªúÂíåÊú¨Âú∞ËµÑÊ∫êÂØπ‰ªª‰ΩïÁªôÂÆö‰ªªÂä°ËøõË°åÂÖ®Èù¢Á†îÁ©∂„ÄÇ\n\nÂÆÉÁîüÊàêËØ¶ÁªÜ„ÄÅ‰∫ãÂÆûÊÄßÂíåÊó†ÂÅèËßÅÁöÑÊä•ÂëäÔºåÂπ∂ÈôÑÊúâÂºïÁî®ÔºåÊèê‰æõÂÆåÊï¥ÁöÑÂÆöÂà∂ÈÄâÈ°πÔºå‰ª•ÂàõÂª∫ÈáèË∫´ÂÆöÂà∂ÁöÑÁâπÂÆöÈ¢ÜÂüüÁ†îÁ©∂Êô∫ËÉΩ‰Ωì„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*_4Q680CBSvpCZOLW)\n\n**‰ºòÁÇπÔºö**\n\n* **Ëá™‰∏ªÁ†îÁ©∂ËÉΩÂäõÔºö** GPT Researcher Ëá™Âä®ÂåñÁ†îÁ©∂ËøáÁ®ãÔºåÊúâÊïàÂú∞‰ªéÂêÑÁßçÊù•Ê∫êÊî∂ÈõÜÂíåÁªºÂêà‰ø°ÊÅØÔºåÁîüÊàêÂÖ®Èù¢ÁöÑÊä•Âëä„ÄÇ\n* **ÂÆöÂà∂ÂíåÁÅµÊ¥ªÊÄßÔºö** Áî®Êà∑ÂèØ‰ª•ÂÆöÂà∂Êô∫ËÉΩ‰Ωì‰ª•‰∏ìÊ≥®‰∫éÁâπÂÆöÈ¢ÜÂüüÊàñ‰∏ªÈ¢òÔºå‰ªéËÄåÊª°Ë∂≥ÁâπÂÆöÈúÄÊ±ÇÁöÑÂÆöÂà∂Á†îÁ©∂ËæìÂá∫„ÄÇ\n* **ÂºÄÊ∫êÂèØËÆøÈóÆÊÄßÔºö** ‰Ωú‰∏∫‰∏Ä‰∏™ÂºÄÊ∫êÈ°πÁõÆÔºåGPT Researcher ÈºìÂä±Á§æÂå∫Âçè‰ΩúÂíåÊåÅÁª≠ÊîπËøõÔºå‰∏∫Áî®Êà∑Êèê‰æõÈÄèÊòéÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ\n\n**Áº∫ÁÇπÔºö**\n\n* **ÊäÄÊúØËÆæÁΩÆË¶ÅÊ±ÇÔºö** ÂÆûÊñΩ GPT Researcher ÂèØËÉΩÈúÄË¶ÅÊäÄÊúØ‰∏ìÈïøÔºåÂåÖÊã¨ÂØπ Git„ÄÅPython Âíå Docker ÁöÑÁÜüÊÇâÔºåËøôÂèØËÉΩÂØπÈùûÊäÄÊúØÁî®Êà∑ÊûÑÊàêÈöúÁ¢ç„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§ö‰ø°ÊÅØÂíåËÆøÈóÆ GPT ResearcherÔºåËØ∑ËÆøÈóÆ [ÂÆòÊñπ GitHub Â≠òÂÇ®Â∫ì](https://github.com/assafelovic/gpt-researcher)Ôºö\n\n## ‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂ÁöÑ‰∫∫ÊÄßÂåñ\n\nËÆ©Êàë‰ª¨Èù¢ÂØπ‰∏Ä‰∏™ÊòæËÄåÊòìËßÅÁöÑÈóÆÈ¢òÔºö‚ÄúËøô‰∫õÊô∫ËÉΩ‰Ωì‰ºöÂèñ‰ª£‰∫∫Á±ªÁ†îÁ©∂ËÄÖÂêóÔºü‚ÄùÁªùÂØπ‰∏ç‰ºö„ÄÇÁõ∏ÂèçÔºåÂÆÉ‰ª¨ËÆ©Á†îÁ©∂ËÄÖËÉΩÂ§ü‰∏ìÊ≥®‰∫é‰∫∫Á±ªÊúÄÊìÖÈïøÁöÑ‰∫ãÊÉÖÔºöÂàõÈÄ†ÊÄßÊÄùÁª¥„ÄÅÂ§çÊùÇÈóÆÈ¢òËß£ÂÜ≥ÂíåÁîüÊàêÂàõÊñ∞ÂÅáËÆæ„ÄÇ\n\nÂèØ‰ª•ÊääÂÆÉÊÉ≥Ë±°Êàê‰∏Ä‰∏™Ë∂ÖÁ∫ßÂº∫Â§ßÁöÑÁ†îÁ©∂Âä©ÊâãÔºåÂÆÉ‰ªé‰∏çÁù°Ëßâ„ÄÅ‰ªé‰∏çÁñ≤ÂÄ¶ÔºåÂπ∂‰∏îËÉΩÂ§ü‰ª•Èó™ÁîµËà¨ÁöÑÈÄüÂ∫¶Â§ÑÁêÜ‰ø°ÊÅØ„ÄÇÂΩì‰∫∫Â∑•Êô∫ËÉΩÂ§ÑÁêÜÊ∑±Â±ÇÁü•ËØÜÁ†îÁ©∂Êó∂ÔºåÁ†îÁ©∂ËÄÖÂèØ‰ª•‰∏ìÊ≥®‰∫éÁ™ÅÁ†¥ÊÄßÁöÑÊ¥ûÂØü„ÄÇ\n\n## ‰∏∫Èù©ÂëΩÂÅöÂ•ΩÂáÜÂ§á\n\nÈÇ£‰πàÔºåÊàë‰ª¨Â¶Ç‰Ωï‰∏∫ËøôÂú∫‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èù©ÂëΩÂÅöÂ•ΩÂáÜÂ§áÂë¢Ôºü\n\nÈ¶ñÂÖàÔºåÁ†îÁ©∂‰∫∫ÂëòÈúÄË¶ÅÊèêÂçá‰ªñ‰ª¨ÁöÑÊäÄËÉΩ„ÄÇÊàëÂπ∂‰∏çÊòØËØ¥ÊØè‰∏™‰∫∫ÈÉΩÈúÄË¶ÅÊàê‰∏∫ÁºñÁ†Å‰∏ìÂÆ∂Ôºå‰ΩÜÁêÜËß£Ëøô‰∫õ‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂‰ª£ÁêÜÁöÑ**‰ºòÂäøÂíåÂ±ÄÈôêÊÄß**Â∞ÜÊòØÂÖ≥ÈîÆ„ÄÇ\n\nÂ§ßÂ≠¶Ê≠£Âú®Ë∞ÉÊï¥‰ªñ‰ª¨ÁöÑËØæÁ®ãÔºåÊàëÁúãÂà∞Ë∂äÊù•Ë∂äÂ§öÁöÑ[Á†îÁ©∂‰∫∫Âëò](https://drmichaellevin.org/resources/levinbot.html)Âà©Áî®‰∫∫Â∑•Êô∫ËÉΩÊù•ËæÖÂä©‰ªñ‰ª¨ÁöÑÁ†îÁ©∂ÂÆûÈ™åÂÆ§„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*E733R9Fn9ufaXnTF)\n\n## Â±ïÊúõ2025Âπ¥‰πãÂêé\n\nËøôÈáåÁöÑÊΩúÂäõ‰ª§‰∫∫ÈúáÊÉä„ÄÇËøô‰∫õAIÁ†îÁ©∂‰ª£ÁêÜÂ∞Ü‰ΩøÊàë‰ª¨ËÉΩÂ§üËøõË°åÁõÆÂâçÂá†‰πéÊó†Ê≥ïÊÉ≥Ë±°ÁöÑÁ†îÁ©∂Á±ªÂûã„ÄÇ\n\nË∑®Â≠¶ÁßëÁöÑÂàõÊñ∞Â∞ÜÊàê‰∏∫Â∏∏ÊÄÅÔºåÂõ†‰∏∫AI‰ª£ÁêÜÂ∏ÆÂä©ËøûÊé•Êàë‰ª¨‰ªéÊú™ÊÑèËØÜÂà∞ÁöÑ‰∏çÂêåÈ¢ÜÂüü‰πãÈó¥ÁöÑËÅîÁ≥ª„ÄÇ\n\nÊàëÁâπÂà´ÂÖ¥Â•ãÁöÑÊòØÔºåËøôÈ°πÊäÄÊúØÂèØËÉΩ‰ºö‰ΩøÁ†îÁ©∂ÂèòÂæóÊõ¥Âä†Ê∞ë‰∏ªÂåñ„ÄÇÈÇ£‰∫õÊó†Ê≥ïË¥üÊãÖÂ§ßÂûãÁ†îÁ©∂Âõ¢ÈòüÁöÑÂ∞èÂûãÂÆûÈ™åÂÆ§ÂíåÊú∫ÊûÑÂ∞ÜËÉΩÂ§üÂà©Áî®AI‰ª£ÁêÜ‰∏éÊõ¥Â§ßËßÑÊ®°ÁöÑÂèÇ‰∏éËÄÖÁ´û‰∫â„ÄÇËøôÊÑèÂë≥ÁùÄÂ∞Ü‰ºöÊúâÊõ¥Â§öÊ†∑ÂåñÁöÑËßÜËßíÂíåÊõ¥Â§öÁ™ÅÁ†¥ÊÄßÁöÑÂèëÁé∞„ÄÇ\n\n‰∏æ‰∏™‰æãÂ≠êÔºå[Â°îÂ§´Ëå®Â§ßÂ≠¶ÁöÑLevinÂÆûÈ™åÂÆ§](https://drmichaellevin.org/resources/levinbot.html)ËÉΩÂ§üÂú®Âá†‰∏™Â∞èÊó∂ÂÜÖÊûÑÂª∫Âá∫ÊúÄÂ•ΩÁöÑAIÂ∑•ÂÖ∑‰πã‰∏Ä‚Äî‚ÄîÂ±ïÁ§∫‰∫ÜAIÊ∞ë‰∏ªÂåñÁöÑÁúüÊ≠£ÂäõÈáè„ÄÇ\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nÂú®Ëä±‰∫ÜÂá†‰∏™ÊúàÊó∂Èó¥Á†îÁ©∂Ëøô‰∏™ËØùÈ¢òÂπ∂‰∏éËØ•È¢ÜÂüüÁöÑ‰∏ìÂÆ∂‰∫§Ë∞àÂêéÔºåÊàëÁõ∏‰ø°AIÁ†îÁ©∂‰ª£ÁêÜÂ∞Ü‰ºöÂÉè‰∫íËÅîÁΩëÂØπÁßëÂ≠¶ÁöÑÂΩ±Âìç‰∏ÄÊ†∑ÂÖ∑ÊúâÂèòÈù©ÊÄß„ÄÇÂÆÉ‰ª¨‰∏ç‰ªÖ‰ªÖÊòØÂ∑•ÂÖ∑‚Äî‚ÄîÂÆÉ‰ª¨ÊòØÁ†îÁ©∂ËøáÁ®ã‰∏≠ÁöÑÂêà‰Ωú‰ºô‰º¥ÔºåÂ∞ÜÂ∏ÆÂä©Êàë‰ª¨Â∫îÂØπ‰∫∫Á±ªÈù¢‰∏¥ÁöÑ‰∏Ä‰∫õÊúÄÂ§ßÊåëÊàò„ÄÇ\n\nÂΩìÁÑ∂ÔºåËøòÊúâËÆ∏Â§öÈöúÁ¢çÈúÄË¶ÅÂÖãÊúçÔºåÊäÄËÉΩÈúÄË¶ÅÂèëÂ±ï„ÄÇ‰ΩÜÊΩúÂú®ÁöÑÂ•ΩÂ§ÑÂ§™Â∑®Â§ßÔºåÊó†Ê≥ïÂøΩËßÜ„ÄÇÂ¶ÇÊûú‰Ω†‰ªé‰∫ãÂ∏ÇÂú∫Ëê•ÈîÄÊàñÁ†îÁ©∂ÔºåÁé∞Âú®ÊòØÂºÄÂßã‰∏∫Ëøô‰∏ÄËΩ¨ÂèòÂÅöÂáÜÂ§áÁöÑÊó∂ÂÄô„ÄÇ\n\nËØ∑ËÆ∞‰ΩèÔºöÈÇ£‰∫õÊó©ÊúüÊã•Êä±ËøôÈ°πÊäÄÊúØÁöÑÂõ¢ÈòüÂíåÊú∫ÊûÑÂ∞ÜÂú®Êú™Êù•Âá†Âπ¥‰∏≠Êã•ÊúâÂ∑®Â§ßÁöÑ‰ºòÂäø„ÄÇÂú®ËøôÂú∫Â°ëÈÄ†Êàë‰ª¨Áü•ËØÜÁ†îÁ©∂ÊñπÂºèÁöÑÈáçÂ§ßÈù©ÂëΩ‰∏≠Ôºå‰∏çË¶ÅË¢´ËêΩÂú®ÂêéÈù¢‚Äî‚ÄîÊó†ËÆ∫‰Ω†ÊòØ‰∏∫SEOÊí∞ÂÜôÂçöÂÆ¢ÊñáÁ´†ÔºåËøòÊòØÂú®ÁßëÂ≠¶‰∏ªÈ¢ò‰∏äÊîªËØªÂçöÂ£´Â≠¶‰Ωç„ÄÇ\n\n*‰Ω†ÂØπAIÁ†îÁ©∂‰ª£ÁêÜÊúâ‰ªÄ‰πàÁúãÊ≥ïÔºü‰Ω†ÊòØÂê¶Â∑≤ÁªèÂºÄÂßãÂ∞ÜÂÆÉ‰ª¨Êï¥ÂêàÂà∞‰Ω†ÁöÑÁ†îÁ©∂Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÔºüÊàëÂæàÊÉ≥Âú®‰∏ãÈù¢ÁöÑËØÑËÆ∫‰∏≠Âê¨Âê¨‰Ω†ÁöÑÁªèÂéÜ„ÄÇ*\n\n"},{"lang":"zh","group":"blog","slug":"blog/alibabas-open-source-qwen-how-it-s-revolutionizing-ai-and-how-you-can-use-it-dcba8f687c97","frontmatter":{"title":"ÈòøÈáåÂ∑¥Â∑¥ÂºÄÊ∫ê QwenÔºöÂÆÉÂ¶Ç‰ΩïÂΩªÂ∫ïÊîπÂèò‰∫∫Â∑•Êô∫ËÉΩ‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®ÂÆÉ","meta_title":"ÈòøÈáåÂ∑¥Â∑¥ÂºÄÊ∫ê QwenÔºöÂÆÉÂ¶Ç‰ΩïÂΩªÂ∫ïÊîπÂèò‰∫∫Â∑•Êô∫ËÉΩ‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®ÂÆÉ","description":"ÈòøÈáåÂ∑¥Â∑¥ÊúÄËøëÂú® 2024 Âπ¥‰∫ëÊ†ñÂ§ß‰ºöÊúüÈó¥ÂºÄÊ∫ê‰∫Ü Qwen 2.5 Ê®°ÂûãÔºåÂú® AI È¢ÜÂüüÊéÄËµ∑‰∫ÜÊ≥¢Êæú„ÄÇË∂ÖËøá 100 ‰∏™‚Ä¶","date":"2024-10-26T00:26:25.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*I7QDwbLMzoJ_ORq5.jpg","categories":["Programming","Machine Learning","Natural Language Processing"],"author":"Rifx.Online","tags":["Qwen","multimodal","open-source","fine-tune","text-to-video"],"draft":false,"slug":"blog/alibabas-open-source-qwen-how-it-s-revolutionizing-ai-and-how-you-can-use-it-dcba8f687c97"},"content":"\nÈòøÈáåÂ∑¥Â∑¥ÊúÄËøëÂú®‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÂºïËµ∑‰∫ÜËΩ∞Âä®ÔºåÂú®2024Âπ¥ Apsara Â§ß‰ºö‰∏äÂºÄÊ∫ê‰∫ÜÂÖ∂ **Qwen 2.5** Ê®°Âûã„ÄÇQwen Êã•ÊúâË∂ÖËøá 100 ‰∏™Ê®°ÂûãÔºåÊ∂µÁõñËØ≠Ë®Ä„ÄÅËßÜËßâ„ÄÅÈü≥È¢ëÂíå‰ª£Á†ÅÁ≠âÂ§öÁßçÊ®°ÊÄÅÔºå‰ΩøÂÖ∂Êàê‰∏∫ÊúÄÂÖ®Èù¢ÁöÑÂºÄÊ∫ê‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°à‰πã‰∏Ä„ÄÇÊ≠§Ê¨°ÂèëÂ∏ÉÈÄöËøáÊèê‰æõÂ§öÊ†∑ÂåñÂ∫îÁî®ÁöÑÂ∑•ÂÖ∑ÔºåËµãËÉΩÂºÄÂèëËÄÖÔºå‰ªéÊñáÊú¨Âà∞ËßÜÈ¢ëÁîüÊàêÂà∞ÂÆûÊó∂ÈóÆÁ≠î„ÄÇ\n\n\n\n## ÈòøÈáåÂ∑¥Â∑¥ Qwen Ê®°ÂûãÁöÑÂÖ≥ÈîÆÁâπÊÄß\n\n1. **Â§öÊ®°ÊÄÅËÉΩÂäõ**ÔºöQwen Ê®°ÂûãÂ§ÑÁêÜÂ§öÁßçËæìÂÖ•ÔºåÂåÖÊã¨ÊñáÊú¨„ÄÅÈü≥È¢ëÂíåËßÜËßâÊï∞ÊçÆ„ÄÇËøôÁßçÂ§öÊ®°ÊÄÅÊñπÊ≥ï‰ΩøÂÖ∂ÈÄÇÁî®‰∫éÂπøÊ≥õÁöÑË°å‰∏öÔºå‰ªéÂ™í‰ΩìÂíåÂ®±‰πêÂà∞Êú∫Âô®‰∫∫ÊäÄÊúØ„ÄÇ\n2. **ÂºÄÊ∫ê**ÔºöQwen ÂèØÂú® **Hugging Face** Âíå **ModelScope** Á≠âÂπ≥Âè∞‰∏äËé∑ÂèñÔºåÂ∑≤ÁªèË¢´‰∏ãËΩΩË∂ÖËøá 4000 ‰∏áÊ¨°ÔºåÂü∫‰∫éÂÖ∂Âü∫Á°ÄÊûÑÂª∫ÁöÑËá™ÂÆö‰πâÊ®°ÂûãË∂ÖËøá 50,000 ‰∏™„ÄÇ\n3. **Â¢ûÂº∫ÊÄßËÉΩ**ÔºöQwen2.5 ÂºïÂÖ•‰∫ÜÊîπËøõÁöÑËØ≠Ë®ÄÁêÜËß£„ÄÅÊï∞Â≠¶ÂíåÁºñÁ†ÅËÉΩÂäõÔºå‰∏éËØ•È¢ÜÂüüÁöÑÈ¢ÜÂÖàÊ®°ÂûãÁ´û‰∫â„ÄÇÈÄöËøáÈíàÂØπÁªìÊûÑÂåñÊï∞ÊçÆÁêÜËß£ÂíåÈïøÊñáÊú¨ÁîüÊàêÁ≠â‰ªªÂä°ÁöÑ‰ºòÂåñÊÄßËÉΩÔºåQwen ‰∏∫È´òÁ∫ß AI Â∫îÁî®ÊâìÂºÄ‰∫ÜÂ§ßÈó®„ÄÇ\n\n## Â¶Ç‰Ωï‰ΩøÁî®ÈòøÈáåÂ∑¥Â∑¥ÁöÑ Qwen\n\nÂºÄÂèëËÄÖÂíåÁªÑÁªáÂèØ‰ª•Âú® Hugging Face Á≠âÂπ≥Âè∞‰∏äËÆøÈóÆ Qwen Ê®°ÂûãÔºåÂÖ∑‰ΩìÂèØ‰ª•Ôºö\n\n* **ÂæÆË∞ÉÊ®°Âûã**Ôºö‰∏∫ÁâπÂÆöË°å‰∏öÂ∫îÁî®ÈáèË∫´ÂÆöÂà∂ QwenÔºå‰æãÂ¶ÇÂÆ¢Êà∑ÊúçÂä°„ÄÅËá™Âä®ÂåñÊàñËßÜÈ¢ëÂÜÖÂÆπÂàõ‰Ωú„ÄÇ\n* **‰∏éÂ∫îÁî®ÈõÜÊàê**ÔºöQwen ÁöÑÊñáÊú¨ËΩ¨ËßÜÈ¢ëÊ®°ÂûãÂèØ‰ª•ÈõÜÊàêÂà∞Â™í‰ΩìÂà∂‰ΩúÊµÅÁ®ã‰∏≠Ôºå‰ªéÈùôÊÄÅÂõæÂÉèÂíåÊñáÊú¨ÊèêÁ§∫ÁîüÊàêÂä®ÊÄÅÂÜÖÂÆπ„ÄÇ\n* **ÂºÄÂèë AI Âä©Êâã**ÔºöÂÄüÂä©Â¢ûÂº∫ÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºåQwen ÂèØÁî®‰∫éÊú∫Âô®‰∫∫ÂíåËá™Âä®È©æÈ©∂Ê±ΩËΩ¶Ôºå‰ª•Â§ÑÁêÜËßÜÈ¢ëÊï∞ÊçÆÂπ∂ÊâßË°åÂÆûÊó∂‰ªªÂä°ÔºåÂ¶ÇÂØºËà™ÊàñÁâ©‰ΩìËØÜÂà´„ÄÇ\n\n**ÈÄöËøá Hugging Face ‰ΩøÁî® Qwen ÁöÑÁ§∫‰æã**Ôºö\n\n```python\nfrom transformers import QwenTokenizer, QwenModel\n\ntokenizer = QwenTokenizer.from_pretrained(\"qwen-2.5\")\nmodel = QwenModel.from_pretrained(\"qwen-2.5\")\n\ninput_text = \"What is the future of AI in healthcare?\"\ninput_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\noutputs = model(input_ids)\n```\n\nËøô‰ΩøÁî®Êà∑ËÉΩÂ§üËÆøÈóÆ Qwen Ê®°ÂûãÔºåËøêË°åÊé®ÁêÜÔºåÂπ∂Ê†πÊçÆÁâπÂÆöÈúÄÊ±ÇËøõË°åÂÆöÂà∂„ÄÇ\n\n## QwenÂú®ÂêÑË°å‰∏öÁöÑÂΩ±Âìç\n\n1. **Â™í‰Ωì‰∏éÂ®±‰πê**ÔºöÂá≠ÂÄüÊñ∞ÁöÑÊñáÊú¨Âà∞ËßÜÈ¢ëÂäüËÉΩÔºåQwenÂèØ‰ª•Ëá™Âä®‰ªé‰π¶Èù¢ËÑöÊú¨ÁîüÊàêËßÜÈ¢ëÔºåÈÄöËøáËá™Âä®ÂåñÁπÅÁêêÁöÑÂà∂‰Ωú‰ªªÂä°Êù•ÊîπÂèòÂàõÊÑè‰∫ß‰∏ö„ÄÇ\n2. **Êú∫Âô®‰∫∫ÊäÄÊúØ‰∏éËá™Âä®È©æÈ©∂ËΩ¶ËæÜ**ÔºöQwen‰∏≠Â¢ûÂº∫ÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Áé∞ÂÆû‰∏ñÁïåÁéØÂ¢ÉÔºå‰ªéËÄåÂú®Ëá™Âä®È©æÈ©∂ÊàñÂà∂ÈÄ†‰∏≠ÂÅöÂá∫Êõ¥Â•ΩÁöÑÂÜ≥Á≠ñ„ÄÇ\n3. **ËΩØ‰ª∂ÂºÄÂèë**ÔºöÁî±QwenÈ©±Âä®ÁöÑÈòøÈáåÂ∑¥Â∑¥AIÂºÄÂèëÂ∑•ÂÖ∑Ëá™Âä®Âåñ‰∫Ü‰ª£Á†ÅÁîüÊàê„ÄÅË∞ÉËØïÂíåÈúÄÊ±ÇÂàÜÊûêÁ≠â‰ªªÂä°Ôºå‰ΩøÂºÄÂèë‰∫∫ÂëòËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊõ¥È´òÂ±ÇÊ¨°ÁöÑÈóÆÈ¢òËß£ÂÜ≥„ÄÇ\n\n## ÁªìËÆ∫ÔºöÂºÄÊîæAIÂàõÊñ∞ÁöÑÊñ∞Á∫™ÂÖÉ\n\nÈÄöËøáÂºÄÊ∫êÂÖ∂Qwen 2.5Ê®°ÂûãÔºåÈòøÈáåÂ∑¥Â∑¥Ê≠£Âú®‰ΩøÂÖàËøõÁöÑAIÊäÄÊúØÂèòÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÂºÄÂèëËÄÖ„ÄÅÂàùÂàõ‰ºÅ‰∏öÂíåÂ§ßÂûã‰ºÅ‰∏öÈÉΩÂèØ‰ª•Âà©Áî®QwenÁöÑÂ§öÊ®°ÊÄÅÂíåÂÆûÊó∂ËÉΩÂäõÔºåÂú®‰ªéÂ™í‰ΩìÂà∞Ëá™Âä®È©æÈ©∂Ê±ΩËΩ¶Á≠âË°å‰∏öÊé®Âä®ÂàõÊñ∞„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÂ∏åÊúõ‰∏∫ÁâπÂÆöÂ∫îÁî®ÂæÆË∞ÉÊ®°ÂûãÁöÑÂºÄÂèëËÄÖÔºåËøòÊòØÂ∞ÜAIÈõÜÊàêÂà∞Âü∫Á°ÄËÆæÊñΩ‰∏≠ÁöÑ‰ºÅ‰∏öÔºåQwenÈÉΩÊèê‰æõÂº∫Â§ßÁöÑÂ∑•ÂÖ∑Êù•Âä†ÈÄüËøõÊ≠•„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/artifacts-top-mindblowing-uses-of-claude-3-5-sonent-6830b2acfa4b","frontmatter":{"title":"ÊñáÁâ©ÔºöClaude 3.5 Sonent ÊúÄ‰ª§‰∫∫ÊÉäÂèπÁöÑÁî®ÈÄî","meta_title":"ÊñáÁâ©ÔºöClaude 3.5 Sonent ÊúÄ‰ª§‰∫∫ÊÉäÂèπÁöÑÁî®ÈÄî","description":"Anthropic ÊúÄËøëÊé®Âá∫‰∫ÜÂÖ∂ÊúÄÂÖàËøõÁöÑÊ≥ïÂ≠¶Á°ïÂ£´ËØæÁ®ã‚ÄúClaude 3.5 Sonnet‚ÄùÔºåËøô‰ª§‰∫∫ÊÉäÂèπ„ÄÇÁ§æ‰∫§Â™í‰Ωì‰∏äÁöÑ‰∫∫‰ª¨Áß∞ËøôÁßçÊ®°Âºè‰∏∫‚Ä¶‚Ä¶","date":"2024-11-08T00:18:38.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XL1dN9VCFcbz3m5N","categories":["Programming","Natural Language Processing","Generative AI"],"author":"Rifx.Online","tags":["Sonnet","context","Artifacts","code","generation"],"draft":false,"slug":"blog/artifacts-top-mindblowing-uses-of-claude-3-5-sonent-6830b2acfa4b"},"content":"\n\n\nAnthropic ÊúÄËøëÊé®Âá∫‰∫ÜÂÖ∂ÊúÄÂÖàËøõÁöÑ LLMÔºå‚ÄúClaude 3\\.5 Sonnet‚ÄùÔºåËÆ©‰∫∫ÊÉäÂèπ„ÄÇÁ§æ‰∫§Â™í‰Ωì‰∏äÁöÑ‰∫∫‰ª¨Áß∞Ëøô‰∏ÄÊ®°Âûã‰∏∫ÂΩìÂâçÊúÄÂÖàËøõÁöÑ LLM„ÄÇËøô‰∏™ AI Ê®°ÂûãÂú®ÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫ÜÊâÄÊúâÁé∞ÊúâÁöÑ LLMÔºå‰æãÂ¶Ç GPT\\-4„ÄÅGPT\\-4o mini„ÄÅLlama 3 Á≠âÁ≠â„ÄÇClaude 3\\.5 Sonnet ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£‰∏∫ 200KÔºåÊúÄÂ§ßËæìÂá∫‰∏∫ 8192 ‰∏™ tokens„ÄÇÂÆÉÂèØ‰ª•ÁîüÊàê‰∏Ä‰∏™ÂåÖÂê´Â§ßÈáèÊï∞ÊçÆ‰Ωú‰∏∫ËæìÂÖ•ÁöÑÂ∫ûÂ§ßÊÆµËêΩ„ÄÇClaude 3\\.5 Sonnet ÊòØÊúÄÂ•ΩÁöÑ AI ËßÜËßâÊ®°Âûã‰πã‰∏ÄÔºåÂú®ÂêÑÁßçÊµãËØïÊ°à‰æã‰∏≠ÂáªË¥•‰∫Ü GPT\\-4o Âíå Llama 3„ÄÇÂÆÉÂèØ‰ª•‰ªéÊñáÊ°£Âíå PDF ‰∏≠ÊèêÂèñÊï∞ÊçÆÂíåÊñáÊú¨„ÄÇËøô‰∫õÂè™ÊòØ‰Ωø Claude 3\\.5 Sonnet Êàê‰∏∫ÊúÄ‰Ω≥ÁöÑÂá†‰∏™Âõ†Á¥†Ôºå‰ΩÜ Anthropic ËøòÊñ∞Â¢û‰∫Ü‰∏Ä‰∏™ÂäüËÉΩÔºå‰ΩøËØ• LLM Êàê‰∏∫ÊúÄ‰Ω≥‰ª£Á†ÅÁîüÊàêÂô®Ôºå‚ÄúArtifacts‚Äù„ÄÇËøôÊòØ‰∏Ä‰∏™ÂºπÂá∫Á™óÂè£ÔºåÂÖÅËÆ∏Áî®Êà∑Êü•Áúã‰ªñ‰ª¨ÁöÑ‰ª£Á†Å„ÄÅÁºñËæë‰ª£Á†ÅÔºåÂπ∂Âú®ËØ•ÂºπÂá∫Á™óÂè£‰∏≠ÂÆûÊó∂Êü•Áúã‰ªñ‰ª¨ÁöÑÈ°πÁõÆ„ÄÇÊú¨ÊñáÂ∞ÜÂ±ïÁ§∫ Artifacts Âíå Claude 3\\.5 Sonnet ÁöÑÈ°∂Á∫ßÊ°à‰æãÔºå‰ª•ÂèäÊÇ®ÂèØ‰ª•‰ΩøÁî®Ê≠§Â∑•ÂÖ∑ÂºÄÂèëÁöÑÊñ∞È°πÁõÆ„ÄÇ\n\n\n\n## Claude 3\\.5 Sonnet ÁöÑ‰ΩøÁî®Ê°à‰æã\n\nË¶Å‰ΩøÁî®Ëøô‰∫õÂ∑•‰ª∂ÔºåÊÇ®ÂøÖÈ°ªÊã•Êúâ‰∏Ä‰∏™ Claude Â∏êÊà∑„ÄÇClaude 3\\.5 Sonnet ÂØπÊâÄÊúâ‰∫∫ÂÖçË¥πÔºå‰ΩÜÊØèÂ§©‰ªÖÂÖÅËÆ∏ÊúâÈôêÁöÑËÅäÂ§©„ÄÇÁî®Êà∑ÂøÖÈ°ªË¥≠‰π∞Â§ßÁ∫¶ $20 ÁöÑËÆ¢ÈòÖÔºå‰ª•‰æøÊó†ÈôêÂà∂‰ΩøÁî®ËØ•Ê®°ÂûãËøõË°åËÅäÂ§©„ÄÇÂú® Claude 3\\.5 Sonnet ‰∏≠Â∞ùËØïËøô‰∫õÊèêÁ§∫Âπ∂ÂàõÂª∫‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÂ∑•ÂÖ∑„ÄÇÁî®Êà∑ËøòÂèØ‰ª•ÈÄöËøáÂàÜ‰∫´ÈìæÊé•Âú®‰∫íËÅîÁΩë‰∏äÂèëÂ∏É‰ªñ‰ª¨ÁöÑÈ°πÁõÆ„ÄÇ\n\n### 1\\. ‰∫íÂä®PDF‰ª™Ë°®Êùø\n\nÈòÖËØªÂ§ßÂûãPDFÊñá‰ª∂ÂæàÊó†ËÅä„ÄÇÂõ†Ê≠§ÔºåËÆ©Êàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™‰∫íÂä®PDF‰ª™Ë°®ÊùøÔºå‰ª•‰æøÊàëËÉΩÊõ¥Â•ΩÂú∞ÈòÖËØªÊàëÁöÑPDFÊñá‰ª∂„ÄÇ\n\n***ÊèêÁ§∫\\- ÂàõÂª∫‰∏Ä‰∏™‰∫íÂä®PDF‰ª™Ë°®ÊùøÔºåÂ∏ÆÂä©Êàë‰ª•Êõ¥ÂÖ∑ËßÜËßâÂê∏ÂºïÂäõÁöÑÊñπÂºèÊü•Áúã„ÄÅÈòÖËØªÂíåÂ≠¶‰π†Ëøô‰∫õ‰ø°ÊÅØ„ÄÇÂÆÉÊúâ‰∏Ä‰∏™Ê†áÁ≠æÔºåÂèØ‰ª•Ê†πÊçÆPDF‰∏≠ÁöÑ‰ø°ÊÅØËøõË°åÊµãÈ™å„ÄÇÁ°Æ‰øùÂÆÉÂÖ∑ÊúâÊöóÊ®°Âºè„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*66Iowbu8ZKA-IGfK)\n\nË¶Å‰ΩøÁî®Ê≠§ÊèêÁ§∫ÔºåÈ¶ñÂÖàÈôÑ‰∏äÊÇ®ÊÉ≥Ë¶ÅÈòÖËØªÊëòË¶ÅÁöÑPDFÂíåÊèêÁ§∫„ÄÇÁî®Êà∑ËøòÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÂñúÂ•ΩËøõË°åÊõ¥ÊîπÔºåClaude 3\\.5 SonnetÂ∞ÜÊ†πÊçÆÊõ¥ÊîπÈáçÊñ∞ÁîüÊàê‰ª£Á†Å„ÄÇ\n\n[***ÁÇπÂáªËøôÈáåÊü•ÁúãÈ°πÁõÆ***](https://claude.site/artifacts/4b9590a8-260e-476a-ab75-ec1d69f81d1e)***.***\n\n### 2\\. ‰ΩøÁî®Âä®ÁîªÂèØËßÜÂåñ‰ªª‰Ωï‰∫ãÁâ©\n\nÂèØËßÜÂåñÊÇ®ÊâÄÈòÖËØªÁöÑ‰ªª‰ΩïÂÜÖÂÆπÂèØËÉΩÊòØÁêÜËß£ÂÆÉÁöÑÊúÄ‰Ω≥ÊñπÂºè„ÄÇÊ∑ªÂä†Âä®ÁîªÂ∞Ü‰ΩøÊÇ®ÁöÑÂèØËßÜÂåñÊõ¥‰∏ä‰∏ÄÂ±ÇÊ•ºÔºå‰ΩøÂÖ∂Êòì‰∫éÁêÜËß£„ÄÇ\n\n***ÊèêÁ§∫Ôºö‰∏∫ÊØè‰∏™ËøáÁ®ãÊ≠•È™§Ê∑ªÂä†Âä®ÁîªÔºå‰ª•ÂàõÂª∫ÂÖâÂêà‰ΩúÁî®ÁöÑÂèØËßÜÂåñ„ÄÇÁ°Æ‰øù‰ΩøÁî®‰∏çÂêåÁöÑÈ¢úËâ≤ÂíåÁ∫πÁêÜ‰ΩøÊï¥‰∏™‰ª™Ë°®ÊùøÂú®ËßÜËßâ‰∏äÂê∏Âºï‰∫∫Ôºå‰ª•ÂàõÂª∫È´òË¥®ÈáèÁöÑÂä®Áîª„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*W5lWitTO5fj7lOs0)\n\nËøôÊòØÊàë‰ª¨ÂæóÂà∞ÁöÑÁ¨¨‰∏Ä‰∏™ËæìÂá∫ÔºåÂú®10ÁßíÁöÑÂ§ÑÁêÜÊó∂Èó¥ÂÜÖ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÔºå‰ΩÜÈÄöËøáÊèê‰æõÊõ¥Â§öÁöÑÊåá‰ª§ÂíåÁ≤æÁ°ÆÂ∫¶Êù•‰ºòÂåñÊèêÁ§∫ÂêéÂèØ‰ª•Êõ¥Â•Ω„ÄÇÊàë‰ª¨ÂæóÂà∞\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*TAguaCWhC1CYFNw7)\n\nÊ≠£Â¶ÇÊÇ®ÊâÄÁúãÂà∞ÁöÑÔºåÊàë‰ª¨Â∞ÜÊï¥‰∏™Âæ™ÁéØÂàÜ‰∏∫‰∏çÂêåÁöÑÈò∂ÊÆµÔºåÊúÄÁªàÁªìÊûú‰ª§‰∫∫Èöæ‰ª•ÁΩÆ‰ø°„ÄÇËøôÁßçÊñπÊ≥ïÂèØ‰ª•ÈÄöËøáÂ∞Ü‰ªª‰ΩïËøáÁ®ãÂàÜËß£‰∏∫Êõ¥ÁÆÄÂçïÁöÑÊ≠•È™§Êù•Â∏ÆÂä©ÊÇ®ÁêÜËß£„ÄÇ\n\n[***ÁÇπÂáªËøôÈáåÊü•ÁúãÈ°πÁõÆ***](https://claude.site/artifacts/b9769e4e-c20b-43da-945a-bfc41782900c)***.***\n\n### 3\\. ÁßëÂ≠¶Â∑•ÂÖ∑\n\nÁßëÂ≠¶Â∑•ÂÖ∑ÊòØÂ∏ÆÂä©Áî®Êà∑Âø´ÈÄüÂíåÁõ¥ËßÇÁêÜËß£ÁßëÂ≠¶Ê¶ÇÂøµÁöÑÂ∑•ÂÖ∑ÂíåÊúçÂä°„ÄÇÂú® Claude 3\\.5 Sonnet ÁöÑÂ∏ÆÂä©‰∏ãÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáÂçï‰∏™ÊèêÁ§∫ÂàõÂª∫ÁßëÂ≠¶Â∑•ÂÖ∑„ÄÇÂè™ÈúÄËØ¶ÁªÜÊèèËø∞ÊÇ®ÁöÑÂ∑•ÂÖ∑„ÄÇÊàëÂ∞ÜÂà©Áî®ÂÆÉ‰∏∫ÁîµÂ≠êÂ∑•Á®ãÂàõÂª∫‰∏Ä‰∏™‰∫§‰∫íÂºèÂ∑•ÂÖ∑„ÄÇ\n\n***ÊèêÁ§∫ ‚Äî ‰ΩøÁî® React ÂàõÂª∫‰∏Ä‰∏™ÊòæÁ§∫‰∫åÊûÅÁÆ°ÁöÑ‰ª™Ë°®Êùø„ÄÇÊàë‰ª¨ÂèØ‰ª•Âú®ÁîµË∑Ø‰∏≠ËøûÊé•Ê≠£ÂêëÂÅèÁΩÆÊàñÂèçÂêëÂÅèÁΩÆÔºåÂπ∂Ê†πÊçÆÊé∫ÊùÇÂíåËÄóÂ∞ΩÂå∫Á≠âÁâ©ÁêÜÂõ†Á¥†ÔºåÈÄöËøáÊòæÁ§∫‰∫åÊûÅÁÆ°‰∏≠Â≠îÂíåÁîµÂ≠êÁöÑËøêÂä®Êù•ÊîπÂèòÂú∫ÊôØ„ÄÇÂèØ‰ª•Êõ¥ÊîπÊâÄÊúâÂÜÖÂÆπÔºåÂ¶ÇÁîµÂéã„ÄÅÁîµÊµÅ„ÄÅ‰∫åÊûÅÁÆ°Á±ªÂûã„ÄÅSi Êàñ GeÔºåÂπ∂‰ΩøÁî®‰∏çÂêåÁöÑÈ¢úËâ≤ÂíåÂä®ÊÄÅÂÖÉÁ¥†ËøõË°åÂä®Áîª„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*9bE50q8nsh6_SQ36)\n\nÁî®Êà∑ÂèØ‰ª•‰ΩøÁî® Claude 3\\.5 Sonnet ÂàõÂª∫Â§ö‰∏™Â∑•ÂÖ∑Ôºå‰æãÂ¶ÇÂü∫Êú¨È°πÁõÆÂ≠¶Ê†°„ÄÅÁ£ÅÂú∫ÁöÑÁîµÊµÅÊïàÂ∫î„ÄÅÂéãÂäõ‰∏éÊ∏©Â∫¶ÂÖ≥Á≥ªÂ∑•ÂÖ∑„ÄÅÂéüÂ≠êÊ®°ÂûãÂä®ÁîªÁ≠â„ÄÇ\n\n***ÁÇπÂáª [ËøôÈáåÊü•ÁúãÈ°πÁõÆ](https://claude.site/artifacts/5b18fb27-1093-41d2-ac4e-54e47e4ddd3a)„ÄÇ***\n\n### 4\\. Ê∏∏ÊàèÂºÄÂèë\n\nÊØè‰∏™‰∫∫ÈÉΩÂñúÊ¨¢Áé©Ê∏∏Êàè„ÄÇ‰ΩøÁî® Claude 3\\.5 SonnetÔºåÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏çÂêåÁ±ªÂûãÁöÑÊ∏∏Êàè„ÄÇÊàëÂ∞Ü‰ΩøÁî® LLM Âà∂‰Ωú‰∏Ä‰∏™‰∫ïÂ≠óÊ£ãÊ∏∏Êàè„ÄÇ\n\n***ÊèêÁ§∫\\- ‰ΩøÁî® React ÂàõÂª∫‰∏Ä‰∏™‰∫ïÂ≠óÊ£ãÊ∏∏ÊàèÔºåÂπ∂‰ΩøÂÖ∂ÂäüËÉΩÊ≠£Â∏∏„ÄÇÈÄöËøá‰ΩøÁî® CSS ‰ΩøÂÖ∂Âú®ËßÜËßâ‰∏äÊõ¥ÂÖ∑Âê∏ÂºïÂäõ„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*jlSn7mCbaFadUT3F)\n\nÁªìÊûúÂèØ‰ª•Êõ¥Â•Ω„ÄÇ‰πãÂêéÔºåÊàëÂ∞ùËØïÊèê‰æõÊõ¥Â§öÂª∫ËÆÆÂíåËæìÂÖ•ÔºåÂπ∂Ê†πÊçÆÊàëÁöÑÂª∫ËÆÆÔºåClaude ÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÂÆåÁæéÁöÑ‰∫ïÂ≠óÊ£ãÊ∏∏ÊàèÔºåÁªìÊûúÂ¶Ç‰∏ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4v9KP4KFmQgY14YZ)\n\nÂ¶ÇÊÇ®ÊâÄËßÅÔºåÊúÄÁªà‰∫ßÂìÅ‰ºòÂåñ‰∫Ü CSS„ÄÇÂä®ÁîªÊúâ‰∫ÜÂæàÂ§ßÊîπÂñÑÔºåÂπ∂Âú®Ê∏∏ÊàèÁªìÊùüÊó∂Ê∑ªÂä†‰∫Ü‰∏Ä‰∏™ÂºπÂá∫Á™óÂè£ÔºåÊòæÁ§∫Ëé∑ËÉúËÄÖÁöÑÂêçÂ≠ó„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®Ëøô‰∫õÊèêÁ§∫Âà∂‰ΩúËØ∏Â¶ÇË¥™ÂêÉËõá„ÄÅÈ£ûË°åÊ£ã„ÄÅÁü≥Â§¥Ââ™ÂàÄÂ∏ÉÁ≠âÊ∏∏Êàè„ÄÇ\n\n[***ÁÇπÂáªËøôÈáåÂ∞ùËØïËØ•È°πÁõÆ„ÄÇ***](https://claude.site/artifacts/d57fdf93-79fb-443a-9bee-a58ab6eb911f)\n\n### 5\\. ÁΩëÁªúÂ∫îÁî®\n\nÁΩëÁªúÂ∫îÁî®ÊòØÂèØ‰ª•Áõ¥Êé•Âú®ÊµèËßàÂô®‰∏äËÆøÈóÆÁöÑÂ∑•ÂÖ∑ÔºåÊó†ÈúÄÂú®ÊâãÊú∫‰∏äÂÆâË£ÖÂ∫îÁî®Á®ãÂ∫è„ÄÇClaude 3\\.5 Sonnet ÂèØÁî®‰∫éÂºÄÂèë‰∏çÂêåÁ±ªÂûãÁöÑÁΩëÁªúÂ∫îÁî®„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨Â∞ÜÁ†îÁ©∂‰∏Ä‰∏™Ë¥πÁî®Ë∑üË∏™Â∫îÁî®„ÄÇ\n\n***ÊèêÁ§∫\\- ÂàõÂª∫‰∏Ä‰∏™Ë¥πÁî®Ë∑üË∏™ÁöÑÁΩëÁªúÂ∫îÁî®ÔºåÂÖ∑Â§á‰ª•‰∏ãÂäüËÉΩÔºöÈ¶ñÂÖàÔºåËØ¢ÈóÆ‰ªñ‰ª¨ÁöÑÊúàÊîØÂá∫‚Äî‚ÄîÊØîÂ¶ÇËØ¥ 2000 Âç¢ÊØî„ÄÇÁé∞Âú®ÔºåÊó†ËÆ∫Ëøô‰∏™‰∫∫Ëä±Ë¥π‰ªÄ‰πàÔºåËØ∑Á°Æ‰øùÂàõÂª∫‰∏Ä‰∫õÁ±ªÂà´ÔºåÂ¶ÇÈ£üÂìÅ„ÄÅÊóÖË°åÂíåÂøÖÈúÄÂìÅÔºåÂπ∂Êèê‰æõÊ∑ªÂä†‰ªª‰ΩïÂÜÖÂÆπÁöÑÈÄâÈ°π„ÄÇÂú®ÊúàÊú´Ê∑ªÂä†‰∏Ä‰∏™ËäÇÁúÅËµÑÈáëÁöÑÈÄâÈ°π„ÄÇÊ≠§Â§ñÔºåÂÆÉËøòÊúâÊäïËµÑÈÄâÈ°πÔºåÁé∞Âú®‰Ω†Áü•ÈÅìÊòØ‰ªÄ‰πàÁ±ªÂûãÁöÑ„ÄÇ‰æãÂ¶ÇÔºå‚ÄúÂ¶ÇÊûú‰Ω†ÊØèÊúàÂú®ÂÖ±ÂêåÂü∫Èáë‰∏≠ÊäïËµÑ 200Ôºå‰∫îÂπ¥Âêé‰Ω†Â∞ÜÊã•Êúâ X ÈáëÈ¢ù„ÄÇ‚ÄùÊ≠§Â§ñÔºåËØ•Â∫îÁî®ËøòÊúâÁîüÊàê‰∏éÊîØÂá∫Áõ∏ÂÖ≥ÁöÑÂõæË°®ÂíåÂõæÂΩ¢ÁöÑÂäüËÉΩ„ÄÇÁ°Æ‰øùËØ•Â∫îÁî®ÁöÑ UI/UX ËÆæËÆ°ËßÜËßâ‰∏äÂê∏Âºï‰∫∫„ÄÇ***\n\nËøôÊòØÊúÄÁªàÁªìÊûú„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XGOwT3vpxL0dxzzP)\n\nÁî®Êà∑ÂèØ‰ª•‰ΩøÁî® Claude 3\\.5 Sonnet ÂàõÂª∫Â§ö‰∏™Â∑•ÂÖ∑ÔºåÂ¶ÇÂæÖÂäû‰∫ãÈ°πÂàóË°®„ÄÅÁÆÄÂçïËÆ°ÁÆóÂô®„ÄÅÁîµÂΩ±Êé®ËçêÂ∫îÁî®„ÄÅÊñáÊú¨ÊëòË¶ÅÂ∑•ÂÖ∑Á≠â„ÄÇ\n\n[***ÁÇπÂáªËøôÈáåÂ∞ùËØïËØ•È°πÁõÆ***](https://claude.site/artifacts/66770d05-aafe-45c4-b938-8cda0e82b903)***.***\n\n### 6\\. 3DÊ®°Êãü\n\nClaude 3\\.5 SonentÂèØ‰ª•ÂàõÂª∫Ê®°ÂûãÊàñÈ°πÁõÆÁöÑ3DÊ®°ÊãüÔºåÊó†ËÆ∫ÊòØÂ§™Èò≥Á≥ªÊ®°Âûã„ÄÅÂéüÂ≠êÊ®°Âûã„ÄÅÂàÜÂ≠êÁîüÁâ©Â≠¶ÁöÑ‰∏≠ÂøÉÊ≥ïÂàôÁ≠â„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™LLMÂú®3D‰∏≠ÂèØËßÜÂåñ‰ªª‰ΩïÊÉ≥Ê≥ï„ÄÇÊàë‰ª¨Â∞ÜÊ®°Êãü‰∏Ä‰∏™3DÂ§™Èò≥Á≥ªÊ®°ÂûãÔºåÊâÄÊúâË°åÊòüÂõ¥ÁªïÂ§™Èò≥ÊóãËΩ¨„ÄÇ\n\n***ÊèêÁ§∫\\-Âà∂‰Ωú‰∏Ä‰∏™ÂåÖÂê´Â§™Èò≥Á≥ªÈáçÂäõÁöÑÁ©∫Èó¥Ê®°ÊãüÁöÑthree jsÂ∫îÁî®Á®ãÂ∫èÔºåÊâÄÊúâË°åÊòüÂú®‰∏Ä‰∏™ÁΩëÈ°µÊñá‰ª∂‰∏≠„ÄÇÂ§™Èò≥Á≥ª‰∏≠Ë°åÊòüÂõ¥ÁªïÂ§™Èò≥ÊóãËΩ¨‚Ä¶‚Ä¶ÊØèÂΩìÊúâ‰∫∫ÊÇ¨ÂÅúÈº†Ê†áÊó∂Ôºå‰ºöÂºπÂá∫Ë°åÊòüÁöÑÂêçÁß∞ÂíåÂü∫Êú¨ÁªÜËäÇÔºåÂ¶ÇË¥®Èáè„ÄÅÈáçÂäõÁ≠âÔºõ‰øùÊåÅÁâ©ÁêÜÊ¶ÇÂøµÔºåÂ¶ÇË°åÊòüÁöÑËá™ËΩ¨ÂíåÂÖ¨ËΩ¨ÔºåÂÆåÊï¥„ÄÇ***\n\n‰ΩøÁî®Ëøô‰∏™ÊèêÁ§∫‰ª•Ëé∑ÂæóÊâÄÈúÄÁöÑÁªìÊûú„ÄÇ\n\n***ÁÇπÂáªËøôÈáåÊü•ÁúãÈ°πÁõÆ„ÄÇ***\n\n[***È°πÁõÆ 1***](https://x.com/websim_ai/status/1803901523522699730?t=BCe28ywbC2xD1Mk4DRmo5w&s=08)\n\n[***È°πÁõÆ 2***](https://x.com/ammaar/status/1804649903815115053?t=7PeWPg62bkABtKEtKVmFbw&s=08)\n\n[***È°πÁõÆ 3***](https://x.com/goldcaddy77/status/1804724702901891313?t=iqcLQBhYaIRnt3gIBRKBQg&s=08)\n\n### 7\\. ÊÄùÁª¥ÂØºÂõæ\n\nÊÄùÁª¥ÂØºÂõæÊòØ‰∏ÄÁßçÂèØËßÜÂåñÁªÑÁªá‰ø°ÊÅØÁöÑÂ§¥ËÑëÈ£éÊö¥ÊäÄÊúØÔºåÈááÁî®Â±ÇÊ¨°ÁªìÊûÑ„ÄÇÂÖ∂‰∏ªË¶ÅÁâπÁÇπÊòØÂ∞Ü‰∏Ä‰∏™‰∏ªË¶ÅÊÄùÊÉ≥‰Ωú‰∏∫ÂõæË°®ÁöÑ‰∏≠ÂøÉÁÇπÔºåÂ≠ê‰∏ªÈ¢ò‰ªé‰∏≠ÂøÉÁÇπÂàÜÊîØÂá∫Êù•Âπ∂ËøûÊé•Âà∞ÊîØÊåÅÊÄùÊÉ≥„ÄÇËøôÊúâÂä©‰∫éËØªËÄÖÂø´ÈÄüËÆ∞ÂøÜÂíåÁêÜËß£‰ø°ÊÅØ„ÄÇËÆ©Êàë‰ª¨ÈÄöËøáÂàõÂª∫ÊÄùÁª¥ÂØºÂõæÊù•ÁîüÊàê‰∏Ä‰∏™ÊèêÁ§∫„ÄÇ\n\n***ÊèêÁ§∫ÔºöÂàõÂª∫‰∏Ä‰∏™ÂÖ≥‰∫éÁâ©‰ΩìÊ£ÄÊµãÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÊÄùÁª¥ÂØºÂõæ„ÄÇ‰ΩøÁî®Âä®ÁîªÂíåÈ¢úËâ≤‰ΩøÂÖ∂‰∫íÂä®ÊÄßÂº∫‰∏îËßÜËßâ‰∏äÂê∏Âºï‰∫∫„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*igUaLzf8b2ZTEy-m)\n\nÈÄöËøáÊõ¥Êîπ‰∏ªÈ¢òÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®Ê≠§ÊèêÁ§∫ÁîüÊàêÊÇ®ÊÉ≥Ë¶ÅÁöÑ‰ªª‰ΩïÊÄùÁª¥ÂØºÂõæ„ÄÇÊÇ®ËøòÂèØ‰ª•Ê∑ªÂä†‰∏çÂêåÁöÑÈ¢úËâ≤ÂíåÂä®ÁîªÔºå‰ΩøÂÖ∂Êõ¥Âä†‰∫íÂä®„ÄÇ\n\n[***ÁÇπÂáªËøôÈáåÂ∞ùËØïËØ•È°πÁõÆ***](https://claude.site/artifacts/f1ce9002-9434-4b40-9713-ef184c467557)\n\n### 8\\. SEOÂ∑•ÂÖ∑\n\nSEOÂØπ‰∫é‰ªª‰ΩïÂçöÂÆ¢ÊñáÁ´†Âú®Google‰∏äÁöÑÊéíÂêçËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰ΩøÁî®ClaudeÔºåÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™Â∑•ÂÖ∑ÔºåÂ∏ÆÂä©Êàë‰ª¨ÊîπÂñÑÁΩëÁ´ôÁöÑSEO„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÊèêÁ§∫Êù•Âà∂‰ΩúÊÇ®ÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n***ÊèêÁ§∫\\- ÂàõÂª∫‰∏Ä‰∏™SEOÂ∑•ÂÖ∑ÔºåÂÖÅËÆ∏Êàë‰∏ä‰º†ÊàëÁöÑÂçöÂÆ¢ÊñáÁ´†„ÄÅË°å‰∏öÂíåÊàëËØïÂõæÊéíÂêçÁöÑÂÖ≥ÈîÆÂ≠ó„ÄÇÂú®Êàë‰∏ä‰º†ÊâÄÊúâËøô‰∫õÂÜÖÂÆπÂêéÔºåÊàëÂ∏åÊúõÁÇπÂáª‰∏Ä‰∏™ÊåâÈíÆÔºåÁªôÂá∫Á™ÅÂá∫ÊòæÁ§∫ÁöÑÂª∫ËÆÆÔºåËØ¥ÊòéÈúÄË¶ÅÊõ¥ÊîπÁöÑÂÜÖÂÆπ„ÄÇÂåÖÊã¨‰∏Ä‰∏™ÈáçÁΩÆÊåâÈíÆÔºåÈáçÊñ∞ÂºÄÂßãËøô‰∏™ËøáÁ®ã„ÄÇÂπ∂‰∏îÂú®ÂÖ≥ÈîÆÂ≠óÊóÅËæπÊ∑ªÂä†‰∏Ä‰∏™Âä†Âè∑ÊåâÈíÆÔºåÊàëÂèØ‰ª•Ê∑ªÂä†Â§ö‰∏™„ÄÇÂú®SEOÂª∫ËÆÆÂå∫ÂüüÔºåÂàÜÊûêSEOÂêéÔºåÁªôÂá∫ÂÖ∑‰ΩìÁöÑÊï∞Â≠ó„ÄÅÊù•Ëá™ÊàëÁöÑÂçöÂÆ¢ÊñáÁ´†ÁöÑÁªüËÆ°Êï∞ÊçÆ‰ª•ÂèäË≠¶ÂëäÊ†áÂøóÔºå‰ª•ÊòæÁ§∫ÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑÂÜÖÂÆπ„ÄÇÂú®ÊàëÁîüÊàêÂçöÂÆ¢ÊñáÁ´†ÂêéÔºåÂü∫‰∫éÂÖ≥ÈîÆÂ≠óÁªôÂá∫‰øÆËÆ¢ÂêéÁöÑÂçöÂÆ¢ÊñáÁ´†Âª∫ËÆÆ„ÄÇÊàë‰ºöÂØπÂÖ∂ËøõË°åÊéíÂêçÔºåÂπ∂Ëß£Èáä‰∏∫‰ªÄ‰πà‰πüÊèêÂá∫Ëøô‰∏™Âª∫ËÆÆ„ÄÇÈÄöËøá‰ΩøCSSÊõ¥Âä†È´òÁ∫ßÂπ∂Ê∑ªÂä†‰∏Ä‰∏™ÊÇ®ËÆ§‰∏∫ÂøÖË¶ÅÁöÑÁã¨ÁâπÂäüËÉΩÔºå‰ΩøÂÖ∂Êõ¥ÂÖ∑‰∫íÂä®ÊÄßÔºå‰ª•Â∏ÆÂä©ÂçöÂÆ¢‰ΩúËÄÖ„ÄÇÁ°Æ‰øùËØ•Â∑•ÂÖ∑ÂÖ∑ÊúâËßÜËßâ‰∏äÂê∏Âºï‰∫∫ÁöÑUI/UXËÆæËÆ°„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*OfY0zIa4rzO7J55r)\n\nÁî®Êà∑ÂèØ‰ª•ÂàõÂª∫ÂêÑÁßçÂ∑•ÂÖ∑Ôºå‰∏ç‰ªÖÂ∏ÆÂä©‰ªñ‰ª¨ËøõË°åSEOÔºåËøòÂèØ‰ª•Âú®ÂêÑ‰∏™È¢ÜÂüüÊèêÈ´òÁîü‰∫ßÂäõ„ÄÇ\n\n[***ÁÇπÂáªËøôÈáåÂ∞ùËØïËØ•È°πÁõÆ***](https://claude.site/artifacts/09f21906-6295-4d0a-9fa0-be4afd6dab71)***.***\n\n### 9\\. ÁõÆÊ†áÊ£ÄÊµãÂ∑•ÂÖ∑\n\nÊÇ®ËøòÂèØ‰ª•‰ΩøÁî® Claude 3\\.5 Sonent Âü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÂíåÊú∫Âô®Â≠¶‰π†ËøõË°åÈ°πÁõÆÂºÄÂèë„ÄÇÊÇ®ÂèØ‰ª•Â∞ùËØïÈÄöËøáÊ∑ªÂä†ÂäüËÉΩÊù•ÂàõÂª∫‰ª§‰∫∫ÊÉäÂèπÁöÑÈ°πÁõÆ„ÄÇ\n\n***ÊèêÁ§∫ - ÂàõÂª∫‰∏Ä‰∏™Áî®‰∫éÂÆûÊó∂ÁõÆÊ†áÊ£ÄÊµãÁöÑÂçï‰∏Ä HTML Êñá‰ª∂ÁΩëÁªúÂ∫îÁî®Á®ãÂ∫è„ÄÇ‰ΩøÁî® TensorFlow.js Âíå COCO-SSD Ê®°Âûã***\n\n***ËØ•Â∫îÁî®Á®ãÂ∫èÂ∫îÔºö***\n\n* ***ËÆøÈóÆÁî®Êà∑ÁöÑÁΩëÁªúÊëÑÂÉèÂ§¥Âπ∂ÊòæÁ§∫ËßÜÈ¢ëÊµÅ„ÄÇ***\n* ***ÂØπËßÜÈ¢ëÊµÅËøõË°åÂÆûÊó∂ÁõÆÊ†áÊ£ÄÊµã„ÄÇ***\n* ***Âú®Ê£ÄÊµãÂà∞ÁöÑÂØπË±°Âë®Âõ¥ÁªòÂà∂ËæπÁïåÊ°ÜÔºåÂπ∂Áî®ÂÖ∂Á±ªÂà´ÂíåÊ£ÄÊµãÁΩÆ‰ø°Â∫¶Ê†áËÆ∞ÂÆÉ‰ª¨„ÄÇ***\n* ***Âú®ËßÜÈ¢ëÊµÅ‰∏ãÊñπÊòæÁ§∫ÂîØ‰∏ÄÊ£ÄÊµãÂà∞ÁöÑÂØπË±°ÂàóË°®ÔºåÊòæÁ§∫ÂØπË±°Á±ªÂà´ÂèäÂÖ∂È¶ñÊ¨°Ê£ÄÊµãÊó∂Èó¥„ÄÇ***\n* ***Á°Æ‰øùÊØè‰∏™ÂØπË±°Á±ªÂà´Âè™ÂàóÂá∫‰∏ÄÊ¨°ÔºåÊó†ËÆ∫ÂÖ∂Ë¢´Ê£ÄÊµãÁöÑÈ¢ëÁéáÂ¶Ç‰Ωï„ÄÇ***\n* ***‰ΩøÁî® 2 FPS ÁöÑÊ£ÄÊµãÈ¢ëÁéá‰ª•Âπ≥Ë°°ÊÄßËÉΩÂíåÂìçÂ∫îËÉΩÂäõ„ÄÇ***\n* ***ÂåÖÂê´ÂØπÊëÑÂÉèÂ§¥ËÆøÈóÆÂíåÊ®°ÂûãÂä†ËΩΩÁöÑÈîôËØØÂ§ÑÁêÜ„ÄÇ***\n* ***‰∏∫Â∫îÁî®Á®ãÂ∫èËÆæËÆ°‰∏Ä‰∏™Âπ≤ÂáÄ„ÄÅÁé∞‰ª£ÁöÑÂ§ñËßÇÔºåÂπ∂ÂÖ∑ÊúâÂìçÂ∫îÂºèËÆæËÆ°„ÄÇ***\n* ***Âú®‰∏Ä‰∏™Ëá™ÂåÖÂê´ÁöÑ HTML Êñá‰ª∂‰∏≠ÂåÖÂê´ÊâÄÊúâÂøÖË¶ÅÁöÑ HTML„ÄÅCSS Âíå JavaScript„ÄÇ***\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*QSvMcxCuulkRKOlm)\n\n## ÁªìËÆ∫\n\nClaude 3\\.5 SonnetÔºåAnthropic ÊúÄÊñ∞ÁöÑ LLMÔºåÂá≠ÂÄüÂÖ∂ÂÖàËøõÁöÑÂäüËÉΩÂíåÂ§öÊ†∑ÂåñÁöÑÂ∫îÁî®ÔºåÂΩªÂ∫ïÊîπÂèò‰∫Ü AI ËÉΩÂäõ„ÄÇËØ•Ê®°Âûã‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 200K ‰∏ä‰∏ãÊñáÁ™óÂè£„ÄÅÂçìË∂äÁöÑËßÜËßâËÉΩÂäõ‰ª•ÂèäÁî®‰∫é‰ª£Á†ÅÁîüÊàêÁöÑÂàõÊñ∞‚ÄúArtifacts‚ÄùÂäüËÉΩ‰ΩøÂÖ∂Âú®Á´û‰∫âÂØπÊâã‰∏≠ËÑ±È¢ñËÄåÂá∫„ÄÇÊú¨ÊñáÂ±ïÁ§∫‰∫Ü Claude 3\\.5 Sonnet ÁöÑÂ§öÁßç‰ΩøÁî®Ê°à‰æãÔºåËØÅÊòé‰∫ÜÂÆÉÂú®ÂàõÂª∫‰∫§‰∫íÂºè‰ª™Ë°®Êùø„ÄÅÂèØËßÜÂåñ„ÄÅÁßëÂ≠¶Â∑•ÂÖ∑„ÄÅÊ∏∏Êàè„ÄÅWeb Â∫îÁî®Á®ãÂ∫è„ÄÅ3D Ê®°Êãü„ÄÅÊÄùÁª¥ÂØºÂõæÂíå SEO Â∑•ÂÖ∑ÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇËøô‰∫õ‰æãÂ≠êÁ™ÅÊòæ‰∫ÜËØ•Ê®°ÂûãÂú®ÁÆÄÂçïÊèêÁ§∫‰∏ãÁîüÊàêÂ§çÊùÇ„ÄÅÂäüËÉΩÈΩêÂÖ®‰∏îËßÜËßâÂê∏Âºï‰∫∫ÁöÑÈ°πÁõÆÁöÑËÉΩÂäõ„ÄÇClaude 3\\.5 Sonnet ÂèãÂ•ΩÁöÑÁî®Êà∑ÁïåÈù¢ÂíåÂº∫Â§ßÁöÑËÉΩÂäõ‰ΩøÂÖ∂Êàê‰∏∫ÂºÄÂèë‰∫∫Âëò„ÄÅÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂêÑ‰∏™È¢ÜÂüü‰∏ì‰∏ö‰∫∫Â£´ÁöÑÂÆùË¥µÂ∑•ÂÖ∑Ôºå‰∏∫ AI ËæÖÂä©Âàõ‰ΩúÂíåÈóÆÈ¢òËß£ÂÜ≥ÂºÄËæü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/bolt-new-and-ollama-revolutionizing-ai-powered-full-stack-web-development-2aa6aadf5958","frontmatter":{"title":"Bolt.new Âíå OllamaÔºöÈù©Êñ∞‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂÖ®Ê†àÂºè Web ÂºÄÂèë","meta_title":"Bolt.new Âíå OllamaÔºöÈù©Êñ∞‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂÖ®Ê†àÂºè Web ÂºÄÂèë","description":"Bolt.newÊòØ‰∏ÄÊ¨æÂàõÊñ∞ÁöÑAIÈ©±Âä®ÂÖ®Ê†àWebÂºÄÂèëÂ∑•ÂÖ∑ÔºåËÉΩÂú®ÊµèËßàÂô®‰∏≠ÁÆÄÂåñÂ∫îÁî®Á®ãÂ∫èÁöÑÊûÑÂª∫‰∏éÈÉ®ÁΩ≤„ÄÇÁªìÂêàOllamaÔºåÁî®Êà∑ÂèØ‰ª•Âú®Êú¨Âú∞ËøêË°åÂºÄÊ∫êAIÊ®°ÂûãÔºåÈôç‰ΩéÊàêÊú¨Âπ∂ÊèêÂçáÁÅµÊ¥ªÊÄß„ÄÇBolt.newÈÄöËøáÂÖ®Èù¢ÊéßÂà∂ÂºÄÂèëÁéØÂ¢ÉÔºåÊîØÊåÅ‰ªéÁÆÄÂçïÁΩëÈ°µÂà∞Â§çÊùÇÈáëËûçÊúçÂä°Â∫îÁî®ÁöÑÂºÄÂèëÔºåÊûÅÂ§ßÂú∞ÊèêÈ´ò‰∫ÜÂºÄÂèëÊïàÁéáÂíå‰æøÊç∑ÊÄß„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vbo04xVLorq_rvpeEDCaAg.jpeg","categories":["Programming","Technology/Web","Data Science"],"author":"Rifx.Online","tags":["Bolt","Ollama","browser","deployment","web"],"draft":false,"slug":"blog/bolt-new-and-ollama-revolutionizing-ai-powered-full-stack-web-development-2aa6aadf5958"},"content":"\n\n\n\n\nÂú®Âø´ÈÄüÂèëÂ±ïÁöÑ Web ÂºÄÂèë‰∏ñÁïå‰∏≠ÔºåÊïàÁéáÂíåÂàõÊñ∞Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÂºÄÂèëËÄÖ„ÄÅÈ°πÁõÆÁªèÁêÜÂíåËÆæËÆ°Â∏à‰ª¨ÈÉΩÂú®‰∏çÊñ≠ÂØªÊâæËÉΩÂ§üÁÆÄÂåñÂ∑•‰ΩúÊµÅÁ®ã„ÄÅÈôç‰ΩéÊàêÊú¨ÂíåÊèêÈ´òÁîü‰∫ßÂäõÁöÑÂ∑•ÂÖ∑„ÄÇ**Bolt.new** ÊòØ‰∏ÄÊ¨æÁ™ÅÁ†¥ÊÄßÁöÑ AI È©±Âä®ÂÖ®Ê†à Web ÂºÄÂèë‰ª£ÁêÜÔºåÂÆåÂÖ®Âú®ÊÇ®ÁöÑÊµèËßàÂô®‰∏≠ËøêË°å„ÄÇ‰∏é **Ollama** ÈÖçÂêà‰ΩøÁî®ÔºåÂêéËÄÖÂÖÅËÆ∏ÊÇ®Âú®Êú¨Âú∞ËøêË°åÂºÄÊ∫ê AI Ê®°ÂûãÔºåBolt.new Â∞ÜÂΩªÂ∫ïÊîπÂèòÊàë‰ª¨ÊûÑÂª∫ÂíåÈÉ®ÁΩ≤ Web Â∫îÁî®Á®ãÂ∫èÁöÑÊñπÂºè„ÄÇÊú¨ÊñáÂ∞ÜÊ∑±ÂÖ•Êé¢ËÆ® Bolt.new„ÄÅÂÆÉ‰∏é Ollama ÁöÑÈõÜÊàêÔºåÂπ∂Êèê‰æõ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂÖ•Èó®ÊåáÂçó„ÄÇ\n\n## ÁõÆÂΩï\n\n1. Bolt.new ÁÆÄ‰ªã\n2. Bolt.new ÁöÑÁã¨Áâπ‰πãÂ§Ñ\n* ÊµèËßàÂô®‰∏≠ÁöÑÂÖ®Ê†àÂºÄÂèë\n* ÂÖ∑Â§áÁéØÂ¢ÉÊéßÂà∂ÁöÑ AI\n\n3\\. Â∞Ü Bolt.new ‰∏é Ollama ÈõÜÊàê\n\n* ‰∏∫‰ªÄ‰πà‰ΩøÁî® OllamaÔºü\n* ÂÆâË£Ö‰∏éËÆæÁΩÆ\n\n4\\. ÂÆâË£ÖÊåáÂçóÈÄêÊ≠•Ëß£Êûê\n\n* ÂâçÁΩÆÊù°‰ª∂\n* ÂÖãÈöÜ‰ª£Á†ÅÂ∫ì\n* ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè\n* ÂÆâË£Ö‰æùËµñ\n* ËøêË°åÂ∫îÁî®Á®ãÂ∫è\n\n5\\. ‰ΩøÁî® Docker ËøêË°å Bolt.new\n\n6\\. ÂÆûÈôÖÊºîÁ§∫\n\n* ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁΩëÈ°µ\n* ÊûÑÂª∫‰∏Ä‰∏™Ë¥™ÂêÉËõáÊ∏∏Êàè\n* ÂºÄÂèëÂÖ®Ê†àÈáëËûçÊúçÂä°ÁΩëÈ°µÂ∫îÁî®\n\n7\\. ÊúÄÂ§ßÂåñÂà©Áî® Bolt.new ÁöÑÊäÄÂ∑ß‰∏éÁ™çÈó®\n\n## Bolt.newÁÆÄ‰ªã\n\nBolt.new ÊòØ‰∏ÄÊ¨æÂàõÊñ∞Â∑•ÂÖ∑ÔºåÊó®Âú®ÁÆÄÂåñÊûÑÂª∫ÂÖ®Ê†à web Â∫îÁî®Á®ãÂ∫èÁöÑËøáÁ®ã„ÄÇÈÄöËøáÂà©Áî®ÂÖàËøõÁöÑ AI Ê®°ÂûãÔºåBolt.new ÂÖÅËÆ∏Áî®Êà∑Áõ¥Êé•‰ªéÊµèËßàÂô®‰∏≠ **ÊèêÁ§∫**„ÄÅ**ËøêË°å**„ÄÅ**ÁºñËæë** Âíå **ÈÉ®ÁΩ≤** Â∫îÁî®Á®ãÂ∫è„ÄÇËøôÊ∂àÈô§‰∫ÜÂ§çÊùÇÁöÑÊú¨Âú∞ËÆæÁΩÆÈúÄÊ±ÇÔºå‰Ωø web ÂºÄÂèëÂèòÂæóÊõ¥Âä†‰æøÊç∑ÂíåÈ´òÊïà„ÄÇ\n\nÊó†ËÆ∫ÊÇ®ÊòØÁªèÈ™å‰∏∞ÂØåÁöÑÂºÄÂèë‰∫∫Âëò„ÄÅË¥üË¥£Â§ö‰∏™È°πÁõÆÁöÑÈ°πÁõÆÁªèÁêÜÔºåËøòÊòØÂ∏åÊúõÂø´ÈÄüÂéüÂûãËÆæËÆ°ÁöÑËÆæËÆ°Â∏àÔºåBolt.new Êèê‰æõ‰∫Ü‰∏Ä‰∏™Â§öÂäüËÉΩÂπ≥Âè∞Ôºå‰ª•ÊúÄÂ∞èÁöÑÂä™ÂäõÂ∞ÜÊÇ®ÁöÑÊÉ≥Ê≥ïÂèò‰∏∫Áé∞ÂÆû„ÄÇ\n\n## Bolt.new ÁöÑÁã¨Áâπ‰πãÂ§Ñ\n\nËôΩÁÑ∂Êúâ‰ºóÂ§ö AI Ê®°ÂûãÂíåÂºÄÂèëÂ∑•ÂÖ∑Ôºå‰ΩÜ Bolt.new ÈÄöËøáÂÖ∂ÂÖ®Èù¢ÁöÑÂäüËÉΩÂíåÊó†ÁºùÁöÑÈõÜÊàêËÑ±È¢ñËÄåÂá∫„ÄÇ‰ª•‰∏ãÊòØ Bolt.new Áã¨Áâπ‰πãÂ§ÑÁöÑËØ¶ÁªÜ‰ªãÁªçÔºö\n\n## ÊµèËßàÂô®‰∏≠ÁöÑÂÖ®Ê†àÂºÄÂèë\n\nBolt.new Â∞ÜÊúÄÂÖàËøõÁöÑ AI Ê®°Âûã‰∏éÁî± [StackBlitz ÁöÑ WebContainers](https://github.com/stackblitz/webcontainer-core) È©±Âä®ÁöÑÊµèËßàÂô®ÂºÄÂèëÁéØÂ¢ÉÈõÜÊàêÂú®‰∏ÄËµ∑„ÄÇËøô‰∏ÄÈõÜÊàêÂÆûÁé∞‰∫Ü‰∏ÄÁ≥ªÂàóÂäüËÉΩÔºö\n\n* **ÂÆâË£ÖÂíåËøêË°å npm Â∑•ÂÖ∑ÂíåÂ∫ìÔºö** Âà©Áî®ÊµÅË°åÊ°ÜÊû∂Â¶Ç Vite„ÄÅNext.js Á≠âÔºåÊó†ÈúÄÁ¶ªÂºÄÊµèËßàÂô®„ÄÇ\n* **ËøêË°å Node.js ÊúçÂä°Âô®Ôºö** Êó†ÁºùÁÆ°ÁêÜÂêéÁ´ØÊìç‰Ωú„ÄÇ\n* **‰∏éÁ¨¨‰∏âÊñπ API ‰∫§‰∫íÔºö** ÈÄöËøáÈõÜÊàêÂêÑÁßçÊúçÂä°Â¢ûÂº∫Â∫îÁî®Á®ãÂ∫èÁöÑÂäüËÉΩ„ÄÇ\n* **ÈÄöËøáËÅäÂ§©Áõ¥Êé•ÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢ÉÔºö** ÈÄöËøáËÅäÂ§©ÁïåÈù¢Áõ¥Êé•Â∞ÜÂ∫îÁî®Á®ãÂ∫èÊé®Âêë‰∏äÁ∫ø„ÄÇ\n* **ÈÄöËøá URL ÂàÜ‰∫´Â∑•‰ΩúÔºö** ËΩªÊùæ‰∏éÂêà‰ΩúËÄÖÊàñÂà©ÁõäÁõ∏ÂÖ≥ËÄÖÂàÜ‰∫´È°πÁõÆ„ÄÇ\n\n## AI‰∏éÁéØÂ¢ÉÊéßÂà∂\n\n‰∏é‰º†ÁªüÂºÄÂèëÁéØÂ¢É‰∏≠AIÂä©Êâã‰ªÖÈôê‰∫é‰ª£Á†ÅÁîüÊàê‰∏çÂêåÔºåBolt.new‰ΩøAIÊ®°ÂûãËÉΩÂ§ü**ÂÆåÂÖ®ÊéßÂà∂**ÂºÄÂèëÁéØÂ¢É„ÄÇËøôÂåÖÊã¨ÁÆ°ÁêÜÊñá‰ª∂Á≥ªÁªü„ÄÅËäÇÁÇπÊúçÂä°Âô®„ÄÅÂåÖÁÆ°ÁêÜÂô®„ÄÅÁªàÁ´ØÂíåÊµèËßàÂô®ÊéßÂà∂Âè∞„ÄÇËøôÁßçÂÖ®Èù¢ÁöÑÊéßÂà∂‰ΩøAI‰ª£ÁêÜËÉΩÂ§üÂ§ÑÁêÜÊï¥‰∏™Â∫îÁî®Á®ãÂ∫èÁîüÂëΩÂë®Êúü‚Äî‚Äî‰ªéÂàõÂª∫Âà∞ÈÉ®ÁΩ≤‚Äî‚ÄîÊòæËëóÁÆÄÂåñ‰∫ÜÂºÄÂèëËøáÁ®ã„ÄÇ\n\n## Â∞Ü Bolt.new ‰∏é Ollama ÈõÜÊàê\n\n‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•Â¢ûÂº∫ Bolt.new ÁöÑÂäüËÉΩÂπ∂Êèê‰æõÊõ¥Â§öÁÅµÊ¥ªÊÄßÔºå‰∏é **Ollama** ÁöÑÈõÜÊàêÊòØ‰∏Ä‰∏™ÊîπÂèòÊ∏∏ÊàèËßÑÂàôÁöÑ‰∏æÊé™„ÄÇ\n\n## ‰∏∫‰ªÄ‰πà‰ΩøÁî® OllamaÔºü\n\n**Ollama** ÂÖÅËÆ∏ÊÇ®Âú®Êú¨Âú∞Êú∫Âô®‰∏äËøêË°åÂºÄÊ∫ê AI Ê®°Âûã„ÄÇËøôÁßçÈõÜÊàêÊèê‰æõ‰∫ÜÂá†‰∏™‰ºòÂäøÔºö\n\n* **ÊàêÊú¨ÊïàÁõäÔºö** ÈÅøÂÖç‰∏∫Âü∫‰∫é‰∫ëÁöÑ AI Ê®°ÂûãÊîØ‰ªò‰∏é‰ª§Áâå‰ΩøÁî®Áõ∏ÂÖ≥ÁöÑË¥πÁî®„ÄÇ\n* **ÁÅµÊ¥ªÊÄßÔºö** Ê†πÊçÆÊÇ®ÁöÑÂÅèÂ•ΩËÆøÈóÆÂêÑÁßçÊ®°ÂûãÔºå‰ªé Llama 3.2 Vision Âà∞ Deep SE Coder„ÄÇ\n* **ÈöêÁßÅÂíåÊéßÂà∂Ôºö** Êú¨Âú∞ËøêË°åÊ®°Âûã‰ª•Áª¥Êä§Êï∞ÊçÆÈöêÁßÅÂπ∂ÊéßÂà∂ÂºÄÂèëÁéØÂ¢É„ÄÇ\n\n## ÂÆâË£ÖÂíåËÆæÁΩÆ\n\nÂ∞Ü Ollama ‰∏é Bolt.new ÈõÜÊàêÊ∂âÂèäÂá†‰∏™ÁÆÄÂçïÁöÑÊ≠•È™§„ÄÇ‰ª•‰∏ãÊòØÂ∏ÆÂä©ÊÇ®ÂÖ•Èó®ÁöÑËØ¶ÁªÜÊåáÂçó„ÄÇ\n\n## Ê≠•È™§\\-ÈÄêÊ≠•ÂÆâË£ÖÊåáÂçó\n\n## ÂâçÊèêÊù°‰ª∂\n\nÂú®‰ΩøÁî® Ollama ËÆæÁΩÆ Bolt.new ‰πãÂâçÔºåËØ∑Á°Æ‰øùÊÇ®ÁöÑÁ≥ªÁªü‰∏äÂ∑≤ÂÆâË£Ö‰ª•‰∏ãÂÜÖÂÆπÔºö\n\n1. **Git:** ÂÖãÈöÜ‰ª£Á†ÅÂ∫ìÊâÄÂøÖÈúÄÁöÑÂ∑•ÂÖ∑„ÄÇ\n* [‰∏ãËΩΩ Git](https://git-scm.com/downloads)\n\n**2\\. Node.js:** Áî®‰∫éÂú®ÊúçÂä°Âô®‰∏äÊâßË°å JavaScript ÁöÑËøêË°åÊó∂ÁéØÂ¢É„ÄÇ\n\n* [‰∏ãËΩΩ Node.js](https://nodejs.org/en/download/)\n\n**3\\. DockerÔºàÂèØÈÄâÔºâÔºö** Áî®‰∫éÂÆπÂô®ÂåñÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n* [‰∏ãËΩΩ Docker](https://www.docker.com/)\n\n**4\\. Ollama:** Áî®‰∫éÊú¨Âú∞ËøêË°åÂºÄÊ∫ê AI Ê®°Âûã„ÄÇ\n\n* [‰∏ãËΩΩ Ollama](https://ollama.com/)\n\n## ÂÖãÈöÜ‰ªìÂ∫ì\n\nÈ¶ñÂÖà‰ªé GitHub ÂÖãÈöÜ Bolt.new ‰ªìÂ∫ì\n\n\n```python\ngit clone https://github.com/coleam00/bolt.new-any-llm.git\n```\n\n## ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè\n\n1. **ÈáçÂëΩÂêçÈÖçÁΩÆÊñá‰ª∂Ôºö** ÂØºËà™Âà∞ÂÖãÈöÜÁöÑ‰ªìÂ∫ìÔºåÂπ∂Â∞Ü `.env.example` Êñá‰ª∂ÈáçÂëΩÂêç‰∏∫ `.env.local`„ÄÇ\n2. **Ê∑ªÂä†ÊÇ®ÁöÑ LLM API ÂØÜÈí•Ôºö** ÊâìÂºÄ `.env.local` Êñá‰ª∂Âπ∂Ê∑ªÂä†ÊÇ®ÁöÑ API ÂØÜÈí•Ôºö\n\n```python\nGROQ_API_KEY=YOUR_GROQ_API_KEY\nOPENAI_API_KEY=YOUR_OPENAI_API_KEY\nANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY\n```\n**Ê≥®ÊÑèÔºö** Â¶ÇÊûúÊÇ®‰ΩøÁî® OllamaÔºåÂÆÉ‰∏çÈúÄË¶Å API ÂØÜÈí•ÔºåÂõ†‰∏∫ÂÆÉÂú®Êú¨Âú∞ËøêË°å„ÄÇ\n\n**3\\. ÂèØÈÄâË∞ÉËØïÁ∫ßÂà´Ôºö** ÊÇ®ÂèØ‰ª•ËÆæÁΩÆË∞ÉËØïÁ∫ßÂà´‰ª•Â∏ÆÂä©ÊïÖÈöúÊéíÈô§Ôºö\n\n```python\nVITE_LOG_LEVEL=debug\n```\n**ÈáçË¶ÅÔºö** ÂàáÂãøÂ∞ÜÊÇ®ÁöÑ `.env.local` Êñá‰ª∂Êèê‰∫§Âà∞ÁâàÊú¨ÊéßÂà∂ÔºåÂõ†‰∏∫ÂÆÉÂ∑≤ÂåÖÂê´Âú® `.gitignore` ‰∏≠„ÄÇ\n\n## ÂÆâË£Ö‰æùËµñ\n\nBolt.new ‰ΩøÁî® `pnpm` ËøõË°åÂåÖÁÆ°ÁêÜ„ÄÇ‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£Ö‰æùËµñÔºö\n\n1. **ÂÆâË£Ö pnpmÔºàÂ¶ÇÊûúÂ∞öÊú™ÂÆâË£ÖÔºâÔºö**\n\n\n```python\nsudo npm install -g pnpm\n```\n**2\\. ÂÆâË£ÖÈ°πÁõÆ‰æùËµñ**\n\n\n```python\npnpm install\n```\n\n## ËøêË°åÂ∫îÁî®Á®ãÂ∫è\n\n‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂêØÂä®ÂºÄÂèëÊúçÂä°Âô®Ôºö\n\n\n```python\npnpm run dev\n```\nËØ•ÂëΩ‰ª§ÂàùÂßãÂåñ Remix Vite ÂºÄÂèëÊúçÂä°Âô®„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÊÄßËÉΩÔºåÂª∫ËÆÆ‰ΩøÁî® [Google Chrome Canary](https://www.google.com/chrome/canary/) ‰Ωú‰∏∫ÊÇ®ÁöÑÊµèËßàÂô®„ÄÇ\n\n## ‰ΩøÁî® Docker ËøêË°å Bolt.new\n\nÂØπ‰∫éÈÇ£‰∫õÂñúÊ¨¢ÂÆπÂô®ÂåñÁéØÂ¢ÉÁöÑÁî®Êà∑ÔºåBolt.new Êèê‰æõ‰∫ÜÂº∫Â§ßÁöÑ Docker ÊîØÊåÅ„ÄÇ\n\n## ‰ΩøÁî®ËæÖÂä©ËÑöÊú¨\n\nBolt.new Êèê‰æõ‰∫ÜÁî®‰∫éÊûÑÂª∫ Docker ÈïúÂÉèÁöÑ NPM ËÑöÊú¨Ôºö\n\n* **ÂºÄÂèëÊûÑÂª∫Ôºö**\n\n\n```python\nnpm run dockerbuild\n```\n* **Áîü‰∫ßÊûÑÂª∫Ôºö**\n\n\n```python\nnpm run dockerbuild:prod\n```\n\n## Áõ¥Êé• Docker ÊûÑÂª∫ÂëΩ‰ª§\n\nÊàñËÄÖÔºå‰ΩøÁî® Docker ÁöÑÁõÆÊ†áÁâπÊÄßÊù•ÊåáÂÆöÊûÑÂª∫ÁéØÂ¢ÉÔºö\n\n* **ÂºÄÂèëÊûÑÂª∫Ôºö**\n\n\n```python\ndocker build . --target bolt-ai-development\n```\n* **Áîü‰∫ßÊûÑÂª∫Ôºö**\n\n\n```python\ndocker build . --target bolt-ai-productio\n```\n\n## Docker Compose ‰∏éÈÖçÁΩÆÊñá‰ª∂\n\n‰ΩøÁî® Docker Compose ÈÖçÁΩÆÊñá‰ª∂ÁÆ°ÁêÜ‰∏çÂêåÁöÑÁéØÂ¢ÉÔºö\n\n* **ÂºÄÂèëÁéØÂ¢ÉÔºö**\n\n```python\ndocker-compose --profile development up\n```\n* **Áîü‰∫ßÁéØÂ¢ÉÔºö**\n\n```python\ndocker-compose --profile production up\n```\n**Ê≥®ÊÑèÔºö** ÂΩì‰ΩøÁî®ÂºÄÂèëÈÖçÁΩÆÊñá‰ª∂ËøêË°å Docker Compose ÂëΩ‰ª§Êó∂ÔºåÊÇ®Êú∫Âô®‰∏ä‰ª£Á†ÅÁöÑ‰ªª‰ΩïÊõ¥ÊîπÂ∞ÜËá™Âä®ÂèçÊò†Âú®ËøêË°å‰∏≠ÁöÑÂÆπÂô®‰∏≠Ôºå‰ªéËÄåÂÆûÁé∞ÁÉ≠ÈáçËΩΩ„ÄÇ\n\n## ÂÆûÁî®ÊºîÁ§∫\n\n‰∏∫‰∫ÜÂ±ïÁ§∫ Bolt.new ÁöÑÂäüËÉΩÔºåËÆ©Êàë‰ª¨ÈÄöËøáÂá†‰∏™ÂÆûÁî®Á§∫‰æãÊù•ËøõË°åÊºîÁ§∫„ÄÇ\n\n## ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁΩëÈ°µ\n\nÂÖ∂‰∏≠‰∏Ä‰∏™ÊúÄÁÆÄÂçïÁöÑÊºîÁ§∫ÊòØÁîüÊàê‰∏Ä‰∏™Âü∫Êú¨ÁöÑÁΩëÈ°µÔºö\n\n1. **Prompt Bolt.new:** ËØ∑Ê±ÇAIÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁΩëÈ°µ„ÄÇ\n2. **Generation:** Bolt.newÁîüÊàêÊâÄÊúâÂøÖË¶ÅÁöÑÊñá‰ª∂Â§πÂíåÊñá‰ª∂„ÄÇ\n3. **Preview:** Âà©Áî®È¢ÑËßàÂäüËÉΩÂç≥Êó∂Êü•ÁúãËæìÂá∫„ÄÇ\n\nËøô‰∏™ËøáÁ®ãÂº∫Ë∞É‰∫ÜBolt.newÈ´òÊïàÂ§ÑÁêÜÁÆÄÂçï‰ªªÂä°ÁöÑËÉΩÂäõÔºå‰∏∫Êõ¥Â§çÊùÇÁöÑÈ°πÁõÆÊèê‰æõ‰∫ÜÂùöÂÆûÁöÑÂü∫Á°Ä„ÄÇ\n\n## ÊûÑÂª∫Ë¥™ÂêÉËõáÊ∏∏Êàè\n\nBolt.newÁöÑËÉΩÂäõÂú®ÂàõÂª∫‰∫§‰∫íÂºèÂ∫îÁî®Á®ãÂ∫èÊó∂ÂèòÂæóÊõ¥Âä†ÊòéÊòæÔºå‰æãÂ¶ÇË¥™ÂêÉËõáÊ∏∏ÊàèÔºö\n\n1. **ÊèêÁ§∫Bolt.newÔºö** ËØ∑Ê±ÇAIÂ∏ÆÂä©ÂàõÂª∫Ë¥™ÂêÉËõáÊ∏∏Êàè„ÄÇ\n2. **ÁîüÊàêÔºö** Bolt.newÁîüÊàêÊâÄÊúâÊâÄÈúÄÁöÑÊñá‰ª∂„ÄÅÂåÖÂíåÂâçÁ´ØÁïåÈù¢„ÄÇ\n3. **È¢ÑËßàÔºö** ÊâìÂºÄÁîüÊàêÁöÑHTMLÊñá‰ª∂ÔºåÊü•Áúã‰∏Ä‰∏™ÂäüËÉΩÈΩêÂÖ®ÁöÑË¥™ÂêÉËõáÊ∏∏ÊàèÔºåÂπ∂Ë∑üË∏™ÂæóÂàÜ„ÄÇ\n\n**ÁªìÊûúÔºö** AIÊàêÂäüÁîüÊàê‰∫Ü‰∏Ä‰∏™ËßÜËßâ‰∏äÂê∏Âºï‰∫∫‰∏îÂäüËÉΩÈΩêÂÖ®ÁöÑÊ∏∏ÊàèÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Â§ÑÁêÜÂä®ÊÄÅÂíå‰∫§‰∫íÂºèÁΩëÈ°µÂ∫îÁî®Á®ãÂ∫èÁöÑËÉΩÂäõ„ÄÇ\n\n## ÂºÄÂèëÂÖ®Ê†àÈáëËûçÊúçÂä°ÁΩëÈ°µÂ∫îÁî®\n\n‰∏∫‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑÊºîÁ§∫ÔºåËÆ©Êàë‰ª¨Êé¢ËÆ®ÊûÑÂª∫‰∏Ä‰∏™ÂÖ®Ê†àÈáëËûçÊúçÂä°Â∫îÁî®Á®ãÂ∫èÔºö\n\n1. **Prompt Bolt.new:**\n* **ÂâçÁ´Ø:** ‰ΩøÁî® React ‰Ωú‰∏∫Áî®Êà∑ÁïåÈù¢„ÄÇ\n* **ÂêéÁ´Ø:** ÂÆûÁé∞ Next.js ËøõË°åÊúçÂä°Âô®Á´ØÊ∏≤Êüì„ÄÇ\n* **Êï∞ÊçÆÂ∫ì:** ÈõÜÊàê PostgreSQL ËøõË°åÊï∞ÊçÆÁÆ°ÁêÜ„ÄÇ\n* **Ë∫´‰ªΩÈ™åËØÅ:** ‰ΩøÁî® Clerk ËøõË°åËÆæÁΩÆ„ÄÇ\n\n```python\nCreate a full-stack financial service web app with a clean, intuitive UI using ChatGPT and React for the frontend, Next.js for server-side rendering, PostgreSQL for data management, and authentication set up with Clerk.\n```\n**2\\. ÁîüÊàêËøáÁ®ã:**\n\n* **Êñá‰ª∂ÂàõÂª∫:** Bolt.new ÁîüÊàêÂøÖË¶ÅÁöÑÈ°πÁõÆÁªìÊûÑÂíåÊñá‰ª∂„ÄÇ\n* **ÂåÖÂÆâË£Ö:** ÂÆâË£ÖÊâÄÈúÄÁöÑÂåÖÔºåÂ¶Ç React„ÄÅNext.js Âíå Clerk„ÄÇ\n* **ÂêéÁ´ØËÆæÁΩÆ:** ÈÖçÁΩÆÊúçÂä°Âô®Á´ØÊ∏≤ÊüìÂíåÊï∞ÊçÆÂ∫ìËøûÊé•„ÄÇ\n* **Ë∫´‰ªΩÈ™åËØÅ:** ÈõÜÊàê Clerk ËøõË°åÁî®Êà∑Ë∫´‰ªΩÈ™åËØÅ„ÄÇ\n\n**3\\. È¢ÑËßà:** ÈÄöËøáÊèê‰æõÁöÑ URL ËÆøÈóÆÂ∫îÁî®Á®ãÂ∫èÔºåÊü•ÁúãÂÆåÊï¥ÂäüËÉΩÁöÑÈáëËûç‰ª™Ë°®ÊùøÔºåÁâπÁÇπÂåÖÊã¨Ôºö\n\n* **‰ΩôÈ¢ùÂéÜÂè≤:** ÊâÄÊúâÂ≠òÊ¨æÁöÑÊ¶ÇËø∞„ÄÇ\n* **È¢ÑÁÆóÈÖçÁΩÆ:** ËÉΩÂ§ü‰ªéÂêÑ‰∏™Á±ªÂà´Ê∑ªÂä†È¢ÑÁÆó„ÄÇ\n* **‰∫§ÊòìÁÆ°ÁêÜ:** Ê∑ªÂä†ÂíåÊü•Áúã‰∫§Êòì„ÄÇ\n* **ÊäïËµÑË∑üË∏™:** ÁõëÊéßÊäïËµÑ„ÄÇ\n\n**ÁªìÊûú:** Bolt.new È´òÊïàÂú∞ÁÆ°ÁêÜÂ§çÊùÇÂ§öÈù¢ÁöÑÂ∫îÁî®Á®ãÂ∫èÂàõÂª∫ÔºåÁ™ÅÂá∫ÂÖ∂Âú®Â§ßËßÑÊ®°È°πÁõÆ‰∏≠ÁöÑÊΩúÂäõ„ÄÇ\n\n## Tips and Tricks for Maximizing Bolt.new\n\n‰∏∫‰∫ÜÂÖÖÂàÜÂà©Áî® Bolt.newÔºåËØ∑ËÄÉËôë‰ª•‰∏ãÁ≠ñÁï•Ôºö\n\n1. **ÊòéÁ°ÆÊÇ®ÁöÑÊäÄÊúØÊ†àÔºö**\n* Âú®ÂàùÂßãÊèêÁ§∫‰∏≠Ê∏ÖÊ•öÂú∞ÊèêÂèäÊÇ®Â∏åÊúõ‰ΩøÁî®ÁöÑÊ°ÜÊû∂ÊàñÂ∫ìÔºà‰æãÂ¶ÇÔºåAstro„ÄÅTailwind„ÄÅShadCNÔºâÔºå‰ª•Á°Æ‰øù Bolt.new ÊåâÁÖßÊÇ®ÁöÑÈúÄÊ±ÇÊê≠Âª∫È°πÁõÆ„ÄÇ\n\n**2\\. ‰ΩøÁî®Â¢ûÂº∫ÊèêÁ§∫ÂõæÊ†áÔºö**\n\n* Âú®Êèê‰∫§ÊèêÁ§∫‰πãÂâçÔºå‰ΩøÁî®‚ÄúÂ¢ûÂº∫‚ÄùÂäüËÉΩÊù•‰ºòÂåñÊÇ®ÁöÑÊåá‰ª§„ÄÇËøôÂ∞ÜÂØºËá¥Êõ¥ÂáÜÁ°ÆÂíåÈ´òÊïàÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÇ\n\n**3\\. È¶ñÂÖàÊê≠Âª∫Âü∫Á°ÄÁªìÊûÑÔºö**\n\n* Âú®Ê∑ªÂä†È´òÁ∫ßÂäüËÉΩ‰πãÂâçÔºå‰ªéÂ∫îÁî®Á®ãÂ∫èÁöÑÂü∫Êú¨ÁªìÊûÑÂºÄÂßã„ÄÇËøôÊúâÂä©‰∫é Bolt.new ÁêÜËß£È°πÁõÆÂü∫Á°ÄÔºåÁ°Æ‰øùÂêéÁª≠ÂäüËÉΩÁöÑËâØÂ•ΩÈõÜÊàê„ÄÇ\n\n**4\\. ÊâπÈáèÂ§ÑÁêÜÁÆÄÂçïÊåá‰ª§Ôºö**\n\n* Â∞ÜÂ§ö‰∏™ÁÆÄÂçï‰ªªÂä°ÂêàÂπ∂‰∏∫‰∏Ä‰∏™ÊèêÁ§∫Ôºå‰ª•ËäÇÁúÅÊó∂Èó¥Âπ∂ÂáèÂ∞ë API È¢ùÂ∫¶Ê∂àËÄó„ÄÇ‰æãÂ¶ÇÔºåËØ∑Ê±ÇÊõ¥ÊîπÈÖçËâ≤ÊñπÊ°à„ÄÅÊ∑ªÂä†ÁßªÂä®ÂìçÂ∫îËÉΩÂäõÔºå‰ª•Âèä‰∏ÄÊ¨°ÊÄßÈáçÂêØÂºÄÂèëÊúçÂä°Âô®„ÄÇ\n\n**5\\. Âà©Áî®ÂºÄÊ∫êËá™ÂÆö‰πâÔºö**\n\n* Áî±‰∫é Bolt.new ÊòØÂºÄÊ∫êÁöÑÔºåËØ∑Êé¢Á¥¢ [Bolt.new GitHub ‰ªìÂ∫ì](https://github.com/coleam00/bolt.new-any-llm.git)Ôºå‰ª•Ëá™ÂÆö‰πâÂíåÊâ©Â±ïÂäüËÉΩ‰ª•Êª°Ë∂≥ÊÇ®ÁöÑÁâπÂÆöÈ°πÁõÆÈúÄÊ±Ç„ÄÇ\n\nBolt.newÔºåÁâπÂà´ÊòØÂú®‰∏é Ollama ÈõÜÊàêÊó∂Ôºå‰ª£Ë°®‰∫Ü AI È©±Âä®ÁöÑÁΩëÈ°µÂºÄÂèëÁöÑÈáçÂ§ßËøõÊ≠•„ÄÇÈÄöËøáÂ∞ÜÂÖàËøõÁöÑ AI Ê®°Âûã‰∏éÂº∫Â§ßÁöÑÂºÄÂèëÂ∑•ÂÖ∑ÁªìÂêàËµ∑Êù•ÔºåBolt.new ÁÆÄÂåñ‰∫ÜÊûÑÂª∫„ÄÅÈÉ®ÁΩ≤ÂíåÁÆ°ÁêÜÂÖ®Ê†àÂ∫îÁî®Á®ãÂ∫èÁöÑËøáÁ®ã„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÂ∏åÊúõÂä†Âø´ÂºÄÂèëÂ∑•‰ΩúÊµÅÁ®ã„ÄÅÊé¢Á¥¢ AI È©±Âä®ÁöÑÁºñÁ†ÅËæÖÂä©ÔºåËøòÊòØ‰ª•ÊúÄÂ∞èÁöÑËÆæÁΩÆÊûÑÂª∫Â§çÊùÇÁöÑÁΩëÈ°µÂ∫îÁî®Á®ãÂ∫èÔºåBolt.new ÈÉΩÊèê‰æõ‰∫ÜÂÆûÁé∞ÁõÆÊ†áÊâÄÈúÄÁöÑÂ∑•ÂÖ∑ÂíåÁÅµÊ¥ªÊÄß„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/build-a-customer-support-assistant-with-llama3-1-7bf60611e428","frontmatter":{"title":"‰ΩøÁî® Llama3.1 ÂàõÂª∫ÂÆ¢Êà∑ÊîØÊåÅÂä©ÁêÜ","meta_title":"‰ΩøÁî® Llama3.1 ÂàõÂª∫ÂÆ¢Êà∑ÊîØÊåÅÂä©ÁêÜ","description":"‰ΩøÁî® LLM ‰ª£ÁêÜÂíå Amazon Bedrock ‰ª•‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÂÆ¢Êà∑ÈóÆÈ¢òÔºö‰ΩøÁî® Llama3.1 ÊûÑÂª∫ÂíåÈÉ®ÁΩ≤ÊîØÊåÅÂä©ÁêÜÊåáÂçó","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lNyf72c2_r1wKjnoRA1_FQ.png","categories":["Programming","Chatbots","Technology/Web"],"author":"Rifx.Online","tags":["Llama3.1","AmazonBedrock","Gradio","EC2","CustomerSupport"],"draft":false,"slug":"blog/build-a-customer-support-assistant-with-llama3-1-7bf60611e428"},"content":"\n\n\n### ‰ΩøÁî® LLM ‰ª£ÁêÜÂíå Amazon Bedrock Ëß£ÂÜ≥ÂÆ¢Êà∑Êü•ËØ¢ÁöÑ AIÔºöÊûÑÂª∫ÂíåÈÉ®ÁΩ≤ÊîØÊåÅÂä©ÊâãÁöÑÊåáÂçóÔºå‰ΩøÁî® Llama3\\.1\n\n\n\n## ‰ªãÁªç\n\n### ÈóÆÈ¢ò\n\n‰ºÅ‰∏öÁªèÂ∏∏Èù¢‰∏¥Â§ÑÁêÜÂ§ßÈáèÂÆ¢Êà∑ËØ¢ÈóÆÁöÑÊåëÊàò„ÄÇËøô‰∫õËØ¢ÈóÆÂèØËÉΩ‰ªéÁÆÄÂçïÁöÑÈóÆÈ¢ò‚ÄúÊàëÁöÑËÆ¢ÂçïÁä∂ÊÄÅÊòØ‰ªÄ‰πàÔºü‚ÄùÂà∞ÈúÄË¶Å‰∫∫Â∑•Âπ≤È¢ÑÁöÑÊõ¥Â§çÊùÇÁöÑÈóÆÈ¢ò‰∏çÁ≠â„ÄÇÈáçÂ§çËØ¢ÈóÆÁöÑÂ∫ûÂ§ßÊï∞ÈáèÂèØËÉΩ‰ºö‰ΩøÂÆ¢Êà∑ÊîØÊåÅÂõ¢Èòü‰∏çÂ†™ÈáçË¥üÔºåÂØºËá¥ÂìçÂ∫îÊó∂Èó¥Âª∂ÈïøÂíåÂÆ¢Êà∑Êª°ÊÑèÂ∫¶Èôç‰Ωé„ÄÇÊ≠§Â§ñÔºåÂà©Áî®‰∫∫ÂäõËµÑÊ∫êÂ§ÑÁêÜÁÆÄÂçïÁöÑ‰æãË°åËØ¢ÈóÆÊïàÁéá‰Ωé‰∏ã‰∏îÊàêÊú¨È´òÊòÇ„ÄÇËø´ÂàáÈúÄË¶ÅËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜ‰æãË°åËØ¢ÈóÆÁöÑËá™Âä®ÂåñËß£ÂÜ≥ÊñπÊ°àÔºå‰ª•‰æø‰∫∫Á±ª‰ª£ÁêÜÂèØ‰ª•‰∏ìÊ≥®‰∫éÈúÄË¶ÅÁªÜËá¥ÈóÆÈ¢òËß£ÂÜ≥ÁöÑÂçáÁ∫ßÊ°à‰æã„ÄÇ\n\n### Ëß£ÂÜ≥ÊñπÊ°à\n\nÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰ª£ÁêÜÁöÑÂºïÂÖ•‰∏∫Ëøô‰∏™ÈóÆÈ¢òÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÂâçÊôØÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰∏Ä‰∏™ [LLM ‰ª£ÁêÜ](https://proxy.rifx.online/https://research.ibm.com/blog/what-are-ai-agents-llm) ÂèØ‰ª•ÈÄöËøáËÆøÈóÆÂíåËß£ÈáäÂÖ¨Âè∏Êï∞ÊçÆÂ∫ì‰∏≠ÁöÑÊï∞ÊçÆÊù•ÂìçÂ∫îÁî®Êà∑Êü•ËØ¢ÔºåÂ§ÑÁêÜ‰∏Ä‰∫õÁÆÄÂçïÁöÑÊìç‰ΩúÔºå‰æãÂ¶ÇÊ£ÄÊü•ËÆ¢ÂçïÁä∂ÊÄÅ„ÄÅÊ£ÄÁ¥¢Ë¥¶Êà∑‰ø°ÊÅØÂíåÂõûÁ≠îÂ∏∏ËßÅÈóÆÈ¢ò„ÄÇÈÄöËøáËá™Âä®ÂåñËøô‰∫õÊó•Â∏∏‰ªªÂä°ÔºåLLM ‰ª£ÁêÜÁ°Æ‰øù‰∫ÜÊõ¥Âø´ÁöÑËß£ÂÜ≥Êó∂Èó¥ÔºåÂπ∂ÈáäÊîæ‰∫∫ÂäõËµÑÊ∫ê‰ª•Â∫îÂØπÊõ¥Â§çÊùÇÁöÑÂÆ¢Êà∑ÊîØÊåÅÂú∫ÊôØ„ÄÇÂú®Êú¨ÊåáÂçó‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Â¶Ç‰Ωï‰ΩøÁî®Êù•Ëá™ Amazon Bedrock Tools api ÁöÑ Llama3\\.1 Ê®°ÂûãÊûÑÂª∫‰∏Ä‰∏™ÂÆ¢Êà∑ÊîØÊåÅÂä©Êâã„ÄÇ\n\nÊúÄÂêéÔºåÊàë‰ª¨Â∞ÜÂú®Êú¨Âú∞Êú∫Âô®‰∏äËøêË°åÂä©ÊâãÔºåÂπ∂Ë∞ÉÁî®‰∏Ä‰∏™ÂÅáÊï∞ÊçÆÂ∫ìÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Ok9N3mdX50JVWbaJKUrJeQ.gif)\n\n## LLM ‰ª£ÁêÜ\n\n### ‰ªÄ‰πàÊòØ LLM ‰ª£ÁêÜ\n\n[LLM ‰ª£ÁêÜ](https://proxy.rifx.online/https://research.ibm.com/blog/what-are-ai-agents-llm) ÊòØÂü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ¶Ç Llama3.1 ÊûÑÂª∫ÁöÑ‰∏ìÁî®Â∫îÁî®Á®ãÂ∫èÔºåÊó®Âú®ÊâßË°åÁâπÂÆö‰ªªÂä°ÊàñÂäüËÉΩ„ÄÇ‰∏éÊ†πÊçÆÁªôÂÆöÊèêÁ§∫ÁîüÊàêÁ±ª‰∫∫ÊñáÊú¨ÁöÑÈÄöÁî® LLM ‰∏çÂêåÔºåLLM ‰ª£ÁêÜÂÖ∑Â§áÈ¢ùÂ§ñÁöÑËÉΩÂäõÔºåÂ¶ÇËÆøÈóÆÂ§ñÈÉ®Êï∞ÊçÆÂ∫ì„ÄÅÊâßË°åÊìç‰ΩúÂíåÊ†πÊçÆÈ¢ÑÂÆö‰πâËßÑÂàôÂÅöÂá∫ÂÜ≥Á≠ñ„ÄÇÂÆÉ‰ª¨Ë¢´ÂÆöÂà∂Áî®‰∫éÂ§ÑÁêÜÁâπÂÆöÁî®‰æãÔºå‰æãÂ¶ÇÂÆ¢Êà∑ÊîØÊåÅÔºåÂú®Ëøô‰∫õÂú∫ÊôØ‰∏≠ÔºåÂÆÉ‰ª¨ÂèØ‰ª•‰∏éÁî®Êà∑‰∫íÂä®„ÄÅÊ£ÄÁ¥¢‰ø°ÊÅØÂπ∂Ê†πÊçÆÂØπËØùÁöÑ‰∏ä‰∏ãÊñáÊâßË°åÂëΩ‰ª§„ÄÇ\n\nËôΩÁÑ∂ÈÄöÁî® LLM Âú®ÁîüÊàêËøûË¥ØÊñáÊú¨ÂíåÁêÜËß£ËØ≠Ë®ÄÊñπÈù¢ÈùûÂ∏∏Âº∫Â§ßÔºå‰ΩÜ LLM ‰ª£ÁêÜÈÄöËøá‰∏éÂ§ñÈÉ®Á≥ªÁªüÈõÜÊàêÔºåËøõ‰∏ÄÊ≠•ÊãìÂ±ï‰∫ÜÂÖ∂ËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊâßË°åË∂ÖÂá∫ÊñáÊú¨ÁîüÊàêÁöÑÁé∞ÂÆû‰∏ñÁïå‰ªªÂä°„ÄÇ\n\n‰ª£ÁêÜÂÖ∑Êúâ‰∏ÄÂ•óÊåá‰ª§„ÄÅÂü∫Á°ÄÊ®°Âûã„ÄÅ‰∏ÄÁªÑÂèØÁî®Êìç‰ΩúÂíåÁü•ËØÜÂ∫ìÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊâßË°åÂ§çÊùÇ‰ªªÂä°„ÄÇ\n\nÁîüÊàêÊ®°ÂûãÂèØ‰ª•ÂõûÁ≠î‰∏ÄËà¨ÊÄßÈóÆÈ¢òÊàñ‰∏éÊÇ®ÁöÑÊñáÊ°£Áõ∏ÂÖ≥ÁöÑÈóÆÈ¢òÔºå‰æãÂ¶Ç‚ÄúÊàëÁúã‰∏çÂà∞ÊàëÁöÑ‰ºöËÆÆÔºüÊàëËØ•Â¶Ç‰ΩïÈ¢ÑÂÆö‰ºöËÆÆÔºü‚Äù„ÄÇËÄå‰ª£ÁêÜÂàô‰ΩøÁî®Âü∫Á°ÄÊ®°Âûã‰Ωú‰∏∫Êé®ÁêÜÈÄªËæëÔºåÂπ∂ÁªìÂêàÂ§ñÈÉ®Êï∞ÊçÆÊ∫êÂ¶ÇÊÇ®ÁöÑ APIÔºåËÉΩÂ§üËøîÂõûÁî®Êà∑Â∑≤È¢ÑÂÆö‰ºöËÆÆÁöÑÊï∞ÈáèÔºåÊàñÁõ¥Êé•‰ªé‰∫§‰∫íÁïåÈù¢ÂÆâÊéí‰ºöËÆÆ„ÄÇ\n\n‚ÄúÈÄöÁî®ÁõÆÁöÑ‚ÄùÁ±ªÂà´‰∏≠ÊúâËÆ∏Â§ö‰ª£ÁêÜÔºåËøòÊúâ‰∏Ä‰∫õ‰∏ìÈó®Áî®‰∫éÁâπÂÆö‰ªªÂä°ÁöÑ‰ª£ÁêÜÔºåÂ¶Ç‰ª£Á†ÅÂä©ÊâãÔºà[Amazon CodeWhisperer, Copilot](https://proxy.rifx.online/https://www.missioncloud.com/blog/github-copilot-vs-amazon-codewhisperer)Ôºâ„ÄÅÂÜô‰ΩúÂä©Êâã„ÄÅÁ≥ªÁªüËÆæËÆ°Ôºà[Amazon Q](https://proxy.rifx.online/https://aws.amazon.com/q/)Ôºâ„ÄÅÁª¥Âü∫ÁôæÁßëÊëòË¶ÅÁ≠â„ÄÇ\n\n**AI ‰ª£ÁêÜÁîüÊÄÅÁ≥ªÁªüÔºö**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VuAyzZ2BfrD7o-z0lOpUwA.png)\n\n### ‰ΩøÁî® Python ‰ªéÂ§¥ÂàõÂª∫‰∏Ä‰∏™Âü∫Êú¨‰ª£ÁêÜ\n\nËÆ©Êàë‰ª¨‰ΩøÁî® Python ‰ªéÂ§¥ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑ LLM ‰ª£ÁêÜ„ÄÇÊú¨ÊñáÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂú®‰∏ç‰æùËµñ‰ªª‰ΩïÂ∫ìÊàñÊ°ÜÊû∂ÁöÑÊÉÖÂÜµ‰∏ãÊûÑÂª∫‰ª£ÁêÜ„ÄÇ\n\n## Ëá™ÂÆö‰πâÊîØÊåÅÂä©Êâã\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨‰ΩøÁî®Êù•Ëá™ [Bedrock](https://proxy.rifx.online/https://aws.amazon.com/bedrock/) ÁöÑ [Llama3\\.1](https://proxy.rifx.online/https://llama.meta.com/) Ê®°ÂûãÂàõÂª∫‰∏Ä‰∏™Êõ¥Â§çÊùÇÁöÑÂÆ¢Êà∑ÊîØÊåÅÂä©Êâã„ÄÇËØ•‰ª£ÁêÜÂ∞ÜËÉΩÂ§üÊâßË°åÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°Ôºå‰æãÂ¶Ç‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Êü•ÊâæÁî®Êà∑Êï∞ÊçÆÂíåÊâßË°åÁÆÄÂçïÊìç‰ΩúÔºåÂ¶ÇÊü•ÁúãËÆ¢ÂçïÁöÑËøêËæìÁä∂ÊÄÅ„ÄÇ\n\n### ÂÆö‰πâËÉΩÂäõÂíåËæπÁïå\n\nÂú®ÊûÑÂª∫Êàë‰ª¨ÁöÑÂä©Êâã‰πãÂâçÔºåÂÆö‰πâ‰ª£ÁêÜÂèØ‰ª•ÊâßË°åÁöÑÊìç‰ΩúÂπ∂Âª∫Á´ãÂÖ∂Êìç‰ΩúÁöÑÊòéÁ°ÆËæπÁïåËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÔºåËøô‰∫õËÉΩÂäõÂíåËæπÁïåÂØπ‰∫éÁ°Æ‰øù‰ª£ÁêÜÊúâÊïà‰∏îÂÆâÂÖ®Âú∞ËøêË°åËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n**ËÉΩÂäõÔºö**\n\n* ÂõûÂ§çÂ∏∏ËßÅÂÆ¢Êà∑Êü•ËØ¢Ôºà‰æãÂ¶ÇÔºåËÆ¢ÂçïÁä∂ÊÄÅ„ÄÅÈÄÄË¥ßÊîøÁ≠ñÔºâ„ÄÇ\n* ‰ªéÊï∞ÊçÆÂ∫ì‰∏≠ËÆøÈóÆÂíåÊ£ÄÁ¥¢Áî®Êà∑Êï∞ÊçÆ„ÄÇ\n* ÊâßË°åÁÆÄÂçïÊìç‰ΩúÔºåÂ¶ÇÊü•ÁúãËÆ¢ÂçïÁä∂ÊÄÅ„ÄÅÊõ¥Êñ∞ÂÆ¢Êà∑‰ø°ÊÅØÁ≠â„ÄÇ\n\n**ËæπÁïåÔºö**\n\n* ‰ª£ÁêÜ‰∏çÂ∫îÊâßË°åÈúÄË¶Å‰∫∫Á±ªÂà§Êñ≠ÁöÑÊìç‰ΩúÔºå‰æãÂ¶ÇÂ§ÑÁêÜÈÄÄÊ¨æÊàñÂ§ÑÁêÜÂçáÁ∫ß„ÄÇ\n* Â∫îÂú®ÂÆö‰πâÁöÑËåÉÂõ¥ÂÜÖÊìç‰ΩúÔºåÈô§ÈùûÊòéÁ°ÆÂÖÅËÆ∏ÔºåÂê¶Âàô‰∏çÂ∫îËÆøÈóÆÊïèÊÑüÊï∞ÊçÆ„ÄÇ\n* Â∫î‰∏∫‰∏çÊîØÊåÅÁöÑÊü•ËØ¢ËÆæÁΩÆÈîôËØØÂ§ÑÁêÜÂíåÂõûÈÄÄÊú∫Âà∂„ÄÇ\n\n### Êû∂ÊûÑ\n\nÊàë‰ª¨Ëß£ÂÜ≥ÊñπÊ°àÁöÑÁ≥ªÁªüÊû∂ÊûÑÊ∂âÂèäÂ§ö‰∏™ÁªÑ‰ª∂ÂçèÂêåÂ∑•‰ΩúÔºö\n\n1. **LLM Agent**: Á≥ªÁªüÁöÑÊ†∏ÂøÉÔºå‰ΩøÁî® [Llama3\\.1](https://proxy.rifx.online/https://llama.meta.com/) Êàñ [Claude 3\\.5 Sonnet](https://proxy.rifx.online/https://www.anthropic.com/news/claude-3-5-sonnet) Ê®°ÂûãÊûÑÂª∫ÔºåÂ§ÑÁêÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÂÜ≥Á≠ñÂà∂ÂÆö„ÄÇ\n2. **Êï∞ÊçÆÂ∫ì**: Â≠òÂÇ®ÂÆ¢Êà∑Êï∞ÊçÆÂíåÂÖ∂‰ªñÁõ∏ÂÖ≥‰ø°ÊÅØÔºå‰æõ‰ª£ÁêÜÊü•ËØ¢„ÄÇ\n3. **APIÂ±Ç**: ‰øÉËøõLLM‰ª£ÁêÜ‰∏éÊï∞ÊçÆÂ∫ì‰πãÈó¥ÁöÑÈÄö‰ø°Ôºå‰Ωø‰ª£ÁêÜËÉΩÂ§üÊ£ÄÁ¥¢ÂíåÊìç‰ΩúÊï∞ÊçÆ„ÄÇ\n4. **Áî®Êà∑ÁïåÈù¢**: ‰∏Ä‰∏™ÂâçÁ´ØÁïåÈù¢Ôºà‰æãÂ¶ÇÔºåËÅäÂ§©Êú∫Âô®‰∫∫ÁïåÈù¢ÔºâÔºåÂÆ¢Êà∑Âú®Ê≠§‰∏éÊîØÊåÅÂä©Êâã‰∫íÂä®„ÄÇ\n\n### ‰ª£Á†Å\n\nÂú®Êàë‰ª¨Ê£ÄÊü•‰ª£Á†Å‰πãÂâçÔºåËØ∑Á°Æ‰øùÊÇ®ÂÖ∑Â§á‰ª•‰∏ãÊù°‰ª∂Ôºö\n\n1. ‰∫ÜËß£ Python Âíå [boto3](https://proxy.rifx.online/https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) Â∫ì„ÄÇ\n2. Êã•Êúâ‰∏Ä‰∏™ÂêØÁî®‰∫ÜÊ®°ÂûãËÆøÈóÆÁöÑÊúâÊïà AWS Ë¥¶Êà∑ÔºåÂú® [Bedrock](https://proxy.rifx.online/https://aws.amazon.com/bedrock/) ‰∏≠„ÄÇ\n3. ÂÆâË£Ö‰∫Ü Python Âíå boto3 ÁöÑ [ËôöÊãüÁéØÂ¢É](https://proxy.rifx.online/https://docs.anaconda.com/miniconda/)„ÄÇ\n\n### ‰ª£Á†ÅÊºîÁ§∫\n\n\n```python\nfrom datetime import datetime\nimport json\nfrom typing import Any, Dict, List\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n## Initialize a Boto3 session and create a Bedrock runtime client\nsession = boto3.Session()\nregion = \"us-east-1\" # us-west-2 has better runtime quota\nbedrock_client = session.client(service_name = 'bedrock-runtime', region_name = region)\n```\nÈ¶ñÂÖàÔºåÊàë‰ª¨ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂåÖÔºåÂπ∂‰∏∫ `us-east-1` Âå∫ÂüüÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ `bedrock_client` ÁöÑ `boto3` Bedrock ËøêË°åÊó∂ÂÆ¢Êà∑Á´ØÂÆû‰æã„ÄÇÂ¶ÇÊûúÊÇ®ÁöÑ AWS Ë¥¶Êà∑ÂêØÁî®‰∫Ü `us-west-2` ÂèØÁî®Âå∫ (AZ)ÔºåËØ∑ÊîπÁî®ËØ•Âå∫Âüü„ÄÇÊí∞ÂÜôÊú¨ÊñáÊó∂ÔºåLlama3\\.1 Ê®°Âûã‰ªÖÂú® `us-west-2` AZ ÂèØÁî®ÔºåÂπ∂‰∏î‰∏é‰ªÖÊîØÊåÅÊØèÂàÜÈíü 50 Ê¨°ËØ∑Ê±ÇÁöÑ `us-east-1` AZ Áõ∏ÊØîÔºå`claude-3.5-sonnet` Ê®°ÂûãÁöÑËøêË°åÊó∂ÈÖçÈ¢ùÊõ¥Â§ßÔºàÊØèÂàÜÈíü 250 Ê¨°ËØ∑Ê±ÇÔºâ„ÄÇ\n\n\n```python\n## Define available models with their respective request limits\navailable_models = {\n    \"sonnet3-5\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\", # 50 requests per min\n    \"sonnet\": \"anthropic.claude-3-sonnet-20240229-v1:0\", # 500 requests per min\n    \"llama31-70b\": \"meta.llama3-1-70b-instruct-v1:0\", # 400 requests per min\n    \"llama31-405b\": \"meta.llama3-1-405b-instruct-v1:0\", # 50 requests per min\n}\nmodelId = available_models[\"sonnet3-5\"]  # Select model for conversation\n```\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÂàõÂª∫ Bedrock ‰∏≠Ê®°Âûã ID ÁöÑÊò†Â∞Ñ„ÄÇ**ÁõÆÂâçÂπ∂ÈùûÊâÄÊúâÂèØÁî®‰∫é Amazon Bedrock ÁöÑÊ®°ÂûãÈÉΩÊîØÊåÅÂ∑•ÂÖ∑‰ΩøÁî®**„ÄÇËØ∑Êü•Áúã Amazon Bedrock Áî®Êà∑ÊåáÂçó‰∏≠ÁöÑ [ÊîØÊåÅÁöÑÊ®°ÂûãÂàóË°®](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features) [ËøôÈáå](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features)„ÄÇ\n\n\n```python\nclass FakeDatabase:\n    \"\"\"Sample fake database implementation.\"\"\"\n    def __init__(self):\n        self.customers = [\n            {\"id\": \"1213210\", \"name\": \"John Doe\", \"email\": \"john@gmail.com\", \"phone\": \"123-456-7890\", \"username\": \"johndoe\"},\n            {\"id\": \"2837622\", \"name\": \"Priya Patel\", \"email\": \"priya@candy.com\", \"phone\": \"987-654-3210\", \"username\": \"priya123\"},\n            {\"id\": \"3924156\", \"name\": \"Liam Nguyen\", \"email\": \"lnguyen@yahoo.com\", \"phone\": \"555-123-4567\", \"username\": \"liamn\"},\n            {\"id\": \"4782901\", \"name\": \"Aaliyah Davis\", \"email\": \"aaliyahd@hotmail.com\", \"phone\": \"111-222-3333\", \"username\": \"adavis\"},\n            {\"id\": \"5190753\", \"name\": \"Hiroshi Nakamura\", \"email\": \"hiroshi@gmail.com\", \"phone\": \"444-555-6666\", \"username\": \"hiroshin\"},\n            {\"id\": \"6824095\", \"name\": \"Fatima Ahmed\", \"email\": \"fatimaa@outlook.com\", \"phone\": \"777-888-9999\", \"username\": \"fatimaahmed\"},\n            {\"id\": \"7135680\", \"name\": \"Alejandro Rodriguez\", \"email\": \"arodriguez@protonmail.com\", \"phone\": \"222-333-4444\", \"username\": \"alexr\"},\n            {\"id\": \"8259147\", \"name\": \"Megan Anderson\", \"email\": \"megana@gmail.com\", \"phone\": \"666-777-8888\", \"username\": \"manderson\"},\n            {\"id\": \"9603481\", \"name\": \"Kwame Osei\", \"email\": \"kwameo@yahoo.com\", \"phone\": \"999-000-1111\", \"username\": \"kwameo\"},\n            {\"id\": \"1057426\", \"name\": \"Mei Lin\", \"email\": \"meilin@gmail.com\", \"phone\": \"333-444-5555\", \"username\": \"mlin\"}\n        ]\n\n        self.orders = [\n            {\"id\": \"24601\", \"customer_id\": \"1213210\", \"product\": \"Wireless Headphones\", \"quantity\": 1, \"price\": 79.99, \"status\": \"Shipped\"},\n            {\"id\": \"13579\", \"customer_id\": \"1213210\", \"product\": \"Smartphone Case\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Processing\"},\n            {\"id\": \"97531\", \"customer_id\": \"2837622\", \"product\": \"Bluetooth Speaker\", \"quantity\": 1, \"price\": \"49.99\", \"status\": \"Shipped\"}, \n            {\"id\": \"86420\", \"customer_id\": \"3924156\", \"product\": \"Fitness Tracker\", \"quantity\": 1, \"price\": 129.99, \"status\": \"Delivered\"},\n            {\"id\": \"54321\", \"customer_id\": \"4782901\", \"product\": \"Laptop Sleeve\", \"quantity\": 3, \"price\": 24.99, \"status\": \"Shipped\"},\n            {\"id\": \"19283\", \"customer_id\": \"5190753\", \"product\": \"Wireless Mouse\", \"quantity\": 1, \"price\": 34.99, \"status\": \"Processing\"},\n            {\"id\": \"74651\", \"customer_id\": \"6824095\", \"product\": \"Gaming Keyboard\", \"quantity\": 1, \"price\": 89.99, \"status\": \"Delivered\"},\n            {\"id\": \"30298\", \"customer_id\": \"7135680\", \"product\": \"Portable Charger\", \"quantity\": 2, \"price\": 29.99, \"status\": \"Shipped\"},\n            {\"id\": \"47652\", \"customer_id\": \"8259147\", \"product\": \"Smartwatch\", \"quantity\": 1, \"price\": 199.99, \"status\": \"Processing\"},\n            {\"id\": \"61984\", \"customer_id\": \"9603481\", \"product\": \"Noise-Cancelling Headphones\", \"quantity\": 1, \"price\": 149.99, \"status\": \"Shipped\"},\n            {\"id\": \"58243\", \"customer_id\": \"1057426\", \"product\": \"Wireless Earbuds\", \"quantity\": 2, \"price\": 99.99, \"status\": \"Delivered\"},\n            {\"id\": \"90357\", \"customer_id\": \"1213210\", \"product\": \"Smartphone Case\", \"quantity\": 1, \"price\": 19.99, \"status\": \"Shipped\"},\n            {\"id\": \"28164\", \"customer_id\": \"2837622\", \"product\": \"Wireless Headphones\", \"quantity\": 2, \"price\": 79.99, \"status\": \"Processing\"}\n        ]\n\n    def get_user(self, key:str, value:str) -> Dict[str, str]:\n        \"\"\"Return metadata of user.\"\"\"\n        if key in {\"email\", \"phone\", \"username\"}:\n            for customer in self.customers:\n                if customer[key] == value:\n                    return customer\n            return f\"Couldn't find a user with {key} of {value}\"\n        else:\n            raise ValueError(f\"Invalid key: {key}\")\n        \n        return None\n\n    def get_order_by_id(self, order_id: str) -> Dict[str, str]:\n        \"\"\"Return metadata of the order using order id.\"\"\"\n        for order in self.orders:\n            if order[\"id\"] == order_id:\n                return order\n        return None\n    \n    def get_customer_orders(self, customer_id: str) -> List[Dict[str, str]]:\n        \"\"\"Return a list of orders for a specific customer.\"\"\"\n        return [order for order in self.orders if order[\"customer_id\"] == customer_id]\n\n    def cancel_order(self, order_id: str) -> str:\n        \"\"\"Cancel an order if it's in 'Processing' status.\"\"\"\n        order = self.get_order_by_id(order_id)\n        if order:\n            if order[\"status\"] == \"Processing\":\n                order[\"status\"] = \"Cancelled\"\n                return \"Cancelled the order\"\n            else:\n                return \"Order has already shipped.  Can't cancel it.\"\n        return \"Can't find that order!\"\n```\nÂú®Êú¨ÊºîÁ§∫‰∏≠ÔºåÊàë‰ª¨ÂÆûÁé∞‰∫Ü‰∏Ä‰∏™Ê®°ÊãüÊï∞ÊçÆÂ∫ìÁ±ªÔºåÂÖ∂‰∏≠ÂåÖÂê´È¢ÑÂÆö‰πâÁöÑÂÆ¢Êà∑ÂèäÂÖ∂ËÆ¢ÂçïÂàóË°®„ÄÇËøô‰∏™Ê®°ÊãüÊï∞ÊçÆÂ∫ìÁ±ªËøòÂåÖÊã¨‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢Êï∞ÊçÆÁöÑÊñπÊ≥ï„ÄÇ\n\n* `get_user` : ËøîÂõûÁî®Êà∑\n* `get_order_by_id` : ‰ΩøÁî®ËÆ¢Âçï ID ËøîÂõûËÆ¢Âçï\n* `get_customer_orders` : ËøîÂõûÁâπÂÆöÂÆ¢Êà∑ÁöÑÊâÄÊúâËÆ¢Âçï\n* `cancel_order` : Â¶ÇÊûúËÆ¢ÂçïÂ§Ñ‰∫é‚ÄúÂ§ÑÁêÜ‰∏≠‚ÄùÁä∂ÊÄÅÔºåÂàôÂèñÊ∂àËÆ¢Âçï„ÄÇ\n\n\n```python\n## Define all the tools avilable to the model\ntool_config = {\n    \"tools\": [\n        {\n            \"toolSpec\": {\n                \"name\": \"get_user\",\n                \"description\": \"Looks up a user by email, phone, or username.\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"key\": {\n                                \"type\": \"string\",\n                                \"enum\": [\"email\", \"phone\", \"username\"],\n                                \"description\": \"The attribute to search for a user by (email, phone, or username).\",\n                            },\n                            \"value\": {\n                                \"type\": \"string\",\n                                \"description\": \"The value to match for the specified attribute.\",\n                            },\n                        },\n                        \"required\": [\"key\", \"value\"],\n                    }\n                },\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"get_order_by_id\",\n                \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"order_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The unique identifier for the order.\",\n                            }\n                        },\n                        \"required\": [\"order_id\"],\n                    }\n                },\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"get_customer_orders\",\n                \"description\": \"Retrieves the list of orders belonging to a user based on a user's customer id.\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"customer_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The customer_id belonging to the user\",\n                            }\n                        },\n                        \"required\": [\"customer_id\"],\n                    }\n                },\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"cancel_order\",\n                \"description\": \"Cancels an order based on a provided order_id.  Only orders that are 'processing' can be cancelled\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"order_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The order_id pertaining to a particular order\",\n                            }\n                        },\n                        \"required\": [\"order_id\"],\n                    }\n                },\n            }\n        },\n    ],\n    \"toolChoice\": {\"auto\": {}},\n}\n```\nÊé•‰∏ãÊù•Êàë‰ª¨ÂÆö‰πâ‰∏Ä‰∏™ `tool_config` „ÄÇ\n\nÊÇ®ÂèØ‰ª•‰ΩøÁî® Amazon Bedrock API ‰∏∫Ê®°ÂûãÊèê‰æõËÆøÈóÆ [Â∑•ÂÖ∑](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html)ÔºåÂ∏ÆÂä©ÂÖ∂ÁîüÊàêÊÇ®ÂèëÈÄÅÁªôÊ®°ÂûãÁöÑÊ∂àÊÅØÁöÑÂìçÂ∫î„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØËÉΩÊúâ‰∏Ä‰∏™ËÅäÂ§©Â∫îÁî®Á®ãÂ∫èÔºåËÆ©Áî®Êà∑Êü•ÊâæÂπøÊí≠ÁîµÂè∞Êí≠ÊîæÁöÑÊúÄÂèóÊ¨¢ËøéÁöÑÊ≠åÊõ≤„ÄÇ‰∏∫‰∫ÜÂõûÁ≠îÊúâÂÖ≥ÊúÄÂèóÊ¨¢ËøéÊ≠åÊõ≤ÁöÑËØ∑Ê±ÇÔºåÊ®°ÂûãÈúÄË¶Å‰∏Ä‰∏™ÂèØ‰ª•Êü•ËØ¢Âπ∂ËøîÂõûÊ≠åÊõ≤‰ø°ÊÅØÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n> ‰∏éÊ®°Âûã‰∏ÄËµ∑‰ΩøÁî®Â∑•ÂÖ∑‰πüË¢´Áß∞‰∏∫ *ÂáΩÊï∞Ë∞ÉÁî®*„ÄÇ\n\nÂú® Amazon Bedrock ‰∏≠ÔºåÊ®°ÂûãÂπ∂‰∏çÁõ¥Êé•Ë∞ÉÁî®Â∑•ÂÖ∑„ÄÇÁõ∏ÂèçÔºåÂΩìÊÇ®ÂêëÊ®°ÂûãÂèëÈÄÅÊ∂àÊÅØÊó∂ÔºåÊÇ®ËøòÊèê‰æõ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Â∑•ÂÖ∑ÁöÑÂÆö‰πâÔºåËøô‰∫õÂ∑•ÂÖ∑ÂèØËÉΩ‰ºöÂ∏ÆÂä©Ê®°ÂûãÁîüÊàêÂìçÂ∫î„ÄÇÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊÇ®Â∞ÜÊèê‰æõ‰∏Ä‰∏™ËøîÂõûÂÆ¢Êà∑ËØ¶ÊÉÖ„ÄÅËÆ¢ÂçïËØ¶ÊÉÖÊàñÂèñÊ∂àËÆ¢ÂçïÁöÑÂ∑•ÂÖ∑ÂÆö‰πâ„ÄÇÂ¶ÇÊûúÊ®°ÂûãÁ°ÆÂÆöÈúÄË¶ÅÂ∑•ÂÖ∑Êù•ÁîüÊàêÊ∂àÊÅØÁöÑÂìçÂ∫îÔºåÊ®°ÂûãÂ∞ÜÂõûÂ§çÊÇ®ËØ∑Ê±ÇË∞ÉÁî®ËØ•Â∑•ÂÖ∑„ÄÇÂÆÉËøòÂåÖÊã¨Ë¶Å‰º†ÈÄíÁªôÂ∑•ÂÖ∑ÁöÑËæìÂÖ•ÂèÇÊï∞ÔºàÊâÄÈúÄÁöÑÂÆ¢Êà∑ ID ÊàñËÆ¢Âçï IDÔºâ„ÄÇ\n\nÂú®ÊÇ®ÁöÑ‰ª£Á†Å‰∏≠ÔºåÊÇ®‰ª£Ë°®Ê®°ÂûãË∞ÉÁî®Â∑•ÂÖ∑„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂÅáËÆæÂ∑•ÂÖ∑ÂÆûÁé∞ÊòØ‰∏Ä‰∏™ API„ÄÇÂ∑•ÂÖ∑‰πüÂèØ‰ª•ÊòØÊï∞ÊçÆÂ∫ì„ÄÅLambda ÂáΩÊï∞ÊàñÂÖ∂‰ªñËΩØ‰ª∂„ÄÇÊÇ®ÂÜ≥ÂÆöÂ¶Ç‰ΩïÂÆûÁé∞Â∑•ÂÖ∑„ÄÇÁÑ∂ÂêéÔºåÊÇ®ÈÄöËøáÊèê‰æõÂ∑•ÂÖ∑ÁªìÊûúÁöÑÊ∂àÊÅØ‰∏éÊ®°ÂûãÁªßÁª≠ÂØπËØù„ÄÇÊúÄÂêéÔºåÊ®°ÂûãÁîüÊàê‰∏Ä‰∏™ÂåÖÂê´ÊÇ®ÂèëÈÄÅÁªôÊ®°ÂûãÁöÑÂ∑•ÂÖ∑ÁªìÊûúÁöÑÂéüÂßãÊ∂àÊÅØÁöÑÂìçÂ∫î„ÄÇ\n\nÂú®Êàë‰ª¨ÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨Âú® `tool_config` ‰∏≠ÂÆö‰πâ‰∫ÜÊàë‰ª¨Â∏åÊúõËÅäÂ§©Êú∫Âô®‰∫∫ÊâßË°åÁöÑÊâÄÊúâÂäüËÉΩ„ÄÇÊúâÂÖ≥ ToolConfiguration API ÁöÑÊõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ [Amazon Bedrock ÊñáÊ°£](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ToolConfiguration.html)„ÄÇ\n\n```python\ndef process_tool_call(tool_name: str, tool_input: Any) -> Any:\n    \"\"\"Process the tool call based on the tool name and input.\"\"\"\n    if tool_name == \"get_user\":\n        return db.get_user(tool_input[\"key\"], tool_input[\"value\"])\n    elif tool_name == \"get_order_by_id\":\n        return db.get_order_by_id(tool_input[\"order_id\"])\n    elif tool_name == \"get_customer_orders\":\n        return db.get_customer_orders(tool_input[\"customer_id\"])\n    elif tool_name == \"cancel_order\":\n        return db.cancel_order(tool_input[\"order_id\"])\n```\nÁî±‰∫éÊàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫è‰ª£Á†ÅÂ∞Ü‰ª£Ë°® LLM Ë∞ÉÁî®ÊâÄÈúÄÁöÑÂ∑•ÂÖ∑ÔºåÊàë‰ª¨Â∞ÜÊâÄÊúâÂ∑•ÂÖ∑ÊâìÂåÖÂà∞‰∏Ä‰∏™Âçï‰∏ÄÁöÑÂáΩÊï∞‰∏≠„ÄÇ`process_tool_call` ÂáΩÊï∞Ê†πÊçÆ LLM Êèê‰æõÁöÑ `tool_name` Âíå `tool_input` ÊâßË°åÁõ∏Â∫îÁöÑÂäüËÉΩ„ÄÇ\n\n```python\ndef simple_chat():\n    \"\"\"Main chat function that interacts with the user and the LLM.\"\"\"\n    system_prompt = \"\"\"\n    You are a customer support chat bot for an online retailer called TechNova. \n    Your job is to help users look up their account, orders, and cancel orders.\n    Be helpful and brief in your responses.\n    You have access to a set of tools, but only use them when needed.  \n    If you do not have enough information to use a tool correctly, ask a user follow up questions to get the required inputs.\n    Do not call any of the tools unless you have the required data from a user. \n    \"\"\"\n    # Initial user message\n    user_message = input(\"\\nUser: \")\n    messages = [{\"role\": \"user\", \"content\": [{\"text\": user_message}]}]\n\n    while True:\n        # If the last message is from the assistant, get another input from the user\n        if messages[-1].get(\"role\") == \"assistant\":\n            user_message = input(\"\\nUser: \")\n            messages.append({\"role\": \"user\", \"content\": [{\"text\": user_message}]})\n\n        # Parameters for API request to the Bedrock model\n        converse_api_params = {\n            \"modelId\": modelId,\n            \"system\": [{\"text\": system_prompt}],\n            \"messages\": messages,\n            \"inferenceConfig\": {\"maxTokens\": 4096},\n            \"toolConfig\": tool_config,  # Pass the tool config\n        }\n\n        # Get response from Bedrock model\n        response = bedrock_client.converse(**converse_api_params)\n\n        # Append assistant's message to the conversation\n        messages.append(\n            {\"role\": \"assistant\", \"content\": response[\"output\"][\"message\"][\"content\"]}\n        )\n\n        # If the model wants to use a tool, process the tool call\n        if response[\"stopReason\"] == \"tool_use\":\n            tool_use = response[\"output\"][\"message\"][\"content\"][\n                -1\n            ]  # Naive approach assumes only 1 tool is called at a time\n            tool_id = tool_use[\"toolUse\"][\"toolUseId\"]\n            tool_name = tool_use[\"toolUse\"][\"name\"]\n            tool_input = tool_use[\"toolUse\"][\"input\"]\n\n            print(f\"Claude wants to use the {tool_name} tool\")\n            print(f\"Tool Input:\")\n            print(json.dumps(tool_input, indent=2))\n\n            # Run the underlying tool functionality on the fake database\n            tool_result = process_tool_call(tool_name, tool_input)\n\n            print(f\"\\nTool Result:\")\n            print(json.dumps(tool_result, indent=2))\n\n            # Append tool result message\n            messages.append(\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"toolResult\": {\n                                \"toolUseId\": tool_id,\n                                \"content\": [{\"text\": str(tool_result)}],\n                            }\n                        }\n                    ],\n                }\n            )\n\n        else:\n            # If the model does not want to use a tool, just print the text response\n            print(\n                \"\\nTechNova Support:\"\n                + f\"{response['output']['message']['content'][0]['text']}\"\n            )\n```\n`simple_chat` ÂáΩÊï∞Â§ÑÁêÜÁî®Êà∑‰∫§‰∫íÔºåË∞ÉÁî® LLMÔºåÂπ∂Â∞ÜÂ∑•ÂÖ∑ÂìçÂ∫î‰º†Âõû LLM„ÄÇ\n\nËØ•ÂáΩÊï∞‰∏≠ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅË°åÊòØ `response[\"stopReason\"] == \"tool_use\"`„ÄÇËøôÂÜ≥ÂÆö‰∫Ü LLM ÊòØÂê¶ÊÉ≥Ë¶Å‰ΩøÁî®Â∑•ÂÖ∑ÔºåÂπ∂Âú®Ëøõ‰∏ÄÊ≠•Ëß£ÊûêÊó∂ÊåáÁ§∫ LLM ÊâìÁÆóË∞ÉÁî®Âì™‰∏™Â∑•ÂÖ∑„ÄÇ\n\n‰ª•‰∏ãÊòØ bedrock-runtime `converse` API ÁöÑÂìçÂ∫îÂØπË±°Á§∫‰æãÔºö\n\n```python\n{\n    'ResponseMetadata': {\n        'RequestId': '07f323a7-cc52-4813-9d1b-83e5c3ae932a', \n        'HTTPStatusCode': 200, \n        'HTTPHeaders': {\n            'date': 'Thu, 08 Aug 2024 10:52:59 GMT', \n            'content-type': 'application/json', \n            'content-length': '519', \n            'connection': 'keep-alive', \n            'x-amzn-requestid': '07f323a7-cc52-4813-9d1b-83e5c3ae932a'\n        }, \n        'RetryAttempts': 0\n    }, \n    'output': {\n        'message': {\n            'role': 'assistant', 'content': [\n                {\n                    'text': \"Certainly! I'll search for search for your orders. Let me use our search tool to find that information for you.\"\n                }, {\n                    'toolUse': {\n                        'toolUseId': 'tooluse_8C_XIwrAROC3t3eEu5FCVw', \n                        'name': 'get_customer_orders', \n                        'input': {'customer_id': '1213210'}\n                    }\n                }\n            ]\n        }\n    }, \n    'stopReason': 'tool_use',\n    'usage': {'inputTokens': 672, 'outputTokens': 103, 'totalTokens': 775}, \n    'metrics': {'latencyMs': 2431}\n}\n```\nÊúâÂÖ≥ Converse API ÁöÑÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ [Amazon Bedrock API ÂèÇËÄÉ](https://proxy.rifx.online/https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html)„ÄÇ\n\n‰∏ÄÊó¶Êàë‰ª¨‰ΩøÁî® `process_tool_call` ÂáΩÊï∞Ë∞ÉÁî®ÊâÄÈúÄÁöÑÂ∑•ÂÖ∑ÊàñÂäüËÉΩÔºåÊàë‰ª¨Â∞ÜÂáΩÊï∞ÁöÑÂìçÂ∫î‰º†Âõû LLMÔºå‰ª•ÁîüÊàêÊúÄÁªàÁî®Êà∑ÁöÑÂìçÂ∫î„ÄÇ\n\nËØ∑Ê≥®ÊÑèÔºåÊàë‰ª¨Ê≠£Âú®‰ΩøÁî® boto3 Bedrock ËøêË°åÊó∂ÂÆ¢Êà∑Á´ØÁöÑ Converse API„ÄÇÊÇ®ËøòÂèØ‰ª•‰ΩøÁî® Converse Stream API ÁîüÊàêÊµÅÂºèÂìçÂ∫î„ÄÇÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ Amazon Bedrock API ÂèÇËÄÉ‰∏≠ÁöÑ Converse Stream API Âíå Boto3 ÊñáÊ°£‰∏≠ÁöÑ Converse Stream API„ÄÇ\n\n### Âú®Êú¨Âú∞ÁªàÁ´ØËøêË°å\n\n‰∏ÄÊó¶ÊÇ®Ê≠£Á°ÆËÆæÁΩÆ‰∫ÜÊâÄÊúâÂÜÖÂÆπÔºåËØ∑Âú®ËôöÊãüÁéØÂ¢É‰∏≠ËøêË°å Python Êñá‰ª∂Ôºå‰ΩøÁî®Ôºö\n\n```python\n## ‰ªéËôöÊãüÁéØÂ¢ÉÂÜÖÈÉ®\npython main.py\n```\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Ok9N3mdX50JVWbaJKUrJeQ.gif)\n\n## Âú® EC2 ‰∏äÈÉ®ÁΩ≤\n\nÊÇ®ÂèØ‰ª•Âú® EC2 ÂÆû‰æã‰∏äÈÉ®ÁΩ≤ËÅäÂ§©Êú∫Âô®‰∫∫‰ª•ËøõË°åÊºîÁ§∫Ôºå‰ΩøÁî® [Gradio](https://proxy.rifx.online/https://www.gradio.app/) Â∫îÁî®Á®ãÂ∫èÔºåÂÆÉÂè™ÈúÄÂá†Ë°å‰ª£Á†ÅÂç≥ÂèØÊèê‰æõÁ±ª‰ººËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÁïåÈù¢ÔºåÂπ∂‰∏éÊàë‰ª¨ÁöÑ‰∏ªÂáΩÊï∞Êó†ÁºùÈõÜÊàê„ÄÇ\n\n### Gradio\n\n[Gradio](https://proxy.rifx.online/https://www.gradio.app/) ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑ Python Â∫ìÔºåÁÆÄÂåñ‰∫ÜÊûÑÂª∫ÂíåÈÉ®ÁΩ≤Âü∫‰∫éÁΩëÈ°µÁöÑÊú∫Âô®Â≠¶‰π†ÊºîÁ§∫ÁöÑËøáÁ®ã„ÄÇÂÆÉÂÖÅËÆ∏ÂºÄÂèëËÄÖ‰ª•ÊúÄÂ∞ëÁöÑÁºñÁ†ÅÂàõÂª∫Áõ¥ËßÇÁöÑÁΩëÈ°µÁïåÈù¢Ôºå‰ΩøÂæóÈÉ®ÁΩ≤ÂíåÂàÜ‰∫´Ê®°ÂûãÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇ\n\nËÆ©Êàë‰ª¨ÁºñÂÜô‰∏Ä‰∏™ËÅäÂ§©ÂáΩÊï∞ÔºåÈöèÊú∫ÂìçÂ∫î `Yes` Êàñ `No`Ôºå‰ΩøÁî® gradio„ÄÇ\n\nËøôÊòØÊàë‰ª¨ÁöÑËÅäÂ§©ÂáΩÊï∞ÔºàÂ¶ÇÊûúÊÇ®ËøòÊ≤°ÊúâÂÆâË£ÖÔºåËØ∑Âú®ÊÇ®ÁöÑËôöÊãüÁéØÂ¢É‰∏≠ÊâßË°å `pip install gradio`ÔºâÔºö\n\n```python\nimport random\n\nimport gradio as gr\n\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n\ngr.ChatInterface(random_response).launch()\n```\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XxkUM6yO3lmjN545tRlOvQ.png)\n\nÈòÖËØªÊõ¥Â§öÂÖ≥‰∫é [gradio ËÅäÂ§©Êú∫Âô®‰∫∫ÊñáÊ°£ÁöÑ‰ø°ÊÅØ](https://proxy.rifx.online/https://www.gradio.app/main/docs/gradio/chatbot)„ÄÇ\n\n### Âú®ÊÇ®ÁöÑ Web ÊúçÂä°Âô®‰∏ä‰ΩøÁî® Nginx ËøêË°å Gradio Â∫îÁî®\n\nËÆ©Êàë‰ª¨Âú® EC2 ‰∏ä‰ΩøÁî® Nginx ÈÉ®ÁΩ≤Êàë‰ª¨ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫‰ª£ÁêÜ„ÄÇ\n\n**ÂÆâË£Ö Nginx Âπ∂ÂàõÂª∫Êñ∞ÁöÑ conda ÁéØÂ¢É**\n\n1. **ÂàõÂª∫‰∏Ä‰∏™Ëá≥Â∞ëÊúâ 2‚Äì3 GB ÂÜÖÂ≠òÁöÑ EC2 ÂÆû‰æã**„ÄÇÊÇ®‰πüÂèØ‰ª•Âú® Kubernetes Êàñ ECS ÈõÜÁæ§‰∏äÈÉ®ÁΩ≤„ÄÇÁ°Æ‰øù‰øÆÊîπ Nginx ÈÖçÁΩÆÊñá‰ª∂‰ª•ÂåπÈÖçÊÇ®ÁöÑËÆæÁΩÆ„ÄÇ\n\n2\\. **SSH ËøõÂÖ•ÊÇ®ÁöÑ EC2 ÂÆû‰æã**Âπ∂ [ÂÆâË£Ö Nginx](https://proxy.rifx.online/https://devopsden.io/article/how-to-install-nginx-on-ec2-instance):\n\n\n```python\nsudo yum update -y\nsudo amazon-linux-extras install nginx1.12\nsudo systemctl start nginx\nsudo systemctl enable nginx\nsudo systemctl status nginx\n```\n3\\. [**ÂÆâË£Ö Miniconda**](https://proxy.rifx.online/https://docs.anaconda.com/miniconda/#quick-command-line-install) ‰ª•ÁÆ°ÁêÜ Python ÂåÖ:\n\n\n```python\nmkdir -p ~/miniconda3\nwget https://proxy.rifx.online/https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm -rf ~/miniconda3/miniconda.sh\n\n~/miniconda3/bin/conda init bash\n~/miniconda3/bin/conda init zsh\n```\n4\\. **ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑ Conda ÁéØÂ¢É**Ôºå‰ΩøÁî® Python 3ÔºåÂπ∂ÂÆâË£Ö `boto3` Âíå `gradio`:\n\n\n```python\nconda create --name gradio-demo python=3.12 pip -y\nconda activate gradio-demo\npip install --no-cache-dir gradio boto3\n```\n5\\. **‰∏∫ÊÇ®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫Âíå Gradio ‰ª£Á†ÅÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑ Python Êñá‰ª∂**„ÄÇÂ∞ÜÊâÄÊúâ‰ª£Á†ÅÂ§çÂà∂Âà∞Ê≠§Êñá‰ª∂‰∏≠:\n\n\n```python\nvim gradio_demo.py\n```\nÊàñËÄÖÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî® `scp` Â∞ÜÊñá‰ª∂Áõ¥Êé•‰ªéÊú¨Âú∞ËÆ°ÁÆóÊú∫Â§çÂà∂Âà∞ËøúÁ®ãÂÆû‰æã„ÄÇ\n\n**ËÆæÁΩÆ Nginx**\n\nÁé∞Âú®Êàë‰ª¨Â∞Ü **ËÆæÁΩÆ Nginx** ‰ª•Â∞ÜÊâÄÊúâÊµÅÈáè‰ªé `/gradio-demo` Ë∑ØÂæÑÈáçÂÆöÂêëÂà∞Áî± `gradio_demo.py` Êñá‰ª∂ÂêØÂä®ÁöÑÊú¨Âú∞ÊúçÂä°Âô®„ÄÇËØ∑ÂèÇÈòÖ [Ê≠§Â§ÑÁöÑÂÆòÊñπÊñáÊ°£‰ª•Âú® Nginx ‰∏äËøêË°å Gradio](https://proxy.rifx.online/https://www.gradio.app/guides/running-gradio-on-your-web-server-with-nginx)„ÄÇ\n\n1. ÁºñËæë‰Ωç‰∫é `/etc/nginx/nginx.conf` ÁöÑ Nginx ÈÖçÁΩÆÊñá‰ª∂:\n\n\n```python\nvim /etc/nginx/nginx.conf\n```\n2\\. Âú® `http` Âùó‰∏≠ÔºåÊ∑ªÂä†‰ª•‰∏ãË°å‰ª•ÂåÖÂê´Êù•Ëá™ÂçïÁã¨Êñá‰ª∂ÁöÑÊúçÂä°Âô®ÂùóÈÖçÁΩÆ:\n\n\n```python\nserver_names_hash_bucket_size  128;\ninclude /etc/nginx/sites-enabled/*;\n```\n3\\. Âú® `/etc/nginx/sites-available` ÁõÆÂΩï‰∏≠ÂàõÂª∫‰∏Ä‰∏™Êñ∞Êñá‰ª∂ÔºàÂ¶ÇÊûúËØ•ÁõÆÂΩï‰∏çÂ≠òÂú®ÂàôÂàõÂª∫ÔºâÔºå‰ΩøÁî®‰∏Ä‰∏™Ë°®Á§∫ÊÇ®ÁöÑÂ∫îÁî®Á®ãÂ∫èÁöÑÊñá‰ª∂ÂêçÔºå‰æãÂ¶ÇÔºö`sudo vim /etc/nginx/sites-available/my_gradio_app` :\n\n\n```python\nsudo mkdir -p /etc/nginx/sites-enabled\nsudo vim /etc/nginx/sites-available/my_gradio_app\n```\nÂú® `my_gradio_app` Êñá‰ª∂‰∏≠Á≤òË¥¥‰ª•‰∏ãÂÜÖÂÆπ:\n\n\n```python\nserver {\n    listen 80;\n    server_name www.ec2-12-34-56-78.us-west-2.compute.amazonaws.com; # Â∞ÜÊ≠§Êõ¥Êîπ‰∏∫ÊÇ®ÁöÑÂüüÂêç\n\n    location /gradio-demo/ {  # Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®‰∏çÂêåË∑ØÂæÑ‰∏äÊèê‰æõ Gradio Â∫îÁî®ÔºåËØ∑Êõ¥ÊîπÊ≠§Â§Ñ\n        proxy_pass http://127.0.0.1:7860/; # Â¶ÇÊûúÊÇ®ÁöÑ Gradio Â∫îÁî®Â∞ÜÂú®‰∏çÂêåÁ´ØÂè£‰∏äËøêË°åÔºåËØ∑Êõ¥ÊîπÊ≠§Â§Ñ\n        proxy_buffering off;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Host $host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n```\n4\\. Âú® `/etc/nginx/sites-enabled` ÁõÆÂΩï‰∏≠ÂàõÂª∫ÊåáÂêëÊ≠§Êñá‰ª∂ÁöÑÁ¨¶Âè∑ÈìæÊé•:\n\n\n```python\nsudo ln -s /etc/nginx/sites-available/my_gradio_app /etc/nginx/sites-enabled/\n```\n5\\. **Êõ¥Êñ∞ `gradio_demo.py` Êñá‰ª∂** ‰ª•Âú® Gradio ÂêØÂä® API ‰∏≠ËÆæÁΩÆÊ†πË∑ØÂæÑ:\n\n\n```python\n.launch(root_path=\"/gradio-demo\")\n```\n6\\. **Ê£ÄÊü• Nginx ÈÖçÁΩÆ** Âπ∂ÈáçÂêØ Nginx:\n\n\n```python\nsudo nginx -t\nsudo systemctl restart nginx\n```\nÂ¶ÇÊûúÊÇ®Âú® `nginx -t` ÂëΩ‰ª§‰∏≠ÈÅáÂà∞ÈîôËØØÔºåËØ∑Âú®ÁªßÁª≠‰πãÂâçËß£ÂÜ≥Ëøô‰∫õÈîôËØØ„ÄÇ\n\n**Âú®ÂêéÂè∞ËøêË°å `gradio_demo.py` Êñá‰ª∂**„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî® `nohup` Êàñ `tmux`:\n\n\n```python\n## ‰ªé Conda ÁéØÂ¢ÉÂÜÖÈÉ®\nnohup python gradio_demo.py &\n```\n**ËÆøÈóÆ EC2 DNS URL** Âπ∂ÈôÑÂä† `/gradio-demo/` ‰ª•Êü•ÁúãÊÇ®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫‰ª£ÁêÜÂú® Gradio ÁïåÈù¢‰∏ä„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rcdUROlShsrcaeBDpBKBAQ.png)\n\n## ÊëòË¶Å\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî® [Llama3\\.1](https://proxy.rifx.online/https://llama.meta.com/) Êàñ [Claude 3\\.5 Sonnet](https://proxy.rifx.online/https://www.anthropic.com/news/claude-3-5-sonnet) Ê®°ÂûãÊûÑÂª∫ÂÆ¢Êà∑ÊîØÊåÅÂä©Êâã„ÄÇÊàë‰ª¨È¶ñÂÖàÂÆö‰πâ‰∫ÜÂ§ÑÁêÜÈáçÂ§çÂÆ¢Êà∑Êü•ËØ¢ÁöÑÈóÆÈ¢òÔºå‰ª•Âèä LLM ‰ª£ÁêÜÂ¶Ç‰ΩïÊèê‰æõËß£ÂÜ≥ÊñπÊ°à„ÄÇÊé•ÁùÄÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫Ü LLM ‰ª£ÁêÜÁöÑÊ¶ÇÂøµ‰ª•ÂèäÂÆÉ‰ª¨‰∏é‰∏ÄËà¨ LLM ÁöÑÂå∫Âà´„ÄÇ‰πãÂêéÔºåÊàë‰ª¨ÊºîÁ§∫‰∫ÜÂ¶Ç‰ΩïÂú® Python ‰∏≠ÂàõÂª∫‰∏Ä‰∏™Âü∫Êú¨‰ª£ÁêÜÔºåÂπ∂‰ΩøÁî® Amazon Bedrock ‰∏≠ÁöÑÊ®°ÂûãÂºÄÂèë‰∫Ü‰∏Ä‰∏™Êõ¥Â§çÊùÇÁöÑÂÆ¢Êà∑ÊîØÊåÅÂä©Êâã„ÄÇÊàë‰ª¨Ëøò‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÂú® EC2 ‰∏äÈÉ®ÁΩ≤Âä©ÊâãÔºåÂåÖÊã¨‰ΩøÁî® Gradio ÂàõÂª∫ Web ÁïåÈù¢ÁöÑÁ§∫‰æã„ÄÇÈÄöËøáËá™Âä®ÂåñÂ∏∏ËßÑÂÆ¢Êà∑ÊîØÊåÅ‰ªªÂä°Ôºå‰ºÅ‰∏öÂèØ‰ª•ÊèêÈ´òÊïàÁéáÔºåÈôç‰ΩéÊàêÊú¨ÔºåÂπ∂ÊîπÂñÑÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ\n\nÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÔºåÊÇ®ÂèØ‰ª•Â∞ÜÁôªÂΩïÁî®Êà∑ÁöÑÂßìÂêçÂíå ID ‰º†ÈÄíÁªôÁ≥ªÁªüÊèêÁ§∫Ôºå‰ª•‰æø LLM ‰∏çÂøÖÂêëÁôªÂΩïÁî®Êà∑ËØ¢ÈóÆÂü∫Êú¨‰ø°ÊÅØ„ÄÇÊüê‰∫õÊìç‰ΩúÔºå‰æãÂ¶ÇÂèñÊ∂àËÆ¢ÂçïÔºåÂèØËÉΩÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÈó®Êéß„ÄÇÊ≠§Â§ñÔºåÂ¶ÇÊûúÂÆ¢Êà∑ÊÑüÂà∞‰∏çÊª°ÊàñÂèòÂæóÊøÄÂä®ÔºåÂ∫îËØ•ÊåáÁ§∫ LLM Â∞ÜÊ°à‰ª∂ÂçáÁ∫ßÂà∞‰∫∫Á±ªÂä©Êâã„ÄÇ\n\nÊÇ®ÂèØ‰ª•ÈÄöËøá LinkedIn ‰∏éÊàëËÅîÁ≥ªÔºö<https://proxy.rifx.online/https://linkedin.com/in/maheshrajput>\n\nÊÑüË∞¢ÊÇ®ÁöÑÈòÖËØª üòä\n\n"},{"lang":"zh","group":"blog","slug":"blog/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-4-put-it-all-ba7bbf706bbd","frontmatter":{"title":"‰ΩøÁî® LangChain„ÄÅStreamlit Âíå PubMed ÊûÑÂª∫Âü∫‰∫é RAG ÁöÑÁßëÂ≠¶ËÅäÂ§©Êú∫Âô®‰∫∫--Á¨¨ 4 ÈÉ®ÂàÜÔºàÂ∞ÜÊâÄÊúâ...","meta_title":"‰ΩøÁî® LangChain„ÄÅStreamlit Âíå PubMed ÊûÑÂª∫Âü∫‰∫é RAG ÁöÑÁßëÂ≠¶ËÅäÂ§©Êú∫Âô®‰∫∫--Á¨¨ 4 ÈÉ®ÂàÜÔºàÂ∞ÜÊâÄÊúâ...","description":"Â§ßÂÆ∂Â•ΩÔºåÊ¨¢ËøéÊù•Âà∞‰ΩøÁî® Langchain„ÄÅStreamlit Âíå PubMed ÊûÑÂª∫ÁßëÂ≠¶ËÅäÂ§©Êú∫Âô®‰∫∫Á≥ªÂàóÁöÑÊúÄÂêé‰∏ÄÈÉ®ÂàÜÔºÅ","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MQ7XtBd9WHn5n-gAMgd6pQ.jpeg","categories":["Chatbots","Natural Language Processing","Science"],"author":"Rifx.Online","tags":["ChatBot","LangChain","Streamlit","PubMed","RAG"],"draft":false,"slug":"blog/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-4-put-it-all-ba7bbf706bbd"},"content":"\n\n\n\n\nÊÇ®Â•ΩÔºåÊ¨¢ËøéÊù•Âà∞ÊûÑÂª∫ÁßëÂ≠¶ËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÁ≥ªÂàóÊúÄÂêé‰∏ÄÈÉ®ÂàÜÔºå‰ΩøÁî®Langchain„ÄÅStreamlitÂíåPubMedÔºÅ\n\nÂú®Ââç‰∏ÄÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜÊï∞ÊçÆÊåÅ‰πÖÊÄßÂíåÂ∏¶ÊúâÂêëÈáèÂ≠òÂÇ®ÁöÑRAGÁÆ°ÈÅì„ÄÇÁé∞Âú®ÔºåÊòØÊó∂ÂÄôÂ∞ÜÊàë‰ª¨ÊâÄÊûÑÂª∫ÁöÑ‰∏ÄÂàáÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂàõÂª∫ËÅäÂ§©Êú∫Âô®‰∫∫Áî®Êà∑ÁïåÈù¢ÔºåÂà©Áî®Êàë‰ª¨ÊûÑÂª∫ÁöÑÂêéÁ´ØÂäüËÉΩÔºåÂ∏ÆÂä©ÁßëÂ≠¶ÂÆ∂ÂõûÁ≠î‰ªñ‰ª¨ÁöÑÁßëÂ≠¶ÈóÆÈ¢òÔºÅ\n\n‰Ωú‰∏∫ÊèêÈÜíÔºåËøôÂ∞±ÊòØÊàë‰ª¨Âú®Á≥ªÂàó‰∏≠ÊûÑÂª∫ÁöÑÂÆåÊï¥Ëß£ÂÜ≥ÊñπÊ°àÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*NFCO_uRjlAgm0WYH.png)\n\n## Â∫îÁî®ÊºîÁ§∫\n\n* ‰Ωú‰∏∫È¢ÑÂëäÔºåËÆ©Êàë‰ª¨ÂÖàÊù•ÁúãÁúãÂ∫îÁî®ÁöÑÁïåÈù¢Á§∫‰æãÔºÅ \n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OKEQO_2kwnV93Va4SAVWZg.gif)\n\n## Âª∫ËÆæ\n\n### Â∑≤ÂÆåÊàêÊ≠•È™§Ê¶ÇËø∞\n\n* Â¶ÇÊûúÊÇ®ËøòÊ≤°ÊúâÂÆåÊàê [Á¨¨‰∏ÄÈÉ®ÂàÜ](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-1-set-up-streamlit-37550b44b266)„ÄÅ[Á¨¨‰∫åÈÉ®ÂàÜ](https://proxy.rifx.online/https://readmedium.com/llm-aided-retrieval-of-relevant-scientific-abstracts-via-pubmed-api-using-natural-language-part2-9e10f78575e6) Âíå [Á¨¨‰∏âÈÉ®ÂàÜ](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-3-create-vector-1e5e401e72e6)ÔºåËØ∑Âä°ÂøÖÂÖàÂÆåÊàêÔºåÂõ†‰∏∫Êàë‰ª¨Â∞ÜÂü∫‰∫éËøô‰∫õÂÜÖÂÆπËøõ‰∏ÄÊ≠•ÊûÑÂª∫„ÄÇÂú®ÊúÄÂêé‰∏ÄÈÉ®ÂàÜÁªìÊùüÊó∂ÔºåÊàë‰ª¨ÂæóÂà∞‰∫ÜÂ¶Ç‰∏ãÁöÑÈ°πÁõÆÁªìÊûÑÔºö\n\n```python\n.\n‚îú‚îÄ‚îÄ app\n‚îÇ   ‚îú‚îÄ‚îÄ app.py\n‚îÇ   ‚îú‚îÄ‚îÄ backend\n‚îÇ   ‚îÇ  ‚îú‚îÄ‚îÄ abstract_retrieval\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ interface.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ pubmed_retriever.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ pubmed_query_simplification.py\n‚îÇ   ‚îÇ  ‚îú‚îÄ‚îÄ data_repository\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ interface.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ local_data_store.py\n‚îÇ   ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ models.py\n‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ rag_pipeline\n‚îÇ   ‚îÇ      ‚îú‚îÄ‚îÄ interface.py\n‚îÇ   ‚îÇ      ‚îú‚îÄ‚îÄ chromadb_rag.py\n‚îÇ   ‚îÇ      ‚îî‚îÄ‚îÄ embeddings.py\n‚îÇ   ‚îú‚îÄ‚îÄ components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_utils.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py\n‚îÇ   ‚îî‚îÄ‚îÄ tests\n‚îÇ       ‚îî‚îÄ‚îÄ test_chat_utils.py\n‚îú‚îÄ‚îÄ assets\n‚îÇ   ‚îî‚îÄ‚îÄ pubmed-screener-logo.jpg\n‚îî‚îÄ‚îÄ environment\n    ‚îî‚îÄ‚îÄ requirements.txt\n```\nÂú®Á≥ªÂàóÁöÑÊúÄÂêé‰∏ÄÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÈáçÁÇπÂÖ≥Ê≥®ÂÆö‰πâÊàë‰ª¨ÁöÑ Streamlit UI ÁöÑ‰ª£Á†ÅÈÉ®ÂàÜ‚Äî‚Äî***app/app.py*** Âíå ***app/components*** Ê®°Âùó„ÄÇ\n\n### ‰øÆÊîπ chat\\_utils.py ‰ª•ÂåÖÂê´ RAG ÈÄªËæë\n\n[Âú®Á¨¨‰∏ÄÈÉ®ÂàÜ](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-1-set-up-streamlit-37550b44b266)ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂàùÊ≠•ÁâàÊú¨ÁöÑ ***chat\\_utils.py***ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏Ä‰∏™ÁÆÄÂçïÁöÑ QA ËÅäÂ§©Êú∫Âô®‰∫∫ÂÆûÁé∞ÔºàÊ≤°Êúâ RAGÔºâ„ÄÇÁé∞Âú®ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•Á†îÁ©∂Âπ∂Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫‰∏Ä‰∏™‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑ QA ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåËØ•Êú∫Âô®‰∫∫Â∞ÜÊ†πÊçÆÁî®Êà∑ÈóÆÈ¢òÊûÑÂª∫Á≠îÊ°àÔºåÂπ∂ÈÄöËøáÁõ∏‰ººÊÄßÊêúÁ¥¢‰ªéÊàë‰ª¨ÁöÑÂêëÈáèÁ¥¢Âºï‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥‰∏ä‰∏ãÊñáÔºàÊëòË¶ÅÔºâ„ÄÇ\n\nÊàë‰ª¨Â∞Ü‰ΩøÁî®[Á¨¨‰∏âÈÉ®ÂàÜ](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-3-create-vector-1e5e401e72e6)‰∏≠ÊûÑÂª∫ÁöÑÊâÄÊúâÂêéÁ´ØÂäüËÉΩÊù•ÂÆûÁé∞Ëøô‰∏ÄÁõÆÁöÑ„ÄÇ\n\n**app/components/chat\\_utils.py**\n\n```python\nfrom typing import List\nimport streamlit as st\nfrom langchain_core.documents.base import Document\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_core.runnables.base import Runnable\nfrom langchain_core.runnables.utils import Output\nfrom langchain_community.chat_message_histories import StreamlitChatMessageHistory\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.vectorstores import VectorStore\n\n\nclass ChatAgent:\n    def __init__(self, prompt: ChatPromptTemplate, llm: Runnable):\n        \"\"\"\n        ÂàùÂßãÂåñ ChatAgent„ÄÇ\n\n        ÂèÇÊï∞Ôºö\n        - prompt (ChatPromptTemplate): ËÅäÂ§©ÊèêÁ§∫Ê®°Êùø„ÄÇ\n        - llm (Runnable): ËØ≠Ë®ÄÊ®°ÂûãÂèØËøêË°åÂØπË±°„ÄÇ\n        \"\"\"\n        self.history = StreamlitChatMessageHistory(key=\"chat_history\")\n        self.llm = llm\n        self.prompt = prompt\n        self.chain = self.setup_chain()\n    \n    def reset_history(self) -> None:\n        \"\"\"\n        Ê∏ÖÈô§ËÅäÂ§©ÂéÜÂè≤‰ª•ÂºÄÂßãÊñ∞ÁöÑËÅäÂ§©‰ºöËØù„ÄÇ\n        \"\"\"\n        self.history.clear()\n\n    def setup_chain(self) -> RunnableWithMessageHistory:\n        \"\"\"\n        ‰∏∫ ChatAgent ËÆæÁΩÆÈìæ„ÄÇ\n\n        ËøîÂõûÔºö\n        - RunnableWithMessageHistory: ÈÖçÁΩÆÂ•ΩÁöÑÂ∏¶ÊúâÊ∂àÊÅØÂéÜÂè≤ÁöÑÈìæ„ÄÇ\n        \"\"\"\n        chain = self.prompt | self.llm\n        return RunnableWithMessageHistory(\n            chain,\n            lambda session_id: self.history,\n            input_messages_key=\"question\",\n            history_messages_key=\"history\",\n        )\n\n    def display_messages(self, selected_query: str) -> None:\n        \"\"\"\n        Âú®ËÅäÂ§©ÁïåÈù¢ÊòæÁ§∫Ê∂àÊÅØ„ÄÇ\n        Â¶ÇÊûúÊ≤°ÊúâÊ∂àÊÅØÔºåÂàôÊ∑ªÂä†ÈªòËÆ§ÁöÑ AI Ê∂àÊÅØ„ÄÇ\n        \"\"\"\n        if len(self.history.messages) == 0:\n            self.history.add_ai_message(f\"ËÆ©Êàë‰ª¨ËÅäËÅä‰Ω†ÁöÑÈóÆÈ¢òÔºö{selected_query}\")\n        for msg in self.history.messages:\n            st.chat_message(msg.type).write(msg.content)\n    \n    def format_retreieved_abstracts_for_prompt(self, documents: List[Document]) -> str:\n        \"\"\"\n        Â∞ÜÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£Ê†ºÂºèÂåñ‰∏∫Â≠óÁ¨¶‰∏≤Ôºå‰ª•‰æø‰º†ÈÄíÁªô LLM„ÄÇ\n        \"\"\"\n        formatted_strings = []\n        for doc in documents:\n            formatted_str = f\"ÊëòË¶ÅÊ†áÈ¢òÔºö{doc.metadata['title']}, ÊëòË¶ÅÂÜÖÂÆπÔºö{doc.page_content}, ÊëòË¶Å DOIÔºö{doc.metadata['source'] if 'source' in doc.metadata.keys() else 'Áº∫Â∞ë DOI..'}\"\n            formatted_strings.append(formatted_str)\n        return \"; \".join(formatted_strings)\n    \n    def get_answer_from_llm(self, question: str, retrieved_documents: List[Document]) -> Output:\n        \"\"\"\n        Ê†πÊçÆÁî®Êà∑ÈóÆÈ¢òÂíåÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£‰ªé LLM Ëé∑ÂèñÂìçÂ∫î„ÄÇ\n        \"\"\"\n        config = {\"configurable\": {\"session_id\": \"any\"}}\n        return self.chain.invoke(\n            {\n                \"question\": question, \n                \"retrieved_abstracts\": retrieved_documents,\n            }, config\n        )\n    \n    def retrieve_documents(self, retriever: VectorStore, question: str, cut_off: int = 5) -> List[Document]:\n        \"\"\"\n        ‰ΩøÁî®Áõ∏‰ººÊÄßÊêúÁ¥¢Ê£ÄÁ¥¢ÊñáÊ°£\n        cut_off ÂèÇÊï∞ÊéßÂà∂Ê£ÄÁ¥¢Âà∞ÁöÑÁªìÊûúÊï∞ÈáèÔºàÈªòËÆ§‰∏∫ 5Ôºâ\n        \"\"\"\n        return retriever.similarity_search(question)[:cut_off]\n\n    def start_conversation(self, retriever: VectorStore, selected_query: str) -> None:\n        \"\"\"\n        Âú®ËÅäÂ§©ÁïåÈù¢ÂºÄÂßãÂØπËØù„ÄÇ\n        ÊòæÁ§∫Ê∂àÊÅØÔºåÊèêÁ§∫Áî®Êà∑ËæìÂÖ•ÔºåÂπ∂Â§ÑÁêÜ AI ÂìçÂ∫î„ÄÇ\n        \"\"\"\n        self.display_messages(selected_query)\n        user_question = st.chat_input(placeholder=\"ÈóÆÊàë‰ªª‰Ωï‰∫ãÊÉÖ..\")\n        if user_question:\n            documents = self.retrieve_documents(retriever, user_question)\n            retrieved_abstracts = self.format_retreieved_abstracts_for_prompt(documents)\n            st.chat_message(\"human\").write(user_question)\n            response = self.get_answer_from_llm(user_question, retrieved_abstracts)\n            st.chat_message(\"ai\").write(response.content)\n```\n**Êõ¥ÊîπÂÜÖÂÆπÔºö**\n\n* Êàë‰ª¨Ê∑ªÂä†‰∫ÜÊñπÊ≥ï ***retrieve\\_documents***ÔºåËØ•ÊñπÊ≥ïÂ∞ÜÊàë‰ª¨ÁöÑÂêëÈáèÁ¥¢ÂºïÔºàÊ£ÄÁ¥¢Âô®Ôºâ‰Ωú‰∏∫ÂèÇÊï∞ÔºåÂπ∂Ë∞ÉÁî®Ê£ÄÁ¥¢Âô®‰∏äÁöÑÊñπÊ≥ï similarity\\_searchÔºå‰ªéÊàë‰ª¨ÁöÑÁßëÂ≠¶ÊëòË¶ÅÁöÑÂêëÈáèÁ¥¢Âºï‰∏≠Ëé∑Âèñ‰∏éÁî®Êà∑ÈóÆÈ¢òÊúÄÁõ∏‰ººÁöÑËÆ∞ÂΩï„ÄÇËØ∑Ê≥®ÊÑèÂèÇÊï∞ cut\\_offÔºåÂÆÉÊåáÂÆöË¶ÅÊ£ÄÁ¥¢ÁöÑÁªìÊûúÊï∞ÈáèÔºàÈªòËÆ§‰∏∫ 5Ôºâ„ÄÇ\n* Ê∑ªÂä†‰∫ÜÊñπÊ≥ï ***format\\_retreieved\\_abstracts\\_for\\_prompt***ÔºåËØ•ÊñπÊ≥ïÊé•Êî∂ÈÄöËøá retrieve\\_documents ÊñπÊ≥ïÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£ÔºåÂπ∂Â∞ÜÂÖ∂Ê†ºÂºèÂåñ‰∏∫ LLM ‰ΩøÁî®„ÄÇËøôÂú®Êàë‰ª¨Ë¶ÅÊ±Ç LLM Âú®ÊèêÁ§∫‰∏≠ÂºïÁî®Áõ∏ÂÖ≥Êù•Ê∫êÔºàÊñáÁ´† DOI ÂíåÊ†áÈ¢òÔºâÊó∂Â∞ÜÈùûÂ∏∏ÊúâÁî®„ÄÇ\n* Ê∑ªÂä†‰∫ÜÊñπÊ≥ï ***get\\_answer\\_from\\_llm***ÔºåÁî®‰∫éË∞ÉÁî® LLM Âπ∂‰º†ÈÄíÂøÖË¶ÅÁöÑÂèòÈáèÔºå‰ª•‰øùÊåÅÂÆ¢Êà∑Á´ØÂáΩÊï∞ start\\_conversation ÁöÑÁÆÄÊ¥Å„ÄÇ\n* ‰øÆÊîπ‰∫Ü ***start\\_conversation*** ÊñπÊ≥ï‰ª•ÂåÖÂê´ RAG ÈÄªËæë„ÄÇ\n\n### ÂàõÂª∫ QA ËÅäÂ§©ÊèêÁ§∫\n\n* Êàë‰ª¨Â∞Ü‰øÆÊîπÁé∞ÊúâÁöÑËÅäÂ§©ÊèêÁ§∫Ôºå‰ª•ÂåÖÂê´Ê£ÄÁ¥¢Âà∞ÁöÑÊëòË¶ÅÔºåÂπ∂Âü∫‰∫éËøô‰∫õÊëòË¶ÅÊûÑÂª∫Á≠îÊ°à„ÄÇ\n* Êàë‰ª¨ËøòÂ∞ÜÂåÖÂê´‰∏Ä‰∏™È¢ùÂ§ñÁöÑÔºàÁÆÄÂçïÁöÑÔºâÊèêÁ§∫ÔºåÁî®‰∫éÂú®ËÅäÂ§©Êú∫Âô®‰∫∫ÈÉ®ÂàÜ‰πãÂ§ñÊèê‰æõÁõ¥Êé•ÁöÑÂç≥Êó∂Á≠îÊ°àÔºå‰ª•‰æøÁî®Êà∑Âú® UI ‰∏äËé∑ÂæóÁõ¥Êé•ÁöÑÁ≠îÊ°à„ÄÇ\n\n**app/components/chat\\_prompts.py**\n\n```python\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n\n\nchat_prompt_template = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"You are a knowledgeable expert chatbot in the biomedicine field.\"),\n        MessagesPlaceholder(variable_name=\"history\"),\n        (\n            \"human\", \n            \"\"\"\n            Answer the following scientific question: {question}, \n            using the following context retrieved from scientific articles: {retrieved_abstracts}.\n\n            The user might refer to the history of your conversation. Please, use the following history of messages for the context as you see fit.\n\n            The abstracts will come formatted in the following way: ABSTRACT TITLE: <abstract title>; ABSTRACT CONTENT: <abstract content>, ABSTRACT DOI: <abstract doi> (the content inside <> will be variable).\n            In your answer, ALWAYS cite the abstract title and abstract DOI when citing a particular piece of information from that given abstract.\n\n            Your example response might look like this:\n\n            In the article (here in the brackets goes the contents of ABSTRACT_TITLE), it was discussed, that Cannabis hyperemesis syndrome (CHS) is associated with chronic, heavy cannabis use. The endocannabinoid system (ECS) plays a crucial role in the effects of cannabis on end organs and is central to the pathophysiology of CHS. (here, in the end of the cited chunk, the ABSTRACT_DOI goes)\n            \"\"\"\n        ),\n    ]\n)\n\nqa_template = PromptTemplate(\n    input_variables=['question', 'retrieved_abstracts'],\n    template=\"\"\"\n        Answer the following scientific question: {question}, \n        using the following context retrieved from scientific articles: {retrieved_abstracts}.\n\n        The abstracts will come formatted in the following way: ABSTRACT TITLE: <abstract title>; ABSTRACT CONTENT: <abstract content>, ABSTRACT DOI: <abstract doi> (the content inside <> will be variable).\n        In your answer, ALWAYS cite the abstract title and abstract DOI when citing a particular piece of information from that given abstract.\n\n        Your example response might look like this:\n\n        In the article (here in the brackets goes the contents of ABSTRACT_TITLE), it was discussed, that Cannabis hyperemesis syndrome (CHS) is associated with chronic, heavy cannabis use. The endocannabinoid system (ECS) plays a crucial role in the effects of cannabis on end organs and is central to the pathophysiology of CHS. (here, in the end of the cited chunk, the ABSTRACT_DOI goes)\n    \"\"\"\n)\n```\n* ËØ∑Ê≥®ÊÑèÔºå‰∏§‰∏™ÊèêÁ§∫ÁöÑÂÜÖÂÆπÂá†‰πéÁõ∏ÂêåÔºå‰ΩÜËÅäÂ§©ÊèêÁ§∫ÂåÖÂê´ÂØπËÅäÂ§©ÂéÜÂè≤ÁöÑÂºïÁî®Ôºå‰ΩøÁî® MessagesPlaceholderÔºåÂπ∂ÊåáÁ§∫Âú®ÂØπËØùËøáÁ®ã‰∏≠Ê†πÊçÆ LLM ÁöÑÂà§Êñ≠‰ΩøÁî®ËÅäÂ§©ÂéÜÂè≤„ÄÇ\n\n### ÂàõÂª∫Êñ∞Êñá‰ª∂ app/components/layout\\_extensions.py\n\n* ËØ•Êñá‰ª∂Â∞Ü‰øùÂ≠ò‰∏Ä‰∏™ËæÖÂä©ÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞Â∞ÜÂêëÁî®Êà∑ÂëàÁé∞Êàë‰ª¨Â∫îÁî®Á®ãÂ∫èÂ∏ÉÂ±ÄÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂπ∂Êèê‰æõÊü•ËØ¢Á§∫‰æãÔºàÂ¶Ç‰Ωï‰ΩøÁî®Â∫îÁî®Á®ãÂ∫èÁöÑÊèêÁ§∫Ôºâ„ÄÇÊàëÂÜ≥ÂÆöÂàõÂª∫Ëøô‰∏™Êâ©Â±ïÊñá‰ª∂Ôºå‰ª•ÈÅøÂÖç‰ΩøÊàë‰ª¨ÁöÑ app.py Êñá‰ª∂ÊùÇ‰π±ÔºåÂπ∂‰øùÊåÅÂÖ∂Êï¥Ê¥ÅÔºåÂõ†‰∏∫ËøôÊÆµ‰ª£Á†ÅÁõ∏ÂΩìÂÜóÈïøÔºåÂπ∂ÂåÖÂê´‰∏Ä‰∫õËá™ÂÆö‰πâÊ†∑ÂºèÔºàÂ∫îÁî®‰ø°ÊÅØÂ∞ÜÂú®Áî®Êà∑ÊÇ¨ÂÅúÊó∂ÊòæÁ§∫ÔºâÔºö\n\n```python\nimport streamlit as st\n\n\ndef render_app_info():\n    st.title(\"PubMed Screener\")\n    st.markdown(\"\"\"\n        PubMed Screener is a ChatGPT & PubMed powered insight generator from biomedical abstracts.\n    \"\"\")\n\n    # Adding custom HTML and CSS for an improved hover-over tooltip\n    st.markdown(\"\"\"\n        <style>\n        .tooltip {\n            position: relative;\n            display: inline-block;\n            border-bottom: 1px dotted black; /* Style for the hoverable text */\n        }\n\n        .tooltip .tooltiptext {\n            visibility: hidden;\n            width: 800px; /* Width to fit content */\n            background-color: #f9f9f9;\n            color: #000;\n            text-align: left;\n            border-radius: 6px;\n            padding: 15px;\n            position: absolute;\n            z-index: 1;\n            bottom: 100;\n            right: -430px; /* Positioning to the right and slightly offset */\n            opacity: 0;\n            transition: opacity 0.5s;\n            box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.8); /* Adding some shadow for better visibility */\n        }\n\n        .tooltip:hover .tooltiptext {\n            visibility: visible;\n            opacity: 1;\n        }\n        </style>\n        <div class=\"tooltip\">üîç Á§∫‰æãÈóÆÈ¢ò\n            <span class=\"tooltiptext\">\n                <strong>Á§∫‰æãÁßëÂ≠¶ÈóÆÈ¢òÔºö</strong>\n                <ul>\n                    <li>Â¶Ç‰ΩïÂà©Áî®ÂÖàËøõÁöÑÊàêÂÉèÊäÄÊúØÂíåÁîüÁâ©Ê†áÂøóÁâ©Êó©ÊúüËØäÊñ≠ÂíåÁõëÊµãÁ•ûÁªèÈÄÄË°åÊÄßÁñæÁóÖÁöÑËøõÂ±ïÔºü</li>\n                    <li>Âπ≤ÁªÜËÉûÊäÄÊúØÂíåÂÜçÁîüÂåªÂ≠¶Âú®Á•ûÁªèÈÄÄË°åÊÄßÁñæÁóÖÊ≤ªÁñó‰∏≠ÁöÑÊΩúÂú®Â∫îÁî®ÊòØ‰ªÄ‰πàÔºüÁõ∏ÂÖ≥ÊåëÊàòÂèàÊòØ‰ªÄ‰πàÔºü</li>\n                    <li>ËÇ†ÈÅìÂæÆÁîüÁâ©Áæ§ÂíåËÇ†ËÑëËΩ¥Âú®1ÂûãÂíå2ÂûãÁ≥ñÂ∞øÁóÖÂèëÁóÖÊú∫Âà∂‰∏≠ÁöÑ‰ΩúÁî®ÊòØ‰ªÄ‰πàÔºüÂ¶Ç‰ΩïË∞ÉËäÇËøô‰∫õÁõ∏‰∫í‰ΩúÁî®‰ª•Ëé∑ÂæóÊ≤ªÁñóÁõäÂ§ÑÔºü</li>\n                    <li>ÈíàÂØπÁôåÁóáÈù∂ÂêëÊ≤ªÁñóÁöÑËÄêËçØÊÄßÂèëÂ±ïÁöÑÂàÜÂ≠êÊú∫Âà∂ÊòØ‰ªÄ‰πàÔºüÂ¶Ç‰ΩïÂÖãÊúçËøô‰∫õËÄêËçØÊú∫Âà∂Ôºü</li>\n                </ul>\n            </span>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n    \n    st.text(\"\")py\n```\n\n### ‰øÆÊîπ app/app.py\n\n* ÊúÄÂêéÔºåÊòØÊó∂ÂÄôÂ∞ÜÊàë‰ª¨ÊûÑÂª∫ÁöÑÊâÄÊúâÂÜÖÂÆπÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫‰∏Ä‰∏™ streamlit Â∫îÁî®Á®ãÂ∫èËøõË°åÂ±ïÁ§∫ÔºÅ\n\n\n```python\nimport streamlit as st\nfrom metapub import PubMedFetcher\nfrom components.chat_utils import ChatAgent\nfrom components.chat_prompts import chat_prompt_template, qa_template\nfrom components.llm import llm\nfrom components.layout_extensions import render_app_info\nfrom backend.abstract_retrieval.pubmed_retriever import PubMedAbstractRetriever\nfrom backend.data_repository.local_storage import LocalJSONStore\nfrom backend.rag_pipeline.chromadb_rag import ChromaDbRag\nfrom backend.rag_pipeline.embeddings import embeddings\n\n\n## ÂÆû‰æãÂåñÂØπË±°\npubmed_client = PubMedAbstractRetriever(PubMedFetcher())\ndata_repository = LocalJSONStore(storage_folder_path=\"backend/data\")\nrag_client = ChromaDbRag(persist_directory=\"backend/chromadb_storage\", embeddings=embeddings)\nchat_agent = ChatAgent(prompt=chat_prompt_template, llm=llm)\n\ndef main():\n    st.set_page_config(\n        page_title=\"Pubmed ÊëòË¶ÅÁ≠õÈÄâÂô®\",\n        page_icon='üí¨',\n        layout='wide'\n    )\n\n    # ÂÆö‰πâÂàó - ËøôÂ∞Ü‰ΩøÂ∏ÉÂ±ÄÊ∞¥Âπ≥ÂàÜÂâ≤\n    column_logo, column_app_info, column_answer = st.columns([1, 4, 4])\n\n    # Âú®Á¨¨‰∏ÄÂàóÊîæÁΩÆ logo\n    with column_logo:\n        st.image('../assets/pubmed-screener-logo.jpg')\n\n    # Âú®Á¨¨‰∫åÂàóÊîæÁΩÆËß£ÈáäÂ∫îÁî®Á®ãÂ∫èÁõÆÁöÑÁöÑÊñáÊú¨‰ª•ÂèäÁî®Êà∑ÂèØËÉΩÊèêÂá∫ÁöÑ‰∏Ä‰∫õÁ§∫‰æãÁßëÂ≠¶ÈóÆÈ¢ò„ÄÇ\n    with column_app_info:\n\n        # ËøêË°åÂ∫îÁî®Á®ãÂ∫è‰ø°ÊÅØÔºåÂåÖÊã¨Á§∫‰æãÈóÆÈ¢ò‰Ωú‰∏∫Áî®Êà∑ÁöÑÊèêÁ§∫\n        render_app_info()\n\n        # ËæìÂÖ•ÁßëÂ≠¶ÈóÆÈ¢òÁöÑÈÉ®ÂàÜ\n        st.header(\"ËæìÂÖ•ÊÇ®ÁöÑÁßëÂ≠¶ÈóÆÈ¢òÔºÅ\")\n        placeholder_text = \"Âú®Ê≠§ËæìÂÖ•ÊÇ®ÁöÑÁßëÂ≠¶ÈóÆÈ¢ò...\"\n        scientist_question = st.text_input(\"ÊÇ®ÁöÑÈóÆÈ¢òÊòØ‰ªÄ‰πàÔºü\", placeholder_text)\n        get_articles = st.button('Ëé∑ÂèñÊñáÁ´† & Á≠îÊ°à')\n\n        # Â§ÑÁêÜÁî®Êà∑ÈóÆÈ¢òÔºåËé∑ÂèñÊï∞ÊçÆ\n        with st.spinner('Ê≠£Âú®Ëé∑ÂèñÊëòË¶Å„ÄÇËøôÂèØËÉΩÈúÄË¶Å‰∏ÄÊÆµÊó∂Èó¥...'):\n            if get_articles:\n                if scientist_question and scientist_question != placeholder_text:\n\n                    # Ëé∑ÂèñÊëòË¶ÅÊï∞ÊçÆ\n                    retrieved_abstracts = pubmed_client.get_abstract_data(scientist_question)\n                    if not retrieved_abstracts:\n                        st.write('Êú™ÊâæÂà∞ÊëòË¶Å„ÄÇ')\n                    else:\n                        # Â∞ÜÊëòË¶Å‰øùÂ≠òÂà∞Â≠òÂÇ®Âπ∂ÂàõÂª∫ÂêëÈáèÁ¥¢Âºï\n                        query_id = data_repository.save_dataset(retrieved_abstracts, scientist_question)\n                        documents = data_repository.create_document_list(retrieved_abstracts)\n                        rag_client.create_vector_index_for_user_query(documents, query_id)\n                        \n                        # Áõ¥Êé•ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢òÂπ∂Âú® UI ‰∏äÊòæÁ§∫Á≠îÊ°à\n                        vector_index = rag_client.get_vector_index_by_user_query(query_id)\n                        retrieved_documents = chat_agent.retrieve_documents(vector_index, scientist_question)\n                        chain = qa_template | llm\n                        \n                        with column_answer:\n                            st.markdown(f\"##### ÊÇ®ÁöÑÈóÆÈ¢òÁöÑÁ≠îÊ°àÔºö'{scientist_question}'\")\n                            st.write(chain.invoke({\n                                \"question\": scientist_question, \n                                \"retrieved_abstracts\": retrieved_documents,\n                            }).content)\n\n    # ËÅäÂ§©Êú∫Âô®‰∫∫ÈÉ®ÂàÜÁöÑÂºÄÂßã\n    # ÊòæÁ§∫Êü•ËØ¢ÂàóË°®‰ª•ÈÄâÊã©‰∏Ä‰∏™ËøõË°åÂØπËØù\n    query_options = data_repository.get_list_of_queries()\n\n    if query_options:\n        st.header(\"‰∏éÊëòË¶ÅËÅäÂ§©\")\n        selected_query = st.selectbox('ÈÄâÊã©‰∏Ä‰∏™ËøáÂéªÁöÑÊü•ËØ¢', options=list(query_options.values()), key='selected_query')\n        \n        # ÂàùÂßãÂåñÂÖ≥‰∫éÁî®Êà∑ÈóÆÈ¢òÂéÜÂè≤‰∏≠ÁöÑÊüê‰∏™Êü•ËØ¢ÁöÑËÅäÂ§©\n        if selected_query:\n            selected_query_id = next(key for key, val in query_options.items() if val == selected_query)\n            vector_index = rag_client.get_vector_index_by_user_query(selected_query_id)\n\n            # ÂàáÊç¢Êü•ËØ¢ËøõË°åËÅäÂ§©Êó∂Ê∏ÖÈô§ËÅäÂ§©ÂéÜÂè≤\n            if 'prev_selected_query' in st.session_state and st.session_state.prev_selected_query != selected_query:\n                chat_agent.reset_history()\n\n            st.session_state.prev_selected_query = selected_query\n\n            # ÂºÄÂßãËÅäÂ§©‰ºöËØù\n            chat_agent.start_conversation(vector_index, selected_query)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n* ‰ª£Á†ÅÂåÖÂê´‰ª•‰∏ãÈÉ®ÂàÜÔºö\n1. ÂÆû‰æãÂåñÊàë‰ª¨Âú®Á≥ªÂàó‰πãÂâçÈÉ®ÂàÜ‰∏≠ÊûÑÂª∫ÁöÑÊâÄÊúâÂØπË±° ‚Üí ***PubMedAbstractRetriever***„ÄÅ***LocalJSONStore***„ÄÅ***ChromaDbRag*** Âíå ***ChatAgent***„ÄÇÊàë‰ª¨Â∞ÜÂú®Â∫îÁî®Á®ãÂ∫è‰ª£Á†Å‰∏≠‰ΩøÁî®Ëøô‰∫õÂØπË±°„ÄÇ\n2. ÂÆö‰πâÂ∏ÉÂ±Ä‰ª•ÂëàÁé∞Â∫îÁî®Á®ãÂ∫èÊ†áÈ¢ò„ÄÅlogo ÂíåÂ∫îÁî®Á®ãÂ∫è‰ø°ÊÅØ„ÄÇ\n3. ÂÆö‰πâÁî®Êà∑ÈóÆÈ¢òÁöÑËæìÂÖ•Âíå‰∏Ä‰∏™Êèê‰∫§ÊåâÈíÆ„ÄÇÂΩìÊåâÈíÆË¢´ÁÇπÂáªÊó∂ÔºåËøôÂ∞ÜËß¶ÂèëÊêúÁ¥¢ÂíåËé∑Âèñ PubMed ÊñáÁ´†ÁöÑÈÄªËæëÔºà‰ΩøÁî® ***PubMedAbstractRetriever ‚Äî*** pubmed\\_clientÔºâÔºåÂ∞ÜÂÆÉ‰ª¨‰øùÂ≠òÂà∞Êú¨Âú∞Êï∞ÊçÆÂ≠òÂÇ®Â∫ìÔºà‰ΩøÁî® ***LocalJSONStore ‚Äî*** data\\_repositoryÔºâÔºåÂπ∂‰∏∫ÂÆÉ‰ª¨ÂàõÂª∫ÂêëÈáèÁ¥¢ÂºïÔºà‰ΩøÁî® ***ChromaDbRag ‚Äî*** rag\\_clientÔºâ„ÄÇ\n4. Áõ¥Êé•ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢òÂπ∂Âú® UI ‰∏äÊòæÁ§∫„ÄÇ\n5. ÊòæÁ§∫ËÅäÂ§©Êú∫Âô®‰∫∫ÈÉ®ÂàÜÔºåËÆ©ÊÇ®ÈÄâÊã©‰∏Ä‰∏™ËøáÂéªÁöÑÊü•ËØ¢ËøõË°åÂØπËØùÔºå‰ª•‰æøËøõ‰∏ÄÊ≠•ËØ¢ÈóÆÊëòË¶Å„ÄÇÂú®ÈÄâÊã©ËøáÂéªÁöÑÊü•ËØ¢ÂêéÔºåÂä†ËΩΩÁõ∏Â∫îÁöÑÂêëÈáèÁ¥¢ÂºïÔºåÂπ∂ÂêØÂä®ËÅäÂ§©‰ºöËØùÔºà***chat\\_agent.start\\_conversation(‚Ä¶)***Ôºâ„ÄÇÁé∞Âú®ÊÇ®ÂèØ‰ª•‰∏éÊëòË¶ÅËÅäÂ§©ÔºÅ\n\n## ÈôêÂà∂\n\nÊàëÂæàÈ´òÂÖ¥‰Ω†ÂíåÊàë‰∏ÄËµ∑Ëµ∞ËøáËøô‰∏™Á≥ªÂàóÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÁßëÂ≠¶ËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÂéüÂûãÔºÅ‰∏çËøáÈúÄË¶ÅËØ¥ÊòéÁöÑÊòØÔºåËøô‰∏™Â∫îÁî®Á®ãÂ∫è‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™Ê¶ÇÂøµÈ™åËØÅÔºàPoCÔºâÔºåÊâÄÂ±ïÁ§∫ÁöÑÂÆûÁé∞Â≠òÂú®‰∏Ä‰∫õÈúÄË¶ÅÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÈÉ®ÁΩ≤‰πãÂâçËß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n\n**ÁÆÄÂçïRAGÁöÑÈôêÂà∂ÂíåËÄÉËôë**\n\n* **Ê£ÄÁ¥¢ÂÜÖÂÆπÁöÑÁõ∏ÂÖ≥ÊÄß**Ôºö‰Ω†Êó†Ê≥ïÁ°ÆÂÆöÊ£ÄÁ¥¢Âà∞ÁöÑÂÜÖÂÆπÔºà‰∏éÁî®Êà∑ÈóÆÈ¢òÊúÄÁõ∏‰ººÁöÑÂÜÖÂÆπÔºâÊòØÂê¶ÊòØÊúÄÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇÊúâ‰∏Ä‰∫õÂÖàËøõÁöÑRAGÊäÄÊúØÔºåÂ¶Ç*ÂÅáËÆæÊÄßÈóÆÈ¢ò*Êàñ*Â±ÇÊ¨°Á¥¢Âºï*ÔºåÂèØ‰ª•Â∏ÆÂä©Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò‚Äî‚ÄîÂú®[ËøôÁØáÊñáÁ´†](https://proxy.rifx.online/https://readmedium.com/advanced-rag-techniques-unlocking-the-next-level-040c205b95bc)‰∏≠‰∫ÜËß£Êõ¥Â§öÂÖ≥‰∫éËøô‰∫õÊäÄÊúØÁöÑ‰ø°ÊÅØ„ÄÇ\n* **Ê£ÄÁ¥¢ÂÜÖÂÆπÁöÑÊà™Êñ≠**ÔºöÂæàÈöæËØÑ‰º∞ÊòØÂê¶Ê£ÄÁ¥¢Âà∞‰∫ÜÊâÄÊúâÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÁî±‰∫éLLMÁöÑ‰ª§ÁâåÈôêÂà∂ÔºåÈÄÇÂ∫îÊâÄÊúâ‰∏ä‰∏ãÊñáÂà∞ÊèêÁ§∫‰∏≠ÂèØËÉΩ‰ºöÂæàÂÖ∑ÊåëÊàòÊÄß„ÄÇÂú®Êàë‰ª¨ÁöÑÊ°à‰æã‰∏≠ÔºåÈªòËÆ§ÁöÑÊà™Êñ≠Á≠â‰∫é5‰∏™ÊëòË¶ÅÔºàÂú®Êàë‰ª¨ÁöÑChatAgentÁöÑretrieve_documentsÊñπÊ≥ï‰∏≠ÔºâÔºåÂ¶ÇÊûúÁî®Êà∑ÊèêÂá∫‰∏Ä‰∏™ÂπøÊ≥õÁöÑÈóÆÈ¢òÔºåËøôÊòæÁÑ∂ÂèØËÉΩ‰∏çÂ§ü„ÄÇ\n* **ÈÄÇÁî®ÊÄßÊúâÈôê**ÔºöÊúâÊó∂ÔºåÁî®Êà∑ÁöÑÈóÆÈ¢òÂèØËÉΩÊõ¥ÂÄæÂêë‰∫éÊÄªÁªìÊÄßË¥®ÔºåËÄå‰ΩøÁî®‰∏çÂêå‰∫éRAGÁöÑÊäÄÊúØÂèØËÉΩÊõ¥ÈÄÇÂêàËøô‰∏™ÁõÆÁöÑ„ÄÇ‰æãÂ¶ÇÔºå‰Ω†ÂèØ‰ª•ÊûÑÂª∫‰∏Ä‰∏™‰ª£ÁêÜÔºåÂÜ≥ÂÆö‰ªªÂä°ÊòØÊÄªÁªì/Ê£ÄÁ¥¢ÔºåÂü∫‰∫éÁî®Êà∑ÈóÆÈ¢ò„ÄÇÂú®Ê≠§ËØÑ‰º∞‰πãÂêéÔºåÂ∞ÜÊúâ‰∏Ä‰∏™ÂáΩÊï∞ÊâßË°å‰∏çÂêåÁöÑÈÄªËæëÔºåÂàÜÂà´ËøõË°åÊÄªÁªìÊàñÊ£ÄÁ¥¢„ÄÇ\n\n**ÈÉ®ÁΩ≤Êû∂ÊûÑËÄÉËôë**\n\n* **ËøêË°åÁéØÂ¢É**ÔºöÂú®Êú¨Á≥ªÂàóÁöÑËåÉÂõ¥ÂÜÖÔºåÊàë‰ª¨‰ªÖÂú®Êú¨Âú∞ÊûÑÂª∫‰∫ÜÊàë‰ª¨ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÊ≤°ÊúâËÄÉËôëÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥Ë¶ÅÂ∞ÜËøô‰∏™Â∫îÁî®Á®ãÂ∫èÈÉ®ÁΩ≤‰ª•ÊúçÂä°‰∏Ä‰∫õÁúüÂÆûÁî®Êà∑Êó∂ÈúÄË¶ÅÂÅöÂá∫ÁöÑ‰ªª‰ΩïÊû∂ÊûÑÂÜ≥Á≠ñ„ÄÇ\n* **ÂêåÊ≠•Â§ÑÁêÜ**ÔºöÁî±‰∫éÊï∞ÊçÆËé∑ÂèñÂèØËÉΩÈúÄË¶ÅÁõ∏ÂΩìÈïøÁöÑÊó∂Èó¥ÔºåÂÆûÁé∞Âü∫‰∫éÈòüÂàóÁöÑÂºÇÊ≠•Â§ÑÁêÜÁî®Êà∑ËØ∑Ê±Ç‰ºöÊõ¥È´òÊïàÔºåÂπ∂Âú®Êï∞ÊçÆËé∑ÂèñÂÆåÊàêÂêéÈÄöÁü•Áî®Êà∑„ÄÇ‰ª•ÂêåÊ≠•ÊñπÂºèËøõË°åÊ≠§Êìç‰ΩúÂèØËÉΩ‰ºöËÄóË¥πÂ§ßÈáèÊó∂Èó¥ÔºåËøôÂèØËÉΩÂØºËá¥ËÆ∏Â§öÊúçÂä°Âô®Ë∂ÖÊó∂„ÄÇ\n* **ÂêéÁ´ØÊäÄÊúØ**ÔºöÂú®Êàë‰ª¨ÁöÑÊ°à‰æã‰∏≠Ôºå‰ΩøÁî®ÁöÑÂêéÁ´ØÊòØChromaDBÔºåÈááÁî®Êú¨Âú∞Â≠òÂÇ®ÁöÑJSONÊñá‰ª∂„ÄÇÂØπ‰∫é‰∏Ä‰∏™ÊúçÂä°Áî®Êà∑ÁöÑÈÉ®ÁΩ≤Â∫îÁî®Á®ãÂ∫èÔºåËøôÂ∫îËØ•ÈáçÊñ∞ËØÑ‰º∞Âπ∂ÈÄâÊã©ÂêàÈÄÇÁöÑÊäÄÊúØ„ÄÇËøôÂèØ‰ª•ÈÄöËøáÂü∫‰∫éÂ∫îÁî®Á®ãÂ∫èÂêéÁ´Ø‰ª£Á†Å‰∏≠ÁöÑÊé•Âè£ÂÆö‰πâÔºà*RagWorkflow*Âíå*UserQueryDataStore*Êé•Âè£ÔºâËΩªÊùæÂÆûÁé∞„ÄÇ\n\n**ÂåÖÊã¨Êõ¥Â§öÁßëÂ≠¶Êï∞ÊçÆÂ∫ì**\n\n* Âú®Ëøô‰∏™Á≥ªÂàó‰∏≠ÔºåÊàë‰ª¨‰ªÖÂÖ≥Ê≥®PubMedÔºå‰ΩÜ‰∏∫‰∫ÜÊèê‰æõ‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñáÂü∫Á°ÄÔºåÂèØ‰ª•Ê∑ªÂä†ÂÖ∂‰ªñÁßëÂ≠¶ËÆ∫ÊñáÊï∞ÊçÆÂ∫ìÔºàÂç≥ScopusÔºâ„ÄÇËøôÂèØ‰ª•ÈÄöËøáÂü∫‰∫éÂ∫îÁî®Á®ãÂ∫èÂêéÁ´Ø‰ª£Á†Å‰∏≠ÁöÑÊé•Âè£ÂÆö‰πâÔºà*AbstractRetriever*Êé•Âè£ÔºâËΩªÊùæÂÆûÁé∞„ÄÇ\n\n## ÂÆåÊï¥‰ª£Á†ÅÂ∫ì GitHub ÈìæÊé•\n\nÈöèÊÑèÂàÜÂèâËØ•‰ªìÂ∫ìÂπ∂Â∞ÜÂÖ∂ÈÄÇÂ∫îÊÇ®ÁöÑ UCÔºÅ\n\n### ÈìæÊé•Âà∞ GitHub ‰ªìÂ∫ì pubmed\\-rag\\-screener\n\n## ÊëòË¶Å\n\n* Âú®Êú¨Á≥ªÂàóÁöÑÊúÄÂêé‰∏ÄÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰πãÂâçÊûÑÂª∫ÁöÑÊâÄÊúâÁªÑ‰ª∂ÁªÑÂêàÂú®‰∏ÄËµ∑ÔºåÂàõÂª∫‰∏Ä‰∏™Áî®Êà∑ÁïåÈù¢ÔºåËÆ©ÁßëÂ≠¶ÂÆ∂ÂèØ‰ª•ÊèêÂá∫ÈóÆÈ¢òÔºåÂü∫‰∫éÁßëÂ≠¶ÊëòË¶ÅËé∑ÂæóÁ≠îÊ°àÔºåÁÑ∂Âêé‰∏éÊëòË¶ÅËøõË°åËøõ‰∏ÄÊ≠•ÁöÑ‰∫§ÊµÅ„ÄÇ\n* Â∫îÁî®ÈÄªËæëÊòØÊ®°ÂùóÂåñÁöÑÔºå‰æø‰∫é‰ΩøÁî®Êèê‰æõÁöÑÊé•Âè£ËøõË°åÊâ©Â±ï„ÄÇ\n* Ê¶ÇËø∞Âπ∂Âº∫Ë∞É‰∫ÜËØ•ÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÔºåÂπ∂ÂåÖÊã¨‰∫Ü‰∏Ä‰∫õÊûÑÂª∫Áîü‰∫ßÁ∫ßÂ∫îÁî®ÁöÑÂª∫ËÆÆ„ÄÇ\n\n> ÈùûÂ∏∏ÊÑüË∞¢ÊÇ®‰∏éÊàë‰∏ÄËµ∑ÂÆåÊàêËøô‰∏™Á≥ªÂàóÔºÅÂ∏åÊúõÊÇ®ÂñúÊ¨¢ÊûÑÂª∫Ëøô‰∏™‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÁî®‰æã :)\n\n> Â¶ÇÊûúÊÇ®ÊÉ≥ËÆ®ËÆ∫ÊúâÂÖ≥ÂºÄÂèë„ÄÅÊï∞ÊçÆ„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰ªª‰ΩïÂÜÖÂÆπÔºåÊàñËÄÖÂè™ÊòØÊÉ≥ËÅîÁ≥ªÔºåËØ∑ÈöèÊó∂‰∏éÊàëËÅîÁ≥ª ‚Äî [Âú®LinkedIn‰∏äËÅîÁ≥ªÊàë](https://proxy.rifx.online/https://www.linkedin.com/in/sbarankova/)\n\n## Á≥ªÂàóÂÜÖÂÆπ\n\n* [Á¨¨‰∏ÄÈÉ®ÂàÜ ‚Äî Ëß£ÈáäÁî®‰æãÔºåËÆæÁΩÆÂ∏¶ÊúâËÅäÂ§©Êú∫Âô®‰∫∫ÁïåÈù¢ÁöÑ Streamlit Â∫îÁî®ÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-1-set-up-streamlit-37550b44b266)\n* [Á¨¨‰∫åÈÉ®ÂàÜ ‚Äî ÈÄöËøá PubMed API ‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄËæÖÂä©Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁßëÂ≠¶ÊëòË¶Å](https://proxy.rifx.online/https://readmedium.com/llm-aided-retrieval-of-relevant-scientific-abstracts-via-pubmed-api-using-natural-language-part2-9e10f78575e6)\n* [Á¨¨‰∏âÈÉ®ÂàÜ ‚Äî ËÆæÁΩÆÂêéÁ´Ø ‚Äî ‰ªéÊ£ÄÁ¥¢Âà∞ÁöÑÁßëÂ≠¶ÊëòË¶ÅÂàõÂª∫ÂêëÈáèÂµåÂÖ•Âπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®ÂêëÈáèÂ∫ì‰∏≠](https://proxy.rifx.online/https://readmedium.com/build-a-rag-based-scientific-chatbot-with-langchain-streamlit-pubmed-part-3-create-vector-1e5e401e72e6)\n* **Á¨¨ÂõõÈÉ®ÂàÜÔºàÊú¨ÊñáÔºâ ‚Äî ÈÄöËøá RAG Â∞ÜÊâÄÊúâÂÜÖÂÆπÊï¥ÂêàÂú®‰∏ÄËµ∑ ‚Äî ‰∏éÁßëÂ≠¶ÊëòË¶ÅËÅäÂ§©**\n\n"},{"lang":"zh","group":"blog","slug":"blog/build-your-talking-voice-ai-assistant-locally-memory-retaining-chatbot-with-streamlit-ui-09da4f10687c","frontmatter":{"title":"Âú®Êú¨Âú∞ÊûÑÂª∫‰ºöËØ¥ËØùÁöÑËØ≠Èü≥‰∫∫Â∑•Êô∫ËÉΩÂä©ÁêÜÔºöÂÖ∑ÊúâÊµÅÂÖâÊ∫¢ÂΩ©Áî®Êà∑ÁïåÈù¢ÁöÑËÆ∞ÂøÜ‰øùÊåÅËÅäÂ§©Êú∫Âô®‰∫∫...","meta_title":"Âú®Êú¨Âú∞ÊûÑÂª∫‰ºöËØ¥ËØùÁöÑËØ≠Èü≥‰∫∫Â∑•Êô∫ËÉΩÂä©ÁêÜÔºöÂÖ∑ÊúâÊµÅÂÖâÊ∫¢ÂΩ©Áî®Êà∑ÁïåÈù¢ÁöÑËÆ∞ÂøÜ‰øùÊåÅËÅäÂ§©Êú∫Âô®‰∫∫...","description":"Êú¨ÊñáÊèê‰æõ‰∫Ü‰∏Ä‰∏™ËØ¶ÁªÜÁöÑÊåáÂçóÔºå‰ªãÁªçÂ¶Ç‰Ωï‰ΩøÁî®Streamlit„ÄÅLangChainÂíåOllama LlamaÊ®°ÂûãÊûÑÂª∫‰∏Ä‰∏™ÂÖ∑ÊúâËÆ∞ÂøÜ‰øùÁïôÂäüËÉΩÁöÑ‰∏™‰∫∫ËØ≠Èü≥AIÂä©ÊâãPorter„ÄÇPorterËÉΩÂ§üÂú®Êú¨Âú∞ËøêË°åÔºåÁ°Æ‰øùÁî®Êà∑Êï∞ÊçÆÂÆâÂÖ®Âπ∂Êèê‰æõÂø´ÈÄüÂìçÂ∫î„ÄÇÂÖ∂‰∏ªË¶ÅÂäüËÉΩÂåÖÊã¨ËØ≠Èü≥ËæìÂÖ•ËæìÂá∫„ÄÅ‰ºöËØùËÆ∞ÂøÜ„ÄÅËÅäÂ§©ËÆ∞ÂΩïÂíåÂèØÂÆöÂà∂ÁöÑÊ®°ÂûãÂèÇÊï∞ËÆæÁΩÆ„ÄÇÈÄöËøáÊï¥ÂêàÂÖàËøõÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊäÄÊúØÔºåPorterÊó®Âú®‰∏∫Áî®Êà∑Êèê‰æõ‰∏™ÊÄßÂåñÁöÑÂä©Êâã‰ΩìÈ™åÔºåÈÄÇÁî®‰∫éÂêÑÁßçÂ∫îÁî®Âú∫ÊôØ„ÄÇËØ•È°πÁõÆÂº∫Ë∞É‰∫ÜÈöêÁßÅ‰øùÊä§ÂíåÈ´òÊïà‰∫§‰∫íÁöÑÈáçË¶ÅÊÄßÔºåÂ±ïÁ§∫‰∫ÜÁé∞‰ª£AIÂä©ÊâãÁöÑÊΩúÂäõ„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5WJoI0IAKwMpEaCdSY63_A.png","categories":["Voice Assistants","Natural Language Processing","Programming/Scripting"],"author":"Rifx.Online","tags":["Porter","Llama","Streamlit","Whisper","offline"],"draft":false,"slug":"blog/build-your-talking-voice-ai-assistant-locally-memory-retaining-chatbot-with-streamlit-ui-09da4f10687c"},"content":"\n\n\n### ÂºÄÂèëÊÇ®Ëá™Â∑±ÁöÑÂÖ∑Êúâ‰∏ä‰∏ãÊñáËÆ∞ÂøÜÂíåÂÆûÊó∂ËÅäÂ§©ÂäüËÉΩÁöÑËØ≠Èü≥ AI ÁöÑÈÄêÊ≠•ÊåáÂçóÔºåÂü∫‰∫é Llama3.1 Âíå Llama3.2 Ê®°Âûã\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è \\| üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) \\|üìù [Medium](https://medium.com/@monsuralirana)\n\n\n\nÂü∫‰∫éËØ≠Èü≥ÁöÑ‰∏™‰∫∫Âä©ÊâãÁöÑÊ¶ÇÂøµÂ∑≤ÁªèË∂ÖË∂ä‰∫ÜÊñ∞Â•áÁöÑËåÉÁï¥‚Äî‚ÄîÂÆÉÂ∑≤Êàê‰∏∫ÂøôÁ¢åÁöÑ‰∏ì‰∏ö‰∫∫Â£´„ÄÅËøúÁ®ãÂõ¢ÈòüÂíåÁßëÊäÄÁà±Â•ΩËÄÖÁöÑÂÆûÁî®Êó†ÈöúÁ¢çËß£ÂÜ≥ÊñπÊ°à„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰∏Ä‰∏™ÂèØ‰ª•ÂÄæÂê¨„ÄÅÂõûÂ∫îÁîöËá≥Ë∑üË∏™ËøáÂéªÂØπËØùÁöÑËØ≠Èü≥ AIÔºåÊâÄÊúâËøô‰∫õÈÉΩÂú®ÊÇ®ÁöÑËÆæÂ§á‰∏äÊú¨Âú∞ËøêË°å„ÄÇ‰ªãÁªç *Porter*Ôºå‰∏Ä‰∏™Êó®Âú®ÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÁöÑ‰∏™‰∫∫ AI Âä©Êâã„ÄÇ\n\nÂú®Êú¨ÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊåáÂØºÊÇ®ÂàõÂª∫ *Porter*Ôºå‰∏Ä‰∏™ÂÖàËøõÁöÑËØ≠Èü≥Âä©ÊâãÔºåËÉΩÂ§üÂìçÂ∫îËØ≠Èü≥Êü•ËØ¢ÔºåÈÄöËøáÂØπËØùËÆ∞ÂøÜ‰øùÊåÅ‰∏ä‰∏ãÊñáÔºåÂπ∂ÈÄöËøáÂêàÊàêËØ≠Èü≥Êèê‰æõÂìçÂ∫î„ÄÇ*Porter* Âà©Áî® Ollama ÁöÑÂ∞ñÁ´Ø Llama Ê®°Âûã„ÄÅ**Streamlit** Êèê‰æõÁõ¥ËßÇÁöÑÁî®Êà∑ÁïåÈù¢Ôºå‰ª•Âèä OpenAI ÁöÑ **Whisper** Ê®°ÂûãËøõË°åËΩ¨ÂΩï„ÄÇËØ•ÊåáÂçóÂ∞ÜÂ∏¶ÊÇ®ÈÄêÊ≠•ÂÆåÊàê‰ªéÂÆâË£ÖÂà∞ÊúÄÁªàÂú®Êú¨Âú∞Êú∫Âô®‰∏äÈÉ®ÁΩ≤ÁöÑËøáÁ®ã„ÄÇ\n\n## ÁõÆÂΩï\n\n1. ‰ªãÁªç\n2. ‰∏∫‰ªÄ‰πàÈÄâÊã© *Porter*?\n3. *Porter* ÁöÑÂÖ≥ÈîÆÁâπÊÄß\n4. Áî®Êà∑ÁïåÈù¢ (UI) Ê¶ÇËø∞\n5. ÂàÜÊ≠•ÊïôÁ®ã\n6. Êú¨Âú∞ËøêË°å Porter\n7. ÁªìËÆ∫\n\n## 1\\. ÂºïË®Ä\n\nÈöèÁùÄËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁöÑÊúÄÊñ∞ËøõÂ±ïÔºåËØ≠Èü≥Âä©ÊâãÂú®ÁêÜËß£Â§çÊùÇÊü•ËØ¢„ÄÅ‰ª•Ëá™ÁÑ∂ËØ≠Ë®ÄÂìçÂ∫î‰ª•ÂèäÂú®ÂØπËØù‰∏≠‰øùÊåÅ‰∏ä‰∏ãÊñáÊñπÈù¢ÂèòÂæóË∂äÊù•Ë∂äÂº∫Â§ß„ÄÇ*Porter*ÔºåÊàë‰ª¨ÁöÑ‰∫∫Â∑•Êô∫ËÉΩËØ≠Èü≥Âä©ÊâãÔºåÊó®Âú®Âà©Áî®Ëøô‰∫õËøõÂ±ïÔºå‰∏∫Áî®Êà∑Êèê‰æõËá™ÁÑ∂„ÄÅÂìçÂ∫îËøÖÈÄü‰∏î‰∏™ÊÄßÂåñÁöÑÂä©Êâã‰ΩìÈ™å„ÄÇPorter Âü∫‰∫é Ollama ÁöÑÂÖàËøõÊ®°ÂûãÊûÑÂª∫ÔºåÊèê‰æõÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÔºåÂπ∂‰ΩøÁî® **Streamlit** Êèê‰æõÁÆÄÂçïÊòìÁî®ÁöÑ‰∫§‰∫íÂºèÁî®Êà∑ÁïåÈù¢„ÄÇ\n\n**Porter** Êèê‰æõÔºö\n\n* ËÉΩÂ§üËÆ∞‰ΩèËøáÂéª‰∫§ÊµÅÁöÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ\n* Êòì‰∫éÂØºËà™ÁöÑÊµÅÁïÖÁïåÈù¢„ÄÇ\n* ÂèØÂÆöÂà∂ÁöÑÂèÇÊï∞‰ª•ÂÆûÁé∞‰∏™ÊÄßÂåñÂìçÂ∫î„ÄÇ\n\n## 2\\. ‰∏∫‰ªÄ‰πàÈÄâÊã© PorterÔºü\n\nÂ§ßÂ§öÊï∞ËØ≠Èü≥Âä©ÊâãÈúÄË¶Å‰∫íËÅîÁΩëËøûÊé•Âπ∂‰æùËµñÂ§ñÈÉ®ÊúçÂä°Âô®ÔºåËøôÂºïÂèë‰∫ÜÂÖ≥‰∫éÂÆâÂÖ®ÊÄß„ÄÅÊéßÂà∂ÊùÉÂíåÂìçÂ∫îÂª∂ËøüÁöÑÊãÖÂøß„ÄÇ*Porter* ÈÄöËøáÊú¨Âú∞ËøêË°åÔºåÊèê‰æõ‰∫ÜÔºö\n\n* **ÈöêÁßÅ**ÔºöÊó†ÈúÄ‰∫íËÅîÁΩëËÆøÈóÆÔºåÊâÄÊúâÂØπËØùÂíåÊï∞ÊçÆÈÉΩÂÆâÂÖ®Âú∞‰øùÁïôÂú®ÊÇ®ÁöÑËÆæÂ§á‰∏ä„ÄÇ\n* **Âø´ÈÄüÂìçÂ∫îÊó∂Èó¥**ÔºöÊâÄÊúâÊìç‰ΩúÈÉΩÂú®Êú¨Âú∞ËøõË°åÔºåÂ§ÑÁêÜÂíåÂìçÂ∫îÁöÑÂª∂ËøüÊúÄÂ∞è„ÄÇ\n* **ËÆ∞ÂøÜ‰øùÁïôÁöÑÂØπËØù**Ôºö‰ΩøÁî® LangChainÔºå*Porter* ÂèØ‰ª•Âú®Â§öÊ¨°‰∫§‰∫í‰∏≠ËÆ∞‰Ωè‰∏ä‰∏ãÊñáÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂáÜÁ°ÆÂõûÁ≠îÂêéÁª≠ÈóÆÈ¢ò„ÄÇ\n\n## 3\\. Ê≥¢ÁâπÁöÑÂÖ≥ÈîÆÁâπÊÄß\n\n### ËØ≠Èü≥ËæìÂÖ•ÂíåËæìÂá∫\n\n*Porter* ‰ΩøÁî® WhisperÔºå‰∏Ä‰∏™Âº∫Â§ßÁöÑËá™Âä®ËØ≠Èü≥ËØÜÂà´ (ASR) Ê®°ÂûãÔºåÂ∞ÜËØ≠Èü≥ËæìÂÖ•ËΩ¨ÂΩï‰∏∫ÊñáÊú¨„ÄÇÂÆÉËøòÂèØ‰ª•ÁîüÊàêËØ≠Èü≥ÂìçÂ∫îÔºåÊèê‰æõÊó†ÁºùÁöÑÂÖçÊèê‰ΩìÈ™å„ÄÇ\n\n### ‰ºöËØùËÆ∞ÂøÜ‰∏éÂØπËØù‰∏ä‰∏ãÊñá\n\nÈÄöËøá LangChain ÁöÑ **ConversationBufferMemory**Ôºå*Porter* ËÉΩÂ§ü‰øùÁïôËøáÂéªÁöÑÂØπËØùÔºå‰ªéËÄåÂÆûÁé∞Ëá™ÁÑ∂ÁöÑÂ§öËΩÆÂØπËØù„ÄÇËØ•ËÆ∞ÂøÜÂäüËÉΩ‰Ωø *Porter* ËÉΩÂ§üÂºïÁî®ËøáÂéªÁöÑÁî®Êà∑Êü•ËØ¢Âπ∂Êèê‰æõËøûË¥ØÊÄß„ÄÇ\n\n### ÂéÜÂè≤Ê¶ÇËø∞ÂíåËÅäÂ§©ËÆ∞ÂΩï\n\n*Porter* ÂåÖÂê´‰∏Ä‰∏™ **ËÅäÂ§©ËÆ∞ÂΩï** ÂäüËÉΩÔºåÊèê‰æõÂΩìÂâç‰ºöËØù‰∏≠ÊâÄÊúâËøáÂéª‰∫íÂä®ÁöÑÊ¶ÇËø∞„ÄÇÊ≠§ËÅäÂ§©ËÆ∞ÂΩïÊòæÁ§∫Âú®Áî®Êà∑ÁïåÈù¢‰∏äÔºåÂ∏ÆÂä©Áî®Êà∑Ë∑üË∏™Â∑≤ËÆ®ËÆ∫ÁöÑÂÜÖÂÆπ„ÄÇ\n\n### ÂèØÂÆöÂà∂ÁöÑÊ®°ÂûãÂèÇÊï∞\n\nÂú® *Porter* ÁöÑ Streamlit ‰æßËæπÊ†è‰∏≠ÔºåÁî®Êà∑ÂèØ‰ª•ÈÄâÊã©‰∏çÂêåÁöÑÊ®°ÂûãÁâàÊú¨ (Llama3\\.1, Llama3\\.2) Âπ∂Ë∞ÉÊï¥ÂèÇÊï∞ÔºåÂ¶Ç **temperature** Âíå **max tokens** ‰ª•ÊéßÂà∂ÂìçÂ∫îÁöÑÂàõÈÄ†ÊÄßÂíåÈïøÂ∫¶„ÄÇ\n\n### Âü∫‰∫é Streamlit ÁöÑÁî®Êà∑ÁïåÈù¢\n\nStreamlit ‰∏∫ *Porter* Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÁÆÄÊ¥Å„ÄÅÁõ¥ËßÇÁöÑÁî®Êà∑ÁïåÈù¢Ôºå‰ΩøÁî®Êà∑ËÉΩÂ§üËΩªÊùæ‰∏éÂä©ÊâãËøõË°å‰∫íÂä®„ÄÇËØ•Â∫îÁî®ÊòæÁ§∫‰∫Ü‰πãÂâçÁöÑ‰∫§ÊµÅ„ÄÅÊ®°ÂûãËÆæÁΩÆÔºåÂπ∂ÂÖÅËÆ∏ËΩªÊùæËøõË°åËØ≠Èü≥ËæìÂÖ•„ÄÇ\n\n## 4\\. Áî®Êà∑ÁïåÈù¢ (UI) Ê¶ÇËø∞\n\n*Porter* ÁöÑ Streamlit Áî®Êà∑ÁïåÈù¢ÁÆÄÂçï‰∏îÁî®Êà∑ÂèãÂ•ΩÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*x_oxCvi14LfcsG8H4VeXUg.png)\n\n* **ËØ≠Èü≥ËæìÂÖ•Â∞èÈÉ®‰ª∂**Ôºö‰∏Ä‰∏™È∫¶ÂÖãÈ£éÂõæÊ†áËÆ©Áî®Êà∑ÂΩïÂà∂‰ªñ‰ª¨ÁöÑÊü•ËØ¢„ÄÇ\n* **ËÅäÂ§©ÊòæÁ§∫**ÔºöÊòæÁ§∫Áî®Êà∑Ê∂àÊÅØÂíå *Porter* ÁöÑÂõûÂ§çÔºåÂåÖÊã¨Êó∂Èó¥Êà≥ÂíåÂìçÂ∫îÊó∂Èó¥„ÄÇ\n* **ËÆæÁΩÆ‰æßËæπÊ†è**ÔºöÈÄöËøáÊ®°ÂûãÈÄâÈ°π„ÄÅÊ∏©Â∫¶ÂíåÊúÄÂ§ß token Ëá™ÂÆö‰πâ *Porter*„ÄÇ\n* **ÂéÜÂè≤Ê¶ÇËßà**ÔºöÂú®ËÅäÂ§©Á™óÂè£‰∏≠Êü•ÁúãÂØπËØùÂéÜÂè≤Ôºå‰æø‰∫éË∑üË∏™‰πãÂâçÁöÑ‰∫§ÊµÅ„ÄÇ\n\n## 5\\. ÂàÜÊ≠•ÊïôÁ®ã\n\nËÆ©Êàë‰ª¨ÂàÜËß£‰ª£Á†ÅÔºåÁúãÁúãÂ¶Ç‰ΩïÂÆûÁé∞Porter„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®‰∏§‰∏™‰∏ªË¶ÅÊñá‰ª∂Ôºö`app.py`ÔºàÁî®‰∫éStreamlitÂ∫îÁî®ÔºâÂíå`voicebot.py`ÔºàÁî®‰∫éÂêéÁ´ØÈÄªËæëÔºâ„ÄÇ\n\n### ÂâçÊèêÊù°‰ª∂Ôºö\n\n* Python 3\\.7\\+\n* Êú¨Âú∞ conda ÁéØÂ¢É\n* Streamlit Áî®‰∫éÁî®Êà∑ÁïåÈù¢\n* Ollama Áî®‰∫éÊ®°ÂûãÊé®ÁêÜ\n* LangChain Áî®‰∫éÁÆ°ÁêÜÊ®°Âûã‰∏éËÆ∞ÂøÜ‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇ\n\n### Á¨¨‰∏ÄÊ≠•ÔºöÂÆâË£ÖÂøÖË¶ÅÁöÑÂåÖ\n\nÂÆâË£ÖÂøÖË¶ÅÁöÑÂ∫ìÂíåÂ∑•ÂÖ∑Ôºö\n\n```python\n!pip install langchain==0.0.318\n!pip install langchain-ollama \n!pip install langchain-community==0.0.3 \n!pip install ollama==0.0.8\n!pip install streamlit==1.25.0\n!pip install pathlib==1.0.1\n!pip install audio-recorder-streamlit==0.0.10\n!pip install torch==2.4.1\n!pip install transformer==4.44.2\n```\n\n> **ÊàëÂ∑≤ÁªèÈÄöËøá Ollama ËÆæÁΩÆ‰∫Ü LLaMA 3\\.1 Âíå 3\\.2 Ê®°Âûã„ÄÇÂ¶ÇÊûú‰Ω†Âú®Êú¨Âú∞Êú∫Âô®‰∏äÊ≤°Êúâ Ollama Êàñ LLaMA Ê®°ÂûãÔºåËØ∑ÊåâÁÖß‰∏ãÈù¢ÈìæÊé•‰∏≠ÁöÑËØ¥ÊòéËøõË°åÂÆâË£Ö„ÄÇÈìæÊé•‰ªÖÈÄÇÁî®‰∫é Llama 3\\.2Ôºå‰ΩÜ‰Ω†ÂèØ‰ª•ÈÄöËøáËøêË°å `\"ollama pull llama3.1\"` Êù•Ëé∑Âèñ Llama 3\\.1„ÄÇ**\n\n> **Êàë‰ΩøÁî®‰∫Ü Piper TTS Ê®°ÂûãËøõË°åÊñáÊú¨Âà∞ËØ≠Èü≥ËΩ¨Êç¢„ÄÇÂÆÉËΩªÈáèÁ∫ßÔºåÈÄüÂ∫¶Âø´10ÂÄçÔºåÂÆûÊó∂Â∑•‰ΩúÔºåÁ¶ªÁ∫øÊìç‰ΩúÔºåÂπ∂‰∏î‰∫ßÁîüÁ±ª‰ºº‰∫∫Á±ªÁöÑÂ£∞Èü≥„ÄÇ**\n\n### Á¨¨2Ê≠•ÔºöËÆæÁΩÆStreamlitÂ∫îÁî®Á®ãÂ∫è\n\n\n```python\nimport streamlit as st\nimport time\nfrom audio_recorder_streamlit import audio_recorder\nfrom voicebot import initialize_chat, text_to_speech, transcribe_audio\n\nst.title(\"Porter - Your Personal Voice AI Assistant\")\n\n## Initialize session state variables\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\nif \"audio_bytes\" not in st.session_state:\n    st.session_state.audio_bytes = None\n\n## Sidebar Settings\nwith st.sidebar:\n    logo_path = \"/path/to/logo.png\"\n    st.image(logo_path, caption=\"AI Enterprise\", use_column_width=True)\n    st.subheader(\"Êé®ÁêÜËÆæÁΩÆ\")\n    st.session_state.model = st.selectbox(\"Ê®°Âûã\", [\"llama3.1\", \"llama3.2:latest\"], index=0)\n    st.session_state.temperature = st.slider(\"Ê∏©Â∫¶\", 0.0, 1.0, 0.0, 0.05)\n    st.session_state.max_tokens = st.slider(\"ÊúÄÂ§ß‰ª§ÁâåÊï∞\", 100, 5000, 500, 100)\n\n## Initialize chat model\nif \"chain\" not in st.session_state:\n    st.session_state.chain = initialize_chat()\n```\nÂú®Êú¨ËäÇ‰∏≠Ôºö\n\n1. **‰ºöËØùÁä∂ÊÄÅÂèòÈáè**ÔºöÂ≠òÂÇ®Ê∂àÊÅØÂéÜÂè≤ÂíåÈü≥È¢ëÂ≠óËäÇ„ÄÇ\n2. **‰æßËæπÊ†èÊéß‰ª∂**ÔºöÊèê‰æõÁî®Êà∑ÁïåÈù¢Êéß‰ª∂‰ª•Ëá™ÂÆö‰πâÊ®°Âûã„ÄÅÊ∏©Â∫¶Âíå‰ª§ÁâåÈïøÂ∫¶„ÄÇ\n3. **ËÅäÂ§©Ê®°ÂûãÂàùÂßãÂåñ**ÔºöÂä†ËΩΩËÅäÂ§©Ê®°Âûã‰ª•‰æõÂ∫îÁî®Á®ãÂ∫è‰ΩøÁî®„ÄÇ\n\n### Á¨¨3Ê≠•ÔºöÂÆûÁé∞ËÅäÂ§©ÂäüËÉΩ\n\n\n```python\n## Display chat history\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\n## Record voice input\nfooter_container = st.container()\nwith footer_container:\n    st.session_state.audio_bytes = audio_recorder(text=\"Record a question\", icon_size=\"lg\")\n\nif st.session_state.audio_bytes:\n    transcript = transcribe_audio(st.session_state.audio_bytes)\n    if transcript:\n        st.session_state.messages.append({\"role\": \"user\", \"content\": transcript})\n        \n        # Display user input in chat\n        with st.chat_message(\"user\"):\n            st.markdown(transcript)\n\n        # Get response from model\n        with st.chat_message(\"assistant\"):\n            start_time = time.time()\n            with st.spinner(\"Porter is thinking...\"):\n                response = st.session_state.chain.run(transcript)\n            end_time = time.time()\n\n            response_time_str = f\"Response time: {end_time - start_time:.2f} seconds\"\n            st.markdown(response)\n            text_to_speech(response)\n            st.markdown(f\"_{response_time_str}_\")\n\n        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response, \"response_time\": response_time_str})\n```\nËøôÈáåÔºö\n\n1. **ÊòæÁ§∫‰πãÂâçÁöÑÊ∂àÊÅØ**ÔºöËÅäÂ§©Á™óÂè£ÊòæÁ§∫ÂØπËØùÂéÜÂè≤„ÄÇ\n2. **ËØ≠Èü≥ËæìÂÖ•‰∏éËΩ¨ÂΩï**ÔºöÂΩïÂà∂Âπ∂ËΩ¨ÂΩïÈü≥È¢ëËæìÂÖ•‰∏∫ÊñáÊú¨ÔºåÊ∑ªÂä†Âà∞ËÅäÂ§©‰∏≠„ÄÇ\n3. **Âä©ÊâãÂõûÂ§ç**ÔºöÂ∞ÜÁî®Êà∑ËæìÂÖ•ÂèëÈÄÅÂà∞Ê®°ÂûãÔºåÊ£ÄÁ¥¢ÂõûÂ§çÔºåÂπ∂Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Èü≥È¢ë‰ª•‰æõÊí≠Êîæ„ÄÇ\n\n### Á¨¨4Ê≠•ÔºöÂÆûÁé∞ÂêéÁ´Ø (voicebot.py)\n\nÂú® `voicebot.py` ‰∏≠Ôºå‰∏ªË¶ÅÁªÑ‰ª∂Áî®‰∫éÂàùÂßãÂåñPorterÁöÑÂØπËØùÊ®°ÂûãÔºåÂπ∂Â§ÑÁêÜÊñáÊú¨Âà∞ËØ≠Èü≥ÂíåËΩ¨ÂΩïÔºö\n\n```python\nimport os\nimport subprocess\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain.memory.chat_message_histories.file import FileChatMessageHistory\nfrom langchain_community.chat_models.ollama import ChatOllama\nfrom langchain.chains.llm import LLMChain\nfrom transformers import pipeline\nimport torch\n\ndef initialize_chat():\n    def get_llm():\n        return ChatOllama(\n            model=st.session_state.model,\n            temperature=st.session_state.temperature,\n            max_tokens=st.session_state.max_tokens,\n        )\n\n    from langchain.prompts import (\n        HumanMessagePromptTemplate,\n        ChatPromptTemplate,\n        MessagesPlaceholder,\n        SystemMessagePromptTemplate,\n    )\n\n    def get_chat_prompt_template():\n        return ChatPromptTemplate(\n            input_variables=[\"content\", \"messages\"],\n            messages=[\n                SystemMessagePromptTemplate.from_template(\n                    \"You're a Personal Assistant, and your name is Porter.\"\n                ),\n                MessagesPlaceholder(variable_name=\"messages\"),\n                HumanMessagePromptTemplate.from_template(\"{content}\"),\n            ],\n        )\n\n    def get_memory():\n        return ConversationBufferMemory(\n            memory_key=\"messages\",\n            chat_memory=FileChatMessageHistory(file_path=\"memory.json\"),\n            return_messages=True,\n            input_key=\"content\",\n        )\n\n    llm = get_llm()\n    prompt = get_chat_prompt_template()\n    return LLMChain(llm=llm, prompt=prompt, memory=get_memory())\n\n## ÊñáÊú¨ËΩ¨ËØ≠Èü≥\ndef text_to_speech(text):\n    subprocess.call(f'echo \"{text}\" | piper --model en_US-amy-medium --output_file output.wav', shell=True)\n    os.system(\"aplay output.wav\")\n\n## ËØ≠Èü≥ËØÜÂà´\npipe = pipeline(\"automatic-speech-recognition\", \"openai/whisper-large-v3-turbo\", torch_dtype=torch.float16, device=\"cuda:0\")\n\ndef transcribe_audio(audio_bytes):\n    webm_file_path = \"temp_audio.mp3\"\n    with open(webm_file_path, \"wb\") as f:\n        f.write(audio_bytes)\n    \n    transcript = pipe(webm_file_path)['text'].strip()\n    os.remove(webm_file_path)\n    return transcript\n```\nÊú¨ËäÇÔºö\n\n1. **Ê®°ÂûãËÆæÁΩÆ**ÔºöÈÖçÁΩÆËÅäÂ§©Ê®°ÂûãÂíåÊèêÁ§∫Ê®°Êùø„ÄÇ\n2. **ÊñáÊú¨ËΩ¨ËØ≠Èü≥**ÔºöÂ∞ÜÊ®°ÂûãÂìçÂ∫îËΩ¨Êç¢‰∏∫Èü≥È¢ë„ÄÇ\n3. **ËØ≠Èü≥ËΩ¨ÊñáÊú¨**Ôºö‰ΩøÁî®WhisperËΩ¨ÂΩïÂΩïÂà∂ÁöÑÈü≥È¢ëËæìÂÖ•„ÄÇ\n\n### Á¨¨5Ê≠•ÔºöÈÉ®ÁΩ≤Porter\n\nÂÆåÊàêËÆæÁΩÆÂêéÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®StreamlitÂêØÂä®ÊÇ®ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇË¶ÅËøêË°åÂ∫îÁî®Á®ãÂ∫èÔºåËØ∑ÂØºËà™Âà∞ÊÇ®ÁöÑÈ°πÁõÆÊñá‰ª∂Â§πÔºåÂπ∂Âú®ÁªàÁ´Ø‰∏≠ËøêË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö\n\n```python\nstreamlit run apps.py\n```\nÂ∫îÁî®Á®ãÂ∫èÂêØÂä®ÂêéÔºåÊÇ®Â∞ÜÂú®ÁªàÁ´Ø‰∏≠ÁúãÂà∞‰ª•‰∏ãÊ∂àÊÅØÔºö\n\n```python\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8501\n  Network URL: http://172.30.254.103:8501\n```\nÂ¶ÇÊûúÊÇ®Âú®Âêå‰∏ÄÂè∞Êú∫Âô®‰∏äÔºåÂèØ‰ª•ÈÄöËøáÂú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ**Local URL**Ôºà`http://localhost:8501`ÔºâÊù•ËÆøÈóÆPorter„ÄÇÊàñËÄÖÔºåÂ¶ÇÊûúÊÇ®ÊÉ≥‰ªéÂêå‰∏ÄÁΩëÁªú‰∏äÁöÑÂÖ∂‰ªñËÆæÂ§áËÆøÈóÆÂÆÉÔºåËØ∑‰ΩøÁî®**Network URL**Ôºà`http://172.30.254.103:8501`Ôºâ„ÄÇ\n\nÁé∞Âú®ÔºåÊÇ®Â∞ÜÊã•Êúâ‰∏Ä‰∏™ÂäüËÉΩÈΩêÂÖ®ÁöÑ‰∏™‰∫∫AIÂä©ÊâãÔºÅ\n\n> **‚Äú‰∏éPorterÂØπËØùÔºöÂÆÉÂ¶Ç‰ΩïËÆ∞‰ΩèÂíåÂõûÂøÜËøáÂéªÁöÑ‰∫íÂä®‚Äù**\n\nPorter‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™Âú®Áû¨Èó¥ÂõûÁ≠îÈóÆÈ¢òÁöÑAI‚Äî‚ÄîÂÆÉË¢´ËÆæËÆ°Áî®Êù•ËÆ∞‰ΩèËøáÂéªÁöÑÂØπËØù„ÄÇÂæóÁõä‰∫éÂÖ∂ËÆ∞ÂøÜÁ≥ªÁªüÔºåÂÆÉÂèØ‰ª•ÂõûÂøÜËµ∑‰ª•ÂâçÁöÑËÅäÂ§©ÔºåÊèê‰æõ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÁöÑÂìçÂ∫îÔºå‰Ωø‰∫íÂä®ÊÑüËßâÊõ¥Âä†‰∏™ÊÄßÂåñÂíåÊµÅÁïÖ„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÂú®ÈáçÊ∏©ÊóßËØùÈ¢òËøòÊòØÂèëÂá∫Porter‰πãÂâçÂ§ÑÁêÜËøáÁöÑÂëΩ‰ª§ÔºåÂÆÉÈÉΩËÉΩÊô∫ËÉΩÂú∞ÂõûÂøÜËµ∑ËøáÂéªÁöÑ‰∫§ÊµÅÔºå‰ªéËÄåÂÆûÁé∞Êó†Áºù„ÄÅËøûË¥ØÁöÑÂØπËØùÔºåÊÑüËßâÂ∞±ÂÉèÊòØ‰∏ÄÂú∫ÊåÅÁª≠ÁöÑÂØπËØùÔºåËÄå‰∏çÊòØÊØèÊ¨°ÈÉΩÈáçÊñ∞ÂºÄÂßã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dKn8HbZ7YhHHzml-OtBY4w.png)\n\n> ***GitHub‰ª£Á†ÅÔºö***\n\n> **Áïô‰∏ãÊÇ®ÁöÑÂèçÈ¶à„ÄÅËØÑËÆ∫ÔºåÂπ∂‰∏∫Ëøô‰∏™ÊïÖ‰∫ãüëè üëè ÁÇπËµûÔºÅÔºÅüëèüëè**\n\n## ÁªìËÆ∫\n\n***Porter*** ÁöÑÂàõÂª∫Â±ïÁ§∫‰∫Ü‰∏™‰∫∫ AI Âä©ÊâãÁöÑ‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÊΩúÂäõÔºåËøô‰∫õÂä©ÊâãÈÄöËøáÊú¨Âú∞Êìç‰Ωú‰ºòÂÖàËÄÉËôë **ÈöêÁßÅ** Âíå **ÂìçÂ∫îÊÄß**„ÄÇÈÄöËøáÊï¥Âêà LangChain ËøõË°åÂØπËØùËÆ∞ÂøÜ„ÄÅOllama ÁöÑÈ´òÊÄßËÉΩ Llama Ê®°ÂûãÁî®‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ª•Âèä Whisper ËøõË°åËØ≠Èü≥ËØÜÂà´Ôºå*Porter* Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞ÜËøô‰∫õÂÖàËøõÂ∑•ÂÖ∑ÁªìÂêàËµ∑Êù•ÔºåÂàõÂª∫‰∏Ä‰∏™Âº∫Â§ß‰∏îÁõ¥ËßÇÁöÑËØ≠Èü≥Âä©Êâã„ÄÇËØ•È°πÁõÆ‰∏ç‰ªÖÂº∫Ë∞É‰∫ÜÁé∞‰ª£ AI ÁöÑÂèØÂèäÊÄßÔºåËøòÁ™ÅÂá∫‰∫Ü‰øùÊä§Áî®Êà∑Êï∞ÊçÆÂÆâÂÖ®ÂíåÂø´ÈÄü‰∫§‰∫íÁöÑÈáçË¶ÅÊÄß‚Äî‚ÄîËøôÊòØÊú¨Âú∞Ëß£ÂÜ≥ÊñπÊ°àÁöÑ‰∏§‰∏™‰ºòÂäøÈ¢ÜÂüü„ÄÇ\n\nÂá≠ÂÄü Porter ÁÅµÊ¥ªÁöÑÊû∂ÊûÑÔºåÊúâË∂≥Â§üÁöÑÁ©∫Èó¥Êù•Êâ©Â±ïÂÖ∂ÂäüËÉΩ„ÄÇÂºÄÂèë‰∫∫ÂëòÂèØ‰ª•ÈõÜÊàêÂÖ∂‰ªñÊú¨Âú∞ NLP Ê®°ÂûãÊàñ‰∏∫‰∏çÂêåÁî®‰æãÊ∑ªÂä†ÂÆöÂà∂Â∑•‰ΩúÊµÅÁ®ãÔºå‰æãÂ¶ÇÂÆ¢Êà∑ÊîØÊåÅ„ÄÅÊïôËÇ≤ËæÖÂØºÊàñÊäÄÊúØÊïÖÈöúÊéíÈô§„ÄÇÊ≠§Â§ñÔºåÈöèÁùÄÊñ∞ËØ≠Ë®ÄÊ®°ÂûãÂíåËØ≠Èü≥Â§ÑÁêÜÊäÄÊúØÁöÑÂá∫Áé∞Ôºå*Porter* ÂèØ‰ª•Êõ¥Êñ∞‰ª•Êèê‰æõÊõ¥ÁªÜËá¥ÂíåÂÖ∑Êúâ‰∏ä‰∏ãÊñáÊÑèËØÜÁöÑÂìçÂ∫î„ÄÇ\n\n## ÂèÇËÄÉÊñáÁåÆ\n\n\\[1] Llama 3\\.2: ‰∏ã‰∏Ä‰ª£ËΩªÈáèÁ∫ßÊåá‰ª§Ë∞É‰ºòËØ≠Ë®ÄÊ®°ÂûãÔºöÂÆûË∑µÊïôÁ®ãÔºå2024\\. ÂèØÁî®ÈìæÊé•Ôºö[https://readmedium.com/llama\\-3\\-2\\-the\\-next\\-generation\\-of\\-lightweight\\-instruction\\-tuned\\-language\\-models\\-a\\-hands\\-on\\-9bca07c8af1d](https://readmedium.com/llama-3-2-the-next-generation-of-lightweight-instruction-tuned-language-models-a-hands-on-9bca07c8af1d)\n\n\\[2] Hugging Face, *Transformers ÊñáÊ°£Ôºö‰ΩøÁî® LLaMA 3\\.2 ËßÜËßâÊ®°Âûã*, Hugging Face, 2024\\. ÂèØÁî®ÈìæÊé•Ôºö<https://huggingface.co/blog/llama32>\n\n\\[3] ÊûÑÂª∫‰∏Ä‰∏™Âü∫Êú¨ÁöÑ LLM ËÅäÂ§©Â∫îÁî®Á®ãÂ∫è„ÄÇÂèØÁî®ÈìæÊé•Ôºö[https://docs.streamlit.io/develop/tutorials/llms/build\\-conversational\\-apps](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps)\n\nÂø´‰πêÁºñÁ†ÅÔºÅ üéâ\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è \\| üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) \\|üìù [Medium](https://medium.com/@monsuralirana)\n\nÊÑüË∞¢ÊÇ®Ëä±Êó∂Èó¥ÈòÖËØªËøôÁØáÊñáÁ´†ÔºÅ\n\nËØ∑Á°Æ‰øùÁïô‰∏ãÊÇ®ÁöÑÂèçÈ¶àÂíåËØÑËÆ∫„ÄÇ üëè ‰∏∫Ëøô‰∏™ÊïÖ‰∫ãÁÇπËµûÂπ∂ÂÖ≥Ê≥®Êõ¥Â§öÊïÖ‰∫ã„ÄÇ‰∏ãÊ¨°ÂçöÂÆ¢ËßÅÔºåÊï¨ËØ∑ÂÖ≥Ê≥® üì¢\n\n## ‰∫´ÂèóËøôÁØáÊñáÁ´†ÂêóÔºüÊü•ÁúãÊàëÊõ¥Â§öÁöÑ‰ΩúÂìÅÔºö\n\n* **‰ΩøÁî®Elasticsearch„ÄÅOllama„ÄÅLLaMA 3\\.1ÂíåLangChainÊûÑÂª∫Ëá™ÂÆö‰πâÊñáÊ°£‰ª£ÁêÜ:** Êé¢Á¥¢Â¶Ç‰Ωï‰ΩøÁî®LLaMA 3\\.1ÂíåOllamaËÆæÁΩÆ‰∏™ÊÄßÂåñÊñáÊ°£Ê£ÄÁ¥¢‰ª£ÁêÜÔºå‰ª•ÂÆûÁé∞Êó†Áºù‰ø°ÊÅØÊ£ÄÁ¥¢„ÄÇ[Âú®ËøôÈáåÈòÖËØªÂÆåÊï¥ÊïôÁ®ã](https://readmedium.com/building-a-custom-documents-agent-with-elasticsearch-ollama-llama-3-1-and-langchain-926b28047e1d)„ÄÇ\n* **‰ΩøÁî®OllamaÁöÑLLaMA3\\.1„ÄÅLLaMA3\\.2Ê®°Âûã„ÄÅStreamlit UIÂíåÊú¨Âú∞ÁéØÂ¢ÉÊûÑÂª∫‰∏™‰∫∫AIÂä©Êâã:** ÂèëÁé∞Â¶Ç‰ΩïÂºÄÂèë‰∏Ä‰∏™ËÉΩÂ§üËÆ∞‰ΩèËøáÂéª‰∫íÂä®ÁöÑAIÂä©ÊâãÔºå‰ΩøÁî®ÊúÄÊñ∞ÁöÑLLaMAÊ®°ÂûãÂíåÁî®Êà∑ÂèãÂ•ΩÁöÑStreamlitÁïåÈù¢„ÄÇ[Âú®ËøôÈáåÈòÖËØªÂÆåÊï¥ÊïôÁ®ã„ÄÇ](https://readmedium.com/building-porter-your-personal-ai-assistant-with-memory-using-ollamas-llama3-1-efb32b80c129)\n* **OpenAI SwarmÔºö‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÂ§ö‰ª£ÁêÜÁºñÊéíÊ°ÜÊû∂:** Ê∑±ÂÖ•‰∫ÜËß£‰∏Ä‰∏™Êó®Âú®È´òÊïàÁÆ°ÁêÜÂ§ö‰∏™AI‰ª£ÁêÜÁöÑÊñ∞Ê°ÜÊû∂ÔºåÊèêÂçáÊÇ®ÁöÑAIÈ°πÁõÆÁÆ°ÁêÜËÉΩÂäõ„ÄÇ[Âú®ËøôÈáåÈòÖËØªÂÆåÊï¥ÊïôÁ®ã„ÄÇ](https://readmedium.com/openai-swarm-a-lightweight-framework-for-multi-agent-orchestration-b4a83a1a1e37)\n* **Â¶Ç‰Ωï‰ΩøÁî®Molmo\\-7BËøõË°åÂ§öÊ®°ÊÄÅAIÔºö‰ΩøÁî®ÂºÄÊ∫êËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÊèêÂèñÊñáÊú¨ÂíåÂõæÂÉè:** Â≠¶‰π†Â¶Ç‰ΩïÂà©Áî®Molmo\\-7BÊ®°ÂûãÊèêÂèñÊñáÊú¨ÂíåÂõæÂÉèÔºåÂΩªÂ∫ïÊîπÂèòÊÇ®ÂØπÂ§öÊ®°ÊÄÅAIÁöÑÂ§ÑÁêÜÊñπÂºè„ÄÇ[Âú®ËøôÈáåÈòÖËØªÂÆåÊï¥ÊïôÁ®ã„ÄÇ](https://readmedium.com/how-to-use-molmo-7b-for-multimodal-ai-extract-text-and-images-with-an-open-source-vision-language-8a31939a2960)\n* **Meta Spirit LMÔºöÊñáÊú¨ÂíåËØ≠Èü≥ÁîüÊàêÁöÑÂ§öÊ®°ÊÄÅAIÂÆåÊï¥ÊåáÂçó:** Êé¢Á¥¢Meta Spirit LMÂú®ÁîüÊàêÊñáÊú¨ÂíåËØ≠Èü≥ÊñπÈù¢ÁöÑËÉΩÂäõÔºå‰ª•ÂèäÂÆÉÂ¶Ç‰ΩïÂ∫îÁî®‰∫éÂêÑÁßçAIÂ∫îÁî®„ÄÇ[Âú®ËøôÈáåÈòÖËØªÂÆåÊï¥ÊïôÁ®ã„ÄÇ](https://readmedium.com/meta-spirit-lm-a-complete-guide-to-multimodal-ai-for-text-and-speech-generation-ed0af74bc950)\n* **‰ΩøÁî®Piper TTSË∂ÖÁ∫ßÂ¢ûÂº∫ÊñáÊú¨Âà∞ËØ≠Èü≥:** ‰∫ÜËß£Â¶Ç‰ΩïÂú®Ëøô‰∏™Âä®Êâã*Google ColabÊïôÁ®ã*‰∏≠ÂÆûÁé∞10ÂÄçÊõ¥Âø´„ÄÅÂÆûÊó∂„ÄÅÁ¶ªÁ∫øÁöÑ‰∫∫Â£∞ÂêàÊàê„ÄÇ[Âú®ËøôÈáåÂ∞ÜÊÇ®ÁöÑÊñáÊú¨ËΩ¨Âåñ‰∏∫Ê†©Ê†©Â¶ÇÁîüÁöÑËØ≠Èü≥„ÄÇ](https://readmedium.com/unleashing-the-power-of-piper-tts-transforming-text-to-speech-10x-faster-with-ai-human-like-voice-eadf2065d66d)\n\n"},{"lang":"zh","group":"blog","slug":"blog/building-a-local-ai-powered-news-aggregator-with-ollama-swarm-and-duckduckgo-95aaf8b3ee41","frontmatter":{"title":"‰ΩøÁî® Ollama„ÄÅSwarm Âíå DuckDuckGo ÊûÑÂª∫Êú¨Âú∞ AI Êñ∞ÈóªËÅöÂêàÂô®","meta_title":"‰ΩøÁî® Ollama„ÄÅSwarm Âíå DuckDuckGo ÊûÑÂª∫Êú¨Âú∞ AI Êñ∞ÈóªËÅöÂêàÂô®","description":"Ê≤°ÊúâÊèê‰æõÂ≠óÂπï","date":"2024-10-24T17:47:43.000Z","image":"https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OHMOTk_WYGOxWHBsKqdpNQ.jpeg","categories":["Programming","Generative AI","Technology/Web"],"author":"Rifx.Online","tags":["Llama","Swarm","DuckDuckGo","News","Aggregator"],"draft":false,"slug":"blog/building-a-local-ai-powered-news-aggregator-with-ollama-swarm-and-duckduckgo-95aaf8b3ee41"},"content":"\n# ‰ΩøÁî®OllamaSwarmÂíåDuckDuckGoÊûÑÂª∫Êú¨Âú∞AIÈ©±Âä®ÁöÑÊñ∞ÈóªËÅöÂêàÂô®\n\n\n\nÂú®ÂΩì‰ªäÂø´ËäÇÂ•èÁöÑ‰∏ñÁïå‰∏≠ÔºåË∑ü‰∏äÁâπÂÆöÈ¢ÜÂüüÊúÄÊñ∞Êñ∞ÈóªÁöÑÊ≠•‰ºêÂèØËÉΩ‰ºöÂæàÂÖ∑ÊåëÊàòÊÄß„ÄÇÂ¶ÇÊûúÊàë‰ª¨ËÉΩÂ§üÂà©Áî®ÁîüÊàêÂºèAIÂíå‰ª£ÁêÜÁöÑÂäõÈáèÔºåÂàõÂª∫‰∏Ä‰∏™ÂÆåÂÖ®Âú®Êú¨Âú∞Êú∫Âô®‰∏äËøêË°åÁöÑ‰∏™ÊÄßÂåñÊñ∞ÈóªËÅöÂêàÂô®Âë¢ÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Â¶Ç‰Ωï‰ΩøÁî®**Ollama**ÁöÑLlama 3.2Ê®°Âûã„ÄÅ**Swarm**ËøõË°å‰ª£ÁêÜÁºñÊéíÔºå‰ª•Âèä**DuckDuckGo**ËøõË°åÁΩëÁªúÊêúÁ¥¢Êù•ÊûÑÂª∫ËøôÊ†∑ÁöÑÁ≥ªÁªü„ÄÇ\n\n# Êú¨Âú∞AIÁöÑÂäõÈáè\n\nÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ¥Ëµ∑ÔºåÊàë‰ª¨Áé∞Âú®ËÉΩÂ§üÂú®‰∏™‰∫∫ÁîµËÑë‰∏äËøêË°åÂ§çÊùÇÁöÑAIÁ≥ªÁªü„ÄÇËøô‰∏∫ÂàõÂª∫ÈíàÂØπÊàë‰ª¨ÁâπÂÆöÈúÄÊ±ÇÂÆöÂà∂ÁöÑÂ∑•ÂÖ∑ÂºÄËæü‰∫ÜÊó†ÈôêÂèØËÉΩ„ÄÇÊàë‰ª¨ÁöÑÊñ∞ÈóªËÅöÂêàÂô®Â∞±ÊòØËøô‰∏ÄÊΩúÂäõÁöÑÂÆåÁæé‰æãËØÅ„ÄÇ\n\n# Êàë‰ª¨Á≥ªÁªüÁöÑÁªÑÊàêÈÉ®ÂàÜ\n\n1. **Ollama with Llama 3.2**: ËøôÊòØÊàë‰ª¨Á≥ªÁªüÁöÑÊ†∏ÂøÉÔºå‰∏∫Êàë‰ª¨ÁöÑAI‰ª£ÁêÜÊèê‰æõÂä®Âäõ„ÄÇ\n2. **Swarm**: ‰∏Ä‰∏™‰ª£ÁêÜÁºñÊéíÊ°ÜÊû∂ÔºåÂÖÅËÆ∏Êàë‰ª¨ÂàõÂª∫ÂíåÁÆ°ÁêÜÂ§ö‰∏™AI‰ª£ÁêÜ„ÄÇ\n3. **DuckDuckGo Search**: Êèê‰æõÊúÄÊñ∞ÁöÑÁΩëÈ°µÊêúÁ¥¢ÁªìÊûúÔºåËÄå‰∏çË∑üË∏™Áî®Êà∑Êï∞ÊçÆ„ÄÇ\n\n# Â∑•‰ΩúÂéüÁêÜ\n\nÊàë‰ª¨ÁöÑÊñ∞ÈóªËÅöÂêàÂô®Áî±‰∏§‰∏™‰∏ªË¶ÅÁöÑAI‰ª£ÁêÜÁªÑÊàêÔºö\n\n1. **Êñ∞ÈóªÂä©Êâã**Ôºö‰ΩøÁî®DuckDuckGoÊêúÁ¥¢Ëé∑ÂèñÁâπÂÆö‰∏ªÈ¢òÁöÑÊúÄÊñ∞Êñ∞ÈóªÊñáÁ´†„ÄÇ\n2. **ÁºñËæëÂä©Êâã**ÔºöÂÆ°Êü•Âπ∂Á≤æÁÇºÊî∂ÈõÜÂà∞ÁöÑÊñ∞Èóª‰ª•‰æõÊúÄÁªàÂ±ïÁ§∫„ÄÇ\n\nËÆ©Êàë‰ª¨Êù•ÂàÜËß£‰∏Ä‰∏ãÂ∑•‰ΩúÊµÅÁ®ãÔºö\n\n# 1. ËÆæÁΩÆÁéØÂ¢É\n\n\n```python\nollama pull llama3.2\n\nexport OPENAI_MODEL_NAME=llama3.2\nexport OPENAI_BASE_URL=http://localhost:11434/v1\nexport OPENAI_API_KEY=any\n\npip install git+https://github.com/openai/swarm.git duckduckgo-search\n```\nÊàë‰ª¨È¶ñÂÖàÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ìÂπ∂ÂàùÂßãÂåñÊàë‰ª¨ÁöÑ Swarm ÂÆ¢Êà∑Á´ØÔºö\n\n\n```python\nfrom duckduckgo_search import DDGS\nfrom swarm import Swarm, Agent\nfrom datetime import datetime\n\ncurrent_date = datetime.now().strftime(\"%Y-%m\")\nclient = Swarm()\n```\n\n# 2. ÂàõÂª∫Êñ∞ÈóªÊêúÁ¥¢ÂäüËÉΩ\n\nÊàë‰ª¨ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞Êù•‰ΩøÁî® DuckDuckGo ÊêúÁ¥¢Êñ∞ÈóªÔºö\n\n```python\npythondef get_news_articles(topic):\n  ddg_api = DDGS()\n  results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n  if results:\n      news_results = \"\\n\\n\".join([f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results])\n      return news_results\n  else:\n      return f\"Could not find news results for {topic}.\"\n```\n\n# 3. ÂÆö‰πâÊàë‰ª¨ÁöÑ AI ‰ª£ÁêÜ\n\nÊàë‰ª¨‰ΩøÁî® Ollama ÁöÑ Llama 3.2 Ê®°ÂûãÂàõÂª∫‰∏§‰∏™‰ª£ÁêÜÔºö\n\n\n```python\nnews_agent = Agent(\n  model=\"llama3.2\",\n  name=\"News Assistant\",\n  instructions=\"You provide the latest news articles for a given topic using DuckDuckGo search.\",\n  functions=[get_news_articles],\n)\n\neditor_agent = Agent(\n  model=\"llama3.2\",\n  name=\"Editor Assistant\",\n  instructions=\"You review and finalise the news article for publishing.\",\n)\n```\n\n# 4. ÂçèË∞ÉÂ∑•‰ΩúÊµÅÁ®ã\n\nÊàë‰ª¨ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞Êù•ËøêË°åÊàë‰ª¨ÁöÑÊñ∞ÈóªËÅöÂêàÂ∑•‰ΩúÊµÅÁ®ãÔºö\n\n```python\ndef run_news_workflow(topic):\n  # Fetch news\n  news_response = client.run(\n      agent=news_agent,\n      messages=[{\"role\": \"user\", \"content\": f\"Get me the news about {topic} on {current_date}\"}],\n  )\n  raw_news = news_response.messages[-1][\"content\"]\n  \n  # Pass news to editor for final review\n  edited_news_response = client.run(\n      agent=editor_agent,\n      messages=[{\"role\": \"system\", \"content\": raw_news}],\n  )\n  print(f\"{edited_news_response.messages[-1]['content']}\")\n```\n\n# 5. ËøêË°åÁ≥ªÁªü\n\nÊúÄÂêéÔºåÊàë‰ª¨ÂèØ‰ª•ÈíàÂØπ‰ªª‰ΩïÊÑüÂÖ¥Ë∂£ÁöÑËØùÈ¢òËøêË°åÊàë‰ª¨ÁöÑÊñ∞ÈóªËÅöÂêàÂô®Ôºö\n\n\n```python\nrun_news_workflow(\"AI in Drug Discovery\")\n```\n\n# ÂÆåÊï¥‰ª£Á†Å : app.py\n\n\n```python\nfrom duckduckgo_search import DDGS\nfrom swarm import Swarm, Agent\nfrom datetime import datetime\n\ncurrent_date = datetime.now().strftime(\"%Y-%m\")\n\n# ÂàùÂßãÂåñ Swarm ÂÆ¢Êà∑Á´Ø\nclient = Swarm()\n\n# 1. ÂàõÂª∫‰∫íËÅîÁΩëÊêúÁ¥¢Â∑•ÂÖ∑\n\ndef get_news_articles(topic):\n    print(f\"Ê≠£Âú®‰∏∫ {topic} ËøõË°å DuckDuckGo Êñ∞ÈóªÊêúÁ¥¢...\")\n    \n    # DuckDuckGo ÊêúÁ¥¢\n    ddg_api = DDGS()\n    results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n    if results:\n        news_results = \"\\n\\n\".join([f\"Ê†áÈ¢ò: {result['title']}\\nÁΩëÂùÄ: {result['href']}\\nÊèèËø∞: {result['body']}\" for result in results])\n        return news_results\n    else:\n        return f\"Êú™ËÉΩÊâæÂà∞ÂÖ≥‰∫é {topic} ÁöÑÊñ∞ÈóªÁªìÊûú„ÄÇ\"\n    \n# 2. ÂàõÂª∫ AI ‰ª£ÁêÜ\n\ndef transfer_to_editor_assistant(raw_news):\n    print(\"Â∞ÜÊñáÁ´†‰º†ÈÄíÁªôÁºñËæëÂä©Êâã...\")\n    return editor_agent.run({\"role\": \"system\", \"content\": raw_news})\n\n# Êñ∞Èóª‰ª£ÁêÜ‰ª•Ëé∑ÂèñÊñ∞Èóª\nnews_agent = Agent(\n    model=\"llama3.2\",\n    name=\"Êñ∞ÈóªÂä©Êâã\",\n    instructions=\"ÊÇ®Êèê‰æõÊúâÂÖ≥ÁªôÂÆö‰∏ªÈ¢òÁöÑÊúÄÊñ∞Êñ∞ÈóªÊñáÁ´†Ôºå‰ΩøÁî® DuckDuckGo ÊêúÁ¥¢„ÄÇ\",\n    functions=[get_news_articles],\n)\n\n# ÁºñËæë‰ª£ÁêÜ‰ª•ÁºñËæëÊñ∞Èóª\neditor_agent = Agent(\n    model=\"llama3.2\",\n    name=\"ÁºñËæëÂä©Êâã\",\n    instructions=\"ÊÇ®ÂÆ°ÈòÖÂπ∂ÊúÄÁªàÁ°ÆÂÆöÊñ∞ÈóªÊñáÁ´†‰ª•‰æõÂèëÂ∏É„ÄÇ\",\n)\n\n# 3. ÂàõÂª∫Â∑•‰ΩúÊµÅÁ®ã\n\ndef run_news_workflow(topic):\n    print(\"ËøêË°åÊñ∞Èóª‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ã...\")\n    \n    # Á¨¨‰∏ÄÊ≠•: Ëé∑ÂèñÊñ∞Èóª\n    news_response = client.run(\n        agent=news_agent,\n        messages=[{\"role\": \"user\", \"content\": f\"Ëé∑ÂèñÂÖ≥‰∫é {topic} Âú® {current_date} ÁöÑÊñ∞Èóª\"}],\n    )\n    raw_news = news_response.messages[-1][\"content\"]\n    print(f\"Ëé∑ÂèñÁöÑÊñ∞Èóª: {raw_news}\")\n    \n    # Á¨¨‰∫åÊ≠•: Â∞ÜÊñ∞Èóª‰º†ÈÄíÁªôÁºñËæëËøõË°åÊúÄÁªàÂÆ°Êü•\n    edited_news_response = client.run(\n        agent=editor_agent,\n        messages=[{\"role\": \"system\", \"content\": raw_news}],\n    )\n    print(f\"{edited_news_response.messages[-1]['content']}\")\n\n\n# ËøêË°åÁªôÂÆö‰∏ªÈ¢òÁöÑÊñ∞ÈóªÂ∑•‰ΩúÊµÅÁ®ãÁ§∫‰æã\nrun_news_workflow(\"ËçØÁâ©ÂèëÁé∞‰∏≠ÁöÑ AI\")\n```\n\n# Á§∫‰æãËæìÂá∫\n\n\n```python\nRunning news Agent workflow...\nRunning DuckDuckGo news search for AI in Drug Discovery...\nFetched news: Here's a formatted answer based on the news articles:\n\n**ËçØÁâ©ÂèëÁé∞‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÔºöÈù©ÂëΩÊÄßÁöÑËΩ¨Âèò**\n\n‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÂú®ËçØÁâ©ÂèëÁé∞‰∏≠ÁöÑ‰ΩúÁî®Ê†áÂøóÁùÄÂà∂ËçØÈ¢ÜÂüüÁöÑÈù©ÂëΩÊÄßËΩ¨Âèò„ÄÇAIÂà©Áî®Â§çÊùÇÁöÑÁÆóÊ≥ïËøõË°åËá™‰∏ªÂÜ≥Á≠ñÔºå‰ªéÊï∞ÊçÆÂàÜÊûê‰∏≠Â¢ûÂº∫‰∫∫Á±ªËÉΩÂäõÔºåËÄå‰∏çÊòØÂèñ‰ª£ÂÆÉ‰ª¨„ÄÇ\n\n**ÊåëÊàò‰∏éÂ±ÄÈôêÊÄß**\n\nÂ∞ΩÁÆ°ÊúâÁùÄ‰ª§‰∫∫ÊúüÂæÖÁöÑËøõÂ±ïÔºå‰ΩÜÂú®ËØ•È¢ÜÂüü‰∏≠‰ªçÁÑ∂Â≠òÂú®ÊåëÊàòÂíåÂ±ÄÈôêÊÄß„ÄÇËÆ∫Êñá„ÄäAIÂú®ËçØÁâ©ÂèëÁé∞‰∏≠ÁöÑ‰ΩúÁî®„ÄãÊé¢ËÆ®‰∫ÜËøô‰∫õÈóÆÈ¢òÔºåÂº∫Ë∞É‰∫ÜÈ´òË¥®ÈáèÊï∞ÊçÆÁöÑÂøÖË¶ÅÊÄß„ÄÅ‰º¶ÁêÜÈóÆÈ¢òÁöÑËß£ÂÜ≥‰ª•ÂèäÂØπÂü∫‰∫éAIÁöÑÊñπÊ≥ïÂ±ÄÈôêÊÄßÁöÑËÆ§ËØÜ„ÄÇ\n\n**AIÂú®ËçØÁâ©ÂèëÁé∞‰∏≠ÁöÑÂ∫îÁî®**\n\nAIÊúâÊΩúÂäõÂú®ËçØÁâ©ÂèëÁé∞„ÄÅËÆæËÆ°ÂíåÁ†îÁ©∂ËçØÁâ©Èó¥Áõ∏‰∫í‰ΩúÁî®‰∏≠ÂèëÊå•ÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇAIÂú®ËçØÁâ©ÂèëÁé∞‰∏≠ÁöÑÂ∫îÁî®ÂåÖÊã¨Ôºö\n\n* Â§öÈù∂ÁÇπËçØÁêÜÂ≠¶ÔºöAIÂèØ‰ª•È¢ÑÊµãÂåñÂêàÁâ©ÂØπÂ§öÁßçÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇ\n* ÂåñÂ≠¶ÂêàÊàêÔºöAIÂèØ‰ª•‰ºòÂåñÂåñÂ≠¶ÂêàÊàêËøáÁ®ãÔºå‰ª•ÂÆûÁé∞Êõ¥Âø´ÂíåÊõ¥È´òÊïàÁöÑÁîü‰∫ß„ÄÇ\n* ËçØÁâ©ÈáçÂÆö‰ΩçÔºöAIÂèØ‰ª•ËØÜÂà´Áé∞ÊúâËçØÁâ©ÁöÑÊñ∞Áî®ÈÄî„ÄÇ\n* È¢ÑÊµãËçØÁâ©ÁâπÊÄßÔºöAIÂèØ‰ª•È¢ÑÊµãÂåñÂêàÁâ©ÁöÑÊïàÂäõ„ÄÅÊØíÊÄßÂíåÁâ©ÁêÜÂåñÂ≠¶ÁâπÊÄß„ÄÇ\n\n**ËçØÁâ©ÂèëÁé∞‰∏≠AIÁöÑÊú™Êù•**\n\nÈöèÁùÄAIÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåÈ¢ÑËÆ°Â∞ÜÂØπÂà∂ËçØË°å‰∏ö‰∫ßÁîüÈáçÂ§ßÂΩ±Âìç„ÄÇAIÁöÑÊàêÂäüÂ∫îÁî®Â∞Ü‰æùËµñ‰∫éÈ´òË¥®ÈáèÊï∞ÊçÆÁöÑÂèØÁî®ÊÄß„ÄÅ‰º¶ÁêÜÈóÆÈ¢òÁöÑËß£ÂÜ≥‰ª•ÂèäÂØπÂü∫‰∫éAIÁöÑÊñπÊ≥ïÂ±ÄÈôêÊÄßÁöÑËÆ§ËØÜ„ÄÇ\n```\n\n# Êú¨Âú∞ AI Êñ∞ÈóªËÅöÂêàÁöÑÂ•ΩÂ§Ñ\n\n* **ÈöêÁßÅ**ÔºöÊâÄÊúâÂ§ÑÁêÜÈÉΩÂú®ÊÇ®ÁöÑÊú¨Âú∞Êú∫Âô®‰∏äËøõË°åÔºåÁ°Æ‰øùÊÇ®ÁöÑÊï∞ÊçÆÁïôÂú®ÊÇ®Ëá™Â∑±Êâã‰∏≠„ÄÇ\n* **ÂÆöÂà∂Âåñ**ÔºöÊÇ®ÂèØ‰ª•ËΩªÊùæ‰øÆÊîπ‰ª£ÁêÜÁöÑÊåá‰ª§ÊàñÊ∑ªÂä†Êñ∞ÁöÑ‰ª£ÁêÜ‰ª•Êª°Ë∂≥ÊÇ®ÁöÑÁâπÂÆöÈúÄÊ±Ç„ÄÇ\n* **ÊúÄÊñ∞‰ø°ÊÅØ**ÔºöÈÄöËøá‰ΩøÁî® DuckDuckGo ÊêúÁ¥¢ÔºåÊÇ®ÊÄªÊòØËÉΩËé∑ÂæóÂÖ≥‰∫éÊÇ®ÈÄâÊã©‰∏ªÈ¢òÁöÑÊúÄÊñ∞Êñ∞Èóª„ÄÇ\n* **AI È©±Âä®ÁöÑÁ≠ñÂ±ï**ÔºöÁºñËæëÂä©ÊâãÂ∏ÆÂä©Á≤æÁÇºÂíåÁªÑÁªáÊî∂ÈõÜÁöÑÊñ∞ÈóªÔºåÊèê‰æõÊõ¥Á≤æËá¥ÁöÑÊúÄÁªàËæìÂá∫„ÄÇ\n\n# ÁªìËÆ∫\n\nËøô‰∏™Êú¨Âú∞ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®Êñ∞ÈóªËÅöÂêàÂô®Â±ïÁ§∫‰∫ÜÂ∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏éÁΩëÁªúÊêúÁ¥¢ËÉΩÂäõÁªìÂêàÁöÑÊΩúÂäõ„ÄÇÈÄöËøáÂà©Áî®OllamaÁöÑLlama 3.2Ê®°Âûã„ÄÅSwarmËøõË°å‰ª£ÁêÜÁºñÊéíÔºå‰ª•ÂèäDuckDuckGoËøõË°åÊêúÁ¥¢ÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÂ∑•ÂÖ∑ÔºåÂèØ‰ª•ËÆ©Êàë‰ª¨Âú®‰ªª‰ΩïÊÑüÂÖ¥Ë∂£ÁöÑËØùÈ¢ò‰∏ä‰øùÊåÅ‰ø°ÊÅØÁÅµÈÄöÔºåÂêåÊó∂Áª¥Êä§Êàë‰ª¨ÁöÑÈöêÁßÅÔºåÂπ∂ÂÆåÂÖ®Âú®Êú¨Âú∞ËÆ°ÁÆóÊú∫‰∏äËøêË°å„ÄÇ\n\nÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåÂàõÂª∫‰∏™ÊÄßÂåñ„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®Â∑•ÂÖ∑ÁöÑÂèØËÉΩÊÄßÂè™‰ºö‰∏çÊñ≠Êâ©Â§ß„ÄÇËøô‰∏™Êñ∞ÈóªËÅöÂêàÂô®Âè™ÊòØ‰∏Ä‰∏™ÂºÄÂßã‚Äî‚ÄîÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÂà©Áî®Ëøô‰∫õÊäÄÊúØ‰Ω†ËøòÂèØ‰ª•ÊûÑÂª∫Âì™‰∫õÂÖ∂‰ªñÂàõÊñ∞Â∫îÁî®ÔºÅ\n\n# ÂèÇËÄÉÔºö\n\nSwarm Github : <https://github.com/openai/swarm>\n\nÂ¶ÇÊûúÊÇ®ËßâÂæóËøôÁØáÊñáÁ´†‰ø°ÊÅØ‰∏∞ÂØå‰∏îÊúâ‰ª∑ÂÄºÔºåÊàëÂ∞ÜÈùûÂ∏∏ÊÑüË∞¢ÊÇ®ÁöÑÊîØÊåÅÔºö\n\n* Âú®Medium‰∏ä‰∏∫ÂÆÉÁÇπËµûÂá†Ê¨° üëèÔºåÂ∏ÆÂä©ÂÖ∂‰ªñ‰∫∫ÂèëÁé∞ËøôÁØáÂÜÖÂÆπÔºàÊÇ®Áü•ÈÅìÊÇ®ÂèØ‰ª•ÁÇπËµûÂ§öËææ50Ê¨°ÂêóÔºüÔºâ„ÄÇÊÇ®ÁöÑÁÇπËµûÂ∞ÜÂ∏ÆÂä©Êõ¥Â§öËØªËÄÖ‰º†Êí≠Áü•ËØÜ„ÄÇ\n- ‰∏éÊÇ®ÁöÑAIÁà±Â•ΩËÄÖÂíå‰∏ì‰∏ö‰∫∫Â£´ÁΩëÁªúÂàÜ‰∫´„ÄÇ\n- Âú®LinkedIn‰∏ä‰∏éÊàëËÅîÁ≥ªÔºö<https://www.linkedin.com/in/manjunath-janardhan-54a5537/>\n\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/building-a-reliable-text-classification-pipeline-with-llms-a-step-by-step-guide-87dc73213605","frontmatter":{"title":"‰ΩøÁî® LLMs ÊûÑÂª∫ÂèØÈù†ÁöÑÊñáÊú¨ÂàÜÁ±ªÁÆ°ÈÅìÔºöÂàÜÊ≠•ÊåáÂçó","meta_title":"‰ΩøÁî® LLMs ÊûÑÂª∫ÂèØÈù†ÁöÑÊñáÊú¨ÂàÜÁ±ªÁÆ°ÈÅìÔºöÂàÜÊ≠•ÊåáÂçó","description":"Êú¨Êñá‰ªãÁªç‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊûÑÂª∫ÂèØÈù†ÁöÑÊñáÊú¨ÂàÜÁ±ªÁÆ°ÈÅìÔºåÈáçÁÇπÊé¢ËÆ®‰∫Ü‰∏âÁßçÂÖ≥ÈîÆÊäÄÊúØÔºöÂèóÈôêÁîüÊàê„ÄÅÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫ÂíåÂä®ÊÄÅÁ§∫‰æãÈÄâÊã©„ÄÇÂèóÈôêÁîüÊàêÈÄöËøáÈôêÂà∂Ê®°ÂûãËæìÂá∫Âú®È¢ÑÂÆö‰πâÁ±ªÂà´ÂÜÖÔºåÂáèÂ∞ë‰∫ÜÂêéÂ§ÑÁêÜÈúÄÊ±ÇÔºõÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫Âà©Áî®Ê®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ËÉΩÂäõ‰ª•ÊèêÈ´òÂàÜÁ±ªÂáÜÁ°ÆÊÄßÔºõÂä®ÊÄÅÁ§∫‰æãÈÄâÊã©ÂàôÈÄöËøáÊ£ÄÁ¥¢‰∏éËæìÂÖ•ÊñáÊú¨Áõ∏‰ººÁöÑÁ§∫‰æãÔºåÊòæËëóÊèêÂçáÂàÜÁ±ªÂáÜÁ°ÆÁéáËá≥88.6%„ÄÇËøô‰∫õÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜLLMsÂú®ÊñáÊú¨ÂàÜÁ±ª‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÁÅµÊ¥ªÊÄßÔºå‰∏∫ÊûÑÂª∫È´òÊÄßËÉΩÂàÜÁ±ªÁ≥ªÁªüÊèê‰æõ‰∫ÜÂèØË°åÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Cmk7IkUnY-SIxhVF","categories":["Natural Language Processing","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["constrained","generation","prompting","selection","classification"],"draft":false,"slug":"blog/building-a-reliable-text-classification-pipeline-with-llms-a-step-by-step-guide-87dc73213605"},"content":"\n\n\n### ÂÖãÊúçÂü∫‰∫éLLMÁöÑÊñáÊú¨ÂàÜÁ±ª‰∏≠ÁöÑÂ∏∏ËßÅÊåëÊàò\n\n\n\nÂú®Êú¨ÂàÜÊ≠•ÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ªãÁªçÂ¶Ç‰Ωï‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊûÑÂª∫‰∏Ä‰∏™ÂáÜÁ°Æ‰∏îÂèØÈù†ÁöÑÊñáÊú¨ÂàÜÁ±ªÁÆ°ÈÅì„ÄÇLLMsÊòØÂº∫Â§ßÁöÑÈÄöÁî®Ê®°ÂûãÔºåÂú®ÂêÑÁßçËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°‰∏≠Â±ïÁ§∫‰∫ÜÂçìË∂äÁöÑËÉΩÂäõÔºåÂπ∂‰∏îÂÆÉ‰ª¨Âú®ËÆ∏Â§ö‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®‰∏≠Ë∂äÊù•Ë∂äÂ§öÂú∞Âèñ‰ª£‰∫Ü‰∏ì‰∏öÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂ¶ÇÊûú‰∏çË∞®ÊÖéÂ§ÑÁêÜÔºå‰ΩøÁî®LLMsËøõË°åÂàÜÁ±ªÂèØËÉΩ‰ºöÂæàÊ£òÊâã„ÄÇ\n\nÂú®Â∞ÜLLMsÂ∫îÁî®‰∫éÂàÜÁ±ªÊó∂Ôºå‰∏Ä‰∏™Â∏∏ËßÅÁöÑÈóÆÈ¢òÊòØÊ®°ÂûãÂèØËÉΩÊó†Ê≥ï‰ª•È¢ÑÊúüÁöÑËæìÂá∫ÊàñÊ†ºÂºèÂìçÂ∫îÔºå‰ªéËÄåÂØºËá¥È¢ùÂ§ñÁöÑÂêéÂ§ÑÁêÜÔºåËÄåËøô‰∫õÂêéÂ§ÑÁêÜÂèØËÉΩÂ§çÊùÇ‰∏îËÄóÊó∂„ÄÇÊú¨ÊñáÂ∞ÜÊ∂µÁõñËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÁöÑÂÆûÁî®ÊäÄÂ∑ßÂíåÊäÄÊúØ„ÄÇÊØèÁßçÁ≠ñÁï•ÈÉΩÊòì‰∫éÂÆûÊñΩÔºå‰ΩÜÂèØ‰ª•ÊòæËëóÊèêÈ´òLLMs‰Ωú‰∏∫ÊñáÊú¨ÂàÜÁ±ªÂô®ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÁî®ÊÄß„ÄÇËÆ©Êàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ®Ôºå‰ΩøÊÇ®ÁöÑLLMÊñáÊú¨ÂàÜÁ±ªÁ≥ªÁªüÊó¢È´òÊïàÂèàÂèØÈù†„ÄÇ\n\n## ‰∏ªË¶ÅÊÄùÊÉ≥\n\nÂú®Êú¨ÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®‰∏âÁßçÂÖ≥ÈîÆÊäÄÊúØÔºåËøô‰∫õÊäÄÊúØÂèØ‰ª•‰Ωø LLM Âú®ÊñáÊú¨ÂàÜÁ±ªÂô®‰∏≠ÂèòÂæóÊõ¥Âä†ÊúâÊïàÂíåÈ´òÊïà„ÄÇ**Êú¨ÊïôÁ®ã‰∏≠Êàë‰ª¨‰∏ç‰ºöÊ∑±ÂÖ•ËÆ®ËÆ∫ÂæÆË∞ÉÈÄâÈ°π**Ôºå‰ΩÜÂ¶ÇÊûúÊÇ®ÂØπËøô‰∏ÄÊäÄÊúØÊÑüÂÖ¥Ë∂£ÔºåÂèØ‰ª•Êü•ÁúãÊàëÂÖ∂‰ªñÁöÑ‰∏Ä‰∫õÂ∏ñÂ≠êÔºö\n\nÁ¨¨‰∏ÄÁßçÊäÄÊúØÊòØ *ÂèóÈôêÁîüÊàê*„ÄÇËøôÊ∂âÂèäËÆæÂÆöÁâπÂÆöÁöÑÁ∫¶ÊùüÔºåÂºïÂØº LLM ÁîüÊàêÈÅµÂæ™ÊåáÂÆöÊû∂ÊûÑÁöÑÊ†áËÆ∞ÔºåËøôÊúâÂä©‰∫éÁ°Æ‰øùËæìÂá∫Á¨¶ÂêàÈ¢ÑÊúüÊ†ºÂºè„ÄÇÈÄöËøáÂ∫îÁî®Ëøô‰∫õÁ∫¶ÊùüÔºåÊàë‰ª¨ÂèØ‰ª•ÂáèÂ∞ëÂ§çÊùÇÂêéÂ§ÑÁêÜÁöÑÈúÄË¶ÅÔºå‰ª•Ëé∑ÂæóÊ≠£Á°ÆÊ†ºÂºèÁöÑÁ±ªÂà´È¢ÑÊµã„ÄÇ\n\nÊàë‰ª¨Â∞ÜÁ†îÁ©∂ÁöÑÁ¨¨‰∫åÁßçÊäÄÊúØÊòØ *Â∞ëÈáèÁ§∫‰æãÊèêÁ§∫*„ÄÇÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫ÈÄöËøáÂú® LLM Â∞ùËØïÂàÜÁ±ªÊñ∞Êï∞ÊçÆ‰πãÂâçÊèê‰æõ‰∏Ä‰∫õÁ§∫‰æãËæìÂá∫Êù•Â∑•‰Ωú„ÄÇÁî±‰∫é LLM Ë¢´ËÆ§‰∏∫ÊòØÂº∫Â§ßÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ËÄÖÔºåÂÆÉ‰ª¨ËÉΩÂ§ü‰ªéËøô‰∫õÁ§∫‰æã‰∏≠ËØÜÂà´Ê®°ÂºèÔºåÂπ∂ÁîüÊàê‰∏é‰πãÁõ∏‰ººÁöÑËæìÂá∫„ÄÇËøôÁßçÊñπÊ≥ï‰ΩøÊàë‰ª¨ËÉΩÂ§üÈÄöËøáÂêë LLM Â±ïÁ§∫ÂÆÉÂ∫îËØ•ÁîüÊàêÁöÑÂìçÂ∫îÁ±ªÂûãÊù•ÊèêÈ´òÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n\nÊúÄÂêéÔºåÊàë‰ª¨Â∞Ü‰ªãÁªçÁî®‰∫éÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫ÁöÑ *Âä®ÊÄÅÁ§∫‰æãÈÄâÊã©*„ÄÇÁ±ª‰ºº‰∫éÂ¢ûÂº∫Ê£ÄÁ¥¢ÁîüÊàêÔºå‰ΩÜ‰∏ì‰∏∫ÂàÜÁ±ª‰ªªÂä°ËÆæËÆ°ÔºåËøôÁßçÊñπÊ≥ïÂü∫‰∫é‰∏éÊñ∞ËæìÂÖ•ÁöÑÁõ∏‰ººÊÄßÂä®ÊÄÅÈÄâÊã©Á§∫‰æãÔºå‰ΩøÁî®ÊúÄËøëÈÇªÊäÄÊúØ„ÄÇËøôÊ†∑ÔºåLLM Âú®ÁîüÊàêÊúÄÁªàÂàÜÁ±ª‰πãÂâçÔºå‰ºöÊé•Êî∂Âà∞ÊúÄÁõ∏ÂÖ≥ÁöÑËæìÂÖ•-ËæìÂá∫ÂØπÔºå‰ªéËÄåÂØºËá¥Êõ¥Á≤æÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇ\n\nÊØèÁßçÊäÄÊúØÂ∞ÜËØ¶ÁªÜËß£ÈáäÔºåÂπ∂Êèê‰æõÂü∫‰∫é LangChain Ê°ÜÊû∂ÁöÑ‰ª£Á†ÅÁ§∫‰æã‰ª•ÁÆÄÂåñÂÆûÁé∞„ÄÇÊÇ®Â∞ÜËÉΩÂ§üÂ∞ÜËøô‰∫õÊñπÊ≥ïÁõ¥Êé•Á∫≥ÂÖ•ÊÇ®ÁöÑ NLP Â∑•ÂÖ∑ÂåÖÔºåÊàñÊ†πÊçÆÊÇ®ÁöÑÁâπÂÆöÈúÄÊ±ÇËøõË°åÂÆöÂà∂Ôºå‰ª•‰æøÂª∫Á´ã‰∏Ä‰∏™ÂèØÈù†‰∏îÂáÜÁ°ÆÁöÑÊñáÊú¨ÂàÜÁ±ªÁÆ°ÈÅì„ÄÇ\n\n## ‰∏∫‰ªÄ‰πà‰ΩøÁî® LLM ËøõË°åÂàÜÁ±ª\n\nÂú®ÂºÄÂßã‰πãÂâçÔºåËÆ©Êàë‰ª¨Ëä±‰∏ÄÁÇπÊó∂Èó¥ËÄÉËôë‰∏Ä‰∏ã‰∏∫‰ªÄ‰πàÊÇ®ÂèØËÉΩÈÄâÊã©‰ΩøÁî® LLM ËøõË°åÊñáÊú¨ÂàÜÁ±ªÔºåËÄå‰∏çÊòØ‰ΩøÁî®ÂÆöÂà∂ÁöÑ‰∏ìÁî®Ê®°Âûã„ÄÇ\n\n‰ΩøÁî® LLM ÁöÑ‰∏Ä‰∏™‰∏ªË¶Å‰ºòÂäøÊòØÂÆÉ‰ª¨Âú®Èõ∂Ê†∑Êú¨ÂíåÂ∞ëÊ†∑Êú¨È¢ÑÊµãÊñπÈù¢ÁöÑÁÜüÁªÉÁ®ãÂ∫¶„ÄÇÂç≥‰ΩøÊï∞ÊçÆÈáèÂæàÂ∞ëÔºåLLM ÈÄöÂ∏∏‰πüËÉΩ‰∫ßÁîüÂêàÁêÜÁöÑÁªìÊûúÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨Âú®Ê†áËÆ∞Êï∞ÊçÆÁ®ÄÁº∫Êó∂Êàê‰∏∫ÊûÅÂ•ΩÁöÑÈÄâÊã©„ÄÇÊ≠§Â§ñÔºå‰Ωú‰∏∫ÈÄöÁî®Ê®°ÂûãÔºåLLM ÂØπ‰∏ñÁïåÊúâÁùÄÂπøÊ≥õÁöÑÁü•ËØÜÔºåÊúâÊïàÂú∞ËÆ∞ÂøÜÊù•Ëá™ÂêÑÁßçÊù•Ê∫êÁöÑ‰ø°ÊÅØ„ÄÇËøôÊÑèÂë≥ÁùÄÂÆÉ‰ª¨ÊúâÊó∂ËÉΩÂ§üÂ§ÑÁêÜÊÑèÂ§ñËæìÂÖ•ÔºåÂπ∂‰ªçÁÑ∂‰∫ßÁîüÂáÜÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇ\n\nÂè¶‰∏Ä‰∏™ÊòæËëóÁöÑÂ•ΩÂ§ÑÊòØÊñπ‰æøËÆøÈóÆ LLM ‰Ωú‰∏∫ÊúçÂä°„ÄÇËÆ∏Â§ö LLM Áé∞Âú®ÈÄöËøá‰∫ëÂπ≥Âè∞Êèê‰æõÔºåËøôÊÑèÂë≥ÁùÄÊÇ®‰∏çÈúÄË¶ÅËá™Â∑±ÁÆ°ÁêÜ‰ªª‰ΩïÂü∫Á°ÄËÆæÊñΩ„ÄÇÊÇ®Âè™ÈúÄ‰∏∫ÊâÄ‰ΩøÁî®ÁöÑÊúçÂä°‰ªòË¥πÔºåËøô‰∏∫ÊÇ®Êèê‰æõ‰∫ÜÁÅµÊ¥ªÊÄßÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅËøõË°åÊâ©Â±ïÔºåËÄåÊó†ÈúÄÊäïËµÑÁ°¨‰ª∂ÊàñÁÆ°ÁêÜ GPU ËµÑÊ∫ê„ÄÇËøôÂØπ AI Â∫îÁî®Á®ãÂ∫èÊù•ËØ¥ÊòØ‰∏Ä‰∏™Â∑®Â§ßÁöÑËµÑ‰∫ßÔºåÂõ†‰∏∫ÂÆÉÈôç‰Ωé‰∫ÜÂâçÊúüÊàêÊú¨ÔºåÂπ∂Ê∂àÈô§‰∫ÜÁª¥Êä§Â§çÊùÇÊú∫Âô®Â≠¶‰π†Âü∫Á°ÄËÆæÊñΩÁöÑÂøÖË¶ÅÊÄß„ÄÇ\n\nÁÑ∂ËÄåÔºå‰πüÊúâ‰∏Ä‰∫õÊΩúÂú®ÁöÑÁº∫ÁÇπÈúÄË¶ÅËÄÉËôë„ÄÇ‰∏Ä‰∏™ÊòØÂª∂ËøüÔºöËôΩÁÑ∂ÂÆöÂà∂ÁöÑÂ∞èÂûãÂàÜÁ±ªÊ®°ÂûãÈÄöÂ∏∏Âú®Âá†ÂçÅÊØ´ÁßíÂÜÖÂìçÂ∫îÔºå‰ΩÜ LLM ÁöÑÂª∂ËøüÈÄöÂ∏∏Êõ¥È´òÔºåËåÉÂõ¥‰ªéÂá†ÁôæÊØ´ÁßíÂà∞Âá†ÁßíÔºåÂÖ∑‰ΩìÂèñÂÜ≥‰∫éÂÖ∂Â§ßÂ∞è„ÄÇÂØπ‰∫éÈúÄË¶ÅÂÆûÊó∂Â§ÑÁêÜÁöÑÂ∫îÁî®Á®ãÂ∫èÔºåËøôÁßçÂª∂ËøüÂèØËÉΩÊòØ‰∏Ä‰∏™Áº∫ÁÇπ„ÄÇ\n\nÊï∞ÊçÆÈöêÁßÅÊòØÂè¶‰∏Ä‰∏™ÂÖ≥Ê≥®ÁÇπ„ÄÇÂ¶ÇÊûúÊÇ®ÈúÄË¶ÅÂá∫‰∫éÂêàËßÑÊàñÂÆâÂÖ®ÂéüÂõ†Â∞ÜÊâÄÊúâÊï∞ÊçÆ‰øùÁïôÂú®Ëá™Â∑±ÁöÑÂü∫Á°ÄËÆæÊñΩ‰∏≠Ôºå‰ΩøÁî® LLM ÊúçÂä°ÂèØËÉΩ‰∏çÊòØÊúÄ‰Ω≥ÈÄâÊã©„ÄÇÊÇ®Ë¶Å‰πàÈúÄË¶ÅÂú®ÂÜÖÈÉ®ÊâòÁÆ° LLM‚Äî‚ÄîËøôÂèØËÉΩ‰ºöÂæàÊòÇË¥µ‚Äî‚ÄîË¶Å‰πàÂØªÊâæ‰∏ÄÁßçËÉΩÂ§üÂ∞ÜÊï∞ÊçÆ‰øùÁïôÂú®ÂÜÖÈÉ®ÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ\n\nÂè¶‰∏Ä‰∏™ÈôêÂà∂ÊòØÂØπ LLM ÊúçÂä°Êèê‰æõÂïÜÁöÑ‰æùËµñ„ÄÇÂ∞Ü LLM ‰Ωú‰∏∫ÊúçÂä°‰ΩøÁî®ÊÑèÂë≥ÁùÄÊÇ®ÂèóÂà∞ÂÖ∂ÈÄüÁéáÈôêÂà∂„ÄÅÂª∂ËøüÂíåÊΩúÂú®ÂÅúÊú∫Êó∂Èó¥ÁöÑÂΩ±ÂìçÔºåËÄåÊÇ®ÂØπÊ≠§Âá†‰πéÊ≤°ÊúâÊéßÂà∂ÊùÉ„ÄÇÊèê‰æõÂïÜÁ´ØÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩÂèØËÉΩÂΩ±ÂìçÊÇ®ÂèØÈù†ÂíåÂèäÊó∂Âú∞ÂàÜÁ±ªÊñáÊú¨ÁöÑËÉΩÂäõÔºåËøôÂèØËÉΩÊòØÂØπÈúÄË¶ÅÈ´òÂèØÈù†ÊÄßÁöÑÂ∫îÁî®Á®ãÂ∫èÁöÑ‰∏Ä‰∏™Áº∫ÁÇπ„ÄÇ\n\nËÄÉËôëÂà∞Ëøô‰∫õ‰ºòÁº∫ÁÇπÔºåÊÇ®ÂèØ‰ª•ËØÑ‰º∞‰ΩøÁî® LLM ‰Ωú‰∏∫ÂàÜÁ±ªÂô®ÊòØÂê¶ÈÄÇÂêàÊÇ®ÁöÑÁâπÂÆöÈúÄÊ±Ç„ÄÇÊó†ËÆ∫Â¶Ç‰ΩïÔºåLLM ÊòØÊÇ®Êï∞ÊçÆÁßëÂ≠¶Â∑•ÂÖ∑ÂåÖ‰∏≠‰∏Ä‰∏™Âº∫Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰ΩøÊÇ®ËÉΩÂ§üÂø´ÈÄüËÆæÁΩÆ AI ÊúçÂä°Âπ∂ÂºÄÂßãÊûÑÂª∫ÊúâÂΩ±ÂìçÂäõÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n## ÊÉ≥Ê≥ï 1ÔºöÂàÜÁ±ªÁöÑÁ∫¶ÊùüËæìÂá∫\n\nÁé∞Âú®Êàë‰ª¨Â∑≤ÁªèË¶ÜÁõñ‰∫ÜËÉåÊôØÔºåËÆ©Êàë‰ª¨Ê∑±ÂÖ•ÊïôÁ®ãÁöÑÊäÄÊúØÈÉ®ÂàÜ„ÄÇÂ¶ÇÂâçÊâÄËø∞ÔºåÊàë‰ª¨ÁöÑÁ¨¨‰∏Ä‰∏™ÊäÄÊúØÊòØÂÆûÁé∞**Á∫¶ÊùüÁîüÊàê**Ôºå‰ª•Á°Æ‰øùLLM‰ªÖËæìÂá∫ÊúâÊïàÁöÑÁ±ªÂà´Ê†áÁ≠æ„ÄÇÈÄöËøáÂ∞ÜËæìÂá∫ÈôêÂà∂‰∏∫È¢ÑÂÆö‰πâÁöÑÁ±ªÂà´ÂêçÁß∞ÈõÜÂêàÔºåÊàë‰ª¨Ê∂àÈô§‰∫ÜËß£ÊûêÊàñÊ∏ÖÁêÜËá™Áî±Ê†ºÂºèÂìçÂ∫îÁöÑÈúÄË¶ÅÔºå‰ªéËÄåÂáèÂ∞ë‰∫ÜÈîôËØØÁöÑÂèØËÉΩÊÄßÔºåÂπ∂ÊèêÈ´ò‰∫ÜÂàÜÁ±ªÁÆ°ÈÅìÁöÑÂèØÈù†ÊÄß„ÄÇ\n\n‰∏∫Ê≠§ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®LangChain OpenAIÂÆ¢Êà∑Á´ØÂåÖË£ÖÂô®Ôºå‰ΩÜÂÆÉÈÄÇÁî®‰∫é‰ªª‰Ωï‰∏éOpenAIÂÖºÂÆπÁöÑÊ®°Âûã*(Êàë‰ª¨Âú®Ëøô‰∫õÂÆûÈ™å‰∏≠‰ΩøÁî®[NebiusAI](https://studio.nebius.ai/))*„ÄÇËøô‰∏™ÂåÖË£ÖÂô®Â∞ÜÂÖÅËÆ∏Êàë‰ª¨ÂêëLLMÂèëÈÄÅÁªìÊûÑÂåñÊü•ËØ¢ÔºåÈÅµÂæ™Êàë‰ª¨Â∞ÜÂÆö‰πâÁöÑÁâπÂÆöÊ®°Âºè„ÄÇ\n\n### Á¨¨‰∏ÄÊ≠•ÔºöÂÆö‰πâËæìÂá∫Ê®°Âºè\n\nÊàë‰ª¨È¶ñÂÖàÂÆö‰πâËæìÂá∫ÁöÑÊ®°ÂºèÔºåËØ•Ê®°ÂºèÂ∞ÜÁî±‰∏Ä‰∏™Á±ªÂà´Â≠óÊÆµÁªÑÊàê„ÄÇËØ•Â≠óÊÆµÂ∞Ü‰ΩøÁî® \\`Literal\\` Á±ªÂûãÔºåÂàóÂá∫ÊØè‰∏™ÂèØËÉΩÁöÑÁ±ªÂêç‰Ωú‰∏∫Â≠óÁ¨¶‰∏≤„ÄÇÈÄöËøáËøôÊ†∑ÂÅöÔºåÊàë‰ª¨Á°Æ‰øù LLM ÁöÑËæìÂá∫‰∏•Ê†ºÊòØËøô‰∫õÊúâÊïàÁ±ª‰∏≠ÁöÑ‰∏Ä‰∏™ÔºåÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•Â∞ÜÂÖ∂Áî®‰ΩúÊ®°ÂûãÁöÑÈ¢ÑÊµã„ÄÇ\n\nÊ®°ÂºèÂÆö‰πâ‰ΩøÁî® \\`pydantic\\` ÂÆûÁé∞Â¶Ç‰∏ãÔºö\n\n```python\nfrom typing import Literal\nfrom pydantic import BaseModel\n\ndef generate_classification_model(list_classes: list[str]):\n    assert list_classes  # Á°Æ‰øùÁ±ªÂàóË°®‰∏ç‰∏∫Á©∫\n\n    class ClassificationOutput(BaseModel):\n        category: Literal[tuple(list_classes)]\n\n    return ClassificationOutput\n\n## Á§∫‰æãÁî®Ê≥ï\nif __name__ == \"__main__\":\n    Categories = generate_classification_model([\"Yes\", \"No\"])\n    categories = Categories(category=\"Yes\")\n    print(categories)\n```\nÂú®Ëøô‰∏™Á§∫‰æã‰∏≠ÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ \\`ClassificationOutput\\` ÁöÑ Pydantic Ê®°ÂûãÔºåÂÖ∑Êúâ‰∏Ä‰∏™ \\`category\\` Â≠óÊÆµÔºåËØ•Â≠óÊÆµÈôêÂà∂‰∏∫‰∏ÄÁªÑÂ≠óÈù¢ÂÄºÔºåÂ¶Ç‚ÄúYes‚ÄùÂíå‚ÄúNo‚Äù„ÄÇËøô‰∏™ËÆæÁΩÆ‰ΩøÊàë‰ª¨ËÉΩÂ§üÈ™åËØÅ LLM ÁöÑËæìÂá∫ÔºåÁ°Æ‰øùÂÆÉÊòØÈ¢ÑÂÆö‰πâÁ±ªÂêç‰πã‰∏Ä„ÄÇ\n\n### Á¨¨2Ê≠•ÔºöÊûÑÂª∫Âπ∂ÂèëÈÄÅÊ∂àÊÅØ\n\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÂáÜÂ§á‰∏ÄÁ≥ªÂàóÊ∂àÊÅØÂèëÈÄÅÁªôLLM„ÄÇÁ¨¨‰∏ÄÊù°Ê∂àÊÅØÊòØÁ≥ªÁªüÊèêÁ§∫ÔºåÈÄöËøáÊèèËø∞‰ªªÂä°ÔºàÂàÜÁ±ªÔºâÂπ∂ÂàóÂá∫ÂèØËÉΩÁöÑËæìÂá∫Á±ªÂà´Êù•ËÆæÁΩÆ‰∏ä‰∏ãÊñá„ÄÇËøôÂºïÂØºLLMÁîüÊàê‰∏éÊâÄÈúÄÊ®°ÂºèÂåπÈÖçÁöÑËæìÂá∫„ÄÇÁ¨¨‰∫åÊù°Ê∂àÊÅØÂåÖÂê´Êàë‰ª¨Â∏åÊúõLLMÂàÜÁ±ªÁöÑÂÆûÈôÖÊñáÊú¨„ÄÇ\n\n‰ΩøÁî®LangChainÂÆ¢Êà∑Á´ØÂåÖË£ÖÂô®ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãËÆæÁΩÆÈÖçÁΩÆÊàë‰ª¨ÁöÑLLMÔºö\n\n```python\nimport os\nfrom typing import Literal\n\nfrom dotenv import load_dotenv\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel\n\nload_dotenv()\n\n\nclass ClassificationOutput(BaseModel):\n    category: Literal[\"news\", \"clickbait\"]\n\n\nllm_client = ChatOpenAI(\n    openai_api_base=os.environ.get(\"LLM_BASE_URL\"),\n    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n    openai_api_key=os.environ.get(\"LLM_API_KEY\"),\n    temperature=0,\n    max_retries=2,\n)\n\nconstrained_llm = llm_client.with_structured_output(ClassificationOutput)\n\nmessages = [\n    SystemMessage(\n        content=\"Â∞Ü‰ª•‰∏ãÊñáÊú¨ÂàÜÁ±ª‰∏∫È¢ÑÂÆö‰πâÁ±ªÂà´‰πã‰∏ÄÔºöÊñ∞ÈóªÊàñÁÇπÂáªËØ±È•µ\"\n    ),\n    HumanMessage(content=\"‰Ω†‰∏ç‰ºöÁõ∏‰ø°Êé•‰∏ãÊù•ÂèëÁîü‰∫Ü‰ªÄ‰πàÔºÅ\"),\n]\nprediction = constrained_llm.invoke(messages)\n\nprint(prediction)\n\n## Gives category='clickbait'\n```\nÈÄöËøáËøôÁßçÊñπÊ≥ïÔºåLLMÁöÑËæìÂá∫Â∞Ü‰∏éÊàë‰ª¨È¢ÑÂÆö‰πâÁöÑÁ±ªÂà´ÂåπÈÖçÔºå‰ΩøÂÖ∂ÂèØ‰ª•Áõ¥Êé•‰Ωú‰∏∫ÂàÜÁ±ªÁªìÊûú‰ΩøÁî®ÔºåËÄåÊó†ÈúÄËøõ‰∏ÄÊ≠•Â§ÑÁêÜ„ÄÇ\n\n### Á¨¨3Ê≠•ÔºöËØÑ‰º∞\n\n‰∏∫‰∫ÜËØÑ‰º∞Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÊàë‰ª¨Âú®[20 NewsgroupsÊï∞ÊçÆÈõÜ](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)ÔºàCC BY 4\\.0\\Ôºâ‰∏äËøõË°å‰∫ÜÊµãËØïÔºåÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéáËææÂà∞‰∫Ü**76\\.3%**„ÄÇËØ•ËÆæÁΩÆÂ±ïÁ§∫‰∫ÜÂèóÈôêÁîüÊàêÂú®ÊèêÈ´òÂàÜÁ±ªÂáÜÁ°ÆÊÄßÂíåÂáèÂ∞ëÈ¢ùÂ§ñÂ§ÑÁêÜÊ≠•È™§ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ\n\n## Idea 2: Few\\-shot prompting\n\nÁ¨¨‰∫åÁßçÊäÄÊúØÊòØ *few\\-shot prompting*ÔºåÊàë‰ª¨Âú®ÊèêÁ§∫‰∏≠ÂåÖÂê´‰∏Ä‰∫õÁ§∫‰æãËæìÂÖ•\\-ËæìÂá∫ÂØπÔºå‰ª•ÂºïÂØºLLM„ÄÇËøôÁßçÊñπÊ≥ïÂà©Áî®‰∫ÜLLMÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§ü‰ªéÊèê‰æõÁöÑÁ§∫‰æã‰∏≠ÊçïÊçâÊ®°ÂºèÔºåÈÄöÂ∏∏‰ºöÂØºËá¥ÂàÜÁ±ªÂáÜÁ°ÆÊÄßÁöÑÊèêÈ´ò„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨Â∞ÜÈÄöËøáÂú®ÊèêÁ§∫‰∏≠Áõ¥Êé•Ê∑ªÂä†‰∏Ä‰∫õÁ§∫‰æãÂàÜÁ±ªÊù•ÂÆûÁé∞few\\-shot promptingÔºå‰ª•Â¢ûÂº∫Ê®°ÂûãÁöÑËæìÂá∫Ë¥®Èáè„ÄÇ\n\nËÆ©Êàë‰ª¨Êù•ÁúãÁúã‰ª£Á†ÅÔºö\n\n```python\nimport os\nfrom typing import Literal\n\nfrom dotenv import load_dotenv\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel\n\nload_dotenv()\n\n\nclass ClassificationOutput(BaseModel):\n    category: Literal[\"news\", \"clickbait\"]\n\n\nllm_client = ChatOpenAI(\n    openai_api_base=os.environ.get(\"LLM_BASE_URL\"),\n    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n    openai_api_key=os.environ.get(\"LLM_API_KEY\"),\n    temperature=0,\n    max_retries=10,\n)\n\nconstrained_llm = llm_client.with_structured_output(ClassificationOutput)\n\nmessages = [\n    SystemMessage(\n        content=\"Classify the following text into one of the predefined categories: news or clickbait\"\n    ),\n    HumanMessage(content=\"The Shocking Truth Behind a Popular Wellness Trend\"),\n    AIMessage(content=\"clickbait\"),\n    HumanMessage(content=\"UK farmers call for weedkiller ban over Parkinson‚Äôs fears\"),\n    AIMessage(content=\"news\"),\n    HumanMessage(content=\"You won't believe what happened next!\"),\n]\nprediction = constrained_llm.invoke(messages)\n\nprint(prediction)\n\n## Gives category='clickbait'\n```\nÂú®Ëøô‰∏™ËÆæÁΩÆ‰∏≠ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ *HumanMessage* Âíå *AIMessage* Á±ªÂûãÁöÑÂØπËØùÂéÜÂè≤Ôºå‰ª•Ê®°ÊãüÊàë‰ª¨ÊúüÊúõLLMÂØπÊñáÊú¨ËøõË°åÂàÜÁ±ªÁöÑÁ§∫‰æã„ÄÇÈÄöËøáÂ±ïÁ§∫Êàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÂàÜÁ±ªÈ£éÊ†ºÂíåÊ†ºÂºè‚Äî‚Äî‰æãÂ¶ÇÂ∞Ü‚ÄúThe Shocking Truth Behind a Popular Wellness Trend‚ÄùÂàÜÁ±ª‰∏∫‚Äúclickbait‚ÄùÔºåÂ∞Ü‚ÄúUK farmers call for weedkiller ban over Parkinson‚Äôs fears‚ÄùÂàÜÁ±ª‰∏∫‚Äúnews‚Äù‚Äî‚ÄîÊàë‰ª¨‰∏∫Ê®°ÂûãËÆæÂÆö‰∫ÜÊòéÁ°ÆÁöÑÊúüÊúõ„ÄÇÂΩìÊúÄÁªàÁöÑÂàÜÁ±ªËØ∑Ê±Ç‚ÄúYou won‚Äôt believe what happened next!‚ÄùË¢´ÂèëÈÄÅÊó∂ÔºåLLMÂèØ‰ª•Âà©Áî®Ëøô‰∫õÁ§∫‰æãÊù•Á°ÆÂÆöÈÄÇÂΩìÁöÑÂìçÂ∫î„ÄÇ\n\nÂú®ÊµãËØïËøôÁßçfew\\-shotÊñπÊ≥ïÂêéÔºåÊàë‰ª¨ËßÇÂØüÂà∞ÂáÜÁ°ÆÁéá‰∏∫ **76\\.6%**ÔºåÊØîÊàë‰ª¨ÁöÑÁ∫¶ÊùüÁîüÊàêÊñπÊ≥ïÁï•ÊúâÊèêÈ´ò„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÁ§∫‰æãÊòØÈöèÊú∫ÈÄâÊã©ÁöÑÔºåËøôÂèØËÉΩÊó†Ê≥ïÂÖÖÂàÜÂ±ïÁ§∫few\\-shot promptingÁöÑÊΩúÂäõ„ÄÇ‰ªîÁªÜÈÄâÊã©ÊàñÁ≠ñÂàí‰∏éËæìÂÖ•Êï∞ÊçÆÊõ¥Á¥ßÂØÜÂåπÈÖçÁöÑÁ§∫‰æãÂèØËÉΩ‰ºö‰∫ßÁîüÊõ¥Â•ΩÁöÑÁªìÊûú„ÄÇÂú®Êú¨ÊïôÁ®ãÁöÑ‰∏ã‰∏ÄÈÉ®ÂàÜÔºåÊàë‰ª¨Â∞ÜÁ†îÁ©∂‰∏ÄÁßçÊõ¥È´òÁ∫ßÁöÑÊäÄÊúØÔºöÂü∫‰∫éÁõ∏‰ººÊÄßÂä®ÊÄÅÈÄâÊã©Á§∫‰æãÔºåËøôÂèØËÉΩËøõ‰∏ÄÊ≠•ÊèêÈ´òÂáÜÁ°ÆÊÄß„ÄÇ\n\n## ÊÉ≥Ê≥ï 3ÔºöÂä®ÊÄÅÁ§∫‰æãÈÄâÊã©\n\nÊàë‰ª¨ÊèêÈ´ò LLM ÂàÜÁ±ªÂáÜÁ°ÆÊÄßÁöÑÁ¨¨‰∏âÁßçÊäÄÊúØÊòØÊ†πÊçÆÊü•ËØ¢‰∏≠ÁöÑÊñáÊú¨Âä®ÊÄÅÈÄâÊã©Áõ∏ÂÖ≥Á§∫‰æã„ÄÇÊàë‰ª¨‰∏çÊòØ‰ΩøÁî®ÈùôÊÄÅÁöÑÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫ÔºåËÄåÊòØÈíàÂØπÊØè‰∏™Êü•ËØ¢‰ΩøÁî® ChromaDB ËøõË°åÁõ∏‰ººÊÄßÊêúÁ¥¢Ôºå‰ª•ËØÜÂà´ÂÖ∂Âú®Ê†áËÆ∞ËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑÊúÄËøëÈÇª„ÄÇÈÄöËøáÈÄâÊã©‰∏éËæìÂÖ•ÊñáÊú¨Âú®ËØ≠Â¢É‰∏äÁõ∏‰ººÁöÑÁ§∫‰æãÔºåÊàë‰ª¨ÂèØ‰ª•‰∏∫ LLM Êèê‰æõÈ´òÂ∫¶Áõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂ¢ûÂä†ÂáÜÁ°ÆÂàÜÁ±ªÁöÑÂèØËÉΩÊÄß„ÄÇ\n\nË¶ÅÂÆûÁé∞Ëøô‰∏ÄÁÇπÔºåÊàë‰ª¨È¶ñÂÖàÊûÑÂª∫‰∏Ä‰∏™Âü∫‰∫éÂµåÂÖ•ÁöÑÊ£ÄÁ¥¢Á≥ªÁªü„ÄÇÂÆÉÁöÑÂ∑•‰ΩúÂéüÁêÜÂ¶Ç‰∏ãÔºö\n\n### Á¨¨‰∏ÄÊ≠•Ôºö‰ΩøÁî®Âä®ÊÄÅÊèêÁ§∫ÂàùÂßãÂåñÂàÜÁ±ªÂô®\n\nÊàë‰ª¨ÁöÑ `LLMTextClassifier` Á±ªÊé•ÂèóÂèØËÉΩÁ±ªÂà´ÁöÑÂàóË°®ÔºåÂπ∂ÊûÑÂª∫‰∏Ä‰∏™Áî®‰∫éÂàÜÁ±ªÁöÑÊèêÁ§∫Ê®°Êùø„ÄÇÊàë‰ª¨ÈÖçÁΩÆÂàÜÁ±ªÂô®‰ª•Ê£ÄÁ¥¢‰∏éÊü•ËØ¢ÊñáÊú¨ÊúÄÁõ∏‰ººÁöÑ‰∏ÄÂÆöÊï∞ÈáèÁöÑÁ§∫‰æãÔºàÁî± `max_examples` ÊéßÂà∂Ôºâ„ÄÇ\n\n‰ΩøÁî®Ê≠§ËÆæÁΩÆÔºåÂàÜÁ±ªÂô®Âä®ÊÄÅÈÄâÊã©Á§∫‰æãÔºåÂ∞ÜÂÆÉ‰ª¨Ê≥®ÂÖ•ÊèêÁ§∫‰∏≠ÔºåÊ†ºÂºè‰∏éÂâç‰∏ÄÁßçÊñπÊ≥ï‰∏≠ÁöÑÂ∞ëÈáèÁ§∫‰æãÁõ∏ÂêåÔºö\n\n```python\nclass LLMTextClassifier:\n    def __init__(\n        self,\n        categories: list[str],\n        system_prompt_template: PromptTemplate = PromptTemplate(\n            input_variables=[\"categories\", \"schema\"],\n            template=\"Classify the following text into one of the following classes: {categories}.\\n \"\n            \"Use the following schema: {schema}\",\n        ),\n        llm_client: BaseChatModel = llm_medium,\n        max_examples: int = 5,\n    ):\n        # Initialize model, prompt, and retrieval variables\n        self.categories = categories\n        self.categories_model = generate_classification_model(categories)\n        self.system_prompt_template = system_prompt_template\n        self.system_prompt = system_prompt_template.format(\n            categories=categories, schema=self.categories_model.model_json_schema()\n        )\n        self.llm_classifier = llm_client.with_structured_output(self.categories_model)\n        self.max_examples = max_examples\n        self.examples = None\n        self.vector_store = None\n        self.retriever = None\n```\n\n### Á¨¨2Ê≠•Ôºö‚ÄúËÆ≠ÁªÉ‚ÄùÂàÜÁ±ªÂô®‰∏éÁ§∫‰æãÊï∞ÊçÆ\n\n‰∏∫‰∫Ü‚ÄúËÆ≠ÁªÉ‚ÄùÊàë‰ª¨ÁöÑÂàÜÁ±ªÂô®ÔºàËøôÈáåÁöÑËÆ≠ÁªÉÊòØÂÆΩÊ≥õÁöÑÔºåÂõ†‰∏∫Ê≤°ÊúâÊõ¥Êñ∞ÊùÉÈáçÔºâÔºåÊàë‰ª¨Áî®Ê†áËÆ∞‰∫ÜÂêÑËá™Á±ªÂà´ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÁ§∫‰æãÂ°´ÂÖÖÂêëÈáèÂ≠òÂÇ®„ÄÇËøô‰∏ÄËÆæÁΩÆ‰∏∫ÂàÜÁ±ªÂô®Âú®ËæìÂÖ•Êñ∞Êü•ËØ¢Êó∂Âä®ÊÄÅÊ£ÄÁ¥¢ÊúÄÁõ∏ÂÖ≥ÁöÑÁ§∫‰æãÂÅöÂ•ΩÂáÜÂ§áÔºö\n\n```python\n    def fit(self, texts, labels):\n        self.examples = [\n            Document(page_content=text, metadata={\"label\": label})\n            for text, label in zip(texts, labels)\n        ]\n\n        if len(self.examples) > self.max_examples:\n            # Add examples to vector store\n            self.vector_store = Chroma.from_documents(\n                documents=self.examples,\n                collection_name=\"llm-classifier\",\n                embedding=ChromaEmbeddingsAdapter(\n                    embedding_functions.DefaultEmbeddingFunction()\n                ),\n            )\n            self.retriever = self.vector_store.as_retriever(\n                search_kwargs={\"k\": self.max_examples}\n            )\n```\n\n### Á¨¨3Ê≠•ÔºöÂä®ÊÄÅÊ£ÄÁ¥¢Áõ∏ÂÖ≥Á§∫‰æãÂπ∂ÂàÜÁ±ª\n\nÂΩìËæìÂÖ•Êñ∞ÁöÑÊñáÊú¨ËøõË°åÂàÜÁ±ªÊó∂ÔºåÂàÜÁ±ªÂô®Ê†πÊçÆ‰∏éÊü•ËØ¢ÁöÑÁõ∏‰ººÊÄßÊ£ÄÁ¥¢Áõ∏ÂÖ≥Á§∫‰æã„ÄÇËøô‰∏™Áõ∏ÂÖ≥Á§∫‰æãÁöÑÂàóË°®Ë¢´Ê∑ªÂä†Âà∞ÊèêÁ§∫‰∏≠ÔºåÁ¥ßÊé•ÁùÄÊòØÊü•ËØ¢Êú¨Ë∫´ÔºåÁÑ∂ÂêéÂèëÈÄÅÁªôLLMËøõË°åÂàÜÁ±ªÔºö\n\n```python\n def predict(self, text: str) -> str:\n        messages = [SystemMessage(content=self.system_prompt)]\n        \n        for example in self.fetch_examples(text=text):\n            messages.append(HumanMessage(content=example.page_content))\n            messages.append(AIMessage(content=example.metadata[\"label\"]))\n\n        messages.append(HumanMessage(content=text))\n        prediction = self.llm_classifier.invoke(messages)\n\n        return prediction.category\n```\n\n### Á¨¨4Ê≠•ÔºöÁ§∫‰æãËøêË°å\n\n\n```python\nif __name__ == \"__main__\":\n    categories = [\"news\", \"clickbait\"]\n    classifier = LLMTextClassifier(categories=categories, max_examples=1)\n\n    texts = [\"Donald Trump won Michigan\", \"You won't believe what happened next!\"]\n    labels = [\"news\", \"clickbait\"]\n    \n    classifier.fit(texts, labels)\n\n    text = \"Donald Trump won Florida\"\n    result = classifier.predict(text)\n    print(result)  # Should output \"news\" if similar to \"news\" examples\n```\n‰ΩøÁî®Âä®ÊÄÅÂ∞ëÊ†∑Êú¨ÊäÄÊúØÔºåÊàë‰ª¨Âú®ÂàÜÁ±ªÂáÜÁ°ÆÁéá‰∏äÁúãÂà∞‰∫ÜÊòæËëóÊèêÈ´òÔºåËææÂà∞‰∫Ü **88.6%**„ÄÇËøôÊØî‰ª•ÂâçÁöÑÊñπÊ≥ïÊúâ‰∫ÜÊòæËëóÁöÑÂ¢ûÂä†ÔºåÂ±ïÁ§∫‰∫ÜÊ†πÊçÆ‰∏éÊü•ËØ¢ÊñáÊú¨ÁöÑÁõ∏‰ººÊÄßÂä®ÊÄÅÈÄâÊã©Áõ∏ÂÖ≥Á§∫‰æãÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇ\n\n## ÁªìËÆ∫\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÂº∫Â§ßÁöÑÊñπÊ≥ïÔºåÈÄöËøá‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊûÑÂª∫ÂèØÈù†‰∏îÂáÜÁ°ÆÁöÑÊñáÊú¨ÂàÜÁ±ªÁÆ°ÈÅì„ÄÇÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏âÁßçÂÖ≥ÈîÆÊäÄÊúØÔºö*ÂèóÈôêÁîüÊàê*„ÄÅ*Â∞ëÈáèÁ§∫‰æãÊèêÁ§∫*Âíå*Âä®ÊÄÅÂ∞ëÈáèÁ§∫‰æãÈÄâÊã©*„ÄÇËøô‰∫õÊñπÊ≥ïÂêÑËá™Â∏¶Êù•‰∫ÜÁã¨ÁâπÁöÑ‰ºòÂäøÔºå‰ª•ÊèêÈ´òÂàÜÁ±ªÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÁî®ÊÄßÔºå‰ΩøLLMsÊàê‰∏∫ÊúâÊïàÁöÑÊñáÊú¨ÂàÜÁ±ªÂ∑•ÂÖ∑„ÄÇ\n\nÁ¨¨‰∏ÄÁßçÊäÄÊúØÔºåÂèóÈôêÁîüÊàêÔºåÊ∂âÂèäÂ∞ÜLLMÁöÑÂìçÂ∫îÈôêÂà∂Âú®È¢ÑÂÆö‰πâÁöÑÁ±ªÂà´ÂÜÖÔºåÂáèÂ∞ë‰∫ÜÂ§çÊùÇÂêéÂ§ÑÁêÜÁöÑÈúÄÊ±ÇÔºåÂπ∂‰ΩøËß£ÊûêÊ®°ÂûãËæìÂá∫ÂèòÂæóÊõ¥ÂÆπÊòì„ÄÇ‰ªÖÂá≠Ëøô‰∏ÄÊñπÊ≥ïÔºåÊàë‰ª¨Â∞±ËÉΩÂ§üÈÅøÂÖçËá™Áî±ÊñáÊú¨ÁîüÊàêÁöÑÂ∏∏ËßÅÈô∑Èò±ÔºåÊèêÈ´òLLMÂú®ÂàÜÁ±ª‰∏≠ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ\n\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÂÆûÊñΩ‰∫ÜÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫ÔºåÊàë‰ª¨ÂêëLLMÊèê‰æõ‰∫Ü‰∏Ä‰∫õÊ†áËÆ∞ÁöÑÁ§∫‰æã‰Ωú‰∏∫ÊèêÁ§∫ÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÈÄöËøáÂà©Áî®Ê®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ËÉΩÂäõÔºåÂ∞ëÈáèÁ§∫‰æãÊèêÁ§∫ÈÄöËøá‰∏∫ËæìÂá∫Ê†ºÂºèÂíåÂÜÖÂÆπËÆæÂÆöÊòéÁ°ÆÁöÑÊúüÊúõÔºåÊèêÈ´ò‰∫ÜÂàÜÁ±ªÂáÜÁ°ÆÊÄß„ÄÇÁÑ∂ËÄåÔºåÊàë‰ª¨ÂèëÁé∞Á§∫‰æãÁöÑÈÄâÊã©Ëá≥ÂÖ≥ÈáçË¶Å‚Äî‚ÄîÈöèÊú∫ÈÄâÊã©ÁöÑÁ§∫‰æã‰ªÖÊèê‰æõ‰∫ÜÈÄÇÂ∫¶ÁöÑÊîπÂñÑ„ÄÇËøô‰ΩøÊàë‰ª¨ËΩ¨Âêë‰∫ÜÊúÄÂêé‰∏ÄÁßçÊäÄÊúØÔºöÂä®ÊÄÅÂ∞ëÈáèÁ§∫‰æãÈÄâÊã©„ÄÇ\n\nÂä®ÊÄÅÂ∞ëÈáèÁ§∫‰æãÈÄâÊã©ÊòØÊúÄÂÖàËøõÂíåÊúâÊïàÁöÑÊñπÊ≥ïÔºåËææÂà∞‰∫Ü88.6%ÁöÑÈ´òÂàÜÁ±ªÂáÜÁ°ÆÁéá„ÄÇÈÄöËøá‰ΩøÁî®ChromaDB‰∏∫ÊØè‰∏™Êü•ËØ¢Ê£ÄÁ¥¢ÊúÄÁõ∏‰ººÁöÑÁ§∫‰æãÔºåËøôÁßçÊäÄÊúØ‰ΩøLLM‰ªÖËÆøÈóÆÊúÄÁõ∏ÂÖ≥ÁöÑ‰∏ä‰∏ãÊñáÔºå‰ªéËÄåÊòæËëóÂ¢ûÂº∫‰∫ÜÂÖ∂È¢ÑÊµãÂáÜÁ°ÆÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÊòØ‰∏ÄÁßçÂÆûÁî®ÁöÑÊñπÂºèÔºå‰ΩøÂÉèLLMsËøôÊ†∑ÁöÑÈÄöÁî®Ê®°ÂûãË°®Áé∞ÂæóÊõ¥ÂÉè‰∏ì‰∏öÂàÜÁ±ªÂô®ÔºåËÄåÊó†ÈúÄ‰ªéÂ§¥ÂºÄÂßãËÆ≠ÁªÉËá™ÂÆö‰πâÊ®°Âûã„ÄÇ\n\n### ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nÈöèÁùÄLLMsÂèòÂæóË∂äÊù•Ë∂äÂèØËÆøÈóÆÂíåÂº∫Â§ßÔºåÂÆÉ‰ª¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®‰πü‰∏çÊñ≠Â¢ûÈïø„ÄÇËôΩÁÑ∂Ëøô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÊòØÈÄöÁî®ÁöÑÔºå‰ΩÜÊàë‰ª¨ÁöÑÊïôÁ®ãÂ±ïÁ§∫‰∫ÜÈÄöËøáÊúâÈíàÂØπÊÄßÁöÑÊäÄÊúØÔºåÂÆÉ‰ª¨ÂèØ‰ª•Ë¢´Ë∞ÉÊï¥‰∏∫È´òÊÄßËÉΩÁöÑÂàÜÁ±ªÂô®„ÄÇÊàë‰ª¨Âú®ËøôÈáå‰ªãÁªçÁöÑÊØèÁßçÊñπÊ≥ï‚Äî‚Äî‰ªéÁÆÄÂçïÁöÑÁ∫¶ÊùüÁîüÊàêÂà∞ÂÖàËøõÁöÑÂä®ÊÄÅÂ∞ëÈáèÊ†∑Êú¨ÈÄâÊã©‚Äî‚ÄîÈÉΩÊèê‰æõ‰∫ÜÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇÂÆÉ‰ª¨‰∏∫ÊûÑÂª∫ÂàÜÁ±ªÁ≥ªÁªüÊèê‰æõ‰∫ÜÂèØÊâ©Â±ïÁöÑËß£ÂÜ≥ÊñπÊ°àÔºå‰ΩøÂæóÂ∞ÜLLMsÈõÜÊàêÂà∞Áîü‰∫ß‰∏≠ÂèòÂæóÂèØË°åÔºåËÄåÊó†ÈúÄÂ§ßÈáèÁöÑÊï∞ÊçÆÊî∂ÈõÜÊàñËÆ≠ÁªÉ„ÄÇ\n\nÊó†ËÆ∫ÊÇ®ÊòØNLP‰ªé‰∏öËÄÖ„ÄÅÊï∞ÊçÆÁßëÂ≠¶ÂÆ∂ËøòÊòØAIÁà±Â•ΩËÄÖÔºåËøô‰∫õÊäÄÊúØÈÉΩ‰∏∫ÊÇ®ÁöÑÊú∫Âô®Â≠¶‰π†Â∑•ÂÖ∑ÂåÖÂ¢ûÂä†‰∫ÜÂ§öÂäüËÉΩÁöÑÂ∑•ÂÖ∑„ÄÇÂÄüÂä©LLMsÂíåËøô‰∫õÊäÄÊúØÔºåÊÇ®ÂèØ‰ª•ÈÉ®ÁΩ≤ÈíàÂØπÁâπÂÆöÈúÄÊ±ÇÈáèË∫´ÂÆöÂà∂ÁöÑÂº∫Â§ßÊúâÊïàÁöÑÊñáÊú¨ÂàÜÁ±ªÁ≥ªÁªü„ÄÇ\n\nÊÑüË∞¢ÊÇ®ÁöÑÈòÖËØªÔºÅ\n\nCode: <https://github.com/CVxTz/llmclassifier>\n\n"},{"lang":"zh","group":"blog","slug":"blog/building-autonomous-multi-agent-systems-with-crewai-1a3b3a348271","frontmatter":{"title":"Âà©Áî® CrewAI ÊûÑÂª∫Ëá™‰∏ªÂ§ö‰ª£ÁêÜÁ≥ªÁªü","meta_title":"Âà©Áî® CrewAI ÊûÑÂª∫Ëá™‰∏ªÂ§ö‰ª£ÁêÜÁ≥ªÁªü","description":"Êú¨Êñá‰ªãÁªç‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®CrewAIÂíåLangChainÊûÑÂª∫Ëá™‰∏ªÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü„ÄÇÊñáÁ´†È¶ñÂÖàÈòêËø∞‰∫ÜÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑÊ¶ÇÂøµÔºåÂº∫Ë∞É‰ª£ÁêÜ„ÄÅÂ∑•ÂÖ∑Âíå‰ªªÂä°ÁöÑÂçè‰ΩúÂÖ≥Á≥ª„ÄÇÊé•ÁùÄÔºåËØ¶ÁªÜÊèèËø∞‰∫ÜCrewAIÊ°ÜÊû∂ÁöÑ‰ºòÂäøÂíåÈ°πÁõÆÁªìÊûÑÔºåÂåÖÊã¨Â¶Ç‰ΩïÂàõÂª∫‰ª£ÁêÜ„ÄÅÂÆö‰πâ‰ªªÂä°Âíå‰ΩøÁî®Â∑•ÂÖ∑„ÄÇÈÄöËøá‰∏Ä‰∏™ËÆ∫ÊñáÂÜô‰ΩúÈ°πÁõÆÁ§∫‰æãÔºåÂ±ïÁ§∫‰∫Ü‰ª£ÁêÜÂ¶Ç‰ΩïÊî∂ÈõÜ‰ø°ÊÅØ„ÄÅÊí∞ÂÜôÂíåÁºñËæëÂÜÖÂÆπ„ÄÇÊúÄÂêéÔºå‰ΩøÁî®StreamlitÊ°ÜÊû∂Â∞ÜÂ∫îÁî®Á®ãÂ∫èÈÉ®ÁΩ≤Ôºå‰ΩøÁî®Êà∑ËÉΩÂ§ü‰∏éÁ≥ªÁªüËøõË°å‰∫§‰∫í„ÄÇÊï¥‰Ωì‰∏äÔºåÊñáÁ´†Âº∫Ë∞É‰∫ÜÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂú®ÊèêÈ´ò‰ªªÂä°ÊïàÁéáÂíåÂçè‰ΩúÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*72Cy_QqOie7G2NAiWr13Kw.jpeg","categories":["Autonomous Systems","Programming","Data Science"],"author":"Rifx.Online","tags":["CrewAI","LangChain","multi-agent","Streamlit","essay-writing"],"draft":false,"slug":"blog/building-autonomous-multi-agent-systems-with-crewai-1a3b3a348271"},"content":"\n### ‰ªÄ‰πàÊòØÂ§öÊô∫ËÉΩ‰ΩìËá™‰∏ªÁ≥ªÁªü‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®CrewAIÂíåLangChainÊûÑÂª∫‰∏Ä‰∏™Ôºü\n\n\n\n## Âä®Êú∫\n\nÂÆûÈôÖ‰∏äÔºåÊàë‰ª¨ÂØπËøô‰∫õÊ¶ÇÂøµÂπ∂‰∏çÈôåÁîüÔºõÊàë‰ª¨‰ªéÁîµÂΩ±‰∏≠‰∫ÜËß£Âà∞ÂÆÉ‰ª¨„ÄÇ‰∏Ä‰∏™‰∫∫ÊåáÊå•‰ªñ‰ª¨ÁöÑAIÔºåËÄåAIÈÄöËøá‰ΩøÁî®ÂêÑÁßçÂ∑•ÂÖ∑Êù•ÊâßË°åËøô‰∫õÂëΩ‰ª§„ÄÇËøôÂ∞±ÊòØÊàë‰ª¨‰ªäÂ§©Âú®AIÁ≥ªÁªüÂ¥õËµ∑ÁöÑÈÅìË∑Ø‰∏äÊâÄËµ∞ÁöÑÊñπÂêë„ÄÇÊó∂‰ª£Ê≠£Âú®ÈÄêÊ∏êÂèòÂåñ„ÄÇÂú®ËøáÂéªÔºå‰∫∫‰ª¨Êó†Ê≥ïÁã¨Ëá™ÂÆåÊàê‰∏ÄÈ°π‰ªªÂä°ÔºåÈúÄË¶Å‰∏Ä‰∏™Âõ¢Èòü„ÄÇÊ≤°ÊúâÂõ¢ÈòüÔºå‰ªñ‰ª¨Ë¶Å‰πàÂú®‰∏ÄÊÆµÊó∂Èó¥ÂêéÁ≤æÁñ≤ÂäõÁ´≠ÔºåË¶Å‰πàËææÂà∞ËÉΩÂäõÁöÑÊûÅÈôê„ÄÇÊúÄÁªàÔºåÊàêÂäüÁöÑÈ°πÁõÆÊù•Ëá™‰∫éÁî±ÂÖ∑Êúâ‰∏çÂêåÊäÄËÉΩÁöÑ‰∏™‰∫∫ÁªÑÊàêÁöÑÂõ¢Èòü„ÄÇ\n\n> Âõ¢ÈòüÂêà‰Ωú‰ΩøÊ¢¶ÊÉ≥ÊàêÁúü„ÄÇ\n\nÁÑ∂ËÄåÔºåÂ¶Ç‰ªä‰∏ÄÁßçÊñ∞ÊäÄÊúØÂºÄÂßãÂ¥≠Èú≤Â§¥Ëßí„ÄÇÊàë‰ª¨ÂèØ‰ª•Áß∞‰πã‰∏∫AGI‰πãÂâçÁöÑAI‰∏ã‰∏Ä‰∏™Èò∂ÊÆµÔºö‚Äú‰ª£ÁêÜ‚Äù„ÄÇÈÇ£‰πàÔºåËøô‰∫õ‰ª£ÁêÜÊòØ‰ªÄ‰πàÂë¢ÔºüÂú®Ê∑±ÂÖ•‰ª£Á†Å‰πãÂâçÔºåËÆ©Êàë‰ª¨ÂÖàË∞àË∞àÂ§ö‰ª£ÁêÜÁ≥ªÁªüÁöÑÁªìÊûÑ„ÄÇ\n\n## ÂÆÉÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÔºü\n\nÁÆÄÂçïÊù•ËØ¥ÔºåËøô‰∏™ÊñπÁ®ãÂºèÂèØ‰ª•Ë°®Á§∫‰∏∫Ôºö`Multi Agent Systems = AGENTs + TOOLs + TASKs` ËøôÊòØ‰∏Ä‰∏™Â§ö‰∏™‰ª£ÁêÜÈÖçÂ§á‰∫ÜÂêÑÁßç‰ªªÂä°ÂíåÂ∑•ÂÖ∑ÁöÑÁ≥ªÁªü„ÄÇ\n\n### ‰ª£ÁêÜ\n\nÊàë‰ª¨ÁÜüÊÇâËßíËâ≤ÊâÆÊºîÊ∏∏ÊàèÔºåÂú®Ëøô‰∫õÊ∏∏Êàè‰∏≠Ôºå‰Ω†ÁöÑËßíËâ≤Êúâ‰∏Ä‰∏™ËßíËâ≤ÔºåÊØîÂ¶ÇÊàòÂ£´„ÄÇ‰æãÂ¶Ç„ÄÇÂú®Ê∏∏Êàè‰∏≠Ôºå‰Ω†Â∞ÜËá™Â∑±ÁΩÆ‰∫é‰ªñ‰ª¨ÁöÑ‰ΩçÁΩÆÔºåÊó®Âú®ÈÄöËøáÂÆåÊàêÂ°ëÈÄ†‰ªñ‰ª¨ËÉåÊôØÊïÖ‰∫ãÁöÑ‰ªªÂä°Ôºå‰ªé‰∏ÄÊ¨°ÂÜíÈô©Âà∞‰∏ã‰∏ÄÊ¨°ÂÜíÈô©Êù•ÂÆåÊàêÊ∏∏Êàè„ÄÇÁ±ª‰ººÂú∞ÔºåÁ†îÁ©∂‰∫∫ÂëòÂèëÁé∞ÔºåÂΩìÁªôÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLMs) ËßíËâ≤„ÄÅËÉåÊôØÊïÖ‰∫ãÂíåÁõÆÊ†áÊó∂ÔºåÂÆÉ‰ª¨ÂèØ‰ª•Ë¢´ÊøÄÂä±‰ª•ÊúÄ‰Ω≥ÊñπÂºèÊâßË°å‰ªªÂä°„ÄÇËøô‰ΩøÊàë‰ª¨ËÉΩÂ§üÈÄöËøáÂá†‰∏™ÁÆÄÂçïÁöÑÊèêÁ§∫Êù•ÊøÄÂä± LLM ÊâßË°åÂêÑÁßç‰ªªÂä°„ÄÇ\n\n‰ª£ÁêÜÊú¨Ë¥®‰∏äÂ∞ÜÂàÜÈÖçÁöÑ‰ªªÂä°ÂàÜËß£‰∏∫ÁÆÄÂçïÁöÑÊ≠•È™§ÔºåÁÑ∂ÂêéÈÄöËøá‚ÄúÊÄùËÄÉ‚Äù‚Äî‚ÄîÊòØÁöÑÔºåÊÄùËÄÉ‚Äî‚ÄîÊåâÈ°∫Â∫èÊâßË°åËøô‰∫õÊ≠•È™§„ÄÇËøô‰ΩøÊàë‰ª¨ËÉΩÂ§üÂàõÂª∫‰∏Ä‰∏™‰∏ç‰ªÖËÉΩÊ∑±ÊÄùÁÜüËôëÂú∞ÊâßË°åÊ≠•È™§ÁöÑ‰ª£ÁêÜÔºåËøòËÉΩÂí®ËØ¢ÂÖ∂‰ªñÂÖ∑Êúâ‰∏çÂêå‰∏ì‰∏öÈ¢ÜÂüüÁöÑ‰ª£ÁêÜÔºåËÄå‰∏çÊòØ‰æùËµñÂçï‰∏™ LLM ËæìÂÖ•ÊèêÁ§∫Âπ∂Êé•Êî∂ËæìÂá∫„ÄÇ\n\n### Â∑•ÂÖ∑\n\n‰∫∫Á±ªÊúÄ‰ºüÂ§ßÁöÑËÉΩÂäõ‰πã‰∏ÄÊó†ÁñëÊòØÊàë‰ª¨‰ΩøÁî®Â∑•ÂÖ∑ÁöÑÊäÄËÉΩ„ÄÇËøôÁßçËÉΩÂäõÈÄöËøáËøõÂåñÂíåÊñáÂåñËøáÁ®ã‰∏çÊñ≠ÊºîÂèòÂíåÂèëÂ±ïÔºå‰ΩøÊàë‰ª¨ËÉΩÂ§üÂàõÈÄ†Âá∫‰ªäÂ§©ÊâÄ‰ΩøÁî®ÁöÑÂÖàËøõÊäÄÊúØ„ÄÇÂêåÊ†∑ÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈöèÁùÄËÆ≠ÁªÉÂú®Êõ¥Â§ßÊï∞ÊçÆÈõÜ‰∏äÁöÑËÉΩÂäõ‰πüÂú®‰∏çÊñ≠Â¢ûÂº∫„ÄÇÁé∞Âú®ÔºåÂΩìÂ∑•ÂÖ∑ÁöÑÂäüËÉΩÂèäÂÖ∂‰ΩøÁî®ÊñπÂºèË¢´Ê∏ÖÊô∞Ëß£ÈáäÊó∂ÔºåËøô‰∫õÊ®°ÂûãËÉΩÂ§üÂú®ÈÄÇÂΩìÊù°‰ª∂‰∏ãËá™‰∏ª‰ΩøÁî®Â∑•ÂÖ∑ÔºåÂÆåÂÖ®Ëá™Âä®ÊâßË°åÔºåÂπ∂Ê†πÊçÆËæìÂá∫ËßÑÂàí‰∏ã‰∏ÄÊ≠•ÔºåËÄåÊó†ÈúÄÁ≠âÂæÖËøõ‰∏ÄÊ≠•ÁöÑÂëΩ‰ª§„ÄÇ\n\nÂõ†Ê≠§ÔºåÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®‰πüÂèØ‰ª•Ë¢´ËßÜ‰∏∫ÂÆÉ‰ª¨ËøõÂåñ‰∏≠ÊúÄÈáçË¶ÅÁöÑÈÉ®ÂàÜ‰πã‰∏Ä„ÄÇÂ∞§ÂÖ∂ÊòØÈÄöËøá‰∫íËÅîÁΩëÊµèËßàÂ∑•ÂÖ∑Ôºå‰ª£ÁêÜÂèØ‰ª•ÊåâÁÖßÊåáÂÆöÂäüËÉΩÁöÑÊ≠•È™§ËÆøÈóÆÂøÖË¶ÅÁöÑËµÑÊ∫êÔºåÊó†ËÆ∫ÊòØÈÄöËøáÁΩëÁªúÁà¨Ëô´ËøòÊòØ‰ΩøÁî®ÊåáÂÆöÁΩëÁ´ôÁöÑÊêúÁ¥¢ÂºïÊìé„ÄÇ\n\nÊÇ®Â∑•ÂÖ∑ÁöÑÂäüËÉΩÂíåÁõÆÁöÑÂÆåÂÖ®ÂèñÂÜ≥‰∫éÊÇ®ÁöÑÊÉ≥Ë±°Âäõ„ÄÇÁÑ∂ËÄåÔºåÂ¶ÇÊûúÊÇ®Â∏åÊúõÂ∞ÜÈ¢ÑÊûÑÂª∫ÁöÑÂ∑•ÂÖ∑ÈõÜÊàêÂà∞ÊÇ®ÁöÑ‰ª£ÁêÜ‰∏≠ÔºåCrewAI Âíå LangChain Â∫ìÈÉΩÊèê‰æõ‰∫ÜÂπøÊ≥õÁöÑÂÜÖÁΩÆÂ∑•ÂÖ∑‰æõÊÇ®‰ΩøÁî®„ÄÇÂú®Ëøô‰∏™È°πÁõÆ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÈáçÁÇπÂàõÂª∫Êàë‰ª¨Ëá™Â∑±ÁöÑËá™ÂÆö‰πâÂ∑•ÂÖ∑„ÄÇ\n\n### ‰ªªÂä°\n\nÂ∞±ÂÉèÊàë‰ª¨ÂàõÂª∫‰ª£ÁêÜ‰∏ÄÊ†∑ÔºåÊàë‰ª¨‰πüÂàõÂª∫‰ªªÂä°ÔºåÊØè‰∏™‰ªªÂä°ÈÉΩÈúÄË¶ÅÂêÑÁßçÂ∑•ÂÖ∑„ÄÇ‰∏æ‰∏Ä‰∏™‰∫∫Á±ªË°å‰∏∫ÁöÑ‰æãÂ≠êÔºåÂΩìÊàë‰ª¨ÈúÄË¶ÅÁ†îÁ©∂Êüê‰∏™‰∫ãÊÉÖÊó∂ÔºåÊàë‰ª¨‰ºöÂÅö‰ªÄ‰πàÔºü\n\n1\\- Êàë‰ª¨Âú®‰∫íËÅîÁΩë‰∏äÊêúÁ¥¢„ÄÇ\n\n2\\- Êàë‰ª¨ËøõË°åÊ∑±ÂÖ•ÁöÑÊù•Ê∫êÁ†îÁ©∂„ÄÇ\n\n3\\- Êàë‰ª¨ÂØπÊàë‰ª¨ÁöÑÂèëÁé∞ËøõË°åÁ¨îËÆ∞„ÄÇ\n\n‰ª•ÂêåÊ†∑ÁöÑÊñπÂºèÔºåÊàë‰ª¨ÂèØ‰ª•ËÆæËÆ°‰ªªÂä°Êù•ÈÅµÂæ™Ëøô‰∫õÊ≠•È™§ÔºåÊàë‰ª¨Â∞ÜÈÄöËøá‰ª£Á†ÅËÆ®ËÆ∫ÂÆÉ‰ª¨ÊòØÂ¶Ç‰ΩïËÆæËÆ°ÁöÑ„ÄÇ\n\n## ‰ªÄ‰πàÊòØ CrewAIÔºü\n\nCrewAI ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑ Python Ê°ÜÊû∂ÔºåÁî®‰∫éÂçèË∞ÉËßíËâ≤ÊâÆÊºîÁöÑËá™‰∏ª AI ‰ª£ÁêÜÔºåÂÖ∑Êúâ Crew„ÄÅTask„ÄÅAgent„ÄÅProcess Á≠âÊñπÊ≥ïÔºåÂπ∂ÊîØÊåÅÂ§öÁßç LLMÔºåÂåÖÊã¨Êú¨Âú∞Ê®°Âûã„ÄÇ\n\nÂ¶ÇÊûúÊàë‰ª¨ÁúãÁúãËØ•Ê°ÜÊû∂Êèê‰æõÁöÑ‰∏ªË¶Å‰ºòÂäøÔºö\n\n* Âü∫‰∫éËßíËâ≤ÁöÑ‰ª£ÁêÜËÆæËÆ°„ÄÇ\n* Ëá™‰∏ªÁöÑ‰ª£ÁêÜÈó¥ÂßîÊ¥æ„ÄÇ\n* ÁÅµÊ¥ªÁöÑ‰ªªÂä°ÁÆ°ÁêÜ„ÄÇ\n* Âü∫‰∫éÊµÅÁ®ãÁöÑÊâßË°å„ÄÇ\n* ËæìÂá∫‰øùÂ≠ò‰∏∫ .markdown Êñá‰ª∂Á≠âÊ†ºÂºè„ÄÇ\n* ‰∏éÂºÄÊ∫êÂíå‰∏ìÊúâÊ®°ÂûãÔºàÂ¶Ç OpenAIÔºâÂÖºÂÆπ„ÄÇ\n\n## ÊûÑÂª∫Â§öÊô∫ËÉΩ‰Ωì\n\n‰ªÖ‰ªÖÈÄöËøáÊèèËø∞ÊÄßÁöÑËß£ÈáäÂèØËÉΩ‰∏çË∂≥‰ª•ÂÆåÂÖ®ÁêÜËß£‰∏Ä‰∏™Ê¶ÇÂøµÔºåÂõ†Ê≠§ËÆ©Êàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™Â∞èÂûãÁöÑËÆ∫ÊñáÂÜô‰ΩúÈ°πÁõÆÔºå‰ª•Êõ¥Â•ΩÂú∞ÊéåÊè°Â§öÊô∫ËÉΩ‰ΩìÊñπÊ≥ï„ÄÇÂú®Ëøô‰∏™È°πÁõÆ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÁªìÂêà LangChain Âíå CrewAI Ê°ÜÊû∂„ÄÇË¶ÅËøêË°åËØ•È°πÁõÆÔºåÊÇ®ÈúÄË¶Å‰∏Ä‰∏™ OpenAI API ÂØÜÈí•ÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáËÆøÈóÆ [https://proxy.rifx.online/https://platform.openai.com/signup](https://proxy.rifx.online/https://platform.openai.com/signup) Êù•Ëé∑Âèñ„ÄÇ\n\nÊàë‰ª¨È°πÁõÆÁöÑÁªìÊûÑÁî±Âá†‰∏™‰∏çÂêåÁöÑ Python ËÑöÊú¨ÁªÑÊàêÔºö\n\n* `crew.py`ÔºåÂú®ËøôÈáåÊàë‰ª¨ÂÆö‰πâÊàë‰ª¨ÁöÑÊô∫ËÉΩ‰ΩìÂèäÂÖ∂‰ªªÂä°„ÄÇ\n* `graph.py`ÔºåÊûÑÂª∫ LangGraph ÁªìÊûÑ„ÄÇ\n* `extra_tools.py`ÔºåÂåÖÂê´Êàë‰ª¨ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑„ÄÇ\n* `pdf_writer.py`ÔºåË¥üË¥£Â∞ÜËÆ∫ÊñáËΩ¨Êç¢‰∏∫ PDF„ÄÇ\n* `app.py`Ôºå‰∏∫Êàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫èÊèê‰æõ Streamlit ÁïåÈù¢„ÄÇ\n\n```python\n## È°πÁõÆÁªìÊûÑ\nAutonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer\n‚îú‚îÄ‚îÄ app.py              # ‰∏ªË¶ÅÁöÑ streamlit Â∫îÁî®Á®ãÂ∫è\n‚îú‚îÄ‚îÄ crew.py             # CrewAI Êô∫ËÉΩ‰ΩìÂíå‰ªªÂä°Â§ÑÁêÜ\n‚îú‚îÄ‚îÄ extra_tools.py      # Êô∫ËÉΩ‰ΩìÂ∑•ÂÖ∑ÁöÑÂäüËÉΩ\n‚îú‚îÄ‚îÄ graph.py            # LangGraph ÂíåÈ°πÁõÆÂ∑•‰ΩúÊµÅÁ®ã\n‚îú‚îÄ‚îÄ pdf_writer.py       # Â§ÑÁêÜ PDF ËæìÂá∫ÁîüÊàê\n‚îú‚îÄ‚îÄ requirements.txt    # ÊâÄÈúÄÂ∫ìÂàóË°®\n‚îú‚îÄ‚îÄ media\n‚îÇ   ‚îî‚îÄ‚îÄ cover.jpg       # È°πÁõÆÂ∞ÅÈù¢ÂõæÂÉè\n‚îî‚îÄ‚îÄ README.md        \n```\n\nËØ•È°πÁõÆÊâÄÈúÄÁöÑÂ∫ìÂàóÂú® `requirements.txt` Êñá‰ª∂‰∏≠„ÄÇÊ≠§Â§ñÔºåËØ∑Á°Æ‰øùÊÇ®Â∑≤ÂÆâË£Ö Python 3\\.12 ÊàñÊõ¥È´òÁâàÊú¨„ÄÇÂú®ËøêË°åÈ°πÁõÆ‰πãÂâçÔºåËØ∑‰∏çË¶ÅÂøòËÆ∞ÂÆâË£Ö‰æùËµñÈ°π„ÄÇÊàë‰ª¨‰ΩøÁî®ÁöÑÂ∫ìÂåÖÊã¨Ôºö\n\n```python\nlangchain-core\nlangchain-openai\nlanggraph\nstreamlit\nwikipedia\nreportlab\ncrewai[tools]\npysqlite3-binary\nbs4\n```\n\n### Â∑•‰ΩúÊµÅÁ®ã\n\nÂú®Êàë‰ª¨ÁöÑËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰∏∫‰ª£ÁêÜÂàÜÈÖçÂêÑÁßçËßíËâ≤„ÄÇ‰æãÂ¶ÇÔºåÂΩì‰∏Ä‰∏™‰ª£ÁêÜÁ≠âÂæÖÂè¶‰∏Ä‰∏™‰ª£ÁêÜÂÆåÊàêÂÖ∂Âú®‰∫íËÅîÁΩë‰∏äÁ†îÁ©∂ÁöÑ‰ªªÂä°Êó∂ÔºåÂè¶‰∏Ä‰∏™‰ª£ÁêÜÂ∞ÜÁã¨Á´ãËøõË°åÁª¥Âü∫ÁôæÁßëÁöÑÁ†îÁ©∂„ÄÇ‰∏ÄÊó¶‰∏§‰∏™‰ª£ÁêÜÈÉΩÂÆåÊàê‰∫Ü‰ªñ‰ª¨ÁöÑ‰ªªÂä°ÔºåÁ≠âÂæÖ‰ø°ÊÅØÁöÑ‰ª£ÁêÜÂ∞ÜÁªßÁª≠ËøõË°åÂÜô‰ΩúÔºåËøôÊòØ‰ªñ‰ª¨Ë¢´ÂàÜÈÖçÁöÑ‰ªªÂä°„ÄÇ\n\nÂ¶ÇÊûúÊàë‰ª¨Ë¶ÅÂ∞ÜÂÖ∂ÂèØËßÜÂåñÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Emb37H_8OAKp1s1ChLLVQg.png)\n\n* Áî®Êà∑Êü•ËØ¢ÊúÄÂàùÂèëÈÄÅÂà∞Ë∑ØÁî±Âô®„ÄÇ\n* Ë∑ØÁî±Âô®ËØªÂèñÊü•ËØ¢Âπ∂Á°ÆÂÆöÁî®Êà∑ÊòØÊÉ≥ÂÜô‰∏ÄÁØáÊñ∞ÊñáÁ´†„ÄÅÁºñËæë‰πãÂâçÁöÑÊñáÁ´†ÔºåËøòÊòØ‰ªÖ‰ªÖ‰º†Ëææ‰∏Ä‰∏™ËÆ®ËÆ∫‰∏ªÈ¢ò„ÄÇÂ¶ÇÊûúÁî®Êà∑Â∏åÊúõÂÜô‰∏ÄÁØáÊñ∞ÊñáÁ´†ÔºåËØ∑Ê±ÇÂ∞ÜËΩ¨ÂèëÁªôÂ∞èÁªÑ„ÄÇ\n* ÂèëÈÄÅÂà∞Â∞èÁªÑÁöÑËØ∑Ê±ÇÈ¶ñÂÖàÂèëÈÄÅÁªôÁ†îÁ©∂‰ª£ÁêÜ„ÄÇ\n* Á†îÁ©∂‰ª£ÁêÜ‰ΩøÁî®ÂàÜÈÖçÁªô‰ªñÁöÑÂ∑•ÂÖ∑ÊêúÁ¥¢‰∏éÁî®Êà∑ÊÉ≥Ë¶ÅÂÜôÁöÑ‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑ‰∫íËÅîÁΩëËµÑÊ∫ê„ÄÇ\n* ‰∏ÄÊó¶ËµÑÊ∫êÊî∂ÈõÜËøáÁ®ãÂÆåÊàêÔºåÊî∂ÈõÜÂà∞ÁöÑ‰ø°ÊÅØÂ∞ÜËΩ¨ÂèëÁªôÂÜô‰Ωú‰ª£ÁêÜ„ÄÇ\n* ÂΩìÂÜô‰Ωú‰ª£ÁêÜËµ∑ËçâÊñáÁ´†Êó∂ÔºåÁºñËæë‰ª£ÁêÜËøõË°åÊúÄÁªàË∞ÉÊï¥ÔºåÁ∫†Ê≠£ËØ≠Ê≥ïÈîôËØØÔºåÂπ∂Â∞ÜËçâÁ®ø‰Ωú‰∏∫JSONÊñá‰ª∂ËøîÂõûÁªôLangGraph„ÄÇ\n* JSONÊñá‰ª∂Â∞ÜÂèëÈÄÅÂà∞Â∞ÜÂú®ÊúÄÁªàËäÇÁÇπÂàõÂª∫Êàë‰ª¨ÊñáÁ´†ÁöÑPDFÊñá‰ª∂ÁöÑÂäüËÉΩ„ÄÇ\n\n### ÊûÑÂª∫ LangGraph\n\nÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅÂª∫Á´ãÊàë‰ª¨Êû∂ÊûÑÁöÑÊ°ÜÊû∂„ÄÇ‰∏ÄÊó¶Êàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Â∑•‰ΩúÊµÅÁ®ãÔºå‰ΩøÊàë‰ª¨ËÉΩÂ§üÂú®ÈúÄË¶ÅÊó∂‰∏éÊàë‰ª¨ÁöÑ‰ª£ÁêÜËøõË°åËÅîÁ≥ªÔºåÂâ©‰∏ãÁöÑÂ∞±ÊòØÂÜ≥ÂÆöÂú®Â∑•‰ΩúÊµÅÁ®ãÁöÑÂì™‰∫õÈò∂ÊÆµÊàë‰ª¨Â∞ÜÂêëÊàë‰ª¨ÁöÑ‰ª£ÁêÜÂèëÈÄÅËØ∑Ê±Ç„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨Â∞ÜÈ¶ñÂÖà‰ΩøÁî® LangChain ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iHQzJymxAstrW40THoRxwA.png)\n\n```python\n#LangGraph workflow\n\nbuilder = StateGraph(GraphState)\n\nbuilder.add_node(\"answer\", self.answer)\nbuilder.add_node(\"write_essay\", self.write_essay)\nbuilder.add_node(\"edit_essay\", self.edit_essay)\n\n\nbuilder.set_conditional_entry_point(self.router_query,\n                              {\"write_essay\": \"write_essay\",\n                                        \"answer\": \"answer\",\n                                        \"edit_essay\": \"edit_essay\"})\nbuilder.add_edge(\"write_essay\", END)\nbuilder.add_edge(\"edit_essay\", END)\nbuilder.add_edge(\"answer\", END)\n\nself.graph = builder.compile()\n```\n\n**Ë∑ØÁî±ËäÇÁÇπ**ÔºöÊ≠£Â¶ÇÊàë‰ª¨Âú®Â∑•‰ΩúÊµÅÁ®ãÊèèËø∞‰∏≠ÊèêÂà∞ÁöÑÔºåÊàë‰ª¨ÁöÑË∑ØÁî±Âô®Ê†πÊçÆ‰º†ÂÖ•ËØ∑Ê±ÇÂ∞Ü‰ªªÂä°ÂàÜÈÖçÁªôÂêÑ‰∏™ËäÇÁÇπ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶ÅÂàõÂª∫‰∏Ä‰∏™ÊúâÊïàÁöÑÊèêÁ§∫ÔºåÊ∂µÁõñÁî®Êà∑Êèê‰æõÁöÑ‰∏ªÈ¢òÂπ∂ÁªìÂêàËøáÂéªÁöÑÂØπËØù„ÄÇÊØïÁ´üÔºåÊàë‰ª¨Ê≠£Âú®ÂºÄÂèë‰∏Ä‰∏™Â§ö‰ª£ÁêÜÁöÑ‰ΩúÊñáÂÜô‰ΩúËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂÆÉÂèØ‰ª•ËÆ∞‰ΩèÂπ∂ÂõûÂøÜ‰πãÂâçÁöÑËÆ®ËÆ∫„ÄÇ\n\nËÆ©Êàë‰ª¨Ëµ∑Ëçâ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊèêÁ§∫ÂíåÁõ∏Â∫îÁöÑËäÇÁÇπÊù•Âà©Áî®Ëøô‰∏™ÊèêÁ§∫„ÄÇÂú®ÊèêÁ§∫‰∏≠ÔºåÊàë‰ª¨Â∫îËØ•‰ΩøÁî® Pydantic Â∫ìÂÆö‰πâ‰∏Ä‰∏™ `BaseModel`Ôºå‰ª•Á°Æ‰øùÊàë‰ª¨ÁöÑË∑ØÁî±Âô®ÈÄâÊã©‰∏âÁßçÊΩúÂú®ÂìçÂ∫îÁ≠ñÁï•‰∏≠ÁöÑ‰∏ÄÁßç„ÄÇËøô‰∫õÁ≠ñÁï•Â∞ÜÊåáÂØºËÅäÂ§©Êú∫Âô®‰∫∫ÊúâÊïàÂú∞Âà∂ÂÆöÂÖ∂ÂìçÂ∫î„ÄÇ\n\nÂú®ËäÇÁÇπ‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî® Langchain ÁöÑ `PromptTemplate` ÊñπÊ≥ïÂÆûÁé∞Ëøô‰∏™ÊèêÁ§∫„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨Â∞ÜË∞ÉÁî® LLMÔºàÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºâÔºåÂ∞ÜÁî®Êà∑Êü•ËØ¢ÂíåÂØπËØùÂéÜÂè≤‰∏ÄËµ∑‰º†ÂÖ•Ôºå‰ª•Á°Æ‰øùÂìçÂ∫îÂú®‰∏ä‰∏ãÊñá‰∏äÁõ∏ÂÖ≥Âπ∂Á¨¶ÂêàÁî®Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ\n\n1. **ÂÆö‰πâ Pydantic Ê®°Âûã**ÔºöÂàõÂª∫‰∏Ä‰∏™Ê®°ÂûãÔºåÊåáÂÆöÊâÄÈúÄÁöÑÂìçÂ∫îÁ≠ñÁï•„ÄÇ\n2. **ÊûÑÂª∫ÊèêÁ§∫**ÔºöÁºñÂÜô‰∏Ä‰∏™Ê∏ÖÊô∞Ê¶ÇËø∞‰∏âÁßçÁ≠ñÁï•ÁöÑÊèêÁ§∫„ÄÇ\n3. **ËÆæÁΩÆËäÇÁÇπ**Ôºö‰ΩøÁî® Langchain ÁöÑ `PromptTemplate` Âä®ÊÄÅÊ†ºÂºèÂåñÊèêÁ§∫„ÄÇ\n4. **Ë∞ÉÁî® LLM**Ôºö‰ΩøÁî®Ê†ºÂºèÂåñÁöÑÊèêÁ§∫„ÄÅÁî®Êà∑Êü•ËØ¢ÂíåÂØπËØùÂéÜÂè≤Ë∞ÉÁî® LLM„ÄÇ\n\nÈÄöËøáÈÅµÂæ™Ëøô‰∫õÊ≠•È™§ÔºåÊàë‰ª¨ÂèØ‰ª•Á°Æ‰øùËÅäÂ§©Êú∫Âô®‰∫∫ÂáÜÁ°ÆÂìçÂ∫îÂπ∂‰øùÊåÅ‰πãÂâç‰∫íÂä®ÁöÑ‰∏ä‰∏ãÊñá„ÄÇ\n\n```python\n#Router Prompt and Router Node\nclass RouteQuery(BaseModel):\n    \"\"\"Â∞ÜÁî®Êà∑Êü•ËØ¢Ë∑ØÁî±Âà∞Áõ¥Êé•ÂõûÁ≠îÊàñÁ†îÁ©∂„ÄÇ\"\"\"\n\n    way: Literal[\"edit_essay\",\"write_essay\", \"answer\"] = Field(\n        ...,\n        description=\"Ê†πÊçÆÁî®Êà∑ÈóÆÈ¢òÈÄâÊã©Â∞ÜÂÖ∂Ë∑ØÁî±Âà∞ write_essay„ÄÅedit_essay Êàñ answer\",\n    )\n\nself.router_prompt = \n    \"\"\"\n    ‰Ω†ÊòØ‰∏Ä‰∏™Ë∑ØÁî±Âô®Ôºå‰Ω†ÁöÑËÅåË¥£ÊòØÂ∞ÜÁî®Êà∑ÂºïÂØºÂà∞Ê≠£Á°ÆÁöÑ‰∏ìÂÆ∂„ÄÇ\n    ÂßãÁªàÊ£ÄÊü•ÂØπËØùÂéÜÂè≤ÔºåÂπ∂Ê†πÊçÆÂÖ∂ËÄÉËôë‰Ω†ÁöÑË°åÂä®„ÄÇ\n    Â¶ÇÊûú‰∏ªÈ¢òÊòØÂÖ≥‰∫éËÆ∞ÂøÜÊàñÊó•Â∏∏Ë∞àËØùÔºåÂ∞ÜÁî®Êà∑ÂºïÂØºÂà∞ÂõûÁ≠î‰∏ìÂÆ∂„ÄÇ\n    Â¶ÇÊûú‰∏ªÈ¢ò‰ª•‚Äú‰Ω†ËÉΩÂÜô...‚ÄùÂºÄÂ§¥ÔºåÊàñËÄÖÁî®Êà∑ËØ∑Ê±Ç‰Ω†ÂÜô‰∏ÄÁØáÊñáÁ´†ÊàñËÆ∫ÊñáÔºåÂ∞ÜÁî®Êà∑ÂºïÂØºÂà∞ÂÜô‰Ωú‰∏ìÂÆ∂„ÄÇ\n    Â¶ÇÊûú‰∏ªÈ¢òÊòØÁî®Êà∑ÊÉ≥Ë¶ÅÁºñËæëËÆ∫Êñá‰∏≠ÁöÑ‰ªª‰ΩïÂÜÖÂÆπÔºåÂ∞ÜÁî®Êà∑ÂºïÂØºÂà∞ÁºñËæë‰∏ìÂÆ∂„ÄÇ\n  \n    \\nÂØπËØùÂéÜÂè≤: {memory}\n    \\n‰∏ªÈ¢ò: {topic}\n    \"\"\"\n\ndef router_query(self, state: GraphState):\n    print(\"**ROUTER**\")\n    prompt = PromptTemplate.from_template(self.router_prompt)\n    memory = self.memory.load_memory_variables({})\n\n    router_query = self.model.with_structured_output(RouteQuery)\n    chain = prompt | router_query\n    result:  RouteQuery = chain.invoke({\"topic\": state[\"topic\"],\n                                       \"memory\": memory})\n\n    print(\"Router Result: \", result.way)\n    return result.way\n```\n\n**ÁÆÄÂçïÂõûÁ≠îËäÇÁÇπ**ÔºöÂú®Â∞ÜÊàë‰ª¨ÁöÑË∑ØÁî±Âô®‰Ωú‰∏∫ÂºÄÂßãÈÉ®ÂàÜÁöÑËäÇÁÇπÂêéÔºå‰∏ã‰∏ÄÊ≠•ÊòØÂàõÂª∫ÂÖ∂‰ªñ‰∏â‰∏™ËäÇÁÇπÔºö`write_essay`„ÄÅ`edit_essay` Âíå `answer`„ÄÇ‰∏∫‰∫ÜÈááÂèñÁÆÄÂçïÁöÑÊñπÂºèÔºåÊàë‰ª¨ÈúÄË¶ÅÁºñÁ®ãÊàë‰ª¨ÁöÑ `answer` ËäÇÁÇπÔºå‰ª•‰æøÂú®Áî®Êà∑ÂèëÈÄÅÈöèÊÑèÊ∂àÊÅØÊàñÂèÇ‰∏éÊúâÂÖ≥ËÆ∫ÊñáÁöÑÂØπËØùÊó∂Áõ¥Êé•‰ΩøÁî®ÂÖ∂ËÆ∞ÂøÜÁîüÊàêÂìçÂ∫î„ÄÇ\n\n‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂøÖÈ°ªÈ¶ñÂÖà‰∏∫Ê≠§‰ªªÂä°ÁºñÂÜô‰∏Ä‰∏™ÂêàÈÄÇÁöÑÊèêÁ§∫„ÄÇÁÑ∂ÂêéÔºåÂà©Áî®Ëøô‰∏™ÊèêÁ§∫ÔºåÊàë‰ª¨Â∞ÜËÆæËÆ°‰∏Ä‰∏™ÁÆÄÂçïÁöÑËäÇÁÇπ„ÄÇËÆ©Êàë‰ª¨ÁªßÁª≠Ëøô‰∏™ËÆæËÆ°„ÄÇ\n\n```python\n#Simple Answer Prompt and Node\n\nself.simple_answer_prompt = \n      \"\"\"\n      ‰Ω†ÊòØ‰∏Ä‰∏™‰∏ìÂÆ∂Ôºå‰Ω†Ê≠£Âú®‰∏∫Áî®Êà∑ÁöÑÈóÆÈ¢òÊèê‰æõÁÆÄÂçïÁöÑ \n      Á≠îÊ°à„ÄÇ\n    \n      \\nÂØπËØùÂéÜÂè≤: {memory}\n      \\n‰∏ªÈ¢ò: {topic}\n      \"\"\"\ndef answer(self, state: GraphState):\n    print(\"**ANSWER**\")\n    prompt = PromptTemplate.from_template(self.simple_answer_prompt)\n    memory = self.memory.load_memory_variables({})\n    chain = prompt | self.model | StrOutputParser()\n    result = chain.invoke({\"topic\": state[\"topic\"], \"memory\": memory})\n\n    self.memory.save_context(inputs={\"input\": state[\"topic\"]}, outputs={\"output\": result})\n    return {\"response\": result}\n```\n\n**ÂÜô‰ΩúËäÇÁÇπ**ÔºöÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÈúÄË¶ÅËÆæËÆ° `writing_essay` ËäÇÁÇπ„ÄÇËØ•ËäÇÁÇπÁöÑÁõÆÁöÑÊòØ‰ΩøÁî® CrewAI ÁöÑ `kickoff` ÊñπÊ≥ïÂ∞ÜÁî®Êà∑Êî∂Âà∞ÁöÑÊü•ËØ¢ËΩ¨ÂèëÁªôÊàë‰ª¨ÁöÑ‰ª£ÁêÜÔºåÁÑ∂ÂêéÂ∞Ü‰ª£ÁêÜËøîÂõûÁöÑ JSON Êñá‰ª∂ËΩ¨Êç¢‰∏∫ PDF„ÄÇËá™ÁÑ∂ÔºåÊàë‰ª¨‰∏çÈúÄË¶Å‰∏∫Ëøô‰∏™ËäÇÁÇπÁºñÂÜôÊèêÁ§∫ÔºåÂõ†‰∏∫ÊèêÁ§∫Â∞ÜÂú®‰ª£ÁêÜÂàõÂª∫Èò∂ÊÆµÂÆö‰πâ„ÄÇËøô‰∏™ËäÇÁÇπÂ∞Ü‰ªÖÁî®‰∫éË∞ÉÁî®‰ª£ÁêÜÂíåÂà©Áî®ËøîÂõûÁöÑÂÄº„ÄÇ\n\n1. **Ë∞ÉÁî®‰ª£ÁêÜ**Ôºö‰ΩøÁî® CrewAI ÁöÑ `kickoff` ÊñπÊ≥ïÂ∞ÜÁî®Êà∑ÁöÑÊü•ËØ¢ÂèëÈÄÅÁªô‰ª£ÁêÜ„ÄÇ\n2. **Â§ÑÁêÜËøîÂõûÁöÑ JSON**ÔºöÂ§ÑÁêÜ‰ªé‰ª£ÁêÜÊî∂Âà∞ÁöÑ JSON ÂìçÂ∫î„ÄÇ\n3. **ËΩ¨Êç¢‰∏∫ PDF**ÔºöÂ∞Ü JSON ‰∏≠ÁöÑÁõ∏ÂÖ≥Êï∞ÊçÆËΩ¨Êç¢‰∏∫ PDF Ê†ºÂºè„ÄÇ\n\n```python\n#Write Essay Node\ndef write_essay(self, state: GraphState):\n    print(\"**ESSAY COMPLETION**\")\n\n    self.essay = self.crew.kickoff({\"topic\": state[\"topic\"]})\n\n    self.memory.save_context(inputs={\"input\": state[\"topic\"]},\n                           outputs={\"output\": str(self.essay)})\n\n    pdf_name = generate_pdf(self.essay)\n    return {\"response\": \"ËøôÊòØ‰Ω†ÁöÑËÆ∫ÊñáÔºÅ\",  \"pdf_name\": f\"{pdf_name}\"}\n```\n\n**ÁºñËæëËÆ∫ÊñáËäÇÁÇπ**ÔºöËÆ©Êàë‰ª¨ÁÆÄË¶ÅËÆ®ËÆ∫Êàë‰ª¨ÁöÑÊúÄÂêé‰∏Ä‰∏™ËäÇÁÇπ `edit_essay`„ÄÇ‰ª£Á†ÅÂèØËÉΩÁúãËµ∑Êù•ÊúâÁÇπÂÜóÈïøÔºåÂõ†‰∏∫ÊèêÁ§∫Ë¢´‰øùÁïôÂú®ËäÇÁÇπÂÜÖ„ÄÇÂ¶ÇÊûú‰Ω†ÊÑøÊÑèÔºå‰πüÂèØ‰ª•Âú®Á±ªÂÆö‰πâÊúüÈó¥ÁºñÂÜôÊèêÁ§∫Âπ∂Â∞ÜÂÖ∂ÂàÜÈÖç‰∏∫ÂèòÈáè„ÄÇ\n\nÂΩìË∑ØÁî±Âô®Ê£ÄÊµãÂà∞Áî®Êà∑ÁöÑ‰ªª‰ΩïËÆ∫Êñá‰øÆÊîπËØ∑Ê±ÇÊó∂ÔºåÂ∞ÜÊøÄÊ¥ªËØ•ËäÇÁÇπ„ÄÇÂú®Ê≠§ËäÇÁÇπ‰∏≠ÔºåÊàë‰ª¨ÈúÄË¶Å‰∏â‰∏™ÈáçË¶ÅÂÄºÔºöÂØπËØùÂéÜÂè≤„ÄÅÁî®Êà∑ËØ∑Ê±ÇÂíåÊúÄËøëÁîüÊàêÁöÑËÆ∫Êñá„ÄÇÊ≠§Â§ñÔºåÊèêÁ§∫‰∏≠Êúâ‰∏Ä‰∏™ÂèòÈáèÔºåLangchain Â∞ÜÁîüÊàêÔºåÁß∞‰∏∫ `format_instructions`„ÄÇËøô‰∏™ÂèòÈáè‰ΩøÊàë‰ª¨ËÉΩÂ§üÂêë LLM ‰º†ËææÊàë‰ª¨Â∏åÊúõ‰øùÊåÅÁºñËæëËÆ∫Êñá JSON Ê†ºÂºèÁöÑÁªìÊûÑÔºåÂπ∂‰ª•Áõ∏ÂêåÊ†ºÂºèÊé•Êî∂ÂìçÂ∫î„ÄÇ‰πãÂêéÔºåÊàë‰ª¨Â∞ÜÊääËøîÂõûÁöÑÂìçÂ∫îÂèëÈÄÅÂà∞Êàë‰ª¨ÁöÑ PDF ÁîüÊàêÂ∑•ÂÖ∑„ÄÇ\n\n1. **Ê£ÄÊµãÁºñËæëËØ∑Ê±Ç**ÔºöË∑ØÁî±Âô®ËØÜÂà´Áî®Êà∑ËØ∑Ê±ÇÊòØÂê¶‰∏∫ÁºñËæëËÆ∫Êñá„ÄÇ\n2. **Êî∂ÈõÜÂøÖË¶ÅÂÄº**ÔºöÊî∂ÈõÜÂØπËØùÂéÜÂè≤„ÄÅÁî®Êà∑ËØ∑Ê±ÇÂíåÊúÄÂêéÁîüÊàêÁöÑËÆ∫Êñá„ÄÇ\n3. **ÂàõÂª∫Âπ∂‰ΩøÁî®ÊèêÁ§∫**ÔºöÊûÑÂª∫‰∏Ä‰∏™ÂåÖÂê´ `format_instructions` ÁöÑÊèêÁ§∫„ÄÇ\n4. **ÁîüÊàêÁºñËæëÂêéÁöÑËÆ∫Êñá**ÔºöË∞ÉÁî® LLM Ëé∑ÂèñÁºñËæëÂêéÁöÑËÆ∫ÊñáÔºåÂπ∂Â∞ÜÂìçÂ∫î‰º†ÈÄíÁªô PDF ÁîüÊàêÂô®„ÄÇ\n\n```python\n#Edit Essay Node\n\ndef edit_essay(self, state: GraphState):\n    print(\"**ESSAY EDIT**\")\n    memory = self.memory.load_memory_variables({})\n\n    user_request = state[\"topic\"]\n    parser = JsonOutputParser(pydantic_object=Essay)\n    prompt = PromptTemplate(\n      template=(\"ÊåâÁÖßÁî®Êà∑ËØ∑Ê±ÇÁºñËæë JSON Êñá‰ª∂ÔºåÂπ∂ËøîÂõûÊñ∞ÁöÑ JSON Êñá‰ª∂„ÄÇ\"\n                \"\\nËØ∑Ê±Ç:{user_request} \"\n                \"\\nÂØπËØùÂéÜÂè≤: {memory}\"\n                \"\\n JSON Êñá‰ª∂: {essay}\"\n                \" \\n{format_instructions}\"),\n      input_variables=[\"memory\",\"user_request\",\"essay\"],\n      partial_variables={\"format_instructions\": parser.get_format_instructions()},\n  )\n\n    chain = prompt | self.model | parser\n\n    self.essay = chain.invoke({\"user_request\": user_request,\n                               \"memory\": memory, \n                                \"essay\": self.essay})\n\n\n    self.memory.save_context(inputs={\"input\": state[\"topic\"]},\n                             outputs={\"output\": str(self.essay)})\n    pdf_name = generate_pdf(self.essay)\n    return {\"response\": \"ËøôÊòØ‰Ω†ÁöÑÁºñËæëÂêéÁöÑËÆ∫ÊñáÔºÅ\", \n            \"essay\": self.essay, \"pdf_name\": f\"{pdf_name}\"}\n```\n\n## ÊûÑÂª∫‰ª£ÁêÜ\n\n**ÂÜÖÂÆπÁ†îÁ©∂Âëò**Ôºö‰∏∫‰∫Ü‰øùÊåÅÊàë‰ª¨ÁöÑÈ°πÁõÆÁÆÄÂçïÔºåÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏â‰∏™‰ª£ÁêÜÔºåÂÆÉ‰ª¨Â∞ÜÁõ∏‰∫íÈÄö‰ø°Âπ∂ËøõË°å‰∫íËÅîÁΩëÊêúÁ¥¢‰ª•Êí∞ÂÜôÊñáÁ´†„ÄÇËÆ©Êàë‰ª¨ËÆæËÆ°Á¨¨‰∏Ä‰∏™‰ª£ÁêÜÔºåÁ†îÁ©∂Âëò‰ª£ÁêÜ„ÄÇËØ•‰ª£ÁêÜÂ∞ÜÂØπÁª¥Âü∫ÁôæÁßëÂíåÂÖ∂‰ªñÁΩëÁ´ôËøõË°åÁΩëÈ°µÊäìÂèñÔºåÊî∂ÈõÜÂøÖË¶ÅÁöÑÊù•Ê∫êÔºåÁõ¥Âà∞ÂÆÉÁ°ÆÂÆöÂ∑≤Êî∂ÈõÜÂà∞Ë∂≥Â§üÁöÑ‰ø°ÊÅØ„ÄÇÂÆÉÂ∞ÜËé∑Âèñ‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑ‰∏ªË¶ÅÊ†áÈ¢ò„ÄÅÂâØÊ†áÈ¢òÂíåÊñáÁ´†ÔºåÂπ∂ÂáÜÂ§áÊëòË¶Å„ÄÇÈöèÂêéÔºåËøô‰∫õÊñáÊ°£Â∞ÜË¢´Â≠òÂÇ®Ôºå‰ª•‰æøÂèëÈÄÅÁªôÂÜô‰Ωú‰ª£ÁêÜ„ÄÇ\n\nÂú®ËÆæËÆ°Ëøô‰∏™‰ª£ÁêÜÊó∂ÔºåÊàë‰ª¨ÈúÄË¶ÅËÄÉËôëÂÆÉÁöÑËßíËâ≤„ÄÅËÉåÊôØÊïÖ‰∫ãÂíåÁõÆÊ†á„ÄÇÊàë‰ª¨Â∞ÜËøô‰∫õÂàÜÈÖçÁªô`Agent`Á±ª‰∏≠ÁöÑÂèÇÊï∞ÔºåÁ±ª‰ºº‰∫éÊûÑÂª∫ÊèêÁ§∫Ôºå‰ªéËÄå‰∏∫‰ª£ÁêÜÁöÑÊìç‰ΩúÂÅöÂ•ΩÂáÜÂ§á„ÄÇ\n\n```python\n#Content Researcher Agent and Task\n\nself.researcher = Agent(\n    role=\"Content Researcher\",\n\n    goal=\"Research accurate content on {topic}\",\n\n    backstory=\"You're researching content to write \n                an essay about the topic: {topic}.\"\n              \"You collect information that helps \n                the audience learn something and make informed decisions.\"\n              \"Your work is the basis for the Content Writer to \n                write an article on this topic.\",\n    verbose=True\n)\n\nself.research = Task(\n    description=(\n        \"1. Prioritize the latest trends, key players, \n            and noteworthy news on {topic}.\\n\"\n        \"2. Identify the target audience, considering their \n            interests and pain points.\\n\"\n        \"3. Research a detailed content outline including \n            an introduction, key points, and a conclusion.\\n\"\n        \"4. Include SEO keywords and relevant data or sources.\"\n    ),\n    expected_output=\"A comprehensive document with an outline, \n                    audience analysis, SEO keywords, and resources.\",\n    tools=[search_wikipedia, scrap_webpage],\n    agent=self.researcher,\n)\n```\n\nÊàë‰ª¨ÈúÄË¶ÅÂàõÂª∫‰∏§‰∏™Á±ªÔºö`Agent`Âíå`Task`„ÄÇÊØè‰∏™‰ª£ÁêÜÂèØ‰ª•Êúâ‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÂàÜÈÖçÁöÑ‰ªªÂä°„ÄÇÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•Â∞ÜÂ∑•ÂÖ∑ÂàÜÈÖçÁªô‰ª£ÁêÜÔºåÊàñËÄÖÊ∑ªÂä†ÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÂ∑•ÂÖ∑„ÄÇÈÄöËøá‰∏∫‰ªªÂä°‰∏ìÈó®Ê∑ªÂä†Â∑•ÂÖ∑ÔºåÊàë‰ª¨Á°Æ‰øùËØ•Â∑•ÂÖ∑‰ªÖÂú®ÁâπÂÆö‰ªªÂä°‰∏≠‰ΩøÁî®„ÄÇ\n\n### ÂèÇÊï∞\n\nÊàë‰ª¨ÁöÑ `Agent` Á±ªÁöÑÂèÇÊï∞Ôºö\n\n1. **ËßíËâ≤**ÔºöÂÆö‰πâ‰ª£ÁêÜÂú®Âõ¢Èòü‰∏≠ÁöÑÂäüËÉΩ„ÄÇÂÆÉÂÜ≥ÂÆö‰∫Ü‰ª£ÁêÜÊúÄÈÄÇÂêàÊâßË°åÁöÑ‰ªªÂä°Á±ªÂûãÔºåÂ∫îÁÆÄÁü≠‰∏îÂÖ∑ÊúâÊèèËø∞ÊÄß„ÄÇ\n2. **ÁõÆÊ†á**ÔºöËøôÊòØ‰ª£ÁêÜÊó®Âú®ÂÆûÁé∞ÁöÑ‰∏™‰∫∫ÁõÆÊ†á„ÄÇÂÆÉÊåáÂØº‰ª£ÁêÜÁöÑÂÜ≥Á≠ñËøáÁ®ãÔºåÂ∫îÁÆÄÁü≠‰∏îÁÆÄÂçï„ÄÇ\n3. **ËÉåÊôØÊïÖ‰∫ã**Ôºö‰∏∫‰ª£ÁêÜÁöÑËßíËâ≤ÂíåÁõÆÊ†áÊèê‰æõËÉåÊôØÔºå‰∏∞ÂØå‰∫íÂä®ÂíåÂçè‰ΩúÂä®ÊÄÅ„ÄÇÂ∫îÂ∞ΩÂèØËÉΩËØ¶ÁªÜ„ÄÇ\n4. **ËØ¶ÁªÜ**ÔºöÂ∞ÜÂÖ∂ËÆæÁΩÆ‰∏∫ `True` ÂèØÈÖçÁΩÆÂÜÖÈÉ®ËÆ∞ÂΩïÂô®ÔºåÊèê‰æõËØ¶ÁªÜÁöÑÊâßË°åÊó•ÂøóÔºåÊúâÂä©‰∫éË∞ÉËØïÂíåÁõëÊéßÊàë‰ª¨ÁöÑ‰ª£ÁêÜÊ≠£Âú®ËøõË°åÁöÑÊ¥ªÂä®„ÄÇ\n\nÊàë‰ª¨ÁöÑ `Task` Á±ªÁöÑÂèÇÊï∞Ôºö\n\n1. **ÊèèËø∞**ÔºöÂØπ‰ªªÂä°ÂÜÖÂÆπÁöÑÊ∏ÖÊô∞ÁÆÄÊ¥ÅÁöÑÈôàËø∞„ÄÇÂ∫îÂ∞ΩÂèØËÉΩËØ¶ÁªÜ‰ª•Á°Æ‰øùÊ∏ÖÊô∞„ÄÇ\n2. **È¢ÑÊúüËæìÂá∫**ÔºöÂØπ‰ªªÂä°ÂÆåÊàêÂêéÁªìÊûúÁöÑËØ¶ÁªÜÊèèËø∞ÔºåÊúâÂä©‰∫éËÆæÂÆöÂØπÁªìÊûúÁöÑÊòéÁ°ÆÊúüÊúõ„ÄÇ\n3. **Â∑•ÂÖ∑**Ôºö‰ª£ÁêÜÂèØ‰ª•Âà©Áî®Êù•ÊâßË°å‰ªªÂä°ÁöÑÂäüËÉΩÊàñËÉΩÂäõ„ÄÇÂú®ËøôÈáåÔºåÊÇ®ÂèØ‰ª•Ê†πÊçÆÈúÄË¶Å‰ΩøÁî® LangChain„ÄÅCrewAI ÊàñËá™ÂÆö‰πâÂ∑•ÂÖ∑„ÄÇ\n4. **‰ª£ÁêÜ**ÔºöË¥üË¥£ËØ•‰ªªÂä°ÁöÑ‰ª£ÁêÜÔºåÂèØ‰ª•Áõ¥Êé•ÂàÜÈÖçÊàñÈÄöËøáÂõ¢ÈòüÁöÑÊµÅÁ®ãÂàÜÈÖç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ocQ9ZUZwFtGx7a7pPrTbuQ.png)\n\n**ÂÜÖÂÆπÊí∞ÂÜôËÄÖ**Ôºö‰∏ÄÊó¶Êàë‰ª¨ÁöÑÁ†îÁ©∂‰ª£ÁêÜÈÄöËøáÂ§öÊ¨°Ëø≠‰ª£Êî∂ÈõÜ‰∫ÜÂøÖË¶ÅÁöÑ‰ø°ÊÅØÔºåÂÆÉÂ∞ÜÊääÊî∂ÈõÜÂà∞ÁöÑÊï∞ÊçÆÂ≠òÂÇ®Âú®ÂÜÖÂ≠ò‰∏≠ÔºåËÆ§‰∏∫Ëá™Â∑±Â∑≤Ëé∑ÂæóË∂≥Â§üÁöÑÁü•ËØÜÔºåÂπ∂Â∞Ü‰ªªÂä°‰º†ÈÄíÁªôÊàë‰ª¨ÁöÑ‰∏ã‰∏Ä‰∏™‰ª£ÁêÜÔºåÂÜÖÂÆπÊí∞ÂÜôËÄÖ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HD1Bm7twxsUIVGPiqEhHAg.png)\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ÂÆö‰πâÊàë‰ª¨ÁöÑÂÜÖÂÆπÊí∞ÂÜôËÄÖ‰ª£ÁêÜÂèäÂÖ∂ËßíËâ≤„ÄÇËØ•‰ª£ÁêÜ‰∏çÈúÄË¶Å‰ΩøÁî®‰ªª‰ΩïÂ∑•ÂÖ∑ÔºåÂõ†Ê≠§Âè™ÈúÄËØ¶ÁªÜËØ¥ÊòéËÉåÊôØÊïÖ‰∫ãÂíåÊèèËø∞ÔºåÁ±ª‰ºº‰∫éÁ†îÁ©∂‰ª£ÁêÜ„ÄÇÂú®ËÉåÊôØÊïÖ‰∫ã‰∏≠ÔºåÊàë‰ª¨ÂøÖÈ°ªËÆ∞ÂæóÊåáÂÆöÂì™‰∏™‰ª£ÁêÜÊèê‰æõ‰∫Ü‰ø°ÊÅØÊù•Ê∫ê„ÄÇ\n\n### ÂèÇÊï∞\n\n1. **ËßíËâ≤**ÔºöÈ°πÁõÆ‰∏≠ÂÜÖÂÆπÁºñÂÜô‰ª£ÁêÜÁöÑÂäüËÉΩ„ÄÇËøôÂ∫îÁÆÄÊ¥ÅÂú∞ÊçïÊçâ‰ª£ÁêÜÁöÑ‰ΩúÁî®„ÄÇ\n2. **ÁõÆÊ†á**ÔºöÂÜÖÂÆπÁºñÂÜôËÄÖÊó®Âú®ÂÆûÁé∞ÁöÑÂÖ∑‰ΩìÁõÆÊ†áÔºå‰æãÂ¶ÇÊ†πÊçÆÊî∂ÈõÜÁöÑ‰ø°ÊÅØÊí∞ÂÜô‰∏ÄÁØáÁªìÊûÑËâØÂ•ΩÁöÑÊñáÁ´†„ÄÇ\n3. **ËÉåÊôØÊïÖ‰∫ã**Ôºö‰∏∫ÂÜÖÂÆπÁºñÂÜôËÄÖÁöÑËßíËâ≤Êèê‰æõ‰∏ä‰∏ãÊñáÔºåÂåÖÊã¨ÂÖ≥‰∫éÁ†îÁ©∂ËÄÖ‰ª£ÁêÜÂèäÂÖ∂Êèê‰æõÁöÑ‰ø°ÊÅØÁöÑËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇÁ≤æÂøÉÂà∂‰ΩúÁöÑËÉåÊôØÊïÖ‰∫ãÂèØ‰ª•Â¢ûÂº∫ÂèôËø∞ÂíåÂçè‰ΩúÂä®ÊÄÅ„ÄÇ\n4. **ÊèèËø∞**ÔºöÂØπÂÜÖÂÆπÁºñÂÜôËÄÖÊâÄÂÅöÂ∑•‰ΩúÁöÑÊ∏ÖÊô∞ÁÆÄÊ¥ÅÁöÑÈôàËø∞ÔºåÈáçÁÇπÂÖ≥Ê≥®ÂÖ∂ËÅåË¥£Âíå‰ªªÂä°„ÄÇ\n5. **È¢ÑÊúüËæìÂá∫**ÔºöÂØπ‰ªªÂä°ÂÆåÊàêÁöÑËØ¶ÁªÜÊèèËø∞ÔºåÂ∏ÆÂä©ËÆæÂÆöÂØπÁªìÊûúÁöÑÊòéÁ°ÆÊúüÊúõ„ÄÇ\n6. **‰∏ä‰∏ãÊñá**ÔºöÂú®ÊâßË°å‰ªªÂä°‰πãÂâçÔºåÊàë‰ª¨ÊåáÂÆöË¶ÅÁ≠âÂæÖÂÆåÊàêÁöÑ‰ªªÂä°ÔºåÂπ∂‰ªéËØ•‰ªªÂä°ËæìÂá∫‰∏≠Ëé∑ÂèñÂøÖË¶ÅÁöÑ‰ø°ÊÅØÔºåÁªìÂêà‰∏ä‰∏ãÊñáÂèÇÊï∞„ÄÇ\n\n```python\n#Content Writer Agent and Task\n\nself.writer = Agent(\n  role=\"Content Writer\",\n\n  goal=\"Êí∞ÂÜôÊúâÂÖ≥Êèê‰æõ‰∏ªÈ¢òÁöÑÊ∑±Âàª‰∏î‰∫ãÂÆûÂáÜÁ°ÆÁöÑ \"\n       \"ËßÇÁÇπÊñáÁ´†\",\n\n  backstory=\"ÊÇ®Ê≠£Âú®Êí∞ÂÜô‰∏ÄÁØáÂÖ≥‰∫éÊèê‰æõ‰∏ªÈ¢òÁöÑÊñ∞ËßÇÁÇπÊñáÁ´†„ÄÇ\"\n            \"ÊÇ®Âü∫‰∫éÂÜÖÂÆπÁ†îÁ©∂ÂëòÁöÑÂ∑•‰ΩúÔºåËØ•Á†îÁ©∂ÂëòÊèê‰æõ‰∫Ü‰∏ªÈ¢òÁöÑÊèêÁ∫≤ÂíåÁõ∏ÂÖ≥ËÉåÊôØ‰ø°ÊÅØ„ÄÇ\"\n            \"ÊÇ®ÈÅµÂæ™ÂÜÖÂÆπÁ†îÁ©∂ÂëòÊèê‰æõÁöÑÊèêÁ∫≤ÁöÑ‰∏ªË¶ÅÁõÆÊ†áÂíåÊñπÂêë„ÄÇ\"\n            \"ÊÇ®ËøòÊèê‰æõÂÆ¢ËßÇÂíåÂÖ¨Ê≠£ÁöÑËßÅËß£ÔºåÂπ∂Áî®ÂÜÖÂÆπÁ†îÁ©∂ÂëòÊèê‰æõÁöÑ‰ø°ÊÅØËøõË°åÊîØÊåÅ„ÄÇ\",\n  verbose=True,\n)\n\nself.write = Task(\n  description=(\n      \"1. ‰ΩøÁî®ÂÜÖÂÆπÊí∞ÂÜô‰∏ÄÁØáÂºï‰∫∫ÂÖ•ËÉúÁöÑÊñáÁ´†„ÄÇ\\n\"\n      \"2. Ëá™ÁÑ∂Âú∞ËûçÂÖ•SEOÂÖ≥ÈîÆËØç„ÄÇ\\n\"\n      \"3. ÂêÑÈÉ®ÂàÜ/ÂâØÊ†áÈ¢ò‰ª•Âºï‰∫∫ÂÖ•ËÉúÁöÑÊñπÂºèÂëΩÂêç„ÄÇ\\n\"\n      \"4. Á°Æ‰øùÊñáÁ´†ÁªìÊûÑÂêàÁêÜÔºåÂåÖÂê´Âºï‰∫∫ÂÖ•ËÉúÁöÑÂºïË®Ä„ÄÅÊ∑±ÂàªÁöÑ‰∏ª‰ΩìÂíåÊÄªÁªìÊÄßÁöÑÁªìËÆ∫„ÄÇ\\n\"\n      \"5. Ê†°ÂØπËØ≠Ê≥ïÈîôËØØÂπ∂Á°Æ‰øù‰∏éÂìÅÁâåÂ£∞Èü≥‰∏ÄËá¥„ÄÇ\\n\"\n      \"6. ÈÄâÊã©ÂêàÈÄÇÁöÑÊ†áÈ¢ò„ÄÇ\\n\"\n  ),\n  expected_output=\"‰∏ÄÁØá‰ª•markdownÊ†ºÂºèÊí∞ÂÜôÁöÑÊñáÁ´†Ôºå\"\n                  \"ÂáÜÂ§áÂèëÂ∏ÉÔºåÊØè‰∏™ÈÉ®ÂàÜÂ∫îÊúâ2Êàñ3ÊÆµ„ÄÇ\",\n  context=[self.research],\n  agent=self.writer,\n)\n```\n\n**ÂÜÖÂÆπÁºñËæëÂô®**ÔºöÂú®ÂÆö‰πâ‰∫ÜÁºñÂÜô‰ª£ÁêÜÂêéÔºåÊàë‰ª¨Êú¨ÂèØ‰ª•ÁªìÊùüËøô‰∏™ËøáÁ®ãÔºõÁÑ∂ËÄåÔºåÂç≥‰ΩøÁºñÂÜô‰ª£ÁêÜË¥üË¥£ÂÜô‰ΩúÔºåÂÆÉ‰ªçÂèØËÉΩÂá∫Áé∞ÊãºÂÜôÈîôËØØÂíåÁ†¥ÂùèÂÜÖÂÆπËøûË¥ØÊÄßÁöÑÈîôËØØ„ÄÇ‰∏∫Èò≤Ê≠¢Ëøô‰∫õÈóÆÈ¢òÂπ∂Â∞ÜÊñáÁ´†ËæìÂá∫‰∏∫JSONÊ†ºÂºèÔºåÊàë‰ª¨Â∞ÜÂÆö‰πâ‰∏Ä‰∏™Êñ∞ÁöÑ‰ª£ÁêÜÔºöÂÜÖÂÆπÁºñËæëÂô®„ÄÇ\n\nÂú®ËØ•‰ª£ÁêÜÁöÑËÉåÊôØÊïÖ‰∫ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜËØ¥ÊòéÂÆÉË¥üË¥£ÂÆ°Êü•ÂíåÁ∫†Ê≠£‰ªéÁºñÂÜô‰ª£ÁêÜÊî∂Âà∞ÁöÑÊñáÁ´†„ÄÇÂú®‰ªªÂä°Èò∂ÊÆµÔºåÊàë‰ª¨ËøòÂ∞ÜÂÆö‰πâÊâÄÈúÄÁöÑËæìÂá∫Ê†ºÂºè„ÄÇ\n\n```python\n#Content Editor Agent and Task\nself.editor = Agent(\n    role=\"Content Editor\",\n\n    goal=\"ÁºñËæëÁªôÂÆöÁöÑÊñáÁ´†Ôºå‰ª•Á¨¶ÂêàÁªÑÁªáÁöÑÂÜô‰ΩúÈ£éÊ†º„ÄÇ\",\n\n    backstory=\"ÊÇ®ÊòØ‰∏ÄÂêçÁºñËæëÔºåÊî∂Âà∞Êù•Ëá™ÂÜÖÂÆπÁºñÂÜôËÄÖÁöÑÊñáÁ´†„ÄÇ\"\n              \"ÊÇ®ÁöÑÁõÆÊ†áÊòØÂÆ°Êü•ÊñáÁ´†Ôºå‰ª•Á°Æ‰øùÂÖ∂ÈÅµÂæ™ÊúÄ‰Ω≥ÂÆûË∑µÔºåÊèê‰æõÂπ≥Ë°°ÁöÑËßÇÁÇπ\"\n              \"Âú®Êèê‰æõÊÑèËßÅÊàñÊñ≠Ë®ÄÊó∂ÔºåÂ∞ΩÈáèÈÅøÂÖçÈáçÂ§ß‰∫âËÆÆËØùÈ¢òÊàñÊÑèËßÅ„ÄÇ\",\n    verbose=True\n)\n\nself.edit = Task(\n    description=\"Ê†°ÂØπÁªôÂÆöÊñáÁ´†ÁöÑËØ≠Ê≥ïÈîôËØØÔºåÂπ∂Á°Æ‰øù‰∏éÂìÅÁâåÂ£∞Èü≥‰∏ÄËá¥„ÄÇ\",\n\n    expected_output=\"‰∏ÄÁØá‰ª•ÊâÄÈúÄÊ†ºÂºèÊí∞ÂÜôÁöÑÊñáÁ´†Ôºå\"\n                    \"ÂáÜÂ§áÂèëÂ∏ÉÔºåÊØè‰∏™ÈÉ®ÂàÜÂ∫îÊúâ2Êàñ3ÊÆµ„ÄÇ\",\n    output_json = Essay,\n    context=[self.write],\n    agent=self.editor\n)\n```\n\nÂú®ËøôÈáåÔºåÊàë‰ª¨ÁöÑËæìÂá∫ÊòØ‰∏Ä‰∏™Âêç‰∏∫`Essay`ÁöÑÂØπË±°ÔºåÂÆÉÊòØÈÄöËøáPydanticÂ∫ì‰∏≠ÁöÑ`BaseModel`Âíå`Field`Á±ªÂàõÂª∫ÁöÑ„ÄÇÈÄöËøáÊ∑ªÂä†Êàë‰ª¨ÁöÑ‰ª£ÁêÜÂèØ‰ª•ÁêÜËß£ÁöÑËß£ÈáäÔºåÊàë‰ª¨Á°Æ‰øù‰ª£ÁêÜÂ∞ÜÊï∞ÊçÆ‰ª•PDFÊâìÂç∞ÂäüËÉΩÊâÄÊúüÊúõÁöÑÊ†ºÂºèËæìÂá∫„ÄÇ\n\n```python\n#Expected Pydantic Output\n\nclass Paragraph(TypedDict):\n    sub_header: str\n    paragraph: str\n\nclass Essay(BaseModel):\n    header: str = Field(..., description=\"ÊñáÁ´†ÁöÑÊ†áÈ¢ò\")\n    entry: str = Field(..., description=\"ÊñáÁ´†ÁöÑÂºïË®Ä\")\n    paragraphs: List[Paragraph] = Field(..., description=\"ÊñáÁ´†ÁöÑÊÆµËêΩ\")\n    conclusion: str = Field(..., description=\"ÊñáÁ´†ÁöÑÁªìËÆ∫\")\n    seo_keywords: List[str] = Field(..., description=\"ÊñáÁ´†ÁöÑSEOÂÖ≥ÈîÆËØç\")\n```\n\nÊàë‰ª¨Â∑≤ÁªèÂÆö‰πâ‰∫ÜÊàë‰ª¨ÁöÑ‰ª£ÁêÜÂèäÂÖ∂‰ªªÂä°„ÄÇÁé∞Âú®ÔºåËÆ©Êàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑ‰∏â‰∏™‰ª£ÁêÜÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨Â∫îËØ•‰ΩøÁî®CrewAIÂ∫ì‰∏≠ÁöÑ‰∏Ä‰∏™Â∞èËÄåÂÆûÁî®ÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫`Crew`„ÄÇÂú®Ê≠§ÊñπÊ≥ï‰∏≠ÔºåÊàë‰ª¨ÂàóÂá∫Â∞ÜÈ°∫Â∫èÊìç‰ΩúÁöÑ‰ª£ÁêÜÂèäÂÖ∂Â∞Ü‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑„ÄÇÂ¶ÇÊûú‰ªªÂä°ÈúÄË¶ÅÊåâÈ°∫Â∫èÊâßË°åÔºåÂ¶ÇÂú®Êàë‰ª¨ÁöÑÈ°πÁõÆ‰∏≠ÔºåÊàë‰ª¨Â∞Ü`process`ÂèÇÊï∞ËÆæÁΩÆ‰∏∫`Process.sequential`„ÄÇÊàë‰ª¨ËøòÂ∞Ü`memory`ÂèÇÊï∞ËÆæÁΩÆ‰∏∫`True`Ôºå‰ª•‰Ωø‰ª£ÁêÜËÉΩÂ§ü‰ΩøÁî®Áü≠ÊúüÂíåÈïøÊúüËÆ∞ÂøÜËøõË°åÁõ∏‰∫íÈÄö‰ø°„ÄÇ\n\n```python\n#Crew Run\n\ndef kickoff(self,*args):\n    return Crew(\n        agents=[self.researcher, self.writer, self.editor],\n        tasks=[self.research, self.write, self.edit],\n        process=Process.sequential,\n        verbose=True,\n        memory=True\n    ).kickoff(*args)\n```\n\nÊàë‰ª¨ÁöÑ‰ª£ÁêÜÁªìÊûÑÂ∑≤ÁªèÂÆåÊàêÔºå‰ΩÜÊàë‰ª¨ËøòÊ≤°ÊúâËÆ®ËÆ∫Êàë‰ª¨ÁöÑÂ∑•ÂÖ∑„ÄÇÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ÁÆÄË¶ÅËØ¥Êòé‰∏Ä‰∏ãÊàë‰ª¨ÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n## ÊûÑÂª∫Â∑•ÂÖ∑\n\nÂ∑•ÂÖ∑Êú¨Ë¥®‰∏äÊòØÊé•ÂèóÂêÑÁßçËæìÂÖ•Âπ∂ËøîÂõûÂÄº‰Ωú‰∏∫ËæìÂá∫ÁöÑÂáΩÊï∞„ÄÇÊàë‰ª¨ÁöÑ‰ª£ÁêÜÂ∞ÜÁÆÄÂçïÂú∞Êèê‰æõËøô‰∫õÂáΩÊï∞ÊâÄÈúÄÁöÑËæìÂÖ•ÔºåÂπ∂Â§ÑÁêÜ‰ªñ‰ª¨Êî∂Âà∞ÁöÑËæìÂá∫„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶Å‰ª•È´òÂÆπÈîôÊÄßËÆæËÆ°Êàë‰ª¨ÁöÑÂ∑•ÂÖ∑„ÄÇÂΩìÂèëÁîü‰ΩøÁî®ÈîôËØØÊó∂ÔºåÊàë‰ª¨ÁöÑ‰ª£ÁêÜÂ∫îËØ•ËÉΩÂ§üËØªÂèñÈîôËØØÔºåÂπ∂ÈÖçÂ§á‰ø°ÊÅØ‰ª•‰æøÂú®‰∏ã‰∏ÄÊ¨°Ëø≠‰ª£‰∏≠Ê≠£Á°Æ‰ΩøÁî®Â∑•ÂÖ∑„ÄÇ\n\nÂú®‰∏∫Êàë‰ª¨ÁöÑÂ∑•ÂÖ∑ÂáÜÂ§áÂ•ΩÂáΩÊï∞ÂêéÔºåÊàë‰ª¨Â∫îËØ•‰ΩøÁî® LangChain Êàñ CrewAI ÁöÑÂ∑•ÂÖ∑ÂàõÂª∫Á±ªÂ∞ÜÂÆÉ‰ª¨ËΩ¨Êç¢‰∏∫Â∑•ÂÖ∑ÂØπË±°ÔºåÂπ∂ÈôÑ‰∏äÂêÑÁßçËØ¥Êòé„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨ÈÄöËøáÁÆÄÂçïÂú∞Âú®ÂáΩÊï∞È°∂ÈÉ®ÂÜô‰∏ä C**rewAI ÁöÑÂ∑•ÂÖ∑Ë£ÖÈ•∞Âô®**Â∞ÜÊàë‰ª¨ÁöÑÂ∑•ÂÖ∑ËΩ¨Êç¢‰∏∫‰ª£ÁêÜÂèØ‰ª•‰ΩøÁî®ÁöÑÂΩ¢Âºè„ÄÇ\n\n```python\nfrom crewai_tools import tool\n\n@tool(\"Wikipedia Search Tool\")\ndef search_wikipedia(query: str) -> str:\n    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n    page_titles = wikipedia.search(query)\n    summaries = []\n\n    for page_title in page_titles[:3]:  # First 3 results\n        try:\n            wiki_page = wikipedia.page(title=page_title, auto_suggest=False)\n            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n        except wikipedia.PageError: # Page Not Found\n            pass\n        except wikipedia.DisambiguationError: # Disambiguation Error\n            pass\n\n    if not summaries:\n        return \"No good Wikipedia Search Result was found\"\n\n    return \"\\n\\n\".join(summaries)\n```\n\n## ÊûÑÂª∫Â∫îÁî®Á®ãÂ∫è\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨‰ΩøÁî®ÊàëÁªèÂ∏∏‰ΩøÁî®Âπ∂‰∏îËÆ§‰∏∫Êèê‰æõ‰∫ÜÁÆÄÂçïÁïåÈù¢ËÆæËÆ°ÁöÑ Streamlit Ê°ÜÊû∂Êù•ÂÆûÊó∂ÈÉ®ÁΩ≤Êàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇStreamlit ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑ Python Ê°ÜÊû∂Ôºå‰æõÊï∞ÊçÆÁßëÂ≠¶ÂÆ∂Âíå AI/ML Â∑•Á®ãÂ∏à‰ΩøÁî®Ôºå‰ªÖÈúÄÂá†Ë°å‰ª£Á†ÅÂç≥ÂèØ‰∫§‰ªòÂä®ÊÄÅÊï∞ÊçÆÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\nÂΩìÁî®Êà∑Âú® `text_input` Ê°Ü‰∏≠ËæìÂÖ•‰ªñ‰ª¨ÁöÑ OpenAI ÂØÜÈí•Âπ∂ÁÇπÂáª‚ÄúÂàùÂßãÂåñ‰ª£ÁêÜ‚ÄùÊåâÈíÆÊó∂ÔºåÊàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏ªË¶ÅÊøÄÊ¥ª„ÄÇÂΩìÁî®Êà∑ÈÄöËøáÊ¥ªÂä®ÁöÑ `chat_input` ÈÉ®ÂàÜÂèëÈÄÅÊ∂àÊÅØÊó∂Ôºå‰ª•‰∏ãÂáΩÊï∞Áî®‰∫éÂ∞ÜËæìÂÖ•ÁöÑËØ∑Ê±Ç‰º†ÈÄíÁªôÊàë‰ª¨Âª∫Á´ãÁöÑ‰ª£ÁêÜÁªìÊûÑÔºö\n\n```python\ndef generate_response(topic):\n    return app.invoke(input={\"topic\": topic})\n```\n\nÂÄüÂä© Streamlit ÁöÑ `st.chat_message` ÁªÑ‰ª∂ÔºåÊàë‰ª¨ÂèØ‰ª•ËΩªÊùæÂÆûÁé∞ËÅäÂ§©Êú∫Âô®‰∫∫ÁïåÈù¢„ÄÇÂ¶ÇÊûúÁî®Êà∑Ê≠£Âú®ËøõË°åÂ∏∏ËßÑÊ∂àÊÅØ‰º†ÈÄíÔºåÂìçÂ∫îÂ∞ÜÊòæÁ§∫Ê≠£Â∏∏Á≠îÊ°à„ÄÇÂ¶ÇÊûúÁîüÊàê‰∫Ü‰∏ÄÁØáÊñáÁ´†ÔºåÊàë‰ª¨Â∞ÜÈÄöËøáÁºñÂÜôÁÆÄÂçïÁöÑ if-else Âæ™ÁéØÂêëÁî®Êà∑Êèê‰æõ PDF ÁöÑÁõÆÂΩï„ÄÇ\n\nÂêåÊó∂ÔºåÊàë‰ª¨Â∞Ü‰ªéËÅäÂ§©Êú∫Âô®‰∫∫ÂèëÈÄÅÂíåÊé•Êî∂ÁöÑÊØèÊù°Ê∂àÊÅØÊ∑ªÂä†Âà∞ Streamlit ÁöÑ `session_state` ‰∏≠ÂàõÂª∫ÁöÑ `messages` ÂèòÈáè‰∏≠„ÄÇËøôÊ†∑ÔºåÊàë‰ª¨Â∞±ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂèØËßÅÁöÑËÅäÂ§©Â±èÂπï„ÄÇ\n\n```python\n#Streamlit App\n\nimport streamlit as st\nfrom graph import EssayWriter\nimport os\nimport base64\n\nst.set_page_config(page_title=\"Essay Writer Chat Bot\", page_icon=\"ü§ñ\")\nst.image(\"./media/cover.jpg\", use_column_width=True)\n\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages =  [{\"role\": \"assistant\", \"content\": \"Hello!\"}]\n    st.session_state.app = None\n    st.session_state.chat_active = True\n\nwith st.sidebar:\n    st.info(\" * Ê≠§Â∫îÁî®Á®ãÂ∫è‰ΩøÁî® OpenAI API ÁîüÊàêÊñáÊú¨ÔºåËØ∑Êèê‰æõÊÇ®ÁöÑ API ÂØÜÈí•„ÄÇ\"\n            \"\\n\\n * Ê≠§Â∫îÁî®Á®ãÂ∫è‰ΩøÁî® 'gpt-4o-mini-2024-07-18' Ê®°Âûã„ÄÇÊàêÊú¨ÊúâÊïà‰∏îÈ´òÊïà„ÄÇ\"\n            \"\\n\\n * Â¶ÇÊûúÊÇ®Ê≤°Êúâ API ÂØÜÈí•ÔºåÂèØ‰ª•Âú® [ËøôÈáå](https://proxy.rifx.online/https://platform.openai.com/signup) Ëé∑Âèñ„ÄÇ\"\n            \"\\n\\n * ÊÇ®ËøòÂèØ‰ª•Âú® [ËøôÈáå](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) ÊâæÂà∞Ê≠§Â∫îÁî®Á®ãÂ∫èÁöÑÊ∫ê‰ª£Á†Å„ÄÇ\"\n            \"\\n\\n * Â∫îÁî®Á®ãÂ∫èÂØÜÈí•‰∏ç‰ºö‰ª•‰ªª‰ΩïÊñπÂºèÂ≠òÂÇ®Êàñ‰øùÂ≠ò„ÄÇ\"\n            \"\\n\\n * ÂÜô‰ΩúËÆ∫ÊñáÂèØËÉΩÈúÄË¶Å‰∏Ä‰∫õÊó∂Èó¥ÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ„ÄÇÂ§ßÁ∫¶ 1-2 ÂàÜÈíü„ÄÇ\"\n    openai_key= st.text_input(\"OpenAI API ÂØÜÈí•\", type=\"password\")\n\n\ndef initialize_agents():\n    os.environ[\"OPENAI_API_KEY\"] = openai_key\n    essay_writer = EssayWriter().graph\n\n    if len(openai_key) < 1:\n        st.error(\"ËØ∑ËæìÂÖ•ÊÇ®ÁöÑ OpenAI API ÂØÜÈí•Âπ∂ÂàùÂßãÂåñ‰ª£ÁêÜ„ÄÇ\")\n\n        st.session_state.chat_active = True\n    else:\n        st.success(\"‰ª£ÁêÜÊàêÂäüÂàùÂßãÂåñ\")\n        st.session_state.chat_active = False\n\n    return essay_writer\n\nwith st.sidebar:\n    if st.button(\"ÂàùÂßãÂåñ‰ª£ÁêÜ\", type=\"primary\"):\n        st.session_state.app = initialize_agents()\n\napp = st.session_state.app\ndef generate_response(topic):\n    return app.invoke(input={\"topic\": topic})\n\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"], unsafe_allow_html=True)\n\nif topic:= st.chat_input(placeholder=\"ÈóÆ‰∏Ä‰∏™ÈóÆÈ¢ò\", disabled=st.session_state.chat_active):\n    st.chat_message(\"user\").markdown(topic)\n\n    st.session_state.messages.append({\"role\": \"user\", \"content\": topic})\n    with st.spinner(\"ÊÄùËÄÉ‰∏≠...\"):\n        response = generate_response(topic)\n\n    with st.chat_message(\"assistant\"):\n        if \"pdf_name\" in response:\n            with open(f\"./{response['pdf_name']}\", \"rb\") as file:\n                file_bytes = file.read()\n                b64 = base64.b64encode(file_bytes).decode()\n            href = f'<a href=\"data:application/pdf;base64,{b64}\" download=\"{response['pdf_name']}\">{response['pdf_name']}</a>'\n\n            st.markdown(f\"{response['response']}: {href}\", unsafe_allow_html=True)\n            st.session_state.messages.append({\"role\": \"assistant\", \"content\": f\"{response['response']}: {href}\"})\n        else:\n            st.markdown(response[\"response\"])\n            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"response\"]})\n```\n\n**ÊÅ≠Âñú**ÔºÅÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊàë‰ª¨ÁöÑÈ°πÁõÆ„ÄÇÂ¶ÇÊûúÊÇ®ÊÑøÊÑèÔºåÂèØ‰ª•ËßÇÁúãÊàë‰∏∫ÊÇ®ÂΩïÂà∂ÁöÑÈ°πÁõÆÂ∑•‰ΩúÊó•Âøó„ÄÇ‰∏çË¶ÅÂøòËÆ∞ËÆøÈóÆ GitHub [**‰ªìÂ∫ì**](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) ‰ª•Ëé∑ÂèñÈ°πÁõÆÁöÑÊâÄÊúâ‰ª£Á†Å„ÄÇ\n\nËøôÂ∞±ÊòØÊàë‰ª¨Â∫îÁî®Á®ãÂ∫èÁöÑ‰∏ªÈ°µÂú®ÈÉ®ÁΩ≤ÂêéÂ∞ÜÂëàÁé∞ÁöÑÊ†∑Â≠êÔºÅ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8tDAluuAH6njIohDbb-UqA.png)\n\n## ÁªìËÆ∫\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî® CrewAI ÊûÑÂª∫Ëá™‰∏ªÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü„ÄÇÊàë‰ª¨È¶ñÂÖàËÆ®ËÆ∫‰∫ÜÂàõÂª∫Êô∫ËÉΩ‰ΩìÁöÑÂä®Êú∫Ôºå‰ª•ÂèäÂÆÉ‰ª¨Â¶Ç‰ΩïÂçèÂêåÂ∑•‰Ωú‰ª•Êõ¥È´òÊïàÂú∞ÂÆåÊàê‰ªªÂä°„ÄÇÈÄöËøáÂ∞Ü‰ªªÂä°ÁªÜÂàÜÂπ∂Âà©Áî®Â∑•ÂÖ∑ÔºåÊàë‰ª¨‰ΩøÊàë‰ª¨ÁöÑÊô∫ËÉΩ‰ΩìËÉΩÂ§ü‰ª•ÁªìÊûÑÂåñÁöÑÊñπÂºèÊâßË°åÂ§çÊùÇÊìç‰Ωú„ÄÇ\n\nÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈ°πÁõÆÔºåÈõÜÊàê‰∫Ü CrewAI Âíå LangChain Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫ÜÂ§ö‰∏™Êô∫ËÉΩ‰ΩìÂ¶Ç‰ΩïÂçè‰ΩúÊî∂ÈõÜ‰ø°ÊÅØ„ÄÅÊí∞ÂÜôËÆ∫ÊñáÂíåÁºñËæëÂÜÖÂÆπ„ÄÇÂº∫Ë∞É‰∫ÜÂ∑•ÂÖ∑‰ΩøÁî®Âíå‰ªªÂä°ÁÆ°ÁêÜÔºå‰ª•Á°Æ‰øùÊàë‰ª¨ÁöÑÊô∫ËÉΩ‰ΩìËÉΩÂ§üÈ°∫Âà©ÊúâÊïàÂú∞ËøêË°å„ÄÇ\n\nÊúÄÂêéÔºåÊàë‰ª¨‰ΩøÁî® Streamlit ÈÉ®ÁΩ≤‰∫ÜÊàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫èÔºå‰ΩøÁî®Êà∑ËÉΩÂ§üËΩªÊùæ‰∏éÁ≥ªÁªü‰∫íÂä®„ÄÇ\n\nÊÇ®ÂèØ‰ª•Âú® [**ËøôÈáå**](https://proxy.rifx.online/https://multi-agent-essay-writer.streamlit.app/) Êü•ÁúãÂÆûÊó∂È°πÁõÆÔºåÂú®ÊàëÁöÑ GitHub ‰ªìÂ∫ì [**ËøôÈáå**](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) Êü•ÁúãÊ∫ê‰ª£Á†Å\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/building-self-healing-intelligent-test-automation-with-gen-ai-openai-apis-6c39808adb0f","frontmatter":{"title":"Âà©Áî® Gen AIÔºàOpenAI APIÔºâÊûÑÂª∫Êô∫ËÉΩÊµãËØïËá™Âä®Âåñ","meta_title":"Âà©Áî® Gen AIÔºàOpenAI APIÔºâÊûÑÂª∫Êô∫ËÉΩÊµãËØïËá™Âä®Âåñ","description":"Êàë‰ª¨ÈÉΩÁü•ÈÅìÔºåÁî®Êà∑ÁïåÈù¢ÊµãËØïÊòØË∂ÖÁ∫ßËÑÜÂº±ÁöÑ„ÄÇÂÆÉ‰ª¨‰ºöÂõ†ÂêÑÁßçÂéüÂõ†ËÄåÂ¥©Ê∫ÉÔºåÂÖ∂‰∏≠ÊúÄÂ§ßÁöÑÁΩ™È≠ÅÁ•∏È¶ñ‰πã‰∏ÄÂ∞±ÊòØ UI ÁöÑÊõ¥Êîπ...","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kZ4ZR-jqdTTgH3bpOzcgUw.png","categories":["Generative AI","Programming","Testing"],"author":"Rifx.Online","tags":["Generative","OpenAI","Selenium","LLMs","POM"],"draft":false,"slug":"blog/building-self-healing-intelligent-test-automation-with-gen-ai-openai-apis-6c39808adb0f"},"content":"\n\n\n> Êàë‰ª¨ÈÉΩÁü•ÈÅì UI ÊµãËØïÈùûÂ∏∏ËÑÜÂº±„ÄÇÂÆÉ‰ª¨ÂèØËÉΩÂõ†ÂêÑÁßçÂéüÂõ†ËÄåÂ§±Ë¥•ÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÊúÄÂ§ßÁöÑÈóÆÈ¢òÊòØ UI ÂÆö‰ΩçÂô®ÁöÑÂèòÂåñ„ÄÇÂæàÈöæÊÉ≥Ë±°Êàë‰ª¨Â¶Ç‰ΩïËÉΩËÆ©ÂÆÉ‰ª¨Ë∂≥Â§üÊô∫ËÉΩÔºå‰ª•ÁêÜËß£ÂÆö‰ΩçÂô®‰ΩïÊó∂ÂèëÁîüÂèòÂåñÔºåÂπ∂Âú®ÊµãËØï‰∏≠Âá∫Áé∞ÂÆö‰ΩçÂô®ÈóÆÈ¢ò‰πãÂâçÈò≤Ê≠¢ÊµãËØïËøêË°å„ÄÇ\n\n‰Ω†Ê≤°Âê¨ÈîôÔºÅÁé∞Âú®ÊòØ 2024 Âπ¥ÔºåËá™Âä®ÂåñÊµãËØïÂ∑•ÂÖ∑Â∑≤ÁªèÂèñÂæó‰∫ÜÈïøË∂≥ÁöÑËøõÊ≠•„ÄÇÂú®‰∏éËøô‰∫õÂ∑•ÂÖ∑Êâì‰∫§ÈÅìËøë 18 Âπ¥ÂêéÔºå‰ªé Mercury Winrunner Âà∞ PlaywrightÔºåÊàë‰ª¨Áé∞Âú®ÂèØ‰ª•Âà©Áî®ÁîüÊàêÊÄß AI ÁöÑÂº∫Â§ßÂäüËÉΩÂÅö‰∏Ä‰∫õÁúüÊ≠£‰ª§‰∫∫ÊÉäÂèπÁöÑ‰∫ãÊÉÖ„ÄÇËøôÂ∞±ÂÉèÈ≠îÊ≥ïÔºå‰ΩÜËøôÊòØÁúüÊ≠£ÁöÑÁßëÂ≠¶ÔºÅ\n\nÊ≤°ÈîôÔºåÊàë‰ª¨Áé∞Âú®ÂèØ‰ª•ÊâæÂà∞‰∏ÄÁßçÊñπÊ≥ïÔºåËÆ©Êàë‰ª¨ÁöÑÊµãËØïËá™Âä®Âåñ‰ª£Á†Å **Êõ¥Êô∫ËÉΩ**ÔºåËÄå‰∏çÈúÄË¶ÅËá™Â∑±ÁºñÂÜôÂêÑÁßçÊ®°Á≥äÁöÑÊï∞Â≠¶ÁÆóÊ≥ïÔºåËøô‰∏ÄÂàáÈÉΩÁî± LLM ÁöÑÁ•ûÊù•Â§ÑÁêÜ„ÄÇ\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞ÜËÆ®ËÆ∫Â¶Ç‰Ωï‰ª•Êõ¥ÊúâÊïàÂíåÈ´òÊïàÁöÑÊñπÂºè‰ΩøÊàë‰ª¨ÁöÑÊµãËØïÂèòÂæóÊô∫ËÉΩÔºå‰ΩÜÂêåÊ†∑ÔºåË¶ÅÂÆûÁé∞Ëøô‰∏ÄÁÇπÔºåÊÇ®ÈúÄË¶ÅÂÖ∑Â§á‰ª•‰∏ãÂâçÊèêÊù°‰ª∂Ôºö\n\n1. **Open AI API** Â∏¶‰ø°Áî®È¢ùÂ∫¶ÔºàÊÇ®ÈúÄË¶ÅÂç≥Êó∂Ë¥≠‰π∞Ôºâ\n\n\n\n2\\. C\\# .NET ‰ª£Á†ÅÁü•ËØÜÔºåÂõ†‰∏∫ÊàëÂ∞ÜË¶ÅÊ∂µÁõñÁöÑ‰ª£Á†ÅÊù•Ëá™ .NET Âíå Selenium\n\n3\\. ÂØπÊµãËØïËá™Âä®ÂåñÁöÑÂü∫Êú¨ÁêÜËß£\n\nÂÜçÊ¨°Âº∫Ë∞ÉÔºå‰ª•‰∏äÊâÄÊúâÂÜÖÂÆπ‰ª•Âèä‰ª•‰∏ãËÆ®ËÆ∫ÈÉΩÊòØÊàë [Udemy ËØæÁ®ã](https://proxy.rifx.online/https://www.udemy.com/course/generative-ai-in-software-automation-testing/) ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåËØ•ËØæÁ®ãÊ∂µÁõñ‰∫ÜÊõ¥ËØ¶ÁªÜÁöÑÂÜÖÂÆπÂíåÈÄêÊ≠•ÁºñÂÜô‰ª£Á†ÅÁöÑÊñπÊ≥ï„ÄÇ\n\n## ËÆ©Êàë‰ª¨ÁêÜËß£ÈóÆÈ¢òÈôàËø∞\n\nÊàë‰ª¨Êúâ‰∏Ä‰∏™È°µÈù¢ÔºåÂ∏åÊúõ‰ΩøÁî® Selenium C# ‰ª£Á†ÅËøõË°åËá™Âä®Âåñ„ÄÇÊàë‰ª¨‰ΩøÁî®È°µÈù¢ÂØπË±°Ê®°ÂûãÔºàPOMÔºâÊ®°ÂºèÁºñÂÜô‰∫ÜÈùûÂ∏∏Â•ΩÁöÑ‰ª£Á†ÅÔºå‰∏ÄÂàáÁúãËµ∑Êù•ÈÉΩÂæàÊ£íÔºåÂπ∂‰∏îÂÆåÁæéËøêË°åÔºåÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GPSBTmPEZBpubI72OElwbw.gif)\n\nÊàë‰ª¨ÁöÑÂºÄÂèëÂÜ†ÂÜõÂèëÁé∞‰∫Ü‰∏Ä‰∏™ÈúÄË¶ÅË∞ÉÊï¥ÁöÑ UI ÂÖÉÁ¥†„ÄÇ‰ªñÊ†πÊçÆÂêå‰∫ãÁöÑ‰ª£Á†ÅÂÆ°Êü•ÊÑèËßÅËøõË°å‰∫ÜÊõ¥ÊîπÔºå‰ΩÜ‰∏çÂπ∏ÁöÑÊòØÔºå‰ªñÂà†Èô§‰∫ÜÊàë‰ª¨Âú®Ëá™Âä®ÂåñÊµãËØï‰∏≠‰ΩøÁî®ÁöÑÂÆö‰ΩçÂô®„ÄÇËøôÊÑèÂë≥ÁùÄÊàë‰ª¨ÁöÑ POM ‰ª£Á†ÅÂ∞Ü‰∏çÂÜçÂ∑•‰ΩúÔºåÂõ†‰∏∫ÂÆö‰ΩçÂô®‰∏çÂÜçÂ≠òÂú®ÔºåËøôÊúÄÁªàÂØºËá¥ÊµãËØï **Â§±Ë¥•**„ÄÇ\n\nÊúÄÈáçË¶ÅÁöÑÊòØÔºåÁî±‰∫éÂçï‰∏™ÂÆö‰ΩçÂô®ÁöÑÊõ¥ÊîπÔºåÊâÄÊúâÊµãËØïÂú∫ÊôØÈÉΩÂ∞ÜÂõ†Áõ∏ÂêåÁöÑÂ§±Ë¥•ËÄåÂ§±Ë¥•„ÄÇÊµãËØïÂπ∂‰∏çÁü•ÈÅìÂÆö‰ΩçÂô®Â∑≤Êõ¥ÊîπÔºå‰πüÊ≤°Êúâ‰ªª‰ΩïÊñπÊ≥ïÁü•ÈÅìËøô‰∏ÄÁÇπÔºåÂõ†Ê≠§ÂÆÉÊÄªÊòØÂ§±Ë¥•„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tINBnScOW78vz8sKb6lWbA.gif)\n\n## Â¶Ç‰ΩïËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºü\n\nÊàëÁõ∏‰ø°ÂÉèÊàë‰∏ÄÊ†∑ÔºåÂæàÂ§ö‰∫∫Âú®‰ΩøÁî® UI ÊµãËØïÂ∑•ÂÖ∑Êó∂ÔºåÊØèÂ§©ÈÉΩÂú®ÁªèÂéÜËøô‰∏™ÈóÆÈ¢òÔºåÊó†ËÆ∫ÊòØ **Cypress**„ÄÅ**Selenium** ËøòÊòØ **Playwright**„ÄÇËøô‰∏™ÈóÆÈ¢òÊÄªÊòØÂ≠òÂú®ÔºåÊó†ËÆ∫‰ΩøÁî®‰ªÄ‰πàÂ∑•ÂÖ∑„ÄÇ\n\nÁé∞Âú®ËÆ©Êàë‰ª¨Êù•ÁêÜËß£Â¶Ç‰ΩïËß£ÂÜ≥‰∏äËø∞ÈóÆÈ¢ò„ÄÇ\n\nÊàë‰ª¨ÈÉΩÁü•ÈÅì **ÁîüÊàêÂºè AI** Âíå **Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã**ÔºàLLMsÔºâÂ∑≤ÁªèËøúËøúË∂ÖÂá∫‰∫ÜÊñáÊú¨/ÂõæÂÉè/ËßÜÈ¢ëÁîüÊàêÁöÑËåÉÁï¥„ÄÇÂÆÉ‰ª¨ÁêÜËß£ÁªôÂÆöÁöÑ‰∏ä‰∏ãÊñáÔºåÂπ∂ÁîüÊàêÊàë‰ª¨ÊâÄÂØªÊâæÁöÑÊúâÊÑè‰πâÁöÑ‰ø°ÊÅØÈõÜ„ÄÇ\n\nÂõ†Ê≠§ÔºåÈíàÂØπ‰∏äËø∞ÈóÆÈ¢òÔºåÊàë‰ª¨ÂèØ‰ª•Âà©Áî®ÁîüÊàêÂºè AI ÁöÑÂäõÈáèÔºåÈÄöËøá OpenAI ÁöÑ APIÔºåÂ∞ÜÊàë‰ª¨ÁöÑÊèêÁ§∫ËØ∑Ê±Ç‰º†ÈÄíÁªôÂÉè ***GPT 4o*** Êàñ ***GPT 4 turbo*** ÁöÑ LLMÔºå‰ª•ÁêÜËß£ÈóÆÈ¢òÈôàËø∞Âπ∂ÁªôÂá∫ÊúâÊÑè‰πâÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\n> ÈÇ£‰πàÔºåÊàë‰ª¨ÈúÄË¶ÅÂêë OpenAI ÁöÑ API ‰º†ÈÄí‰ªÄ‰πàÊèêÁ§∫ËØ∑Ê±ÇÔºå‰ª•‰æøÂú®Êàë‰ª¨ÁöÑÊµãËØïËá™Âä®Âåñ‰∏≠ÊâßË°åÊìç‰ΩúÂë¢Ôºü\n\nÂ•ΩÂêßÔºåËøôÂº†ÂõæÂ∞ÜÁªô‰Ω†Á≠îÊ°à„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*bsCOcyWc0FDnxPp9ApssVw.gif)\n\nÊàë‰ª¨ÂèØ‰ª•Â∞ÜÂ∫îÁî®Á®ãÂ∫èÁöÑ‚Äú**ÂÆûÈôÖÊµãËØïÈ°µÈù¢**‚ÄùÂíå Selenium ÊµãËØïÁöÑ‚Äú**È°µÈù¢ÂØπË±°Ê®°Âûã**‚Äù‰ª£Á†Å‰Ωú‰∏∫ÊèêÁ§∫ÂèëÈÄÅÁªô OpenAI ÁöÑ APIÔºàÈôÑÂ∏¶‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÂìçÂ∫îËß£ÊûêÁªÜËäÇÔºâ„ÄÇËøôÂ∞Ü‰Ωú‰∏∫ OpenAI API ÁöÑÈ™åËØÅËøáÁ®ãÔºå‰ª•Êü•ÁúãÂÆö‰ΩçÂô®ÊòØÂê¶‰∏éÁªôÂÆöÈ°µÈù¢ÂåπÈÖç„ÄÇ\n\nÊ†πÊçÆËØ•Êìç‰ΩúÔºåÊàë‰ª¨ÂèØ‰ª•ÂÜ≥ÂÆöÊµãËØïÊòØÂê¶ÊâßË°å„ÄÇÂÆö‰ΩçÂô®ÂèëÁîü‰∫ÜÂèòÂåñÔºåÂõ†Ê≠§ÁªßÁª≠ËøêË°åÊµãËØïÊòØÊ≤°ÊúâÊÑè‰πâÁöÑ„ÄÇ\n\nÊâßË°å‰∏äËø∞Êìç‰ΩúÁöÑ‰ª£Á†ÅÂ§ßËá¥Â¶Ç‰∏ãÔºö\n\n```python\npublic static async Task<string> VerifyPageLocatorFromAiAsync(string pomFileContent, string htmlPageSource)\n{\n    ChatClient client = new(model: \"gpt-4o-mini\", apiKey);\n    \n    var chatMessage = $\"Verify if locators from this Selenium POM class: {pomFileContent} match this page source: {htmlPageSource}\\\", only return True or False result\";\n\n    ChatCompletion completion = await client.CompleteChatAsync(chatMessage);\n\n    return completion.Content.FirstOrDefault().Text;\n}\n```\n‰∏äËø∞‰ª£Á†ÅÂè™ÊòØËØæÁ®ã‰∏≠Ê∂âÂèäÁöÑÂ§ßÈáè‰ª£Á†ÅÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰ΩÜ‰Ω†ÂèØ‰ª•ÁúãÂà∞Â¶Ç‰ΩïÁÆÄÂçïÂú∞ÊâßË°åÂ∞ÜÈ°µÈù¢‰∏é Selenium ÁöÑÈ°µÈù¢ÂØπË±°Ê®°Âûã‰ª£Á†ÅËøõË°åÂàÜÊûêÁöÑÊìç‰Ωú„ÄÇ\n\n## GenAIÂú®ËΩØ‰ª∂ÊµãËØïËØæÁ®ã‰∏≠\n\n*‰ª•‰∏äËÆ®ËÆ∫Âè™ÊòØÊàëÂú®UdemyÊñ∞ËØæÁ®ã‚Äú[**Âú®ËΩØ‰ª∂Ëá™Âä®ÂåñÊµãËØï‰∏≠‰ΩøÁî®ÁîüÊàêÊÄßAI**](https://proxy.rifx.online/https://www.udemy.com/course/generative-ai-in-software-automation-testing/)‚Äù‰∏≠ËÆ®ËÆ∫‰∏ªÈ¢òÁöÑ‰∏ÄÈÉ®ÂàÜ*\n\n‰ª•‰∏ãÊòØËØæÁ®ãÂÜÖÂÆπ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*lHe_b7qVqUQo-9Y5.png)\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rMrsbB2IaKPbthdAr9Rc9g.png)\n\nËØ•ËØæÁ®ãÁõÆÂâçÂú®Udemy‰∏ä‰ª•‰ºòÊÉ†‰ª∑Ê†ºÊèê‰æõÔºå‰Ωú‰∏∫È¶ñÂèë‰ºòÊÉ†ÔºåËØ∑Âú®Ë¥≠‰π∞ËØæÁ®ãÊó∂‰ΩøÁî®‰ºòÊÉ†Á†Å**EA\\_NOV\\_24 ‚ö°Ô∏è**„ÄÇ\n\nÂ¶ÇÊûú‰ºòÊÉ†Á†ÅÂ∑≤ËøáÊúüÔºåËØ∑ÈöèÊó∂Âú®Ê≠§Â∏ñÂ≠ê‰∏ãÁïôË®ÄÔºåÊàë‰ºöÂ∞ÜÊúÄÊñ∞ÁöÑÂèØÁî®‰ºòÊÉ†Á†ÅÂèëÈÄÅÁªôÊÇ®„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/case-study-turning-doctor-transcripts-into-temporal-medical-record-knowledge-graphs-cf624d4927eb","frontmatter":{"title":"Ê°à‰æãÁ†îÁ©∂ÔºöÂ∞ÜÂåªÁîüÁ¨îÂΩïËΩ¨Âåñ‰∏∫Êó∂ÊÄÅÂåªÁñóËÆ∞ÂΩïÁü•ËØÜÂõæË∞±","meta_title":"Ê°à‰æãÁ†îÁ©∂ÔºöÂ∞ÜÂåªÁîüÁ¨îÂΩïËΩ¨Âåñ‰∏∫Êó∂ÊÄÅÂåªÁñóËÆ∞ÂΩïÁü•ËØÜÂõæË∞±","description":"Â±ïÁ§∫Êï∞ÊçÆËΩ¨Êç¢ËøáÁ®ã„ÄÅÊ∂âÂèäÁöÑ 25 ‰∏™ÂºÄÂèëÂ∞èÊó∂ÁöÑÊòéÁªÜ„ÄÅ‰ΩøÁî®ÁöÑÊ®°Âºè„ÄÅÈóÆÈ¢òÂíåÂõûÂ§ç‰ª•ÂèäÂàõÂª∫ÁöÑÂõæË°®","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DUNtg-0w2z-vlF9SCvt5UA.png","categories":["Health","Data Science","Machine Learning"],"author":"Rifx.Online","tags":["transcripts","Temporal","Knowledge","Graphs","vector"],"draft":false,"slug":"blog/case-study-turning-doctor-transcripts-into-temporal-medical-record-knowledge-graphs-cf624d4927eb"},"content":"\n\n\nÊÇ®ÊòØÂê¶ÊúâÂÖ¥Ë∂£Â∞ÜÂåªÁîü/ÊÇ£ËÄÖÁöÑÂåªÁñóËÆ∞ÂΩïÂíåËÆ∞ÂΩïËΩ¨Âåñ‰∏∫ÂèØ‰ª•Ë∑®Â§ö‰∏™ÂåªÁñóÂéÜÂè≤„ÄÅÊó∂Èó¥ÊÆµÂíåÊÇ£ËÄÖËøõË°åÂ§çÊùÇÊü•ËØ¢ÁöÑÊó∂Èó¥ÊÄßÁü•ËØÜÂõæË∞±Ôºü\n\nÂú®Êú¨Ê°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞ÜÂåªÁñóËÆ∞ÂΩïËΩ¨Âåñ‰∏∫ÊÇ®ÂèØ‰ª•‰æùËµñ‰∫é RAG ÂíåÂàÜÊûêÁõÆÁöÑÁöÑÊó∂Èó¥ÊÄßÁü•ËØÜÂõæË∞±„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫ÜÈíàÂØπËØ•Á≥ªÁªüÁöÑÁúüÂÆûÈóÆÁ≠îÔºå‰ª•ÂèäÊÇ®ÂèØ‰ª•ÈÄöËøáËØ•Á≥ªÁªüÂÆûÁé∞ÁöÑ‰∏öÂä°ÊàêÊûú„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåËøôÈáåÊ≠•È™§ÁöÑÁªÑÂêàÊòØ‰∏ÄÁßçÁõ∏ÂØπÊñ∞È¢ñÁöÑÁü•ËØÜÂõæË∞±ÂÆûÁé∞„ÄÇ\n\n### ‰ΩøÁî®ÁöÑÊï∞ÊçÆ\n\nÂá∫‰∫éÊï∞ÊçÆÈöêÁßÅÂéüÂõ†ÔºåÊàë‰ª¨‰ΩøÁî®‰∫Ü‰∏Ä‰∏™ÂêàÊàêÁöÑÂåªÁñóËÆ∞ÂΩïÊï∞ÊçÆÈõÜÔºåËØ•Êï∞ÊçÆÈõÜÊòØÊàë‰ª¨‰ªéSyntheaÊï∞ÊçÆ‰∏≠ÂàõÂª∫ÁöÑÔºåÈìæÊé•Âú®Ê≠§Ôºö[https://synthea.mitre.org/downloads](https://proxy.rifx.online/https://synthea.mitre.org/downloads)„ÄÇ‰ª•‰∏ãÊòØÁî®‰∫éÁü•ËØÜÂõæË∞±ÂàõÂª∫ÁöÑËæìÂÖ•Êï∞ÊçÆ‰πã‰∏ÄÁöÑÂåªÁñóËÆ∞ÂΩïÁ§∫‰æã„ÄÇÊàë‰ª¨Â∞ÜËøô‰∫õËÆ∞ÂΩïÊï∞ÊçÆ‰∏éSyntheaÊï∞ÊçÆ‰∏≠ÁöÑÁªìÊûÑÂåñÂåªÁñóËÆ∞ÂΩïÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇÊàë‰ª¨ÊúâÂ§ßÁ∫¶75‰ªΩËÆ∞ÂΩïÔºåÊ∂µÁõñ‰∫Ü10‰ΩçÊÇ£ËÄÖÔºàÂç≥ÊØè‰ΩçÊÇ£ËÄÖÊúâ5-10‰ªΩËÆ∞ÂΩïÔºâ„ÄÇ‰ª•‰∏ãÊòØ‰ΩøÁî®ÁöÑËÆ∞ÂΩïÁ§∫‰æãÔºö\n\n\n\n## Êñ∞È¢ñÁü•ËØÜÂõæË∞±Êû∂ÊûÑÊ¶ÇËø∞\n\n### ËäÇÁÇπÔºö\n\nÊàë‰ª¨Êúâ5ÁßçÁ±ªÂûãÁöÑËäÇÁÇπÔºöPatient„ÄÅObservation„ÄÅImmunization„ÄÅConditionÂíåEncounter Type\n\n### Triples (Ê†∑Êú¨ÂàóË°®):\n\nPatient \\-\\> Had Encounter \\-\\> Encounter\n\nPatient \\-\\> Has Condition \\-\\> Condition\n\nPatient \\-\\> Received \\-\\> Immunization\n\nPatient \\-\\> Has Measurement \\-\\> Observation\n\n### Chunks:\n\nChunks ÊòØÁã¨Á´ãÁöÑÊñáÊú¨Âùó„ÄÇChunks ‰∏éÊØè‰∏™ Triple Áõ∏ÂÖ≥ËÅîÔºåÂπ∂‰∏îÂèØ‰ª•ÊúâÂ§ö‰∏™ Chunks ÂÖ≥ËÅîÂà∞Âçï‰∏™ Triple„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåChunks ‰∏çÊòØ Triple ÁöÑÈùûÁªìÊûÑÂåñÊù•Ê∫êÔºåËÄåÊòØ‰∏éÊØèÁßç Triple Á±ªÂûãÁõ∏ÂÖ≥ÁöÑÊëòË¶ÅÂíåÂÖ≥ÈîÆÁÇπ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Êúâ 6 ÁßçÁ±ªÂûãÁöÑ ChunksÔºö- ÊÇ£ËÄÖ‰∫∫Âè£ÁªüËÆ° Chunks„ÄÅÁóÖÊÉÖÊëòË¶Å Chunks„ÄÅÂ∞±ËØä Chunks„ÄÅËßÇÂØü Chunks„ÄÅÂÖçÁñ´Êé•Áßç Chunks ÂíåÁóÖÊÉÖËØ¶ÁªÜ Chunks„ÄÇ\n\n‰∏çÂêåÁ±ªÂûãÁöÑ Chunks ÂÖ≥ËÅîÂà∞ Triples ÁöÑÁ§∫‰æãÂ¶Ç‰∏ãÔºö\n\n```python\n1. Patient -> EncounterType\nTriple: (Patient) -[had_encounter]-> (EncounterType)\n- Chunk_ids link to specific visit instances\n- Example Chunk: \"Annual physical on 2024‚Äì01‚Äì15. BP 120/80, routine screenings \nupdated.\"\n\n2. Patient -> Condition\nTriple: (Patient) -[has_condition]-> (Condition)\n- Chunk_ids link to condition episodes\n- Example Chunk: \"Diagnosed with hypertension on 2020‚Äì03‚Äì10. Status: active. \nManaged with medication.\"\n\n3. Patient -> Immunization\nTriple: (Patient) -[received]-> (Immunization)\n- Chunk_ids link to administration records\n- Example Chunk: \"Influenza vaccine administered on 2024‚Äì01‚Äì15.\"\n\n4. Patient -> Observation\nTriple: (Patient) -[has_measurement]-> (Observation)\n- Chunk_ids link to measurement instances\n- Example Chunk: \"2024‚Äì01‚Äì15: Blood Pressure 120/80 mmHg, Weight 70kg.\"\n```\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*8dH_7tP6xheCaW6K)\n\n**Link to the Graph created: [https://proxy.rifx.online/https://main\\-\\-whyhowai.netlify.app/public/graph/673032011997e08c8849316c](https://proxy.rifx.online/https://main--whyhowai.netlify.app/public/graph/673032011997e08c8849316c)**\n\nÈÄöËøáËøôÁßçÁâπÂÆöÁöÑÂõæÂΩ¢Êû∂ÊûÑÔºåÊÇ®ÂèØ‰ª•Â∞ÜÂÖ≥ÈîÆÁÇπÂíåÊëòË¶Å‰∏é Triples ÂÖ≥ËÅîÔºåÁÑ∂ÂêéÂèØ‰ª•‰∏ìÊ≥®‰∫éÈÄöËøáÈùûÁªìÊûÑÂåñÊêúÁ¥¢ÊâæÂà∞Ê≠£Á°ÆÁöÑ‰∏ÄÁªÑ TriplesÔºåÂπ∂ÈöèÂêéÈÄöËøáÁªìÊûÑÂåñÊñπÂºèÂºïÂÖ•ÊâÄÊúâÁõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇ\n\n## Áã¨ÁâπÁöÑWhyHowÊû∂ÊûÑ\n\nÊúâ‰∏Ä‰∫õÁã¨ÁâπÁöÑWhyHowÂõæÂΩ¢Âü∫Á°ÄËÆæÊñΩÔºå‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰ª•ÁÆÄÂçïÁöÑÊñπÂºèÊûÑÂª∫Ê≠§Êû∂ÊûÑ„ÄÇ\n\nÈ¶ñÂÖàÔºåTriplesÈÄöËøáÂêëÈáèÊêúÁ¥¢ÂµåÂÖ•ÂíåÊ£ÄÁ¥¢ÔºåÈÅøÂÖç‰∫ÜÂ∏∏ËßÅÁöÑÊ£ÄÁ¥¢ÈóÆÈ¢òÔºåÂç≥ÂøÖÈ°ª‰ΩøÁî®Text2CypherÊù•ËØÜÂà´ËäÇÁÇπ„ÄÅÂÖ≥Á≥ªÔºåÁÑ∂ÂêéÊûÑÂª∫CypherÊü•ËØ¢Ôºå‰ª•ÊâæÂà∞Ê≠£Á°ÆÁöÑTriple„ÄÇËøôÂ∑≤Ë¢´ËØÅÊòéÂèØ‰ª•ÊòæËëó[ÊèêÈ´òÊ£ÄÁ¥¢ÂáÜÁ°ÆÊÄßËææ3ÂÄç](https://proxy.rifx.online/https://readmedium.com/knowledge-table-multi-document-rag-extraction-memory-ec08450e858f)„ÄÇ\n\nÂÖ∂Ê¨°ÔºåTriplesÊòØWhyHow‰∏≠ÁöÑÁã¨Á´ãÂØπË±°ÔºåÊÇ®ÂèØ‰ª•Â∞ÜÂùóÈìæÊé•Âà∞Ëøô‰∫õÂØπË±°„ÄÇËøô‰ΩøÊÇ®ËÉΩÂ§üÊèêÁÇºÊØè‰∏™TripleÊÉ≥Ë¶ÅÊ£ÄÁ¥¢ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂπ∂Âú®ÊâæÂà∞Ê≠£Á°ÆÁöÑTriplesÂêéÁõ¥Êé•Â∞ÜÂÖ∂ÂºïÂÖ•‰∏ä‰∏ãÊñá„ÄÇËøôÈÅøÂÖç‰∫ÜÂøÖÈ°ª‰ª•ÂõæÂΩ¢Ê†ºÂºèË°®Á§∫ÂÖ≥ÈîÆÁöÑ‰ø°ÊÅØÂíå‰∏ä‰∏ãÊñáÔºà‰ΩøÂæóÊ®°ÂºèÊûÑÂª∫ËøáÁ®ãÂ§çÊùÇÂåñÔºâÔºåÂπ∂Âú®ÂàùÂßãÁöÑÈùûÁªìÊûÑÂåñÂêëÈáèÊêúÁ¥¢Âêé‰ª•ÁªìÊûÑÂåñÁöÑÊñπÂºèÂºïÂÖ•‰ø°ÊÅØ„ÄÇËøôÂú®ËøáÁ®ã‰∏äÁ±ª‰ºº‰∫é[LinkedInÂØπÁü•ËØÜÂõæÁöÑÂ∫îÁî®](https://proxy.rifx.online/https://readmedium.com/5-misconceptions-of-kg-rag-systems-building-using-rag-native-graphs-5e47872e7903)ÔºåÂú®‰ªñ‰ª¨ÁöÑÁ≥ªÁªü‰∏≠ÔºåÂÉè‚ÄúÈáçÁé∞Ê≠•È™§‚ÄùËøôÊ†∑ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØ‰ª•Á±ª‰ººÁöÑÊñπÂºèË°®Á§∫ÂíåÊ£ÄÁ¥¢ÔºåËÄåËøô‰∫õÊ≠•È™§Êú¨Ë∫´ÂàôË¢´Ë°®Á§∫‰∏∫ÂçïÁã¨ÁöÑ‚ÄúÂùó‚Äù/‚ÄúËäÇÁÇπ‚Äù„ÄÇ\n\nÁ¨¨‰∏âÔºåWhyHowÊé•ÂèóJSONÊ†ºÂºèÁöÑÊï∞ÊçÆÔºåËøôÂÖÅËÆ∏‰ªª‰ΩïÊèêÂèñÊ°ÜÊû∂‰∏éÂõæÂΩ¢ÂàõÂª∫‰πãÈó¥Êó†Áºù‰∫íÂä®„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨‰ΩøÁî®ClaudeÂ∞ÜËΩ¨ÂΩïÊï∞ÊçÆÂàùÊ≠•ËΩ¨Êç¢‰∏∫ÂøÖË¶ÅÁöÑJSONÁªìÊûÑÔºå‰ª•Âä†ËΩΩÂà∞WhyHow‰∏≠„ÄÇÂ¶ÇÊûúÊÇ®Â∑≤ÁªèÊúâ‰ø°ÊÅØ‰ª•JSONÊ†ºÂºèÂ≠òÂú®ÔºåÈÇ£‰πàÂ∞ÜÊï∞ÊçÆÂä†ËΩΩÂà∞WhyHow‰∏≠Â∞±ÂÆπÊòìÂ§ö‰∫Ü„ÄÇ\n\nÁ¨¨ÂõõÔºåÁî±‰∫éWhyHowÁ≥ªÁªü‰∏≠ÂùóÂíåÊ£ÄÁ¥¢ËøáÁ®ãÁöÑËÆæËÆ°ÊñπÂºèÔºåÊÇ®ÂèØ‰ª•ËΩªÊùæÂåÖÂê´ÂèØ‰ª•Áî®‰∫éÁÆ°ÁêÜÁ≠îÊ°àÊûÑÂª∫ÊñπÂºèÁöÑÊó∂Èó¥Êï∞ÊçÆ„ÄÇÊó∂Èó¥Êï∞ÊçÆÂú®Áü•ËØÜÂõæ‰∏≠‰∏ÄÁõ¥ÊòØ‰∏Ä‰∏™Èöæ‰ª•Âª∫Ê®°ÁöÑÂÜÖÂÆπÔºà‰ª•Ëá≥‰∫éÈ¢ÜÂÖàÁöÑKG‰∏ìÂÆ∂ÈÄöÂ∏∏Âª∫ËÆÆÈÅøÂÖçÔºâÔºå‰ΩÜÂÆÉÊòæÁÑ∂ÊòØÂ∑•‰ΩúÊµÅÁöÑÈáçË¶ÅÁªÑÊàêÈÉ®ÂàÜ„ÄÇÂç≥‰ΩøÂ∞ùËØïÂª∫Ê®°Êó∂Èó¥Êï∞ÊçÆÁöÑÁé∞ÊúâÊñπÊ≥ï‰πüËØïÂõæÂ∞ÜÂÖ∂ÊëÑÂèñÂà∞Áü•ËØÜÂõæ‰∏≠ÔºåÁÑ∂ÂêéÂü∫‰∫éÁªìÊûÑÂåñÁöÑCypherÊü•ËØ¢ËøõË°åÊ£ÄÁ¥¢ÔºåËÄå‰∏çÊòØÊàë‰ª¨Áã¨Áâπ‰ΩøÁî®LLMÊù•Â∏ÆÂä©ËøáÊª§Êó∂Èó¥Êï∞ÊçÆÁöÑÊû∂ÊûÑ„ÄÇ\n\nÂ∞ÜLLMÁöÑÂº∫Â§ßÂäüËÉΩ‰∏éÁü•ËØÜÂõæÁ≠âÁªìÊûÑÂåñÁü•ËØÜË°®Á§∫ÁªìÂêàËµ∑Êù•ÔºåÊòØÂÆûÁé∞‰∏öÂä°ÊàêÊûúÁöÑÈáçË¶ÅÊñπÂºèÔºåÊàë‰ª¨ËÆ§‰∏∫ËøôÁßçÊó∂Èó¥Áü•ËØÜÂõæÊû∂ÊûÑÂ∞ÜÈÄöËøáÊàêÂäüÂÆûÊñΩÊó∂Èó¥Êï∞ÊçÆÊù•Â∏ÆÂä©ÈáäÊîæÂ§ßÈáè‰∏öÂä°‰ª∑ÂÄº„ÄÇ\n\n### Êï∞ÊçÆËΩ¨Êç¢ËøáÁ®ã\n\nÈ¶ñÂÖàÔºåÊàë‰ª¨‰ΩøÁî®ClaudeÂ∞ÜËΩ¨ÂΩï‰ø°ÊÅØËΩ¨Êç¢‰∏∫‰∏éÊ®°ÂºèÂØπÈΩêÁöÑÊØè‰∏™ËΩ¨ÂΩïÁöÑÊï∞ÊçÆ‰ø°ÊÅØ„ÄÇÁªìÂêàÁªìÊûÑÂåñÂåªÁñóËÆ∞ÂΩïÁöÑ‰ø°ÊÅØÔºåËΩ¨ÂΩïË¢´ËΩ¨Âåñ‰∏∫Â¶Ç‰∏ãÊâÄÁ§∫ÁöÑJSONÊëòË¶ÅÔºö\n\n```python\nPATIENT SUMMARY\nName: Joseph Crona\nDOB: 2022‚Äì08‚Äì29\nAge: 2 years\nGender: male\nMRN: #dbfbaa\n\nCURRENT MEASUREMENTS (as of 2024‚Äì08‚Äì05)\nHeight: 84.1cm (50th percentile)\nWeight: 14.5kg (52nd percentile)\nALLERGIES\nNo known allergies\n\nIMMUNIZATIONS\n- DTaP: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì03‚Äì06, 2024‚Äì02‚Äì05\n- Hepatitis A: 2023‚Äì11‚Äì06\n- Hepatitis B: 2022‚Äì08‚Äì29, 2022‚Äì10‚Äì03, 2023‚Äì03‚Äì06\n- Hib: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì11‚Äì06\n- Influenza: 2023‚Äì03‚Äì06, 2024‚Äì08‚Äì05\n- MMR: 2023‚Äì11‚Äì06\n- PCV13: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì03‚Äì06, 2023‚Äì11‚Äì06\n- Polio: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06, 2023‚Äì03‚Äì06\n- Rotavirus: 2022‚Äì12‚Äì05, 2023‚Äì02‚Äì06\n- Varicella: 2023‚Äì11‚Äì06\n\nMEDICAL HISTORY\n- Viral sinusitis (disorder)\nOnset: 2023‚Äì03‚Äì13\nStatus: resolved\nOutcome: Resolved\n\nGROWTH & DEVELOPMENT\n- 2023‚Äì11‚Äì06: Body Weight: 12.7 kg\n- 2024‚Äì02‚Äì05: Body Height: 79 cm\n- 2024‚Äì02‚Äì05: Body Weight: 13.4 kg\n- 2024‚Äì08‚Äì05: Body Height: 84.1 cm\n- 2024‚Äì08‚Äì05: Body Weight: 14.5 kg\nDevelopment: Age-appropriate milestones met\n- Gross motor: Age appropriate\n- Fine motor: Age appropriate\n- Language: Age appropriate\n- Social: Age appropriate\n\nPREVENTIVE CARE\nWell-Child Visits:\n- 2024‚Äì08‚Äì05: 2yo well visit - Development on track\n- 2024‚Äì02‚Äì05: 1yo well visit - Development on track\n- 2023‚Äì11‚Äì06: 1yo well visit - Development on track\n- 2023‚Äì08‚Äì07: 1yo well visit - Development on track\n- 2023‚Äì05‚Äì08: 9mo well visit - Age appropriate exam completed\n- 2023‚Äì02‚Äì06: 6mo well visit - Age appropriate exam completed\n- 2022‚Äì12‚Äì05: 4mo well visit - Age appropriate exam completed\n- 2022‚Äì10‚Äì03: 2mo well visit - Age appropriate exam completed\n- 2022‚Äì08‚Äì29: Newborn visit - Normal exam\n\nFAMILY HISTORY\nMother: Healthy\nFather: Healthy\nSiblings: None documented\n\nSOCIAL HISTORY\nLiving Situation: Lives with parents\nDevelopment: Meeting age-appropriate milestones\nSleep: Age-appropriate pattern\nNutrition: Age-appropriate diet\n```\nÂÖ∂Ê¨°ÔºåÊàë‰ª¨Â∞ÜÊ≠§JSONÊ®°ÂºèÊò†Â∞ÑÂà∞WhyHowÊ®°ÂºèÔºåÁÑ∂ÂêéÂ∞ÜÊâÄÊúâ‰ø°ÊÅØÂØºÂÖ•WhyHow.AI KG Studio„ÄÇ\n\n‰ª•‰∏ãÊòØÊúÄÁªàÂä†ËΩΩÂà∞WhyHow‰∏≠ÁöÑKGÁªìÊûÑÁ§∫‰æã„ÄÇ\n\n```python\nKnowledge Graph Structure (Timeless):\n\n\nNodes:\n1. Patient Node\n  Structure: {\n      name: str,         # \"John Smith\"\n      label: \"Patient\",\n      properties: {\n          gender: str,   # FHIR gender\n          patient_type: str  # \"adult\" | \"pediatric\"\n      },\n      chunk_ids: List[str]  # Links to demographic chunks\n  }\n\n\n2. EncounterType Node\n  Structure: {\n      name: str,         # \"Well-child visit\" | \"Annual physical\"\n      label: \"EncounterType\",\n      properties: {\n          category: str,  # \"preventive\" | \"acute\" | \"chronic\"\n          specialty: str  # \"primary_care\" | \"pediatrics\" | \"emergency\"\n      },\n      chunk_ids: List[str]  # Links to visit pattern chunks\n  }\n\n\n3. Condition Node\n  Structure: {\n      name: str,         # \"Essential hypertension\"\n      label: \"Condition\",\n      properties: {\n          category: str,     # \"chronic\" | \"acute\" | \"resolved\"\n          system: str,       # \"respiratory\" | \"cardiovascular\" | etc\n          is_primary: bool   # True if primary diagnosis\n      },\n      chunk_ids: List[str]  # Links to condition history chunks\n  }\n\n\n4. Immunization Node\n  Structure: {\n      name: str,         # \"DTaP\" | \"MMR\"\n      label: \"Immunization\",\n      properties: {\n          series: str,       # \"primary\" | \"booster\"\n          target: str        # \"tetanus\" | \"measles\" | etc\n      },\n      chunk_ids: List[str]  # Links to immunization records\n  }\n\n\n5. Observation Node\n  Structure: {\n      name: str,         # \"Blood Pressure\" | \"Height\"\n      label: \"Observation\",\n      properties: {\n          category: str,     # \"vital\" | \"lab\" | \"growth\"\n          unit: str         # \"mmHg\" | \"cm\" | etc\n      },\n      chunk_ids: List[str]  # Links to measurement records\n  }\n\n\nRelations:\n1. Patient -> EncounterType\n  Triple: (Patient) -[had_encounter]-> (EncounterType)\n  - Chunk_ids link to specific visit instances\n\n\n2. Patient -> Condition\n  Triple: (Patient) -[has_condition]-> (Condition)\n  - Chunk_ids link to condition episodes\n\n\n3. Patient -> Immunization\n  Triple: (Patient) -[received]-> (Immunization)\n  - Chunk_ids link to administration records\n\n\n4. Patient -> Observation\n  Triple: (Patient) -[has_measurement]-> (Observation)\n  - Chunk_ids link to measurement instances\n\n\n5. Condition -> EncounterType\n  Triple: (Condition) -[managed_in]-> (EncounterType)\n  - Links conditions to typical encounter types\n\n\n6. Immunization -> EncounterType\n  Triple: (Immunization) -[given_during]-> (EncounterType)\n  - Links vaccines to visit types\n```\nÁ¨¨‰∏âÔºåÊàë‰ª¨ËøêË°å‰∏Ä‰∏™Ëá™ÂÆö‰πâÊèêÁ§∫Ôºå‰ª•Âú®ÊØèÊ¨°Ëá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢ÂêéÂØπ‰ªéÁü•ËØÜÂõæË∞±‰∏≠Ê£ÄÁ¥¢ÁöÑ‰∏âÂÖÉÁªÑËøõË°å‰∏ä‰∏ãÊñáÂåñ„ÄÇ\n\nÂú®ËøôÁßçÊû∂ÊûÑ‰∏ãÔºå‰∏Ä‰∏™ÊúâË∂£ÁöÑ‰∫ãÊÉÖÊòØÔºåÊàë‰ª¨Áé∞Âú®ÂèØ‰ª•ÁªßÁª≠ÂêëÁü•ËØÜÂõæË∞±‰∏≠Ê∑ªÂä†ÊúâÂÖ≥ÊÇ£ËÄÖÂ∞±ËØä„ÄÅÊÇ£ËÄÖÊ≤ªÁñóÂíåÁóÖÊÉÖÁöÑ‰ø°ÊÅØÔºåÂõ†‰∏∫ËøôÂè™ÊòØÂ∞ÜÈ¢ùÂ§ñÁöÑÂùóÊ∑ªÂä†Âà∞Áé∞Êúâ‰∏âÂÖÉÁªÑ‰∏≠ÁöÑÈóÆÈ¢ò„ÄÇÂ¶ÇÊûúÊÇ£ËÄÖÂæó‰∫ÜÊñ∞ÁñæÁóÖÔºåÂàô‰ºöÂêëÊÇ£ËÄÖËäÇÁÇπÊ∑ªÂä†È¢ùÂ§ñÁöÑConditionËäÇÁÇπ„ÄÇ\n\nËøô‰∏™ËøáÁ®ãËä±Ë¥π‰∫Ü25‰∏™ÂºÄÂèëÂ∞èÊó∂ÔºåÂèØ‰ª•ÂàÜËß£‰∏∫‰ª•‰∏ãÂá†‰∏™ÈÉ®ÂàÜÔºö\n\n* 2Â∞èÊó∂Ôºà8%ÔºâÁî®‰∫éÊü•ÁúãÂíåÁêÜËß£Êï∞ÊçÆÔºàÊé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûêÔºâ\n* 18Â∞èÊó∂Ôºà72%ÔºâÁî®‰∫éËø≠‰ª£Ê®°ÂºèÔºåÂºÑÊ∏ÖÊ•öÂõæ‰∏≠Â∫îËØ•ÂåÖÂê´Âì™‰∫õËäÇÁÇπÔºåÂì™‰∫õËäÇÁÇπÂ∫îËØ•ËøûÊé•Âà∞‰ªÄ‰πàÔºåÂ∫îËØ•Â≠òÂú®Âì™‰∫õÂùóÔºåÂ¶Ç‰ΩïËøûÊé•Âà∞ÂêÑÁßç‰∏âÂÖÉÁªÑÔºå‰ΩøÁî®‰∏ÄÁªÑÈóÆÈ¢òÊµãËØïÊ£ÄÁ¥¢ÁöÑÁ≠îÊ°àÔºåÂπ∂Áõ∏Â∫îÂú∞ËøõË°åËø≠‰ª£„ÄÇ\n* 2Â∞èÊó∂Ôºà8%ÔºâÁî®‰∫éÁºñÂÜôÂàõÂª∫Ë¶ÅÂä†ËΩΩÁöÑ‰∏âÂÖÉÁªÑÁöÑ‰ª£Á†Å\n* 3Â∞èÊó∂Ôºà12%ÔºâÁî®‰∫éÁºñÂÜôÈ™åËØÅÊ£ÄÊü•ÂíåËæìÂá∫Ê£ÄÊü•‰ª•ÊçïËé∑‰ªª‰ΩïÈîôËØØ\n\n### ÈóÆÈ¢ò‰∏éÁ≠îÊ°àÔºöÂåªÁñóËÆ∞ÂΩïÁü•ËØÜÂõæË∞±\n\nÁî®‰∫éÂú®‰ªéÁü•ËØÜÂõæË∞±‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥‰∏ä‰∏ãÊñáÂêéÊûÑÂª∫Á≠îÊ°àÁöÑÊèêÁ§∫Ôºå‰ΩøÁî®WhyHowËá™ÁÑ∂ËØ≠Ë®ÄÂõæÊü•ËØ¢ÂºïÊìé\n\n```python\n    You are an AI assistant specializing in medical records analysis. \nUse the following information to answer the user's question. \n    The information is derived from a knowledge graph of patient medical records.\n\n    Relevant Nodes (these represent patients, encounters, and conditions):\n    {node_context}\n\n    Relevant Relationships (these show connections between patients, \nencounters, and conditions):\n    {triple_context}\n\n    Relevant Medical Records:\n    {chunk_context}\n\n    Answer the question using the following steps:\n    1. Analyze the medical information, focusing on the specific topic of the \nquestion\n    2. Identify key medical events, conditions, and temporal relationships\n    3. Formulate a clear and concise answer that directly addresses the \nquestion\n    4. If there are any uncertainties in the medical information, mention \nthem explicitly\n    5. If you don't have enough information to answer confidently, say so\n    6. Consider temporal relationships between medical events\n    7. It's currently {datetime.now().strftime(\"%Y-%m-%d\")}. Consider this \nwhen interpreting dates\n    8. Maintain patient privacy by using only first names or initials when \nnecessary\n\n    Question: {question}\n```\n\n## ‰∏öÂä°‰ª∑ÂÄºÔºöÊÇ£ËÄÖÊ≤ªÁñóÂàÜÊûê\n\n### ÂéÜÂè≤ÊÇ£ËÄÖÂàÜÊûê\n\nÈóÆÈ¢òÔºö**Joseph CronaÂú®ÂÖ∂Á¨¨‰∏ÄÂπ¥Êé•Âèó‰∫ÜÂì™‰∫õÁ±ªÂûãÁöÑÂÅ•Â∫∑ÂÑøÁ´•ËÆøËßÜÂíåÂÖçÁñ´Êé•ÁßçÔºü**\n\nÂõûÁ≠îÔºö\n\n```python\nTo determine the types of well-child visits and immunizations Joseph Crona \nreceived in his first year, we need to consider the relevant medical events \nand their timing. Joseph was born in 2022, and it is currently November 9, 2024.\nTherefore, his first year would span from 2022 to 2023.\n\n**Well-Child Visits:**\n- Joseph had an encounter categorized as a \"Well child visit,\" which falls \nunder preventive care in pediatrics. This type of visit is typically part of \nroutine check-ups for children, especially in their first year.\n\n**Immunizations:**\nDuring his first year, Joseph received the following immunizations, all of \nwhich are common for pediatric patients:\n1. **Hep B, adolescent or pediatric** - Completed\n2. **Hib (PRP-OMP)** - Completed\n3. **Rotavirus, monovalent** - Completed\n4. **IPV (Inactivated Poliovirus Vaccine)** - Completed\n5. **DTaP (Diphtheria, Tetanus, and Pertussis)** - Completed\n6. **Pneumococcal conjugate PCV 13** - Completed\n\nThese immunizations are typically administered during the first year of life \nas part of the standard immunization schedule for infants.\n\nIn summary, Joseph Crona received a well-child visit and completed a series of\nstandard pediatric immunizations during his first year.\n```\nÈóÆÈ¢òÔºö**ÂØπ‰∫é‰∏≠ËÄ≥ÁÇéÊÇ£ËÄÖÔºåËÆ∞ÂΩïÁöÑÊé•Ëß¶ÂíåËßÇÂØüÁöÑÈ°∫Â∫èÊòØ‰ªÄ‰πàÔºü**\n\nÂõûÁ≠îÔºö\n\n```python\nTo address the question regarding the sequence of encounters and observations \nfor patients with otitis media, we will focus on the medical records of Miles \nDickinson, as he is the patient identified with this condition.\n\n1. **Condition Onset:**\n- Miles Dickinson was diagnosed with otitis media on June 10, 2024. The \ncondition is currently resolved.\n\n2. **Encounters:**\n- Miles had two types of encounters recorded:\n- **Well Child Visit:** This is categorized as a preventive encounter in \npediatrics.\n- **Encounter for Symptom:** This is categorized as a follow-up encounter in \nprimary care.\n\n3. **Observations:**\n- Various observations were recorded for Miles, including:\n- **Pain Severity:** Recorded multiple times with scores ranging from 0 to 4.\n- **Body Weight:** Recorded with values ranging from 3.2 kg to 8.2 kg.\n- **Head Occipital-frontal Circumference and Percentile:** Recorded with \nspecific values in cm and percentiles.\n- **Heart Rate:** Recorded with values ranging from 61 to 100 beats per minute.\n- **Respiratory Rate:** Recorded with values ranging from 12 to 16 breaths per\nminute.\n\n4. **Temporal Sequence:**\n- The otitis media diagnosis occurred on June 10, 2024. Observations and \nencounters before this date may have been related to other conditions or \nroutine check-ups. Observations and encounters after this date could be \nrelated to follow-up care for otitis media or other health assessments.\n\n5. **Conclusion:**\n- The sequence of encounters and observations for Miles Dickinson includes \npreventive and follow-up encounters, along with various health observations. \nThe specific sequence related to otitis media is not detailed in terms of exact\ndates for each observation or encounter, but the diagnosis date provides a \ntemporal marker for understanding subsequent medical activities.\n\nIf more detailed temporal data on each observation and encounter were \navailable, a more precise sequence could be established. However, based on \nthe current information, this is the overview of the sequence related to \notitis media for Miles Dickinson.\n```\n\n### ÂéÜÂè≤Â§öÊÇ£ËÄÖÂàÜÊûê\n\nÈóÆÈ¢òÔºö**ÊúâÂ§öÂ∞ëÊÇ£ËÄÖË¢´ËØäÊñ≠‰∏∫ÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇéÔºåÂÖ∏ÂûãÁöÑÂèë‰ΩúÊ®°ÂºèÊòØ‰ªÄ‰πàÔºü**\n\nÁ≠îÊ°àÔºö\n\n```python\nÊ†πÊçÆÊèê‰æõÁöÑÂåªÁñóËÆ∞ÂΩïÔºåÊúâ‰∏§‰ΩçÊÇ£ËÄÖË¢´ËØäÊñ≠‰∏∫ÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇéÔºöMaximo Swaniawski Âíå Bennie Herman„ÄÇ\n\n#### Âèë‰ΩúÊ®°ÂºèÔºö\n- **Maximo Swaniawski**Ôºö\n- ÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇéÁöÑÂèë‰ΩúÊó•ÊúüÔºö\n- 2014Âπ¥10Êúà24Êó•\n- 2015Âπ¥11Êúà7Êó•\n- 2018Âπ¥11Êúà29Êó•\n- **Bennie Herman**Ôºö\n- ÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇéÁöÑÂèë‰ΩúÊó•ÊúüÔºö\n- 2014Âπ¥10Êúà24Êó•\n- 2015Âπ¥11Êúà7Êó•\n- 2018Âπ¥11Êúà29Êó•\n\n#### ÂÖ∏ÂûãÂèë‰ΩúÊ®°ÂºèÔºö\n‰∏§‰ΩçÊÇ£ËÄÖÁöÑÂèë‰ΩúÊó•ÊúüÁõ∏ÂêåÔºåË°®ÊòéÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇéÂèë‰ΩúÁöÑÊ®°ÂºèÂèëÁîüÂú®10ÊúàÂ∫ïÊàñ11Êúà„ÄÇËøôÂèØËÉΩË°®Êòé‰∏ÄÁßçÂ≠£ËäÇÊÄßÊ®°ÂºèÔºåÂèØËÉΩ‰∏éËæÉÂÜ∑ÁöÑÂ§©Ê∞îÊàñÂÖ∂‰ªñÂèØËÉΩÂØºËá¥ÂëºÂê∏Á≥ªÁªüÁñæÁóÖÁöÑÂ≠£ËäÇÊÄßÂõ†Á¥†ÊúâÂÖ≥„ÄÇ\n\n‰∏§‰ΩçÊÇ£ËÄÖÁöÑÁóÖÊÉÖÂ∑≤ÂæóÂà∞Ëß£ÂÜ≥ÔºåË°®ÊòéÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇéÁöÑÂèë‰ΩúÊòØÊÄ•ÊÄßÁöÑÔºåËÄåÈùûÊÖ¢ÊÄßÁöÑ„ÄÇ\n```\nÈóÆÈ¢òÔºö**Âì™‰∫õÊÇ£ËÄÖÂêåÊó∂ÊÇ£ÊúâÁóÖÊØíÊÄßÈºªÁ™¶ÁÇéÂíåÊîØÊ∞îÁÆ°ÁÇéÔºå‰ªñ‰ª¨ÊúÄÊó©ÁöÑÂèë‰ΩúÊó•ÊúüÊòØ‰ªÄ‰πàÔºü**\n\nÁ≠îÊ°àÔºö\n\n```python\nË¶ÅÁ°ÆÂÆöÂì™‰∫õÊÇ£ËÄÖÂêåÊó∂ÊÇ£ÊúâÁóÖÊØíÊÄßÈºªÁ™¶ÁÇéÂíåÊîØÊ∞îÁÆ°ÁÇéÔºåÊàë‰ª¨ÈúÄË¶ÅÂàÜÊûêÊØè‰ΩçÊÇ£ËÄÖÁöÑÁõ∏ÂÖ≥ÁñæÁóÖÂèäÂÖ∂Âèë‰ΩúÊó•Êúü„ÄÇ\n\n1. **Maximo Swaniawski**Ôºö\n- ÁñæÁóÖÔºöÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇé\n- ÊîØÊ∞îÁÆ°ÁÇéÁöÑÊúÄÊó©Âèë‰ΩúÊó•ÊúüÔºö2014Âπ¥10Êúà24Êó•\n2. **Cassandra Monahan**Ôºö\n- ÁñæÁóÖÔºöÁóÖÊØíÊÄßÈºªÁ™¶ÁÇé\n- ÈºªÁ™¶ÁÇéÁöÑÊúÄÊó©Âèë‰ΩúÊó•ÊúüÔºö2014Âπ¥12Êúà12Êó•\n3. **Bennie Herman**Ôºö\n- ÁñæÁóÖÔºöÊÄ•ÊÄßÊîØÊ∞îÁÆ°ÁÇé\n- ÊîØÊ∞îÁÆ°ÁÇéÁöÑÊúÄÊó©Âèë‰ΩúÊó•ÊúüÔºö2014Âπ¥10Êúà24Êó•\n4. **Deangelo Price**Ôºö\n- ÁñæÁóÖÔºöÁóÖÊØíÊÄßÈºªÁ™¶ÁÇé\n- ÈºªÁ™¶ÁÇéÁöÑÊúÄÊó©Âèë‰ΩúÊó•ÊúüÔºö2014Âπ¥12Êúà12Êó•\n5. **Joseph Crona**Ôºö\n- ÁñæÁóÖÔºöÁóÖÊØíÊÄßÈºªÁ™¶ÁÇé\n- ÈºªÁ™¶ÁÇéÁöÑÊúÄÊó©Âèë‰ΩúÊó•ÊúüÔºö2014Âπ¥12Êúà12Êó•\n\nÊ†πÊçÆÊèê‰æõÁöÑ‰ø°ÊÅØÔºåÊ≤°ÊúâÊÇ£ËÄÖÂêåÊó∂ÊÇ£ÊúâÁóÖÊØíÊÄßÈºªÁ™¶ÁÇéÂíåÊîØÊ∞îÁÆ°ÁÇé„ÄÇÊØè‰ΩçÊÇ£ËÄÖ‰ªÖÊúâ‰∏ÄÁßçÁñæÁóÖÔºåËÄåÊ≤°ÊúâÂêåÊó∂Â≠òÂú®‰∏§Áßç„ÄÇÂõ†Ê≠§ÔºåÊ≤°ÊúâÊÇ£ËÄÖÂêåÊó∂ÂÖ∑Â§áËøô‰∏§ÁßçÁñæÁóÖÔºåÂõ†Ê≠§‰πüÊ≤°ÊúâÂçï‰∏ÄÊÇ£ËÄÖÁöÑÊúÄÊó©Âèë‰ΩúÊó•Êúü„ÄÇ\n```\n\n### Áõ∏ËæÉ‰∫é‰ªÖÂêëÈáè RAG Á≥ªÁªüÁöÑ‰ºòÂäø\n\nË∑®Â§ö‰∏™ÊÇ£ËÄÖÁöÑÂçìË∂äÂàÜÊûêÔºö\n\n* Âú®ÂÖ≥‰∫éÂì™‰∫õÊÇ£ËÄÖÂêåÊó∂ÊÇ£ÊúâÊîØÊ∞îÁÆ°ÁÇéÂíåÁóÖÊØíÊÄßÈºªÁ™¶ÁÇéÁöÑÈóÆÈ¢ò‰∏≠ÔºåÊàë‰ª¨ÂøÖÈ°ªËÉΩÂ§üÁü•ÈÅìÊüê‰∏™ÊÇ£ËÄÖÊòØÂê¶Ë¢´ËÆ∞ÂΩï‰∏∫ÊÇ£ÊúâÊàñÊú™ÊÇ£ÊúâÁâπÂÆöÁñæÁóÖ„ÄÇÁî±‰∫é‰ªÖÂêëÈáèÊêúÁ¥¢ÊòØÂÖ≥‰∫éËØÜÂà´Áõ∏ÂÖ≥ÁâáÊÆµÁöÑÔºåÂõ†Ê≠§Êó†Ê≥ïÊ£ÄÊµãÂà∞ÊÇ£ËÄÖÊòØÂê¶Á°ÆÂÆûÊ≤°ÊúâÊüêÁßçÁâπÂÆöÁñæÁóÖ„ÄÇËøôÊÑèÂë≥ÁùÄÈúÄË¶Å‰∏Ä‰∏™‰∏≠‰ªãÊï∞ÊçÆËÅöÂêàÔºåËÉΩÂ§üÊòéÁ°ÆË°®Á§∫ÊÇ£ËÄÖ X Âú®ÂÖ∂ÂêçÂ≠ó‰∏ãÊ≤°Êúâ‚ÄúÁ≥ñÂ∞øÁóÖ‚ÄùËäÇÁÇπ„ÄÇ\n\nÂ§öËΩ¨ÂΩïÊú¨ÂàÜÊûê‰∏é RAGÔºö\n\n* Âú®ÂÖ≥‰∫éËøàÂ∞îÊñØÂèäÂÖ∂ËøáÂéª‰∏ÄÂπ¥Â§öÊ¨°Â∞±ËØäÁöÑÈóÆÈ¢ò‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞Ëøô‰∫õÊÉÖÂÜµË∑®Ë∂ä‰∫ÜÂ§öÊ¨°Â∞±ËØäÂíåÂ§ö‰∏™ËΩ¨ÂΩïÊú¨„ÄÇËøôÊÑèÂë≥ÁùÄÈúÄË¶Å‰∏Ä‰∏™‰∏≠‰ªãÊï∞ÊçÆËÅöÂêàÔºåËÉΩÂ§üÊò†Â∞ÑÂá∫ÊÇ£ËÄÖÂèäÂÖ∂ÈöèÊó∂Èó¥Á¥ØÁßØÁöÑÂ∞±ËØäÂíåËßÇÂØüËÆ∞ÂΩï„ÄÇ\n\nWhyHow.AI Êèê‰æõÁªìÊûÑÂåñÁü•ËØÜ„ÄÅÁü•ËØÜÂõæË∞±ÂíåÊõ¥ÂèØÈù†ÁöÑ‰ª£ÁêÜ RAG Ëß£ÂÜ≥ÊñπÊ°àÁöÑÂ∑•ÂÖ∑„ÄÅÊúçÂä°ÂíåÊµÅÁ®ã„ÄÇÂ¶ÇÊûúÊÇ®ÊúâÂÖ¥Ë∂£Êé¢Á¥¢Êàë‰ª¨ÁöÑ‰ªª‰ΩïÂ∑•ÂÖ∑Ôºà[KG Studio](https://proxy.rifx.online/https://readmedium.com/whyhow-ai-kg-studio-platform-beta-rag-native-graphs-1105e5a84ff2)Ôºå[Áü•ËØÜË°®\\[ÂºÄÊ∫ê\\]](https://proxy.rifx.online/https://readmedium.com/knowledge-table-multi-document-rag-extraction-memory-ec08450e858f)ÔºâÂíåÊúçÂä°ÔºåËØ∑ÈöèÊó∂[‰∏éÊàë‰ª¨ËÅäÂ§©](https://proxy.rifx.online/https://calendly.com/whyhowai/intro-call-whyhow-ai)„ÄÇ\n\nÂ¶ÇÊûúÊÇ®Ê≠£Âú®ËÄÉËôë„ÄÅÊ≠£Âú®ËøõË°åÊàñÂ∑≤ÁªèÂú® RAG ‰∏≠Êï¥ÂêàÁü•ËØÜÂõæË∞±‰ª•ÊèêÈ´òÂáÜÁ°ÆÊÄß„ÄÅËÆ∞ÂøÜÂíåÁ°ÆÂÆöÊÄßÔºåËØ∑ÂÖ≥Ê≥®Êàë‰ª¨ÁöÑÊñ∞ÈóªÈÄöËÆØ[WhyHow.AI](https://proxy.rifx.online/https://whyhow.ai/)ÔºåÊàñÂä†ÂÖ•Êàë‰ª¨ÂÖ≥‰∫é RAG ‰∏≠ËßÑÂàô„ÄÅÁ°ÆÂÆöÊÄßÂíåÁü•ËØÜÂõæË∞±ÁöÑËÆ®ËÆ∫ÔºåÊ¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑ[Discord](https://proxy.rifx.online/https://discord.gg/9bWqrsxgHr)„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/chatgpt-vision-turns-a-picture-into-1000-words-24858615fa28","frontmatter":{"title":"ChatGPT Vision Â∞ÜÂõæÁâáËΩ¨Âåñ‰∏∫ 1000 ‰∏™Â≠ó","meta_title":"ChatGPT Vision Â∞ÜÂõæÁâáËΩ¨Âåñ‰∏∫ 1000 ‰∏™Â≠ó","description":"‰ª•ÂèäÂ¶Ç‰ΩïÊääËøô‰∫õËØùÂèòÊàêÁîüÊÑè","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*lS5aPVDrsCFFnBYz","categories":["Programming","Marketing","Generative AI"],"author":"Rifx.Online","tags":["automation","content","GPT","MAKE","photos"],"draft":false,"slug":"blog/chatgpt-vision-turns-a-picture-into-1000-words-24858615fa28"},"content":"\n\n\n### Â¶Ç‰ΩïÂ∞ÜËøô‰∫õÊñáÂ≠óËΩ¨Âåñ‰∏∫ÂïÜ‰∏ö‰ª∑ÂÄº\n\nÊàëÊúâËøô‰∏™ÊÉ≥Ê≥ïÂø´ÂçÅÂπ¥‰∫Ü„ÄÇ‰∏ÄÂàáÂßã‰∫éÊàëÊê≠Âª∫ÁΩëÁ´ôÁöÑÊó∂ÂÄôÔºå‰∏Ä‰ΩçÊóÖÈ¶ÜËÄÅÊùøÁªôÊàëÂèë‰∫Ü‰∏ÄÊ†πË£ÖÊª°ËøëÂçÉÂº†ÁÖßÁâáÁöÑUÁõòÔºåËøòÊúâ‰∏ÄÁõí35mmÁöÑÁÖßÁâáËÆ©ÊàëÊâ´Êèè„ÄÇ\n\n\n\n> Ëøô‰∫õÈÉΩÊòØ**ÊÉä‰∫∫ÁöÑÁÖßÁâá**‚Äî‚ÄîÂÆ¢‰∫∫‰ª¨Â±ïÁ§∫‰ªñ‰ª¨ÁöÑÁèçË¥µÊçïËé∑„ÄÅ‰ª§‰∫∫ÊÉäÂèπÁöÑÊπñÊôØÔºå‰ª•ÂèäÂêëÂØº‰ª¨Â∏¶È¢ÜÁöÑÊà∑Â§ñÂÜíÈô©„ÄÇ\n\n> ÊàëÁü•ÈÅìÔºåÂ¶ÇÊûúÊàë‰ª¨ËÉΩÊääËøô‰∫õÁÖßÁâáÊîæÂà∞ÁΩë‰∏äÔºåÂÆÉ‰ª¨Â∞Ü‰∏∫ÊóÖÈ¶ÜÂàõÈÄ†‰∏ÄÂú∫**Âè£Á¢ë**Ëê•ÈîÄÁöÑÊµ™ÊΩÆ„ÄÇ\n\n‰ΩÜ‰∫ãÊÉÖÂèòÂæóÂ§çÊùÇ‰∫ÜÔºöÊØèÂº†ÁÖßÁâáÈÉΩÈúÄË¶Å‰∏Ä‰∏™Áã¨ÁâπÁöÑÊèèËø∞„ÄÅÈÄÇÂΩìÁöÑÊ†áÁ≠æ„ÄÅ‰∏ÄÁØáÂçöÂÆ¢ÊñáÁ´†ÂíåÁ§æ‰∫§Â™í‰ΩìÁöÑ‰∏ä‰º†„ÄÇËÄå‰∏îÂá†‰πéÊúâ‰∏ÄÂçÉÂº†ÁÖßÁâáÔºÅ\n\nÊâÄÈúÄÁöÑÊó∂Èó¥ÂíåÊàêÊú¨‰ª§‰∫∫ÈúáÊÉä„ÄÇ‰∏∫Êï∞ÁôæÂº†È±ºÁ±ªÁÖßÁâáÂÜôËØ¥ÊòéÔºüËøôË∂≥‰ª•ËÆ©‰ªª‰Ωï‰∫∫Â§¥Êôï„ÄÇÂõ†Ê≠§ÔºåËøô‰∏™‰ºüÂ§ßÁöÑÊÉ≥Ê≥ï‰ªçÁÑ∂Âè™ÊòØ‰∏Ä‰∏™ÊÉ≥Ê≥ï„ÄÇ\n\nÂø´ËøõÂà∞‰ªäÂ§©„ÄÇÁé∞Âú®ÔºåÂÄüÂä©Ëá™Âä®ÂåñÁöÑÂäõÈáèÔºåÊàëÂ∞ÜËøô‰∏™ÊÉ≥Ê≥ïÂèò‰∏∫Áé∞ÂÆû„ÄÇ\n\nÊàëÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Ëá™Âä®ÂåñÂÜÖÂÆπÂàõ‰ΩúÁ≥ªÁªüÔºåÂ∏ÆÂä©ÊóÖÈ¶ÜÂ∞ÜÊóßÁÖßÁâáËΩ¨Âåñ‰∏∫Âºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ãÔºåÂèØ‰ª•ËΩªÊùæÂú®Á∫øÂèëÂ∏É„ÄÇ\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜÂ∏¶‰Ω†‰∫ÜËß£ÊàëÊûÑÂª∫Ëøô‰∏™Á≥ªÁªüÁöÑÁ°ÆÂàáÊ≠•È™§Ôºå‰ª•Âèä‰Ω†Â¶Ç‰ΩïÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºå‰ª•ËäÇÁúÅÊó∂Èó¥Âπ∂‰øùÂ≠ò‰Ω†ÊóÖÈ¶ÜÁöÑÂéÜÂè≤„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5GBorUl_PfqiLnSW6-Nsjg.png)\n\n## Á¨¨‰∏ÄÊ≠•ÔºöÊî∂ÈõÜÊÇ®ÊóÖÈ¶ÜÁöÑÁã¨Áâπ‰ø°ÊÅØ\n\nËÆæÁΩÆÊ≠§Ëá™Âä®ÂåñÁöÑÁ¨¨‰∏ÄÊ≠•ÊòØÊî∂ÈõÜÊâÄÊúâ‰ΩøÊÇ®ÁöÑÊóÖÈ¶Ü‰∏é‰ºó‰∏çÂêåÁöÑ‰ø°ÊÅØÂíåËµÑ‰∫ß„ÄÇÂØπÊàëÊù•ËØ¥ÔºåËøôÊ∂âÂèäÂà∞Êî∂ÈõÜËÉΩÂ§ü‰ΩøÊàë‰ª¨ÁöÑÂÜÖÂÆπËÑ±È¢ñËÄåÂá∫ÁöÑÁªÜËäÇ„ÄÇËÄÉËôë‰∏Ä‰∏ãÊÇ®ÊóÖÈ¶ÜÊèê‰æõÁöÑÂÖ≥ÈîÆ‰ΩìÈ™åÔºå‰æãÂ¶ÇÈíìÈ±º‰πãÊóÖ„ÄÅÊú¨Âú∞ÂÜíÈô©ÊàñÁã¨ÁâπÁöÑËÆæÊñΩ„ÄÇËøô‰∫õÁªÜËäÇÂ∞Ü‰ΩøÊÇ®ÁöÑÂÜÖÂÆπÊõ¥ÂÖ∑‰∏™‰∫∫ÊÄßÂíåÂê∏ÂºïÂäõ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4QX4oGCYK5djc9EZuE9-EA.png)\n\nÊé•‰∏ãÊù•ÔºåÊî∂ÈõÜÊóßÁÖßÁâá‚Äî‚Äî‰ªéËøáÂéªÂÆ¢‰∫∫ÁöÑ‰ΩìÈ™åÂà∞ÊóÖÈ¶ÜÂë®Âõ¥ÁöÑËá™ÁÑ∂È£éÂÖâ„ÄÇ\n\nÂú®ÊàëÁöÑÂÆûÈ™å‰∏≠ÔºåÊàëÊúÄÂàù‰ΩøÁî®‰∫ÜAIÁîüÊàêÁöÑÂõæÂÉèÔºå‰ΩÜÈöèÂêéÊàë‰ª¨FacebookÈ°µÈù¢ÁöÑ‰∏Ä‰ΩçÁ≤â‰∏ùÂèëÈÄÅ‰∫Ü‰∏Ä‰∫õÁÖßÁâá„ÄÇÊàëËØ∑Ê±Ç‰ªñÂÖÅËÆ∏Êàë‰ΩøÁî®Ëøô‰∫õÁÖßÁâáÔºå‰ªñÈùûÂ∏∏ÂñúÊ¨¢ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PuwLsJ2EuOYOLzXwUvn0cQ.png)\n\nÂ¶ÇÊûúÊÇ®ÊúâËøôÊ†∑ÁöÑÁÖßÁâáÈõÜÔºåËØ∑Â∞ÜÂÆÉ‰ª¨Êï¥ÁêÜÂà∞Google DriveÊñá‰ª∂Â§π‰∏≠„ÄÇËøôÂ∞Ü‰ΩøÊÇ®Âú®Á®çÂêéÂ∞ÜÂÆÉ‰ª¨ËæìÂÖ•Ëá™Âä®ÂåñÁ≥ªÁªüÊó∂Êõ¥Âä†Êñπ‰æø„ÄÇÈô§‰∫ÜÁÖßÁâá‰πãÂ§ñÔºåËøòÂàõÂª∫‰∏Ä‰∏™Google SpreadsheetÔºå‰ª•‰æøËÆ∞ÂΩïÊØèÂº†ÂõæÂÉèÁöÑËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇÊÇ®ÁöÑÁîµÂ≠êË°®Ê†ºÂ∫îÂåÖÊã¨Ôºö\n\n* ÂõæÂÉèURLÔºàÊù•Ëá™ÊÇ®ÁöÑGoogle DriveÊñá‰ª∂Â§πÔºâ\n* ÊóÖÈ¶ÜËØ¶ÊÉÖÔºà‰æãÂ¶ÇÈíìÈ±ºÂêëÂØº„ÄÅÁâπÂà´Ê¥ªÂä®Ôºâ\n* ‰ªª‰ΩïÁõ∏ÂÖ≥ÁöÑÊïÖ‰∫ãÊàñÊèèËø∞ÔºåÂèØ‰ª•‰∏éÁÖßÁâá‰∏ÄËµ∑‰ΩøÁî®\n\nËøôÁúãËµ∑Êù•ÂèØËÉΩÊòØÈ¢ùÂ§ñÁöÑÂ∑•‰ΩúÔºå‰ΩÜÂØπ‰∫éÂ∏ÆÂä©Ëá™Âä®ÂåñÁ≥ªÁªüÁ®çÂêéÂàõÂª∫ÊúâÊÑè‰πâÁöÑÂÜÖÂÆπËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n## Á¨¨2Ê≠•ÔºöÊûÑÂª∫Ëá™Âä®ÂåñËìùÂõæ\n\n‰∏ÄÊó¶ÊÇ®Êî∂ÈõÜ‰∫ÜÊâÄÊúâËµÑ‰∫ßÔºåÂ∞±ÂèØ‰ª•ÂºÄÂßãËÆæÁΩÆËá™Âä®ÂåñËìùÂõæ„ÄÇÊàë‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ [MAKE](https://www.make.com/en/register?pc=saleprice) ÁöÑËá™Âä®ÂåñÂπ≥Âè∞„ÄÇÂ¶ÇÊûúÊÇ®‰ª•Ââç‰ªéÊú™Êé•Ëß¶ËøáËá™Âä®ÂåñÔºåËØ∑‰∏çË¶ÅÊãÖÂøÉ‚Äî‚ÄîËøôÊØîÂê¨Ëµ∑Êù•Ë¶ÅÁÆÄÂçïÂæóÂ§ö„ÄÇ\n\n‚Ä¶‚Ä¶ÊÇ®ÂèØ‰ª•Âú®Êàë‰ª¨ÁöÑ7Â§©ËØïÁî®‰∏≠**ÂÖçË¥π**Ëé∑ÂèñÊàëÊâÄÊúâÁªèËøáÈ™åËØÅÁöÑËìùÂõæ [free](https://whop.com/ai-businessplans)„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ArzS71K2fJf4EfCg5y3BPQ.png)\n\nÈ¶ñÂÖàÔºåÂ§çÂà∂‰∏Ä‰∏™Áé∞ÊúâÁöÑËá™Âä®ÂåñÊ®°ÊùøÔºåÊØîÂ¶Ç‰∏Ä‰∏™ÂèëÂ∏ÉÂ§©Ê∞îÊõ¥Êñ∞Âà∞Á§æ‰∫§Â™í‰ΩìÁöÑÊ®°Êùø„ÄÇÊàëÊúâ‰∏Ä‰∏™Â§©Ê∞îËá™Âä®ÂåñÔºåÊâÄ‰ª•Êàë‰ª•Ê≠§‰∏∫Âü∫Á°ÄÔºåÂéªÊéâ‰∫Ü‰∏çÂøÖË¶ÅÁöÑÈÉ®ÂàÜ„ÄÇÊÇ®Â∏åÊúõÊúâ‰∏Ä‰∏™Âπ≤ÂáÄÁöÑÂ∑•‰ΩúÁéØÂ¢ÉÔºåÂõ†Ê≠§ËØ∑Âà†Èô§‰ªª‰Ωï‰∏çÈÄÇÁî®‰∫éÊÇ®Â∞èÂ±ãÁöÑÊ®°ÂùóÔºå‰æãÂ¶ÇÂ§©Ê∞îÊõ¥Êñ∞ÊàñÊÇ®‰∏ç‰ºö‰ΩøÁî®ÁöÑÈ¢ùÂ§ñÁ§æ‰∫§Â™í‰ΩìÊ∏†ÈÅì„ÄÇ\n\nÁé∞Âú®ÔºåÊòØÊó∂ÂÄôËÆ©Ëá™Âä®ÂåñÊõ¥ÂÖ∑‰ΩìÂú∞ÈÄÇÂ∫îÊÇ®ÁöÑÂ∞èÂ±ã‰∫Ü„ÄÇ\n\n## Á¨¨3Ê≠•Ôºö‰∏∫ÊÇ®ÁöÑÂ∞èÂ±ãÂÆöÂà∂Ëá™Âä®Âåñ\n\nÂú®Âü∫Êú¨ÁªìÊûÑÂª∫Á´ã‰πãÂêéÔºåÈÄöËøáÊ∑ªÂä†ÁâπÂÆö‰∫éÂ∞èÂ±ãÁöÑÂÜÖÂÆπÊù•ÂÆöÂà∂Ëá™Âä®Âåñ„ÄÇËøôÂ∞±ÊòØÊÇ®Âú®Á¨¨1Ê≠•‰∏≠Êî∂ÈõÜÁöÑÁªÜËäÇÂèëÊå•‰ΩúÁî®ÁöÑÂú∞Êñπ„ÄÇËæìÂÖ•ÊÇ®ÁöÑÂ∞èÂ±ãÊèèËø∞ÔºåÊ∑ªÂä†ËøáÂéªÂÜíÈô©ÁöÑÊïÖ‰∫ãÔºåÂπ∂ËûçÂÖ•ÂΩìÂú∞ÊèêÁ§∫„ÄÇÁ°Æ‰øùÂåÖÂê´ÊúâÂä©‰∫éÊÇ®ÁöÑÂÜÖÂÆπÂú®ÁΩë‰∏äË¢´Ê≥®ÊÑèÂà∞ÁöÑÂÖ≥ÈîÆËØç„ÄÇ\n\nÊé•‰∏ãÊù•ÔºåÈÖçÁΩÆËá™Âä®Âåñ‰ª•‰ªéÊÇ®ÁöÑGoogle DriveÊñá‰ª∂Â§π‰∏≠ÊèêÂèñÁÖßÁâáÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨‰∏éÁîµÂ≠êË°®Ê†º‰∏≠ÁöÑÁõ∏Â∫îÊèèËø∞ÂåπÈÖç„ÄÇËøôÁ°Æ‰øù‰∫ÜÊ≠£Á°ÆÁöÑÂõæÂÉè‰∏éÊ≠£Á°ÆÁöÑÊïÖ‰∫ãÈÖçÂØπ„ÄÇ\n\nËøôÈáåÊòØÈ≠îÊ≥ïÂèëÁîüÁöÑÂú∞ÊñπÔºöÊàëÂ∞ÜGPTÔºà‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°ÂûãAIÔºâÈõÜÊàêÂà∞Ëá™Âä®Âåñ‰∏≠„ÄÇGPTÂàÜÊûêÊØèÂº†ÁÖßÁâáÔºåÂπ∂Ê†πÊçÆÊÇ®Êèê‰æõÁöÑÁªÜËäÇÁîüÊàêÁã¨ÁâπÁöÑÂÜÖÂÆπ„ÄÇ\n\n‰æãÂ¶ÇÔºåÂ¶ÇÊûúÁÖßÁâáÊòæÁ§∫‰∏Ä‰ΩçÂÆ¢‰∫∫ÈíìÂà∞‰∫Ü‰∏ÄÊù°Â§ßÈ±ºÔºåGPTÂèØ‰ª•ÂàõÂª∫‰∏ÄÁØáÂÖ≥‰∫éËØ•ÁâπÂÆöÁªèÂéÜÁöÑÂ∏ñÂ≠êÔºåÂåÖÊã¨ÂÖ≥‰∫éÈíìÈ±ºÂêëÂØº„ÄÅÈ±ºÁöÑÁßçÁ±ªÔºåÁîöËá≥ÊòØÂØπÊú™Êù•Ê∏∏ÂÆ¢ÁöÑÂª∫ËÆÆ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wySL0TxoNTFICejPsJOOcA.png)\n\n## Á¨¨4Ê≠•ÔºöËá™Âä®ÂèëÂ∏ÉÂà∞Á§æ‰∫§Â™í‰ΩìÂíåMedium\n\n‰∏ÄÊó¶ÂÜÖÂÆπÁîüÊàêÔºåÂ∞±ÂèØ‰ª•ÂºÄÂßãËá™Âä®ÂèëÂ∏ÉËøáÁ®ã„ÄÇÊàëËøûÊé•‰∫ÜÊàë‰ª¨ÁöÑMediumË¥¶Êà∑Ôºå‰ª•‰æøGPTÁîüÊàêÁöÑÊñáÁ´†ÂèØ‰ª•Áõ¥Êé•‰∏ä‰º†‰∏∫ËçâÁ®øÔºåÂáÜÂ§áÂÆ°Ê†∏„ÄÇMediumÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÈÄÇÂêàÈïøÊ†ºÂºèÂÜÖÂÆπÁöÑÂπ≥Âè∞ÔºåÊØîÂ¶ÇÂçöÂÆ¢ÊñáÁ´†ÊàñËØ¶ÁªÜÁöÑÂÆ¢Â∫ßÊïÖ‰∫ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*56OzNVMIxw9sJKBn1jkriQ.png)\n\nÂØπ‰∫éËæÉÁü≠ÁöÑÂÜÖÂÆπÔºåÊØîÂ¶ÇÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠êÔºåËá™Âä®ÂåñÈìæÊé•Âà∞Êàë‰ª¨ÁöÑFacebookÂíåTwitterË¥¶Êà∑„ÄÇÁ≥ªÁªüÊó®Âú®‰ªéËæÉÈïøÁöÑÊñáÁ´†‰∏≠ÂàõÂª∫ÁâáÊÆµÔºåÈùûÂ∏∏ÈÄÇÂêàÂø´ÈÄüÁöÑÁ§æ‰∫§Â™í‰ΩìÊõ¥Êñ∞„ÄÇÊÇ®ËøòÂèØ‰ª•ÈÖçÁΩÆËá™Âä®Âåñ‰ª•Ëá™Âä®ÂèëÂ∏ÉÊàñÂÆâÊéíÁâπÂÆöÊó∂Èó¥ÁöÑÂ∏ñÂ≠ê„ÄÇ\n\nËøô‰∏™Á≥ªÁªüÁöÑÁæéÂ¶ô‰πãÂ§ÑÂú®‰∫éÔºå‰∏ÄÊó¶ÂÜÖÂÆπËé∑ÂæóÊâπÂáÜÔºåËá™Âä®ÂåñÂ∞±‰ºöÂ§ÑÁêÜ‰ªéÂèëÂ∏ÉÂà∞ÂÆâÊéíÁöÑÊâÄÊúâ‰∫ãÂä°„ÄÇËøôÊòØ‰∏Ä‰∏™Êó†ÈúÄÊâãÂä®Âπ≤È¢ÑÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂèØ‰ª•‰øùÊåÅÊÇ®ÁöÑÂú®Á∫øÂ≠òÂú®Ê¥ªË∑ÉÔºåËÄåÊó†ÈúÄÊåÅÁª≠ÂÖ≥Ê≥®„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rym300CevwmoA4_pvYybqQ.png)\n\n## Á¨¨5Ê≠•ÔºöÊµãËØïÂíåÂæÆË∞É\n\nÁé∞Âú®Ëá™Âä®ÂåñÂ∑≤ÁªèÂà∞‰ΩçÔºåÂú®‰∏äÁ∫ø‰πãÂâçËøõË°åÊµãËØïÊòØÂæàÈáçË¶ÅÁöÑ„ÄÇÊàëËøõË°å‰∫ÜÂá†Ê¨°ÊµãËØïÂèëÂ∏ÉÔºå‰ª•Á°Æ‰øù‰∏ÄÂàáÊåâÈ¢ÑÊúüÂ∑•‰Ωú„ÄÇËá™Âä®ÂåñÊãâÂèñ‰∫ÜÊ≠£Á°ÆÁöÑÁÖßÁâáÔºåÁîüÊàê‰∫ÜÂºï‰∫∫ÂÖ•ËÉúÁöÑÂÜÖÂÆπÔºåÂπ∂È°∫Âà©Âú∞ÂèëÂ∏ÉÂà∞MediumÂíåÁ§æ‰∫§Â™í‰Ωì‰∏ä„ÄÇ\n\nÂú®ÊµãËØïËøáÁ®ã‰∏≠ÔºåÊàëËøõË°å‰∫ÜÂ∞èÁöÑË∞ÉÊï¥Ôºå‰æãÂ¶Ç‰øÆÊîπÊ†áÈ¢òÊàñ‰ºòÂåñGPTÊèêÁ§∫Ôºå‰ª•Á°Æ‰øùÂÜÖÂÆπ‰∏éÊàë‰ª¨ÊóÖÈ¶ÜÁöÑËØ≠Ê∞îÂíåÊïÖ‰∫ãÂÆåÁæéÂ•ëÂêà„ÄÇ\n\n‰∏ÄÊó¶‰∏ÄÂàáÈÉΩË∞ÉÊï¥Âà∞‰ΩçÔºåÊàëÂ∞±ÂèØ‰ª•ÂàõÂª∫Ê∫êÊ∫ê‰∏çÊñ≠ÁöÑÊñ∞ÂÜÖÂÆπÔºå‰øùÊåÅÊàë‰ª¨ÁöÑÂèó‰ºóÂèÇ‰∏é„ÄÇ\n\n## ‰∏Ä‰∏™ÂÆûÈôÖÈ°πÁõÆÁöÑÊµãËØï\n\n‰∏∫‰∫ÜÁªôÊÇ®‰∏Ä‰∏™ÂÆûÈôÖÁöÑ‰æãÂ≠êÔºåËØ∑Êü•Áúã [iFish Canada Facebook È°µÈù¢](https://facebook.com/ifishcanada)„ÄÇ\n\nËØ•È°πÁõÆÊºîÁ§∫‰∫ÜËá™Âä®ÂåñÂú®Áé∞ÂÆûÁîüÊ¥ª‰∏≠ÁöÑÂ∑•‰ΩúÊñπÂºè„ÄÇ\n\nÁ≥ªÁªü‰ªéÊàë‰ª¨ÁöÑÂÖ≥Ê≥®ËÄÖÈÇ£ÈáåËé∑Âèñ‰ªñ‰ª¨Âú®Âä†ÊãøÂ§ßÈíìÈ±ºÊóÖË°å‰∏≠Êèê‰∫§ÁöÑÁÖßÁâáÔºåÈÄöËøá GPT Â§ÑÁêÜÔºåÂπ∂ÁîüÊàêÁã¨ÁâπÁöÑÂ∏ñÂ≠êÔºåÂ±ïÁ§∫ÁÖßÁâáÂèäÂÖ∂‰ΩúËÄÖÁöÑÁªèÂéÜ‚Äî‚ÄîÂú®Êàë‰ª¨ÁöÑ‰æãÂ≠ê‰∏≠ÔºåËøô‰∫õÂ∏ñÂ≠ê‰∏éÊàë‰ª¨ËôöÊûÑÁöÑÊóÖÈ¶ÜÁöÑ‰º†ËØ¥Áõ∏ÁªìÂêà„ÄÇ\n\nÂÜÖÂÆπ‰∏∞ÂØå„ÄÅÂºï‰∫∫ÂÖ•ËÉúÔºåÊúÄÈáçË¶ÅÁöÑÊòØ‚Äî‚ÄîËá™Âä®Âåñ„ÄÇ\n\nÊõæÁªèÁúã‰ºº‰∏çÂèØËÉΩÁöÑ‰ªªÂä°Áé∞Âú®Êàê‰∏∫Áé∞ÂÆûÔºåËäÇÁúÅ‰∫ÜÊï∞Áôæ‰∏™Â∞èÊó∂ÁöÑÊó∂Èó¥ÔºåÂπ∂ËÆ©Êàë‰ª¨ËÉΩÂ§üÂàÜ‰∫´ÈÇ£‰∫õËÆ©Êàë‰ª¨ÁöÑÈíìÈ±ºÁÖßÁâáË¥°ÁåÆËÄÖÊÑüÂà∞Ë¢´ËÆ§ÂèØÂíåÊ¨£ËµèÁöÑÊïÖ‰∫ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Pe-hBjGCN1qbkjLl6cmTmQ.png)\n\n## Á¨¨6Ê≠•ÔºöÁõëÊéß„ÄÅË∞ÉÊï¥ÂíåÊàêÈïø\n\nÂç≥‰ΩøÁ≥ªÁªüÂèØ‰ª•Ëá™Âä®ËøêË°åÔºåÁõëÊéßÁªìÊûúÂπ∂ÈöèÁùÄÊó∂Èó¥ËøõË°åË∞ÉÊï¥‰ªçÁÑ∂ÂæàÈáçË¶Å„ÄÇ\n\nÊàë‰ºöÊü•ÁúãÂì™‰∫õÂ∏ñÂ≠êËé∑Âæó‰∫ÜÊúÄÂ§öÁöÑ‰∫íÂä®ÔºåÂπ∂Ë∞ÉÊï¥GPTÊèêÁ§∫‰ª•ÊîπÂñÑÊú™Êù•ÁöÑÂÜÖÂÆπ„ÄÇËøôÁßçÊåÅÁª≠ÁöÑÂæÆË∞ÉÁ°Æ‰øùÊàë‰ª¨ÁöÑÂú®Á∫øÂ≠òÂú®‰øùÊåÅÊñ∞È≤úÔºåÂπ∂ÁªßÁª≠Âê∏ÂºïÊñ∞ËÆøÂÆ¢„ÄÇ\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊÇ®Â¶Ç‰ΩïËÉΩÂ§ü‰øùÊä§ÊÇ®ÁöÑÂ∞èÂ±ãÈÅó‰∫ßÔºåÂàÜ‰∫´ÈÇ£‰∫õÂèØËÉΩ‰ºöË¢´ÈÅóÂøòÁöÑÂõûÂøÜÔºåÂπ∂‰ª•‰∏ÄÁßçÁé∞‰ª£ËÄåÂº∫Â§ßÁöÑÊñπÂºèÁîüÊàêÂè£Á¢ëËê•ÈîÄ„ÄÇ\n\n## ÂçÅÂπ¥ÁöÑÂä™Âäõ ‚Äî Áé∞Âú®‰Ω†ÂèØ‰ª•Âä†ÂÖ•Êàë\n\nÁªèËøáÂ§öÂπ¥ÁöÑÊ¢¶ÊÉ≥ÔºåËá™Âä®ÂåñËøô‰∏™ËøáÁ®ãÁªà‰∫éÊàê‰∏∫Áé∞ÂÆû„ÄÇÁ≥ªÁªüÂ∑≤ÁªèÊäïÂÖ•‰ΩøÁî®ÔºåÁªìÊûúÂ∞Ü‰∏çË®ÄËÄåÂñª„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*135_nP0nL6NrT_O7JxIk4g.png)\n\nÁé∞Âú®ÔºåÊàëÊÉ≥ÈÇÄËØ∑‰Ω†‰ΩìÈ™å‰∏Ä‰∏ãËøô‰∏™Á≥ªÁªüÔºåÈÄÇÁî®‰∫é‰Ω†ÁöÑÊóÖÈ¶ÜÊàñÂ∫¶ÂÅáÊùë„ÄÇÂ¶ÇÊûú‰Ω†ÊõæÁªèÊÑüÂà∞Ë¢´Â∏ÇÂú∫Ëê•ÈîÄÁöÑÊó∂Èó¥ÊàñÊàêÊú¨ÂéãÂÄíÔºåÊàñËÄÖÂú®‰∏çÊñ≠ÈúÄÊ±ÇÊñ∞ÂÜÖÂÆπÁöÑÊÉÖÂÜµ‰∏ãÊÑüÂà∞Êå£ÊâéÔºå[Ëøô‰∏™Ëá™Âä®ÂåñÁ≥ªÁªü](https://whop.com/ai-businessplans)ÂèØËÉΩÂ∞±ÊòØ‰Ω†‰∏ÄÁõ¥Âú®ÂØªÊâæÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\nËÆøÈóÆ [iFish Canada](https://facebook.com/ifishcanada) ËßÇÁúãÁ≥ªÁªüÁöÑÂÆûÈôÖËøêË°åÔºåÂ¶ÇÊûú‰Ω†ÊÉ≥ÂºÄÂßãËá™Âä®ÂåñËá™Â∑±ÁöÑÂÜÖÂÆπÔºåËØ∑ÈöèÊó∂ËÅîÁ≥ªÊàë„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IJ-R1362_IWUrZ-3KyG8mw.png)\n\nÊàëÂæà‰πêÊÑèÂ∏ÆÂä©‰Ω†ÈáäÊîæËá™Âä®ÂåñÁöÑÂäõÈáèÔºåÊù•ÂèëÂ±ï‰Ω†ÁöÑÊóÖÈ¶ÜÔºåÂàÜ‰∫´‰Ω†ÁöÑÊïÖ‰∫ãÔºåÂê∏ÂºïÊñ∞ÂÆ¢‰∫∫‚Äî‚ÄîÂêåÊó∂ËäÇÁúÅ‰Ω†ÁöÑÊó∂Èó¥ÂíåÁ≤æÂäõ„ÄÇ\n\n‚´∑\n\n### ÊàëÈáçËßÜÊÇ®ÁöÑËØÑËÆ∫\n\nÊàë‰ºöÂõûÂ§çÊâÄÊúâËØÑËÆ∫ÔºåÂπ∂**‰Ωú‰∏∫ÊàëÁöÑÊÑüË∞¢**ÔºåÊàëËøò‰ºöÂú®ÈÄÇÂΩìÁöÑÂú∞ÊñπÂÖ≥Ê≥®„ÄÅÁÇπËµû„ÄÅÁ™ÅÂá∫ÂíåËØÑËÆ∫ÊÇ®ÁöÑÂÜÖÂÆπ„ÄÇÊâÄ‰ª•ËØ∑Áïô‰∏ãÊÇ®ÁöÑÊÉ≥Ê≥ï„ÄÅÈóÆÈ¢òÊàñÊàêÂäüÊïÖ‰∫ãÔºÅÊàëÂñúÊ¨¢ÈòÖËØªÂÆÉ‰ª¨ÔºÅ\n\n*ËøûÊé•* Âú® [YouTube](https://www.youtube.com/channel/UCphdP_nguu6MT3U5tsJNMsQ)„ÄÅ[X (twitter)](https://x.com/Aibusinessplans/status/1803488217079095460) Âíå [Linkedin](https://www.linkedin.com/company/ai-businessplans/) ‚Äî Â∞ùËØïÊàë‰ª¨ÁöÑ [Community](https://whop.com/ai-businessplans)„ÄÇ\n\n‰øùÊåÅÂÆâÂÖ®ÔºåÊØèÂ§©ËøàÂá∫Â∞èÊ≠•‰ºê„ÄÇ \n\nDoug\n\n## ÈòÖËØª‰∏ã‰∏ÄÊ≠• \\-\n\nüõÜ *ÊäïËµÑÂÖçË¥£Â£∞ÊòéÔºö* Âú®ÂÖÖÂàÜÂà©Áî®ÂÖçË¥πÂäüËÉΩ‰πãÂâçÔºåÊÇ®‰∏çÂ∫îÂ∞ÜËµÑÈáëÊäïÂÖ•‰ªòË¥πÂ∑•ÂÖ∑„ÄÇ*Êàë‰ª¨ÂüπËÆ≠‰∫ßÂìÅ‰∏≠ÁöÑ‰ªª‰ΩïÂÜÖÂÆπÈÉΩ‰∏çÊòØÊî∂ÁõäÁöÑÊâøËØ∫Êàñ‰øùËØÅ„ÄÇ*üëà\n\n‚òÑ Êú¨ÊñáÂåÖÂê´ÊàëÊúÄÂñúÊ¨¢ÁöÑÂÜÖÂÆπÂàõ‰ΩúËÄÖÂíåGenAIÁà±Â•ΩËÄÖÁöÑAIÂïÜ‰∏öÂ∑•ÂÖ∑ÁöÑÊé®ËçêÈìæÊé•„ÄÇ\n\nÂ¶ÇÊûúÊÇ®Ë¥≠‰π∞ÊàëÊúÄÂñúÊ¨¢ÁöÑËΩØ‰ª∂ÂíåAIÂ∑•ÂÖ∑ÔºåÊàëÂ∞Ü‰ºöËé∑Âæó‰∏ÄÂ∞èÁ¨î‰Ω£ÈáëÔºåËÄåÊÇ®Êó†ÈúÄÊîØ‰ªòÈ¢ùÂ§ñË¥πÁî®„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/choosing-between-llm-agent-frameworks-69019493b259","frontmatter":{"title":"Âú® LLM ‰ª£ÁêÜÊ°ÜÊû∂‰πãÈó¥ËøõË°åÈÄâÊã©","meta_title":"Âú® LLM ‰ª£ÁêÜÊ°ÜÊû∂‰πãÈó¥ËøõË°åÈÄâÊã©","description":"ÊûÑÂª∫ÂÆöÂà∂Âü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÂíå‰∏ªË¶Å‰ª£ÁêÜÊ°ÜÊû∂‰πãÈó¥ÁöÑÊùÉË°°„ÄÇ","date":"2024-10-29T12:57:34.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*jRMs19HqSCazE5dY","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["agents","frameworks","LangGraph","LlamaIndex","Workflows"],"draft":false,"slug":"blog/choosing-between-llm-agent-frameworks-69019493b259"},"content":"\n### ÂÆöÂà∂‰ª£Á†Å‰ª£ÁêÜ‰∏é‰∏ªË¶Å‰ª£ÁêÜÊ°ÜÊû∂‰πãÈó¥ÁöÑÊùÉË°°\n\n\n\n‰ª£ÁêÜÊ≠£Âú®ËøéÊù•‰∏Ä‰∏™ÈáçË¶ÅÊó∂Âàª„ÄÇÈöèÁùÄÂ§ö‰∏™Êñ∞Ê°ÜÊû∂ÂíåÊñ∞ÁöÑ [ÊäïËµÑ](https://foundationcapital.com/goodbye-aiops-welcome-agentsres-the-next-100b-opportunity/) ÁöÑÊ∂åÂÖ•ÔºåÁé∞‰ª£ AI ‰ª£ÁêÜÊ≠£Âú®ÂÖãÊúç [‰∏çÁ®≥ÂÆöÁöÑËµ∑Ê∫ê](https://arxiv.org/html/2405.13966v1)ÔºåËøÖÈÄüÂèñ‰ª£ RAG Êàê‰∏∫ÂÆûÊñΩ‰ºòÂÖà‰∫ãÈ°π„ÄÇÈÇ£‰πàÔºå2024 Âπ¥ÊòØÂê¶Áªà‰∫é‰ºöÊàê‰∏∫ËÉΩÂ§üÊé•ÁÆ°Êí∞ÂÜôÁîµÂ≠êÈÇÆ‰ª∂„ÄÅÈ¢ÑËÆ¢Ëà™Áè≠„ÄÅ‰∏éÊàë‰ª¨ÁöÑÊï∞ÊçÆÂØπËØùÊàñ‰ºº‰πé‰ªª‰ΩïÂÖ∂‰ªñ‰ªªÂä°ÁöÑËá™‰∏ª AI Á≥ªÁªüÁöÑÂπ¥‰ªΩÔºü\n\n‰πüËÆ∏Ôºå‰ΩÜË¶ÅËææÂà∞Ëøô‰∏ÄÁÇπËøòÊúâÂæàÂ§öÂ∑•‰ΩúË¶ÅÂÅö„ÄÇ‰ªª‰ΩïÊûÑÂª∫‰ª£ÁêÜÁöÑÂºÄÂèëËÄÖ‰∏ç‰ªÖÈúÄË¶ÅÈÄâÊã©Âü∫Á°Ä‚Äî‚Äî‰ΩøÁî®Âì™‰∏™Ê®°Âûã„ÄÅÁî®‰æãÂíåÊû∂ÊûÑ‚Äî‚ÄîËøòÈúÄË¶ÅÈÄâÊã©Âà©Áî®Âì™‰∏™Ê°ÜÊû∂„ÄÇ‰Ω†ÊòØÈÄâÊã©ÈïøÊúüÂ≠òÂú®ÁöÑ LangGraphÔºåËøòÊòØËæÉÊñ∞ÁöÑ LlamaIndex WorkflowsÔºüÊàñËÄÖ‰Ω†ÈÄâÊã©‰º†ÁªüÊñπÂºèÔºåËá™Â∑±ÁºñÂÜôÊï¥‰∏™‰ª£Á†ÅÔºü\n\nÊú¨ÊñáÊó®Âú®ËÆ©Ëøô‰∏™ÈÄâÊã©ÂèòÂæóÁÆÄÂçï‰∏Ä‰∫õ„ÄÇÂú®ËøáÂéªÂá†Âë®ÔºåÊàëÂú®‰∏ªË¶ÅÊ°ÜÊû∂‰∏≠ÊûÑÂª∫‰∫ÜÁõ∏ÂêåÁöÑ‰ª£ÁêÜÔºå‰ª•ÊäÄÊúØÂ±ÇÈù¢Ê£ÄÊü•ÊØè‰∏™Ê°ÜÊû∂ÁöÑ‰∏Ä‰∫õ‰ºòÁº∫ÁÇπ„ÄÇÊØè‰∏™‰ª£ÁêÜÁöÑÊâÄÊúâ‰ª£Á†ÅÈÉΩÂèØ‰ª•Âú® [Ëøô‰∏™Â∫ì](https://github.com/Arize-ai/phoenix/tree/main/examples/agent_framework_comparison) ‰∏≠ÊâæÂà∞„ÄÇ\n\n### ÊµãËØïÁî®‰ª£ÁêÜÁöÑËÉåÊôØ\n\nÁî®‰∫éÊµãËØïÁöÑ‰ª£ÁêÜÂåÖÊã¨ÂäüËÉΩË∞ÉÁî®„ÄÅÂ§öÁßçÂ∑•ÂÖ∑ÊàñÊäÄËÉΩ„ÄÅ‰∏éÂ§ñÈÉ®ËµÑÊ∫êÁöÑËøûÊé•Ôºå‰ª•ÂèäÂÖ±‰∫´Áä∂ÊÄÅÊàñËÆ∞ÂøÜ„ÄÇ\n\nËØ•‰ª£ÁêÜÂÖ∑Êúâ‰ª•‰∏ãËÉΩÂäõÔºö\n\n1. ‰ªéÁü•ËØÜÂ∫ìÂõûÁ≠îÈóÆÈ¢ò\n2. ‰∏éÊï∞ÊçÆÂØπËØùÔºöÂõûÁ≠îÊúâÂÖ≥LLMÂ∫îÁî®Á®ãÂ∫èÁöÑÈÅ•ÊµãÊï∞ÊçÆÁöÑÈóÆÈ¢ò\n3. Êï∞ÊçÆÂàÜÊûêÔºöÂàÜÊûêÊ£ÄÁ¥¢Âà∞ÁöÑÈÅ•ÊµãÊï∞ÊçÆ‰∏≠ÁöÑÊõ¥È´òÁ∫ßË∂ãÂäøÂíåÊ®°Âºè\n\n‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∫õÔºå‰ª£ÁêÜÂÖ∑Êúâ‰∏âÈ°πÂàùÂßãÊäÄËÉΩÔºöÂü∫‰∫é‰∫ßÂìÅÊñáÊ°£ÁöÑRAG„ÄÅÂú®Ë∑üË∏™Êï∞ÊçÆÂ∫ì‰∏äÁîüÊàêSQLÔºå‰ª•ÂèäÊï∞ÊçÆÂàÜÊûê„ÄÇ‰ª£ÁêÜÁî®Êà∑ÁïåÈù¢‰ΩøÁî®ÁÆÄÂçïÁöÑgradioÊîØÊåÅÁöÑÁïåÈù¢Ôºå‰ª£ÁêÜÊú¨Ë∫´ÊûÑÂª∫‰∏∫‰∏Ä‰∏™ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ\n\n## Âü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÔºàÊó†Ê°ÜÊû∂Ôºâ\n\nÂºÄÂèë‰ª£ÁêÜÊó∂ÔºåÊÇ®ÂèØ‰ª•ÈÄâÊã©ÂÆåÂÖ®Ë∑≥ËøáÊ°ÜÊû∂ÔºåËá™Â∑±ÊûÑÂª∫‰ª£ÁêÜ„ÄÇÂºÄÂßãËøô‰∏™È°πÁõÆÊó∂ÔºåÊàëÈááÁî®ÁöÑÂ∞±ÊòØËøôÁßçÊñπÊ≥ï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pw9-0lB5JMlVcPqo)\n\n### Á∫Ø‰ª£Á†ÅÊû∂ÊûÑ\n\n‰∏ãÈù¢ÁöÑÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÁî±‰∏Ä‰∏™Áî±OpenAIÈ©±Âä®ÁöÑË∑ØÁî±Âô®ÁªÑÊàêÔºåËØ•Ë∑ØÁî±Âô®‰ΩøÁî®ÂáΩÊï∞Ë∞ÉÁî®ÈÄâÊã©ÂêàÈÄÇÁöÑÊäÄËÉΩ„ÄÇËØ•ÊäÄËÉΩÂÆåÊàêÂêéÔºåÂÆÉ‰ºöËøîÂõûË∑ØÁî±Âô®Ôºå‰ª•‰æøË∞ÉÁî®Âè¶‰∏Ä‰∏™ÊäÄËÉΩÊàñÂìçÂ∫îÁî®Êà∑„ÄÇ\n\n‰ª£ÁêÜ‰øùÊåÅ‰∏Ä‰∏™ÊåÅÁª≠Êõ¥Êñ∞ÁöÑÊ∂àÊÅØÂíåÂìçÂ∫îÂàóË°®ÔºåÂú®ÊØèÊ¨°Ë∞ÉÁî®Êó∂ÂÆåÊï¥‰º†ÈÄíÁªôË∑ØÁî±Âô®Ôºå‰ª•‰øùÊåÅ‰∏ä‰∏ãÊñáÁöÑËøûË¥ØÊÄß„ÄÇ\n\n```python\ndef router(messages):\n    if not any(\n        isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n    ):\n        system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n        messages.append(system_prompt)\n\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=messages,\n        tools=skill_map.get_combined_function_description_for_openai(),\n    )\n\n    messages.append(response.choices[0].message)\n    tool_calls = response.choices[0].message.tool_calls\n    if tool_calls:\n        handle_tool_calls(tool_calls, messages)\n        return router(messages)\n    else:\n        return response.choices[0].message.content\n```\n\nÊäÄËÉΩÊú¨Ë∫´Âú®ÂêÑËá™ÁöÑÁ±ª‰∏≠ÂÆö‰πâÔºà‰æãÂ¶ÇÔºåGenerateSQLQueryÔºâÔºåËøô‰∫õÁ±ªÂÖ±Âêå‰øùÂ≠òÂú®‰∏Ä‰∏™SkillMap‰∏≠„ÄÇË∑ØÁî±Âô®Êú¨Ë∫´Âè™‰∏éSkillMap‰∫§‰∫íÔºå‰ΩøÁî®ÂÆÉÊù•Âä†ËΩΩÊäÄËÉΩÂêçÁß∞„ÄÅÊèèËø∞ÂíåÂèØË∞ÉÁî®ÂáΩÊï∞„ÄÇËøôÁßçÊñπÊ≥ïÊÑèÂë≥ÁùÄÂ∞ÜÊñ∞ÊäÄËÉΩÊ∑ªÂä†Âà∞‰ª£ÁêÜ‰∏≠Âè™ÈúÄÂ∞ÜËØ•ÊäÄËÉΩÁºñÂÜô‰∏∫Ëá™Â∑±ÁöÑÁ±ªÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞SkillMap‰∏≠ÁöÑÊäÄËÉΩÂàóË°®‰∏≠„ÄÇËøôÈáåÁöÑÊÉ≥Ê≥ïÊòØ‰ΩøÊ∑ªÂä†Êñ∞ÊäÄËÉΩÂèòÂæóÁÆÄÂçïÔºåËÄå‰∏çÂπ≤Êâ∞Ë∑ØÁî±Âô®‰ª£Á†Å„ÄÇ\n\n```python\nclass SkillMap:\n    def __init__(self):\n        skills = [AnalyzeData(), GenerateSQLQuery()]\n\n        self.skill_map = {}\n        for skill in skills:\n            self.skill_map[skill.get_function_name()] = (\n                skill.get_function_dict(),\n                skill.get_function_callable(),\n            )\n\n    def get_function_callable_by_name(self, skill_name) -> Callable:\n        return self.skill_map[skill_name][1]\n\n    def get_combined_function_description_for_openai(self):\n        combined_dict = []\n        for _, (function_dict, _) in self.skill_map.items():\n            combined_dict.append(function_dict)\n        return combined_dict\n\n    def get_function_list(self):\n        return list(self.skill_map.keys())\n\n    def get_list_of_function_callables(self):\n        return [skill[1] for skill in self.skill_map.values()]\n\n    def get_function_description_by_name(self, skill_name):\n        return str(self.skill_map[skill_name][0][\"function\"])\n```\n\nÊÄª‰ΩìËÄåË®ÄÔºåËøôÁßçÊñπÊ≥ïÁõ∏ÂØπÁÆÄÂçïÊòìË°åÔºå‰ΩÜ‰πüÈù¢‰∏¥‰∏Ä‰∫õÊåëÊàò„ÄÇ\n\n### Á∫Ø‰ª£Á†Å‰ª£ÁêÜÁöÑÊåëÊàò\n\nÁ¨¨‰∏Ä‰∏™ÈöæÁÇπÂú®‰∫éÊûÑÂª∫Ë∑ØÁî±Âô®Á≥ªÁªüÊèêÁ§∫„ÄÇÈÄöÂ∏∏Ôºå‰∏äËø∞Á§∫‰æã‰∏≠ÁöÑË∑ØÁî±Âô®ÂùöÊåÅËá™Â∑±ÁîüÊàê SQLÔºåËÄå‰∏çÊòØÂ∞ÜÂÖ∂ÂßîÊâòÁªôÂêàÈÄÇÁöÑÊäÄËÉΩ„ÄÇÂ¶ÇÊûú‰Ω†ÊõæÁªèÂ∞ùËØïËÆ© LLM *‰∏ç* ÂÅöÊüê‰ª∂‰∫ãÔºå‰Ω†Â∞±‰ºöÁü•ÈÅìËøôÁßç‰ΩìÈ™åÊòØÂ§ö‰πà‰ª§‰∫∫Ê≤Æ‰∏ßÔºõÊâæÂà∞‰∏Ä‰∏™ÊúâÊïàÁöÑÊèêÁ§∫ÈúÄË¶ÅÁªèËøáÂ§öËΩÆË∞ÉËØï„ÄÇËÄÉËôëÂà∞ÊØè‰∏™Ê≠•È™§ÁöÑ‰∏çÂêåËæìÂá∫Ê†ºÂºè‰πüÊòØÊ£òÊâãÁöÑ„ÄÇÁî±‰∫éÊàëÈÄâÊã©‰∏ç‰ΩøÁî®ÁªìÊûÑÂåñËæìÂá∫ÔºåÊàëÂøÖÈ°ªÂáÜÂ§áÂ•ΩÂ∫îÂØπË∑ØÁî±Âô®ÂíåÊäÄËÉΩ‰∏≠ÊØè‰∏™ LLM Ë∞ÉÁî®ÁöÑÂ§öÁßç‰∏çÂêåÊ†ºÂºè„ÄÇ\n\n### Á∫Ø‰ª£Á†Å‰ª£ÁêÜÁöÑÂ•ΩÂ§Ñ\n\nÂü∫‰∫é‰ª£Á†ÅÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜËâØÂ•ΩÁöÑÂü∫ÂáÜÂíåËµ∑ÁÇπÔºåÊòØÂ≠¶‰π†‰ª£ÁêÜÂ∑•‰ΩúÂéüÁêÜÁöÑÁªù‰Ω≥ÊñπÂºèÔºåËÄåÊó†ÈúÄ‰æùËµñÁé∞ÊúâÊ°ÜÊû∂‰∏≠ÁöÑÁé∞Êàê‰ª£ÁêÜÊïôÁ®ã„ÄÇÂ∞ΩÁÆ°ËØ¥Êúç LLM ÊåâÈ¢ÑÊúüË°å‰∏∫ÂèØËÉΩÂÖ∑ÊúâÊåëÊàòÊÄßÔºå‰ΩÜ‰ª£Á†ÅÁªìÊûÑÊú¨Ë∫´Ë∂≥Â§üÁÆÄÂçïÔºåÂèØËÉΩÈÄÇÁî®‰∫éÊüê‰∫õÁî®‰æãÔºàÊõ¥Â§öÂÜÖÂÆπËßÅ‰∏ãÈù¢ÁöÑÂàÜÊûêÈÉ®ÂàÜÔºâ„ÄÇ\n\n## LangGraph\n\nLangGraph ÊòØÊúÄÊó©ÁöÑ‰ª£ÁêÜÊ°ÜÊû∂‰πã‰∏ÄÔºåÈ¶ñÊ¨°ÂèëÂ∏É‰∫é 2024 Âπ¥ 1 Êúà„ÄÇËØ•Ê°ÜÊû∂Êó®Âú®ÈÄöËøáÈááÁî® Pregel ÂõæÁªìÊûÑÊù•Ëß£ÂÜ≥Áé∞ÊúâÁÆ°ÈÅìÂíåÈìæÁöÑÊó†ÁéØÁâπÊÄß„ÄÇLangGraph ÈÄöËøáÊ∑ªÂä†ËäÇÁÇπ„ÄÅËæπÂíåÊù°‰ª∂ËæπÁöÑÊ¶ÇÂøµÔºå‰ΩøÊÇ®Êõ¥ÂÆπÊòìÂú®‰ª£ÁêÜ‰∏≠ÂÆö‰πâÂæ™ÁéØÔºå‰ª•ÈÅçÂéÜÂõæÂΩ¢„ÄÇLangGraph Âª∫Á´ãÂú® LangChain ‰πã‰∏äÔºåÂπ∂‰ΩøÁî®ËØ•Ê°ÜÊû∂‰∏≠ÁöÑÂØπË±°ÂíåÁ±ªÂûã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fYgHiGwLhSUSrFv9)\n\n### LangGraph Êû∂ÊûÑ\n\nLangGraph ‰ª£ÁêÜÂú®Ë°®Èù¢‰∏äÁúãËµ∑Êù•‰∏éÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÁõ∏‰ººÔºå‰ΩÜÂÖ∂ËÉåÂêéÁöÑ‰ª£Á†ÅÂç¥Êà™ÁÑ∂‰∏çÂêå„ÄÇLangGraph Âú®ÊäÄÊúØ‰∏ä‰ªçÁÑ∂‰ΩøÁî®‚ÄúË∑ØÁî±Âô®‚ÄùÔºåÂç≥ÈÄöËøáÂáΩÊï∞Ë∞ÉÁî® OpenAIÔºåÂπ∂‰ΩøÁî®ÂìçÂ∫îÁªßÁª≠Âà∞Êñ∞ÁöÑÊ≠•È™§„ÄÇÁÑ∂ËÄåÔºåÁ®ãÂ∫èÂú®ÊäÄËÉΩ‰πãÈó¥ÁöÑÁßªÂä®ÊñπÂºèÂÆåÂÖ®‰∏çÂêå„ÄÇ\n\n```python\ntools = [generate_and_run_sql_query, data_analyzer]\nmodel = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(tools)\n\ndef create_agent_graph():\n    workflow = StateGraph(MessagesState)\n\n    tool_node = ToolNode(tools)\n    workflow.add_node(\"agent\", call_model)\n    workflow.add_node(\"tools\", tool_node)\n\n    workflow.add_edge(START, \"agent\")\n    workflow.add_conditional_edges(\n        \"agent\",\n        should_continue,\n    )\n    workflow.add_edge(\"tools\", \"agent\")\n\n    checkpointer = MemorySaver()\n    app = workflow.compile(checkpointer=checkpointer)\n    return app\n```\n\nËøôÈáåÂÆö‰πâÁöÑÂõæÊúâ‰∏Ä‰∏™Áî®‰∫éÂàùÂßã OpenAI Ë∞ÉÁî®ÁöÑËäÇÁÇπÔºåÁß∞‰∏∫‰∏äÈù¢ÁöÑ‚Äúagent‚ÄùÔºå‰ª•Âèä‰∏Ä‰∏™Áî®‰∫éÂ∑•ÂÖ∑Â§ÑÁêÜÊ≠•È™§ÁöÑËäÇÁÇπÔºåÁß∞‰∏∫‚Äútools‚Äù„ÄÇLangGraph Êúâ‰∏Ä‰∏™ÂÜÖÁΩÆÂØπË±° ToolNodeÔºåÂÆÉÊé•Âèó‰∏Ä‰∏™ÂèØË∞ÉÁî®Â∑•ÂÖ∑ÁöÑÂàóË°®ÔºåÂπ∂Ê†πÊçÆ ChatMessage ÂìçÂ∫îËß¶ÂèëÂÆÉ‰ª¨ÔºåÁÑ∂ÂêéÂÜçËøîÂõûÂà∞‚Äúagent‚ÄùËäÇÁÇπ„ÄÇ\n\n```python\ndef should_continue(state: MessagesState):\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return END\n\ndef call_model(state: MessagesState):\n    messages = state[\"messages\"]\n    response = model.invoke(messages)\n    return {\"messages\": [response]}\n```\n\nÂú®ÊØèÊ¨°Ë∞ÉÁî®‚Äúagent‚ÄùËäÇÁÇπÂêéÔºàÊç¢Âè•ËØùËØ¥ÔºöÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜ‰∏≠ÁöÑË∑ØÁî±Âô®ÔºâÔºåshould_continue ËæπÂÜ≥ÂÆöÊòØÂ∞ÜÂìçÂ∫îËøîÂõûÁªôÁî®Êà∑ÔºåËøòÊòØ‰º†ÈÄíÁªô ToolNode ‰ª•Â§ÑÁêÜÂ∑•ÂÖ∑Ë∞ÉÁî®„ÄÇ\n\nÂú®ÊØè‰∏™ËäÇÁÇπ‰∏≠Ôºå‚Äústate‚ÄùÂ≠òÂÇ®‰∫ÜÊù•Ëá™ OpenAI ÁöÑÊ∂àÊÅØÂíåÂìçÂ∫îÂàóË°®ÔºåÁ±ª‰ºº‰∫éÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÁöÑÊñπÊ≥ï„ÄÇ\n\n### LangGraph ÁöÑÊåëÊàò\n\nÂ§ßÂ§öÊï∞‰∏é LangGraph Áõ∏ÂÖ≥ÁöÑÂõ∞ÈöæÊ∫ê‰∫éÈúÄË¶Å‰ΩøÁî® Langchain ÂØπË±°Ôºå‰ª•‰æøÊµÅÁ®ãÈ°∫ÁïÖ„ÄÇ\n\n**ÊåëÊàò \\#1ÔºöÂáΩÊï∞Ë∞ÉÁî®È™åËØÅ**\n\n‰∏∫‰∫Ü‰ΩøÁî® ToolNode ÂØπË±°ÔºåÊàë‰∏çÂæó‰∏çÈáçÊûÑÊàëÁé∞ÊúâÁöÑÂ§ßÈÉ®ÂàÜ Skill ‰ª£Á†Å„ÄÇToolNode Êé•Âèó‰∏Ä‰∏™ÂèØË∞ÉÁî®ÂáΩÊï∞ÁöÑÂàóË°®ÔºåËøôÊúÄÂàùËÆ©ÊàëËÆ§‰∏∫ÂèØ‰ª•‰ΩøÁî®ÊàëÁé∞ÊúâÁöÑÂáΩÊï∞Ôºå‰ΩÜÁî±‰∫éÊàëÁöÑÂáΩÊï∞ÂèÇÊï∞Ôºå‰∫ãÊÉÖÂç¥Âá∫Áé∞‰∫ÜÈóÆÈ¢ò„ÄÇ\n\nËøô‰∫õÊäÄËÉΩË¢´ÂÆö‰πâ‰∏∫ÂÖ∑ÊúâÂèØË∞ÉÁî®ÊàêÂëòÂáΩÊï∞ÁöÑÁ±ªÔºåËøôÊÑèÂë≥ÁùÄÂÆÉ‰ª¨ÁöÑÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞ÊòØ‚Äúself‚Äù„ÄÇGPT\\-4o Ë∂≥Â§üÊô∫ËÉΩÔºåÊú™Âú®ÁîüÊàêÁöÑÂáΩÊï∞Ë∞ÉÁî®‰∏≠ÂåÖÂê´‚Äúself‚ÄùÂèÇÊï∞ÔºåÁÑ∂ËÄå LangGraph Â∞ÜÂÖ∂ËßÜ‰∏∫Áº∫Â∞ëÂèÇÊï∞ÁöÑÈ™åËØÅÈîôËØØ„ÄÇ\n\nËøôËä±‰∫ÜÊàëÂá†‰∏™Â∞èÊó∂ÊâçÂºÑÊòéÁôΩÔºåÂõ†‰∏∫ÈîôËØØ‰ø°ÊÅØÂç¥Â∞ÜÂáΩÊï∞‰∏≠ÁöÑÁ¨¨‰∏â‰∏™ÂèÇÊï∞ÔºàÊï∞ÊçÆÂàÜÊûêÊäÄËÉΩ‰∏≠ÁöÑ‚Äúargs‚ÄùÔºâÊ†áËÆ∞‰∏∫Áº∫Â§±ÂèÇÊï∞Ôºö\n\n```python\npydantic.v1.error_wrappers.ValidationError: 1 validation error for data_analysis_toolSchema\nargs field required (type=value_error.missing)\n```\n\nÂÄºÂæó‰∏ÄÊèêÁöÑÊòØÔºåÈîôËØØÊ∂àÊÅØÊ∫êËá™ PydanticÔºåËÄå‰∏çÊòØ LangGraph„ÄÇ\n\nÊàëÊúÄÁªà‰∏ãÂÆöÂÜ≥ÂøÉÔºåÂ∞ÜÊàëÁöÑÊäÄËÉΩÈáçÊñ∞ÂÆö‰πâ‰∏∫‰ΩøÁî® Langchain ÁöÑ @tool Ë£ÖÈ•∞Âô®ÁöÑÂü∫Êú¨ÊñπÊ≥ïÔºåÂπ∂ÊàêÂäü‰ΩøÂÖ∂Â∑•‰Ωú„ÄÇ\n\n```python\n@tool\ndef generate_and_run_sql_query(query: str):\n    \"\"\"Ê†πÊçÆÊèêÁ§∫ÁîüÊàêÂπ∂ËøêË°å SQL Êü•ËØ¢„ÄÇ\n\n    ÂèÇÊï∞Ôºö\n        query (str): ÂåÖÂê´ÂéüÂßãÁî®Êà∑ÊèêÁ§∫ÁöÑÂ≠óÁ¨¶‰∏≤„ÄÇ\n\n    ËøîÂõûÔºö\n        str: SQL Êü•ËØ¢ÁöÑÁªìÊûú„ÄÇ\n    \"\"\"\n```\n\n**ÊåëÊàò \\#2ÔºöË∞ÉËØï**\n\nÂ¶ÇÂâçÊâÄËø∞ÔºåÂú®Ê°ÜÊû∂‰∏≠ËøõË°åË∞ÉËØïÊòØÂõ∞ÈöæÁöÑ„ÄÇËøô‰∏ªË¶ÅÂΩíÁªì‰∏∫‰ª§‰∫∫Âõ∞ÊÉëÁöÑÈîôËØØÊ∂àÊÅØÂíåÊäΩË±°Ê¶ÇÂøµÔºå‰ΩøÂæóÊü•ÁúãÂèòÈáèÂèòÂæóÊõ¥Âä†Âõ∞Èöæ„ÄÇ\n\nÊäΩË±°Ê¶ÇÂøµ‰∏ªË¶ÅÂú®Â∞ùËØïË∞ÉËØïÂú®‰ª£ÁêÜ‰∏≠‰º†ÈÄíÁöÑÊ∂àÊÅØÊó∂Âá∫Áé∞„ÄÇLangGraph Â∞ÜËøô‰∫õÊ∂àÊÅØÂ≠òÂÇ®Âú® state\\[‚Äúmessages‚Äù] ‰∏≠„ÄÇÂõæ‰∏≠ÁöÑÊüê‰∫õËäÇÁÇπ‰ºöËá™Âä®‰ªéËøô‰∫õÊ∂àÊÅØ‰∏≠ÊèêÂèñÔºåËøôÂèØËÉΩ‰ΩøÂæóÂú®ËäÇÁÇπËÆøÈóÆÊ∂àÊÅØÊó∂ÁêÜËß£Ê∂àÊÅØÁöÑÂÄºÂèòÂæóÂõ∞Èöæ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*KuCg0WGHSklOKe6t)\n\n### LangGraph ÁöÑÂ•ΩÂ§Ñ\n\nLangGraph ÁöÑ‰∏ªË¶ÅÂ•ΩÂ§Ñ‰πã‰∏ÄÊòØÊòì‰∫é‰ΩøÁî®„ÄÇÂõæÁªìÊûÑ‰ª£Á†ÅÁÆÄÊ¥Å‰∏îÊòì‰∫éËÆøÈóÆ„ÄÇÁâπÂà´ÊòØÂΩìÊÇ®ÊúâÂ§çÊùÇÁöÑËäÇÁÇπÈÄªËæëÊó∂ÔºåÊã•ÊúâÂõæÁöÑÂçï‰∏ÄËßÜÂõæ‰ΩøÁêÜËß£‰ª£ÁêÜ‰πãÈó¥ÁöÑËøûÊé•ÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇLangGraph Ëøò‰ΩøÂ∞ÜÁé∞ÊúâÁöÑÂü∫‰∫é LangChain ÊûÑÂª∫ÁöÑÂ∫îÁî®Á®ãÂ∫èËΩ¨Êç¢ÂèòÂæóÁÆÄÂçï„ÄÇ\n\n### Â§ñÂçñ\n\nÂ¶ÇÊûúÊÇ®‰ΩøÁî®Ê°ÜÊû∂‰∏≠ÁöÑÊâÄÊúâÂÜÖÂÆπÔºåLangGraph Â∞ÜËøêË°åËâØÂ•ΩÔºõÂ¶ÇÊûúÊÇ®Ë∂ÖÂá∫ÂÆÉÁöÑËåÉÂõ¥ÔºåËØ∑ÂáÜÂ§áÂ•ΩËøõË°å‰∏Ä‰∫õË∞ÉËØï„ÄÇ\n\n## LlamaIndex Â∑•‰ΩúÊµÅ\n\nÂ∑•‰ΩúÊµÅÊòØ‰ª£ÁêÜÊ°ÜÊû∂È¢ÜÂüüÁöÑÊñ∞ËøõÂÖ•ËÄÖÔºåÊó©Âú®‰ªäÂπ¥Â§èÂ§©È¶ñÊ¨°‰∫ÆÁõ∏„ÄÇ‰∏é LangGraph Á±ª‰ººÔºåÂÆÉÊó®Âú®ÁÆÄÂåñÂæ™ÁéØ‰ª£ÁêÜÁöÑÊûÑÂª∫„ÄÇÂ∑•‰ΩúÊµÅËøòÁâπÂà´ÂÖ≥Ê≥®ÂºÇÊ≠•ËøêË°å„ÄÇ\n\nÂ∑•‰ΩúÊµÅÁöÑ‰∏Ä‰∫õÂÖÉÁ¥†‰ºº‰πéÊòØÂØπ LangGraph ÁöÑÁõ¥Êé•ÂõûÂ∫îÔºåÁâπÂà´ÊòØÂÆÉ‰ΩøÁî®‰∫ã‰ª∂ËÄå‰∏çÊòØËæπÂíåÊù°‰ª∂Ëæπ„ÄÇÂ∑•‰ΩúÊµÅ‰ΩøÁî®Ê≠•È™§ÔºàÁ±ª‰ºº‰∫é LangGraph ‰∏≠ÁöÑËäÇÁÇπÔºâÊù•ÂÆπÁ∫≥ÈÄªËæëÔºåÂπ∂ÈÄöËøáÂèëÂá∫ÂíåÊé•Êî∂‰∫ã‰ª∂Âú®Ê≠•È™§‰πãÈó¥ÁßªÂä®„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*22WuFVBWctdeiCSL)\n\n‰∏äÈù¢ÁöÑÁªìÊûÑÁúãËµ∑Êù•‰∏é LangGraph ÁªìÊûÑÁõ∏‰ººÔºåÂè™ÊòØÂ¢ûÂä†‰∫Ü‰∏ÄÈ°πÂÜÖÂÆπ„ÄÇÊàëÂú®Â∑•‰ΩúÊµÅ‰∏≠Ê∑ªÂä†‰∫Ü‰∏Ä‰∏™ËÆæÁΩÆÊ≠•È™§Ôºå‰ª•ÂáÜÂ§á‰ª£ÁêÜ‰∏ä‰∏ãÊñáÔºåÊõ¥Â§öÂÜÖÂÆπËØ∑ËßÅ‰∏ãÊñá„ÄÇÂ∞ΩÁÆ°ÁªìÊûÑÁõ∏‰ººÔºå‰ΩÜÊîØÊíëÂÆÉÁöÑ‰ª£Á†ÅÂç¥Êà™ÁÑ∂‰∏çÂêå„ÄÇ\n\n### Â∑•‰ΩúÊµÅÊû∂ÊûÑ\n\n‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÂÆö‰πâ‰∫ÜÂ∑•‰ΩúÊµÅÁªìÊûÑ„ÄÇ‰∏é LangGraph Á±ª‰ººÔºåËøôÈáåÊòØÊàëÂáÜÂ§áÁä∂ÊÄÅÂπ∂Â∞ÜÊäÄËÉΩÈôÑÂä†Âà∞ LLM ÂØπË±°ÁöÑÂú∞Êñπ„ÄÇ\n\n```python\nclass AgentFlow(Workflow):\n    def __init__(self, llm, timeout=300):\n        super().__init__(timeout=timeout)\n        self.llm = llm\n        self.memory = ChatMemoryBuffer(token_limit=1000).from_defaults(llm=llm)\n        self.tools = []\n        for func in skill_map.get_function_list():\n            self.tools.append(\n                FunctionTool(\n                    skill_map.get_function_callable_by_name(func),\n                    metadata=ToolMetadata(\n                        name=func, description=skill_map.get_function_description_by_name(func)\n                    ),\n                )\n            )\n\n    @step\n    async def prepare_agent(self, ev: StartEvent) -> RouterInputEvent:\n        user_input = ev.input\n        user_msg = ChatMessage(role=\"user\", content=user_input)\n        self.memory.put(user_msg)\n\n        chat_history = self.memory.get()\n        return RouterInputEvent(input=chat_history)\n```\n\nËøô‰πüÊòØÊàëÂÆö‰πâÈ¢ùÂ§ñÊ≠•È™§‚Äúprepare\\_agent‚ÄùÁöÑÂú∞Êñπ„ÄÇÊ≠§Ê≠•È™§‰ªéÁî®Êà∑ËæìÂÖ•ÂàõÂª∫‰∏Ä‰∏™ ChatMessageÔºåÂπ∂Â∞ÜÂÖ∂Ê∑ªÂä†Âà∞Â∑•‰ΩúÊµÅÂÜÖÂ≠ò‰∏≠„ÄÇÂ∞ÜÂÖ∂ÂàÜÁ¶ª‰∏∫ÂçïÁã¨Ê≠•È™§ÊÑèÂë≥ÁùÄÊàë‰ª¨Âú®‰ª£ÁêÜÂæ™ÁéØÈÄöËøáÊ≠•È™§Êó∂‰ºöËøîÂõûÂà∞ÂÆÉÔºåËøôÈÅøÂÖç‰∫ÜÈáçÂ§çÂ∞ÜÁî®Êà∑Ê∂àÊÅØÊ∑ªÂä†Âà∞ÂÜÖÂ≠ò‰∏≠„ÄÇ\n\nÂú® LangGraph ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàëÈÄöËøá‰∏Ä‰∏™‰Ωç‰∫éÂõæÂ§ñÁöÑ run\\_agent ÊñπÊ≥ïÂÆåÊàê‰∫ÜÂêåÊ†∑ÁöÑ‰∫ãÊÉÖ„ÄÇÁÑ∂ËÄåÔºåËøô‰∏ÄÂèòÂåñ‰∏ªË¶ÅÊòØÈ£éÊ†º‰∏äÁöÑÔºåÁÑ∂ËÄåÂú®ÊàëÁúãÊù•ÔºåÂ∞ÜÊ≠§ÈÄªËæë‰∏éÂ∑•‰ΩúÊµÅÂíåÂõæÂΩ¢ÁªìÂêàÂú®‰∏ÄËµ∑Êõ¥‰∏∫ÁÆÄÊ¥Å„ÄÇ\n\nËÆæÁΩÆÂ•ΩÂ∑•‰ΩúÊµÅÂêéÔºåÊàëÊé•ÁùÄÂÆö‰πâ‰∫ÜË∑ØÁî±‰ª£Á†ÅÔºö\n\n```python\n@step\nasync def router(self, ev: RouterInputEvent) -> ToolCallEvent | StopEvent:\n    messages = ev.input\n\n    if not any(\n        isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n    ):\n        system_prompt = ChatMessage(role=\"system\", content=SYSTEM_PROMPT)\n        messages.insert(0, system_prompt)\n\n    with using_prompt_template(template=SYSTEM_PROMPT, version=\"v0.1\"):\n        response = await self.llm.achat_with_tools(\n            model=\"gpt-4o\",\n            messages=messages,\n            tools=self.tools,\n        )\n\n    self.memory.put(response.message)\n\n    tool_calls = self.llm.get_tool_calls_from_response(response, error_on_no_tool_call=False)\n    if tool_calls:\n        return ToolCallEvent(tool_calls=tool_calls)\n    else:\n        return StopEvent(result=response.message.content)\n```\n\n‰ª•ÂèäÂ∑•ÂÖ∑Ë∞ÉÁî®Â§ÑÁêÜ‰ª£Á†ÅÔºö\n\n```python\n@step\nasync def tool_call_handler(self, ev: ToolCallEvent) -> RouterInputEvent:\n    tool_calls = ev.tool_calls\n\n    for tool_call in tool_calls:\n        function_name = tool_call.tool_name\n        arguments = tool_call.tool_kwargs\n        if \"input\" in arguments:\n            arguments[\"prompt\"] = arguments.pop(\"input\")\n\n        try:\n            function_callable = skill_map.get_function_callable_by_name(function_name)\n        except KeyError:\n            function_result = \"Error: Unknown function call\"\n\n        function_result = function_callable(arguments)\n        message = ChatMessage(\n            role=\"tool\",\n            content=function_result,\n            additional_kwargs={\"tool_call_id\": tool_call.tool_id},\n        )\n\n        self.memory.put(message)\n\n    return RouterInputEvent(input=self.memory.get())\n```\n\nËøô‰∏§ËÄÖÁúãËµ∑Êù•Êõ¥ÂÉèÊòØÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÔºåËÄå‰∏çÊòØ LangGraph ‰ª£ÁêÜ„ÄÇËøô‰∏ªË¶ÅÊòØÂõ†‰∏∫Â∑•‰ΩúÊµÅÂ∞ÜÊù°‰ª∂Ë∑ØÁî±ÈÄªËæë‰øùÁïôÂú®Ê≠•È™§‰∏≠ÔºåËÄå‰∏çÊòØÂú®Êù°‰ª∂Ëæπ‰∏≠‚Äî‚ÄîÁ¨¨ 18 Âà∞ 24 Ë°åÂú® LangGraph ‰∏≠ÊòØ‰∏Ä‰∏™Êù°‰ª∂ËæπÔºåËÄåÁé∞Âú®ÂÆÉ‰ª¨Âè™ÊòØË∑ØÁî±Ê≠•È™§ÁöÑ‰∏ÄÈÉ®ÂàÜ‚Äî‚Äî‰ª•Âèä LangGraph ÂÖ∑Êúâ‰∏Ä‰∏™ ToolNode ÂØπË±°ÔºåÂá†‰πéËá™Âä®Â§ÑÁêÜ tool\\_call\\_handler ÊñπÊ≥ï‰∏≠ÁöÑÊâÄÊúâÂÜÖÂÆπ„ÄÇ\n\nÂú®Ë∑ØÁî±Ê≠•È™§‰πãÂêéÔºåÊàëÈùûÂ∏∏È´òÂÖ¥Âú∞ÁúãÂà∞ÊàëÂèØ‰ª•Â∞ÜÊàëÁöÑ SkillMap ÂíåÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜ‰∏≠ÁöÑÁé∞ÊúâÊäÄËÉΩ‰∏éÂ∑•‰ΩúÊµÅ‰∏ÄËµ∑‰ΩøÁî®„ÄÇËøô‰∫õÊäÄËÉΩÊó†ÈúÄÊõ¥ÊîπÂ∞±ÂèØ‰ª•‰∏éÂ∑•‰ΩúÊµÅÈÖçÂêà‰ΩøÁî®ÔºåËøôËÆ©ÊàëÁöÑÂ∑•‰ΩúËΩªÊùæ‰∫ÜÂæàÂ§ö„ÄÇ\n\n### Â∑•‰ΩúÊµÅÁöÑÊåëÊàò\n\n**ÊåëÊàò \\#1: ÂêåÊ≠•‰∏éÂºÇÊ≠•**\n\nÂ∞ΩÁÆ°ÂºÇÊ≠•ÊâßË°åÂØπ‰∫éÂÆûÊó∂‰ª£ÁêÜÊõ¥‰∏∫ÁêÜÊÉ≥Ôºå‰ΩÜË∞ÉËØïÂêåÊ≠•‰ª£ÁêÜË¶ÅÂÆπÊòìÂæóÂ§ö„ÄÇÂ∑•‰ΩúÊµÅËÆæËÆ°‰∏∫ÂºÇÊ≠•Â∑•‰ΩúÔºåÂº∫Ë°åÂÆûÁé∞ÂêåÊ≠•ÊâßË°åÈùûÂ∏∏Âõ∞Èöæ„ÄÇ\n\nÊàëÊúÄÂàù‰ª•‰∏∫Âè™ÈúÄÂéªÊéâ‚Äúasync‚ÄùÊñπÊ≥ïÊ†áËØÜÔºåÂ∞Ü‚Äúachat\\_with\\_tools‚ÄùÂàáÊç¢‰∏∫‚Äúchat\\_with\\_tools‚ÄùÂç≥ÂèØ„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éWorkflowÁ±ª‰∏≠ÁöÑÂ∫ïÂ±ÇÊñπÊ≥ï‰πüË¢´Ê†áËÆ∞‰∏∫ÂºÇÊ≠•ÔºåÂõ†Ê≠§ÊúâÂøÖË¶ÅÈáçÊñ∞ÂÆö‰πâËøô‰∫õÊñπÊ≥ï‰ª•‰æøÂÆûÁé∞ÂêåÊ≠•ÊâßË°å„ÄÇÊúÄÁªàÊàëËøòÊòØÂùöÊåÅ‰ΩøÁî®ÂºÇÊ≠•ÊñπÊ≥ïÔºå‰ΩÜËøôÂπ∂Ê≤°Êúâ‰ΩøË∞ÉËØïÂèòÂæóÊõ¥Âä†Âõ∞Èöæ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*78Hzqkiv9cI7W4UA)\n\n**ÊåëÊàò \\#2: Pydantic È™åËØÅÈîôËØØ**\n\nÂú®‰∏éLangGraphÁöÑÂõ∞Â¢ÉÈáçÊºî‰∏≠ÔºåÂÖ≥‰∫éÊäÄËÉΩÁöÑPydanticÈ™åËØÅÈîôËØØÂá∫Áé∞‰∫ÜÁ±ª‰ººÁöÑÈóÆÈ¢ò„ÄÇÂπ∏ËøêÁöÑÊòØÔºåÁî±‰∫éÂ∑•‰ΩúÊµÅËÉΩÂ§üÂæàÂ•ΩÂú∞Â§ÑÁêÜÊàêÂëòÂáΩÊï∞ÔºåËøôÊ¨°Ëß£ÂÜ≥Ëµ∑Êù•Ë¶ÅÂÆπÊòìÂæóÂ§ö„ÄÇÊàëÊúÄÁªà‰∏çÂæó‰∏çÂú®‰∏∫ÊàëÁöÑÊäÄËÉΩÂàõÂª∫LlamaIndex FunctionToolÂØπË±°Êó∂Êõ¥Âä†ËßÑËåÉÔºö\n\n```python\nfor func in skill_map.get_function_list(): \n            self.tools.append(FunctionTool(\n                skill_map.get_function_callable_by_name(func), \n                metadata=ToolMetadata(name=func, description=skill_map.get_function_description_by_name(func))))\n```\n\n*ÊëòËá™ AgentFlow.\\_\\_init\\_\\_ÔºåÁî®‰∫éÊûÑÂª∫ FunctionTools*\n\n### Â∑•‰ΩúÊµÅÁöÑÂ•ΩÂ§Ñ\n\nÊûÑÂª∫ Workflows ‰ª£ÁêÜÊØîÊûÑÂª∫ LangGraph ‰ª£ÁêÜË¶ÅÂÆπÊòìÂæóÂ§öÔºå‰∏ªË¶ÅÊòØÂõ†‰∏∫ Workflows ‰ªçÁÑ∂Ë¶ÅÊ±ÇÊàëËá™Â∑±ÁºñÂÜôË∑ØÁî±ÈÄªËæëÂíåÂ∑•ÂÖ∑Â§ÑÁêÜ‰ª£Á†ÅÔºåËÄå‰∏çÊòØÊèê‰æõÂÜÖÁΩÆÂáΩÊï∞„ÄÇËøô‰πüÊÑèÂë≥ÁùÄÊàëÁöÑ Workflow ‰ª£ÁêÜÁúãËµ∑Êù•‰∏éÊàëÁöÑÂü∫‰∫é‰ª£Á†ÅÁöÑ‰ª£ÁêÜÊûÅ‰∏∫Áõ∏‰ºº„ÄÇ\n\nÊúÄÂ§ßÁöÑÂå∫Âà´Âú®‰∫é‰∫ã‰ª∂ÁöÑ‰ΩøÁî®„ÄÇÊàë‰ΩøÁî®‰∫Ü‰∏§‰∏™Ëá™ÂÆö‰πâ‰∫ã‰ª∂Âú®ÊàëÁöÑ‰ª£ÁêÜ‰∏≠ÁßªÂä®Ê≠•È™§Ôºö\n\n```python\nclass ToolCallEvent(Event):\n    tool_calls: list[ToolSelection]\n\nclass RouterInputEvent(Event):\n    input: list[ChatMessage]\n```\n\nÂèëÂ∞ÑÂô®-Êé•Êî∂Âô®„ÄÅÂü∫‰∫é‰∫ã‰ª∂ÁöÑÊû∂ÊûÑÂèñ‰ª£‰∫ÜÁõ¥Êé•Ë∞ÉÁî®ÊàëÁöÑ‰ª£ÁêÜ‰∏≠ÁöÑÊüê‰∫õÊñπÊ≥ïÔºåÊØîÂ¶ÇÂ∑•ÂÖ∑Ë∞ÉÁî®Â§ÑÁêÜÂô®„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ÊúâÊõ¥Â§çÊùÇÁöÑÁ≥ªÁªüÔºåÂÖ∑ÊúâÂ§ö‰∏™ÂºÇÊ≠•Ëß¶ÂèëÁöÑÊ≠•È™§Âπ∂ÂèØËÉΩÂèëÂá∫Â§ö‰∏™‰∫ã‰ª∂ÔºåËøôÁßçÊû∂ÊûÑÂ∞ÜÈùûÂ∏∏ÊúâÂä©‰∫éÂπ≤ÂáÄÂú∞ÁÆ°ÁêÜËøô‰∫õÊÉÖÂÜµ„ÄÇ\n\nWorkflows ÁöÑÂÖ∂‰ªñÂ•ΩÂ§ÑÂåÖÊã¨ÂÆÉÈùûÂ∏∏ËΩªÈáè‰∏î‰∏çÂº∫Ëø´ÊÇ®‰ΩøÁî®ÂæàÂ§öÁªìÊûÑÔºàÈô§‰∫ÜÊüê‰∫õ LlamaIndex ÂØπË±°ÁöÑ‰ΩøÁî®ÔºâÔºåËÄå‰∏îÂÆÉÁöÑÂü∫‰∫é‰∫ã‰ª∂ÁöÑÊû∂ÊûÑ‰∏∫Áõ¥Êé•ÂáΩÊï∞Ë∞ÉÁî®Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÁî®ÁöÑÊõø‰ª£ÊñπÊ°à‚Äî‚ÄîÁâπÂà´ÊòØÂØπ‰∫éÂ§çÊùÇÁöÑÂºÇÊ≠•Â∫îÁî®Á®ãÂ∫è„ÄÇ\n\n## ÊØîËæÉÊ°ÜÊû∂\n\nÂú®Ëøô‰∏âÁßçÊñπÊ≥ï‰∏≠ÔºåÂêÑËá™ÈÉΩÊúâÂÖ∂‰ºòÁÇπ„ÄÇ\n\nÊó†Ê°ÜÊû∂ÁöÑÊñπÊ≥ïÊòØÊúÄÁÆÄÂçïÁöÑÂÆûÁé∞ÊñπÂºè„ÄÇÂõ†‰∏∫‰ªª‰ΩïÊäΩË±°ÈÉΩÊòØÁî±ÂºÄÂèëËÄÖÂÆö‰πâÁöÑÔºàÂç≥‰∏äÈù¢Á§∫‰æã‰∏≠ÁöÑ SkillMap ÂØπË±°ÔºâÔºå‰øùÊåÅÂêÑÁßçÁ±ªÂûãÂíåÂØπË±°ÁöÑÊ∏ÖÊô∞ÊòØÂæàÂÆπÊòìÁöÑ„ÄÇÁÑ∂ËÄåÔºå‰ª£Á†ÅÁöÑÂèØËØªÊÄßÂíåÂèØËÆøÈóÆÊÄßÂÆåÂÖ®ÂèñÂÜ≥‰∫é‰∏™Âà´ÂºÄÂèëËÄÖÔºåÈöèÁùÄ‰ª£ÁêÜÁöÑÂ§çÊùÇÊÄßÂ¢ûÂä†ÔºåÂ¶ÇÊûúÊ≤°Êúâ‰∏Ä‰∫õÂº∫Âà∂ÁªìÊûÑÔºåÂæàÂÆπÊòìÂèòÂæóÊ∑∑‰π±„ÄÇ\n\nLangGraph Êèê‰æõ‰∫ÜÁõ∏ÂΩìÂ§öÁöÑÁªìÊûÑÔºåËøô‰ΩøÂæó‰ª£ÁêÜÁöÑÂÆö‰πâÈùûÂ∏∏ÊòéÁ°Æ„ÄÇÂ¶ÇÊûú‰∏Ä‰∏™Êõ¥ÂπøÊ≥õÁöÑÂõ¢ÈòüÂú®Âçè‰ΩúÂºÄÂèë‰ª£ÁêÜÔºåËøôÁßçÁªìÊûÑÂ∞ÜÊèê‰æõ‰∏ÄÁßçÂº∫ÊúâÂäõÁöÑÊû∂ÊûÑÂº∫Âà∂ÊñπÂºè„ÄÇÂØπ‰∫éÈÇ£‰∫õ‰∏çÂ§™ÁÜüÊÇâËØ•ÁªìÊûÑÁöÑ‰∫∫ÔºåLangGraph ‰πüÂèØËÉΩ‰∏∫‰ª£ÁêÜÊèê‰æõ‰∏Ä‰∏™ËâØÂ•ΩÁöÑËµ∑ÁÇπ„ÄÇÁÑ∂ËÄåÔºåËøô‰πüÊúâ‰∏Ä‰∏™ÊùÉË°°‚Äî‚ÄîÁî±‰∫é LangGraph ‰∏∫‰Ω†ÂÅö‰∫ÜÂæàÂ§ö‰∫ãÊÉÖÔºåÂ¶ÇÊûú‰Ω†Ê≤°ÊúâÂÆåÂÖ®Êé•ÂèóËøô‰∏™Ê°ÜÊû∂ÔºåÂèØËÉΩ‰ºöÂØºËá¥È∫ªÁÉ¶Ôºõ‰ª£Á†ÅÂèØËÉΩÈùûÂ∏∏Âπ≤ÂáÄÔºå‰ΩÜ‰Ω†ÂèØËÉΩ‰ºö‰∏∫Ê≠§‰ªòÂá∫Êõ¥Â§öÁöÑË∞ÉËØïÊàêÊú¨„ÄÇ\n\nWorkflows ÂàôÂ§Ñ‰∫é‰∏≠Èó¥‰ΩçÁΩÆ„ÄÇÂü∫‰∫é‰∫ã‰ª∂ÁöÑÊû∂ÊûÑÂèØËÉΩÂØπÊüê‰∫õÈ°πÁõÆÊûÅ‰∏∫ÊúâÁî®ÔºåËÄå‰ΩøÁî® LlamaIndex Á±ªÂûãÁöÑË¶ÅÊ±ÇËæÉÂ∞ëÔºå‰∏∫ÈÇ£‰∫õÊ≤°ÊúâÂú®Êï¥‰∏™Â∫îÁî®Á®ãÂ∫è‰∏≠ÂÆåÂÖ®‰ΩøÁî®Ê°ÜÊû∂ÁöÑ‰∫∫Êèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÁÅµÊ¥ªÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*PITmiVGuG8QuDVX6)\n\nÊúÄÁªàÔºåÊ†∏ÂøÉÈóÆÈ¢òÂèØËÉΩÂè™ÊòØ‚Äú‰Ω†ÊòØÂê¶Â∑≤ÁªèÂú®‰ΩøÁî® LlamaIndex Êàñ LangChain Êù•ÂçèË∞É‰Ω†ÁöÑÂ∫îÁî®Á®ãÂ∫èÔºü‚ÄùLangGraph Âíå Workflows ÈÉΩ‰∏éÂêÑËá™ÁöÑÂü∫Á°ÄÊ°ÜÊû∂Á¥ßÂØÜÁõ∏ËøûÔºåÂõ†Ê≠§ÊØè‰∏™ÁâπÂÆö‰∫é‰ª£ÁêÜÁöÑÊ°ÜÊû∂ÁöÑÈ¢ùÂ§ñÂ•ΩÂ§ÑÂèØËÉΩ‰∏çË∂≥‰ª•ÂçïÂá≠‰ºòÁÇπËÄå‰øÉ‰Ωø‰Ω†ÂàáÊç¢„ÄÇ\n\nÁ∫Ø‰ª£Á†ÅÁöÑÊñπÊ≥ïÂèØËÉΩÂßãÁªàÊòØ‰∏Ä‰∏™ÊúâÂê∏ÂºïÂäõÁöÑÈÄâÈ°π„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰∏•Ë∞®ÁöÑÊñπÊ≥ïÊù•ËÆ∞ÂΩïÂíåÂº∫Âà∂ÊâßË°å‰ªª‰ΩïÂàõÂª∫ÁöÑÊäΩË±°ÔºåÈÇ£‰πàÁ°Æ‰øùÂ§ñÈÉ®Ê°ÜÊû∂‰∏ç‰ºöÊãñÊÖ¢‰Ω†ÁöÑÈÄüÂ∫¶ÊòØÂæàÂÆπÊòìÁöÑ„ÄÇ\n\n## ÈÄâÊã©‰ª£ÁêÜÊ°ÜÊû∂ÁöÑÂÖ≥ÈîÆÈóÆÈ¢ò\n\nÂΩìÁÑ∂Ôºå‚ÄúËøôË¶ÅÁúãÊÉÖÂÜµ‚Äù‰ªéÊù•‰∏çÊòØ‰∏Ä‰∏™‰ª§‰∫∫Êª°ÊÑèÁöÑÁ≠îÊ°à„ÄÇËøô‰∏â‰∏™ÈóÆÈ¢òÂ∫îËØ•Â∏ÆÂä©‰Ω†ÂÜ≥ÂÆöÂú®‰∏ã‰∏Ä‰∏™‰ª£ÁêÜÈ°πÁõÆ‰∏≠‰ΩøÁî®Âì™‰∏™Ê°ÜÊû∂„ÄÇ\n\n***‰Ω†ÊòØÂê¶Â∑≤ÁªèÂú®È°πÁõÆÁöÑÈáçË¶ÅÈÉ®ÂàÜ‰ΩøÁî®‰∫Ü LlamaIndex Êàñ LangChainÔºü***\n\nÂ¶ÇÊûúÊòØÔºåËØ∑È¶ñÂÖàÊé¢Á¥¢Ëøô‰∏™ÈÄâÈ°π„ÄÇ\n\n***‰Ω†ÊòØÂê¶ÁÜüÊÇâÂ∏∏ËßÅÁöÑ‰ª£ÁêÜÁªìÊûÑÔºåËøòÊòØÂ∏åÊúõÊúâ‰∏Ä‰∫õÊåáÂØºÊù•ÂëäËØâ‰Ω†Â¶Ç‰ΩïÊûÑÂª∫‰ª£ÁêÜÔºü***\n\nÂ¶ÇÊûú‰Ω†Â±û‰∫éÂêéËÄÖÔºåÂ∞ùËØï Workflows„ÄÇÂ¶ÇÊûú‰Ω†*ÁúüÁöÑ*Â±û‰∫éÂêéËÄÖÔºåÂ∞ùËØï LangGraph„ÄÇ\n\n***‰Ω†ÁöÑ‰ª£ÁêÜ‰πãÂâçÊòØÂê¶Â∑≤ÁªèÊûÑÂª∫ËøáÔºü***\n\nÊ°ÜÊû∂ÁöÑ‰∏Ä‰∏™Â•ΩÂ§ÑÊòØÊØè‰∏™Ê°ÜÊû∂ÈÉΩÊúâËÆ∏Â§öÊïôÁ®ãÂíåÁ§∫‰æãÂèØ‰æõ‰ΩøÁî®„ÄÇËÄåÁ∫Ø‰ª£Á†Å‰ª£ÁêÜÁöÑÁ§∫‰æãÂàôÂ∞ëÂæóÂ§ö„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wF9aSF1db1yaniqO)\n\n## ÁªìËÆ∫\n\nÈÄâÊã©‰∏Ä‰∏™‰ª£ÁêÜÊ°ÜÊû∂Âè™ÊòØ‰ºóÂ§öÈÄâÊã©‰∏≠ÁöÑ‰∏Ä‰∏™ÔºåËøôÂ∞ÜÂΩ±ÂìçÁîüÊàêÂºèAIÁ≥ªÁªüÁöÑÁîü‰∫ßÁªìÊûú„ÄÇÂÉèÂæÄÂ∏∏‰∏ÄÊ†∑ÔºåÂª∫Á´ãÁ®≥ÂÅ•ÁöÑ‰øùÊä§Êé™ÊñΩÂíå [LLM tracing](https://docs.arize.com/phoenix/tracing/llm-traces) ÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑ‚Äî‚ÄîÂπ∂‰∏îË¶ÅÁÅµÊ¥ªÂ∫îÂØπÊñ∞ÁöÑ‰ª£ÁêÜÊ°ÜÊû∂„ÄÅÁ†îÁ©∂ÂíåÊ®°ÂûãÈ¢†Ë¶ÜÊó¢ÂÆöÊäÄÊúØ„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/claude-3-5-haiku-anthropics-speed-demon-gets-a-brain-boost-82f2f0999d4f","frontmatter":{"title":"Claude 3.5 HaikuÔºö‰∫∫Á±ªÁöÑ ÈÄüÂ∫¶‰πãÈ≠î ËÑëÂäõÂ§ßÂ¢û","meta_title":"Claude 3.5 HaikuÔºö‰∫∫Á±ªÁöÑ ÈÄüÂ∫¶‰πãÈ≠î ËÑëÂäõÂ§ßÂ¢û","description":"Claude 3.5 HaikuÊòØAnthropicÊé®Âá∫ÁöÑÊúÄÊñ∞AIÊ®°ÂûãÔºåÂÖ∑Â§áÈ´òÈÄüÂíåÂçìË∂äÊô∫ËÉΩÔºåË∂ÖË∂ä‰∫ÜÂâç‰ªªClaude 3 Opus„ÄÇÂÖ∂ÁºñÁ®ãËÉΩÂäõÂú®SWE-benchÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÊîØÊåÅÊñáÊú¨ËæìÂÖ•ÔºåÊú™Êù•Â∞ÜÊ∑ªÂä†ÂõæÂÉèÂàÜÊûêÂäüËÉΩ„ÄÇÂ∞ΩÁÆ°‰ª∑Ê†º‰∏äÊ∂®ÂõõÂÄçÔºå‰ΩÜÈÄöËøáÊèêÁ§∫ÁºìÂ≠òÂíåÊâπÂ§ÑÁêÜÂèØÈôç‰ΩéÊàêÊú¨„ÄÇËØ•Ê®°ÂûãÈÄÇÁî®‰∫éËΩØ‰ª∂ÂºÄÂèë„ÄÅÂÆ¢Êúç„ÄÅÊï∞ÊçÆÂ§ÑÁêÜÁ≠âÂ§öÁßçÂ∫îÁî®ÔºåÊ†áÂøóÁùÄ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑÈáçË¶ÅËøõÊ≠•„ÄÇ","date":"2024-11-13T01:32:04.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hLedIfhYJhS_ejPDwOQPIw.png","categories":["Programming","Machine Learning","Chatbots"],"author":"Rifx.Online","tags":["Claude","Haiku","coding","SWE-bench","benchmarks"],"draft":false,"slug":"blog/claude-3-5-haiku-anthropics-speed-demon-gets-a-brain-boost-82f2f0999d4f"},"content":"\n\n\n\n\nÂú®‰∫∫Â∑•Êô∫ËÉΩËøõÊ≠•ÁöÑÊó†ÊÉÖÁ´ûËµõ‰∏≠ÔºåAnthropicÂàöÂàöÊé®Âá∫‰∫Ü‰∏Ä‰ΩçÊñ∞ÁöÑÁ´û‰∫âËÄÖ„ÄÇËÆ§ËØÜ‰∏Ä‰∏ãClaude 3\\.5 HaikuÔºåËøôÊòØ‰ªñ‰ª¨ÊúÄÂø´AIÊ®°ÂûãÁöÑÊúÄÊñ∞ÁâàÊú¨„ÄÇÂ∞±ÂÉè‰ªñ‰ª¨ÊääÁü≠Ë∑ëËøêÂä®ÂëòÈÄÅÂà∞‰∫ÜËÑëÂäõËÆ≠ÁªÉËê•„ÄÇÁªìÊûúÂë¢Ôºü‰∏Ä‰∏™‰∏ç‰ªÖÂú®Ë°åÂä®‰∏äËøÖÈÄüÔºåËÄå‰∏îÂú®Êüê‰∫õÊô∫ÂäõÈ¢ÜÂüüËÉΩÂ§üË∂ÖË∂äÂÖ∂Êõ¥Âº∫Â§ßÂÖÑÂºüÁöÑÊ®°Âûã„ÄÇËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£‰∏Ä‰∏ãËøô‰∏™Êñ∞Áîü‰∫ãÁâ©ÁöÑËøê‰ΩúÂéüÁêÜ„ÄÇ\n\n## ÈÄüÂ∫¶ÔºàÂíåÊô∫ÊÖßÔºâÁöÑÈúÄÊ±Ç\n\nAnthropic ‰πãÂâçÁöÑ Haiku Ê®°ÂûãÂ∑≤ÁªèÊòØ‰ªñ‰ª¨ AI Á≥ªÂàó‰∏≠ÁöÑ‰πåËµõÂõ†¬∑ÂçöÂ∞îÁâπ„ÄÇÁé∞Âú®Ôºå‰ªñ‰ª¨‰∏çÁü•ÊÄé‰πàÂú∞Âú®Ëøô‰∏™ÈÄüÂ∫¶ÊÄ™ÂÖΩ‰∏≠Â°ûÂÖ•‰∫ÜÊõ¥Â§öÁöÑÊô∫ÂäõÔºåËÄåÊ≤°ÊúâÁâ∫Áâ≤ÂÖ∂ËøÖÈÄüÊÄß„ÄÇËøôÂ∞±ÂÉèÁúãÁùÄ‰∏ÄÂè™ÁåéË±πÂú®Â•îË∑ëÊó∂Ëß£È≠îÊñπ„ÄÇ\n\n## Âü∫ÂáÜÊµãËØïÁöÑËæâÁÖå\n\nClaude 3\\.5 Haiku ‰∏ç‰ªÖÈÄüÂ∫¶Âø´ÔºåËÄå‰∏îÊô∫ËÉΩÊÉä‰∫∫„ÄÇÂÆÉÂú®ÂêÑÁßçÊô∫ËÉΩÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºò‰∫é Claude 3 Opus ‚Äî‚Äî Anthropic ‰πãÂâçÁöÑÈáçÈáèÁ∫ßÂÜ†ÂÜõ„ÄÇËøô‰∏ç‰ªÖ‰ªÖÊòØ‰∏ÄÊ¨°Â∞èÂπÖÂçáÁ∫ßÔºõËøôÊòØ‰∏ÄÊ¨°È£ûË∑ÉÔºå‰ΩøÂæó‰∫∫Â∑•Êô∫ËÉΩÁ§æÂå∫‰∏∫‰πãÁû©ÁõÆ„ÄÇ\n\n## ÁºñÁ®ãËÉΩÂäõ\n\nÂ¶ÇÊûú‰Ω†ÊòØÂºÄÂèëËÄÖÔºåËØ∑Ê≥®ÊÑè„ÄÇËøô‰∏™Ê®°ÂûãÂú®ÁºñÁ†ÅÈ¢ÜÂüüË°®Áé∞Âá∫Ëâ≤ÔºåÂú®SWE-benchÈ™åËØÅÊµãËØï‰∏≠ÂæóÂàÜÈ´òËææ40.6%„ÄÇËøô‰∏ç‰ªÖ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÔºõËøôÊòØ‰∏ÄÁßçËÆ©‰∫∫Á±ªÁ®ãÂ∫èÂëòÁ¥ßÂº†Âú∞ÂÖ≥Ê≥®‰ªñ‰ª¨Â∑•‰ΩúÂÆâÂÖ®ÁöÑË°®Áé∞„ÄÇ\n\n## ÂºïÊìéÁõñ‰∏ãÁöÑÁßòÂØÜ\n\nËÆ©Êàë‰ª¨ÊâìÂºÄÂºïÊìéÁõñÔºåÁúãÁúãÊòØ‰ªÄ‰πàÈ©±Âä®ÁùÄËøô‰∏™‰∫∫Â∑•Êô∫ËÉΩÁÉ≠ËΩ¶Ôºö\n\n* **ÂèØÁî®ÊÄß**Ôºö‰Ω†ÂèØ‰ª•ÈÄöËøá Anthropic ÁöÑ API„ÄÅAmazon Bedrock Êàñ Google Cloud ÁöÑ Vertex AI Êù•‰ΩìÈ™åÂÆÉ„ÄÇËøôÂ∞±ÂÉèÂú®ÊâÄÊúâ‰∏ªË¶ÅÊµÅÂ™í‰ΩìÂπ≥Âè∞‰∏äÈÉΩÊúâÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁâàÊú¨„ÄÇ\n* **ËæìÂÖ•**ÔºöÁõÆÂâçÂè™ÊîØÊåÅÊñáÊú¨„ÄÇËøòÊ≤°ÊúâÂõæÂÉèÂàÜÊûêÔºå‰ΩÜËøôÂäüËÉΩÂç≥Â∞ÜÊé®Âá∫„ÄÇËøôÂ∞±ÂÉèÊúâ‰∏Ä‰∏™Â§©ÊâçÁöÑÁ¨îÂèãÔºå‰ΩÜ‰ªñÊó†Ê≥ïÊü•Áúã‰Ω†ÁöÑÂ∫¶ÂÅáÁÖßÁâá„ÄÇ\n* **Áü•ËØÜÊà™Ê≠¢Êó•Êúü**Ôºö2024Âπ¥7Êúà„ÄÇÂõ†Ê≠§ÔºåÂÆÉÁü•ÈÅì‰Ω†ÂéªÂπ¥Â§èÂ§©ÂÅöÁöÑÈÇ£‰ª∂Â∞¥Â∞¨ÁöÑ‰∫ãÊÉÖÔºå‰ΩÜ‰∏çÁü•ÈÅìÊòéÂπ¥ÁöÑÊµÅË°åÊ¢ó„ÄÇ\n* **ËæìÂá∫ÈïøÂ∫¶**ÔºöÊØîÂâç‰∏ÄÁâàÊú¨ÊúâÊâÄÊîπËøõ„ÄÇÂÆÉÁé∞Âú®ÂèØ‰ª•ÂÜôÊõ¥ÈïøÁöÑÊñáÁ´†Êù•Â∏Æ‰Ω†ÊãñÂª∂Êó∂Èó¥„ÄÇ\n\n## Show Me the Money\n\nÁé∞Âú®Ôºå‰∫ãÊÉÖÂèòÂæóÊúâË∂£‰∫Ü„ÄÇAnthropic ÂÜ≥ÂÆöÂØπËøô‰∏™ÂçáÁ∫ßÁâàÊ®°ÂûãÊî∂ÂèñÈ´òÈ¢ùË¥πÁî®Ôºö\n\n* ÊØèÁôæ‰∏á‰∏™ËæìÂÖ•‰ª§Áâå $1\n* ÊØèÁôæ‰∏á‰∏™ËæìÂá∫‰ª§Áâå $5\n\nËøôÊØî‰πãÂâçÁöÑÁâàÊú¨Â¢ûÂä†‰∫ÜÂõõÂÄç„ÄÇÂ∞±ÂÉè‰ªñ‰ª¨ÊääÊú¨Áî∞ÊÄùÂüüÂèòÊàê‰∫ÜÁâπÊñØÊãâÔºåÂπ∂Áõ∏Â∫îÂú∞Ë∞ÉÊï¥‰∫Ü‰ª∑Ê†º„ÄÇ\n\n‰ΩÜÂà´ÊãÖÂøÉÔºåËäÇ‰ø≠ÁöÑÊúãÂèã‰ª¨ÔºÅËøòÊúâÁúÅÈí±ÁöÑÊñπÊ≥ïÔºö\n\n* ÊèêÁ§∫ÁºìÂ≠òÂèØ‰ª•ËäÇÁúÅÈ´òËææ 90%„ÄÇËøôÂ∞±ÂÉè‰∏∫ AI ËøõË°åÊûÅÈôê‰ºòÊÉ†Âà∏Ê¥ªÂä®„ÄÇ\n* ‰ΩøÁî®Ê∂àÊÅØÊâπÂ§ÑÁêÜ API ÁöÑÊâπÈáèÂ§ÑÁêÜÂèØ‰ª•Â∞ÜÊàêÊú¨Èôç‰ΩéÈ´òËææ 50%„ÄÇÂ§ßÂÆóË¥≠‰π∞Ôºå‰ΩÜÁî®‰∫éËÆ°ÁÆó„ÄÇ\n\n## Ëøô‰∏™‰∏úË•øËÉΩÂÅö‰ªÄ‰πàÔºü\n\nClaude 3\\.5 Haiku ‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™Ê¥æÂØπÊääÊàè„ÄÇÂÆÉÊúâ‰∏Ä‰∫õ‰∏•ËÇÉÁöÑÁé∞ÂÆûÂ∫îÁî®Ôºö\n\n* **ËΩØ‰ª∂ÂºÄÂèë**ÔºöÂ∞±ÂÉèÊúâ‰∏Ä‰∏™Ê∞∏‰∏çÁù°Ëßâ‰∏î‰∏çÂÅ∑‰Ω†Èõ∂È£üÁöÑÁºñÁ®ã‰ºô‰º¥„ÄÇ\n* **ËÅäÂ§©Êú∫Âô®‰∫∫**Ôºö‰∏çÈúÄË¶ÅÂíñÂï°‰ºëÊÅØÊàñ‰∫∫ÂäõËµÑÊ∫êÂπ≤È¢ÑÁöÑÂÆ¢Êúç‰ª£Ë°®„ÄÇ\n* **Êï∞ÊçÆÂ§ÑÁêÜ**ÔºöÂÆÉËÉΩÊØî‰Ω†ËØ¥‚ÄúÊï∞ÊçÆÂ§ß‚ÄùËøòÂø´Âú∞Â§ÑÁêÜÊï∞Â≠ó„ÄÇ\n* **ÊïôËÇ≤**Ôºö‰∏Ä‰∏™ÈöèÊó∂ÂæÖÂëΩ‰∏î‰ªé‰∏çÂ§±ÂéªËÄêÂøÉÁöÑËæÖÂØºËÄÅÂ∏à„ÄÇ\n* **‰∏™ÊÄßÂåñ**ÔºöÂÆÉËÆ∞‰Ωè‰Ω†ÁöÑÂÅèÂ•ΩÊØî‰Ω†ÁöÑÂè¶‰∏ÄÂçäËøòË¶ÅÂ•Ω„ÄÇ\n* **‰∏ì‰∏ö‰ªªÂä°**ÔºöAI Â≠ê‰ª£ÁêÜÁöÑÁëûÂ£´ÂÜõÂàÄ„ÄÇ\n* **ÂÜÖÂÆπÂÆ°Ê†∏**ÔºöÊØèÊ¨°ÂèëÂ∏ÉÈÉΩÂú®‰øùÊåÅ‰∫íËÅîÁΩëÁöÑÊ∏ÖÊ¥Å„ÄÇ\n\n## ÊùÉË°°\n\nÁé∞Âú®ÔºåÂπ∂‰∏çÊòØÊâÄÊúâ‰∫ãÊÉÖÈÉΩÈÇ£‰πàÁæéÂ•Ω„ÄÇËøòÊúâ‰∏Ä‰∫õÈóÆÈ¢òÔºö\n\n* ÁõÆÂâçËøòÊ≤°ÊúâÂõæÂÉèÂàÜÊûêÂäüËÉΩ„ÄÇÂõ†Ê≠§ÔºåÂÆÉÊó†Ê≥ïÂëäËØâ‰Ω†ÈÇ£Êù°Ë£ôÂ≠êÊòØÂê¶ËÆ©‰Ω†ÁúãËµ∑Êù•ËÉñ„ÄÇ\n* ‰ª∑Ê†º‰∏äÊ∂®ÂèØËÉΩ‰ºöËÆ©‰∏Ä‰∫õÁî®Êà∑ÁªßÁª≠‰ΩøÁî®ÊóßÁâà„ÄÅ‰æøÂÆúÁöÑÁâàÊú¨„ÄÇËøôÂ∞±ÂÉè‰∫∫‰ª¨‰ªçÁÑ∂‰ΩøÁî® Windows 7 ÁöÑ AI Á≠â‰ª∑Áâ©„ÄÇ\n\n## Â∫ïÁ∫ø\n\nClaude 3\\.5 Haiku ÊòØ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑ‰∏ÄÊ¨°ÈáçË¶ÅÈ£ûË∑É„ÄÇÂÆÉÁöÑÈÄüÂ∫¶Âø´Â¶ÇÂ≠êÂºπÔºåÂäõÈáèÂº∫‰∫éÊú∫ËΩ¶ÔºåËÉΩÂ§ü‰∏ÄË∑ÉËÄåËøáÈ´òÊ•ºÂ§ßÂé¶„ÄÇÂ•ΩÂêßÔºå‰πüËÆ∏ÊúÄÂêéÈÇ£ÈÉ®ÂàÜ‰∏çÂ§™ÂáÜÁ°ÆÔºå‰ΩÜ‰Ω†ÊòéÁôΩÊàëÁöÑÊÑèÊÄù„ÄÇ\n\nÂØπ‰∫éÂ∏åÊúõÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÂ§ÑÁêÜÂ§çÊùÇ‰ªªÂä°ÁöÑÂºÄÂèëËÄÖÂíå‰ºÅ‰∏öÊù•ËØ¥ÔºåClaude 3\\.5 Haiku ÊòØ‰∏Ä‰∏™Âºï‰∫∫Ê≥®ÁõÆÁöÑÈÄâÊã©„ÄÇÂÆÉ‰∏ç‰ªÖ‰ªÖÊòØ‰∏ÄÊ¨°ÂçáÁ∫ßÔºõÂÆÉÈáçÊñ∞ÂÆö‰πâ‰∫ÜÂú®‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÈÄüÂ∫¶‰∏éÊô∫ËÉΩ‰∫§Ê±áÂ§ÑÁöÑÂèØËÉΩÊÄß„ÄÇ\n\nÁé∞Âú®ÁöÑÈóÆÈ¢òÊòØÔºöÁ´û‰∫âÂØπÊâãÂ∞ÜÂ¶Ç‰ΩïÂõûÂ∫îÔºüÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàë‰ª¨Ë¶ÅÁ≠âÂ§ö‰πÖÊâçËÉΩÁúãÂà∞ Claude 4\\.0ÔºöÊâìÊ≤πËØóÁâàÔºü\n\n## Â∏∏ËßÅÈóÆÈ¢òËß£Á≠î\n\n**ÈóÆÔºöClaude 3\\.5 Haiku ËÉΩÂàÜÊûêÂõæÂÉèÂêóÔºü**Á≠îÔºöËøò‰∏çËÉΩÔºå‰ΩÜAnthropicËÆ°ÂàíÂú®Êú™Êù•Ê∑ªÂä†Ê≠§ÂäüËÉΩ„ÄÇÁõÆÂâçÔºåÂÆÉ‰ªÖÊîØÊåÅÊñáÊú¨„ÄÇ\n\n**ÈóÆÔºöClaude 3\\.5 Haiku ÊØîÂÖ∂ÂâçË∫´Ë¥µÂ§öÂ∞ëÔºü**Á≠îÔºöË¥µÂõõÂÄçÔºå‰ΩÜÂèØ‰ª•ÈÄöËøáÊèêÁ§∫ÁºìÂ≠òÂíåÊâπÂ§ÑÁêÜÊù•Èôç‰ΩéÊàêÊú¨„ÄÇ\n\n**ÈóÆÔºöClaude 3\\.5 Haiku ÊúÄ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂäüËÉΩÊòØ‰ªÄ‰πàÔºü**Á≠îÔºöÂÆÉÂú®ÂêÑÁßçÊô∫ËÉΩÂü∫ÂáÜÊµãËØï‰∏≠ËÉΩÂ§üË∂ÖË∂äÊõ¥Â§ßÁöÑÊ®°ÂûãÔºåÂ¶ÇClaude 3 OpusÔºåÂêåÊó∂‰øùÊåÅÈ´òÈÄüÂ∫¶„ÄÇ\n\n**ÈóÆÔºöÊàëÂèØ‰ª•Áî® Claude 3\\.5 Haiku ËøõË°åËΩØ‰ª∂ÂºÄÂèëÂêóÔºü**Á≠îÔºöÂΩìÁÑ∂ÂèØ‰ª•„ÄÇÂÆÉÂú®ÁºñÁ†Å‰ªªÂä°‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåËÉΩÂ§üÊèê‰æõÂø´ÈÄü„ÄÅÂáÜÁ°ÆÁöÑ‰ª£Á†ÅÂª∫ËÆÆÂíåË°•ÂÖ®„ÄÇ\n\n**ÈóÆÔºöClaude 3\\.5 Haiku ÂêëÂÖ¨‰ºóÂºÄÊîæÂêóÔºü**Á≠îÔºöÊòØÁöÑÔºåÂèØ‰ª•ÈÄöËøáAnthropicÁöÑAPI„ÄÅAmazon BedrockÂíåGoogle CloudÁöÑVertex AIËÆøÈóÆ„ÄÇ\n\n\\#Claude35Haiku \\#AnthropicAI \\#AIInnovation \\#MachineLearning \\#AIForDevelopers \\#FutureOfAI \\#AIPerformance \\#TechInnovation\n\n‚ÄúClaude 3\\.5 Haiku ÊÄßËÉΩÂü∫ÂáÜ‚ÄùÔºå‚ÄúAI Ê®°ÂûãÂÆö‰ª∑ÊØîËæÉ‚ÄùÔºå‚ÄúÁî®‰∫éËΩØ‰ª∂ÂºÄÂèëÁöÑÂø´ÈÄü AI Ê®°Âûã‚ÄùÔºå‚ÄúAnthropic AI Ê®°ÂûãËÉΩÂäõ‚ÄùÔºå‚ÄúÊàêÊú¨ÊïàÁõäÈ´òÁöÑ AI ÂÆûÊñΩÁ≠ñÁï•‚Äù\n\n"},{"lang":"zh","group":"blog","slug":"blog/claude-3-5-sonnet-new-pioneering-the-future-of-ai-with-computer-control-capabilities-37a6ff9f9033","frontmatter":{"title":"Claude 3.5 SonnetÔºàÊñ∞ÔºâÔºöÂà©Áî®ËÆ°ÁÆóÊú∫ÊéßÂà∂ËÉΩÂäõÂºÄÊãì‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú™Êù•","meta_title":"Claude 3.5 SonnetÔºàÊñ∞ÔºâÔºöÂà©Áî®ËÆ°ÁÆóÊú∫ÊéßÂà∂ËÉΩÂäõÂºÄÊãì‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú™Êù•","description":"Anthropic ‰∫é 2024 Âπ¥ 10 Êúà 22 Êó•ÂèëÂ∏É‰∫ÜÂÖ∂ÊúÄÊñ∞ÁöÑ AI Ê®°Âûã Claude 3.5 Sonnet„ÄÇÊ≠§ÁâàÊú¨ÂºïÂÖ•‰∫ÜÈù©ÂëΩÊÄßÁöÑËÆ°ÁÆóÊú∫ÊéßÂà∂‚Ä¶‚Ä¶","date":"2024-10-27T13:57:00.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*n0NkOFbhUm7_fllJ","categories":["Programming","Technology","Generative AI"],"author":"Rifx.Online","tags":["Claude","Sonnet","automation","benchmarks","safety"],"draft":false,"slug":"blog/claude-3-5-sonnet-new-pioneering-the-future-of-ai-with-computer-control-capabilities-37a6ff9f9033"},"content":"\n\n\n\n\nAnthropic‰∫é2024Âπ¥10Êúà22Êó•ÂèëÂ∏É‰∫ÜÊúÄÊñ∞ÁöÑAIÊ®°ÂûãClaude 3.5 Sonnet„ÄÇÊ≠§Ê¨°ÂèëÂ∏ÉÂºïÂÖ•‰∫ÜÈù©ÂëΩÊÄßÁöÑËÆ°ÁÆóÊú∫ÊéßÂà∂ËÉΩÂäõÔºåÂπ∂Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊòæËëóÊîπËøõÔºå‰∏∫AIË°å‰∏öËÆæÂÆö‰∫ÜÊñ∞Ê†áÂáÜ„ÄÇ\n\n## Èù©ÂëΩÊÄßÁöÑËÆ°ÁÆóÊú∫ÊéßÂà∂ÔºöÊñ∞ÂâçÊ≤ø\n\nClaude 3.5 Sonnet ÁöÑÁ™ÅÂá∫ÁâπÁÇπÊòØÂÖ∂ËÉΩÂ§üÂÉè‰∫∫Á±ª‰∏ÄÊ†∑‰∏éËÆ°ÁÆóÊú∫ËøõË°å‰∫§‰∫í„ÄÇËøô‰∏ÄÁ™ÅÁ†¥ÊÄßÁöÑËÉΩÂäõ‰ΩøÂæó AI ÂèØ‰ª•Ôºö\n\n* ‰ΩøÁî®Èº†Ê†áÂíåÈîÆÁõòËæìÂÖ•ÂØºËà™Ê°åÈù¢ÁïåÈù¢\n* ‰∏éÂêÑÁßçÂ∫îÁî®Á®ãÂ∫èÂíåÁΩëÈ°µÊµèËßàÂô®ËøõË°å‰∫§‰∫í\n* ÊâßË°åÂ§çÊùÇÁöÑÂ§öÊ≠•È™§‰ªªÂä°\n* ÊâßË°åÊñá‰ª∂ÁÆ°ÁêÜÊìç‰Ωú\n* Ëá™Âä®ÂåñÈáçÂ§çÁöÑÂ∑•‰ΩúÊµÅÁ®ã\n\nËøô‰∏ÄËÆ°ÁÆóÊú∫ÊéßÂà∂ÂäüËÉΩÁõÆÂâçÂ§Ñ‰∫éÂÖ¨ÂºÄÊµãËØïÈò∂ÊÆµÔºå‰ª£Ë°®‰∫Ü AI Á≥ªÁªü‰∏éÊï∞Â≠óÁïåÈù¢‰∫§‰∫íÊñπÂºèÁöÑËåÉÂºèËΩ¨Âèò„ÄÇÂ∞ΩÁÆ°‰ªçÂ§Ñ‰∫éÂÆûÈ™åÈò∂ÊÆµÔºå‰ΩÜÊó©ÊúüÊµãËØïÊòæÁ§∫Âá∫ËâØÂ•ΩÁöÑÁªìÊûúÔºåClaude 3.5 Sonnet Âú®‰ªÖÊà™Âõæ‰ªªÂä°ÁöÑ OSWorld Âü∫ÂáÜÊµãËØï‰∏≠ÂæóÂàÜ‰∏∫ 14.9% ‚Äî ÊòæËëóÈ´ò‰∫é‰∏ã‰∏Ä‰∏™ÊúÄ‰Ω≥Á≥ªÁªüÁöÑ 7.8%„ÄÇ\n\n## Âü∫ÂáÜÁ™ÅÁ†¥ÊÄßËÉΩ\n\nÂçáÁ∫ßÂêéÁöÑÊ®°ÂûãÂú®Â§ö‰∏™ÊåáÊ†á‰∏äË°®Áé∞Âá∫ÊòæËëóÁöÑÊîπËøõÔºö\n\n## ÁºñÁ†ÅÂíåÊäÄÊúØ‰ªªÂä°\n\n* Âú®SWE-bench Verified‰∏äÁöÑÊÄßËÉΩ‰∏∫49%ÔºàËæÉ‰πãÂâçÁöÑ33.4%ÊúâÊâÄÊèêÂçáÔºâ\n* Âú®HumanEvalÁºñÁ†Å‰ªªÂä°‰∏≠ÁöÑÂæóÂàÜ‰∏∫93.7%\n* Âú®ËΩØ‰ª∂Â∑•Á®ãÊñπÈù¢ÁöÑË°®Áé∞‰ºò‰∫é‰∏ì‰∏öÁºñÁ†ÅÁ≥ªÁªü\n\n## Â≠¶ÊúØÂíåÊé®ÁêÜËÉΩÂäõ\n\n* 65% ÁöÑÁ†îÁ©∂ÁîüÁ∫ßÊé®ÁêÜ (GPQA-Diamond)\n* 78% ÁöÑÊú¨ÁßëÁ∫ßÁü•ËØÜ (MMLU Pro)\n* 78.3% ÁöÑÊï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõ (MATH)\n\n## ÂïÜ‰∏öÂ∫îÁî®\n\n* 69.2% Âú®Èõ∂ÂîÆÈ¢ÜÂüü‰ªªÂä°‰∏ä (TAU-bench)\n* 46% Âú®Ëà™Á©∫È¢ÜÂüü‰ªªÂä°‰∏ä\n* 90.8% Âú®ÂõæË°®ÂàÜÊûê‰∏äÁöÑÂáÜÁ°ÆÁéá\n* 94.2% Âú®ÊñáÊ°£ÈóÆÁ≠î‰∏äÁöÑÂáÜÁ°ÆÁéá\n\n## ‰ºÅ‰∏öÈõÜÊàê‰∏éÂèØÁî®ÊÄß\n\nClaude 3.5 Sonnet ÂèØ‰ª•ÈÄöËøáÂ§ö‰∏™Âπ≥Âè∞ËÆøÈóÆÔºö\n\n* Anthropic API\n* Amazon Bedrock\n* Google Cloud‚Äôs Vertex AI\n\nÂåÖÊã¨ Asana„ÄÅCanva„ÄÅDoorDash Âíå Replit Âú®ÂÜÖÁöÑ‰∏ªË¶ÅÂÖ¨Âè∏Â∑≤ÁªèÂºÄÂßãÂú®ÂÖ∂Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÂÆûÊñΩ Claude 3.5 Sonnet ÁöÑÂäüËÉΩÔºåÁâπÂà´ÊòØÂà©Áî®ÂÖ∂ËÆ°ÁÆóÊú∫ÊéßÂà∂ÂäüËÉΩÊù•Â§ÑÁêÜÂ§çÊùÇÁöÑËá™Âä®Âåñ‰ªªÂä°„ÄÇ\n\n## ÂÆûÈôÖÂ∫îÁî®\n\n## ËΩØ‰ª∂ÂºÄÂèë\n\n* Ëá™Âä®Âåñ‰ª£Á†ÅÊµãËØïÂíåË∞ÉËØï\n* Êô∫ËÉΩIDE‰∫§‰∫í\n* ‰ª£Á†ÅÂÆ°Êü•‰∏é‰ºòÂåñ\n* ÊñáÊ°£ÁîüÊàê\n\n## ÂÆ¢Êà∑ÊîØÊåÅ\n\n* È´òÁ∫ßËÅäÂ§©Êú∫Âô®‰∫∫ÂäüËÉΩ\n* ÂèØËßÜÂåñÊï∞ÊçÆËß£ËØª\n* Ëá™Âä®ÂåñÂ∑•ÂçïËß£ÂÜ≥\n* ÊµÅÁ®ãËá™Âä®Âåñ\n\n## ÂïÜ‰∏öËøêËê•\n\n* ÊñáÊ°£Â§ÑÁêÜ‰∏éÂàÜÊûê\n* ‰ªéËßÜËßâÊ∫êÊèêÂèñÊï∞ÊçÆ\n* Â∑•‰ΩúÊµÅËá™Âä®Âåñ\n* Â§çÊùÇÈóÆÈ¢òËß£ÂÜ≥\n\n## ÂÆâÂÖ®‰∏éË¥£‰ªª\n\nAnthropic Â∑≤ÂÆûÊñΩÂº∫ÊúâÂäõÁöÑÂÆâÂÖ®Êé™ÊñΩÁî®‰∫éËÆ°ÁÆóÊú∫ÊéßÂà∂ÂäüËÉΩÔºö\n\n* Êñ∞ÂàÜÁ±ªÂô®‰ª•ËØÜÂà´ÊΩúÂú®ÁöÑËØØÁî®\n* ‰∏ªÂä®ÁõëÊéßÁ≥ªÁªü\n* ÈôêÂà∂ÂØπÊïèÊÑüÊìç‰ΩúÁöÑËÆøÈóÆ\n* ÂÆöÊúüÂÆâÂÖ®ËØÑ‰º∞\n\n## Â±ïÊúõÊú™Êù•\n\nËôΩÁÑ∂Claude 3.5 SonnetÂú®‰∫∫Â∑•Êô∫ËÉΩËÉΩÂäõÊñπÈù¢‰ª£Ë°®‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜÈáçË¶ÅÁöÑÊòØË¶ÅÊ≥®ÊÑèÊüê‰∫õÂäüËÉΩÔºåÁâπÂà´ÊòØËÆ°ÁÆóÊú∫ÊéßÂà∂Ôºå‰ªçÂ§Ñ‰∫éÊó©ÊúüÈò∂ÊÆµ„ÄÇÊüê‰∫õÊìç‰ΩúÂ¶ÇÊªöÂä®„ÄÅÊãñÂä®ÂíåÁº©ÊîæÈù¢‰∏¥ÊåëÊàòÔºåAnthropicÈºìÂä±ÂºÄÂèëËÄÖÂú®Êé¢Á¥¢Ëøô‰∫õÊñ∞ÂäüËÉΩÊó∂Ôºå‰ªé‰ΩéÈ£éÈô©‰ªªÂä°ÂºÄÂßã„ÄÇ\n\nClaude 3.5 SonnetÁöÑÂèëÂ∏ÉÊ†áÂøóÁùÄ‰∫∫Â∑•Êô∫ËÉΩÂèëÂ±ïÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÊó∂ÂàªÔºåÂ∞ÜÂÖàËøõÁöÑÊé®ÁêÜËÉΩÂäõ‰∏éÂÆûÁî®ÁöÑËÆ°ÁÆóÊú∫ÊéßÂà∂ÂäüËÉΩÁõ∏ÁªìÂêà„ÄÇÈöèÁùÄÊäÄÊúØÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåÊàë‰ª¨ÂèØ‰ª•ÊúüÂæÖÁúãÂà∞Êõ¥Â§öÂàõÊñ∞ÁöÑÂ∫îÁî®‰ª•Âèä‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªü‰∏éÊàë‰ª¨ÁöÑÊï∞Â≠ó‰∏ñÁïå‰∫íÂä®ÊñπÂºèÁöÑÊîπËøõ„ÄÇ\n\n*Êú¨ÊñáÂü∫‰∫éAnthropic„ÄÅAWSÂíåÂêÑÁ±ªÊäÄÊúØÂêà‰Ωú‰ºô‰º¥ÁöÑÂÆòÊñπÂÖ¨ÂëäÂíåÊñáÊ°£„ÄÇÊúâÂÖ≥ÊúÄÊñ∞‰ø°ÊÅØÔºåËØ∑ÂèÇËÄÉAnthropicÁöÑÂÆòÊñπÊñáÊ°£„ÄÇ*\n\n"},{"lang":"zh","group":"blog","slug":"blog/claude-3-5-sonnet-v-s-gpt-4o-which-one-is-better-3b3675195bf9","frontmatter":{"title":"Claude 3.5 Sonnet V/S GPT-4OÔºöÂì™‰∏Ä‰∏™Êõ¥Â•Ω","meta_title":"Claude 3.5 Sonnet V/S GPT-4OÔºöÂì™‰∏Ä‰∏™Êõ¥Â•Ω","description":"2022 Âπ¥ 11 ÊúàÔºåOpenAI Êé®Âá∫‰∫Ü ChatGPT Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂΩªÂ∫ïÊîπÂèò‰∫ÜÊàë‰ª¨ÊêúÁ¥¢Âíå‰∏é‰ø°ÊÅØ‰∫§‰∫íÁöÑÊñπÂºè„ÄÇÊòéÂπ¥ÔºåÂú®‚Ä¶","date":"2024-10-27T13:59:09.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4MXLuSFfGwFkWWn0","categories":["Generative AI","Machine Learning","Natural Language Processing"],"author":"Rifx.Online","tags":["GPT-4o","Claude","multimodal","reasoning","code-generation"],"draft":false,"slug":"blog/claude-3-5-sonnet-v-s-gpt-4o-which-one-is-better-3b3675195bf9"},"content":"\n\n\nÂú®2022Âπ¥11ÊúàÔºåOpenAIÊé®Âá∫‰∫ÜChatGPTÔºåËøô‰∏ÄÊ®°ÂûãÂΩªÂ∫ïÊîπÂèò‰∫ÜÊàë‰ª¨ÊêúÁ¥¢Âíå‰∏é‰ø°ÊÅØ‰∫íÂä®ÁöÑÊñπÂºè„ÄÇÊ¨°Âπ¥3ÊúàÔºåÁî±ÂâçOpenAIÂëòÂ∑•ÂàõÂäûÁöÑÁæéÂõΩÂàùÂàõÂÖ¨Âè∏‚ÄúAnthropic‚ÄùÊé®Âá∫‰∫Ü‰ªñ‰ª¨Ëá™Â∑±ÁöÑAIÊ®°Âûã‚ÄúClaude‚Äù„ÄÇËá™ÂèëÂ∏É‰ª•Êù•ÔºåËøô‰∏§ÂÆ∂AIÂÖ¨Âè∏‰∏ÄÁõ¥Âú®Á´û‰∫âÔºå‰ª•ÈÄöËøáÂÖ∂AIÊ®°Âûã‰∏∫ÂÆ¢Êà∑Êèê‰æõÊúÄ‰Ω≥ÁöÑÂäüËÉΩÂíå‰ΩìÈ™å„ÄÇÊúÄËøëÔºåOpenAIÊé®Âá∫‰∫Ü‚ÄúGPT-4o‚ÄùÔºåËøôÊòØ‰∏Ä‰∏™‰ª§‰∫∫ÊÉäÂèπÁöÑÊ®°ÂûãÔºåËÉΩÂ§üÂá∫Ëâ≤Âú∞Â§ÑÁêÜÊñá‰ª∂„ÄÅËØ≠Èü≥ÂíåËßÜÈ¢ëÊï∞ÊçÆ„ÄÇÂêåÊ†∑ÔºåClaudeÊé®Âá∫‰∫Ü‚ÄúClaude 3.5 Sonnet‚ÄùÔºå‰ªñ‰ª¨Â£∞Áß∞ËøôÊòØÊúÄÂÖàËøõÁöÑAIÊ®°ÂûãÔºåËÉΩÂ§üÂ§ÑÁêÜÂ§çÊùÇ‰ªªÂä°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÁ°ÆÂÆöClaude 3.5 SonnetÂíåGPT-4o‰πãÈó¥Âì™‰∏™Êõ¥Â•ΩÔºåÂπ∂ÊØîËæÉÂÖ∂Âú®Áõ∏ÂêåËæìÂÖ•‰∏ãÁöÑÂäüËÉΩÂíåËæìÂá∫Ôºå‰ª•Ê£ÄÊü•Âì™‰∏™Êõ¥ÈÄÇÂêàÊÇ®„ÄÇ\n\n## ËÉΩÂäõÂíåÁâπÊÄß\n\n### GPT-4o\n\n\n\nGPT-4o ÊòØ OpenAI ÊúÄÊñ∞Êé®Âá∫ÁöÑ LLM„ÄÇ‚Äúo‚Äù ‰ª£Ë°® omniÔºåÊÑè‰∏∫Êãâ‰∏ÅËØ≠‰∏≠ÁöÑ‚ÄúÊØè‰∏Ä‰∏™‚Äù„ÄÇËØ•Ê®°ÂûãÂèØ‰ª•ÂàÜÊûêËØ≠Èü≥„ÄÅÂõæÂÉè„ÄÅËßÜÈ¢ëÂíåÊñá‰ª∂‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂Áõ∏Â∫îÂú∞ÂÅöÂá∫ÂõûÂ∫î„ÄÇÂÆÉÂèØ‰ª•Êé•ÂèóËØ≠Èü≥ËæìÂÖ•ÔºåÂπ∂‰ª•‰∏çÂêåËßíËâ≤ÁöÑÂ£∞Èü≥ËæìÂá∫ÔºåÂåÖÊã¨ËØ≠Ë∞É„ÄÅÊÉÖÊÑüÁ≠â„ÄÇÊï¥‰∏™ËøáÁ®ã‰∏é‰∫∫Á±ªÂØπËØùÁöÑÂª∂ËøüÁõ∏ÂΩì‰ΩéÔºåÂπ≥Âùá‰∏∫ 0.32 ÁßíÔºåËÄåÂÖ∂‰ªñËØ≠Èü≥Ê®°ÂûãÂàô‰∏∫ 2.8 Áßí„ÄÇÂÆÉËøòÂÖÅËÆ∏Áî®Êà∑ÁîüÊàê‰π¶Èù¢ÂÜÖÂÆπÔºåÂ¶ÇÊñáÁ´†„ÄÅÂçöÂÆ¢„ÄÅ‰∫ßÂìÅÊèèËø∞„ÄÅ‰∏çÂêåÁºñÁ®ãËØ≠Ë®ÄÁöÑ‰ª£Á†Å„ÄÅÊï∞ÊçÆÂàÜÊûê„ÄÅÂõæË°®Á≠â„ÄÇÊ≠§Â§ñÔºåGPT-4o ËøòÂèØ‰ª•ÂàÜÊûêÂõæÂÉèÂíåËßÜÈ¢ëÔºå‰ΩøËØ•Ê®°ÂûãÂèØ‰ª•ÂÖÖÂΩìËØ≠Ë®ÄÁøªËØëÂô®„ÄÅ‰∏™‰∫∫Âä©ÁêÜ„ÄÅËôöÊãüÊïôÂ∏àÊàñË¥≠Áâ©Âä©Êâã„ÄÇÂÆÉËøòÂèØ‰ª•Áî®‰∫éÂåªÂ≠¶„ÄÅÂ∑•Á®ã„ÄÅÂÜõ‰∫ãÁ≠âÈ¢ÜÂüü„ÄÇË¶Å‰ΩøÁî®Ê≠§ÂäüËÉΩÔºåGPT-4o ÂèØ‰ª•‰ΩøÁî®Áî®Êà∑ÁöÑÊëÑÂÉèÂ§¥Ëé∑ÂèñÂÆûÊó∂ËßÜÂõæÔºåÂπ∂Âú®ËØ≠Èü≥Ê®°Âºè‰∏ãÁõ∏Â∫îÂú∞ÂõûÂ∫î„ÄÇÂÆÉËøòÂèØ‰ª•ËÆøÈóÆÊÇ®ÁöÑËÆ°ÁÆóÊú∫Â±èÂπïÔºåÂπ∂ÊèèËø∞Â±èÂπï‰∏äÊòæÁ§∫ÁöÑÂÜÖÂÆπÔºåÁî®Êà∑ÂèØ‰ª•ËØ¢ÈóÆ‰∏éÂ±èÂπï‰∏äÊòæÁ§∫ÁöÑÂÜÖÂÆπÁõ∏ÂÖ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n\n*‰æãÂ¶ÇÔºåÁî®Êà∑ÂèØ‰ª•Âú®Â±èÂπï‰∏äÂêØÁî®ËØ•Ê®°ÂûãÔºåÊâìÂºÄ VS ‰ª£Á†ÅÔºåÂπ∂ÊèêÁ§∫Ê®°ÂûãÂÖÖÂΩìÁºñÁ†ÅÂä©ÊâãÔºå‰ª•Ëé∑ÂèñÁºñÁ†ÅÈóÆÈ¢òÁöÑÁ≠îÊ°à„ÄÇÊàñËÄÖÔºåÊÇ®ÂèØ‰ª•ÂêØÁî®ÊëÑÂÉèÂ§¥ÔºåÂÖÖÂΩìÂÅ•Ë∫´ÊïôÁªÉÔºåÊ£ÄÊü•ÊÇ®ÊòØÂê¶ÂÅöÂæóÊ≠£Á°Æ„ÄÇ*\n\nËØ•Ê®°ÂûãÂÖ∑ÊúâÁã¨ÁâπÁöÑÂäüËÉΩÔºåÂ¶ÇÊï∞ÊçÆÂàÜÊûê„ÄÅ‰ª£Á†ÅËß£ÈáäÂô®ÂíåÂÆûÊó∂ÁΩëÈ°µÊµèËßàÔºå‰ΩøÂÖ∂‰∏éÁ´û‰∫âÂØπÊâã‰∏çÂêå„ÄÇËØ•Ê®°ÂûãËøòÊúâÂ§ßÈáèÁöÑ GPTsÔºåËøôÊòØ ChatGPT ÁöÑÂÆöÂà∂ÁâàÊú¨„ÄÇ\n\n### Claude 3.5 Sonnet\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*BSMcOpvWZ5lUm4Tl)\n\nClaude 3.5 Sonnet ÊòØÁî± Anthropic Êé®Âá∫ÁöÑ AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇÂÆÉÊòØ Claude AI Ê®°ÂûãÁ≥ªÂàóÁöÑÁ¨¨‰∏â‰ª£„ÄÇËøô‰∏ÄÊ®°ÂûãÂú®Â§ö‰∏™ËØÑ‰º∞‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰øùÊåÅ‰∫ÜÈ´òÂü∫ÂáÜÔºåÈÅøÂÖç‰∫ÜÂπªËßâÂíåÈîôËØØ‰ø°ÊÅØ„ÄÇËôΩÁÑ∂ÂÆÉ‰∏çÊîØÊåÅÂÉè GPT-4o ÈÇ£Ê†∑ÁöÑËØ≠Èü≥ÂíåËßÜÈ¢ëÂäüËÉΩÔºå‰ΩÜÂÆÉ‰ªçÁÑ∂ÂèØ‰ª•ÊâßË°åÊâÄÊúâÂü∫Êú¨‰ªªÂä°Ôºå‰æãÂ¶ÇÊñáÊú¨ÁîüÊàêÂíå‰∏çÂêåÁºñÁ®ãËØ≠Ë®ÄÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÅÂ§¥ËÑëÈ£éÊö¥Á≠â„ÄÇÊ†πÊçÆ Anthropic ÁöÑÊä•ÂëäÔºåClaude 3.5 Sonnet ÊòØÂ∏ÇÂú∫‰∏äÊúÄÂ•ΩÁöÑËÆ°ÁÆóÊú∫ËßÜËßâÊ®°Âûã‰πã‰∏ÄÔºåÂèØ‰ª•Áî®‰∫éÂàÜÊûêÂõæË°®ÂíåÂõæÂΩ¢Ôºå‰ªéÂõæÂÉè‰∏≠ËΩ¨ÂΩïÊñáÊú¨Á≠â„ÄÇClaude Êã•Êúâ‰∏Ä‰∏™ÂÖàËøõÁöÑÂäüËÉΩÔºå‚ÄúArtifacts‚ÄùÔºåËøôÊòØ‰∏Ä‰∏™Âú®ÂØπËØù‰∏≠Âá∫Áé∞ÁöÑÁâπÊÆäÂºπÂá∫Á™óÂè£ÔºåÂÖÅËÆ∏Áî®Êà∑Êü•Áúã‰ª£Á†ÅÁâáÊÆµ„ÄÅÊñáÊú¨Êñá‰ª∂ÊàñÁΩëÁ´ôËÆæËÆ°ÔºåÂπ∂ÂÖÅËÆ∏‰ªñ‰ª¨ÂÆûÊó∂ÁºñËæëËæìÂá∫„ÄÇ\n\n*‰æãÂ¶ÇÔºåÁî®Êà∑ÂèØ‰ª•Âú®Â∑•‰ΩúÊµÅÁ®ã‰∏≠‰ΩøÁî®ËÆ°ÁÆóÊú∫ËßÜËßâÂíå artifacts„ÄÇÁî®Êà∑ÂèØ‰ª•Âú®Á∫∏‰∏äËøõË°åÁΩëÁ´ôËÆæËÆ°ÁöÑÂü∫Êú¨ÂéüÂûãÂà∂‰ΩúÔºåÂ∞ÜÊñá‰ª∂ÈôÑÂä†Âà∞ Claude 3.5 SonnetÔºåÂπ∂ÊèêÁ§∫ÂÆÉÊ†πÊçÆÂéüÂûãËÆæËÆ°ÁΩëÁ´ô„ÄÇÁîüÊàêÁöÑ‰ª£Á†ÅÂíåÁΩëÁ´ôËÆæËÆ°‰ºöÂá∫Áé∞Âú® artifacts ‰∏≠„ÄÇÁî®Êà∑ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÈúÄÊ±ÇÁºñËæë‰ª£Á†ÅÂíåËÆæËÆ°„ÄÇÁî®Êà∑ËøòÂèØ‰ª•Â∞Ü‰ªñ‰ª¨ÁöÑÈ°πÁõÆÂÆûÊó∂ÂèëÂ∏ÉÂà∞‰∫íËÅîÁΩë‰∏ä„ÄÇ*\n\n## ÈÄêÈ°πÊØîËæÉ\n\nÂú®Êú¨ËäÇ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ†πÊçÆÂ§çÊùÇÊé®ÁêÜÂíå‰ª£Á†ÅÁîüÊàêÁ≠âÂõ†Á¥†ÊØîËæÉËøô‰∏§‰∏™ LLMÔºåÊ£ÄÊü•ÂÆÉ‰ª¨Âú®Â§ÑÁêÜÂ§çÊùÇ‰ªªÂä°ÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂπ∂ÁúãÁúãÂì™‰∏™Ê®°ÂûãÊõ¥Â•Ω„ÄÇ\n\n* **Á†îÁ©∂ÁîüÊ∞¥Âπ≥Êé®ÁêÜ(GPQA, Diamond)**Ê≠§Âõ†Á¥†ËØÑ‰º∞Ê®°ÂûãÂ§ÑÁêÜÁ†îÁ©∂ÁîüÊ∞¥Âπ≥ÊïôËÇ≤‰∏≠Â§çÊùÇ„ÄÅÈ´òÁ∫ßÊé®ÁêÜ‰ªªÂä°ÁöÑËÉΩÂäõ„ÄÇÂú®Ê≠§‰ªªÂä°‰∏≠ÔºåÁ†îÁ©∂‰∫∫ÂëòÂú® GPQA ÊµãËØï‰∏≠ÊØîËæÉÊ®°ÂûãÔºåËØ•ÊµãËØïÁî±‰∏ìÂÆ∂ËÆæËÆ°ÔºåÂåÖÂê´448‰∏™‰∏çÂêåÈ¢ÜÂüüÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÈóÆÈ¢òÊòØ Google ProofÔºåÂõ†Ê≠§‰ªª‰Ωï‰∫∫ÈÉΩÊó†Ê≥ïÂú®Á∫øÊâæÂà∞ÂÆÉ‰ª¨„ÄÇClaude ÁöÑÂæóÂàÜÊé•Ëøë 59.4%ÔºåËÄå GPT-4o ÁöÑÂæóÂàÜ‰ªÖ‰∏∫ 53.6%„ÄÇËôΩÁÑ∂‰∏§‰∏™ÂæóÂàÜÁõ∏ÂØπÊé•ËøëÔºå‰ΩÜÊ≠£Â¶ÇÊàë‰ª¨ÊâÄËßÅÔºåClaude Âú®ÈúÄË¶ÅÈ´òÁ∫ßÂàÜÊûêÊÄùÁª¥ÁöÑ‰ªªÂä°‰∏≠ÂèØËÉΩÊòØÊõ¥Â•ΩÁöÑÈÄâÊã©Ôºå‰æãÂ¶ÇÁ†îÁ©∂ÂàÜÊûê„ÄÅÂ§çÊùÇÈóÆÈ¢òËß£ÂÜ≥ÂíåÈ´òÂ≠¶ÊúØÊ∞¥Âπ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n* **Êú¨ÁßëÊ∞¥Âπ≥Áü•ËØÜ(MMLU)**MMLUÔºåÂç≥Â§ßËßÑÊ®°Â§ö‰ªªÂä°ËØ≠Ë®ÄÁêÜËß£ÔºåÊòØ‰∏Ä‰∏™Âü∫ÂáÜÔºåËß£Èáä‰ªª‰Ωï AI Ê®°ÂûãÂú®Êú¨ÁßëÊ∞¥Âπ≥‰∏äÂØπÂêÑ‰∏™Â≠¶ÁßëÁöÑÈÄöÁî®Áü•ËØÜÁêÜËß£„ÄÇClaude 3.5 Sonnet Âú®Ê≠§ÂÆûÈ™å‰∏≠ÁöÑÂæóÂàÜ‰∏∫ 88.3%ÔºåËÄå GPT-4o ÁöÑÂæóÂàÜ‰∏∫ 88.7%„ÄÇËøôË°®ÊòéËøô‰∏§‰∏™ LLM Âú®Â§ö‰∏™È¢ÜÂüüËøõË°å‰∫ÜËÆ≠ÁªÉÔºåÂπ∂ÂØπËøô‰∫õÈ¢ÜÂüüÊúâÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£„ÄÇËøô‰ΩøÂæó AI Ê®°ÂûãÊàê‰∏∫ÈÄöÁî®Áü•ËØÜ‰ªªÂä°„ÄÅÂ§ö‰∏™Â≠¶ÁßëÁöÑÂü∫Á°ÄËæÖÂØºÁ≠âÁöÑÂêàÈÄÇÂ∑•ÂÖ∑„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*A4w-tvsxcmFINaQT)\n\n* **‰ª£Á†Å(HumanEval)**HumanEval ÊòØ‰∏Ä‰∏™Âü∫ÂáÜÔºåËØÑ‰º∞Ê®°ÂûãÁîüÊàê„ÄÅÁêÜËß£ÂíåË∞ÉËØï‰ª£Á†ÅÁöÑËÉΩÂäõ„ÄÇÂú®Ëøô‰∏™Âü∫ÂáÜ‰∏≠ÔºåClaude 3.5 Sonnet ËææÂà∞‰∫Ü 92%ÁöÑÂæóÂàÜÔºåËÄå GPT-4o ÁöÑÂæóÂàÜ‰∏∫ 90.2%„ÄÇClaude 3.5 Sonnet Âú®Ê≠§‰ªªÂä°‰∏≠ÁöÑÁªìÊûúÈùûÂ∏∏Âá∫Ëâ≤ÔºåÂõ†‰∏∫ÂÆÉÊèê‰æõ‰∫ÜÊØî GPT-4o Êõ¥Â•ΩÁöÑÁºñÁ†ÅÁéØÂ¢É‚ÄúArtifacts‚ÄùÂíåÊõ¥Â•ΩÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÇClaude ÂÖÅËÆ∏Áî®Êà∑Âú® Artifacts ÂºπÂá∫Á™óÂè£‰∏≠ËÆæËÆ°„ÄÅÁºñËæëÂíåËøêË°å‰ª£Á†Å„ÄÇÂú® Claude 3.5 Sonnet ÂèëÂ∏ÉÂêéÔºåÂ§ßÂÆ∂ÈÉΩÂú®ÂºÄÂèëÂ∑•ÂÖ∑„ÄÅÁΩëÁ´ôÂíåÂü∫Êú¨Ê∏∏ÊàèÔºåÂπ∂Âú®‰∫íËÅîÁΩë‰∏äÂàÜ‰∫´ÂÆÉ‰ª¨„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåGPT-4o ÁöÑÂæóÂàÜ‰πü‰∏çÈîôÔºå‰ΩÜÂÆÉÁöÑÁïåÈù¢‰∏≠Ê≤°Êúâ‰ªª‰ΩïÁºñÁ†ÅÁéØÂ¢ÉÔºåÂõ†Ê≠§ÂºÄÂèë‰∫∫ÂëòÂøÖÈ°ªËä±Ë¥πÂæàÂ§öÁ≤æÂäõÔºåÂõ†‰∏∫ÂÆÉÁîüÊàêÁöÑ‰ª£Á†ÅÂæàÈöæËææÂà∞ÁªìÊûú„ÄÇ\n* **ÊñáÊú¨Êé®ÁêÜ(DROP, FLscore)**DROPÔºàÊÆµËêΩÁ¶ªÊï£Êé®ÁêÜÔºâÊòØ‰∏Ä‰∏™Âü∫ÂáÜÔºåÊµãÈáèÊ®°ÂûãÁêÜËß£Â§çÊùÇÊñáÊú¨‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇÂú®Ëøô‰∏™ÊåëÊàò‰∏≠ÔºåClaude 3.5 Sonnet ÁöÑÂæóÂàÜ‰∏∫ 87.1%ÔºåËÄå GPT-4o ÁöÑÂæóÂàÜ‰∏∫ 83.4%„ÄÇËøôË°®Êòé Claude 3.5 Sonnet Âú®Ê∂âÂèäËØ¶ÁªÜÊñáÊú¨ÂàÜÊûê„ÄÅÊñáÊú¨ÂÆ°Êü•„ÄÅÂ§çÊùÇÈóÆÁ≠îÁ≥ªÁªüÁ≠â‰ªªÂä°Êó∂Êõ¥Â•Ω‰∏îÊõ¥ÊúâÊïà„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Kcy7sFb2FYpbfrwp)\n\n* **Êï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥(MATH)**Ê≠§ÊµãËØïËØÑ‰º∞‰ªª‰Ωï AI Ê®°ÂûãËß£ÂÜ≥ÂêÑÁßçÊï∞Â≠¶ÈóÆÈ¢òÁöÑËÉΩÂäõ„ÄÇClaude 3.5 Sonnet ÁöÑÂæóÂàÜ‰ªÖ‰∏∫ 71.1%ÔºåËÄå GPT-4o ÁöÑÂæóÂàÜ‰∏∫ 76.6%„ÄÇËøô‰∫õÂæóÂàÜ‰Ωø GPT-4o Êàê‰∏∫Êï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥‰ªªÂä°ÁöÑÊõ¥Â•ΩÊ®°ÂûãÔºåÂπ∂ÂèØÁî®‰∫éË¥¢Âä°Âª∫Ê®°„ÄÅÁßëÂ≠¶ËÆ°ÁÆóÂíåÈ´òÁ∫ßÊï∞ÊçÆÂàÜÊûêÁ≠âÊï∞Â≠¶ËÆ°ÁÆó„ÄÇ\n* **Â§öËØ≠Ë®ÄÊï∞Â≠¶(MSGM)**Ê≠§Âõ†Á¥†ÊèèËø∞‰ªª‰Ωï AI Ê®°ÂûãÂú®Â§öÁßçËØ≠Ë®Ä‰∏≠Ëß£ÂÜ≥Êï∞Â≠¶ÈóÆÈ¢òÁöÑËÉΩÂäõ„ÄÇ‰∏§‰∏™Ê®°ÂûãÁöÑÂæóÂàÜÊé•ËøëÔºöGPT-4o 90.5% Âíå Claude 3.5 Sonnet 91.6%„ÄÇËøôË°®Êòé‰∏§‰∏™Ê®°ÂûãË°®Áé∞Âá∫Ëâ≤ÔºåClaude Áï•ËÉú‰∏ÄÁ≠π„ÄÇËØ•ËÉΩÂäõÂØπ‰∫éÊïôËÇ≤Â∫îÁî®Êàñ‰ªª‰ΩïÈúÄË¶ÅË∑®ËØ≠Ë®ÄÈöúÁ¢çËøõË°åÊï∞Â≠¶Êé®ÁêÜ‰∫§ÊµÅÁöÑÂú∫ÊôØÁâπÂà´ÊúâÁî®„ÄÇ\n* **ËßÜËßâÈóÆÁ≠î(MMU/val)**Ê≠§Âõ†Á¥†ÊèèËø∞ LLM ÂàÜÊûêÂõæÂÉè‰∏≠ÂëàÁé∞ÁöÑ‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇGPT-4o Âú®Ëøô‰∏ÄÂü∫ÂáÜ‰∏≠‰ª• 69.1% Ë∂ÖËøá Claude 3.5 Sonnet ÁöÑ 68.3%„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂú®ÂàÜÊûêÊñáÊ°£‰∏≠ÁöÑÊñáÊú¨Êó∂ÔºåClaude 3.5 Sonnet ÁöÑÂæóÂàÜ‰∏∫ 95.2%ÔºåËÄå GPT-4o ÁöÑÂæóÂàÜ‰∏∫ 92.1%„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*xzjqBV2YL0lVFitX)\n\n* **ÂõæÂÉèÁîüÊàê**ÂõæÂÉèÁîüÊàêÊòØ LLM ‰ªéÊñáÊú¨ÁîüÊàêÂõæÂÉèÁöÑËÉΩÂäõ„ÄÇGPT-4o ÈõÜÊàê‰∫Ü DallE-2ÔºåÂèØ‰ª•ÈÄöËøáÊñáÊú¨ÁîüÊàêÂõæÂÉèÔºåÁªìÊûúÈùûÂ∏∏Âá∫Ëâ≤„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåClaude 3.5 Sonnet Êó†Ê≥ïÂàõÂª∫‰ªª‰ΩïÂõæÂÉè„ÄÇÊ≠§ÂäüËÉΩËøòÂ∏ÆÂä© GPT-4o Êõ¥Â•ΩÂú∞ËÆæËÆ°ÁΩëÁ´ôÂíåÂèÇËÄÉÔºåÂõ†‰∏∫ÂÆÉÂú®ËÆ∏Â§öÂõæÂÉè‰∏äËøõË°å‰∫ÜËÆ≠ÁªÉ„ÄÇ\n* **Áü•ËØÜÊà™Ê≠¢**Âú®ËøôÈáåÔºå‰∏§‰∏™Ê®°ÂûãÈÉΩÂú®ÁâπÂÆöÊó•Êúü‰πãÂâçÁöÑÊúâÈôêÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËÆ≠ÁªÉ„ÄÇClaude 3.5 Sonnet Âú® 2024 Âπ¥ 4 Êúà‰πãÂâçÁöÑÊï∞ÊçÆ‰∏äËøõË°å‰∫ÜËÆ≠ÁªÉÔºåËÄå GPT-4o ÂàôÂú® 2024 Âπ¥‰πãÂâçÁöÑÊï∞ÊçÆ‰∏äËøõË°å‰∫ÜËÆ≠ÁªÉ„ÄÇGPT-4o ÁöÑÁúüÊ≠£‰ºòÂäøÂú®‰∫éÂÆÉÂÖ∑ÊúâÂÆûÊó∂ÁΩëÈ°µÊµèËßàÂäüËÉΩÔºåËøôÊúâÂä©‰∫é LLM ÂÆöÊúüÂú®Êñ∞Êï∞ÊçÆ‰∏äËøõË°åËÆ≠ÁªÉ„ÄÇ\n\n## GPT-4o ÁöÑ‰ºòÁÇπÔºö\n\n* Â§ÑÁêÜËØ≠Èü≥„ÄÅÂõæÂÉèÂíåËßÜÈ¢ëËæìÂÖ•„ÄÇ\n* ÂÆûÊó∂ÁΩëÈ°µÊµèËßàËÉΩÂäõ„ÄÇ\n* Êõ¥Âø´ÁöÑÂìçÂ∫îÊó∂Èó¥ÔºàÂπ≥Âùá 0.32 ÁßíÔºâ„ÄÇ\n* Âú®Êï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥ÊñπÈù¢Ë°®Áé∞‰ºòË∂ä„ÄÇ\n* ÂèØ‰ª•‰ΩøÁî® DALL-E 2 ÁîüÊàêÂõæÂÉè„ÄÇ\n\n## GPT-4o ÁöÑÁº∫ÁÇπÔºö\n\n* Á†îÁ©∂ÁîüÊ∞¥Âπ≥Êé®ÁêÜÁöÑÊÄßËÉΩÁ®ç‰Ωé„ÄÇ\n* Ê≤°ÊúâÂÜÖÁΩÆÁöÑÁºñÁ†ÅÁéØÂ¢É„ÄÇ\n* ÊñáÊ°£ËßÜËßâÈóÆÁ≠îÂæóÂàÜËæÉ‰Ωé„ÄÇ\n* ‰ª£Á†ÅÁîüÊàêËÉΩÂäõÁ®çÈÄä„ÄÇ\n* Âú®ËØ¶ÁªÜÊñáÊú¨ÂàÜÊûêÊñπÈù¢ÊïàÊûúËæÉÂ∑Æ„ÄÇ\n\n## Pros Claude 3.5 Sonnet:\n\n* Âú®Á†îÁ©∂ÁîüÁ∫ßÂà´ÁöÑÊé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n* ‰ºòË∂äÁöÑ‰ª£Á†ÅÁîüÊàêÂíåÂÜÖÁΩÆÁöÑ‚ÄúÂ∑•‰ª∂‚ÄùÂäüËÉΩ„ÄÇ\n* Âú®ËØ¶ÁªÜÊñáÊú¨ÂàÜÊûê‰∏≠Ë°®Áé∞Êõ¥‰Ω≥„ÄÇ\n* Âú®ÊñáÊ°£ËßÜËßâÈóÆÁ≠î‰∏≠ÂæóÂàÜÊõ¥È´ò„ÄÇ\n* Âú®Â§öËØ≠Ë®ÄÊï∞Â≠¶ÊñπÈù¢Áï•Êúâ‰ºòÂäø„ÄÇ\n\n## Cons Claude 3.5 È¢ÇÔºö\n\n* Êó†Ê≥ïÂ§ÑÁêÜËØ≠Èü≥ÊàñËßÜÈ¢ëËæìÂÖ•„ÄÇ\n* Ê≤°ÊúâÂõæÂÉèÁîüÊàêËÉΩÂäõ„ÄÇ\n* Âú®ËßÜËßâÈóÆÁ≠îÊñπÈù¢ÊÄßËÉΩÁ®ç‰Ωé„ÄÇ\n* Êó†Ê≥ïËÆøÈóÆÂÆûÊó∂ÁΩëÁªú‰ø°ÊÅØ„ÄÇ\n* Âú®Êï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥ÊñπÈù¢ËæÉÂº±„ÄÇ\n\n## ÁªìËÆ∫\n\nGPT-4o Âíå Claude 3.5 Sonnet Âú®ÂêÑÁßç‰ªªÂä°‰∏≠Â±ïÁé∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂêÑËá™ÊúâÂÖ∂‰ºòÂäø„ÄÇGPT-4o Âú®Â§öÊ®°ÊÄÅËæìÂÖ•„ÄÅÂÆûÊó∂‰ø°ÊÅØËÆøÈóÆÂíåÂõæÂÉèÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩøÂÖ∂Âú®Â§öÁßçÂ∫îÁî®‰∏≠ÈùûÂ∏∏ÁÅµÊ¥ª„ÄÇClaude 3.5 Sonnet Âú®Â§çÊùÇÊé®ÁêÜ„ÄÅ‰ª£Á†ÅÁîüÊàêÂíåËØ¶ÁªÜÊñáÊú¨ÂàÜÊûêÊñπÈù¢Ë°®Áé∞Á™ÅÂá∫ÔºåÂú®ÁâπÂÆöÁöÑÂ≠¶ÊúØÂíå‰∏ì‰∏öËÉåÊôØ‰∏ãÊèê‰æõ‰∫ÜÊõ¥‰ºòÁöÑÊÄßËÉΩ„ÄÇÈÄâÊã©Ëøô‰∏§ÁßçÊ®°ÂûãÂèñÂÜ≥‰∫éÂÖ∑‰ΩìÁöÑ‰ΩøÁî®Ê°à‰æãÂíåÊâÄÈúÄÁöÑÂäüËÉΩ„ÄÇÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑËøõÊ≠•ÔºåÊàë‰ª¨ÂèØ‰ª•ÊúüÂæÖËøõ‰∏ÄÊ≠•ÁöÑÊîπËøõÂíåÈíàÂØπ‰∏çÂêåÈúÄÊ±ÇÁöÑ‰∏ì‰∏öÊ®°Âûã„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/comparative-study-of-langgraph-autogen-and-crewai-for-building-multi-agent-systems-0e7e47f9078e","frontmatter":{"title":"Áî®‰∫éÊûÑÂª∫Â§ö‰ª£ÁêÜÁ≥ªÁªüÁöÑ LangGraph„ÄÅAutogen Âíå Crewai ÊØîËæÉÁ†îÁ©∂","meta_title":"Áî®‰∫éÊûÑÂª∫Â§ö‰ª£ÁêÜÁ≥ªÁªüÁöÑ LangGraph„ÄÅAutogen Âíå Crewai ÊØîËæÉÁ†îÁ©∂","description":"ÂΩìÊàë‰ª¨Ê∂âË∂≥Â§ö‰ª£ÁêÜÁ≥ªÁªüÔºàMASÔºâÈ¢ÜÂüüÊó∂Ôºå‰∫ÜËß£ÂêÑÁßçÁºñÁ®ãËØ≠Ë®ÄÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DBlLuCOA3lWIg6RmpMPg8A.png","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["LangGraph","Autogen","Crewai","multi-agent","scalability"],"draft":false,"slug":"blog/comparative-study-of-langgraph-autogen-and-crewai-for-building-multi-agent-systems-0e7e47f9078e"},"content":"\n\n\nÈöèÁùÄÊàë‰ª¨ËøõÂÖ•Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºàMASÔºâÁöÑÈ¢ÜÂüüÔºå‰∫ÜËß£‰∏ìÈó®‰∏∫Ê≠§ÁõÆÁöÑËÆæËÆ°ÁöÑÂêÑÁßçÁºñÁ®ãËØ≠Ë®ÄËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÈÄöËøáÊØîËæÉ LangGraph„ÄÅAutogen Âíå Crewai ‚Äî‚Äî ËØ•È¢ÜÂüüÁöÑ‰∏âÂ§ßÈáçË¶ÅÂèÇ‰∏éËÄÖÔºåÊ∑±ÂÖ•Êé¢ËÆ® MAS ÂºÄÂèëÁöÑ‰∏ñÁïå„ÄÇ\n\n## ‰ªãÁªç\n\nÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºàMASÔºâÂú®ÂêÑ‰∏™Ë°å‰∏ö‰∏≠ÂèòÂæóË∂äÊù•Ë∂äÈáçË¶Å„ÄÇMASÊòØÁî±Â§ö‰∏™Êô∫ËÉΩ‰ΩìÁªÑÊàêÁöÑÁ≥ªÁªüÔºåËøô‰∫õÊô∫ËÉΩ‰ΩìÁõ∏‰∫í‰πãÈó¥‰ª•Âèä‰∏éÁéØÂ¢ÉËøõË°å‰∫§‰∫íÔºå‰ª•ÂÆûÁé∞ÁâπÂÆöÁõÆÊ†á„ÄÇÂú®ÂèØÁî®‰∫éÊûÑÂª∫MASÁöÑ‰ºóÂ§öÊ°ÜÊû∂‰∏≠ÔºåLangGraph„ÄÅAutogenÂíåCrewaiÊòØ‰∏Ä‰∫õÊúÄÂèóÊ¨¢ËøéÁöÑÈÄâÊã©„ÄÇ\n\n‰Ωú‰∏∫‰ªé‰∫ãMASÈ°πÁõÆÁöÑÂºÄÂèëËÄÖÊàñÁ†îÁ©∂‰∫∫ÂëòÔºåÈÄâÊã©ÂêàÈÄÇÁöÑÊ°ÜÊû∂ÂèØËÉΩ‰ºöËÆ©‰∫∫ÊÑüÂà∞‰∏çÁü•ÊâÄÊé™ÔºåÂ∞§ÂÖ∂ÊòØËÄÉËôëÂà∞ÊòìÁî®ÊÄß„ÄÅÂèØÊâ©Â±ïÊÄß„ÄÅÂÆöÂà∂ÂåñÂíå‰∏éAIÂ∫ìÁöÑÈõÜÊàêÁ≠âÂõ†Á¥†„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜLangGraph„ÄÅAutogenÂíåCrewaiÁöÑÊØîËæÉÁ†îÁ©∂ÔºåÁ™ÅÂá∫‰∫ÜÂÆÉ‰ª¨ÁöÑ‰ºòÁº∫ÁÇπ‰ª•ÂèäÂú®‰∏çÂêåÂ∫îÁî®‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇ\n\n### ÂêÑÊ°ÜÊû∂‰ªãÁªç\n\n## LangGraph: ‰∏Ä‰∏™ÂºÄÊ∫êÊ°ÜÊû∂\n\n**‰ºòÁÇπ**Ôºö\n\n* **Êòì‰∫é‰ΩøÁî®**ÔºöLangGraph Êèê‰æõ‰∫ÜÁÆÄÂçïÁõ¥ËßÇÁöÑ APIÔºå‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üËΩªÊùæ‰∏éÁé∞ÊúâÁ≥ªÁªüÈõÜÊàê„ÄÇ\n* **ÂèØÊâ©Â±ïÊÄß**ÔºöLangGraph ÊîØÊåÅÂ§ßËßÑÊ®°ÂàÜÂ∏ÉÂºèÁ≥ªÁªüÔºå‰ΩøÁî®Êà∑ËÉΩÂ§üÂ§ÑÁêÜÂ§çÊùÇ‰ªªÂä°„ÄÇ\n* **‰∏é AI Â∫ìÁöÑÈõÜÊàê**ÔºöLangGraph ‰∏éÊµÅË°åÁöÑ AI Â∫ìÂ¶Ç TensorFlow„ÄÅPyTorch Âíå Keras ÂÖºÂÆπ„ÄÇ\n\n**Â±ÄÈôêÊÄß**Ôºö\n\n* ÂØπÂàÜÂ∏ÉÂºèÁ≥ªÁªüÁöÑÊîØÊåÅÊúâÈôê\n* ÊØî Autogen Âíå Crewai ÁÅµÊ¥ªÊÄßÂ∑Æ\n\n## Autogen: ‰∏Ä‰∏™Ê®°ÂùóÂåñÁöÑÂºÄÊ∫êÊ°ÜÊû∂\n\n**‰ºòÂäø**Ôºö\n\n* **È´òÂ∫¶ÁÅµÊ¥ªÊÄß**ÔºöAutogen Êèê‰æõ‰∫ÜÊ®°ÂùóÂåñÊû∂ÊûÑÔºå‰ΩøÁî®Êà∑ËÉΩÂ§üÊ†πÊçÆÁâπÂÆöÈúÄÊ±ÇÂÆöÂà∂‰ªñ‰ª¨ÁöÑ MAS„ÄÇ\n* **ÈÄÇÂêàÂ§çÊùÇÂ∫îÁî®**ÔºöAutogen ÁöÑÊ®°ÂùóÂåñ‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÂÖ∑ÊúâÂ§ö‰∏™‰∫íËÅî‰ª£ÁêÜÁöÑÂ§ßÂûãÁ≥ªÁªü„ÄÇ\n* **Âº∫Â§ßÁöÑÁ§æÂå∫ÊîØÊåÅ**ÔºöAutogen Êã•Êúâ‰∏Ä‰∏™Ê¥ªË∑ÉÁöÑÂºÄÂèëËÄÖÂíåÁ†îÁ©∂ËÄÖÁ§æÂå∫Ôºå‰ªñ‰ª¨‰∏∫ËØ•Ê°ÜÊû∂ÂÅöÂá∫Ë¥°ÁåÆÂπ∂Êèê‰æõÊîØÊåÅ„ÄÇ\n\n**Â±ÄÈôêÊÄß**Ôºö\n\n* Â≠¶‰π†Êõ≤Á∫øËæÉÈô°\n* ÈúÄË¶ÅÊõ¥Â§öËµÑÊ∫ê\n\n## Crewai: ÂèØÊâ©Â±ïÁöÑÊï∞ÊçÆÈ©±Âä®Ê°ÜÊû∂\n\n**‰ºòÁÇπ**Ôºö\n\n* **ÂèØÊâ©Â±ïÊÄß**ÔºöCrewai ÂØπÂ§ßËßÑÊ®°Á≥ªÁªüÊèê‰æõ‰∫ÜÂá∫Ëâ≤ÁöÑÊîØÊåÅÔºåÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáèÊï∞ÊçÆÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n* **ÊòìÁî®ÊÄß**ÔºöCrewai Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑ APIÔºå‰æø‰∫é‰∏éÁé∞ÊúâÁ≥ªÁªüÈõÜÊàê„ÄÇ\n* **‰∏é‰∫ëÊúçÂä°ÁöÑÈõÜÊàê**ÔºöCrewai ÂÖÅËÆ∏Áî®Êà∑ËΩªÊùæÂú∞Âú® AWS Âíå Azure Á≠â‰∫ëÂπ≥Âè∞‰∏äÈÉ®ÁΩ≤‰ªñ‰ª¨ÁöÑ MAS„ÄÇ\n\n**Â±ÄÈôêÊÄß**Ôºö\n\n* ÂØπËá™ÂÆö‰πâÊ®°ÂûãÁöÑÊîØÊåÅÊúâÈôê\n* ÁÅµÊ¥ªÊÄß‰∏çÂ¶Ç Autogen\n\n## ÂØπÊØîÁü©Èòµ\n\n\n\n## ÁªìËÆ∫\n\nÊÄª‰πãÔºåÊØè‰∏™Ê°ÜÊû∂ÈÉΩÊúâÂÖ∂Áã¨ÁâπÁöÑ‰ºòÁÇπÂíåÁº∫ÁÇπ„ÄÇLangGraph Êèê‰æõ‰∫ÜÊòìÁî®ÊÄßÂíåÂèØÊâ©Â±ïÊÄßÔºåAutogen Êèê‰æõ‰∫ÜÁÅµÊ¥ªÊÄßÂíåÂèØÂÆöÂà∂ÊÄßÔºåËÄå Crewai Âú®Êï∞ÊçÆÈ©±Âä®ÁöÑÊñπÊ≥ïÂíåÂèØÊâ©Â±ïÊÄßÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\nÂú®ÈÄâÊã©ÊûÑÂª∫ MAS ÁöÑÊ°ÜÊû∂Êó∂ÔºåËØ∑ËÄÉËôëÈ°πÁõÆÁöÑÂÖ∑‰ΩìË¶ÅÊ±ÇÔºö\n\n* **ÊòìÁî®ÊÄß**ÔºöÂ¶ÇÊûúÊÇ®ÈáçËßÜÁÆÄÂçïÊÄßÂíåÂèØÊâ©Â±ïÊÄßÔºåËØ∑ÈÄâÊã© LangGraph„ÄÇ\n* **ÁÅµÊ¥ªÊÄß**ÔºöÂØπ‰∫éÈúÄË¶ÅÂÆöÂà∂ÁöÑÂ§çÊùÇÂ∫îÁî®Á®ãÂ∫èÔºåËØ∑ÈÄâÊã© Autogen„ÄÇ\n* **ÂèØÊâ©Â±ïÊÄß**ÔºöÂØπ‰∫éÈúÄË¶ÅÂ§ßËßÑÊ®°Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂ§ßÂûãÁ≥ªÁªüÔºåËØ∑ËÄÉËôë Crewai„ÄÇ\n\nÈÄöËøá‰∫ÜËß£ÊØè‰∏™Ê°ÜÊû∂ÁöÑ‰ºòÁº∫ÁÇπÔºåÂºÄÂèë‰∫∫ÂëòÂèØ‰ª•ÂÅöÂá∫ÊòéÊô∫ÁöÑÂÜ≥Á≠ñÔºå‰ªéËÄåÈÄâÊã©ÊûÑÂª∫Êõ¥ÊúâÊïàÂíåÈ´òÊïàÁöÑËß£ÂÜ≥ÊñπÊ°àÁöÑ MAS„ÄÇ\n\n## È¢ùÂ§ñËµÑÊ∫ê\n\nÊúâÂÖ≥Ëøõ‰∏ÄÊ≠•ÈòÖËØªÂíåËµÑÊ∫êÔºåËØ∑ÂèÇËßÅÔºö\n\n* [LangGraph ÊñáÊ°£](https://proxy.rifx.online/https://langgraph.com/documentation/)\n* [Autogen ÊïôÁ®ã](https://proxy.rifx.online/https://autogen.com/tutorials)\n* [Crewai API ÂèÇËÄÉ](https://proxy.rifx.online/https://crewai.com/api-reference/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/comparing-leading-text-to-image-image-generation-models-for-adding-text-to-images-7dc001f491ef","frontmatter":{"title":"ÊØîËæÉ‰∏∫ÂõæÂÉèÊ∑ªÂä†ÊñáÊú¨ÁöÑ‰∏ªË¶ÅÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°Âûã","meta_title":"ÊØîËæÉ‰∏∫ÂõæÂÉèÊ∑ªÂä†ÊñáÊú¨ÁöÑ‰∏ªË¶ÅÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°Âûã","description":"Êú¨ÊñáËØÑ‰º∞‰∫Ü‰πùÁßçÈ¢ÜÂÖàÁöÑÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°ÂûãÂú®ÂõæÂÉè‰∏≠ÂáÜÁ°ÆÊ∏≤ÊüìÊñáÊú¨ÁöÑËÉΩÂäõ„ÄÇÊµãËØïÁªìÊûúÊòæÁ§∫ÔºåBlack Forest LabsÁöÑFLUX1.1 [pro]ÂíåStability AIÁöÑStable Image UltraÂú®ÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨ÊñπÈù¢Ë°®Áé∞ÊúÄ‰Ω≥„ÄÇÊñáÁ´†ËøòÊé¢ËÆ®‰∫Ü‰∏âÁßçÊõø‰ª£ÊäÄÊúØÔºå‰ª•ÊèêÈ´òÁîüÊàêÂõæÂÉè‰∏≠ÊñáÊú¨ÁöÑÂáÜÁ°ÆÊÄßÔºåÂåÖÊã¨Âú®ÂõæÂÉè‰∏≠ÊõøÊç¢ÁîüÊàêÁöÑÊñáÊú¨„ÄÅ‰ªéÁ©∫ÁôΩÁîªÂ∏ÉÂºÄÂßãÁîüÊàêÂõæÂÉè‰ª•ÂèäÂàÜÂà´ÁîüÊàêÂõæÂÉèÂíåÊñáÊú¨„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Gvj5CUGClWka1KUsDy5GQw.png","categories":["Generative AI","Natural Language Processing","Technology/Web"],"author":"Rifx.Online","tags":["text","generation","models","accuracy","techniques"],"draft":false,"slug":"blog/comparing-leading-text-to-image-image-generation-models-for-adding-text-to-images-7dc001f491ef"},"content":"\n\n\n### ‰πù‰∏™È¢ÜÂÖàÂõæÂÉèÁîüÊàêÊ®°ÂûãÂú®ÂõæÂÉè‰∏≠Ê∏≤ÊüìÂáÜÁ°ÆÊñáÊú¨ÔºàÂçïËØçÂíåÁü≠ËØ≠ÔºâÁöÑËÉΩÂäõÊØîËæÉ\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞ÜËØÑ‰º∞Êù•Ëá™Â§ö‰∏™Êèê‰æõÂïÜÁöÑ‰πù‰∏™ÊúÄÂÖàËøõÁöÑÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°ÂûãÂú®‰∏çÂêåÊâòÁÆ°Âπ≥Âè∞‰∏äÁöÑËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Â∞ÜÊ†πÊçÆÁªôÂÆöÁöÑÊèêÁ§∫ËØÑ‰º∞ÂÆÉ‰ª¨Âú®ÂõæÂÉè‰∏≠ÁîüÊàêÂáÜÁ°ÆÊñáÊú¨ÔºàÂçïËØçÂíåÁü≠ËØ≠ÔºâÁöÑËÉΩÂäõ„ÄÇÊµãËØïÁöÑÊ®°ÂûãÂåÖÊã¨‰ª•‰∏ãÂÜÖÂÆπÔºàÊåâÂ≠óÊØçÈ°∫Â∫èÊéíÂàóÔºâÔºö\n\n1. Adobe Firefly Image 3ÔºàÈÄöËøá [firefly.adobe.com](http://firefly.adobe.com/)Ôºâ\n2. Amazon Titan Image Generator G1 v2ÔºàÈÄöËøá [Amazon Bedrock](https://aws.amazon.com/bedrock/)Ôºâ\n3. Black Forest Labs FLUX1\\.1 \\[pro] Âíå Ultra ModeÔºàÈÄöËøá [Replicate](http://replicate.com/)Ôºâ\n4. Google Imagen 3ÔºàÈÄöËøá [ImageFX](https://aitestkitchen.withgoogle.com/tools/image-fx)Ôºâ\n5. KLING AI Áî± [Kwai\\-Kolors/Kolors](https://huggingface.co/Kwai-Kolors/Kolors) Êèê‰æõÊîØÊåÅÔºàÈÄöËøá [klingai.com](http://klingai.com/)Ôºâ\n6. Midjourney v6\\.1ÔºàÈÄöËøá [midjourney.com](http://midjourney.com/)Ôºâ\n7. OpenAI DALL¬∑E 3ÔºàÈÄöËøá [ChatGPT](https://quip-amazon.com/62AqA7VtF4Xb/chatgpt.com)Ôºâ\n8. Stability AI Stable Diffusion 3\\.5 LargeÔºàÈÄöËøá [stability.ai](http://stability.ai/) APIÔºâ\n9. Stability AI Stable Image Ultra 1\\.0 v1ÔºàÈÄöËøá [Amazon Bedrock](https://aws.amazon.com/bedrock/)Ôºâ\n\nÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÂ∞ÜÁ†îÁ©∂‰∏âÁßçÊõø‰ª£ÁöÑ„ÄÅÊõ¥ÂèØÈù†ÁöÑÊäÄÊúØÔºå‰ª•Á°Æ‰øùÁîüÊàêÂõæÂÉè‰∏≠ÊñáÊú¨ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n\n## ÊµãËØïÊ®°Âûã\n\nÂØπÊâÄÊúâÊ®°ÂûãËøõË°å‰∫ÜÂá†È°πÊµãËØïÔºå‰ΩøÁî®‰∫Ü‰∏çÂêåÁöÑÊèêÁ§∫Âíå‰∏çÂêåÁ®ãÂ∫¶ÁöÑÁªÜËäÇ„ÄÇÊèêÁ§∫Á§∫‰æãÂåÖÊã¨Ôºö\n\n1. *‰∏ÄÂº†ÂæÆÁ¨ëÁöÑÁßëÂ≠¶ÂÆ∂ÊâãÊåÅÊ†áËØ≠ÁâåÁöÑÁÖßÁâáÔºå‰∏äÈù¢ÂÜôÁùÄÔºö‚ÄúÊó†ÁëïÁöÑ AI ÁîüÊàêÊñáÊú¨ÔºÅ‚Äù*\n2. *‰∏Ä‰∏™Ëî¨ËèúÊëä‰ΩçÔºå‰∏äÈù¢ÊúâÂêÑÁßçËî¨ËèúÔºåÂåÖÊã¨Ë•øÁ∫¢Êüø„ÄÇ‰∏Ä‰∏™ÈªëËâ≤Ê†áÁâå‰∏äÁî®ÁôΩËâ≤Â≠ó‰ΩìÂÜôÁùÄÔºö‚ÄúÂÜúÂú∫Êñ∞È≤úË•øÁ∫¢Êüø $2.99/Á£Ö„ÄÇ‚Äù*\n3. *‰∏ÄÂπÖÂπΩÈªòÊèíÂõæÔºåÊèèÁªò‰∫Ü‰∏ÄÂè™ÂèãÂ•ΩÁöÑÂçóÁìúÔºåËÉåÊôØ‰∏∫ÁôΩËâ≤ÔºåÈÖçÊúâÁßãÂ≠£‰∏ªÈ¢òÁöÑÂêÑÁßçÂçóÁìúÂíåÁßãÂè∂„ÄÇ‚Äú‰∏áÂú£ËäÇÂø´‰πê‚ÄùÁöÑÂ≠óÊ†∑‰ª•Â§ßÊ∑±Ê£ïËâ≤Â≠óÊØçÂ±Ö‰∏≠Âú®ÂçóÁìú‰∏äÊñπ„ÄÇ*\n4. *‰∏ÄÂùóÊó∂Â∞öÁöÑÂπøÂëäÁâåÈ´òËÄ∏Âú®ÁπÅÂøôÁöÑÈ´òÈÄüÂÖ¨Ë∑Ø‰∏äÔºåËΩ¶ÊµÅÂú®È´òÂ≥∞Êó∂ÊÆµÂø´ÈÄüÊé†Ëøá„ÄÇÂú®‰∏Ä‰∏™Âä®ÊÄÅÁöÑÊäΩË±°ËÉåÊôØ‰∏ãÔºåÂ§ßËÄåÁ≤ó‰ΩìÁöÑÊñáÂ≠ó‚ÄúÁîüÊàêÊÄß AIÔºöËΩ¨ÂèòÊï∞Â≠óÂπøÂëä‚ÄùÔºå‰∏∫Ë∑ØËøáÁöÑÂè∏Êú∫Êèê‰æõ‰∫ÜÂç≥Êó∂ÁöÑÂèØËØªÊÄß„ÄÇ*\n\nÂ∞ΩÁÆ°Ê®°Âûã‰πãÈó¥ÁöÑÊï¥‰ΩìÂõæÂÉèË¥®ÈáèÂíåÊòéÊòæÂÅèËßÅÁ®ãÂ∫¶Â∑ÆÂºÇÊòæËëóÔºå‰ΩÜ‰ªÖËØÑ‰º∞‰∫ÜÊñáÊú¨ÁîüÊàêËÉΩÂäõ„ÄÇËÉΩÂ§üËá≥Â∞ë 50% ÂáÜÁ°ÆÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÊñáÊú¨ÁöÑÊ®°ÂûãËé∑Âæó‰∫ÜÂèäÊ†ºÂàÜÊï∞„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÈÄâÂÆöÊµãËØïÁöÑÁªìÊûúÔºåÂ±ïÁ§∫‰∫ÜÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÁªìÊûúÊåâÂ≠óÊØçÈ°∫Â∫èÂëàÁé∞ÔºåËÄå‰∏çÊòØÊåâË¥®ÈáèÊéíÂêç„ÄÇÊØè‰∏™ÊµãËØï‰∏≠ÂåÖÂê´‰∫ÜÂõõÂº†‰ª£Ë°®ÊÄßÁöÑÂπ≥ÂùáË¥®ÈáèÂõæÂÉè„ÄÇ \n\n\n\n## Ê®°Âûã\n\n### Adobe Firefly Image 3\n\nAdobe‰∫é2024Âπ¥4ÊúàÂèëÂ∏É‰∫ÜÂÖ∂Firefly Image 3Âü∫Á°ÄÊ®°Âûã„ÄÇÊ†πÊçÆ[Êñ∞ÈóªÁ®ø](https://news.adobe.com/news/news-details/2024/adobe-introduces-firefly-image-3-foundation-model-to-take-creative-exploration-and-ideation-to-new-heights)ÔºåAdobe Firefly Image 3Âú®ÁÖßÁâáÁúüÂÆûÊÑüË¥®Èáè„ÄÅÈÄ†ÂûãËÉΩÂäõ„ÄÅÁªÜËäÇ„ÄÅÂáÜÁ°ÆÊÄßÂíåÂ§öÊ†∑ÊÄßÊñπÈù¢ÂÆûÁé∞‰∫ÜÊÉä‰∫∫ÁöÑËøõÊ≠•„ÄÇÊ≠§Â§ñÔºåÁîüÊàêÈÄüÂ∫¶ÁöÑÊòæËëóÊèêÂçá‰ΩøÂæóÊûÑÊÄùÂíåÂàõ‰ΩúËøáÁ®ãÊõ¥Âä†È´òÊïàÂíåÂØåÊúâÁîü‰∫ßÂäõ„ÄÇËØ•Ê®°ÂûãÂèØÂú®Adobe PhotoshopÔºàÊµãËØïÁâàÔºâÂíå[firefly.adobe.com](https://firefly.adobe.com/generate/images)‰∏ä‰ΩøÁî®„ÄÇ‰ª•‰∏ãÊòØ‰∏§‰∏™ÁïåÈù¢„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*gcASwZgRSfPNYJB7n5GrlQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vU3NW6VdkgojkNlHaGWoSg.png)\n\nüö´ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåAdobe FireflyÊó†Ê≥ïÂáÜÁ°ÆÈáçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*yWoDLmj5mPKEw8GRg51YXw.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0iskBrEjrtFk-mXNrBvkag.jpeg)\n\n### Amazon Titan Image Generator G1 v2\n\nAmazon Titan Image Generator G1 v2 Ê®°Âûã‰∫é 2024 Âπ¥ 8 ÊúàÂèëÂ∏É„ÄÇÂÆÉÊòØÂØπ‰∏ä‰∏Ä‰ª£ Amazon Titan Image Generator G1 v1 Ê®°ÂûãÁöÑÂçáÁ∫ßÔºåËØ•Ê®°Âûã‰∫é 2023 Âπ¥ 11 ÊúàÂèëÂ∏É„ÄÇAmazon Titan Image Generator G1 v2 Ê®°ÂûãÂ¢ûÂä†‰∫ÜÂ§ö‰∏™ÂäüËÉΩÔºåÂåÖÊã¨ÂõæÂÉèË∞ÉËäÇ„ÄÅ‰ΩøÁî®Ë∞ÉËâ≤ÊùøÁöÑÂõæÂÉèÂºïÂØº„ÄÅËÉåÊôØÁßªÈô§Âíå‰∏ªÈ¢ò‰∏ÄËá¥ÊÄß„ÄÇ\n\nAmazon Titan Image Generator G1 v2 Ê®°ÂûãÂú® Amazon Bedrock ‰∏äËøõË°å‰∫ÜÊµãËØïÔºå Ê†πÊçÆ [AWS](https://aws.amazon.com/bedrock/)ÔºåÂÆÉÊòØ‚Äú*‰∏Ä‰∏™ÂÆåÂÖ®ÊâòÁÆ°ÁöÑÊúçÂä°ÔºåÊèê‰æõÊù•Ëá™È¢ÜÂÖà AI ÂÖ¨Âè∏ÔºàÂ¶Ç AI21 Labs„ÄÅAnthropic„ÄÅCohere„ÄÅMeta„ÄÅMistral AI„ÄÅStability AI Âíå AmazonÔºâÁöÑÈ´òÊÄßËÉΩÂü∫Á°ÄÊ®°ÂûãÔºàFMsÔºâÁöÑÈÄâÊã©ÔºåÈÄöËøáÂçï‰∏Ä APIÔºå‰ª•ÂèäÊûÑÂª∫ÂÖ∑ÊúâÂÆâÂÖ®ÊÄß„ÄÅÈöêÁßÅÊÄßÂíåË¥üË¥£‰ªª AI ÁöÑÁîüÊàê AI Â∫îÁî®ÊâÄÈúÄÁöÑÂπøÊ≥õËÉΩÂäõ„ÄÇ*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TmROyF5c-BXHevqImyflmw.png)\n\nüö´ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåAmazon Titan Image Generator G1 v2 Êó†Ê≥ïÂáÜÁ°ÆÈáçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QLvxsEveORObkPOOB3u1Mg.png)\n\n### ÈªëÊ£ÆÊûóÂÆûÈ™åÂÆ§ FLUX1\\.1 \\[pro] ÂíåË∂ÖÊ®°Âºè\n\nÈªëÊ£ÆÊûóÂÆûÈ™åÂÆ§‰∫é2024Âπ¥10ÊúàÂèëÂ∏É‰∫ÜFLUX1\\.1 \\[pro]„ÄÇÊ†πÊçÆÈªëÊ£ÆÊûóÂÆûÈ™åÂÆ§ÁöÑËØ¥Ê≥ïÔºå‚Äú*FLUX1\\.1 \\[pro] ÁöÑÁîüÊàêÈÄüÂ∫¶ÊØîÂÖ∂ÂâçË∫´FLUX.1 \\[pro]Âø´ÂÖ≠ÂÄçÔºåÂêåÊó∂ÊèêÈ´ò‰∫ÜÂõæÂÉèË¥®Èáè„ÄÅÊèêÁ§∫ÈÅµÂæ™Â∫¶ÂíåÂ§öÊ†∑ÊÄß„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨Êõ¥Êñ∞‰∫ÜFLUX.1 \\[pro]Ôºå‰ΩøÂÖ∂ÁîüÊàê‰∏é‰πãÂâçÁõ∏ÂêåÁöÑËæìÂá∫Ôºå‰ΩÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü‰∏§ÂÄç.*‚Äù Êó©ÊúüÁöÑFLUX.1 \\[pro]Ê®°Âûã‰∫é2024Âπ¥8ÊúàÂèëÂ∏É„ÄÇ\n\nÂú®ÊàëÂáÜÂ§áËøôÁØáÊñáÁ´†Êó∂ÔºåÈªëÊ£ÆÊûóÂÆûÈ™åÂÆ§Êé®Âá∫‰∫ÜFLUX1\\.1 \\[pro]ÁöÑË∂ÖÊ®°ÂºèÂíåÂéüÂßãÊ®°Âºè„ÄÇÊ†πÊçÆÊñ∞ÈóªÁ®øÔºå‚Äú*‰ªäÂ§©ÔºåÊàë‰ª¨‰∏∫FLUX1\\.1 \\[pro]Â¢ûÂä†‰∫ÜÊñ∞ÁöÑÈ´òÂàÜËæ®ÁéáÂäüËÉΩÔºåÊâ©Â±ïÂÖ∂ÂäüËÉΩ‰ª•ÊîØÊåÅ4ÂÄçÊõ¥È´òÁöÑÂõæÂÉèÂàÜËæ®ÁéáÔºàÊúÄÈ´òÂèØËææ4MPÔºâÔºåÂêåÊó∂‰øùÊåÅÊØè‰∏™Ê†∑Êú¨‰ªÖÈúÄ10ÁßíÁöÑÂá∫Ëâ≤ÁîüÊàêÊó∂Èó¥.*‚Äù\n\nÈªëÊ£ÆÊûóÂÆûÈ™åÂÆ§FLUX1\\.1 \\[pro]ÂíåË∂ÖÊ®°ÂºèÁöÑÊµãËØïÊòØÂú®[Replicate](https://replicate.com/blog/machine-learning-needs-better-tools)‰∏äËøõË°åÁöÑ„ÄÇ‰ªñ‰ª¨ÁöÑÁΩëÁ´ôÂ£∞ÊòéÔºå‚Äú*ReplicateÂú®‰∫ë‰∏≠ËøêË°åÊú∫Âô®Â≠¶‰π†Ê®°Âûã„ÄÇÊàë‰ª¨Êúâ‰∏Ä‰∏™ÂºÄÊ∫êÊ®°ÂûãÂ∫ìÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáÂá†Ë°å‰ª£Á†ÅËøêË°å„ÄÇÂ¶ÇÊûúÊÇ®Ê≠£Âú®ÊûÑÂª∫Ëá™Â∑±ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºåReplicate‰ΩøÂÖ∂Êòì‰∫éÂ§ßËßÑÊ®°ÈÉ®ÁΩ≤.*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IUbfTFj32FxIta_3J1W0pQ.png)\n\n‚úÖ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåÈªëÊ£ÆÊûóÂÆûÈ™åÂÆ§FLUX1\\.1 \\[pro]ËÉΩÂ§üÂú®Ë∂ÖËøá50%ÁöÑÊó∂Èó¥ÂÜÖÂáÜÁ°ÆÈáçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇÂÆÉÂú®ÊâÄÊúâÊµãËØïÊ®°Âûã‰∏≠Ë°®Áé∞ÊúÄ‰Ω≥„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RewBBA9MAiNbG93h65WdYg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ISZfNQZHo3PL_QkYu3jEIw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XliNJWJr2TZ5MGwi7RAa-g.png)\n\n### Google Imagen 3\n\nGoogle Imagen 3 ‰∫é2024Âπ¥8ÊúàÂêëÊâÄÊúâÁæéÂõΩÁî®Êà∑ÂèëÂ∏É„ÄÇÊ†πÊçÆË∞∑Ê≠åÁöÑËØ¥Ê≥ïÔºå‚Äú*Imagen 3 ÊòØÊàë‰ª¨ÊúÄÈ´òË¥®ÈáèÁöÑÊñáÊú¨Âà∞ÂõæÂÉèÊ®°ÂûãÔºåËÉΩÂ§üÁîüÊàêÂÖ∑ÊúâÊõ¥Â•ΩÁªÜËäÇ„ÄÅÊõ¥‰∏∞ÂØåÂÖâÁÖßÂíåÊõ¥Â∞ëÂπ≤Êâ∞ÊÄß‰º™ÂΩ±ÁöÑÂõæÂÉèÔºåÊØîÊàë‰ª¨‰πãÂâçÁöÑÊ®°ÂûãÊõ¥Âá∫Ëâ≤„ÄÇ*‚Äù Google Imagen 3 ÁöÑÊµãËØïÂú® [ImageFX](https://aitestkitchen.withgoogle.com/tools/image-fx) ‰∏äËøõË°åÔºåËøôÊòØË∞∑Ê≠å AI Test Kitchen ÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‚Äú*ËøôÊòØ‰∏Ä‰∏™‰∫∫‰ª¨ÂèØ‰ª•‰ΩìÈ™åÂπ∂ÂèçÈ¶àË∞∑Ê≠åÊúÄÊñ∞ AI ÊäÄÊúØÁöÑÂú∞Êñπ„ÄÇ*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nhto3l0o-XITJzEEQoHSTA.png)\n\nüö´ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåGoogle Imagen 3 Êó†Ê≥ïÂáÜÁ°ÆÈáçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9aqKPuZlpGF_lE3pA0ZNtw.png)\n\n### KLING AI Áî± Kolors Êèê‰æõÊîØÊåÅ\n\nKolors ‰∏∫ Kling AI ÁöÑÂõæÂÉèÁîüÊàêËÉΩÂäõÊèê‰æõÊîØÊåÅ„ÄÇÊ†πÊçÆ [Hugging Face](https://huggingface.co/Kwai-Kolors/Kolors) ÁöÑËØ¥Ê≥ïÔºå‚Äú*Kolors ÊòØ‰∏Ä‰∏™Âü∫‰∫éÊΩúÂú®Êâ©Êï£ÁöÑÂ§ßËßÑÊ®°ÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°ÂûãÔºåÁî±Âø´Êâã Kolors Âõ¢ÈòüÂºÄÂèë„ÄÇÁªèËøáÊï∞ÂçÅ‰∫øÂØπÊñáÊú¨-ÂõæÂÉèÁöÑËÆ≠ÁªÉÔºåKolors Âú®ËßÜËßâË¥®Èáè„ÄÅÂ§çÊùÇËØ≠‰πâÂáÜÁ°ÆÊÄß‰ª•Âèä‰∏≠ÊñáÂíåËã±ÊñáÂ≠óÁ¨¶ÁöÑÊñáÊú¨Ê∏≤ÊüìÊñπÈù¢Áõ∏ËæÉ‰∫éÂºÄÊ∫êÂíå‰∏ìÊúâÊ®°ÂûãÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ*‚Äù Ê†πÊçÆ [Kuaishou](https://ir.kuaishou.com/news-releases/news-release-details/kuaishou-launches-full-beta-testing-kling-ai-global-users-0) ÁöÑÊ∂àÊÅØÔºåKling AI ‰∫é 2024 Âπ¥ 7 ÊúàÂèëÂ∏É\\„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*na56zUz3DLWK7Dqj51vSKw.png)\n\nüö´ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåKLING AI Áî± Kolors Êèê‰æõÊîØÊåÅÊó†Ê≥ïÂáÜÁ°ÆÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇÁªìÊûúÊòØÊâÄÊúâÊµãËØïÊ®°Âûã‰∏≠Ë°®Áé∞ÊúÄÂ∑ÆÁöÑ„ÄÇËÆ∏Â§öÂìçÂ∫îÈÉΩÊòØ‰∏≠ÊñáÔºåÂç≥‰ΩøÊòéÁ°ÆË¶ÅÊ±Ç‰ª•Ëã±ÊñáÊòæÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xgq4C0m8s3Wfp4p9Va7fSQ.png)\n\n### Midjourney v6\\.1\n\nMidjourney v6\\.1 ‰∫é2024Âπ¥7ÊúàÂèëÂ∏É„ÄÇÊ†πÊçÆ [Midjourney](https://updates.midjourney.com/version-6-1/)ÔºåÊúÄÊñ∞ÂèëÂ∏ÉÁöÑ v6\\.1 ÂåÖÂê´‰∫ÜÂá†È°πÈáçË¶ÅÊîπËøõÔºåÂåÖÊã¨Êõ¥ËøûË¥ØÁöÑÂõæÂÉèÔºàÊâãËáÇ„ÄÅËÖø„ÄÅÊâã„ÄÅË∫´‰Ωì„ÄÅÊ§çÁâ©„ÄÅÂä®Áâ©Á≠âÔºâ„ÄÅÊõ¥Â•ΩÁöÑÂõæÂÉèË¥®Èáè„ÄÅÊõ¥Á≤æÁ°Æ„ÄÅËØ¶ÁªÜÂíåÊ≠£Á°ÆÁöÑÂ∞èÂõæÂÉèÁâπÂæÅÔºå‰ª•ÂèäÊîπËøõÁöÑÊñáÊú¨ÂáÜÁ°ÆÊÄßÔºàÂú®ÊèêÁ§∫‰∏≠ÈÄöËøá‚ÄúÂºïÂè∑‚ÄùÁªòÂà∂ÂçïËØçÊó∂Ôºâ„ÄÇÊ†πÊçÆ [Midjourney](https://docs.midjourney.com/docs/text-generation)Ôºå‰ΩøÁî® `‚Äî ‚Äî style raw` Ê†áÂøó‰πüÊúâÂä©‰∫éÂú®Êüê‰∫õÊµãËØïÊ°à‰æã‰∏≠ÊèêÈ´òÊñáÊú¨ÂáÜÁ°ÆÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ETXx5VyY4BgEA8zn4K3M0g.png)\n\nüö´ ‚úÖ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåMidjourney v6\\.1 ÁöÑÁªìÊûúÂèÇÂ∑Æ‰∏çÈΩê„ÄÇMidjourney Âú®Ë∂ÖËøá 50% ÁöÑÊó∂Èó¥ÂÜÖÊó†Ê≥ï‰∏ÄËá¥Âú∞ÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇÂú®Êüê‰∫õÊµãËØïÊ°à‰æã‰∏≠ÔºåËæìÂá∫ÊòØÊ≠£Á°ÆÁöÑÔºåËÄåÂú®ÂÖ∂‰ªñÊ°à‰æã‰∏≠ÂàôÊé•ËøëÊèêÁ§∫Ôºå‰ΩÜ‰πüÂêåÊ†∑ÁªèÂ∏∏ÈáçÂ§çÂçïËØçÂíåÊ†áÁÇπÁ¨¶Âè∑„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*yIaVzqP_BwvDGMO5SOo1SA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BDCsxYe_cJSb6pfoxKrWGA.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dqGYigq9T-PMx3GKfqSf2Q.png)\n\n### OpenAI DALL¬∑E 3\n\nOpenAI DALL¬∑E 3 ‰∫é2023Âπ¥10ÊúàÂèëÂ∏ÉÔºåË∑ù‰ªäÂ∑≤Êúâ‰∏ÄÂπ¥Â§ö„ÄÇÊ†πÊçÆ [OpenAI](https://openai.com/index/dall-e-3/)Ôºå\"*DALL¬∑E 3 Âú®ÁîüÊàêÂÆåÂÖ®Á¨¶ÂêàÊÇ®Êèê‰æõÁöÑÊñáÊú¨ÁöÑÂõæÂÉèËÉΩÂäõ‰∏äËøàÂá∫‰∫ÜÈáçË¶Å‰∏ÄÊ≠•„ÄÇDALL¬∑E 3 ÁêÜËß£ÁöÑÁªÜÂæÆÂ∑ÆÂà´ÂíåÁªÜËäÇËøúË∂ÖÊàë‰ª¨‰πãÂâçÁöÑÁ≥ªÁªü [DALL¬∑E 2]Ôºå‰ΩøÊÇ®ËÉΩÂ§üËΩªÊùæÂ∞ÜÊÇ®ÁöÑÊÉ≥Ê≥ïËΩ¨Âåñ‰∏∫ÊûÅÂÖ∂ÂáÜÁ°ÆÁöÑÂõæÂÉè„ÄÇ*\"\n\nOpenAI Imagen 3 ÁöÑÊµãËØïÊòØÂú® [ChatGPT](https://openai.com/index/chatgpt/) ‰∏äËøõË°åÁöÑ„ÄÇÊ≠§Â§ñÔºåÊ†πÊçÆ [OpenAI](https://openai.com/index/dall-e-3/)Ôºå\"*DALL¬∑E 3 ÂéüÁîüÊûÑÂª∫‰∫é ChatGPT ‰πã‰∏äÔºåËøô‰ΩøÊÇ®ÂèØ‰ª•Â∞Ü ChatGPT ‰Ωú‰∏∫Â§¥ËÑëÈ£éÊö¥‰ºô‰º¥ÂíåÊèêÁ§∫ÁöÑÂÆåÂñÑËÄÖ„ÄÇÂè™ÈúÄËØ¢ÈóÆ ChatGPT ÊÇ®Â∏åÊúõÂú®‰ªéÁÆÄÂçïÂè•Â≠êÂà∞ËØ¶ÁªÜÊÆµËêΩ‰∏≠ÁöÑ‰ªª‰ΩïÂÜÖÂÆπ‰∏≠ÁúãÂà∞ÁöÑÂÜÖÂÆπ„ÄÇ*\"\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*x45i0IJoYNiJT1kOi98k7w.png)\n\nüö´ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåOpenAI DALL¬∑E 3 Êó†Ê≥ïÂáÜÁ°ÆÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NirwqSB-k8dzfGRNAw-pQw.png)\n\n### Stability AI Stable Diffusion 3\\.5 Large\n\nÊ†πÊçÆStability AIÔºåÂèëÂ∏É‰∫é2024Âπ¥10ÊúàÁöÑ[Stable Diffusion 3\\.5 Large](https://stability.ai/news/introducing-stable-diffusion-3-5)Ê®°Âûã‚Äú*Êã•Êúâ81‰∫øÂèÇÊï∞ÔºåÂÖ∑ÊúâÂçìË∂äÁöÑË¥®ÈáèÂíåÂØπÊèêÁ§∫ÁöÑÈÅµÂæ™ËÉΩÂäõÔºåËøô‰∏™Âü∫Á°ÄÊ®°ÂûãÊòØStable DiffusionÂÆ∂Êóè‰∏≠ÊúÄÂº∫Â§ßÁöÑ„ÄÇËØ•Ê®°ÂûãÈùûÂ∏∏ÈÄÇÂêà1ÂÖÜÂÉèÁ¥†ÂàÜËæ®ÁéáÁöÑ‰∏ì‰∏öÁî®‰æã*„ÄÇ‚Äù Stability AI Stable Diffusion 3\\.5 Large‰ΩøÁî®[StabilityAI REST API](https://platform.stability.ai/docs/api-reference#tag/Generate/paths/~1v2beta~1stable-image~1generate~1ultra/post)ÂíåÂú®Jupyter Notebook‰∏≠Áî®PythonÁºñÂÜôÁöÑ‰ª£Á†ÅËøõË°å‰∫ÜÊµãËØï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*56Zp5QWVvTzGYlslcWEGKg.png)\n\n‚úÖ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåStability AI Stable Diffusion 3\\.5 LargeËÉΩÂ§üÂú®Ë∂ÖËøá50%ÁöÑÊó∂Èó¥ÂÜÖÂáÜÁ°ÆÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨ÔºåÂÅ∂Â∞î‰ºöÊúâËΩªÂæÆÁöÑÊ†áÁÇπÈîôËØØ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*CQ9I5z7x8ILTdFhu1dCBCQ.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*G2D-L2fEtjKVTTyph3Burg.jpeg)\n\n### Stability AI Stable Image Ultra\n\nÊ†πÊçÆStability AIÁöÑËØ¥Ê≥ïÔºå16 *billion\\-parameter [Stable Image Ultra](https://stability.ai/stable-image) Ê®°Âûã‰∫é2024Âπ¥10ÊúàÂèëÂ∏ÉÔºå‚ÄúÊòØÊàë‰ª¨ÁöÑÊóóËà∞Ê®°ÂûãÔºåÁªìÂêà‰∫ÜSD3 LargeÁöÑÂº∫Â§ßÂäüËÉΩ‰∏éÂÖàËøõÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºå‰ª•Êèê‰æõÊúÄÈ´òË¥®ÈáèÁöÑÁÖßÁâáÁ∫ßÁúüÂÆûÂõæÂÉè„ÄÇËØ•È´òÁ∫ßÊ®°Âûã‰∏ì‰∏∫ÈúÄË¶ÅÊó†‰∏é‰º¶ÊØîËßÜËßâÁúüÂÆûÊÑüÁöÑË°å‰∏öËÆæËÆ°Ôºå‰æãÂ¶ÇÂ∏ÇÂú∫Ëê•ÈîÄ„ÄÅÂπøÂëäÂíåÂª∫Á≠ë„ÄÇ‚Äù‰∏éAmazon Titan Image Generator‰∏ÄÊ†∑ÔºåStability AI Stable Image UltraÊ®°Âûã‰πü‰ΩøÁî®[Amazon Bedrock](https://aws.amazon.com/blogs/aws/stability-ais-best-image-generating-models-now-in-amazon-bedrock/)ËøõË°å‰∫ÜÊµãËØïÔºå‰ΩøÁî®‰∫ÜImage Playground UI„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GjaPW2FWGGhuJ06trs1Jww.png)\n\n‚úÖ Âú®ÊàëÁöÑÊµãËØï‰∏≠ÔºåStability AI Stable Image UltraËÉΩÂ§üÂú®Ë∂ÖËøá50%ÁöÑÊó∂Èó¥ÂÜÖÂáÜÁ°ÆÂÜçÁé∞ÊèêÁ§∫‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨„ÄÇ‰∏éBlack Forest Labs FLUX1\\.1 \\[pro]‰∏ÄËµ∑ÔºåÂÆÉÊòØÊµãËØï‰∏≠Ë°®Áé∞ÊúÄ‰Ω≥ÁöÑÊ®°Âûã‰πã‰∏Ä„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*O7JKeKBPgaEOuvdFW-u2Sg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jDHNLjOKHuEBQlFvTb7nYQ.png)\n\n## AIÁîüÊàêÊñáÊú¨ÁöÑÊõø‰ª£ÊñπÊ°à\n\nBlack Forest LabsÁöÑFLUX1.1 \\[pro]ÂíåStability AIÁöÑStable Image UltraÊ®°ÂûãÊØîÂÖ∂‰ªñÊ®°ÂûãÊõ¥È¢ëÁπÅÂú∞ÂáÜÁ°ÆÂÜçÁé∞ÊèêÁ§∫‰∏≠ÁöÑËØ∑Ê±ÇÁü≠ËØ≠„ÄÇÁÑ∂ËÄåÔºåÁî®Êà∑‰ªçÁÑ∂Êó†Ê≥ïÊéßÂà∂ÂõæÂÉèÁöÑËÆ∏Â§öÊñπÈù¢ÔºåÂåÖÊã¨ÊñáÊú¨ÁöÑÁ°ÆÂàá‰ΩçÁΩÆ„ÄÅÂ§ßÂ∞è„ÄÅÂ≠óË∑ù„ÄÅÈ¢úËâ≤ÂíåÂ≠ó‰ΩìÊ†∑Âºè„ÄÇÂ≠òÂú®Âá†ÁßçÊõø‰ª£‰∏îÊõ¥ÂèØÈù†ÁöÑÊäÄÊúØÔºå‰ª•Á°Æ‰øùÁîüÊàêÂõæÂÉè‰∏≠ÊñáÊú¨ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n\n### ÊõøÊç¢ÁîüÊàêÁöÑÊñáÊú¨\n\n‰∏ÄÁßçÊõø‰ª£ÊñπÊ≥ïÊòØÁîüÊàêÂ∏¶ÊúâÊâÄÈúÄÊñáÊú¨ÁöÑÂõæÂÉèÔºåËÄå‰∏çËÄÉËôëÊãºÂÜôÈîôËØØ„ÄÇÈöèÂêéÔºåÂèØ‰ª•Âú® Adobe Photoshop ‰∏≠Âà†Èô§ÊñáÊú¨ÔºåÂπ∂Áî®Ê≠£Á°ÆÁöÑÊñáÊú¨ÊõøÊç¢ÔºåÁ°Æ‰øù‰ΩçÁΩÆ„ÄÅÂ§ßÂ∞è„ÄÅÈ¢úËâ≤ÂíåÊ†∑ÂºèÂÆåÂÖ®‰∏ÄËá¥„ÄÇÁÑ∂ËÄåÔºåÂ¶ÇÊûúÂâçÊôØ‰∏ª‰ΩìÊàñÈò¥ÂΩ±ÈÉ®ÂàÜÈÅÆÊå°ÊñáÊú¨ÔºåÊàñËÄÖÊñáÊú¨Âá∫Áé∞Âú®‰∏çËßÑÂàôÁöÑË°®Èù¢‰∏äÔºåÂà†Èô§ÂíåÈáçÂª∫ÊñáÊú¨ÂèØËÉΩ‰ºöÂæàÂÖ∑ÊåëÊàòÊÄß„ÄÇ‰∏∫‰∫ÜÂ¢ûÂº∫Êñ∞ÊñáÊú¨ÁöÑÁúüÂÆûÊÑüÔºåÂèØ‰ª•Â∞ÜÁü¢ÈáèÊñáÊú¨Ê†ÖÊ†ºÂåñÔºåÁÑ∂ÂêéÊ∑ªÂä†Âô™Â£∞„ÄÅÊ®°Á≥ä„ÄÅÊâ≠Êõ≤„ÄÅÂÖâÁÖß„ÄÅÁ∫πÁêÜÂíåÂõæÂ±ÇÊ∑∑ÂêàÊïàÊûú„ÄÇ\n\n‰ª•‰∏ãÊòØ‰ΩøÁî® Black Forest Labs FLUX1\\.1 \\[pro] Ultra ÁîüÊàêÁöÑ‰∏§ÂπÖÂõæÂÉèÁ§∫‰æãÔºàÁ¨¨‰∏ÄÂπÖÂõæÂÉèÔºâ„ÄÇÊñáÊú¨Â∑≤Âú® Adobe Photoshop ‰∏≠Âà†Èô§ÔºàÁ¨¨‰∫åÂπÖÂõæÂÉèÔºâÔºåÊ∑ªÂä†‰∫ÜÊñ∞ÁöÑÂü∫‰∫éÁü¢ÈáèÁöÑÊñáÊú¨ÔºàÁ¨¨‰∏âÂπÖÂõæÂÉèÔºâÔºåÊúÄÂêéÔºåÊñáÊú¨Â∑≤Ë¢´Ê†ÖÊ†ºÂåñÂπ∂Êâ≠Êõ≤Ôºå‰ª•ÊòæÂæóÊõ¥ÁúüÂÆûÔºàÁ¨¨ÂõõÂπÖÂõæÂÉèÔºâ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*B0_3d8oImDlrRb6mjpekrw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fmrW46OsZe6Zsc0eshPyYw.png)\n\n### ‰ªéÁ©∫ÁôΩÁîªÂ∏ÉÂºÄÂßã\n\nÁ¨¨‰∫åÁßçÈÄâÊã©ÊòØÁîüÊàêÊ≤°ÊúâÊñáÊú¨ÁöÑÂõæÂÉèÔºåÁÑ∂Âêé‰ΩøÁî® Adobe Photoshop Ê∑ªÂä†ÊÇ®ÊâÄÈúÄÈ¢úËâ≤„ÄÅÂ§ßÂ∞èÂíåÂ≠ó‰ΩìÊ†∑ÂºèÁöÑÊñáÊú¨„ÄÇËøôÁßçÊäÄÊúØÊØîÂØπÁîüÊàêÁöÑÂõæÂÉèËøõË°å‰øÆÈ•∞‰ª•ÂéªÈô§Áé∞ÊúâÊñáÊú¨Ë¶ÅÁÆÄÂçïÂæóÂ§ö„ÄÇÁ§∫‰æãÊòØ‰ΩøÁî® [Replicate](https://replicate.com/docs/get-started/python) APIÔºåÈÄöËøá Jupyter Notebook Ë∞ÉÁî® Black Forest Labs ÁöÑ FLUX1\\.1 \\[pro] Âíå Ultra ÂàõÂª∫ÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iFpqy4fEUJOXaJMzhsgbDA.png)\n\n‰∏ãÈù¢ÊòØ‰ΩøÁî® Black Forest Labs FLUX1\\.1 \\[pro] Ultra ÁîüÊàêÁöÑÂõæÂÉèÔºåÊèêÁ§∫‰∏∫Ôºö‚Äú*‰∏Ä‰ΩçÂæÆÁ¨ëÁöÑÂ•≥ÊÄßÁßëÂ≠¶ÂÆ∂Á©øÁùÄÂÆûÈ™åÂÆ§Â§ñÂ•óÔºåÁ´ôÂú®ÂÆûÈ™åÂÆ§ÈáåÔºåÊâãÊåÅ‰∏ÄÂùóÊ≤°ÊúâÊñáÂ≠óÊàñÂÖ∂‰ªñÂÖÉÁ¥†ÁöÑÁôΩËâ≤Áü©ÂΩ¢Ê†áÁâå„ÄÇ*‚ÄùÁîüÊàêÁöÑÂõæÂÉèÔºàÁ¨¨‰∏ÄÂº†ÂõæÔºâÊ∑ªÂä†‰∫ÜÊñ∞ÊñáÊú¨ÔºàÁ¨¨‰∫åÂº†ÂõæÔºâÔºåÊúÄÂêéÔºåÊñáÊú¨Ë¢´Êâ≠Êõ≤‰ª•ÊòæÂæóÊõ¥ÁúüÂÆûÔºàÁ¨¨‰∏âÂº†ÂõæÔºâ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*c1rgPArHDrUQ2cePV9DUCA.png)\n\n‰∏ãÈù¢ÊòØÂè¶‰∏Ä‰∏™‰æãÂ≠êÔºåÂºÄÂßãÊó∂ÁîüÊàêÁöÑÂõæÂÉèÊ≤°ÊúâÊñáÊú¨ÔºåÂêéÊù•Ê∑ªÂä†‰∫ÜÊñáÊú¨„ÄÇÊúÄÂàùÁöÑÂõæÂÉèÊòØ‰ΩøÁî® Black Forest Labs FLUX1\\.1 \\[pro] Ultra ÁîüÊàêÁöÑÔºåÊèêÁ§∫‰∏∫Ôºö‚Äú*ÂêÑÁßçËî¨ËèúÁöÑËî¨ËèúÊëäÔºåÂåÖÊã¨Ë•øÁ∫¢Êüø„ÄÇ‰∏Ä‰∏™Â∞èÁöÑ„ÄÅÁü©ÂΩ¢ÁöÑ„ÄÅÁ©∫ÁôΩÁöÑÈªëËâ≤Ê†áÁâåÔºåÊóÅËæπÊ≤°ÊúâÊñáÂ≠óÊàñÂÖ∂‰ªñÂÖÉÁ¥†ÔºåÊîæÂú®Ë•øÁ∫¢ÊüøÊóÅËæπ„ÄÇ*‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t_6oM1aItMGQfBUPjH83lA.png)\n\nÊúÄÂêé‰∏Ä‰∏™‰æãÂ≠ê‰ΩøÁî®ÊèêÁ§∫Ôºö‚Äú*‰∏Ä‰∏™ÂÖâÊªëÁöÑÂπøÂëäÁâåÈ´òÈ´òËÄ∏Á´ãÂú®ÁπÅÂøôÁöÑÈ´òÈÄüÂÖ¨Ë∑Ø‰∏äÔºåËΩ¶ËæÜÈ£ûÈ©∞ËÄåËøá„ÄÇÂπøÂëäÁâåÁöÑËÉåÊôØÊòØËâ≤ÂΩ©‰∏∞ÂØå„ÄÅÂä®ÊÄÅÁöÑÊäΩË±°ÂõæÊ°à„ÄÇ*‚ÄùÊù•ÁîüÊàêÂéüÂßãÂõæÂÉè„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KyGveUehRxuFTK-DmWnCaw.jpeg)\n\n## ÂàÜÂà´ÁîüÊàêÂõæÂÉèÂíåÊñáÊú¨\n\nÁ¨¨‰∏âÁßç‰πüÊòØÊúÄÂêé‰∏ÄÁßçÊäÄÊúØÊòØ‰ΩøÁî®ÊÇ®ÈÄâÊã©ÁöÑÊ®°ÂûãÂàÜÂà´ÁîüÊàêÂõæÂÉèÂíåÊñáÊú¨ÔºåÁÑ∂ÂêéÂú®ÂêéÊúüÂà∂‰Ωú‰∏≠‰ΩøÁî® Adobe Photoshop Â∞ÜËøô‰∏§‰∏™ÂÖÉÁ¥†ÁªìÂêàËµ∑Êù•„ÄÇ‰∏ãÈù¢ÊòØÂ∑¶‰æßÊ≤°ÊúâÊñáÊú¨ÁöÑ Midjourney ÂéüÂßãÂõæÂÉèÔºå‰ΩøÁî®ÁöÑÊèêÁ§∫ÊòØÔºö‚Äú*ÂêÑÁßçËî¨ËèúÁöÑËî¨ËèúÊëäÔºåÂåÖÊã¨Ë•øÁ∫¢Êüø„ÄÇ‰∏Ä‰∏™Á©∫ÁôΩÁöÑÈªëÊùøÊ†∑ÂºèÊ†áÂøó„ÄÇ‚Äî ar 1:1*‚Äù\n\n‰∏≠Èó¥ÈªëËâ≤ËÉåÊôØ‰∏äÁöÑÁôΩËâ≤ÊñáÂ≠ó‰πüÊòØÂú® Midjourney ‰∏≠ÁîüÊàêÁöÑÔºå‰ΩøÁî®ÁöÑÊèêÁ§∫ÊòØÔºö‚Äú*Áü≠ËØ≠‚ÄúÂÜúÂú∫Êñ∞È≤úË•øÁ∫¢Êüø $2.99/Á£Ö„ÄÇ‚ÄùÁî®ÁôΩËâ≤Á≤âÁ¨îÂ≠óÂÜôÂú®Á∫ØÈªëËâ≤ËÉåÊôØ‰∏ä„ÄÇ‚Äî Ê≤°ÊúâË•øÁ∫¢ÊüøÊàñÂÖ∂‰ªñÁâ©‰Ωì ‚Äî ar 3:2 ‚Äî È£éÊ†ºÂéüÂßã ‚Äî È£éÊ†ºÂåñ 0*‚Äù\n\nÊñáÊú¨ÂõæÂÉèÂèØ‰ª•ÂæàÂÆπÊòìÂú∞Âè†Âä†Âú®Á¨¨‰∏Ä‰∏™ÂõæÂÉè‰∏äÔºå‰ΩøÁî®ÊñáÊú¨ÂõæÂ±ÇÁöÑ‚ÄúÂèò‰∫Æ‚ÄùÊ∑∑ÂêàÊ®°Âºè„ÄÇÂèØ‰ª•Â∫îÁî®È¢ùÂ§ñÁöÑÊâ≠Êõ≤ÊïàÊûúÔºå‰ΩøÊñáÊú¨Âú®ÊúÄÁªàÂõæÂÉè‰∏≠ÁúãËµ∑Êù•Êõ¥Âä†Ëá™ÁÑ∂„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ZP-pqTQVN8Xy_Vhjm8D0gg.png)\n\n## ÁªìËÆ∫\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫ÜÊù•Ëá™‰∏çÂêåÊèê‰æõÂïÜÁöÑ‰πùÁßçÊúÄÂÖàËøõÁöÑÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°ÂûãÁöÑËÉΩÂäõÔºå‰ª•Ê†πÊçÆÊèêÁ§∫ÁîüÊàêÂõæÂÉè‰∏≠ÁöÑÂáÜÁ°ÆÊñáÊú¨„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåBlack Forest Labs ÁöÑ FLUX1.1 [pro] Âíå Stability AI ÁöÑ Stable Image Ultra Âú®ÂáÜÁ°ÆÂÜçÁé∞ÂõæÂÉè‰∏≠ËØ∑Ê±ÇÁöÑÊñáÊú¨ÊñπÈù¢ÔºåÊØîÂÖ∂‰ªñÊ®°ÂûãÊõ¥ÊàêÂäü„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Ê£ÄÊü•‰∫Ü‰∏âÁßçÊõø‰ª£ÁöÑ„ÄÅÊõ¥ÂèØÈù†ÁöÑÊäÄÊúØÔºå‰ª•Á°Æ‰øùÁîüÊàêÂõæÂÉè‰∏≠ÊñáÊú¨ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n\n*Â¶ÇÊûúÊÇ®Ëøò‰∏çÊòØ Medium ‰ºöÂëòÂπ∂Â∏åÊúõÊîØÊåÅÂÉèÊàëËøôÊ†∑ÁöÑ‰ΩúËÄÖÔºåËØ∑Âú®Ê≠§Ê≥®ÂÜåÔºö<https://garystafford.medium.com/membership>„ÄÇ*\n\n*Êú¨ÂçöÂÆ¢‰ª£Ë°®ÊàëÁöÑËßÇÁÇπÔºåËÄå‰∏çÊòØÊàëÁöÑÈõá‰∏ª‰∫öÈ©¨ÈÄäÁΩëÁªúÊúçÂä°ÔºàAWSÔºâÁöÑËßÇÁÇπ„ÄÇÊâÄÊúâ‰∫ßÂìÅÂêçÁß∞„ÄÅÂõæÂÉè„ÄÅÂæΩÊ†áÂíåÂìÅÁâåÂùá‰∏∫ÂÖ∂ÂêÑËá™ÊâÄÊúâËÄÖÁöÑË¥¢‰∫ß„ÄÇ*\n\n"},{"lang":"zh","group":"blog","slug":"blog/conversational-ai-for-customer-service-best-practices-and-key-steps-for-success-4ceee714dbe1","frontmatter":{"title":"ÂÆ¢Êà∑ÊúçÂä°ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÔºöÊàêÂäüÁöÑÊúÄ‰Ω≥ÂÆûË∑µÂíåÂÖ≥ÈîÆÊ≠•È™§","meta_title":"ÂÆ¢Êà∑ÊúçÂä°ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÔºöÊàêÂäüÁöÑÊúÄ‰Ω≥ÂÆûË∑µÂíåÂÖ≥ÈîÆÊ≠•È™§","description":"ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠Ê≠£ËøÖÈÄüÂ¥õËµ∑ÔºåÈ¢ÑËÆ°Âà∞2025Âπ¥Â∞ÜÂÆûÁé∞40%ÁöÑÂÆ¢Êà∑‰∫íÂä®Ëá™Âä®Âåñ„ÄÇÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÊú∫Âô®Â≠¶‰π†ÔºåËøôÁßçÊäÄÊúØËÉΩÂ§üÊèê‰æõÂç≥Êó∂ÂìçÂ∫î„ÄÅÊèêÈ´òÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÅÈôç‰ΩéËøêËê•ÊàêÊú¨ÔºåÂπ∂ÂÆûÁé∞‰∏™ÊÄßÂåñÊúçÂä°„ÄÇÂÆûÊñΩÊàêÂäüÁöÑÂÖ≥ÈîÆÊ≠•È™§ÂåÖÊã¨ËØÜÂà´ÂÆ¢Êà∑ÁóõÁÇπ„ÄÅÂÆö‰πâ‰ΩøÁî®Ê°à‰æã„ÄÅÈÄâÊã©ÂêàÈÄÇÁöÑÂπ≥Âè∞„ÄÅËÆæËÆ°Áî®Êà∑‰ΩìÈ™å„ÄÅËÆ≠ÁªÉÊï∞ÊçÆ„ÄÅÁ≥ªÁªüÈõÜÊàêÂèäÊåÅÁª≠ÁõëÊµã„ÄÇ‰ºÅ‰∏öÈúÄÈÅµÂæ™ÊúÄ‰Ω≥ÂÆûË∑µÔºåÂ¶ÇÁ°Æ‰øùÂÆâÂÖ®ÂêàËßÑ„ÄÅÂπ≥Ë°°Ëá™Âä®Âåñ‰∏é‰∫∫Â∑•ÊîØÊåÅ„ÄÅ‰∏™ÊÄßÂåñ‰∫íÂä®Á≠âÔºå‰ª•ÂÆûÁé∞ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÈïøÊúüÊàêÂäü„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LrRhvUJrNaS299z8oC2bkg.jpeg","categories":["Natural Language Processing","Machine Learning","Chatbots"],"author":"Rifx.Online","tags":["conversational","automation","personalization","monitoring","security"],"draft":false,"slug":"blog/conversational-ai-for-customer-service-best-practices-and-key-steps-for-success-4ceee714dbe1"},"content":"\n\n\n\n\nÂú®ÂΩì‰ªäÂø´ËäÇÂ•èÁöÑÂïÜ‰∏öÁéØÂ¢É‰∏≠ÔºåÂÆ¢Êà∑ÊúçÂä°Âú®Âª∫Á´ãÂíåÁª¥Êä§ÂÆ¢Êà∑Âø†ËØöÂ∫¶ÊñπÈù¢ÂèëÊå•ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÈöèÁùÄ‰ºÅ‰∏öÂä™ÂäõÊèê‰æõ‰∏™ÊÄßÂåñÂíåÈ´òÊïàÁöÑÊîØÊåÅÔºåÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰Ωú‰∏∫‰∏ÄÁßçÈù©ÂëΩÊÄßËß£ÂÜ≥ÊñπÊ°àÂ∫îËøêËÄåÁîü„ÄÇÈÄöËøáÂ∞Ü‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÈõÜÊàêÂà∞ÂÆ¢Êà∑ÊúçÂä°ËøêËê•‰∏≠ÔºåÂÖ¨Âè∏ÂèØ‰ª•ÁÆÄÂåñÊµÅÁ®ãÔºåÊèê‰æõÂç≥Êó∂ÂìçÂ∫îÔºåÂπ∂ÊòæËëóÊîπÂñÑÊï¥‰ΩìÂÆ¢Êà∑‰ΩìÈ™å„ÄÇ*Gartner* ÁöÑ‰∏Ä‰ªΩÊä•Âëä‰º∞ËÆ°ÔºåÂà∞ **2025** Âπ¥Ôºå**40% ÁöÑÂÆ¢Êà∑ÊúçÂä°‰∫íÂä®** Â∞ÜÈÄöËøá‰∫∫Â∑•Êô∫ËÉΩÂíåÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÂÆûÁé∞ÂÆåÂÖ®Ëá™Âä®ÂåñÔºåËøô‰∏ÄÊØî‰æãÁõ∏ÊØî‰∫é **2023** Âπ¥ÁöÑ **25%** Êúâ‰∫ÜÊòæËëóÊèêÂçá„ÄÇ\n\nÂ∏åÊúõÂºÄÂèëÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°à‰ª•ÊèêÂçáÂÆ¢Êà∑ÊúçÂä°ÁöÑ‰ºÅ‰∏öÊ≠£Âú®ËøõÂÖ•‰∏Ä‰∏™ÂÖ∑ÊúâÂ∑®Â§ßÊΩúÂäõÁöÑÂèòÈù©Á©∫Èó¥„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜÂÆûÊñΩÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰ª•Êé®Âä®ÂÆ¢Êà∑ÊîØÊåÅËøêËê•ÊàêÂäüÁöÑÊúÄ‰Ω≥ÂÆûË∑µ„ÄÅÂÖ≥ÈîÆÊ≠•È™§ÂíåÂ•ΩÂ§ÑÔºå‰∏∫Ê∏¥ÊúõÂºÄÂèëËá™Ë∫´ AI È©±Âä®ÂÆ¢Êà∑ÊúçÂä°Ëß£ÂÜ≥ÊñπÊ°àÁöÑ‰ºÅ‰∏öÊèê‰æõËØ¶ÁªÜÊåáÂçó„ÄÇ\n\n## ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠ÁöÑÂ¥õËµ∑\n\nÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁªìÂêà‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP)„ÄÅÊú∫Âô®Â≠¶‰π†ÂíåËá™Âä®ÂåñÊ∂àÊÅØ‰º†ÈÄíÔºå‰ª•‰øÉËøõÂÆ¢Êà∑‰∏éÊï∞Â≠óÁ≥ªÁªü‰πãÈó¥Êó†Áºù‰∏îÁ±ª‰∫∫ÂåñÁöÑ‰∫íÂä®„ÄÇËøô‰∫õÊäÄÊúØÊó®Âú®ÁêÜËß£ÂÆ¢Êà∑Êü•ËØ¢ÔºåÊèê‰æõÂáÜÁ°ÆÁöÑÂìçÂ∫îÔºåÂπ∂‰∏éÁî®Êà∑ËøõË°åÊúâÊÑè‰πâÁöÑÂØπËØù„ÄÇÈöèÁùÄÂØπÂÖ®Â§©ÂÄôÂÆ¢Êà∑ÊîØÊåÅÂíåÂç≥Êó∂ÈóÆÈ¢òËß£ÂÜ≥ÈúÄÊ±ÇÁöÑÂ¢ûÂä†Ôºå‰ºÅ‰∏öÁé∞Âú®Ê≠£ËΩ¨ÂêëÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÔºå‰ª•È´òÊïàÊª°Ë∂≥Ëøô‰∫õÈúÄÊ±Ç„ÄÇ\n\nÂ∞ÜÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁ∫≥ÂÖ•ÂÆ¢Êà∑ÊúçÂä°‰∏ç‰ªÖÊèêÈ´ò‰∫ÜËøêËê•ÊïàÁéáÔºåËøòÂ¢ûÂº∫‰∫ÜÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ‰∫ãÂÆû‰∏äÔºåÊ†πÊçÆ *Salesforce* ÁöÑÊï∞ÊçÆÔºå**69% ÁöÑÊ∂àË¥πËÄÖ** ÊúüÊúõ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑ‰∫íÂä®ËÉΩÂ§üÊèê‰æõÊõ¥Áõ∏ÂÖ≥Âíå‰∏™ÊÄßÂåñÁöÑ‰ΩìÈ™åÔºåËøôÁ™ÅÊòæ‰∫ÜÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®Êèê‰æõ‰ª•ÂÆ¢Êà∑‰∏∫‰∏≠ÂøÉÁöÑÊúçÂä°‰∏≠ÁöÑÊó•ÁõäÈáçË¶ÅÊÄß„ÄÇ\n\n## ‰∏∫‰ªÄ‰πà‰ºÅ‰∏öÂ∫îËØ•‰∏∫ÂÆ¢Êà∑ÊúçÂä°ÂºÄÂèëÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÔºü\n\nÂØπ‰∫éÂ∏åÊúõ[**ÂºÄÂèë AI È©±Âä®ÁöÑÂÆ¢Êà∑ÊúçÂä°Ëß£ÂÜ≥ÊñπÊ°à**](https://www.blockchainappfactory.com/generative-ai-solutions?utm_source=medium&utm_medium=blog&utm_campaign=elavarasan)ÁöÑ‰ºÅ‰∏öÊù•ËØ¥Ôºå‰ºòÂäøÊòØÂ∑®Â§ßÁöÑ„ÄÇ‰ª•‰∏ãÊòØÊäïËµÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁî®‰∫éÂÆ¢Êà∑ÊúçÂä°ÁöÑÂá†‰∏™ÊúâÂäõÁêÜÁî±Ôºö\n\n**1\\. ÊîπÂñÑÂÆ¢Êà∑‰ΩìÈ™å**\n\nÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËÉΩÂ§üÁ´ãÂç≥ÂõûÂ∫îÂÆ¢Êà∑Êü•ËØ¢ÔºåÊ∂àÈô§‰∫ÜÂÆ¢Êà∑Âú®ÈïøÈòü‰∏≠Á≠âÂæÖÊàñÂ§ÑÁêÜÂª∂ËøüÂìçÂ∫îÁöÑÈúÄÊ±Ç„ÄÇÈÄöËøáÊèê‰æõ 24/7 ÁöÑÊîØÊåÅÔºå‰ºÅ‰∏öÂèØ‰ª•ÈÄöËøá AI È©±Âä®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÂíåËôöÊãüÂä©ÊâãÊèê‰æõÊõ¥Âø´„ÄÅÊõ¥È°∫ÁïÖÁöÑ‰ΩìÈ™åÔºå‰ªéËÄåÊèêÈ´òÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ÂíåÂø†ËØöÂ∫¶„ÄÇ\n\n**2\\. ÊèêÈ´òÊïàÁéá**\n\nAI È©±Âä®ÁöÑÊú∫Âô®‰∫∫ÂèØ‰ª•ÂêåÊó∂Â§ÑÁêÜÂ§ßÈáèÂÆ¢Êà∑ËØ¢ÈóÆÔºå‰ªéËÄåËÆ©‰∫∫Â∑•ÂÆ¢Êúç‰∏ìÊ≥®‰∫éÊõ¥Â§çÊùÇÁöÑÈóÆÈ¢ò„ÄÇËøôÂØºËá¥ËµÑÊ∫êÁöÑÊõ¥ÊúâÊïàÂà©Áî®ÔºåÈôç‰Ωé‰∫ÜËøêËê•ÊàêÊú¨Âπ∂Áº©Áü≠‰∫ÜÂìçÂ∫îÊó∂Èó¥„ÄÇ\n\n**3\\. ÊàêÊú¨ËäÇÁ∫¶**\n\nÂÆûÊñΩÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÊòæËëóÈôç‰Ωé‰∫Ü‰∏éÂÆ¢Êà∑ÊúçÂä°ËøêËê•Áõ∏ÂÖ≥ÁöÑÊàêÊú¨„ÄÇÊ†πÊçÆ *Juniper Research* ÁöÑÊï∞ÊçÆÔºåÂà∞ 2023 Âπ¥ÔºåÊï¥ÂêàËÅäÂ§©Êú∫Âô®‰∫∫Âà∞ÂÆ¢Êà∑ÊúçÂä°ËøêËê•‰∏≠ÁöÑ‰ºÅ‰∏öÊØèÂπ¥ÂèØËäÇÁúÅÈ´òËææ **110 ‰∫øÁæéÂÖÉ**„ÄÇËøô‰∫õËäÇÁúÅÊù•Ëá™‰∫éÂáèÂ∞ëÂØπÂ§ßÂûãÂÆ¢Êà∑ÊúçÂä°Âõ¢ÈòüÁöÑÈúÄÊ±ÇÂíåËá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°„ÄÇ\n\n**4\\. Â¢ûÂº∫‰∏™ÊÄßÂåñ**\n\nÈÄöËøáÂàÜÊûêÂÆ¢Êà∑Êï∞ÊçÆÂíåÂÅèÂ•ΩÔºåAI Á≥ªÁªüÂèØ‰ª•Êèê‰æõÈáèË∫´ÂÆöÂà∂ÁöÑ‰∏™ÊÄßÂåñÂìçÂ∫î„ÄÇËøôÁßçÂÆöÂà∂ÂåñÁ®ãÂ∫¶ÊúâÂä©‰∫é‰ºÅ‰∏ö‰∏éÂÆ¢Êà∑Âª∫Á´ãÊõ¥Âº∫ÁöÑÂÖ≥Á≥ªÔºåÂπ∂‰øÉËøõÊõ¥Â§ßÁöÑÂèÇ‰∏éÂ∫¶„ÄÇ\n\n## ÂÆûÊñΩÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠ÁöÑÂÖ≥ÈîÆÊ≠•È™§\n\nÂÆûÊñΩÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰ª•Êèê‰æõÂÆ¢Êà∑ÊúçÂä°ÈúÄË¶Å‰∏ÄÁßçÊ∑±ÊÄùÁÜüËôëÂíåÊàòÁï•ÊÄßÁöÑÊñπÂºèÔºå‰ª•Á°Æ‰øùÂÖ∂ËÉΩÂ§üÂÆûÁé∞È¢ÑÊúüÁöÑÁªìÊûú„ÄÇ‰ª•‰∏ãÊòØ‰ºÅ‰∏öÂú®ÂºÄÂèëÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆ¢Êà∑ÊîØÊåÅËß£ÂÜ≥ÊñπÊ°àÊó∂Â∫îÈÅµÂæ™ÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇ\n\n**Ê≠•È™§ 1ÔºöËØÜÂà´ÂÆ¢Êà∑ÁóõÁÇπ**\n\nÂú®ÂÆûÊñΩÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰πãÂâçÔºå‰∫ÜËß£ÂÆ¢Êà∑Âú®‰∏éÂÆ¢Êà∑ÊúçÂä°‰∫íÂä®ËøáÁ®ã‰∏≠Èù¢‰∏¥ÁöÑÂÖ∑‰ΩìÊåëÊàòÂíåÁóõÁÇπËá≥ÂÖ≥ÈáçË¶Å„ÄÇËØ∏Â¶ÇÁ≠âÂæÖÊó∂Èó¥ËøáÈïø„ÄÅÈáçÂ§çÊü•ËØ¢ÊàñÈöæ‰ª•Ëé∑Âèñ‰ø°ÊÅØÁ≠âÂ∏∏ËßÅÈóÆÈ¢òÂ∫îÁî±‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°àÊù•Â§ÑÁêÜ„ÄÇËøõË°åË∞ÉÊü•„ÄÅÂàÜÊûêÂÆ¢Êà∑ÊúçÂä°Êï∞ÊçÆÂπ∂Êî∂ÈõÜÂèçÈ¶àÔºå‰ª•Á°ÆÂÆö‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•Êèê‰æõÊúÄÂ§ß‰ª∑ÂÄºÁöÑÈ¢ÜÂüü„ÄÇ\n\n**Ê≠•È™§ 2ÔºöÂÆö‰πâÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰ΩøÁî®Ê°à‰æã**\n\n‰∏ÄÊó¶ËØÜÂà´Âá∫ÂÆ¢Êà∑ÁóõÁÇπÔºåÂ∞±Ë¶ÅÂÆö‰πâÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÊúÄÊúâÊïàÁöÑÂÖ∑‰Ωì‰ΩøÁî®Ê°à‰æã„ÄÇ‰ΩøÁî®Ê°à‰æãÂèØ‰ª•‰ªéÂõûÁ≠îÂ∏∏ËßÅÈóÆÈ¢òÔºàFAQsÔºâÂà∞Â§ÑÁêÜÊõ¥Â§çÊùÇÁöÑÊµÅÁ®ãÔºåÂ¶ÇÈ¢ÑËÆ¢ÊúçÂä°„ÄÅÂ§ÑÁêÜÈÄÄË¥ßÊàñÊèê‰æõ‰∫ßÂìÅÊé®Ëçê„ÄÇ‰ºÅ‰∏öÂøÖÈ°ª‰∏ìÊ≥®‰∫é‰ºòÂÖàËÄÉËôëÁõ¥Êé•Êª°Ë∂≥ÂÆ¢Êà∑ÈúÄÊ±ÇÂπ∂Êèê‰æõÂèØË°°ÈáèÁõäÂ§ÑÁöÑÈ´òÂΩ±Âìç‰ΩøÁî®Ê°à‰æã„ÄÇ\n\n**Â∏∏ËßÅ‰ΩøÁî®Ê°à‰æãÂåÖÊã¨Ôºö**\n\n* **ËÆ¢ÂçïÁä∂ÊÄÅÊü•ËØ¢Ôºö** ‰∫∫Â∑•Êô∫ËÉΩÊú∫Âô®‰∫∫ÂèØ‰ª•Á´ãÂç≥Ê£ÄÁ¥¢Âπ∂‰∏éÂÆ¢Êà∑ÂàÜ‰∫´ËÆ¢ÂçïÁä∂ÊÄÅÊõ¥Êñ∞„ÄÇ\n* **‰∫ßÂìÅ‰ø°ÊÅØÔºö** ËôöÊãüÂä©ÊâãÂèØ‰ª•Êèê‰æõËØ¶ÁªÜÁöÑ‰∫ßÂìÅ‰ø°ÊÅØÔºåÂπ∂Ê†πÊçÆÂÆ¢Êà∑Ë°å‰∏∫Âª∫ËÆÆ‰∫íË°•ÂïÜÂìÅ„ÄÇ\n* **ÊäÄÊúØÊîØÊåÅÔºö** Âü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú∫Âô®‰∫∫ÂèØ‰ª•ÊåáÂØºÁî®Êà∑ËøõË°åÂ∏∏ËßÅÊäÄÊúØÈóÆÈ¢òÁöÑÊïÖÈöúÊéíÈô§Ê≠•È™§„ÄÇ\n* **Ë¥¶ÂçïÂíåÊîØ‰ªòÔºö** ËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•‰øÉËøõÊîØ‰ªò„ÄÅË¥¶ÂçïÊü•ËØ¢ÂíåËÆ¢ÈòÖÁÆ°ÁêÜ„ÄÇ\n\n**Ê≠•È™§ 3ÔºöÈÄâÊã©ÂêàÈÄÇÁöÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂπ≥Âè∞**\n\nÈÄâÊã©ÂêàÈÄÇÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂπ≥Âè∞ÂØπÂÆ¢Êà∑ÊúçÂä°Ëá™Âä®ÂåñÂ∑•‰ΩúÁöÑÊàêÂäüËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ËØÑ‰º∞‰∫∫Â∑•Êô∫ËÉΩÂπ≥Âè∞Êó∂ÔºåËÄÉËôëÂèØÊâ©Â±ïÊÄß„ÄÅÈõÜÊàêÁöÑ‰æøÂà©ÊÄß„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËÉΩÂäõÂíåÂÆöÂà∂ÈÄâÈ°πÁ≠âÂõ†Á¥†„ÄÇÂÉè Google Dialogflow„ÄÅMicrosoft Azure Bot Services Âíå IBM Watson Á≠âÊµÅË°å‰∫∫Â∑•Êô∫ËÉΩÂπ≥Âè∞Êèê‰æõ‰∫ÜÊûÑÂª∫ÂíåÈÉ®ÁΩ≤Âü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆ¢Êà∑ÊúçÂä°Ëß£ÂÜ≥ÊñπÊ°àÁöÑÂº∫Â§ßÂ∑•ÂÖ∑„ÄÇËØ•Âπ≥Âè∞Â∫îÊîØÊåÅÂ§öÊ∏†ÈÅì‰∫íÂä®Ôºà‰æãÂ¶ÇÔºåËÅäÂ§©„ÄÅËØ≠Èü≥„ÄÅÁ§æ‰∫§Â™í‰ΩìÔºâÔºå‰ª•Á°Æ‰øù‰∏éÂÆ¢Êà∑Âú®‰∏çÂêåÂπ≥Âè∞‰∏äÁöÑÊó†ÁºùÊ≤üÈÄö„ÄÇ\n\n**Ê≠•È™§ 4ÔºöËÆæËÆ°Áõ¥ËßÇÁöÑÁî®Êà∑‰ΩìÈ™å**\n\nÁõ¥ËßÇÂíåÁî®Êà∑ÂèãÂ•ΩÁöÑÁïåÈù¢ÊòØÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÊàêÂäüÁöÑÂÖ≥ÈîÆ„ÄÇÁ°Æ‰øù‰∫∫Â∑•Êô∫ËÉΩËÉΩÂ§ü‰ª•Ê∏ÖÊô∞„ÄÅÁÆÄÊòéÁöÑÂØπËØù‰∏éÂÆ¢Êà∑‰∫íÂä®ÔºåÂºïÂØº‰ªñ‰ª¨È´òÊïàËß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁêÜËß£Ëá™ÁÑ∂ËØ≠Ë®ÄÔºåËØÜÂà´ÂÆ¢Êà∑ÊÑèÂõæÔºåÂπ∂ÊèêÂá∫Áõ∏ÂÖ≥ÁöÑÂêéÁª≠ÈóÆÈ¢òÔºå‰ª•Â∏ÆÂä©Áî®Êà∑Âø´ÈÄüËé∑ÂèñÊâÄÈúÄÁöÑ‰ø°ÊÅØ„ÄÇ\n\n‰∏∫‰∫ÜÂ¢ûÂº∫Áî®Êà∑‰ΩìÈ™åÔºåËÆæËÆ°ÂØπËØùÊµÅÁ®ãÂ∞ΩÂèØËÉΩ‰∫∫ÊÄßÂåñ„ÄÇÈÄöËøáÁß∞ÂëºÁî®Êà∑ÁöÑÂêçÂ≠ó„ÄÅÂõûÂøÜËøáÂéªÁöÑÂØπËØùÔºåÂπ∂Ê†πÊçÆ‰ªñ‰ª¨‰∏éÊÇ®‰∏öÂä°ÁöÑÂÖàÂâç‰∫íÂä®Êèê‰æõËß£ÂÜ≥ÊñπÊ°àÔºåÊù•‰∏™ÊÄßÂåñ‰∫íÂä®„ÄÇ\n\n**Ê≠•È™§ 5ÔºöÁî®Áõ∏ÂÖ≥Êï∞ÊçÆËÆ≠ÁªÉ‰∫∫Â∑•Êô∫ËÉΩ**\n\nÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊÄßËÉΩÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÂÜ≥‰∫éÂÖ∂ËÆ≠ÁªÉÁöÑÊï∞ÊçÆÁöÑË¥®ÈáèÂíåÊï∞Èáè„ÄÇÁî®ÁúüÂÆûÁöÑÂÆ¢Êà∑‰∫íÂä®Êï∞ÊçÆÊù•ËÆ≠ÁªÉ‰∫∫Â∑•Êô∫ËÉΩÔºå‰ª•ÊèêÈ´òÂÖ∂ÁêÜËß£‰∏çÂêåÊü•ËØ¢„ÄÅÁªÜÂæÆÂ∑ÆÂà´ÂíåËØ≠Ë®ÄÂèò‰ΩìÁöÑËÉΩÂäõ„ÄÇÈÄöËøá‰∏çÊñ≠Êèê‰æõÊù•Ëá™ËøáÂéª‰∫íÂä®ÁöÑÊï∞ÊçÆÔºåÁ°Æ‰øù‰∫∫Â∑•Êô∫ËÉΩÈöèÁùÄÊó∂Èó¥ÁöÑÊé®Áßª‰∏çÊñ≠Â≠¶‰π†ÂíåÊîπËøõÔºå‰ªéËÄåÂ¢ûÂº∫ÂÖ∂Êèê‰æõÂáÜÁ°ÆÂíå‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÂìçÂ∫îÁöÑËÉΩÂäõ„ÄÇ\n\n**Ê≠•È™§ 6Ôºö‰∏éÁé∞ÊúâÁ≥ªÁªüÈõÜÊàê**\n\n‰∏∫‰∫Ü‰ΩøÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁúüÊ≠£ÊúâÊïàÔºåÂøÖÈ°ª‰∏éÁé∞ÊúâÁöÑÂÆ¢Êà∑ÊúçÂä°Á≥ªÁªüÈõÜÊàê„ÄÇÁ°Æ‰øù‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°àËÉΩÂ§ü‰ªéÊÇ®ÁöÑ CRM„ÄÅË¥¶ÂçïÁ≥ªÁªü„ÄÅËÆ¢ÂçïÁÆ°ÁêÜÂπ≥Âè∞ÂíåÁü•ËØÜÂ∫ì‰∏≠ÊèêÂèñÊï∞ÊçÆÔºå‰ª•ÂêëÂÆ¢Êà∑Êèê‰æõÁõ∏ÂÖ≥ÂíåÂáÜÁ°ÆÁöÑ‰ø°ÊÅØ„ÄÇËøôÁßçÈõÜÊàê‰Ωø‰∫∫Â∑•Êô∫ËÉΩËÉΩÂ§üÂÆûÊó∂ÂìçÂ∫îÊü•ËØ¢ÔºåÂπ∂Á°Æ‰øùÂÆ¢Êà∑Âú®ÊâÄÊúâÊé•Ëß¶ÁÇπ‰∏äËé∑Âæó‰∏ÄËá¥ÁöÑÊîØÊåÅ„ÄÇ\n\n**Ê≠•È™§ 7ÔºöÊåÅÁª≠ÁõëÊµãÂíåÊîπËøõ**\n\nÂú®ÈÉ®ÁΩ≤ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°àÂêéÔºåÊåÅÁª≠ÁõëÊµãÂÖ∂ÊÄßËÉΩÂπ∂ËØÜÂà´ÊîπËøõÈ¢ÜÂüüËá≥ÂÖ≥ÈáçË¶Å„ÄÇË∑üË∏™ÂÖ≥ÈîÆÁª©ÊïàÊåáÊ†áÔºàKPIÔºâÔºåÂ¶ÇÂìçÂ∫îÊó∂Èó¥„ÄÅËß£ÂÜ≥ÁéáÂíåÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ËØÑÂàÜ„ÄÇÂà©Áî®Ëøô‰∫õÊ¥ûÂØüÊù•‰ºòÂåñ‰∫∫Â∑•Êô∫ËÉΩÁöÑËÉΩÂäõ„ÄÅË∞ÉÊï¥ÂØπËØùÊµÅÁ®ãÔºåÂπ∂Ëß£ÂÜ≥‰ªª‰Ωï‰∏çË∂≥‰πãÂ§Ñ„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÂ∫îÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÈÄöËøáÂ≠¶‰π†‰∫íÂä®ÂíåÈÄÇÂ∫î‰∏çÊñ≠ÂèòÂåñÁöÑÂÆ¢Êà∑ÊúüÊúõËÄåÂèëÂ±ï„ÄÇ\n\n## ÊàêÂäüÂÆûÊñΩÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊúÄ‰Ω≥ÂÆûË∑µ\n\nÂºÄÂèëÂíå[**Âú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠ÈÉ®ÁΩ≤ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ**](https://www.blockchainappfactory.com/generative-ai-solutions?utm_source=medium&utm_medium=blog&utm_campaign=elavarasan)ÈúÄË¶ÅÈÅµÂæ™ÊúÄ‰Ω≥ÂÆûË∑µÔºå‰ª•Á°Æ‰øùÈïøÊúüÊàêÂäü„ÄÇ‰ª•‰∏ãÊòØÂ∏åÊúõÊúÄÂ§ßÂåñ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊúçÂä°ÂΩ±ÂìçÁöÑ‰ºÅ‰∏öÁöÑ‰∏Ä‰∫õÊúÄ‰Ω≥ÂÆûË∑µ„ÄÇ\n\n**1\\. ‰ºòÂÖàËÄÉËôëÂÆâÂÖ®ÊÄßÂíåÂêàËßÑÊÄß**\n\nÂÆ¢Êà∑ÊúçÂä°ÈÄöÂ∏∏Ê∂âÂèäÂ§ÑÁêÜÊïèÊÑü‰ø°ÊÅØÔºå‰æãÂ¶ÇÊîØ‰ªòÁªÜËäÇ„ÄÅË¥¶Êà∑‰ø°ÊÅØÂíå‰∏™‰∫∫Êï∞ÊçÆ„ÄÇÁ°Æ‰øùÊÇ®ÁöÑ‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°àÁ¨¶ÂêàÊï∞ÊçÆ‰øùÊä§Ê≥ïËßÑÔºåÂ¶ÇÈÄöÁî®Êï∞ÊçÆ‰øùÊä§Êù°‰æãÔºàGDPRÔºâÊàñÂä†Âà©Á¶èÂ∞º‰∫öÊ∂àË¥πËÄÖÈöêÁßÅÊ≥ïÔºàCCPAÔºâ„ÄÇÂÆûÊñΩÂº∫Â§ßÁöÑÂÆâÂÖ®ÂçèËÆÆ‰ª•Âä†ÂØÜÂÆ¢Êà∑Êï∞ÊçÆÂπ∂Èò≤Ê≠¢Êï∞ÊçÆÊ≥ÑÈú≤„ÄÇ\n\n**2\\. Âú®Ëá™Âä®Âåñ‰∏é‰∫∫Â∑•‰∫íÂä®‰πãÈó¥ÂèñÂæóÂπ≥Ë°°**\n\nËôΩÁÑ∂ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•Â§ÑÁêÜÂêÑÁßçÂÆ¢Êà∑Êü•ËØ¢Ôºå‰ΩÜÂú®Ëá™Âä®ÂåñÂíå‰∫∫Â∑•ÊîØÊåÅ‰πãÈó¥ÂèñÂæóÂπ≥Ë°°Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®‰∫∫Â∑•Êô∫ËÉΩÊó†Ê≥ïËß£ÂÜ≥Â§çÊùÇÈóÆÈ¢òÊàñÂÆ¢Êà∑ÈúÄË¶ÅÊõ¥‰∏™ÊÄßÂåñÁöÑÊîØÊåÅÊó∂ÔºåÁ°Æ‰øù‰∫∫Â∑•Êô∫ËÉΩ‰∏é‰∫∫Â∑•ÂÆ¢Êúç‰πãÈó¥ÁöÑÊó†ÁºùËøáÊ∏°„ÄÇËøô‰∏™Ê∑∑ÂêàÊ®°Âûã‰ΩøÂÆ¢Êà∑ËÉΩÂ§üËé∑Âæó‰∏§ËÄÖÁöÑ‰ºòÁÇπÔºö‰∫∫Â∑•Êô∫ËÉΩÁöÑÂø´ÈÄüÂìçÂ∫îÂíå‰∫∫Â∑•ÂÆ¢ÊúçÁöÑÂêåÁêÜÂøÉ„ÄÇ\n\n**3\\. ÊµãËØïÂíå‰ºòÂåñ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªü**\n\nÂú®Â∞Ü‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÂÖ¨ÂºÄÂèëÂ∏É‰πãÂâçÔºåËøõË°åÂπøÊ≥õÁöÑÊµãËØï‰ª•Á°Æ‰øùÂÖ∂ËææÂà∞È¢ÑÊúüÁöÑÊÄßËÉΩÂü∫ÂáÜ„ÄÇÊµãËØï‰∫∫Â∑•Êô∫ËÉΩÁêÜËß£ÂêÑÁßçËØ≠Ë®Ä„ÄÅÂè£Èü≥ÂíåÊü•ËØ¢ÁªìÊûÑÁöÑËÉΩÂäõ„ÄÇ‰ΩøÁî®A/BÊµãËØïËØÑ‰º∞‰∏çÂêåÁöÑÂØπËØùÊµÅÁ®ãÔºåÂπ∂Ê†πÊçÆÂÆ¢Êà∑ÂèçÈ¶àÂíåÊÄßËÉΩÊï∞ÊçÆËøõË°å‰ºòÂåñ„ÄÇ\n\n**4\\. Áî®‰∫∫Â∑•Êô∫ËÉΩ‰∏™ÊÄßÂåñ‰∫íÂä®**\n\nÂÆ¢Êà∑Ê¨£ËµèÊÑüËßâ‰∏™ÊÄßÂåñÂíåÁõ∏ÂÖ≥ÁöÑ‰∫íÂä®„ÄÇÈÄöËøáÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÂàÜÊûêÂÆ¢Êà∑Êï∞ÊçÆÁöÑËÉΩÂäõÔºå‰ºÅ‰∏öÂèØ‰ª•Ê†πÊçÆÂÆ¢Êà∑ÁöÑÂéÜÂè≤„ÄÅÂÅèÂ•ΩÂíåË°å‰∏∫ÂÆöÂà∂ÂìçÂ∫î„ÄÇ‰∏™ÊÄßÂåñ‰∏ç‰ªÖ‰ªÖÊòØÁß∞ÂëºÂÆ¢Êà∑ÁöÑÂêçÂ≠ó‚Äî‚ÄîËøòÊ∂âÂèäÈ¢ÑÊµã‰ªñ‰ª¨ÁöÑÈúÄÊ±ÇÂπ∂Êèê‰æõÂ¢ûÂÄºÁöÑ‰∏ªÂä®Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\n**5\\. Á∫≥ÂÖ•Â§öËØ≠Ë®ÄËÉΩÂäõ**\n\nÂØπ‰∫éÊã•ÊúâÂÖ®ÁêÉÂÆ¢Êà∑Âü∫Á°ÄÁöÑ‰ºÅ‰∏öÔºåÂºÄÂèëÊîØÊåÅÂ§öÁßçËØ≠Ë®ÄÁöÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂ§öËØ≠Ë®Ä‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÂÖÅËÆ∏ÂÆ¢Êà∑‰ª•‰ªñ‰ª¨ÂÅèÂ•ΩÁöÑËØ≠Ë®Ä‰∏é‰ºÅ‰∏ö‰∫íÂä®ÔºåÊèêÈ´òÂèØÂèäÊÄßÂπ∂Êâ©Â§ßÂÆ¢Êà∑ÊúçÂä°ËøêËê•ÁöÑË¶ÜÁõñËåÉÂõ¥„ÄÇ\n\n**6\\. ‰∏∫ÂÆ¢Êà∑ËÆæÂÆöÊòéÁ°ÆÁöÑÊúüÊúõ**\n\n‰∏∫‰∫ÜÈò≤Ê≠¢ÂÆ¢Êà∑ÊÑüÂà∞Ê≤Æ‰∏ßÔºåÊòéÁ°ÆÂëäÁü•ÂÆ¢Êà∑‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•Âíå‰∏çËÉΩÂÅö‰ªÄ‰πà„ÄÇÂ¶ÇÊûú‰∫∫Â∑•Êô∫ËÉΩ‰ªÖÈôê‰∫éÊüê‰∫õ‰ªªÂä°ÔºàÂ¶ÇÊèê‰æõËÆ¢ÂçïÊõ¥Êñ∞ÊàñÂõûÁ≠îÂ∏∏ËßÅÈóÆÈ¢òÔºâÔºåËØ∑‰ªé‰∫íÂä®ÂºÄÂßãÂ∞±ÊòéÁ°ÆËøô‰∏ÄÁÇπ„ÄÇËøôÁßçÈÄèÊòéÂ∫¶ÊúâÂä©‰∫éÁÆ°ÁêÜÂÆ¢Êà∑ÊúüÊúõÔºåÂπ∂Âú®ËøáÊ∏°Âà∞‰∫∫Â∑•ÂÆ¢ÊúçÂ§ÑÁêÜÊõ¥Â§çÊùÇÈóÆÈ¢òÊó∂Èò≤Ê≠¢Ê∑∑Ê∑Ü„ÄÇ\n\n## Áé∞ÂÆû‰∏ñÁïå‰∏≠ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠ÁöÑÂ∫îÁî®ÂÆû‰æã\n\nÂ§ö‰∏™ÂÖ¨Âè∏Â∑≤ÁªèÂÆûÊñΩ‰∫ÜÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËß£ÂÜ≥ÊñπÊ°àÔºå‰ª•Â¢ûÂº∫‰ªñ‰ª¨ÁöÑÂÆ¢Êà∑ÊúçÂä°ËøêËê•„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂ±ïÁ§∫‰∫∫Â∑•Êô∫ËÉΩÂØπÂÆ¢Êà∑ÊúçÂä°ÊàêÂäüÂΩ±ÂìçÁöÑÁé∞ÂÆû‰∏ñÁïå‰æãÂ≠ê„ÄÇ\n\n**1\\. H\\&MÁöÑÂÆ¢Êà∑ÊúçÂä°ËÅäÂ§©Êú∫Âô®‰∫∫**\n\nÂÖ®ÁêÉÊó∂Â∞öÈõ∂ÂîÆÂïÜ *H\\&M* ‰ΩøÁî®‰∏Ä‰∏™Áî±‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂ∏ÆÂä©ÂÆ¢Êà∑Â§ÑÁêÜ‰∏éËÆ¢ÂçïÁä∂ÊÄÅ„ÄÅ‰∫ßÂìÅÂèØÁî®ÊÄßÂíåÈÄÄË¥ßÊîøÁ≠ñÁõ∏ÂÖ≥ÁöÑÂ∏∏ËßÅÊü•ËØ¢„ÄÇËØ•ËÅäÂ§©Êú∫Âô®‰∫∫ÈÄöËøáËá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°ÔºåÂáèËΩª‰∫ÜÂÆ¢Êà∑ÊúçÂä°‰ª£ÁêÜÁöÑË¥üÊãÖÔºå‰Ωø‰∫∫Á±ª‰ª£ÁêÜËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊõ¥Â§çÊùÇÁöÑËØ¢ÈóÆ„ÄÇH\\&MÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÊîπÂñÑ‰∫ÜÂÆ¢Êà∑ÂìçÂ∫îÊó∂Èó¥ÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊï¥‰ΩìÊª°ÊÑèÂ∫¶„ÄÇ\n\n**2\\. SephoraÁöÑËôöÊãüÁæéÂÆπÈ°æÈóÆ**\n\nÂåñÂ¶ÜÂìÅÈõ∂ÂîÆÂïÜ *Sephora* Êèê‰æõ‰∏Ä‰∏™Áî±ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑ **ËôöÊãüÁæéÂÆπÈ°æÈóÆ**ÔºåÊèê‰æõ‰∏™ÊÄßÂåñÁöÑ‰∫ßÂìÅÊé®ËçêÂíåÁæéÂÆπÊäÄÂ∑ß„ÄÇËØ•‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã‰∏éÂÆ¢Êà∑ËøõË°å‰∫íÂä®ÂØπËØùÔºåËØ¢ÈóÆ‰ªñ‰ª¨ÁöÑÂÅèÂ•ΩÂπ∂Êé®ËçêÁ¨¶ÂêàÂÖ∂ÈúÄÊ±ÇÁöÑ‰∫ßÂìÅ„ÄÇÈÄöËøáÊèê‰æõÈ´òÂ∫¶‰∏™ÊÄßÂåñÁöÑ‰ΩìÈ™åÔºåSephora ÊèêÈ´ò‰∫ÜÂÆ¢Êà∑ÂèÇ‰∏éÂ∫¶Âπ∂Â¢ûÂä†‰∫ÜÂú®Á∫øÈîÄÂîÆ„ÄÇ\n\n**3\\. AmtrakÁöÑÂÆ¢Êà∑ÊúçÂä°ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåJulie**\n\n*Amtrak* ÂÆûÊñΩ‰∫Ü **Julie**Ôºå‰∏Ä‰∏™Áî±‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑËôöÊãüÂä©ÊâãÔºåÂ∏ÆÂä©ÂÆ¢Êà∑È¢ÑËÆ¢ËΩ¶Á•®„ÄÅÊü•ËØ¢ÁÅ´ËΩ¶Êó∂ÂàªË°®ÂíåËé∑ÂèñÊóÖË°åÊõ¥Êñ∞„ÄÇJulie ÊØèÂπ¥Â§ÑÁêÜË∂ÖËøá **500‰∏áÊ¨°Êü•ËØ¢**ÔºåÂáèÂ∞ë‰∫ÜÂëºÂè´‰∏≠ÂøÉÁöÑÂ∑•‰ΩúÈáèÔºåÊèêÈ´ò‰∫Ü Amtrak ÂÆ¢Êà∑ÊúçÂä°ËøêËê•ÁöÑÊï¥‰ΩìÊïàÁéá„ÄÇJulie ÁöÑÊàêÂäü‰Ωø Amtrak ËÉΩÂ§üÈôç‰ΩéÊàêÊú¨ÔºåÂπ∂‰∏∫ÂÆ¢Êà∑Êèê‰æõÊõ¥Âø´ÈÄüÁöÑÊúçÂä°„ÄÇ\n\n## ÂÆ¢Êà∑ÊúçÂä°‰∏≠ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú™Êù•\n\nÂú®Êú™Êù•Âá†Âπ¥ÔºåÂÆ¢Êà∑ÊúçÂä°‰∏≠ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÈááÁî®È¢ÑËÆ°Â∞ÜÊåÅÁª≠Â¢ûÈïøÔºåÂõ†‰∏∫‰ºÅ‰∏öÂ∞ÜÁªßÁª≠‰ºòÂÖàËÄÉËôëËá™Âä®Âåñ„ÄÅÊïàÁéáÂíåÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇÂà∞2030Âπ¥ÔºåÈ¢ÑËÆ°**70%ÁöÑÂÆ¢Êà∑‰∫íÂä®**Â∞ÜÊ∂âÂèäÊüêÁßçÂΩ¢ÂºèÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØ„ÄÇËøôÁßçÂêë‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊúçÂä°ÁöÑËΩ¨ÂèòÂ∞Ü‰Ωø‰ºÅ‰∏öËÉΩÂ§ü‰∏∫ÂÖ®ÁêÉÊï∞Áôæ‰∏áÂÆ¢Êà∑Êèê‰æõ‰∏™ÊÄßÂåñÁöÑÂÆûÊó∂ÊîØÊåÅ„ÄÇ\n\nÈöèÁùÄÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜÂèòÂæóÊõ¥Âä†Êô∫ËÉΩÔºåËÉΩÂ§üÂ§ÑÁêÜÂ§çÊùÇÁöÑËØ¢ÈóÆ„ÄÅÁêÜËß£ÊÉÖÊÑüÂπ∂Êèê‰æõ‰∏ªÂä®Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ‰ªäÂ§©ÊäïËµÑ‰∫éÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰ºÅ‰∏öÂ∞ÜÂú®Êú™Êù•Êõ¥Â•ΩÂú∞Êª°Ë∂≥ÂÆ¢Êà∑Êó•ÁõäÂ¢ûÈïøÁöÑÈúÄÊ±Ç„ÄÇ\n\n## ÁªìËÆ∫\n\nÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∑≤ÁªèÊîπÂèò‰∫Ü‰ºÅ‰∏ö‰∏éÂÆ¢Êà∑‰∫íÂä®ÁöÑÊñπÂºèÔºåÊèê‰æõ‰∫ÜÊõ¥Âø´ÈÄü„ÄÅÊõ¥‰∏™ÊÄßÂåñÂíåÊõ¥È´òÊïàÁöÑÊîØÊåÅ„ÄÇÂØπ‰∫éÂ∏åÊúõÂºÄÂèëÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆ¢Êà∑ÊúçÂä°Ëß£ÂÜ≥ÊñπÊ°àÁöÑ‰ºÅ‰∏öËÄåË®ÄÔºåÊú∫‰ºöÊòØÂ∑®Â§ßÁöÑ„ÄÇÈÄöËøáÈÅµÂæ™ÊúÄ‰Ω≥ÂÆûË∑µÂπ∂ÂÆûÊñΩÂÖ≥ÈîÆÊ≠•È™§Ôºå‰æãÂ¶ÇËØÜÂà´Áî®‰æã„ÄÅÈÄâÊã©ÂêàÈÄÇÁöÑÂπ≥Âè∞‰ª•ÂèäÊåÅÁª≠‰ºòÂåñ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÔºå‰ºÅ‰∏öÂèØ‰ª•Ëé∑ÂæóÊàêÂäüÂπ∂Êé®Âä®ÂÆ¢Êà∑ÊúçÂä°ÁöÑÂàõÊñ∞„ÄÇ\n\nÊäïËµÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰∏ç‰ªÖÊòØÊîπÂñÑÂÆ¢Êà∑ÊúçÂä°ÁöÑÊàòÁï•‰∏æÊé™‚Äî‚ÄîÂÆÉÊòØÊú™Êù•‰øùÈöúÂÆ¢Êà∑ÊîØÊåÅËøêËê•ÁöÑÂøÖË¶ÅÊ≠•È™§„ÄÇÈÄöËøáÊèêÂçáÂÆ¢Êà∑‰ΩìÈ™å„ÄÅÈôç‰ΩéÊàêÊú¨ÂíåÊèê‰æõÂèØÊâ©Â±ïÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰ª£Ë°®‰∫ÜÂÆ¢Êà∑ÊúçÂä°ÁöÑÊú™Êù•„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/explore-swarm-multi-agent-framework-locally-0e25ee617795","frontmatter":{"title":"Êú¨Âú∞Êé¢Á¥¢ Swarm Â§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂","meta_title":"Êú¨Âú∞Êé¢Á¥¢ Swarm Â§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂","description":"Swarm ÊòØ‰∏Ä‰∏™ÂÆûÈ™åÊÄßÁ§∫‰æãÊ°ÜÊû∂ÔºåÁî®‰∫éÊ®°ÊãüËΩªÈáèÁ∫ßÂ§ö‰ª£ÁêÜÊ°ÜÊû∂ÔºåÁî®‰∫éÊïôËÇ≤ÁõÆÁöÑ„ÄÇÈÄöÂ∏∏ÂÆÉ‰∏é Open‚Ä¶ ÈÖçÂêà‰ΩøÁî®","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0ZVceq32bvkytC7HSIgmwA.png","categories":["Programming","Technology","Education"],"author":"Rifx.Online","tags":["Swarm","Multi-Agent","Framework","OpenAI","Ollama"],"draft":false,"slug":"blog/explore-swarm-multi-agent-framework-locally-0e25ee617795"},"content":"\n\n\n\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zkpW8DDwh0TTYuHJVJbDaw.png)\n\nSwarm ÊòØ‰∏Ä‰∏™ÂÆûÈ™åÊÄßÊ†∑Êú¨Ê°ÜÊû∂ÔºåÁî®‰∫éÊ®°ÊãüËΩªÈáèÁ∫ßÂ§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåÊó®Âú®ÊïôËÇ≤ÁõÆÁöÑ„ÄÇÈÄöÂ∏∏ÂÆÉ‰∏é Open AI Key ‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ΩÜÊàë‰ª¨ÂèØ‰ª•Êõ¥Êîπ‰∏∫‰ΩøÁî®Êú¨Âú∞ÁöÑ Ollama Êàñ LM Studio Ê®°Âûã„ÄÇ\n\n**ËÆæÁΩÆÔºö**\n\n\n```python\n## ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑ Conda Êàñ Python ËôöÊãüÁéØÂ¢ÉÂπ∂ÊøÄÊ¥ªÂÆÉ\nconda install python==3.10\npip install torch openai\npip install transformers accelerate huggingface_hub\npip install git+ssh://git@github.com/openai/swarm.git\n```\n**‰ΩøÁî® Open AI KeyÔºö**\n\n\n```python\nexport OPEN_API_KEY = Your Key\n```\n**‰ΩøÁî® Ollama Êàñ LM Studio Êú¨Âú∞ LLM ‚Äî Êõ¥Êñ∞‰∏∫Êú¨Âú∞ URLÔºö**\n\n\n```python\n## Êü•Êâæ conda Êàñ python ËôöÊãüÁéØÂ¢É‰∏≠ÁöÑ site-packages/swarm\n## ÊâæÂà∞Êñá‰ª∂ core.py\nclass Swarm:\n    def __init__(self, client=None):\n        if not client:\n          # ÂÆûÈôÖ‰ª£Á†Å\n          #client = OpenAI()\n          # Â∞ÜÂü∫Á°Ä URL Âíå API Key Êõ¥Êñ∞‰∏∫ Ollama / LM Studio\n          # Âú®Êú¨ÊºîÁ§∫‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî® LM Studio Âíå Llama 3.1\n          client = OpenAI(base_url=\"http://localhost:1234/v1\",api_key=\"random\")\n        self.client = client\n```\n**ÂÖãÈöÜ‰ªìÂ∫ìÔºö**\n\nÂÖãÈöÜ‰ªìÂ∫ì ‚Äî Âú®ËøôÈáåÊÇ®ÂèØ‰ª•ÊâæÂà∞‰∏çÂêåÁî®‰æãÁöÑÁ§∫‰æãÁõÆÂΩïÔºåÂ¶ÇÂü∫Êú¨„ÄÅËà™Á©∫ÂÖ¨Âè∏ÂíåÂ§©Ê∞îÁ≠â„ÄÇ\n\n\n```python\ngit clone https://github.com/openai/swarm.git\ncd swarm/examples\n```\n**Á§∫‰æã‰ª£Á†ÅÔºö**\n\n\n```python\nfrom swarm import Swarm, Agent\n\nclient = Swarm()\n\n\nit_agent = Agent(\n    name=\"IT Agent\",\n    instructions=\"You are an IT Expert with 10 Years of Experience.\",\n)\n\nsales_agent = Agent(\n    name=\"Sales Agent\",\n    instructions=\"You are a Sales Expert with 5 Years of Experience and knows about best selling mobiles.\",\n)\n\ndef transfer_to_sales_agent():\n    print(\"Sales agent in action\")\n    \"\"\"Transfer sales related questions to sales team immediately.\"\"\"\n    return sales_agent\n\ndef transfer_to_it_agent():\n    print(\"IT agent in action\")\n    \"\"\"Transfer IT users immediately.\"\"\"\n    return it_agent\n\nenglish_agent = Agent(\n    name=\"English Agent\",\n    instructions=\"You only speak English.\",\n    functions=[transfer_to_sales_agent,transfer_to_it_agent],\n)\n\n\nmessages = [{\"role\": \"user\", \"content\": \"How to install pandas lib?\"}]\nresponse = client.run(agent=english_agent, messages=messages)\n\nprint(response.messages[-1][\"content\"])\n\nmessages = [{\"role\": \"user\", \"content\": \"What are the best selling items?\"}]\nresponse = client.run(agent=english_agent, messages=messages)\n\nprint(response.messages[-1][\"content\"])\n```\n**ÂèÇËÄÉÊñáÁåÆÔºö**\n\n\n```python\nhttps://github.com/openai/swarm\n\nhttps://github.com/victorb/ollama-swarm/tree/main\n```\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hCFJ4VQoT12yElYPXwXvWA.png)\n\nÈâ¥‰∫éËøôÊòØ‰∏Ä‰∏™ÂÆûÈ™åÊÄßÁâàÊú¨Ôºå‰ªçÊúâÂæàÂ§ßÁöÑÊîπËøõÁ©∫Èó¥„ÄÇËà™Á©∫‰ª£ÁêÜÁ§∫‰æã‰ª£Á†Å [swarm/examples/airline] ÈùûÂ∏∏ÊúâË∂£ÔºåÂõ†Ê≠§ÂèØ‰ª•Â∞ùËØïËøô‰∫õÁ§∫‰æã„ÄÇËØïËØïÁúãÔºåÂπ∂Âú®ËØÑËÆ∫‰∏≠ÂàÜ‰∫´ÊÇ®ÁöÑÁªèÈ™å„ÄÇË∞¢Ë∞¢„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/fine-tuning-llama-3-with-unsloth-79c3465ef3e3","frontmatter":{"title":"‰ΩøÁî® Unsloth ÂØπ LLama 3 ËøõË°åÂæÆË∞É","meta_title":"‰ΩøÁî® Unsloth ÂØπ LLama 3 ËøõË°åÂæÆË∞É","description":"Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂ∞ÜÂêëÊÇ®Â±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî® Unsloth ÂØπ LLMÔºàÊù•Ëá™ Meta ÁöÑ Llama 3ÔºâËøõË°åÂæÆË∞ÉÔºàÂåÖÊã¨Ëá™ÂÆö‰πâÊï∞ÊçÆÈõÜÁöÑÊñπÊ≥ïÔºâ","date":"2024-10-30T12:58:41.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kaXoudNTGeGfuNPl_kta5g.jpeg","categories":["Programming","Machine Learning","Natural Language Processing"],"author":"Rifx.Online","tags":["Llama","Unsloth","LoRA","Alpaca","NVIDIA"],"draft":false,"slug":"blog/fine-tuning-llama-3-with-unsloth-79c3465ef3e3"},"content":"\n\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂ∞ÜÂêëÊÇ®Â±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî® [Unsloth](https://github.com/unslothai/unsloth) ÂæÆË∞É LLMÔºàMeta ÁöÑ Llama 3Ôºâ„ÄÇÊàëËøòÂ∞ÜÊèê‰æõ‰ΩøÁî®ÊÇ®Ëá™Â∑±Ëá™ÂÆö‰πâÊï∞ÊçÆÈõÜÁöÑÊñπÊ≥ï„ÄÇ\n\n**Ê≥®ÊÑèÔºö** Unsloth ÊòØ‰∏Ä‰∏™Âä†ÈÄü LLM Âú® NVIDIA GPU ‰∏äÂæÆË∞ÉÁöÑÂ∫ìÔºà‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÂÜÖÂ≠ò‰ΩøÁî®ÂáèÂ∞ë 40%Ôºâ„ÄÇ‰∏é Hugging Face ÂÖºÂÆπÔºåÊîØÊåÅ Llama Âíå Mistral Êû∂ÊûÑ„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ËßâÂæóÊàëÁöÑÊñáÁ´†ÊúâË∂£ÔºåËØ∑‰∏çË¶ÅÂøòËÆ∞ **ÁÇπËµûÂπ∂ [ÂÖ≥Ê≥®](https://medium.com/@soulawalid)** üëçüèºÔºåÂÜôËøô‰∫õÊñáÁ´†ÈúÄË¶ÅÊó∂Èó¥ÂíåÁ≤æÂäõÔºÅ\n\nÊÇ®ÂèØ‰ª•ËÆøÈóÆ GitHub ‰ªìÂ∫ì‰∏≠Êèê‰æõÁöÑÂÖçË¥πÁ¨îËÆ∞Êú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_L4o4MDQ7W5__OwW0E5RWA.png)\n\nÁî±‰∫éÊàë‰ΩøÁî®ÁöÑÊòØ Llama 3ÔºåÂõ†Ê≠§ÊàëÂ∞ÜÁÇπÂáªÁ¨îËÆ∞Êú¨ÔºàÊÇ®‰πüÂèØ‰ª•Âú®Ëá™Â∑±ÁöÑËÆ°ÁÆóÊú∫‰∏äÂÆâË£Ö UnslothÔºâ„ÄÇ\n\n**Ê≥®ÊÑèÔºö** ÊàëÂ∞Ü‰ΩøÁî®Ëøô‰∏™Êï∞ÊçÆÈõÜ ‚Äú[alpaca\\-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)‚Äù Êù•Ëá™ Hugging FaceÔºåÊï∞ÊçÆÈááÁî® Alpaca Ê†ºÂºèÔºåÂç≥ÂåÖÂê´ÔºàÊåá‰ª§„ÄÅËæìÂÖ•ÂíåËæìÂá∫Ôºâ„ÄÇ\n\n### ÂºÄÂßãÈ°πÁõÆ\n\nÂú®È°πÁõÆ‰∏≠ÔºåÊàëÂ∞ÜÊåáÂØºÊÇ®‰ΩøÁî® Unsloth ËøõË°åÂæÆË∞ÉÔºåËß£Èáä‰ª£Á†ÅÂπ∂Êèê‰æõÂª∫ËÆÆÔºåËÆ©Êàë‰ª¨ÂºÄÂßãÊàë‰ª¨ÁöÑÈ°πÁõÆÔºö\n\n**1/ ÂÆâË£ÖÊâÄÈúÄÁöÑÂåÖÔºö** Êàë‰ª¨È¶ñÂÖàÈúÄË¶ÅÂÆâË£Ö **Unsloth** Âíå **xformers**„ÄÅ**trl**„ÄÅ**peft**„ÄÅ**accelerate**„ÄÅ**bitsandbytes** Â∫ìÔºå‰ª•‰æøËøõË°åÈ´òÊïàÁöÑÊ®°ÂûãËÆ≠ÁªÉÂíåÊé®ÁêÜ„ÄÇ\n\n```python\n!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install --no-deps xformers trl peft accelerate bitsandbytes\n```\n\n**2/ Âä†ËΩΩÂíåÈÖçÁΩÆÊ®°ÂûãÔºö** Âú®ÈÖçÁΩÆ‰∏≠ÔºåÊàëÂ∞ÜËÆæÁΩÆ‰ª•‰∏ãÂÜÖÂÆπÔºö\n\n* Â∞ÜÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶ËÆæÁΩÆ‰∏∫ **2048**\n* Â∞Ü dtype ËÆæÁΩÆ‰∏∫ **None**ÔºåÂÆÉ‰ºöËá™Âä®Ê£ÄÊµãÊï∞ÊçÆÁ±ªÂûã„ÄÇ\n* ‰ª• **4-‰ΩçÁ≤æÂ∫¶**Âä†ËΩΩÊ®°ÂûãÔºåÊàëËÆ§‰∏∫ËøôÂ∑≤ÁªèË∂≥Â§ü„ÄÇ\n\n**Ê≥®ÊÑèÔºö** ÊÇ®ÂèØ‰ª•Âú®ËµÑÊ∫êÈÉ®ÂàÜÊâæÂà∞ÊàëÂÖ≥‰∫éÂæÆË∞É LLM ÁöÑÊäÄÂ∑ßÁöÑÊñáÁ´†„ÄÇ\n\n```python\nfrom unsloth import FastLanguageModel\nimport torch\n\n## ÈÖçÁΩÆ\nmax_seq_length = 2048\ndtype = None\nload_in_4bit = True\n\n## Âä†ËΩΩÈÄâÂÆöÁöÑÊ®°Âûã\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cJSAcJFP7E-qJkqKUsHqLw.png)\n\n**3/ Â∫îÁî® PEFTÔºàÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºâÔºö** ÁÑ∂ÂêéÊàë‰ª¨Â∞Ü‰ΩøÁî® LoRA ÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ\n\n* r = 16 ÊòØ LoRA ÁöÑÁß©ÂèÇÊï∞„ÄÇ**Ê≥®ÊÑèÔºö** Â∏∏ËßÅÂÄº‰∏∫ 8„ÄÅ16„ÄÅ32„ÄÅ64„ÄÅ128\n* lora_alpha = 16 ‰ª£Ë°® LoRA Êõ¥Êñ∞ÁöÑÁº©ÊîæÂõ†Â≠êÔºàÊàëÂ∞ÜÂÜô‰∏ÄÁØáÂÖ≥‰∫é LoRA ÁöÑÊñáÁ´†Ôºå‰ª•ËØ¶ÁªÜËß£ÈáäÊØè‰∏™ÈÉ®ÂàÜÔºâ\n* ÂØπ‰∫é LoRA ‰∏ç‰ΩøÁî® dropout ÂíåÂÅèÁΩÆ\n* ÂØπ‰∫é use_gradient_checkpointingÔºåÊàë‰ª¨‰ΩøÁî® Unsloth Êù•Â§ÑÁêÜÔºàËäÇÁúÅÂÜÖÂ≠òÔºâ\n\n```python\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)\n```\n\n**4/ ÂÆö‰πâÊèêÁ§∫Ê®°ÊùøÔºö** Êàë‰ª¨Â∞ÜÂàõÂª∫ alpaca ÊèêÁ§∫Ê®°Êùø‰ª•Ê†ºÂºèÂåñÊï∞ÊçÆÈõÜÔºàÂ¶ÇÊûúÊÇ®‰ΩøÁî®ÁöÑÊï∞ÊçÆ‰∏çÊòØËøôÁßçÊ†ºÂºèÔºâ„ÄÇ\n\nÊàë‰ª¨ËøòÂ∞ÜÊ∑ªÂä† EOSÔºàÁªìÊùüÂ∫èÂàóÔºâ‰ª•ÈÄöÁü• LLM Âè•Â≠êÂ∑≤ÁªìÊùü„ÄÇ\n\nÊúÄÂêéÊòØÊ†ºÂºèÂåñÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞Êé•Âèó‰∏ÄÊâπÁ§∫‰æãÂπ∂Ê†πÊçÆÊàë‰ª¨‰πãÂâçÁºñÂÜôÁöÑ alpaca ÊèêÁ§∫Ê®°ÊùøÊ†ºÂºèÂåñÊØè‰∏™Á§∫‰æã„ÄÇ\n\n* ÂÆÉ‰ªéÊØè‰∏™Á§∫‰æãÔºàË°åÔºâ‰∏≠ÊèêÂèñÊåá‰ª§„ÄÅËæìÂÖ•ÂíåËæìÂá∫Â≠óÊÆµ„ÄÇ\n* ÁÑ∂ÂêéÂ∞ÜËøô‰∫õÂ≠óÊÆµÊ†ºÂºèÂåñÂà∞Ê®°Êùø‰∏≠Âπ∂ÈôÑÂä† EOS Ê†áËÆ∞„ÄÇ\n* Ê†ºÂºèÂåñÁöÑÊñáÊú¨Â≠òÂÇ®Âú®ÂàóË°®‰∏≠ÔºåÂπ∂‰Ωú‰∏∫ÂÖ∑ÊúâÂçï‰∏™ÈîÆ‚Äútext‚ÄùÁöÑÂ≠óÂÖ∏ËøîÂõû„ÄÇ\n\n```python\nalpaca_prompt = \"\"\"‰ª•‰∏ãÊòØÊèèËø∞‰ªªÂä°ÁöÑÊåá‰ª§ÔºåÈÖçÊúâÊèê‰æõËøõ‰∏ÄÊ≠•‰∏ä‰∏ãÊñáÁöÑËæìÂÖ•„ÄÇÂÜô‰∏Ä‰∏™ÈÄÇÂΩìÂÆåÊàêËØ∑Ê±ÇÁöÑÂìçÂ∫î„ÄÇ\n\n#### Êåá‰ª§Ôºö\n{}\n\n#### ËæìÂÖ•Ôºö\n{}\n\n#### ÂìçÂ∫îÔºö\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token\n\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs = examples[\"input\"]\n    outputs = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return {\"text\": texts}\n```\n\n**5/ Âä†ËΩΩÂíåÊ†ºÂºèÂåñÊï∞ÊçÆÈõÜÔºö** Âä†ËΩΩ Alpaca Êï∞ÊçÆÈõÜÂπ∂ÂØπÊØè‰∏™Êï∞ÊçÆÈõÜÁ§∫‰æãÂ∫îÁî®Ê†ºÂºèÂåñ„ÄÇ\n\n```python\nfrom datasets import load_dataset\ndataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*M8EmbLMdoqrM-JlkMpDv8g.png)\n\n**6/ ËÆæÁΩÆÂíåËÆ≠ÁªÉÊ®°ÂûãÔºö** ÊàëÂú®Êàë[‰πãÂâçÁöÑÊñáÁ´†](https://readmedium.com/supervised-fine-tuning-tips-for-your-llm-projects-f84f20593653)‰∏≠Ê∂µÁõñ‰∫ÜÂ§ßÈÉ®ÂàÜÂÖ≥‰∫éÂæÆË∞ÉÁöÑÊäÄÂ∑ß„ÄÇ\n\n```python\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2, # Áî®‰∫éÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁöÑËøõÁ®ãÊï∞Èáè\n    packing = False, # ÊòØÂê¶Â∞ÜÂ§ö‰∏™Â∫èÂàóÊâìÂåÖÊàê‰∏Ä‰∏™ÊâπÊ¨°‰ª•ÊèêÈ´òËÆ≠ÁªÉÊïàÁéá\n    args = TrainingArguments(\n        per_device_train_batch_size = 2, # ÊØè‰∏™ËÆæÂ§áÁöÑÊâπÊ¨°Â§ßÂ∞è\n        gradient_accumulation_steps = 4, # Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞ÔºåÂÖÅËÆ∏ÊúâÊïàÂ¢ûÂ§ßÊâπÊ¨°Â§ßÂ∞è\n        warmup_steps = 5, # ËøõË°åÁ∫øÊÄßÂ≠¶‰π†ÁéáÈ¢ÑÁÉ≠ÁöÑÊ≠•È™§Êï∞\n        max_steps = 60, # ÊÄªËÆ≠ÁªÉÊ≠•È™§Êï∞\n        learning_rate = 2e-5,# ‰ºòÂåñÂô®ÁöÑÂ≠¶‰π†Áéá\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"cosine\",\n        seed = 3407,\n        output_dir = \"outputs\",\n    ),\n)\n\ntrainer_stats = trainer.train()\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Vb_OqGP9CPc8xZdnkclGyQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PI0JXrTbpjuviyQ4bZJnFg.png)\n\n**7/ Êé®ÁêÜÂíåÁîüÊàêÔºö** Êàë‰ª¨ÈÄöËøáÂáÜÂ§áËæìÂÖ•ÊèêÁ§∫„ÄÅÂØπÂÖ∂ËøõË°åÊ†áËÆ∞ÂåñÔºåÁÑ∂Âêé‰ΩøÁî®Ê®°ÂûãÊ†πÊçÆËØ•ÊèêÁ§∫ÁîüÊàêÊñ∞ÊñáÊú¨Êù•ÂáÜÂ§áÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇÁîüÊàêÁöÑÊñáÊú¨ÈöèÂêéË¢´ËΩ¨Êç¢ÂõûÂèØËØªÂΩ¢Âºè„ÄÇ\n\n```python\nFastLanguageModel.for_inference(model)\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"ÁªßÁª≠ÊñêÊ≥¢ÈÇ£Â•ëÊï∞Âàó„ÄÇ\", # Êåá‰ª§\n        \"1, 1, 2, 3, 5, 8\", # ËæìÂÖ•\n        \"\", # ËæìÂá∫ - ÁïôÁ©∫‰ª•ËøõË°åÁîüÊàêÔºÅ\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PI6SBL_YPPj0-RSAn5nl7g.png)\n\nÊÇ®ËøòÂèØ‰ª•‰ΩøÁî® TextStreamer ËøõË°åËøûÁª≠Êé®ÁêÜÔºåËøôÊ†∑ÊÇ®ÂèØ‰ª•ÁúãÂà∞ÁîüÊàêÁöÑÊØè‰∏™Ê†áËÆ∞ÔºåËÄå‰∏çÊòØ‰∏ÄÁõ¥Á≠âÂæÖÊï¥‰∏™ËøáÁ®ãÔºÅ\n\n```python\nFastLanguageModel.for_inference(model)\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"ÁªßÁª≠ÊñêÊ≥¢ÈÇ£Â•ëÊï∞Âàó„ÄÇ\",\n        \"1, 1, 2, 3, 5, 8\",\n        \"\",\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NaSQ1vQKORU1I3DsOU2iOA.png)\n\n**8/ ‰øùÂ≠òÊ®°ÂûãÔºö** Â¶ÇÊûúÊÇ®ÂØπÊ≠§ÊÑüÂà∞Êª°ÊÑèÔºåÂèØ‰ª•‰øùÂ≠òÊÇ®ÁöÑÊ®°ÂûãÊàñÂ∞ÜÂÖ∂Êé®ÈÄÅÂà∞ Hugging Face Hub„ÄÇ\n\n```python\nmodel.save_pretrained(\"lora_model\")\ntokenizer.save_pretrained(\"lora_model\")\n## model.push_to_hub(\"your_name/lora_model\", token = \"...\")\n## tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\")\n```\n\n**9/ Âä†ËΩΩÊ®°ÂûãÔºö**\n\n```python\nif False:\n    from unsloth import FastLanguageModel\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"lora_model\",\n        max_seq_length = max_seq_length,\n        dtype = dtype,\n        load_in_4bit = load_in_4bit,\n    )\n    FastLanguageModel.for_inference(model)\n```\n\n**10/ Áî®‰∫éÁîüÊàêÔºö**\n\n```python\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"Â∑¥ÂãíÊñØÂù¶ÁöÑÈ¶ñÈÉΩÊòØ‰ªÄ‰πàÔºü\",\n        \"\",\n        \"\",\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)\n```\n\nÂ¶ÇÊûúÊÇ®ÊúâÁâπÂÆö‰∏ªÈ¢òÂ∏åÊúõÊàë‰ª¨ËÆ®ËÆ∫ÔºåËØ∑ÈöèÊó∂ÂëäËØâÊàëÔºÅÊÇ®ÁöÑÂèçÈ¶àÂ∞ÜÊúâÂä©‰∫éÂ°ëÈÄ†ÊàëÁöÑÂÜÖÂÆπÊñπÂêëÔºåÁ°Æ‰øùÂÖ∂‰øùÊåÅÁõ∏ÂÖ≥ÊÄßÂíåÂê∏ÂºïÂäõüòÄ\n\n\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/gemini-1-5-flash-vs-gpt-4o-88b9d8da8152","frontmatter":{"title":"ÂÖ®Êñ∞ Gemini 1.5 FLASH ÂûãÂè∑ÔºöÁªùÂØπÁöÑ Google Ê∏∏ÊàèËßÑÂàôÊîπÂèòËÄÖ","meta_title":"ÂÖ®Êñ∞ Gemini 1.5 FLASH ÂûãÂè∑ÔºöÁªùÂØπÁöÑ Google Ê∏∏ÊàèËßÑÂàôÊîπÂèòËÄÖ","description":"Gemini 1.5 Flash ÂÆåËÉú GPT-4o","date":"2024-11-08T00:27:31.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Reb1owOmiw5DFd4A.png","categories":["Programming","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["Gemini","Flash","GPT-4o","multi-modality","creativity"],"draft":false,"slug":"blog/gemini-1-5-flash-vs-gpt-4o-88b9d8da8152"},"content":"\n‰ªñ‰ª¨ÁöÑÊñ∞ Gemini 1\\.5 Flash Ê®°ÂûãËøúËøúË∂ÖËøá‰∫Ü GPT\\-4oÔºåÂÖ∂ËÉΩÂäõ‰ª§‰∫∫Èöæ‰ª•ÁΩÆ‰ø°„ÄÇ\n\n**Èó™ÁîµËà¨Âø´ÈÄü**„ÄÇ\n\n\n\nÊØî GPT\\-4o ‰æøÂÆú 33 ÂÄçÔºå‰ΩÜ‰∏ä‰∏ãÊñáÂÆπÈáèÂ§ß 700% ‚Äî **100 ‰∏á‰∏™‰ª§Áâå„ÄÇ**\n\nÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠Ôºå100 ‰∏á‰∏™‰ª§ÁâåÊòØ‰ªÄ‰πàÊ¶ÇÂøµÔºüÂ§ßÁ∫¶Ôºö\n\n* Ë∂ÖËøá 1 Â∞èÊó∂ÁöÑËßÜÈ¢ë\n* Ë∂ÖËøá 30,000 Ë°å‰ª£Á†Å\n* Ë∂ÖËøá 700,000 ‰∏™ÂçïËØç\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*E1XIOcpWfeqOZSZC.jpg)\n\n‚ùåGPT\\-4o ÊàêÊú¨Ôºö\n\n* ËæìÂÖ•ÔºöÊØèÁôæ‰∏á‰∏™‰ª§Áâå $2\\.50\n* ËæìÂá∫ÔºöÊØèÁôæ‰∏á‰∏™‰ª§Áâå $10\n* ÁºìÂ≠òËæìÂÖ•ÔºöÊØèÁôæ‰∏á‰∏™‰ª§Áâå $1\\.25\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XM3hFyS_PCcuv8Px.png)\n\n‚úÖ Gemini 1\\.5 Flash ÊàêÊú¨Ôºö\n\n* ËæìÂÖ•ÔºöÊØèÁôæ‰∏á‰∏™‰ª§Áâå $0\\.075\n* ËæìÂá∫ÔºöÊØèÁôæ‰∏á‰∏™‰ª§Áâå $0\\.30\n* ÁºìÂ≠òËæìÂÖ•ÔºöÊØèÁôæ‰∏á‰∏™‰ª§Áâå $0\\.01875\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*d-1ioFlCxW3LB4SL.png)\n\nËøòÊúâÁî®‰∫éÊàêÊú¨ÊïàÁõä‰ªªÂä°ÁöÑ mini Flash\\-8B ÁâàÊú¨ ‚Äî ÊØî GPT\\-4o ‰æøÂÆú 66 ÂÄçÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5B5ybLzTr7penwms.png)\n\nÊúÄÊ£íÁöÑÊòØÂÖ∂Â§öÊ®°ÊÄÅÊÄß ‚Äî ÂÆÉÂèØ‰ª•‰ª•Â§çÊùÇÁöÑÈõÜÊàêÊñπÂºèÂØπÊñáÊú¨„ÄÅÊñá‰ª∂„ÄÅÂõæÂÉèÂíåÈü≥È¢ëËøõË°åÊé®ÁêÜ„ÄÇ\n\nËÄå 1\\.5 Flash Âá†‰πéÂÖ∑Â§á Pro ÁöÑÊâÄÊúâËÉΩÂäõÔºå‰ΩÜÈÄüÂ∫¶Êõ¥Âø´„ÄÇ‰Ωú‰∏∫ÂºÄÂèëËÄÖÔºå‰Ω†Áé∞Âú®Â∞±ÂèØ‰ª•ÂºÄÂßã‰ΩøÁî®ÂÆÉ‰ª¨„ÄÇ\n\nGemini 1\\.5 Pro Âú®‰∏ÄÈÉ® 44 ÂàÜÈíüÁöÑÊó†Â£∞ÁîµÂΩ±‰∏≠ËøõË°å‰∫ÜÊµãËØïÔºå‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÊòØÔºåÂÆÉËΩªÊùæÂ∞ÜÁîµÂΩ±ÂàÜÊûêÊàêÂêÑÁßçÊÉÖËäÇÂíå‰∫ã‰ª∂ÔºåÁîöËá≥ÊåáÂá∫Â§ßÂ§öÊï∞‰∫∫Âú®Á¨¨‰∏ÄÊ¨°ËßÇÁúãÊó∂‰ºöÈîôËøáÁöÑÂ∞èÁªÜËäÇ„ÄÇ\n\n‰∏éÊ≠§ÂêåÊó∂ÔºåGPT\\-4o API ‰ªÖÂÖÅËÆ∏‰Ω†Â§ÑÁêÜÊñáÊú¨ÂíåÂõæÂÉè„ÄÇ\n\n‰Ω†ÂèØ‰ª•Âú®Ë∞∑Ê≠åÁöÑ AI Studio ‰∏≠ËΩªÊùæÂàõÂª∫„ÄÅÊµãËØïÂíåÂÆåÂñÑÊèêÁ§∫ ‚Äî **ÂÆåÂÖ®ÂÖçË¥π**„ÄÇ\n\nËøô‰∏ç‰ºöÂÉèÂú® OpenAI playground ‰∏≠ÈÇ£Ê†∑ËÆ°ÂÖ•‰Ω†ÁöÑË¥¶Âçï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5BKejWrJvrsEWIjc.png)\n\nÁúãÁúãË∞∑Ê≠å AI Studio ÁöÑÂº∫Â§ßÂäüËÉΩ ‚Äî Ê†πÊçÆÂõæÂÉèÂàõÂª∫È£üË∞±Ôºö\n\nÊàë‰∏ä‰º†‰∫ÜËøôÂº†Êù•Ëá™ gettyimages ÁöÑÁæéÂë≥Èù¢ÂåÖÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fC5YL_dplJ9Od_vN.jpg)\n\nÁé∞Âú®Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*GezbFh9KzFXRVhr3.png)\n\nÂ¶ÇÊûúÊàëÊÉ≥Ë¶ÅÂìçÂ∫î‰ª•ÊàëÁöÑ API ÊàñÂÖ∂‰ªñÂÜÖÂÆπÁöÑÁâπÂÆöÊ†ºÂºèÂë¢Ôºü\n\nÈÇ£‰πà‰Ω†ÂèØ‰ª•ÊâìÂºÄ JSON Ê®°ÂºèÂπ∂ÊåáÂÆöÂìçÂ∫îÊ®°ÂºèÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*aRZuia7Iz_mI2s9b.png)\n\nOpenAI playground ‰πüÊúâËøô‰∏™Ôºå‰ΩÜ‰ΩøÁî®Ëµ∑Êù•‰∏çÂ¶ÇÂÆÉÁõ¥ËßÇ„ÄÇ\n\nGemini Áõ∏ËæÉ‰∫é OpenAI ÁöÑÂè¶‰∏Ä‰∏™ÂçáÁ∫ßÊòØÂÆÉÁöÑÂàõÈÄ†Âäõ„ÄÇ\n\nÂú® Gemini ‰∏≠Ôºå‰Ω†ÂèØ‰ª•Â∞Ü `temperature` ‰ªé 0 Â¢ûÂä†Âà∞ 200% Êù•ÊéßÂà∂ÂìçÂ∫îÁöÑÈöèÊú∫ÊÄßÂíåÂàõÈÄ†ÊÄßÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4AAFdAMfT_xyflmv.png)\n\nËÄåÂú® OpenAI ‰∏≠ÔºåÂ¶ÇÊûú‰Ω†Â∞ùËØïË∂ÖËøá 100%Ôºå‰Ω†ÂæàÂèØËÉΩ‰ºöÂæóÂà∞‰∏ÄÂ†ÜÂÆåÂÖ®Êó†ÊÑè‰πâÁöÑÂÜÖÂÆπ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yzFQL69pyJmgE9UB.png)\n\nËÄå‰∏îÊúÄÊ£íÁöÑÊòØ ‚Äî ÂΩì‰Ω†ÂÆåÊàêÂàõÂª∫ÊèêÁ§∫ÂêéÔºå‰Ω†ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî® **Ëé∑Âèñ‰ª£Á†Å** ‚Äî ËΩªÊùæÂ§çÂà∂Âπ∂Á≤òË¥¥Ê®°Êùø API ‰ª£Á†ÅÔºåÂø´ÈÄüËøõÂÖ•ÂºÄÂèë„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*xgaZfVe9b8WSBMmq.png)\n\nÊîØÊåÅÂåÖÊã¨ Kotlin„ÄÅSwift Âíå Dart Âú®ÂÜÖÁöÑÂ§öÁßçËØ≠Ë®Ä ‚Äî Âú®ÁßªÂä®ÂºÄÂèë‰∏≠ÂÆûÁé∞È´òÊïàÁöÑ AI Â∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*AMkfKm-3KQRxnltO.png)\n\nÂú® OpenAI playground ‰∏≠Ôºå‰Ω†ÂèØ‰ª•Ëé∑Âæó Python Âíå JavaScript ÁöÑ‰ª£Á†Å„ÄÇ\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nGemini 1.5 Flash ÊòØ‰∏ÄÊ¨æÈ¢†Ë¶ÜÊÄßÁöÑ‰∫ßÂìÅÔºå‰ª•ÊûÅ‰ΩéÁöÑÊàêÊú¨Êèê‰æõÊó†‰∏é‰º¶ÊØîÁöÑËÉΩÂäõ„ÄÇ\n\nÂá≠ÂÄüÂÖ∂ÂÖàËøõÁöÑÂ§öÊ®°ÊÄÅÊòìÁî®ÊÄß„ÄÅÊÖ∑ÊÖ®ÁöÑÂÖçË¥πÂÆö‰ª∑ÂíåÂàõÈÄ†ÊΩúÂäõÔºåÂÆÉ‰∏∫‰∫∫Â∑•Êô∫ËÉΩËÆæÂÆö‰∫ÜÊñ∞ÁöÑÊ†áÂáÜÔºåËÆ© GPT-4o Áõ∏ÂΩ¢ËßÅÁªå„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/gemma-vs-llama-vs-mistral-exploring-smaller-ai-models-672a95f4b9b7","frontmatter":{"title":"Gemma„ÄÅLlama Âíå MistralÔºöÊé¢Á¥¢ËæÉÂ∞èÁöÑ AI Ê®°Âûã","meta_title":"Gemma„ÄÅLlama Âíå MistralÔºöÊé¢Á¥¢ËæÉÂ∞èÁöÑ AI Ê®°Âûã","description":"Â∞èËßÑÊ®°ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊØîËæÉÁ†îÁ©∂ÔºöËØÑ‰º∞ Gemma„ÄÅLlama 3 Âíå Mistral Âú®ÈòÖËØªÁêÜËß£‰ªªÂä°‰∏≠ÁöÑË°®Áé∞","date":"2024-11-10T22:36:54.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TJqJ12YQCeYTS5fWOYR5Ig.png","categories":["Natural Language Processing","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Gemma","Llama","Mistral","SQuAD","Multi-Query"],"draft":false,"slug":"blog/gemma-vs-llama-vs-mistral-exploring-smaller-ai-models-672a95f4b9b7"},"content":"\n### Â∞èËßÑÊ®°ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊØîËæÉÁ†îÁ©∂ÔºöÂú®ÈòÖËØªÁêÜËß£‰ªªÂä°‰∏≠ËØÑ‰º∞ Gemma„ÄÅLlama 3 Âíå Mistral\n\n## ÂºïË®Ä\n\nÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊ≠£Âú®Âø´ÈÄüÂèëÂ±ï„ÄÇÊØè‰∏™ÊúàÔºåÊñ∞ÁöÑÊ®°ÂûãË¢´ÂºÄÂèëÂá∫Êù•Ôºå‰ª•Ë∂ÖË∂äÂΩìÂâçÂ∏ÇÂú∫‰∏äÁöÑÈ°∂Â∞ñÊ®°Âûã„ÄÇËøôÁßçÂÅ•Â∫∑ÁöÑÁ´û‰∫âÊúâÂà©‰∫éÂàõÈÄ†Êñ∞ÁöÑÊñπÊ≥ïÔºåÊèêÈ´òË¥®ÈáèÂíåÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåÂêÑÂÖ¨Âè∏Ëøò‰∏ìÊ≥®‰∫éÂºÄÂèëÊõ¥Â∞èÁöÑÊ®°ÂûãÔºå‰ª•‰æø‰ΩøÂÖ∂ËÉΩÂ§üË¢´Ê≤°ÊúâÂº∫Â§ßËÆ°ÁÆóËµÑÊ∫êÁöÑ‰∏™‰∫∫ÊàñÁªÑÁªáÊâÄ‰ΩøÁî®„ÄÇ\n\nÂ∞±Âú®Âá†Âë®ÂâçÔºåËãπÊûúÂÖ¨Âè∏Âú®ÂÖ∂ÂÖ®ÁêÉÂºÄÂèëËÄÖÂ§ß‰ºö‰∏äÊé®Âá∫‰∫ÜApple Intelligence„ÄÇËøôÊòØ‰∏ÄÂ•óÂ§ö‰∏™ÁîüÊàêÊ®°ÂûãÔºåÁªèËøáÂæÆË∞É‰ª•Â∏ÆÂä©Áî®Êà∑Êí∞ÂÜôÂíåÂÆåÂñÑÊñáÊú¨„ÄÅ‰ºòÂÖàÂ§ÑÁêÜÂíåÊÄªÁªìÈÄöÁü•„ÄÅÂàõÂª∫ÂõæÂÉè‰ª•ÂèäËøõË°åÂ∫îÁî®ÂÜÖÊìç‰Ωú„ÄÇÂú®ËØ•Â•ó‰ª∂‰∏≠ÔºåËãπÊûúÂÖ¨Âè∏ÂºÄÂèëÁöÑÂîØ‰∏ÄÂü∫Á°ÄÂíå‰∏ìÊúâÊ®°ÂûãÊòØÂú®Âêå‰∏ÄÂ§ß‰ºö‰∏ä‰ªãÁªçÁöÑ„ÄÇÂÆÉÊòØ‰∏Ä‰∏™Êó®Âú®ËÆæÂ§á‰∏äËøêË°åÁöÑÂ∞èÂûãÊ®°ÂûãÔºåÂÖ∂‰∏≠Á°¨‰ª∂Êàê‰∏∫‰∏Ä‰∏™ÈáçË¶ÅÁöÑÈôêÂà∂„ÄÇÂú®ËãπÊûúÁöÑÊ°à‰æã‰∏≠ÔºåËØ•Ê®°ÂûãÊòØÈó≠Ê∫êÁöÑ„ÄÇÊàë‰ª¨ÊâÄÁü•ÈÅìÁöÑÊòØÔºåÂÆÉÊòØ‰∏Ä‰∏™Á∫¶30‰∫øÂèÇÊï∞ÁöÑÊ®°ÂûãÔºå‰∏éGemma„ÄÅMistralÂíåLlama 3ÁöÑ7bÁâàÊú¨Áõ∏ÂΩìÔºàÊ†πÊçÆËãπÊûúÂàÜ‰∫´ÁöÑÁªìÊûúÔºâ„ÄÇ\n\nËôΩÁÑ∂ËãπÊûúÁöÑÊñ∞Ê®°Âûã‰ª§‰∫∫ÂÖ¥Â•ãÔºå‰ΩÜÊàë‰ª¨Êó†Ê≥ïÊµãËØïÊàñÈáçÁî®ÂÆÉ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Êõ¥ÊÑüÂÖ¥Ë∂£ÁöÑÊòØÂÖ¨ÂºÄÂèØÁî®ÁöÑÊ®°ÂûãÔºåÂõ†‰∏∫ÂºÄÂèëËÄÖÂíåÂÖ¨Âè∏ÂèØ‰ª•Âà©Áî®ÂÆÉ‰ª¨Êù•ÊûÑÂª∫Êñ∞‰∫ßÂìÅÂíåÊúçÂä°„ÄÇÂå∫ÂàÜÂºÄÊîæLLMsÂíåÂºÄÊ∫êLLMsÊòØÈáçË¶ÅÁöÑ„ÄÇ‰ªéÂéÜÂè≤‰∏äÁúãÔºåÂºÄÊ∫êËΩØ‰ª∂ÊåáÁöÑÊòØÂú®ÁâπÂÆöËÆ∏ÂèØËØÅ‰∏ãÂèëÂ∏ÉÁöÑËÆ°ÁÆóÊú∫Á®ãÂ∫èÔºå‰ΩøÊ∫ê‰ª£Á†ÅÂèØ‰æõÂÖ¨‰ºó‰ΩøÁî®Êàñ‰øÆÊîπ„ÄÇÂú®LLMs‰∏≠ÔºåÂ≠òÂú®È¢ùÂ§ñÁöÑÂ§çÊùÇÊÄßÔºåÂåÖÊã¨ËÆ≠ÁªÉÊï∞ÊçÆÂíåÊ®°ÂûãÊùÉÈáç„ÄÇÂõ†Ê≠§ÔºåÂºÄÊîæLLMsÈÄöÂ∏∏‰ºöÊä´Èú≤Ê®°ÂûãÊùÉÈáçÂíåÂàùÂßã‰ª£Á†Å„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂºÄÊ∫êLLMÂ∞ÜÂàÜ‰∫´ËÆ≠ÁªÉËøáÁ®ãÁöÑÊØè‰∏ÄÊ≠•ÔºåÂåÖÊã¨ËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ª•Âèä‰∏Ä‰∏™ÂÆΩÊùæÁöÑËÆ∏ÂèØËØÅ„ÄÇÂÆÉÂ∫îËØ•ÂÖÅËÆ∏ÂÖ∂‰ªñ‰∫∫‰ΩøÁî®„ÄÅÊûÑÂª∫ÂíåËøõ‰∏ÄÊ≠•ÂàÜÂèëËØ•Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂ¶Ç‰ªäÂèëÂ∏ÉÁöÑÂ§ßÂ§öÊï∞Ê®°ÂûãÈÉΩÂ±û‰∫éÂºÄÊîæLLMsÁöÑËåÉÁï¥ÔºåÂõ†‰∏∫‰æãÂ¶ÇÂÆÉ‰ª¨Âπ∂Êú™ÂèëÂ∏ÉÁî®‰∫éËÆ≠ÁªÉÁöÑÊï∞ÊçÆÂ∫ì„ÄÇËøôÁßçÊÉÖÂÜµÈÄÇÁî®‰∫éË∞∑Ê≠åÁöÑGemma„ÄÅMistral AIÁöÑMistralÂíåMetaÁöÑLlama„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êõ¥‰ªîÁªÜÂú∞ÂàÜÊûêGemmaÔºå‰ª•‰∫ÜËß£Ëøô‰∫õËæÉÂ∞èÊ®°ÂûãÁöÑÂå∫Âà´„ÄÇGemmaÊòØË∞∑Ê≠åÊúÄËøëÂèëÂ∏ÉÁöÑÊ®°Âûã‰πã‰∏Ä„ÄÇÂÆÉÊúâ‰∏§‰∏™ÁâàÊú¨ÔºåÂàÜÂà´ÊòØ20‰∫øÂíå70‰∫øÂèÇÊï∞„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂèØ‰ª•Âú®ËæπÁºòËÆæÂ§á‰∏ä‰ΩøÁî®ÔºåÂπ∂Êó®Âú®Ë∂ÖË∂äMistralÂíåLlama 3Á≠âÊúÄÂÖàËøõÁöÑÊ®°Âûã„ÄÇ\n\nÊ≠§Â§ñÔºåÊàë‰ª¨Â∞ÜGemma„ÄÅLlama 3ÂíåMistralÂ∫îÁî®‰∫é‰∏Ä‰∏™Âêç‰∏∫SQuADÁöÑÈòÖËØªÁêÜËß£Êï∞ÊçÆÈõÜ„ÄÇLLMsÁöÑ‰ªªÂä°ÊòØÊ†πÊçÆÁªôÂÆöÁöÑ‰∏ä‰∏ãÊñáÂõûÁ≠îÁâπÂÆöÈóÆÈ¢ò„ÄÇÊàë‰ª¨‰ΩøÁî®ÂÆöÈáèÊåáÊ†áËØÑ‰º∞ÂÆÉ‰ª¨ÁöÑÊÄßËÉΩÔºå‰æãÂ¶ÇÊé®ÁêÜÈÄüÂ∫¶ÂíåÂπ≥ÂùáÂõûÁ≠îÈïøÂ∫¶„ÄÇÊàë‰ª¨Ëøò‰ΩøÁî®‰∫Ü\\[1]ÊèêÂá∫ÁöÑÁõ∏ÂØπÁ≠îÊ°àË¥®ÈáèÔºàRAQÔºâÊ°ÜÊû∂„ÄÇRAQÈÄöËøáÊ†πÊçÆÁ≠îÊ°àÁõ∏ÂØπ‰∫éÁúüÂÆûÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÂØπÁ≠îÊ°àËøõË°åÊéíÂêçÔºåÂ°´Ë°•‰∫ÜÂú®ÁâπÂÆöÁî®‰æã‰∏≠ËØÑ‰º∞LLMsÁöÑÁ©∫ÁôΩÔºå‰ªéËÄåÊèê‰æõ‰∫ÜÊõ¥ÁªÜËá¥ÂíåÂÆûÁî®ÁöÑÊ®°ÂûãÊÄßËÉΩËØÑ‰º∞„ÄÇ\n\n\n\nÂ¶ÇÂæÄÂ∏∏‰∏ÄÊ†∑Ôºå‰ª£Á†ÅÂèØÂú®Êàë‰ª¨ÁöÑ[GitHub](https://github.com/zaai-ai/lab)‰∏äÊâæÂà∞„ÄÇ\n\n## Gemma: GeminiÁöÑÂü∫Á°ÄÊñáÊú¨Ê®°Âûã\n\nË∞∑Ê≠åÂèëÂ∏É‰∫ÜGemma \\[2]ÔºåËøôÊòØÂü∫‰∫éÂÖ∂Âº∫Â§ßÁöÑÈó≠Ê∫êÊ®°ÂûãGemini \\[3]ÂºÄÂèëÁöÑÂºÄÊîæLLM„ÄÇ\n\nË∞∑Ê≠åÂèëÂ∏É‰∫ÜÈ¢ÑËÆ≠ÁªÉÂíåÂæÆË∞ÉÁöÑÊ£ÄÊü•ÁÇπÔºå‰ª•‰øÉËøõËØ•Ê®°ÂûãÂú®Êñ∞Áî®‰æã‰∏≠ÁöÑËøõ‰∏ÄÊ≠•Á†îÁ©∂ÔºåÊèê‰æõ‰∫Ü‰∏§Áßç‰∏çÂêåÁöÑÂ§ßÂ∞èÔºö\n\n* 7BÊ®°ÂûãÂ∞ÜË¢´ÈÉ®ÁΩ≤Âπ∂Âú®GPUÊàñTPU‰∏äËøõ‰∏ÄÊ≠•ÂºÄÂèë„ÄÇ\n* 2BÊ®°ÂûãÊó®Âú®Ëß£ÂÜ≥ËÆ°ÁÆóÈôêÂà∂ÔºåÂπ∂ÂÖÅËÆ∏Âú®CPUÊàñËÆæÂ§áÂ∫îÁî®Á®ãÂ∫è‰∏ä‰ΩøÁî®„ÄÇ\n\nGemmaÊâøËØ∫Âú®‰∏éÂÖ∂‰ªñÂ§ßËá¥Áõ∏ÂêåËßÑÊ®°ÁöÑÂºÄÊîæÊ®°ÂûãÔºàÂ¶ÇLlama 3 7BÊàñMistral 7BÔºâÁõ∏ÊØîÊó∂ÔºåËææÂà∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇËøôÂ∫îËØ•Âú®‰∏çÂêåÈ¢ÜÂüü‰∏≠ÂÆûÁé∞Ôºå‰æãÂ¶ÇÈóÆÁ≠î„ÄÅÂ∏∏ËØÜÊé®ÁêÜ„ÄÅÊï∞Â≠¶/ÁßëÂ≠¶ÂíåÁºñÁ†Å„ÄÇ\n\n## Gemma: Êúâ‰ªÄ‰πàÊñ∞ÂèòÂåñÔºü\n\nGemma ÁöÑÊû∂ÊûÑÂü∫‰∫é‰∏Ä‰∏™‰ªÖËß£Á†ÅÂô® \\[4] Transformer \\[5]Ôºå‰∏ä‰∏ãÊñáÈïøÂ∫¶‰∏∫ 8192 ‰∏™Ê†áËÆ∞„ÄÇËÆ©Êàë‰ª¨Êù•Êé¢ËÆ®‰∏Ä‰∏ã‰∏∫‰ΩøÂÖ∂Êõ¥Â∞èËÄåÈááÂèñÁöÑÊñπÊ≥ï„ÄÇ\n\n## Â§öÊü•ËØ¢Ê≥®ÊÑèÂäõ\n\n2BÊ®°ÂûãÂà©Áî®Â§öÊü•ËØ¢Ê≥®ÊÑèÂäõÔºàMQAÔºâÊòæËëóÂáèÂ∞ë‰∫ÜÂä†ËΩΩÊâÄÊúâÊü•ËØ¢„ÄÅÈîÆÂíåÂÄºÂ§¥ÊâÄÈúÄÁöÑÂÜÖÂ≠òËµÑÊ∫êÔºåËÄå‰∏çÊòØ‰ΩøÁî®Â§öÂ§¥Ê≥®ÊÑèÂäõÔºàMHAÔºâÊñπÊ≥ï„ÄÇMQAÈÄöËøáÂú®Ê≥®ÊÑèÂäõÂ±Ç‰∏≠ÂØπÂ§ö‰∏™Êü•ËØ¢Â§¥‰ΩøÁî®Âçï‰∏ÄÁöÑÈîÆÂíåÂÄºÊù•ÂÆûÁé∞ËøôÁßçÂÜÖÂ≠òÂáèÂ∞ëÔºåÂ¶ÇÂõæ3ÊâÄÁ§∫„ÄÇ\n\nËôΩÁÑ∂ËøôÁßçÊñπÊ≥ïÂÖÅËÆ∏Gemma 2BÂú®ÂÜÖÂ≠òËµÑÊ∫êËæÉÂ∞èÁöÑËÆæÂ§á‰∏äÈÉ®ÁΩ≤Ôºå‰ΩÜÂèØËÉΩÂØºËá¥Ë¥®Èáè‰∏ãÈôçÂíåËÆ≠ÁªÉ‰∏çÁ®≥ÂÆö„ÄÇÂõ†Ê≠§Ôºå‰ΩúËÄÖÈÄâÊã©Âú®7BÁâàÊú¨‰∏≠‰ΩøÁî®MHAÔºåÈÅµÂæ™‰∏éLlama 3Áõ∏ÂêåÁöÑÊñπÊ≥ï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cgSktHmd_iQeTU4DwWLCPQ.png)\n\n## RoPE ÂµåÂÖ•\n\nTransformers ÈúÄË¶Å‰ΩçÁΩÆÂµåÂÖ•ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Êú¨Ë¥®‰∏äÊòØÊó†Â∫è‰∏çÂèòÁöÑ„ÄÇËøôÊÑèÂë≥ÁùÄÂ¶ÇÊûúÊ≤°Êúâ‰ΩçÁΩÆ‰ø°ÊÅØÔºåTransformer Â∞Ü‰ª•Áõ∏ÂêåÁöÑÊñπÂºèË°®Á§∫ÂÖ∑ÊúâÁõ∏ÂêåÂçïËØç‰ΩÜ‰∏çÂêåÈ°∫Â∫èÂíåÊÑè‰πâÁöÑÂè•Â≠ê„ÄÇ‰æãÂ¶ÇÔºö\n\n> *Âè•Â≠ê 1:* Gemma ÊØî Llama 3 Êõ¥Â•Ω\n\n> *Âè•Â≠ê 2:* Llama 3 ÊØî Gemma Êõ¥Â•Ω\n\n‰ΩçÁΩÆ‰ø°ÊÅØÈÄöÂ∏∏‰ΩøÁî®‰∏§‰∏™Ê≠£Âº¶ÂáΩÊï∞ÔºàÊ≠£Âº¶Âíå‰ΩôÂº¶ÔºâÊù•Ë°®Á§∫„ÄÇÁÑ∂ÂêéÔºåÊ†πÊçÆ‰ΩçÁΩÆ„ÄÅÊ†áËÆ∞ÂµåÂÖ•Áª¥Â∫¶ÂíåÊ®°ÂûãÁª¥Â∫¶Ôºå‰∏∫Â∫èÂàó‰∏≠ÁöÑÊØè‰∏™‰ΩçÁΩÆÂàõÂª∫‰∏Ä‰∏™Áã¨ÁâπÁöÑ‰ΩçÁΩÆ‰ø°ÊÅØÂµåÂÖ•„ÄÇ\n\nÂõ†Ê≠§ÔºåÊ∑ªÂä†‰ΩçÁΩÆ‰ø°ÊÅØÂØπ‰∫é‰Ωø Transformers Ê≠£Á°ÆÂ§ÑÁêÜÊñáÊú¨Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÂéüÂßã Transformer Êû∂ÊûÑ‰ΩøÁî®**ÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•**ÔºåÂÖ∂‰∏≠‰ΩçÁΩÆÁöÑÂêëÈáèË°®Á§∫Ë¢´Ê∑ªÂä†Âà∞Ê†áËÆ∞ÁöÑÂêëÈáèË°®Á§∫‰∏≠„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cU5a_5-ATKwrQVeka-ViXQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JZLrvgvc7l_52uewCrPSbg.png)\n\nÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•ÁöÑÊåëÊàòÂú®‰∫éÂÆÉ‰ª¨Âπ∂Êú™ÊòéÁ°ÆÁºñÁ†ÅÊ†áËÆ∞‰πãÈó¥ÁöÑÁõ∏ÂØπË∑ùÁ¶ª„ÄÇËôΩÁÑ∂ÂÆÉ‰ª¨‰ΩøÁî®Ê≠£Âº¶Âíå‰ΩôÂº¶ÂáΩÊï∞ÊçïËé∑‰ΩçÁΩÆ‰ø°ÊÅØÔºå‰ΩÜËøô‰∫õÂµåÂÖ•ÊòØÈíàÂØπÊØè‰∏™‰ΩçÁΩÆÁã¨Á´ãËÆ°ÁÆóÁöÑ„ÄÇËøôÊÑèÂë≥ÁùÄÊ®°ÂûãÂπ∂‰∏çÂõ∫ÊúâÂú∞ÁêÜËß£Â∫èÂàó‰∏≠‰∏çÂêå‰ΩçÁΩÆÁöÑÊé•ËøëÊÄßÊàñÂÖ≥Á≥ªÈáçË¶ÅÊÄß„ÄÇ‰æãÂ¶ÇÔºå‰ΩçÁΩÆ 1 Âíå 2 ÁöÑÊ†áËÆ∞ÂµåÂÖ•ÂèØËÉΩÁî±‰∫éÊ≠£Âº¶ÂáΩÊï∞ÁöÑÊÄßË¥®ËÄåÁúãËµ∑Êù•Áõ∏‰ººÔºå‰ΩÜÊ®°ÂûãÂπ∂Êú™ÊòéÁ°ÆËØÜÂà´Ëøô‰∫õ‰ΩçÁΩÆÊòØÁõ∏ÈÇªÁöÑ„ÄÇ\n\nÂõ†Ê≠§ÔºåÊ®°ÂûãÂèØËÉΩÊó†Ê≥ïÂå∫ÂàÜ‰ΩçÁΩÆ 1 Âíå 2 ÁöÑÊ†áËÆ∞‰πãÈó¥ÁöÑÂÖ≥Á≥ª‰∏é‰ΩçÁΩÆ 1 Âíå 500 ÁöÑÊ†áËÆ∞‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËøáÁ®ã‰∏≠ÔºåÂè•Â≠ê‰∏≠Áõ∏ËøëÁöÑÂçïËØçÈÄöÂ∏∏ÂÖ±‰∫´Êõ¥Â§ö‰∏ä‰∏ãÊñáÊàñÂÖ∑ÊúâÊØîËøúÁ¶ªÁöÑÂçïËØçÊõ¥Âº∫ÁöÑËØ≠‰πâÊàñÂè•Ê≥ïÂÖ≥Á≥ª„ÄÇÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•ÂèØËÉΩÊó†Ê≥ïÂÆåÂÖ®ÊçïËé∑ËøôÁßçÁªÜÂæÆÂ∑ÆÂà´„ÄÇËøôÂèØËÉΩÂØºËá¥Âú®ÊçïËé∑ÈïøÁ®ã‰æùËµñÂÖ≥Á≥ªÊàñËØ≠Ë®ÄÁöÑÂ±ÇÊ¨°ÁªìÊûÑÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*p-fG2ydLbOhJHjO7Y0LyUw.png)\n\nÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÔºàRoPEÔºâ\\[6] ÈÄöËøáÂØπÂ∫èÂàó‰∏≠ÁöÑÊ†áËÆ∞ÂµåÂÖ•ËøõË°åÊóãËΩ¨Êù•Âª∫Ê®°Ê†áËÆ∞ÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÔºå‰ªéËÄåËß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢ò„ÄÇ\n\nËÆ©Êàë‰ª¨‰ΩøÁî®‰πãÂâçÁöÑ‰æãÂ≠êÔºå*‚ÄòGemma ÊØî Llama Êõ¥Â•Ω*ÔºåÂπ∂ËÄÉËôëÊØè‰∏™ÂçïËØç‰Ωú‰∏∫Áî± 2D ÂêëÈáèË°®Á§∫ÁöÑÊ†áËÆ∞„ÄÇÂçïËØç *better* Â∞ÜÁî±Ê†πÊçÆÂÖ∂‰ΩçÁΩÆ *m* Âíå‰∏Ä‰∏™Â∏∏ÈáèËßíÂ∫¶ Œ∏ ‰ªéÂéüÂßãÂêëÈáèÊóãËΩ¨ËÄåÊù•ÁöÑ 2D ÂêëÈáèË°®Á§∫ÔºåÂ¶ÇÂõæ 5 ÊâÄÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nX3llo0cwBIrCQ8Gn21-gg.png)\n\nËøôÁßçÊñπÊ≥ï‰øùÁïô‰∫ÜÊ†áËÆ∞‰πãÈó¥ÁöÑÁõ∏ÂØπË∑ùÁ¶ªÔºåÂõ†‰∏∫ÊóãËΩ¨ÂèòÊç¢‰øùÊåÅ‰∫ÜÂêëÈáè‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÔºåÊó†ËÆ∫ÂÆÉ‰ª¨Âú®Â∫èÂàó‰∏≠ÁöÑ‰ΩçÁΩÆÂ¶Ç‰Ωï„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊàë‰ª¨Âú®ÂéüÂßãÂè•Â≠ê‰∏≠Ê∑ªÂä†‰∏§‰∏™ÂçïËØçÔºå‰ΩøÂÖ∂Âèò‰∏∫‚Äò*The LLM Gemma ÊØî Llama Êõ¥Â•Ω*‚ÄôÔºåÂàô *better* Âíå *than* ÁöÑ‰ΩçÁΩÆ‰ªé (3 & 4) Âèò‰∏∫ (5 & 6)„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÊóãËΩ¨ËßíÂ∫¶‰øùÊåÅ‰∏ÄËá¥ÔºåËøô‰∫õÂêëÈáè‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÔºàÈÄöËøáÁÇπÁßØÊµãÈáèÔºâ‰øùÊåÅ‰∏çÂèòÔºå‰ªéËÄåÁ°Æ‰øù‰∫Ü‰∏ÄËá¥ÁöÑÁõ∏ÂØπ‰ΩçÁΩÆ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6cpWPXTexZC8YQbnasHOUg.png)\n\n## GeGLU ÊøÄÊ¥ªÂáΩÊï∞\n\n‰ΩúËÄÖÂ∞Ü‰º†ÁªüÁöÑ ReLU ÊøÄÊ¥ªÂáΩÊï∞ÊõøÊç¢‰∏∫‰∏ÄÁßçÁß∞‰∏∫ GeGLU ÁöÑÈó®ÊéßÁ∫øÊÄßÂçïÂÖÉÔºàGLUÔºâÂèò‰ΩìÔºåÂõ†‰∏∫Âè¶‰∏ÄÈ°πÁ†îÁ©∂ \\[7] Ë°®ÊòéÂÆÉÊîπÂñÑ‰∫Ü LLM ÁîüÊàêÁöÑËæìÂá∫Ë¥®Èáè„ÄÇ\n\nReLU Âíå GeGLU ‰πãÈó¥Êúâ‰∏§‰∏™Âå∫Âà´Ôºö\n\n1. **ÊøÄÊ¥ªÂáΩÊï∞** ‚Äî GeGLU ‰ΩøÁî®È´òÊñØËØØÂ∑ÆÁ∫øÊÄßÂçïÂÖÉÔºàGELUÔºâ\\[8] ÂáΩÊï∞Ôºå‰∏é ReLU ÁöÑ‰∏çÂêå‰πãÂ§ÑÂú®‰∫éÔºåÂÆÉÂ∞ÜÁ•ûÁªèÂÖÉËæìÂÖ• *x* ‰πò‰ª•Ê≠£ÊÄÅÂàÜÂ∏ÉÁöÑÁ¥ØÁßØÂàÜÂ∏ÉÂáΩÊï∞„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºå*x* Ë¢´‰∏¢ÂºÉÁöÑÊ¶ÇÁéáÈöèÁùÄ *x* ÁöÑÂáèÂ∞èËÄåÂ¢ûÂä†„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FXCfQpvdMJXPk5s6AO-RuA.png)\n\n2\\. **Sigmoid ÊøÄÊ¥ª** ‚Äî ÁÆÄÂçïÁöÑ ReLU Êàñ GELU ÊøÄÊ¥ªÂáΩÊï∞Â∫îÁî®‰∫éÈöêËóèË°®Á§∫ *x* Âíå‰∏§‰∏™Áî±‰∏§‰∏™Áü©Èòµ (*W1* Âíå *W2*) Ë°®Á§∫ÁöÑÁ∫øÊÄßÂèòÊç¢‰πãÈó¥„ÄÇGeGLU ‰∏≠ÁöÑÈó®ÊéßÂèò‰ΩìÂØπÂÖ∂‰∏≠‰∏Ä‰∏™ÁªÑ‰ª∂Â∫îÁî®Èó®ÊéßÊú∫Âà∂ÔºàsigmoidÔºâÔºåÂ¶ÇÂÖ¨Âºè 3 ÊâÄÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Z9hUjuy4NvQVDrPj6iSfrQ.png)\n\n## Normalizer Location\n\nÂØπÂéüÂßãTransformerÊû∂ÊûÑÁöÑÊúÄÂêé‰øÆÊîπÂ¶ÇÂõæ8ÊâÄÁ§∫„ÄÇ‰ΩúËÄÖÂØπÊØè‰∏™transformerÂ≠êÂ±ÇÁöÑËæìÂÖ•ÂíåËæìÂá∫ËøõË°å‰∫ÜÂΩí‰∏ÄÂåñÔºå‰ª•ÊèêÈ´òËÆ≠ÁªÉÁöÑÁ®≥ÂÆöÊÄßÔºåËøô‰∏éÂéüÂßãËÆ∫Êñá‰ªÖÂØπËæìÂá∫ËøõË°åÂΩí‰∏ÄÂåñÁöÑÂÅöÊ≥ïÁõ∏Âèç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NQe4ME2MhvRWVzobVdIloA.png)\n\n‰ªñ‰ª¨ËøòÁî®RMSNorm \\[8]ÊõøÊç¢‰∫Ü‰º†ÁªüÁöÑLayerNormÂáΩÊï∞„ÄÇRMSNormÂú®‰øùÊåÅËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÊîπËøõÁöÑÂêåÊó∂ÔºåËÆ°ÁÆó‰∏äÊõ¥È´òÊïàÔºåÂπ∂ÊúâÂä©‰∫éÊ®°ÂûãÊî∂Êïõ„ÄÇ\n\nRMSNormÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊïàÁéáÔºåÂõ†‰∏∫ÂÖ∂‰ΩúËÄÖËØÅÊòéLayerNormÁöÑÂ•ΩÂ§ÑÊù•Ëá™‰∫éÈáçÊñ∞Áº©Êîæ‰∏çÂèòÊÄßÔºåËÄå‰∏çÊòØÈáçÊñ∞‰∏≠ÂøÉÂåñ‰∏çÂèòÊÄß„ÄÇÈáçÊñ∞Áº©Êîæ‰∏çÂèòÊÄßÊÑèÂë≥ÁùÄÔºåÂ¶ÇÊûú‰∏Ä‰∏™Â∏∏Êï∞Âõ†Â≠êÁº©ÊîæËæìÂÖ•ÔºåÂàôÂΩí‰∏ÄÂåñËøáÁ®ãÁöÑËæìÂá∫‰øùÊåÅ‰∏çÂèò„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂ∞ÜÊâÄÊúâËæìÂÖ•‰πò‰ª•‰∏Ä‰∏™Â∏∏Êï∞‰∏ç‰ºöÂΩ±ÂìçÂΩí‰∏ÄÂåñËæìÂá∫„ÄÇÈáçÊñ∞‰∏≠ÂøÉÂåñ‰∏çÂèòÊÄßÊÑèÂë≥ÁùÄÔºåÂ¶ÇÊûú‰∏Ä‰∏™Â∏∏Êï∞ÂÄºÂä†Âà∞ÊâÄÊúâËæìÂÖ•‰∏äÔºåÂàôÂΩí‰∏ÄÂåñËøáÁ®ãÁöÑËæìÂá∫‰øùÊåÅ‰∏çÂèò„ÄÇËøôÊÑèÂë≥ÁùÄÂ∞ÜÊâÄÊúâËæìÂÖ•Âπ≥Áßª‰∏Ä‰∏™Â∏∏Êï∞Èáè‰∏ç‰ºöÂΩ±ÂìçÂΩí‰∏ÄÂåñËæìÂá∫„ÄÇËøô‰∏™ÂèëÁé∞‰ΩøÂæóÂèØ‰ª•ÂéªÊéâËÆ°ÁÆóÂùáÂÄºÁöÑÂºÄÈîÄÔºàÂè™ÈúÄËÆ°ÁÆóÊ†áÂáÜÂ∑ÆÔºâÔºå‰ªéËÄå‰ΩøRMSNormÊõ¥ÁÆÄÂçï„ÄÅÊõ¥È´òÊïà„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qblXBo8SCcxzPWePhFVlYg.png)\n\n## Mistral AI vs. Meta vs. Google: Gemma 7B„ÄÅLlama 3 7B Âíå Mistral 7B ÁöÑÊØîËæÉ\n\nÂú®Êú¨ËäÇ‰∏≠ÔºåÊàë‰ª¨Â∞Ü 3 ‰∏™ LLM‚Äî‚ÄîGemma 7B„ÄÅMistral 7B Âíå Llama 3 7B‚Äî‚ÄîËøõË°åÊµãËØï„ÄÇÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™Âêç‰∏∫ SQuAD ÁöÑÈóÆÁ≠îÊï∞ÊçÆÈõÜÔºåÈÅµÂæ™ CC BY-SA 4.0 ËÆ∏ÂèØËØÅÔºàÂèØ‰ª•Âú® [ËøôÈáå](https://huggingface.co/datasets/rajpurkar/squad) ÊâæÂà∞Ôºâ„ÄÇËØ•Êï∞ÊçÆÈõÜÊòØ‰∏Ä‰∏™ÈòÖËØªÁêÜËß£Êï∞ÊçÆÈõÜÔºåÂåÖÂê´ÂÖ≥‰∫é‰∏ÄÁªÑÁª¥Âü∫ÁôæÁßëÊñáÁ´†ÁöÑÈóÆÈ¢ò„ÄÇÊ†πÊçÆ‰∏ä‰∏ãÊñáÔºåÊ®°ÂûãÂ∫îËØ•ËÉΩÂ§üÊ£ÄÁ¥¢Âà∞ÈóÆÈ¢òÁöÑÊ≠£Á°ÆÁ≠îÊ°à„ÄÇÂØπ‰∫éÊàë‰ª¨ÁöÑÁî®‰æãÔºå3 ‰∏™ÊúÄÈáçË¶ÅÁöÑÂ≠óÊÆµÊòØÔºö\n\n* `question` - Ê®°ÂûãÂ∫îËØ•ÂõûÁ≠îÁöÑÈóÆÈ¢ò„ÄÇ\n* `context` - Ê®°ÂûãÈúÄË¶Å‰ªé‰∏≠ÊèêÂèñÁ≠îÊ°àÁöÑËÉåÊôØ‰ø°ÊÅØ„ÄÇ\n* `answers` - ÈóÆÈ¢òÁöÑÊñáÊú¨Á≠îÊ°à„ÄÇ\n\nËØÑ‰º∞ËøáÁ®ãÂ∞ÜÂåÖÊã¨‰∏§‰∏™ÂÆöÈáèÊåáÊ†áÔºö\n\n* `words per second` - ËØÑ‰º∞Êé®ÁêÜÈÄüÂ∫¶„ÄÇ\n* `words` - ËØÑ‰º∞Á≠îÊ°àÁöÑÈïøÂ∫¶„ÄÇ\n\n‰∏∫‰∫ÜËØÑ‰º∞Ê®°ÂûãÂú®Êàë‰ª¨Áî®‰æã‰∏≠ÁöÑÂáÜÁ°ÆÊÄßÔºåÊàë‰ª¨‰ΩøÁî® RAQ \\[1]„ÄÇRAQ ‰ΩøÁî®‰∏Ä‰∏™Áã¨Á´ãÁöÑ LLM ÂØπÊâÄÊúâ LLM ÁöÑÁ≠îÊ°àËøõË°åÊéíÂêçÔºåÂü∫‰∫éÂÆÉ‰ª¨‰∏éÁúüÂÆûÁ≠îÊ°àÁöÑÊé•ËøëÁ®ãÂ∫¶„ÄÇ\n\nÊàë‰ª¨È¶ñÂÖà‰∏ãËΩΩ‰ª• `.gguf` Ê†ºÂºèÊèê‰æõÁöÑÊ®°ÂûãÔºå‰ª•‰æøÂú® CPU ‰∏äËøêË°åÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨ÊîæÂú® `model/` Êñá‰ª∂Â§π‰∏ã„ÄÇ\n\nÊàë‰ª¨‰ΩøÁî®ÊØè‰∏™Ê®°ÂûãÁöÑÊåá‰ª§ÁâàÊú¨ÔºåÂπ∂ËøõË°å‰∫Ü 4 ‰ΩçÈáèÂåñÔºö\n\n* `mistral-7b-instruct-v0.1.Q4_K_M.gguf` Êù•Ëá™ [https://huggingface.co/TheBloke/Mistral\\-7B\\-Instruct\\-v0\\.1\\-GGUF/tree/main](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/tree/main)\n* `Meta-Llama-3-8B-Instruct-Q4_K_M.gguf` Êù•Ëá™ [https://huggingface.co/NousResearch/Meta\\-Llama\\-3\\-8B\\-Instruct\\-GGUF](https://huggingface.co/NousResearch/Meta-Llama-3-8B-Instruct-GGUF)\n* `gemma-7b-it-Q4_K_M.gguf` Êù•Ëá™ [https://huggingface.co/rahuldshetty/gemma\\-7b\\-it\\-gguf\\-quantized/tree/main](https://huggingface.co/rahuldshetty/gemma-7b-it-gguf-quantized/tree/main)\n\n‰πãÂêéÔºåÊàë‰ª¨ÂØºÂÖ•ÊâÄÊúâÂ∫ìÂíåÊé•Êî∂Êàë‰ª¨ÊÉ≥Ë¶Å‰ΩøÁî®ÁöÑÊ®°Âûã‰Ωú‰∏∫ÂèÇÊï∞ÁöÑÁîüÊàêÂô®„ÄÇ\n\n```python\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scikit_posthocs as sp\nimport pandas as pd\nimport utils\n\nfrom dotenv import load_dotenv\nfrom datasets import load_dataset\nfrom generator.generator import Generator\n\nllama = Generator(model='llama')\nmistral = Generator(model='mistral')\ngemma = Generator(model='gemma')\nload_dotenv('env/var.env')\n```\n\nËØ•Á±ªË¥üË¥£ÂØºÂÖ•Âú® `config.yaml` Êñá‰ª∂‰∏≠ÂÆö‰πâÁöÑÊ®°ÂûãÂèÇÊï∞ÔºåÂÖ∑Êúâ‰ª•‰∏ãÁâπÂæÅÔºö`context_length` ‰∏∫ 1024Ôºå`temperature` ‰∏∫ 0.7Ôºå`max_tokens` ‰∏∫ 2000\\„ÄÇ\n\n```python\ngenerator:\n  llama:\n    llm_path: \"model/Meta-llama-3-8B-Instruct-Q4_K_M.gguf\"\n  mistral:\n    llm_path: \"model/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n  gemma:\n    llm_path: \"model/gemma-7b-it-Q4_K_M.gguf\"\n  context_length: 1024\n  temperature: 0.7\n  max_tokens: 2000\n```\n\nÂÆÉËøòÂàõÂª∫‰∫ÜÊèêÁ§∫Ê®°Êùø„ÄÇËØ•Ê®°ÊùøÊúâÂä©‰∫éÂú®Â∞ÜÊü•ËØ¢Âíå‰∏ä‰∏ãÊñá‰º†ÈÄíÁªô LLM ‰ª•Ëé∑ÂèñÂìçÂ∫î‰πãÂâçÊ†ºÂºèÂåñÂÆÉ‰ª¨„ÄÇ\n\n```python\nfrom langchain import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.llms import LlamaCpp\n\nfrom base.config import Config\nclass Generator(Config):\n    \"\"\"Generator, aka LLM, to provide an answer based on some question and context\"\"\"\n    def __init__(self, model) -> None:\n        super().__init__()\n    # template\n        self.template = \"\"\"\n            Use the following pieces of context to answer the question at the end.\n            {context}\n            Question: {question}\n            Answer:\n        \"\"\"\n   # load llm from local file\n        self.llm = LlamaCpp(\n            model_path=f\"{self.parent_path}/{self.config['generator'][model]['llm_path']}\",\n            n_ctx=self.config[\"generator\"][\"context_length\"],\n            temperature=self.config[\"generator\"][\"temperature\"],\n        )\n        # create prompt template\n        self.prompt = PromptTemplate(\n            template=self.template, input_variables=[\"context\", \"question\"]\n        )\n    def get_answer(self, context: str, question: str) -> str:\n        \"\"\"\n        Get the answer from llm based on context and user's question\n        Args:\n            context: most similar document retrieved\n            question: user's question\n        Returns:\n            llm answer\n        \"\"\"\n        query_llm = LLMChain(\n            llm=self.llm,\n            prompt=self.prompt,\n            llm_kwargs={\"max_tokens\": self.config[\"generator\"][\"max_tokens\"]},\n        )\n        return query_llm.run({\"context\": context, \"question\": question})\n```\n\nÂä†ËΩΩ LLM ÂêéÔºåÊàë‰ª¨‰ªé HuggingFace Ëé∑Âèñ SQuAD Êï∞ÊçÆÈõÜÂπ∂ÂØπÂÖ∂ËøõË°åÊ¥óÁâåÔºå‰ª•Á°Æ‰øùÈóÆÈ¢ò‰∏ªÈ¢òÁöÑÂ§öÊ†∑ÊÄß„ÄÇ\n\n```python\nsquad = load_dataset(\"squad\", split=\"train\")\nsquad = squad.shuffle()\n```\n\nÁé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•Âæ™ÁéØÂ§ÑÁêÜ 60 ‰∏™ÈóÆÈ¢òÂíå‰∏ä‰∏ãÊñáÔºåÂπ∂ËÆ∞ÂΩï‰∏äËø∞ÊåáÊ†á„ÄÇ\n\n```python\nfor i in range(60):\n    context = squad[i]['context']\n    query = squad[i]['question']\n    answer = squad[i]['answers']['text'][0]\n\n    # Llama\n    answer_llama, words_per_second, words = utils.get_llm_response(llama, context, query)\n    llama_metrics[\"words_per_second\"].append(words_per_second)\n    llama_metrics[\"words\"].append(words)\n    # mistral\n    answer_mistral, words_per_second, words = utils.get_llm_response(mistral, context, query)\n    mistral_metrics[\"words_per_second\"].append(words_per_second)\n    mistral_metrics[\"words\"].append(words)\n    # gemma\n    answer_gemma, words_per_second, words = utils.get_llm_response(gemma, context, query)\n    gemma_metrics[\"words_per_second\"].append(words_per_second)\n    gemma_metrics[\"words\"].append(words)\n  \n    # GPT-3.5 rank\n    llm_answers_dict = {'llama': answer_llama, 'mistral': answer_mistral, 'gemma': answer_gemma}\n    rank = utils.get_gpt_rank(answer, llm_answers_dict, os.getenv(\"OPENAI_API_KEY\"))\n    llama_metrics[\"rank\"].append(rank.index('1')+1)\n    mistral_metrics[\"rank\"].append(rank.index('2')+1)\n    gemma_metrics[\"rank\"].append(rank.index('3')+1)\n```\n\nÂáΩÊï∞ `get_llm_response` Ë¥üË¥£Êé•Êî∂Âä†ËΩΩÁöÑ LLM„ÄÅ‰∏ä‰∏ãÊñáÂíåÈóÆÈ¢òÔºåÂπ∂ËøîÂõû LLM Á≠îÊ°à‰ª•ÂèäÂÆöÈáèÊåáÊ†á„ÄÇ\n\n```python\ndef get_llm_response(model: Generator, context: str, query: str) -> Tuple[str, int, int]:\n    \"\"\"\n    Generates an answer from a given LLM based on context and query\n    returns the answer and the number of words per second and the total number of words\n    Args:\n        model: LLM\n        context: context data\n        query: question\n    Returns:\n        answer, words_per_second, words\n    \"\"\"\n    init_time = time.time()\n    answer_llm = model.get_answer(context, query)\n    total_time = time.time()-init_time\n    words_per_second = len(re.sub(\"[^a-zA-Z']+\", ' ', answer_llm).split())/total_time\n    words = len(re.sub(\"[^a-zA-Z']+\", ' ', answer_llm).split())\n    return answer_llm, words_per_second, words\n```\n\nÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÔºåLlama 3 ÁöÑÈÄüÂ∫¶Âø´‰∫é Mistral Âíå GemmaÔºåÂπ≥ÂùáÊØèÁßíÁîüÊàêÁ∫¶ 0.7 ‰∏™ÂçïËØçÔºåËÄå Mistral Á∫¶‰∏∫ 0.26ÔºåGemma Á∫¶‰∏∫ 0.4 ‰∏™ÂçïËØç„ÄÇÂú®Á≠îÊ°àÈïøÂ∫¶ÊñπÈù¢ÔºåLlama 3 ‰πüÁîüÊàêÊØî Mistral Âíå Gemma Êõ¥ÈïøÁöÑÁ≠îÊ°àÔºåÂπ≥ÂùáÁ≠îÊ°àÈïøÂ∫¶‰∏∫ 148 ‰∏™ÂçïËØçÔºåËÄå Mistral ‰∏∫ 20 ‰∏™ÂçïËØçÔºåGemma ‰∏∫ 50 ‰∏™ÂçïËØç„ÄÇÊúÄÂêéÔºåÊ†πÊçÆ RAQÔºåMistral ÁöÑÂπ≥ÂùáÊéíÂêçÊúÄÂ•ΩÔºåÁ∫¶‰∏∫ 1.81ÔºåÂÖ∂Ê¨°ÊòØ GemmaÔºåÂπ≥Âùá‰∏∫ 2.05ÔºåËÄå Llama 3 ÁöÑË°®Áé∞ËæÉÂ∑ÆÔºåÂπ≥ÂùáÊéíÂêçÁ∫¶‰∏∫ 2.1\\„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GVeFQbMZZ5oUScVEHQPu8A.png)\n\nRAQ Ê°ÜÊû∂ËøòÂåÖÊã¨ÁªüËÆ°Ê£ÄÈ™åÔºå‰ª•‰∫ÜËß£ËßÇÂØüÂà∞ÁöÑÂ∑ÆÂºÇÊòØÂê¶ÊòæËëó„ÄÇË°® 1 ÊòæÁ§∫‰∫Ü Dunn ‰∫ãÂêéÊ£ÄÈ™åÁöÑÁªìÊûúÔºåÊØîËæÉ‰∏çÂêåËØ≠Ë®ÄÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇÊØè‰∏™ÂçïÂÖÉÊ†ºË°®Á§∫Áõ∏Â∫îÊ®°Âûã‰πãÈó¥ÁöÑÊÄßËÉΩÂ∑ÆÂºÇÂú® 5% ÊòæËëóÊÄßÊ∞¥Âπ≥‰∏ãÊòØÂê¶ÂÖ∑ÊúâÁªüËÆ°ÊòæËëóÊÄß„ÄÇ‚ÄúÊòæËëó‚ÄùË°®Á§∫ÁªüËÆ°‰∏äÊòæËëóÁöÑÂ∑ÆÂºÇÔºàp ÂÄº ‚â§ 0.05ÔºâÔºåËÄå‚ÄúÊó†ÊòæËëóÊÄß‚ÄùË°®Á§∫Ê≤°ÊúâÁªüËÆ°‰∏äÊòæËëóÁöÑÂ∑ÆÂºÇÔºàp ÂÄº > 0.05Ôºâ„ÄÇÂØπ‰∫éÊâÄÈÄâÁöÑÊòæËëóÊÄßÊ∞¥Âπ≥ÔºåDunn Ê£ÄÈ™åÁªìÊûúË°®ÊòéÊ®°Âûã‰πãÈó¥ÁöÑÊÄßËÉΩÂ∑ÆÂºÇ‰∏çÊòæËëó„ÄÇ\n\n```python\np_values = sp.posthoc_dunn([Llama_metrics['rank'], mistral_metrics['rank'], gemma_metrics['rank']], p_adjust='holm')\np_values > 0.05\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ftCaagMKAm5RzeATYm_7Ug.png)\n\nÂÆöÊÄßËØÑ‰º∞‰∏Ä‰∫õÁ§∫‰æãÂßãÁªàÂæàÈáçË¶Å„ÄÇ‰ª•‰∏ãÊòØ 3 ‰∏™Ê®°ÂûãÂØπÈóÆÈ¢ò *‚ÄòPower House Day Âú®Á∫ΩÈªëÊñáÁöÑÂì™‰∏ÄÂ§©Â∫ÜÁ•ùÔºü‚Äô* ÁöÑÂõûÁ≠îÔºåÂü∫‰∫é‰ª•‰∏ã‰∏ä‰∏ãÊñáÔºö\n\n> ***Context:***‚Äò‰∏Ä‰∏™Â§ö‰∏ñÁ∫™‰ª•Êù•ÔºåÁ∫ΩÈªëÊñáÂ∏ÇÊ∞ë‰∏ÄÁõ¥‰∏éÂ∏∏ËßÑËã±ÂõΩÂÜõÈòü‰∏ÄËµ∑Âú®ÊÆñÊ∞ëÊ∞ëÂÖµ‰∏≠‰ΩúÊàòÔºåÂ∞±ÂÉèÂú®Ê≥ïÂõΩÂíåÂç∞Á¨¨ÂÆâÊàò‰∫â‰∏≠‰∏ÄÊ†∑„ÄÇÈöèÁùÄÁæéÂõΩÈù©ÂëΩÁöÑ‰∏¥ËøëÔºåÂ§ßÂç´¬∑‰ºçÊñØÁâπÂ∞ÜÂÜõÂíåÂÖ∂‰ªñÊúâÂΩ±ÂìçÂäõÁöÑÂ±ÖÊ∞ëÂ∏åÊúõ‰∏éËã±ÂõΩÊîøÂ∫úÁöÑÂÜ≤Á™ÅËÉΩÂ§üÂú®‰∏çÂèçÂèõÁöÑÊÉÖÂÜµ‰∏ãËß£ÂÜ≥„ÄÇÂú® 1775 Âπ¥ 4 Êúà 23 Êó•ÔºåËøô‰∏ÄÂ§©Âú®Á∫ΩÈªëÊñá‰ªçË¢´Â∫ÜÁ•ù‰∏∫ÁÅ´ËçØÂ±ãÊó•ÔºåÁ∫ΩÈªëÊñáÁöÑÁ¨¨‰∫åÂÖ¨Âè∏ÔºåÂ∑ûÈïøÁöÑÊ≠•ÂÖµÂç´ÈòüÔºåÂèÇ‰∏é‰∫Ü‰∏éÁªüÊ≤ªËã±ÂõΩËÆÆ‰ºöÁöÑÊñó‰∫â„ÄÇÂú®Êú¨Â∞ºËø™ÂÖãÁâπ¬∑ÈòøËØ∫Âæ∑ËàπÈïøÁöÑÊåáÊå•‰∏ãÔºå‰ªñ‰ª¨ÈóØÂÖ•ÁÅ´ËçØÂ∫ì‰ª•Ê≠¶Ë£ÖËá™Â∑±ÔºåÂπ∂ÂºÄÂßã‰∫Ü‰∏∫Êúü‰∏âÂ§©ÁöÑÊ∏∏Ë°åÔºåÂâçÂæÄÈ©¨Ëê®ËØ∏Â°ûÂ∑ûÁöÑÂâëÊ°•„ÄÇÂÖ∂‰ªñÁ∫ΩÈªëÊñáÊ∞ëÂÖµÊàêÂëòÂú®Âú∫Êä§ÈÄÅ‰πîÊ≤ª¬∑ÂçéÁõõÈ°øÔºå‰ªé‰ªñÂú®Á∫ΩÈªëÊñáÁöÑËøáÂ§ú‰ΩèÂÆøÂâçÂæÄÂâëÊ°•„ÄÇÊù•Ëá™ÂèåÊñπÁöÑÂΩì‰ª£Êä•ÂëäÈÉΩÊèêÂà∞‰∫ÜÁ∫ΩÈªëÊñáÂøóÊÑøËÄÖÁöÑ‰∏ì‰∏öÂÜõ‰∫ãÈ£éËåÉÔºåÂåÖÊã¨Âà∂Êúç„ÄÇ‚Äô\n\nÊâÄÊúâ 3 ‰∏™Ê®°ÂûãÈÉΩÁªôÂá∫‰∫ÜÊ≠£Á°ÆÁ≠îÊ°à„ÄÇËôΩÁÑ∂ Llama 3 Âíå Gemma Êèê‰æõ‰∫ÜÊõ¥ÂÆåÊï¥ÁöÑÁ≠îÊ°àÔºå‰ΩÜ Mistral ÂàôÊõ¥Âä†ÁÆÄÊ¥Å„ÄÇ\n\n> ***Llama 3 answer:***‚ÄòÁ∫ΩÈªëÊñáÁöÑÁÅ´ËçØÂ±ãÊó•Â∫ÜÁ•ù‰∫é 4 Êúà 23 Êó•„ÄÇ‚Äô\n\n> ***Gemma answer:***‚ÄòÂΩìÁÑ∂ÔºÅÊñáÊú¨‰∏≠ËØ¥Êòé‰∫ÜÁÅ´ËçØÂ±ãÊó•Â∫ÜÁ•ùÁöÑÊó•ÊúüÔºöÁÅ´ËçØÂ±ãÊó•Âú®Á∫ΩÈªëÊñáÂ∫ÜÁ•ù‰∫é **4 Êúà 23 Êó•**„ÄÇ‚Äô\n\n> ***Mistral answer:***‚Äô23 April‚Äô\n\n## ÁªìËÆ∫\n\nÂú®ËÆæÂ§á‰∏äÁöÑÊ®°Âûã‰∏∫ÊèêÂçáÁî®Êà∑‰ΩìÈ™åÊèê‰æõ‰∫ÜÊûÅÂ§ßÁöÑÊú∫‰ºöÔºå‰ΩøÂº∫Â§ßÁöÑ LLM ËÉΩÂ§üÂú®ËÆ°ÁÆóËµÑÊ∫êËæÉ‰ΩéÁöÑËÆæÂ§á‰∏ä‰ΩøÁî®„ÄÇËãπÊûúÂíåË∞∑Ê≠åÈÉΩÂú®ÁßØÊûÅÂºÄÂèëÊõ¥Â∞è„ÄÅÊõ¥È´òÊïàÁöÑÊ®°ÂûãÔºå‰ª•Êª°Ë∂≥Ëøô‰∏ÄÈúÄÊ±ÇÔºå‰ΩøÊõ¥Â§ö‰∫∫ËÉΩÂ§üÂú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÂèóÁõä‰∫éÂÖàËøõÁöÑ‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫ÜË∞∑Ê≠åÂºÄÂèëÁöÑÂºÄÊ∫ê LLM GemmaÔºåÂÆÉÂú®‰º†ÁªüÁöÑ Transformer Êû∂ÊûÑ‰∏≠ÂºïÂÖ•‰∫ÜÂõõ‰∏™Êñ∞ÁâπÊÄßÔºö2B ÁâàÊú¨‰∏≠ÁöÑÂ§öÊü•ËØ¢Ê≥®ÊÑèÂäõ„ÄÅÁî®‰∫é‰ΩçÁΩÆÁºñÁ†ÅÁöÑ RoPE ÂµåÂÖ•„ÄÅ‰Ωú‰∏∫ÊøÄÊ¥ªÂáΩÊï∞ÁöÑ GeGLUÔºå‰ª•ÂèäËæìÂÖ•ÂΩí‰∏ÄÂåñ„ÄÇ\n\nÊàë‰ª¨ËøòÂ∞Ü Gemma ÁöÑÊÄßËÉΩ‰∏é Llama 3 Âíå Mistral Âú®ÈòÖËØªÁêÜËß£Êï∞ÊçÆÈõÜ‰∏äÁöÑË°®Áé∞ËøõË°å‰∫ÜÊØîËæÉ„ÄÇÊàë‰ª¨ËßÇÂØüÂà∞ÔºåGemma ÊØèÁßíÁîüÊàêÁöÑÂçïËØçÊï∞Êõ¥Â§öÔºåÂÜôÂá∫ÁöÑÁ≠îÊ°àÊØî Mistral Êõ¥ÈïøÔºå‰ΩÜÂú®Ëøô‰∫õÊåáÊ†á‰∏äÂπ∂Êú™Ë∂ÖËøá Llama 3„ÄÇ‰ΩøÁî® RAQ Ê°ÜÊû∂ÔºåÊàë‰ª¨ËØÑ‰º∞‰∫ÜËøô‰∏âÁßçÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂ∞ΩÁÆ°Êï∞ÊçÆË°®Êòé Mistral ÁöÑÁªìÊûúÊõ¥‰Ω≥ÔºåÂÖ∂Ê¨°ÊòØ GemmaÔºå‰ΩÜÂ∑ÆÂºÇÂπ∂‰∏çÂÖ∑ÊúâÁªüËÆ°Â≠¶ÊÑè‰πâ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÂèØ‰ª•ËØ¥Ëøô‰∏âÁßçÊ®°ÂûãÂú®Â∫îÁî®‰∫éÊàë‰ª¨ÁöÑÈòÖËØªÁêÜËß£Áî®‰æãÊó∂Ë°®Áé∞Áõ∏‰ºº„ÄÇ\n\n## ÂèÇËÄÉÊñáÁåÆ\n\n\\[1] Lu√≠s Roque, Rafael Guedes. ‰ªéÁ†îÁ©∂Âà∞Áîü‰∫ßÔºöÁõ∏ÂØπÁ≠îÊ°àË¥®ÈáèÔºàRAQÔºâ‰∏éNVIDIA NIM. [https://readmedium.com/research\\-to\\-production\\-relative\\-answer\\-quality\\-raq\\-and\\-nvidia\\-nim\\-15ce0c45b3b6](https://readmedium.com/research-to-production-relative-answer-quality-raq-and-nvidia-nim-15ce0c45b3b6), 2024\\.\n\n\\[2] Gemma Team, Google DeepMind. GemmaÔºöÂü∫‰∫éGeminiÁ†îÁ©∂ÂíåÊäÄÊúØÁöÑÂºÄÊîæÊ®°Âûã, 2023\\.\n\n\\[3] Gemini Team. GeminiÔºö‰∏ÄÁ≥ªÂàóÈ´òËÉΩÂäõÁöÑÂ§öÊ®°ÊÄÅÊ®°Âûã, 2023\\.\n\n\\[4] Noam Shazeer. Âø´ÈÄüTransformerËß£Á†ÅÔºö‰∏ÄÂè™ÂÜôÂ§¥Â∞±Ë∂≥Â§ü‰∫Ü. arXiv:1911\\.02150, 2019\\.\n\n\\[5] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Ê≥®ÊÑèÂäõÂç≥‰∏ÄÂàá. arXiv:1706\\.03762, 2017\\.\n\n\\[6] Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu. RoFormerÔºöÂ∏¶ÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÁöÑÂ¢ûÂº∫ÂûãTransformer. arXiv:2104\\.09864, 2021\\.\n\n\\[7] Noam Shazeer. GLUÂèò‰ΩìÊîπÂñÑTransformer. arXiv:2002\\.05202, 2020\\.\n\n\\[8] Dan Hendrycks, Kevin Gimpel. È´òÊñØËØØÂ∑ÆÁ∫øÊÄßÂçïÂÖÉÔºàGELUsÔºâ. arXiv:1606\\.08415, 2016\\.\n\n\\[9] Biao Zhang, Rico Sennrich. ÂùáÊñπÊ†πÂ±ÇÂΩí‰∏ÄÂåñ. arXiv:1910\\.07467, 2019\\.\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/generating-structured-data-from-an-image-with-gpt-vision-and-langchain-34aaf3dcb215","frontmatter":{"title":"‰ΩøÁî® GPT Vision Âíå Langchain ‰ªéÂõæÂÉèÁîüÊàêÁªìÊûÑÂåñÊï∞ÊçÆ","meta_title":"‰ΩøÁî® GPT Vision Âíå Langchain ‰ªéÂõæÂÉèÁîüÊàêÁªìÊûÑÂåñÊï∞ÊçÆ","description":"Âú®ÂΩì‰ªä‰∏ñÁïåÔºåËßÜËßâÊï∞ÊçÆÈùûÂ∏∏‰∏∞ÂØåÔºå‰ªéÂõæÂÉè‰∏≠ÊèêÂèñÊúâÊÑè‰πâ‰ø°ÊÅØÁöÑËÉΩÂäõÂèòÂæóË∂äÊù•Ë∂äÈáçË¶Å‚Ä¶‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FPRRg85jYb7MrzXEpNWbmw.jpeg","categories":["Programming","Computer Vision","Natural Language Processing"],"author":"Rifx.Online","tags":["Langchain","GPT","vision","LLMs","structured"],"draft":false,"slug":"blog/generating-structured-data-from-an-image-with-gpt-vision-and-langchain-34aaf3dcb215"},"content":"\n\n\n\n\nÂú®ÂΩì‰ªäËøô‰∏™ËßÜËßâÊï∞ÊçÆ‰∏∞ÂØåÁöÑ‰∏ñÁïå‰∏≠Ôºå‰ªéÂõæÂÉè‰∏≠ÊèêÂèñÊúâÊÑè‰πâ‰ø°ÊÅØÁöÑËÉΩÂäõÂèòÂæóË∂äÊù•Ë∂äÈáçË¶Å„ÄÇLangchainÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÊûÑÂª∫Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ∫îÁî®Á®ãÂ∫èÔºåÊèê‰æõ‰∫Ü‰∏ÄÂ•óÂ§öÂäüËÉΩÁöÑÂ∑•ÂÖ∑Êù•Â∫îÂØπËøô‰∏ÄÊåëÊàò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Â¶Ç‰Ωï‰ΩøÁî®Langchain‰ªéÂõæÂÉè‰∏≠ÊèêÂèñÁªìÊûÑÂåñ‰ø°ÊÅØÔºå‰æãÂ¶ÇËÆ°ÁÆó‰∫∫Êï∞ÂíåÂàóÂá∫‰∏ªË¶ÅÁâ©‰Ωì„ÄÇ\n\nÂú®Ê∑±ÂÖ•‰ª£Á†Å‰πãÂâçÔºåËÆ©Êàë‰ª¨ÂÖà‰∫ÜËß£‰∏Ä‰∏ã‰ªªÂä°ÁöÑËÉåÊôØ„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ã‰Ω†Êúâ‰∏ÄÂº†Âú∫ÊôØÁöÑÂõæÂÉèÔºåÊØîÂ¶ÇÂüéÂ∏ÇË°óÈÅì„ÄÇ‰Ω†ÁöÑÁõÆÊ†áÊòØ‰ªéËøôÂº†ÂõæÂÉè‰∏≠ÊèêÂèñÊúâ‰ª∑ÂÄºÁöÑ‰ø°ÊÅØÔºåÂåÖÊã¨Âú®Âú∫ÁöÑ‰∫∫Êï∞ÂíåÂú∫ÊôØ‰∏≠ÁöÑ‰∏ªË¶ÅÁâ©‰ΩìÂàóË°®„ÄÇ\n\n## ÂÖ≥‰∫é Langchain\n\nLangchain ÊòØ‰∏Ä‰∏™ÁªºÂêàÊ°ÜÊû∂ÔºåÂÖÅËÆ∏ÂºÄÂèëËÄÖÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÂº∫Â§ßÂäüËÉΩÊûÑÂª∫Â§çÊùÇÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇÂÆÉÊèê‰æõ‰∫ÜÊ®°ÂùóÂåñÂíåÂèØÊâ©Â±ïÁöÑÊû∂ÊûÑÔºå‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üÂàõÂª∫ÈíàÂØπÁâπÂÆöÈúÄÊ±ÇÁöÑËá™ÂÆö‰πâÁÆ°ÈÅì„ÄÅ‰ª£ÁêÜÂíåÂ∑•‰ΩúÊµÅ„ÄÇ\n\nLangchain ÁÆÄÂåñ‰∫Ü LLM ÁöÑÈõÜÊàêÔºåÊèê‰æõ‰∫ÜÂ§ÑÁêÜÂêÑÁßçÊï∞ÊçÆÊ∫êÔºàÂåÖÊã¨ÊñáÊú¨„ÄÅÂõæÂÉèÂíåÁªìÊûÑÂåñÊï∞ÊçÆÔºâÁöÑÊäΩË±°ÂíåÂ∑•ÂÖ∑„ÄÇÂÆÉÊîØÊåÅÊù•Ëá™‰∏çÂêåÊèê‰æõÂïÜÁöÑÂπøÊ≥õ LLMÔºå‰æãÂ¶Ç OpenAI Âíå AnthropicÔºå‰ΩøÂæóÂú®Âçï‰∏™Â∫îÁî®Á®ãÂ∫è‰∏≠ËΩªÊùæÂàáÊç¢Ê®°ÂûãÊàñÁªÑÂêàÂ§ö‰∏™Ê®°ÂûãÂèòÂæóÁÆÄÂçï„ÄÇ\n\n## ÂáÜÂ§áÁéØÂ¢ÉÂπ∂ËÆæÁΩÆ OpenAI API ÂØÜÈí•\n\nË¶ÅË∑üÈöèÊú¨ÊïôÁ®ãÔºåÊÇ®ÈúÄË¶ÅÂÆâË£Ö Langchain„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî® pip ÂÆâË£ÖÂÆÉÔºö\n\n```python\npip install langchain langchain_openai\n```\nË¶ÅÂú® Langchain ‰∏≠‰ΩøÁî® OpenAI ËØ≠Ë®ÄÊ®°ÂûãÔºåÊÇ®ÈúÄË¶Å‰ªé OpenAI Ëé∑Âèñ‰∏Ä‰∏™ API ÂØÜÈí•„ÄÇÂ¶ÇÊûúÊÇ®ËøòÊ≤°Êúâ API ÂØÜÈí•ÔºåÂèØ‰ª•Âú® OpenAI ÁΩëÁ´ô‰∏äÊ≥®ÂÜå‰∏Ä‰∏™ (<https://openai.com/api/>)„ÄÇ\n\n‰∏ÄÊó¶ÊÇ®Êã•Êúâ‰∫Ü API ÂØÜÈí•ÔºåÂèØ‰ª•Â∞ÜÂÖ∂ËÆæÁΩÆ‰∏∫Á≥ªÁªü‰∏≠ÁöÑÁéØÂ¢ÉÂèòÈáèÔºåÊàñËÄÖÁõ¥Êé•Âú®‰ª£Á†Å‰∏≠Êèê‰æõ„ÄÇ‰ª•‰∏ãÊòØÂ¶Ç‰ΩïÂ∞Ü API ÂØÜÈí•ËÆæÁΩÆ‰∏∫ÁéØÂ¢ÉÂèòÈáèÁöÑÁ§∫‰æãÔºö\n\n```python\nexport OPENAI_API_KEY=\"your_openai_api_key_here\"\n```\nÊàñËÄÖÔºåÊÇ®ÂèØ‰ª•Áõ¥Êé•Âú® Python ‰ª£Á†Å‰∏≠Êèê‰æõ API ÂØÜÈí•Ôºö\n\n```python\nimport os\nimport langchain\nos.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\"\n```\nÂú®ËÆæÁΩÆÂ•Ω API ÂØÜÈí•ÂêéÔºåLangchain Â∞ÜËÉΩÂ§ü‰∏é OpenAI API ËøõË°åË∫´‰ªΩÈ™åËØÅÂπ∂‰ΩøÁî®‰ªñ‰ª¨ÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n\n## Âä†ËΩΩÂíåÁºñÁ†ÅÂõæÂÉè\n\nÂú®Êàë‰ª¨‰ΩøÁî® Langchain Â§ÑÁêÜÂõæÂÉè‰πãÂâçÔºåÊàë‰ª¨ÈúÄË¶Å‰ªéÊñá‰ª∂‰∏≠Âä†ËΩΩÂõæÂÉèÊï∞ÊçÆÔºåÂπ∂Â∞ÜÂÖ∂ÁºñÁ†Å‰∏∫ÂèØ‰ª•‰º†ÈÄíÁªôËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†ºÂºè„ÄÇ‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÂáΩÊï∞ `load_image`ÔºåËØ•ÂáΩÊï∞Êé•Âèó‰∏Ä‰∏™ÂåÖÂê´ `image_path` ÈîÆÁöÑÂ≠óÂÖ∏ÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™Êñ∞ÁöÑÂ≠óÂÖ∏ÔºåÂÖ∂‰∏≠ `image` ÈîÆÂåÖÂê´ÁºñÁ†Å‰∏∫ base64 Â≠óÁ¨¶‰∏≤ÁöÑÂõæÂÉèÊï∞ÊçÆ„ÄÇ\n\n```python\ndef load_image(inputs: dict) -> dict:\n    \"\"\"Load image from file and encode it as base64.\"\"\"\n    image_path = inputs[\"image_path\"]\n  \n    def encode_image(image_path):\n        with open(image_path, \"rb\") as image_file:\n            return base64.b64encode(image_file.read()).decode('utf-8')\n    image_base64 = encode_image(image_path)\n    return {\"image\": image_base64}\n```\n`load_image` ÂáΩÊï∞È¶ñÂÖà‰ªéËæìÂÖ•Â≠óÂÖ∏‰∏≠ÊèêÂèñ `image_path`„ÄÇÁÑ∂ÂêéÔºåÂÆÉÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÂµåÂ•óÂáΩÊï∞ `encode_image`ÔºåËØ•ÂáΩÊï∞‰ª•‰∫åËøõÂà∂Ê®°ÂºèÊâìÂºÄÂõæÂÉèÊñá‰ª∂ÔºåËØªÂèñÂÖ∂ÂÜÖÂÆπÔºåÂπ∂‰ΩøÁî® Python Ê†áÂáÜÂ∫ì‰∏≠ÁöÑ `base64.b64encode` ÂáΩÊï∞Â∞ÜÂÖ∂ÁºñÁ†Å‰∏∫ base64 Â≠óÁ¨¶‰∏≤„ÄÇ\n\n`load_image` ÂáΩÊï∞‰ΩøÁî®Êèê‰æõÁöÑ `image_path` Ë∞ÉÁî® `encode_image`ÔºåÂπ∂Â∞ÜÁªìÊûú base64 ÁºñÁ†ÅÂ≠óÁ¨¶‰∏≤Â≠òÂÇ®Âú® `image_base64` ÂèòÈáè‰∏≠„ÄÇÊúÄÂêéÔºåÂÆÉËøîÂõû‰∏Ä‰∏™Êñ∞ÁöÑÂ≠óÂÖ∏ÔºåÂÖ∂‰∏≠ `image` ÈîÆËÆæÁΩÆ‰∏∫ `image_base64`„ÄÇ\n\n‰∏∫‰∫ÜÂ∞ÜÊ≠§ÂáΩÊï∞ÈõÜÊàêÂà∞ Langchain ÊµÅÊ∞¥Á∫ø‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™ `TransformChain`ÔºåËØ•ÈìæÊé•Âèó `image_path` ‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ÁîüÊàê `image`Ôºàbase64 ÁºñÁ†ÅÂ≠óÁ¨¶‰∏≤Ôºâ‰Ωú‰∏∫ËæìÂá∫„ÄÇ\n\n```python\nload_image_chain = TransformChain(\n    input_variables=[\"image_path\"],\n    output_variables=[\"image\"],\n    transform=load_image\n)\n```\nÈÄöËøáËøôÁßçËÆæÁΩÆÔºåÊàë‰ª¨ÂèØ‰ª•ËΩªÊùæÂú∞Â∞ÜÂõæÂÉèÂä†ËΩΩÂíåÁºñÁ†Å‰Ωú‰∏∫Êõ¥Â§ß Langchain Â∑•‰ΩúÊµÅÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰ªéËÄå‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ§ÑÁêÜËßÜËßâÊï∞ÊçÆÂíåÊñáÊú¨„ÄÇ\n\n## ÂÆö‰πâËæìÂá∫ÁªìÊûÑ\n\nÂú®Êàë‰ª¨ÊèêÂèñÂõæÂÉè‰ø°ÊÅØ‰πãÂâçÔºåÈúÄË¶ÅÂÆö‰πâÊàë‰ª¨Â∏åÊúõÊé•Êî∂ÁöÑËæìÂá∫ÁªìÊûÑ„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ `ImageInformation` ÁöÑ Pydantic Ê®°ÂûãÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÂõæÂÉèÊèèËø∞ÂíåÊàë‰ª¨ÂèØËÉΩÊÉ≥Ë¶ÅÊèêÂèñÁöÑ‰ªª‰ΩïÂÖ∂‰ªñ‰ø°ÊÅØÁöÑÂ≠óÊÆµ„ÄÇ\n\n```python\nfrom langchain_core.pydantic_v1 import BaseModel, Field\n\nclass ImageInformation(BaseModel):\n \"\"\"Information about an image.\"\"\"\n image_description: str = Field(description=\"a short description of the image\")\n people_count: int = Field(description=\"number of humans on the picture\")\n main_objects: list[str] = Field(description=\"list of the main objects on the picture\")\n```\n\n## ËÆæÁΩÆÂõæÂÉèÊ®°Âûã\n\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™ÈìæÔºåÂ∞ÜÂõæÂÉèÂä†ËΩΩÂíåÁºñÁ†ÅÊ≠•È™§‰∏é LLM Ë∞ÉÁî®Ê≠•È™§ÁªìÂêàËµ∑Êù•„ÄÇÁî±‰∫é `ChatOpenAI` Ê®°ÂûãÂú®ÊàëÁöÑÁêÜËß£‰∏≠Âπ∂‰∏çÂÖ∑Â§áÂêåÊó∂Â§ÑÁêÜÊñáÊú¨ÂíåÂõæÂÉèËæìÂÖ•ÁöÑËÉΩÂäõÔºåÊàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™ÂåÖË£ÖÈìæÊù•ÂÆûÁé∞Ëøô‰∏ÄÂäüËÉΩ„ÄÇ\n\n```python\nfrom langchain.chains import TransformChain\nfrom langchain_core.messages import HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain import globals\nfrom langchain_core.runnables import chain\n\n## Set verbose\nglobals.set_debug(True)\n\n@chain\ndef image_model(inputs: dict) -> str | list[str] | dict:\n \"\"\"Invoke model with image and prompt.\"\"\"\n model = ChatOpenAI(temperature=0.5, model=\"gpt-4-vision-preview\", max_tokens=1024)\n msg = model.invoke(\n             [HumanMessage(\n             content=[\n             {\"type\": \"text\", \"text\": inputs[\"prompt\"]},\n             {\"type\": \"text\", \"text\": parser.get_format_instructions()},\n             {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{inputs['image']}\"}},\n             ])]\n             )\n return msg.content\n```\nÂú®Ëøô‰∏™‰ª£Á†ÅÁâáÊÆµ‰∏≠ÔºåÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ `image_model` ÁöÑÈìæÔºå‰ΩøÁî®Êèê‰æõÁöÑÊèêÁ§∫„ÄÅÊ†ºÂºèËØ¥ÊòéÂíåÂõæÂÉèË∞ÉÁî® `ChatOpenAI` Ê®°Âûã„ÄÇ`image_model` ÈìæÊé•Âèó‰∏Ä‰∏™ÂåÖÂê´ÊèêÁ§∫Âíå base64 ÁºñÁ†ÅÂõæÂÉèÂ≠óÁ¨¶‰∏≤ÁöÑÂ≠óÂÖ∏ `inputs`„ÄÇ\n\nÂú®ÈìæÂÜÖÈÉ®ÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ `HumanMessage` ÂØπË±°ÔºåËØ•ÂØπË±°ÁªìÂêà‰∫ÜÊèêÁ§∫ÊñáÊú¨„ÄÅÊ†ºÂºèËØ¥ÊòéÂíåÂõæÂÉè URLÔºå‰ª•Êï∞ÊçÆ URI Ê†ºÂºèÂåñÔºåÂåÖÂê´ base64 ÁºñÁ†ÅÁöÑÂõæÂÉèÊï∞ÊçÆ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨‰ΩøÁî®Ëøô‰∏™ `HumanMessage` ÂØπË±°Ë∞ÉÁî® `ChatOpenAI` Ê®°ÂûãÔºå‰ΩøÁî®‰∏ìÈó®‰∏∫Ê∂âÂèäÊñáÊú¨ÂíåÂõæÂÉèÁöÑÂ§öÊ®°ÊÄÅ‰ªªÂä°ËÆæËÆ°ÁöÑ `gpt-4-vision-preview` Ê®°Âûã„ÄÇ\n\nËØ•Ê®°ÂûãÂ§ÑÁêÜÊñáÊú¨ÊèêÁ§∫ÂíåÂõæÂÉèÔºåÂπ∂ËøîÂõûËæìÂá∫„ÄÇ\n\n## Êï¥ÂêàÊâÄÊúâÂÜÖÂÆπ\n\nÁé∞Âú®Êàë‰ª¨Â∑≤ÁªèÊã•Êúâ‰∫ÜÊâÄÊúâÂøÖË¶ÅÁöÑÁªÑ‰ª∂ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞Êù•ÂçèË∞ÉÊï¥‰∏™ËøáÁ®ãÔºö\n\n```python\nfrom langchain_core.output_parsers import JsonOutputParser\n\nparser = JsonOutputParser(pydantic_object=ImageInformation)\ndef get_image_informations(image_path: str) -> dict:\n   vision_prompt = \"\"\"\n   Given the image, provide the following information:\n   - A count of how many people are in the image\n   - A list of the main objects present in the image\n   - A description of the image\n   \"\"\"\n   vision_chain = load_image_chain | image_model | parser\n   return vision_chain.invoke({'image_path': f'{image_path}', \n                               'prompt': vision_prompt})\n```\nÂú®Ëøô‰∏™ÂáΩÊï∞‰∏≠ÔºåÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÊèêÁ§∫ÔºåË¶ÅÊ±ÇLLMÊèê‰æõÂõæÂÉè‰∏≠‰∫∫Áâ©ÁöÑÊï∞ÈáèÂíå‰∏ªË¶ÅÁâ©‰ΩìÁöÑÂàóË°®„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™ÈìæÔºåÂ∞ÜÂõæÂÉèÂä†ËΩΩÊ≠•È™§Ôºà`load\\_image\\_chain`Ôºâ„ÄÅLLMË∞ÉÁî®Ê≠•È™§Ôºà`image\\_model`ÔºâÂíåJSONËæìÂá∫Ëß£ÊûêÂô®Ôºà`parser`ÔºâÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Áî®ÂõæÂÉèË∑ØÂæÑÂíåÊèêÁ§∫Ë∞ÉÁî®Ëøô‰∏™ÈìæÔºåÂáΩÊï∞ËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÊèêÂèñ‰ø°ÊÅØÁöÑÂ≠óÂÖ∏„ÄÇ\n\n## Á§∫‰æãÁî®Ê≥ï\n\nË¶Å‰ΩøÁî®Ê≠§ÂäüËÉΩÔºåÂè™ÈúÄÊèê‰æõÂõæÂÉèÊñá‰ª∂ÁöÑË∑ØÂæÑÔºö\n\n\n```python\nresult = get_image_informations(\"path/to/your/image.jpg\")\nprint(result)\n```\nËøôÂ∞ÜËæìÂá∫‰∏Ä‰∏™ÂåÖÂê´ËØ∑Ê±Ç‰ø°ÊÅØÁöÑÂ≠óÂÖ∏Ôºå‰æãÂ¶ÇÔºö\n\n\n```python\n{\n 'description': 'a view of a city showing cars waiting at a traffic light',\n 'people_count': 5,\n 'main_objects': ['car', 'building', 'traffic light', 'tree']\n}\n```\n\n## ÁªìËÆ∫\n\nLangchain Êèê‰æõ‰∫ÜÂº∫Â§ßÁöÑÂ∑•ÂÖ∑ÈõÜÔºåÁî®‰∫éÂ§ÑÁêÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂπ∂‰ªéÂêÑÁßçÊï∞ÊçÆÊ∫êÔºàÂåÖÊã¨ÂõæÂÉèÔºâ‰∏≠ÊèêÂèñÊúâ‰ª∑ÂÄºÁöÑ‰ø°ÊÅØ„ÄÇÈÄöËøáÂ∞Ü Langchain ÁöÑÂäüËÉΩ‰∏éËá™ÂÆö‰πâÊèêÁ§∫ÂíåËæìÂá∫Ëß£ÊûêÁõ∏ÁªìÂêàÔºåÊÇ®ÂèØ‰ª•ÂàõÂª∫Âº∫Â§ßÁöÑÂ∫îÁî®Á®ãÂ∫èÔºå‰ªéËßÜËßâÊï∞ÊçÆ‰∏≠ÊèêÂèñÁªìÊûÑÂåñ‰ø°ÊÅØ„ÄÇ\n\nËØ∑ËÆ∞‰ΩèÔºåËæìÂá∫ÁöÑË¥®ÈáèÂ∞ÜÂèñÂÜ≥‰∫éÊÇ®‰ΩøÁî®ÁöÑ LLM ÁöÑËÉΩÂäõ‰ª•ÂèäÊÇ®ÊèêÁ§∫ÁöÑÂÖ∑‰ΩìÊÄß„ÄÇÂ∞ùËØï‰∏çÂêåÁöÑÊ®°ÂûãÂíåÊèêÁ§∫Ôºå‰ª•ÊâæÂà∞ÊúÄÈÄÇÂêàÊÇ®Áî®‰æãÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ÊâæÂà∞Êõ¥Â•ΩÁöÑÊñπÊ≥ïÊù•ÂÆûÁé∞Áõ∏ÂêåÁöÑÁªìÊûúÊàñÊúâÊîπËøõÂª∫ËÆÆÔºåËØ∑ÈöèÊó∂Âú®ËØÑËÆ∫‰∏≠ÂàÜ‰∫´„ÄÇÊú¨ÊñáÊèê‰æõÁöÑ‰ª£Á†ÅÁ§∫‰æãÊó®Âú®‰Ωú‰∏∫Ëµ∑ÁÇπÔºåÂèØËÉΩËøòÊúâÂÖ∂‰ªñÊñπÊ≥ïÊàñ‰ºòÂåñ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/generative-ai-in-market-research-and-intelligence-benefits-use-cases-and-strategies-4e9195a07ffc","frontmatter":{"title":"ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂ÂíåÊÉÖÊä•È¢ÜÂüüÁöÑÂ∫îÁî®Ôºö‰ºòÂäø„ÄÅÁî®‰æãÂíåÁ≠ñÁï•","meta_title":"ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂ÂíåÊÉÖÊä•È¢ÜÂüüÁöÑÂ∫îÁî®Ôºö‰ºòÂäø„ÄÅÁî®‰æãÂíåÁ≠ñÁï•","description":"ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊòæËëóÂèòÈù©Â∏ÇÂú∫Á†îÁ©∂ÂíåÊÉÖÊä•ÔºåÊèêÂçáÊï∞ÊçÆÂàÜÊûêÈÄüÂ∫¶ÂíåÊ∑±Â∫¶„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÁîüÊàêÂºèAIËÉΩÂ§üÂÆûÊó∂Â§ÑÁêÜÂ§ßÊï∞ÊçÆÔºåÊèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÊ¥ûÂØüÔºåÈôç‰ΩéÊàêÊú¨ÂíåÊó∂Èó¥Ê∂àËÄó„ÄÇÊ≠§Â§ñÔºåÂÆÉËøòËÉΩ‰ºòÂåñÂ∏ÇÂú∫Á≠ñÁï•ÔºåÈÄöËøáÊÉÖÊÑüÂàÜÊûêÂíåÁî®Êà∑ËßíËâ≤ÂºÄÂèëÂ¢ûÂº∫ÂÆ¢Êà∑‰∫íÂä®„ÄÇ‰ºÅ‰∏öÈÄöËøáÊï¥ÂêàAIÂ∑•ÂÖ∑ÔºåÂèØ‰ª•Âú®Âä®ÊÄÅÂ∏ÇÂú∫‰∏≠‰øùÊåÅÁ´û‰∫âÂäõÔºåÂÆûÁé∞Êï∞ÊçÆÈ©±Âä®ÁöÑÂÜ≥Á≠ñ„ÄÇÊú™Êù•ÔºåAIÂ∞ÜËøõ‰∏ÄÊ≠•Êé®Âä®‰∏™ÊÄßÂåñ„ÄÅÂÆûÊó∂ÁõëÊµãÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂàÜÊûêÔºåÊàê‰∏∫Â∏ÇÂú∫Á†îÁ©∂‰∏çÂèØÊàñÁº∫ÁöÑÁªÑÊàêÈÉ®ÂàÜ„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0J_wBAutefsvq5PyxPL17Q.jpeg","categories":["Generative AI","Market Research","Data Science"],"author":"Rifx.Online","tags":["generative","market","research","insights","automation"],"draft":false,"slug":"blog/generative-ai-in-market-research-and-intelligence-benefits-use-cases-and-strategies-4e9195a07ffc"},"content":"\n\n\n### Âà©Áî®AIËΩ¨ÂèòÂ∏ÇÂú∫ÊÉÖÊä•\n\n\n\nÁîüÊàêÂºèAIÊ≠£Âú®ÊîπÂèò‰ºÅ‰∏öËøõË°åÂ∏ÇÂú∫Á†îÁ©∂ÂíåÊÉÖÊä•ÁöÑÊñπÂºèÔºå‰ΩøÊï∞ÊçÆÂàÜÊûêÂèòÂæóÊõ¥Âø´„ÄÅÊõ¥Ê∑±ÂÖ•„ÄÇ‰º†ÁªüÁöÑÂ∏ÇÂú∫Á†îÁ©∂ÊñπÊ≥ïÈ´òÂ∫¶‰æùËµñÊâãÂä®Êï∞ÊçÆÊî∂ÈõÜ„ÄÅË∞ÉÊü•ÂàÜÊûêÂíåÁ´û‰∫âÂØπÊâãÁ†îÁ©∂ÔºåËøô‰∫õÊñπÊ≥ïÂæÄÂæÄËÄóÊó∂‰∏îËåÉÂõ¥ÊúâÈôê„ÄÇÁîüÊàêÂºèAIÂàôÂÖÅËÆ∏ÂÖ¨Âè∏Âç≥Êó∂ÂàÜÊûêÂ∫ûÂ§ßÁöÑÊï∞ÊçÆÈõÜÔºåÁîüÊàêÂèØËÉΩË¢´ÂøΩËßÜÁöÑÊ¥ûÂØüÔºåÂπ∂ÂàõÂª∫Â∏ÆÂä©Êõ¥ÂáÜÁ°ÆÈ¢ÑÊµãË∂ãÂäøÁöÑÈ¢ÑÊµãÊ®°Âûã„ÄÇ‰ªéÁªºÂêàÊï∞ÊçÆÊä•ÂëäÂà∞ÂàõÂª∫È´òÂ±ÇÊ¨°ÊëòË¶ÅÔºåÁîüÊàêÂºèAIÂä†ÈÄü‰∫ÜÂÜ≥Á≠ñËøáÁ®ãÔºå‰ΩøÂ∏ÇÂú∫Ê¥ûÂØüÊõ¥Âä†Êòì‰∫éËé∑Âèñ„ÄÇ\n\nÈô§‰∫ÜÊï∞ÊçÆÂàÜÊûêÔºåÁîüÊàêÂºèAIËøòÂú®ÊîπÂèòÂÖ¨Âè∏‰∏éÂèó‰ºóÁöÑ‰∫íÂä®ÊñπÂºè‰ª•ÂèäÂ∏ÇÂú∫Á≠ñÁï•ÁöÑ‰ºòÂåñ„ÄÇÈÄöËøá‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâÔºå‰ºÅ‰∏öÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞ÂàõÂª∫Ê®°Êãü„ÄÅÈ¢ÑÊµãË∂ãÂäøÂíåËøõË°åÁ´û‰∫âÂàÜÊûê„ÄÇÊú¨ÊåáÂçóÊé¢ËÆ®‰∫ÜÂà©Áî®ÁîüÊàêÂºèAIÂ¢ûÂº∫Â∏ÇÂú∫Á†îÁ©∂ÁöÑ‰∏ªË¶ÅÂ•ΩÂ§Ñ„ÄÅÂÆûÈôÖÂ∫îÁî®Ê°à‰æãÂíåÁ≠ñÁï•„ÄÇÈÄöËøáÂ∞ÜAIÊï¥ÂêàÂà∞Â∏ÇÂú∫ÊÉÖÊä•Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÔºåÂÖ¨Âè∏ÂèØ‰ª•‰øùÊåÅÁ´û‰∫âÂäõÔºåÂπ∂ÂÅöÂá∫‰∏éÂèó‰ºóÈúÄÊ±ÇÁõ∏Á¨¶ÂêàÁöÑÊï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ„ÄÇ\n\n## ‰º†ÁªüÂ∏ÇÂú∫Á†îÁ©∂ÂèäÂÖ∂Â±ÄÈôêÊÄß\n\n‰º†ÁªüÂ∏ÇÂú∫Á†îÁ©∂Ê∂âÂèäËØ∏Â¶ÇË∞ÉÊü•„ÄÅÁÑ¶ÁÇπÂ∞èÁªÑ„ÄÅËÆøË∞àÂíåÁ´û‰∫âÂàÜÊûêÁ≠âÊàêÁÜüÊñπÊ≥ïÔºåËøô‰∫õÊñπÊ≥ïË¢´ÂÖ¨Âè∏ÂπøÊ≥õ‰ΩøÁî®Ôºå‰ª•‰∫ÜËß£ÂÖ∂ÂÆ¢Êà∑„ÄÅÁ´û‰∫âÂØπÊâãÂíåË°å‰∏öË∂ãÂäø„ÄÇËøô‰∫õÊñπÊ≥ï‰∏ÄÁõ¥ÊòØÂ∏ÇÂú∫ÊÉÖÊä•ÁöÑÊîØÊü±Ôºå‰∏∫ÊàòÁï•ÂÜ≥Á≠ñÊèê‰æõ‰∫ÜÁªìÊûÑÂåñÂíåÁªèËøáÈ™åËØÅÁöÑËßÅËß£„ÄÇÁÑ∂ËÄåÔºåÂ∞ΩÁÆ°ÊúâÊïàÔºå‰º†ÁªüÂ∏ÇÂú∫Á†îÁ©∂Âú®ÂΩì‰ªäÂä®ÊÄÅÂíåÊï∞ÊçÆÈ•±ÂíåÁöÑÁéØÂ¢É‰∏≠Èù¢‰∏¥ÊòæËëóÁöÑÂ±ÄÈôêÊÄß„ÄÇ\n\n### 1\\. È´òÊàêÊú¨\n\n* ‰º†ÁªüÊñπÊ≥ïÈÄöÂ∏∏Ê∂âÂèäÂ§ßÈáèÁöÑË¥¢Âä°ÊäïËµÑÔºåÁâπÂà´ÊòØÂØπ‰∫éÂÖ®Èù¢ÁöÑÁ†îÁ©∂„ÄÇ\n* ÊàêÊú¨Êù•Ëá™‰∫éÈõá‰Ω£Á†îÁ©∂‰∫∫Âëò„ÄÅËøõË°åË∞ÉÊü•„ÄÅËÆæÁΩÆÁÑ¶ÁÇπÂ∞èÁªÑ‰ª•ÂèäÂàÜÊûêÁªìÊûú„ÄÇ\n* ‰∏≠Â∞èÂûã‰ºÅ‰∏öÂèØËÉΩ‰ºöÂèëÁé∞Ëøô‰∫õÊàêÊú¨ËøáÈ´òÔºå‰ªéËÄåÈôêÂà∂‰∫ÜËé∑ÂèñÊ∑±ÂÖ•ËßÅËß£ÁöÑÊú∫‰ºö„ÄÇ\n\n### 2\\. ËÄóÊó∂ÁöÑËøáÁ®ã\n\n* ÈÄöËøá‰º†ÁªüÊñπÊ≥ïÊî∂ÈõÜ„ÄÅÂ§ÑÁêÜÂíåÂàÜÊûêÊï∞ÊçÆÂèØËÉΩÈúÄË¶ÅÊï∞Âë®ÁîöËá≥Êï∞ÊúàÁöÑÊó∂Èó¥„ÄÇ\n* Âú®Âø´ÈÄüÂèòÂåñÁöÑË°å‰∏ö‰∏≠ÔºåÈÄöËøáÁºìÊÖ¢ÁöÑËøáÁ®ãËé∑ÂæóÁöÑËßÅËß£ÂèØËÉΩÂú®ÂèØÊìç‰Ωú‰πãÂâçÂ∞±Â∑≤ÁªèËøáÊó∂„ÄÇ\n* ÂØπÂÆûÊó∂Êï∞ÊçÆÁöÑÈúÄÊ±ÇÊ≠£Âú®Â¢ûÂä†Ôºå‰ΩÜ‰º†ÁªüÊñπÊ≥ïÈöæ‰ª•‰ª•ËøôÊ†∑ÁöÑÈÄüÂ∫¶Êèê‰æõËßÅËß£„ÄÇ\n\n### 3\\. ÊúâÈôêÁöÑÊ†∑Êú¨ÈáèÂíåËåÉÂõ¥\n\n* ‰º†ÁªüÁ†îÁ©∂Â∏∏Â∏∏ÂèóÂà∞È¢ÑÁÆó„ÄÅÊó∂Èó¥ÂíåÂêéÂã§ÈôêÂà∂ÁöÑÁ∫¶ÊùüÔºåËøôÂèØËÉΩÈôêÂà∂Ê†∑Êú¨ÁöÑÂ§öÊ†∑ÊÄßÂíåÂ§ßÂ∞è„ÄÇ\n* ÁÑ¶ÁÇπÂ∞èÁªÑÂíåËÆøË∞àÂèØËÉΩÊó†Ê≥ïÂÖÖÂàÜ‰ª£Ë°®Êõ¥ÂπøÊ≥õÁöÑÂèó‰ºóÁæ§‰ΩìÔºå‰ªéËÄåÂØºËá¥Á†îÁ©∂ÁªìÊûú‰∏≠ÂèØËÉΩÂ≠òÂú®Áõ≤ÁÇπ„ÄÇ\n* ËøôÁßçÈôêÂà∂ÂΩ±Âìç‰∫Ü‰∫∫Âè£ÁªüËÆ°„ÄÅÂøÉÁêÜÁâπÂæÅÂíåË°å‰∏∫Ê¥ûÂØüÁöÑÂáÜÁ°ÆÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖ®ÁêÉÊâ©Â±ïÊó∂„ÄÇ\n\n### 4\\. ÂàÜÊûêÈùûÁªìÊûÑÂåñÊï∞ÊçÆÁöÑÂõ∞Èöæ\n\n* ‰º†ÁªüÊñπÊ≥ïÈÄöÂ∏∏ÈíàÂØπÁªìÊûÑÂåñÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåË∞ÉÊü•‰∏≠ÁöÑÂìçÂ∫îÔºâÔºåËÄå‰∏çÊòØÂÉèÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠ê„ÄÅÂÆ¢Êà∑ËØÑËÆ∫ÊàñËÆ∫ÂùõËÆ®ËÆ∫ËøôÊ†∑ÁöÑÈùûÁªìÊûÑÂåñÊï∞ÊçÆ„ÄÇ\n* ‰ªéÈùûÁªìÊûÑÂåñÊï∞ÊçÆ‰∏≠Ëé∑ÂèñÊúâ‰ª∑ÂÄºÁöÑËßÅËß£ÈúÄË¶ÅÊõ¥Â§çÊùÇÁöÑÂàÜÊûêÔºåËÄå‰º†ÁªüÊñπÊ≥ïÂèØËÉΩÁº∫‰πèÊúâÊïàÂ§ÑÁêÜÊâÄÈúÄÁöÑËµÑÊ∫êÊàñÊäÄÊúØ„ÄÇ\n\n### 5\\. ÊúâÈôêÁöÑÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß\n\n* ‰º†ÁªüÁöÑÁ†îÁ©∂ËÆæËÆ°ÈÄöÂ∏∏ÊòØÂõ∫ÂÆöÁöÑÔºåËøô‰ΩøÂæóÂú®Á†îÁ©∂ËøáÁ®ã‰∏≠ËøõË°åËΩ¨ÂèòÊàñË∞ÉÊï¥ÂèòÂæóÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇ\n* ‰æãÂ¶ÇÔºåÈíàÂØπ‰∏çÂèØÈ¢ÑËßÅÁöÑÂ∏ÇÂú∫‰∫ã‰ª∂ÊàñÂèòÂåñÔºåÊñ∞ÁöÑÁ†îÁ©∂ÂæÄÂæÄÈúÄË¶Å‰ªéÂ§¥ÂºÄÂßãÂêØÂä®„ÄÇ\n* ËøôÁßçÂÉµÂåñÂèØËÉΩ‰ºöÈòªÁ¢çÂìÅÁâåËøÖÈÄüÂ∫îÂØπÂ∏ÇÂú∫Êù°‰ª∂ÊàñÊñ∞ÂÖ¥Ë∂ãÂäøÁöÑËÉΩÂäõ„ÄÇ\n\n## ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂ¶Ç‰ΩïÊîπÂèòÂ∏ÇÂú∫Á†îÁ©∂Ôºü\n\nÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂá≠ÂÄüÂÖ∂Â§ÑÁêÜÊµ∑ÈáèÊï∞ÊçÆÂíåÁîüÊàêÊúâÊÑè‰πâÊ¥ûÂØüÁöÑËÉΩÂäõÔºåÊ≠£Âú®ÂΩªÂ∫ïÊîπÂèò‰º†ÁªüÂ∏ÇÂú∫Á†îÁ©∂„ÄÇÈÄöËøáËß£ÂÜ≥‰º†ÁªüÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ‰ΩøÂæóÂ∏ÇÂú∫Ê¥ûÂØüÁöÑËé∑ÂèñÊõ¥Âä†Âø´ÈÄü„ÄÅÂÖ®Èù¢ÂíåÂÖ∑ÊúâÊàêÊú¨ÊïàÁõä„ÄÇ‰ª•‰∏ãÊòØÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂ¶Ç‰ΩïÈáçÂ°ëÂ∏ÇÂú∫Á†îÁ©∂È¢ÜÂüüÁöÑÊ¶ÇËø∞Ôºö\n\n### 1\\. Êï∞ÊçÆÁîüÊàê‰∏éÂ¢ûÂº∫\n\n* ÂêàÊàêÊï∞ÊçÆÂàõÂª∫ÔºöÁîüÊàêÂºèAIÊ®°ÂûãÂèØ‰ª•ÂàõÂª∫Ê®°ÊãüÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÁöÑÂêàÊàêÊï∞ÊçÆÈõÜÔºåÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÂÖãÊúçÊ†∑Êú¨Â§ßÂ∞èÂíåÂ§öÊ†∑ÊÄßÊñπÈù¢ÁöÑÈôêÂà∂„ÄÇ\n* Â¢ûÂº∫ÊÉÖÊôØÂª∫Ê®°ÔºöÈÄöËøáÊ®°Êãü‰∏çÂêåÁöÑÂ∏ÇÂú∫ÊÉÖÊôØÔºåAI‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÊé¢Á¥¢‚ÄúÂ¶ÇÊûú‚ÄùÊÉÖÂÜµÔºåÂπ∂ÊµãËØïÂ∏ÇÂú∫Êù°‰ª∂Â¶Ç‰ΩïÂΩ±ÂìçÊ∂àË¥πËÄÖË°å‰∏∫Êàñ‰∫ßÂìÅÊàêÂäü„ÄÇ\n\n### 2\\. Âø´ÈÄüÂÜÖÂÆπÁîüÊàê‰ª•Ëé∑ÂèñÊ¥ûÂØü\n\n* Ëá™Âä®ÂåñÊä•ÂëäÊí∞ÂÜôÔºöÁîüÊàêÂºèAIÂèØ‰ª•ÁîüÊàêËØ¶ÁªÜÁöÑÂ∏ÇÂú∫Á†îÁ©∂Êä•ÂëäÔºåÂ∞ÜÊï∞ÊçÆÊÄªÁªìÊàêÊòì‰∫éÁêÜËß£ÁöÑÂèôËø∞Ôºå‰æø‰∫éÂà©ÁõäÁõ∏ÂÖ≥ËÄÖÂø´ÈÄüÊ∂àÂåñ„ÄÇ\n* ÂÆöÂà∂ÂåñÊ¥ûÂØüÔºöÂÉèChatGPTÊàñJasperËøôÊ†∑ÁöÑAIÂ∑•ÂÖ∑ÂèØ‰ª•Ê†πÊçÆÁâπÂÆöÁöÑÊï∞ÊçÆËæìÂÖ•Âø´ÈÄüÁîüÊàêÈáèË∫´ÂÆöÂà∂ÁöÑÊ¥ûÂØüÔºå‰∏∫Â∏ÇÂú∫Ëê•ÈîÄ‰∫∫ÂëòÊèê‰æõÈíàÂØπÁâπÂÆöÂèó‰ºóÁöÑÊä•Âëä„ÄÅÁ´û‰∫âÂØπÊâãÂàÜÊûêÂíåÂÆ¢Êà∑ÊóÖÁ®ãÊëòË¶Å„ÄÇ\n\n### 3\\. ÊÉÖÊÑüÂàÜÊûê‰∏éÁ§æ‰∫§ËÅÜÂê¨\n\n* ÂÆûÊó∂ÊÉÖÊÑüÁõëÊµãÔºöAIÊ®°ÂûãÂèØ‰ª•ÂàÜÊûêÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠ê„ÄÅËØÑËÆ∫ÂíåËÆ∫ÂùõÔºå‰ª•ÊèêÂèñÂÆûÊó∂ÊÉÖÊÑüÔºåË∑üË∏™ÂÆ¢Êà∑ÂØπ‰∫ßÂìÅ„ÄÅÊúçÂä°ÊàñÂìÅÁâåÁöÑÊÑüÂèó„ÄÇ\n* Ë∂ãÂäøËØÜÂà´ÔºöÁîüÊàêÂºèAIÂèØ‰ª•ÈÄöËøáËØÜÂà´ÂÖ≥ÈîÆËØç„ÄÅ‰∏ªÈ¢òÂíåÊÉÖÊÑüÂü∫Ë∞ÉÔºå‰ªéÈùûÁªìÊûÑÂåñÊï∞ÊçÆÊ∫ê‰∏≠ËØÜÂà´Êñ∞ÂÖ¥Ë∂ãÂäøÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ÊéåÊè°Ê∂àË¥πËÄÖÂÅèÂ•Ω„ÄÇ\n\n### 4\\. È´òÁ∫ßÁî®Êà∑ËßíËâ≤‰∏éÂú∫ÊôØÂºÄÂèë\n\n* ËØ¶ÁªÜÁöÑÊ∂àË¥πËÄÖËßíËâ≤ÔºöAIÂèØ‰ª•ÈÄöËøáÂàÜÊûêÂêÑÁßçÊï∞ÊçÆÈõÜ‰∏≠ÁöÑ‰∫∫Âè£ÁªüËÆ°„ÄÅÂøÉÁêÜÁâπÂæÅÂíåË°å‰∏∫Ê®°ÂºèÔºåÁîüÊàêÈ´òÂ∫¶ÁªÜËá¥ÁöÑÊ∂àË¥πËÄÖËßíËâ≤„ÄÇ\n* ÂÅáËÆæÂú∫ÊôØÂàõÂª∫ÔºöÁîüÊàêÂºèAI‰ΩøÂæóÂàõÂª∫ÊΩúÂú®Ê∂àË¥πËÄÖÂú∫ÊôØÊàê‰∏∫ÂèØËÉΩÔºå‰ª•Êé¢ËÆ®Âèó‰ºóÂ¶Ç‰ΩïÂØπÊñ∞‰∫ßÂìÅ„ÄÅÊúçÂä°Êàñ‰ø°ÊÅØÂèòÂåñ‰ΩúÂá∫ÂèçÂ∫îÔºå‰ªéËÄå‰∏∫ÂÖ¨Âè∏Êèê‰æõÊõ¥ÂÖ∑Âä®ÊÄÅÁöÑÂ∏ÇÂú∫ÊµãËØïÊñπÊ≥ï„ÄÇ\n\n### 5\\. Â¢ûÂº∫ÁöÑÁ´û‰∫âÂØπÊâãÂíåË°å‰∏öÂàÜÊûê\n\n* ÂÆûÊó∂Â∏ÇÂú∫ÂÆö‰ΩçÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•ÁõëÊéßÁ´û‰∫âÂØπÊâãÁöÑË°åÂä®„ÄÅ‰ø°ÊÅØ‰º†ÈÄíÂíåÂÆö‰ª∑Á≠ñÁï•Ôºå‰∏∫ÂÖ¨Âè∏Êèê‰æõ‰∏çÊñ≠Êõ¥Êñ∞ÁöÑÂ∏ÇÂú∫ÂÆö‰ΩçËßÜÂõæ„ÄÇ\n* Â∏ÇÂú∫Ë∂ãÂäøÈ¢ÑÊµãÂàÜÊûêÔºöÈÄöËøá‰ΩøÁî®ÂéÜÂè≤Êï∞ÊçÆÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•È¢ÑÊµãÊú™Êù•ÁöÑÂ∏ÇÂú∫Ë∂ãÂäøÔºåÂ∏ÆÂä©ÂÖ¨Âè∏È¢ÑËßÅÊ∂àË¥πËÄÖÂÅèÂ•ΩÁöÑÂèòÂåñ„ÄÅÊñ∞ÂÖ¥‰∫ßÂìÅÈúÄÊ±ÇÊàñÁ´û‰∫âÂÆö‰ΩçÁöÑÂèòÂåñ„ÄÇ\n\n### 6\\. ‰∏™ÊÄßÂåñÂÆ¢Êà∑‰∫íÂä®‰∏éÊ¥ûÂØü\n\n* ÂÜÖÂÆπÁöÑË∂Ö‰∏™ÊÄßÂåñÔºöAI‰ΩøÂæó‰∏∫ÂÆ¢Êà∑ÁªÜÂàÜÁîüÊàêÈ´òÂ∫¶‰∏™ÊÄßÂåñÁöÑÂÜÖÂÆπÊàê‰∏∫ÂèØËÉΩÔºåÂåÖÊã¨Ê†πÊçÆ‰∏™‰∫∫Ê∂àË¥πË°å‰∏∫ÂÆöÂà∂ÁöÑÂπøÂëäÊñáÊ°àÂíå‰∫ßÂìÅÊé®Ëçê„ÄÇ\n* Â¢ûÂº∫ÁöÑÂÆ¢Êà∑ÂèçÈ¶àÂæ™ÁéØÔºöÈÄöËøáÂ§ÑÁêÜÂíåÁªºÂêàÊù•Ëá™Â§ö‰∏™Ê∏†ÈÅìÁöÑÂèçÈ¶àÔºåÁîüÊàêÂºèAIÂèØ‰ª•ÂèëÁé∞ÁâπÂÆöÁöÑÊ¥ûÂØüÔºå‰ª•ÊîπÂñÑ‰∫ßÂìÅÂºÄÂèë„ÄÅÂÆ¢Êà∑ÊúçÂä°ÂíåËê•ÈîÄ‰ø°ÊÅØ„ÄÇ\n\n### 7\\. Ëá™Âä®ÂåñË∞ÉÊü•‰∏éÂèçÈ¶àÂàÜÊûê\n\n* Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁî®‰∫éË∞ÉÊü•ÂèçÈ¶àÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•ÂàÜÊûêÂºÄÊîæÂºèË∞ÉÊü•ÂèçÈ¶àÔºåÊ±áÊÄªÊ∂àË¥πËÄÖÊÑèËßÅÔºåÂπ∂ËØÜÂà´Â∏∏ËßÅ‰∏ªÈ¢òÔºåÊó†ÈúÄÊâãÂä®Â§ÑÁêÜ„ÄÇ\n* ÂÅèËßÅÊ£ÄÊµã‰∏é‰øÆÊ≠£ÔºöÂèØ‰ª•ËÆ≠ÁªÉ‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÊ£ÄÊµãÂπ∂Ë∞ÉÊï¥Ë∞ÉÊü•ÂèçÈ¶à‰∏≠ÁöÑÂÅèËßÅÔºå‰ΩøÁ†îÁ©∂ÁªìÊûúÊõ¥ÂÖ∑‰ª£Ë°®ÊÄß„ÄÇ\n\n## ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫ÊÉÖÊä•‰∏≠ÁöÑÂÖ≥ÈîÆÂ∫îÁî®\n\nÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫ÊÉÖÊä•‰∏≠ÂºïÂÖ•‰∫ÜÁ™ÅÁ†¥ÊÄßÁöÑÂ∫îÁî®Ôºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§ü‰ª•Êõ¥È´òÁöÑÊïàÁéáÂíåÂèØÊâ©Â±ïÊÄßËé∑ÂæóÊõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂÆûÊó∂Ê¥ûÂØü„ÄÇ‰ª•‰∏ãÊòØÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèòÂ∏ÇÂú∫ÊÉÖÊä•ÁöÑ‰∏Ä‰∫õ‰∏ªË¶ÅÊñπÂºèÔºö\n\n### 1\\. Ë∂ãÂäøÂàÜÊûê‰∏éÈ¢ÑÊµã\n\n* Â∏ÇÂú∫Ë∂ãÂäøËØÜÂà´ÔºöÁîüÊàêÂºèAIÊ®°ÂûãÂàÜÊûêÂ§ßÂûãÊï∞ÊçÆÈõÜÔºåÂ¶ÇÁ§æ‰∫§Â™í‰Ωì„ÄÅÊêúÁ¥¢Êï∞ÊçÆÂíåÊñ∞ÈóªÔºå‰ª•Âú®Ë∂ãÂäøÊàê‰∏∫‰∏ªÊµÅ‰πãÂâçËØÜÂà´Êñ∞ÂÖ¥Ë∂ãÂäø„ÄÇ\n* ÈúÄÊ±ÇÈ¢ÑÊµãÔºöÂü∫‰∫éÂéÜÂè≤Êï∞ÊçÆÂíåÂ∏ÇÂú∫ÊåáÊ†áÔºåAIÈ©±Âä®ÁöÑÊ®°ÂûãÈ¢ÑÊµãÈúÄÊ±ÇÂèòÂåñÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂ∞ÜÂÖ∂ÊàòÁï•‰∏éÈ¢ÑÊúüÁöÑÊ∂àË¥πËÄÖÈúÄÊ±ÇÂØπÈΩê„ÄÇ\n* ÊñáÂåñÂíåÁ§æ‰ºöË∂ãÂäøÂàÜÊûêÔºöAIÊâ´ÊèèÂπ∂ÁªºÂêàÊµÅË°åÊñáÂåñ„ÄÅÁîüÊ¥ªÊñπÂºèÂèòÂåñÂíåÁ§æ‰ºöÈóÆÈ¢ò‰∏≠ÁöÑË∂ãÂäøÔºå‰ª•Â∏ÆÂä©ÂìÅÁâå‰∏éÊ∂àË¥πËÄÖ‰ª∑ÂÄºËßÇ‰øùÊåÅ‰∏ÄËá¥„ÄÇ\n\n### 2\\. Áî®Êà∑ËßíËâ≤‰∏éÂú∫ÊôØÂºÄÂèë\n\n* ËØ¶ÁªÜÁöÑÊ∂àË¥πËÄÖËßíËâ≤ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂü∫‰∫é‰∫∫Âè£ÁªüËÆ°„ÄÅË°å‰∏∫ÂíåÂøÉÁêÜÊï∞ÊçÆÂàõÂª∫‰∏∞ÂØåÁöÑÊï∞ÊçÆÈ©±Âä®ËßíËâ≤„ÄÇËøô‰∫õËßíËâ≤ÊúâÂä©‰∫éÁ≤æÂáÜËê•ÈîÄ„ÄÅ‰∫ßÂìÅËÆæËÆ°ÂíåÂÆ¢Êà∑‰ΩìÈ™åËßÑÂàí„ÄÇ\n* Âú∫ÊôØËßÑÂàíÔºöÈÄöËøáÊ®°ÊãüÂêÑÁßçÂ∏ÇÂú∫Êù°‰ª∂ÂíåÊ∂àË¥πËÄÖÂèçÂ∫îÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ‰Ωø‰ºÅ‰∏öËÉΩÂ§üÂèØËßÜÂåñ‰∏çÂêåÁ≠ñÁï•ÁöÑÂΩ±ÂìçÔºå‰ªéËÄåÂÆûÁé∞Êõ¥‰∏∫ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇ\n\n### 3\\. ÂÆûÊó∂Ê∂àË¥πËÄÖÂèçÈ¶àÁöÑÊÉÖÊÑüÂàÜÊûê\n\n* ÂÆ¢Êà∑ÊÉÖÊÑüË∑üË∏™ÔºöÁîüÊàêÂºèAIÂ∑•ÂÖ∑Â§ÑÁêÜÊù•Ëá™ËØÑËÆ∫„ÄÅÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠êÂíåË∞ÉÊü•ÁöÑÈùûÁªìÊûÑÂåñÊï∞ÊçÆÔºå‰ª•ÂÆûÊó∂ËØÑ‰º∞Ê∂àË¥πËÄÖÊÉÖÊÑü„ÄÇ\n* ÊÉÖÊÑüÂíåË°å‰∏∫Ê¥ûÂØüÔºöÈÄöËøáÂàÜÊûêÂÆ¢Êà∑ÂèçÈ¶à‰∏≠ÁöÑËØ≠Ë®ÄÂíåËØ≠Ë∞ÉÔºåAIÂèØ‰ª•Êè≠Á§∫Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑÊÉÖÊÑüÈ©±Âä®Âõ†Á¥†Ôºå‰ΩøÂìÅÁâåËÉΩÂ§üÁõ∏Â∫îÂú∞Ë∞ÉÊï¥ÂÖ∂‰ø°ÊÅØ‰º†ÈÄíÂíå‰∫ßÂìÅÂºÄÂèë„ÄÇ\n* ÂìÅÁâåÂÅ•Â∫∑ÁõëÊµãÔºöAIÁîüÊàêÁöÑÊÉÖÊÑüÂàÜÊûêÊèê‰æõ‰∫ÜÂØπÂìÅÁâåËÆ§Áü•ÁöÑÊåÅÁª≠Ê¥ûÂØüÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂø´ÈÄüÂìçÂ∫îÂÖ¨‰ºóËàÜËÆ∫ÁöÑÂèòÂåñ„ÄÇ\n\n### 4\\. Á´û‰∫âÂØπÊâã‰∏éË°å‰∏öÂàÜÊûê\n\n* Á´û‰∫âÊÉÖÊä•ÔºöAIÈ©±Âä®ÁöÑÂ∑•ÂÖ∑ËøΩË∏™Á´û‰∫âÂØπÊâãÂú®ÂêÑ‰∏™Ê∏†ÈÅìÁöÑË°åÂä®ÔºåÂàÜÊûê‰ªñ‰ª¨ÁöÑÂÆö‰ª∑Á≠ñÁï•„ÄÅ‰∫ßÂìÅÂèëÂ∏ÉÂíåÂÆ¢Êà∑ÂèçÈ¶à„ÄÇËøôÂ∏ÆÂä©ÂìÅÁâåË∞ÉÊï¥ÂÖ∂Á≠ñÁï•‰ª•‰øùÊåÅÁ´û‰∫âÂäõ„ÄÇ\n* Ë°å‰∏öÂü∫ÂáÜÔºöÁîüÊàêÂºèAIÊ±áÊÄªË°å‰∏öÊï∞ÊçÆ‰ª•ËÆæÂÆöÂü∫ÂáÜÔºå‰Ωø‰ºÅ‰∏öËÉΩÂ§üË°°ÈáèËá™Ë∫´Âú®Ë°å‰∏ö‰∏≠ÁöÑË°®Áé∞ÔºåÂπ∂Ê†πÊçÆÈúÄË¶ÅË∞ÉÊï¥Á≠ñÁï•„ÄÇ\n* È¢ÑÊµãÂ∏ÇÂú∫Âä®ÂêëÔºöÈÄöËøáÂéÜÂè≤Êï∞ÊçÆÔºåAIÈ¢ÑÊµãÂèØËÉΩÁöÑÁ´û‰∫âÂØπÊâãË°åÂä®ÂíåÂ∏ÇÂú∫ÂèòÂåñÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§ü‰∏ªÂä®Ë∞ÉÊï¥ÂÖ∂Á≠ñÁï•„ÄÇ\n\n### 5\\. Êä•ÂëäÂíåÊ¥ûÂØüÁöÑÂÜÖÂÆπÁîüÊàê\n\n* Ëá™Âä®ÂåñÊ¥ûÂØüÊëòË¶ÅÔºöAIÂèØ‰ª•Ëá™Âä®ÁîüÊàêÊ¥ûÂØüÊä•ÂëäÔºå‰ª•Êòì‰∫éÊ∂àÂåñÁöÑÊ†ºÂºèÊÄªÁªìÊï∞ÊçÆÔºå‰∏∫Âà©ÁõäÁõ∏ÂÖ≥ËÄÖËäÇÁúÅÊó∂Èó¥ÂíåËµÑÊ∫ê„ÄÇ\n* ÂÆöÂà∂Â∏ÇÂú∫ÊÉÖÊä•Êä•ÂëäÔºöÁîüÊàêÊÄßAIÁîüÊàêÁâπÂÆöÂ∏ÇÂú∫ÊàñÁªÜÂàÜÈ¢ÜÂüüÁöÑ‰∏™ÊÄßÂåñÊä•ÂëäÔºåÊèê‰æõ‰∏é‰∏öÂä°ÁõÆÊ†áÁ¥ßÂØÜÂØπÈΩêÁöÑÈíàÂØπÊÄßÊ¥ûÂØü„ÄÇ\n* ÁøªËØëÂíåÊú¨Âú∞ÂåñÔºöÁîüÊàêÊÄßAIÂèØ‰ª•Ë∑®ËØ≠Ë®ÄÂíåÊñáÂåñËÉåÊôØÁøªËØëÂ∏ÇÂú∫Ê¥ûÂØüÂíåÊä•ÂëäÔºå‰Ωø‰ºÅ‰∏öËÉΩÂ§üÂú®ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÊâ©Â±ïÂ∏ÇÂú∫ÊÉÖÊä•„ÄÇ\n\n### 6\\. ÂÆ¢Êà∑ÊóÖÁ®ãÊò†Â∞Ñ‰∏éÈ¢ÑÊµãÊ¥ûÂØü\n\n* Âä®ÊÄÅÂÆ¢Êà∑ÊóÖÁ®ãÂàÜÊûêÔºöAI ÁªºÂêàÂ§ö‰∏™Êé•Ëß¶ÁÇπÁöÑÊï∞ÊçÆÔºåÁªòÂà∂ÂÆ¢Êà∑ÊóÖÁ®ãÔºåÁ™ÅÂá∫ÂÆ¢Êà∑ÁîüÂëΩÂë®Êúü‰∏≠ÁöÑÂÖ≥ÈîÆÂÜ≥Á≠ñÁÇπÂíåÂÅèÂ•Ω„ÄÇ\n* È¢ÑÊµãÊ∂àË¥πËÄÖË°å‰∏∫ÔºöÂà©Áî®ÂéÜÂè≤Êï∞ÊçÆ‰∏≠ÁöÑÊ®°ÂºèÔºåAI È¢ÑÊµãÊú™Êù•ÁöÑÊ∂àË¥πËÄÖË°å‰∏∫Ôºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üË∞ÉÊï¥ÂÖ∂‰ø°ÊÅØ‰º†ÈÄí„ÄÅ‰∫ßÂìÅÊé®ËçêÂíåËê•ÈîÄÊó∂Êú∫„ÄÇ\n* ÊµÅÂ§±È¢ÑÊµã‰∏é‰øùÁïôÂàÜÊûêÔºöÈÄöËøáÂàÜÊûêÊ∂àË¥πËÄÖ‰∫íÂä®ÂíåÊª°ÊÑèÂ∫¶ËØÑÂàÜÔºåAI ËØÜÂà´È£éÈô©ÂÆ¢Êà∑ÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ÈááÂèñ‰∏ªÂä®ÁöÑ‰øùÁïôÊé™ÊñΩ„ÄÇ\n\n### 7\\. ‰∫ßÂìÅÊûÑÊÄù‰∏éÂºÄÂèë\n\n* Âü∫‰∫éÊ∂àË¥πËÄÖÂÅèÂ•ΩÁöÑÂàõÊÑèÁîüÊàêÔºöAIÂèØ‰ª•ÂàÜÊûêÊ∂àË¥πËÄÖÂÅèÂ•Ω„ÄÅÂèçÈ¶àÂíåÊµÅË°åÂÖ≥ÈîÆËØçÔºå‰ª•Âª∫ËÆÆ‰∫ßÂìÅÁâπÊÄßÊàñÂÖ®Êñ∞‰∫ßÂìÅÔºåÂ∏ÆÂä©ÊûÑÊÄùËøáÁ®ã„ÄÇ\n* Á´û‰∫âÁâπÊÄßÂàÜÊûêÔºöÈÄöËøáË∑üË∏™Á´û‰∫âÂØπÊâãÁöÑ‰∫ßÂìÅÁâπÊÄßÂíåÂÆ¢Êà∑ÂèçÈ¶àÔºåÁîüÊàêÂºèAIÂ∏ÆÂä©ÂìÅÁâåÂÆåÂñÑ‰∫ßÂìÅË∑ØÁ∫øÂõæÔºåÂπ∂‰ºòÂÖàËÄÉËôë‰∏éÁõÆÊ†áÂèó‰ºó‰∫ßÁîüÂÖ±È∏£ÁöÑÁâπÊÄß„ÄÇ\n* ‰∫ßÂìÅÊ¶ÇÂøµÊµãËØïÔºöÁîüÊàêÂºèAIÊ®°ÊãüÂ∏ÇÂú∫ÂØπÊΩúÂú®‰∫ßÂìÅÁöÑÂèçÂ∫îÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂú®ËøõË°åÂÖ®Èù¢ÂºÄÂèë‰πãÂâçÂÆåÂñÑÊ¶ÇÂøµ„ÄÇ\n\n### 8\\. Ë∂Ö‰∏™ÊÄßÂåñ‰∏éÁõÆÊ†áÂÆö‰Ωç\n\n* ÂàÜÂ±ÇÊ¥ªÂä®ÔºöÁîüÊàêÂºèAI‰ΩøÂ∏ÇÂú∫Ëê•ÈîÄ‰∫∫ÂëòËÉΩÂ§ü‰∏∫ÁâπÂÆöÂèó‰ºóÁæ§‰ΩìÁîüÊàêÂÆöÂà∂Âåñ‰ø°ÊÅØÔºåÊèêÈ´òÁõ∏ÂÖ≥ÊÄßÂíåÂèÇ‰∏éÂ∫¶„ÄÇ\n* ÂÆûÊó∂ÂπøÂëäÊñáÊ°àÂíåÂÜÖÂÆπÂÆöÂà∂ÔºöAIÊ®°ÂûãÂèØ‰ª•Ê†πÊçÆÁî®Êà∑Ë°å‰∏∫ÂíåÂÅèÂ•ΩÂä®ÊÄÅË∞ÉÊï¥ÂπøÂëäÊñáÊ°à„ÄÅÁîµÂ≠êÈÇÆ‰ª∂ÂÜÖÂÆπÂíåÁΩëÁ´ô‰ø°ÊÅØÔºå‰ΩøÂ∏ÇÂú∫Ëê•ÈîÄÂ∑•‰ΩúÊõ¥ÊúâÊïà„ÄÇ\n* Êé®ËçêÂºïÊìéÔºöÂà©Áî®ÂÆ¢Êà∑Ë°å‰∏∫ÂíåÊÉÖÊÑüÔºåAIÂàõÂª∫‰∏™ÊÄßÂåñÁöÑ‰∫ßÂìÅÊé®ËçêÔºåÊèêÈ´òÈîÄÂîÆÂíåÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ\n\n## ÈáèÂåñÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂‰∏≠ÁöÑÂ•ΩÂ§Ñ\n\nÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÈÄöËøá‰ΩøÊï∞ÊçÆÈ©±Âä®ÁöÑÊ¥ûÂØüÊõ¥Âä†ÂèØËé∑Âèñ„ÄÅÂáÜÁ°ÆÂíåÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÊù•ÂΩªÂ∫ïÊîπÂèòÂ∏ÇÂú∫Á†îÁ©∂„ÄÇÈáèÂåñËøô‰∫õÂ•ΩÂ§ÑÊúâÂä©‰∫é‰ºÅ‰∏ö‰∫ÜËß£‰∫∫Â∑•Êô∫ËÉΩÂ¶Ç‰ΩïÊèêÈ´òÁ†îÁ©∂ÊïàÁéáÂπ∂Â¢ûÂº∫ÂÖ∂ÊäïËµÑÂõûÊä•ÁéáÔºàROIÔºâ„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂÖ≥ÈîÆÊåáÊ†áÂíåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂‰∏≠Êé®Âä®ÂèØË°°ÈáèÂ•ΩÂ§ÑÁöÑÁ§∫‰æãÔºö\n\n### 1\\. ÊàêÊú¨Èôç‰Ωé\n\n* Èôç‰ΩéÂä≥Âä®ÂäõÊàêÊú¨Ôºö‰º†ÁªüÁ†îÁ©∂ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰∫∫ÂäõËøõË°åÊï∞ÊçÆÊî∂ÈõÜ„ÄÅÂàÜÊûêÂíåÊä•Âëä„ÄÇÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩËá™Âä®Âåñ‰∫ÜËÆ∏Â§öËøô‰∫õ‰ªªÂä°ÔºåÊòæËëóÈôç‰Ωé‰∫ÜÂä≥Âä®ÂäõÊàêÊú¨„ÄÇ\n* Èôç‰ΩéÊï∞ÊçÆÊî∂ÈõÜË¥πÁî®ÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÂèØ‰ª•‰ª•‰º†ÁªüË∞ÉÊü•ÊñπÊ≥ïÊàêÊú¨ÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÂàÜÊûêÁ§æ‰∫§Â™í‰Ωì„ÄÅËÆ∫ÂùõÂíåÊ∂àË¥πËÄÖËØÑ‰ª∑Á≠âÂ§ßÈáèÊï∞ÊçÆÊ∫ê„ÄÇ\n* Á§∫‰æãÔºö‰∏ÄÂÆ∂‰ª•ÂâçÊØèÂπ¥Âú®Â∏ÇÂú∫Á†îÁ©∂‰∏äËä±Ë¥π$100,000ÁöÑÂÖ¨Âè∏ÔºåÈÄöËøá‰ΩøÁî®ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑ÔºåÂèØËÉΩËäÇÁúÅÈ´òËææ40%ÁöÑË¥πÁî®ÔºåÂ∞ÜÂºÄÊîØÂáèÂ∞ëÂà∞$60,000ÔºåÂêåÊó∂Ëé∑ÂæóÁ±ª‰ººÊàñÊõ¥‰∏∞ÂØåÁöÑÊ¥ûÂØü„ÄÇ\n\n### 2\\. Êó∂Èó¥ËäÇÁúÅ‰∏éÊõ¥Âø´ÁöÑÊ¥ûÂØü\n\n* Âä†ÈÄüÁ†îÁ©∂Âë®ÊúüÔºöAIÂ∑•ÂÖ∑ÂÆûÊó∂ÂàÜÊûêÊï∞ÊçÆÔºåÂ∞ÜËé∑ÂèñÊ¥ûÂØüÊâÄÈúÄÁöÑÊó∂Èó¥‰ªéÊï∞Âë®ÊàñÊï∞ÊúàÁº©Áü≠Ëá≥Êï∞Â§©ÁîöËá≥Êï∞Â∞èÊó∂„ÄÇ\n* Âø´ÈÄüÊä•ÂëäÔºöËá™Âä®ÂåñÊä•ÂëäÁîüÊàêÂáèÂ∞ë‰∫ÜÂàÜÊûêÊó∂Èó¥Ôºå‰ΩøÂà©ÁõäÁõ∏ÂÖ≥ËÄÖËÉΩÂ§üÊõ¥Êó©Ëé∑ÂèñÊ¥ûÂØüÂπ∂ÂÅöÂá∫Êõ¥Âø´ÈÄüÁöÑÂÜ≥Á≠ñ„ÄÇ\n* Á§∫‰æãÔºö‰∏ÄÂÆ∂Êé®Âá∫Êñ∞‰∫ßÂìÅÁöÑ‰ºÅ‰∏öÂèØ‰ª•ÂÆûÊó∂Ëé∑ÂèñÂÆ¢Êà∑ËØÑ‰ª∑ÂíåÁ§æ‰∫§Â™í‰ΩìÁöÑÂèçÈ¶àÔºåÂà©Áî®ÁîüÊàêÊÄßAIÂú®24Â∞èÊó∂ÂÜÖÊèê‰æõÊ¥ûÂØüÔºåËÄå‰º†ÁªüÁ±ª‰ººÂàÜÊûêÁöÑÂë®ËΩ¨Êó∂Èó¥‰∏∫‰∏âÂë®„ÄÇ\n\n### 3\\. Â¢ûÂº∫ÁöÑÊï∞ÊçÆÂáÜÁ°ÆÊÄßÂíå‰∏ÄËá¥ÊÄß\n\n* ÊîπÂñÑÊï∞ÊçÆË¥®ÈáèÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ§ÑÁêÜÂ§ßÈáèÊï∞ÊçÆÔºåÂπ∂Âà©Áî®ÂÖàËøõÁöÑÂàÜÊûêÊäÄÊúØ‰ª•ÊØî‰∫∫Â∑•ÂàÜÊûêÊõ¥È´òÁöÑÂáÜÁ°ÆÊÄßËØÜÂà´Ë∂ãÂäø„ÄÇ\n* ÂáèÂ∞ëÂÅèËßÅÔºöÈÄöËøáÁªºÂêàÊù•Ëá™‰∏çÂêåÊù•Ê∫êÁöÑÂèçÈ¶àÔºå‰∫∫Â∑•Êô∫ËÉΩÊúÄÂ∞èÂåñÂèØËÉΩÂõ†Â∞èÂûãÊàñÂêåË¥®Ê†∑Êú¨ËÄå‰∫ßÁîüÁöÑÂÅèËßÅ„ÄÇ\n* Á§∫‰æãÔºöÈÄöËøáÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÊÉÖÊÑüÂàÜÊûêÔºå‰∏ÄÂÆ∂ÂÖ¨Âè∏ÂèØ‰ª•ÂÆûÁé∞Ê∂àË¥πËÄÖÊÉÖÊÑüËøΩË∏™ÂáÜÁ°ÆÊÄßÊØî‰∫∫Â∑•ÊñπÊ≥ïÊèêÈ´ò20%ÁöÑÁõÆÊ†áÔºå‰ªéËÄåÊõ¥ÂèØÈù†Âú∞È¢ÑÊµãÂ∏ÇÂú∫ÂèòÂåñ„ÄÇ\n\n### 4\\. ÂèØÊâ©Â±ïÊÄß‰∏éÁÅµÊ¥ªÊÄß\n\n* Â§ÑÁêÜÂ§ßÊï∞ÊçÆÈõÜÔºöAIÊ®°ÂûãÂèØ‰ª•Â§ÑÁêÜÂ∫ûÂ§ßÁöÑÊï∞ÊçÆÈõÜÔºåËÄå‰∏çÂèó‰º†ÁªüÁ†îÁ©∂ÁöÑÂèØÊâ©Â±ïÊÄßÈôêÂà∂Ôºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂàÜÊûêÂ§ßÂûãÂíåÂ§öÊ†∑ÁöÑÊï∞ÊçÆÊù•Ê∫êÔºå‰ª•Ëé∑ÂæóÂÖ®Èù¢ÁöÑËßÜËßí„ÄÇ\n* ÁÅµÊ¥ªÂ∫îÁî®ÔºöÁîüÊàêÂºèAIÂÖÅËÆ∏‰ºÅ‰∏öÊ†πÊçÆ‰∏çÊñ≠ÂèòÂåñÁöÑÁõÆÊ†áÊàñÊñ∞Êï∞ÊçÆÂÆûÊó∂Ë∞ÉÊï¥Á†îÁ©∂ÂèÇÊï∞ÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßç‰º†ÁªüÊñπÊ≥ïÈöæ‰ª•ÂÆûÁé∞ÁöÑÁÅµÊ¥ªÊÄß„ÄÇ\n* Á§∫‰æãÔºö‰∏Ä‰∏™ÂõΩÈôÖÂìÅÁâåÂèØ‰ª•ËøÖÈÄüÂú®Â§ö‰∏™ÂõΩÂÆ∂ÂíåËØ≠Ë®Ä‰∏≠Êâ©Â±ïÂÖ∂ÊÉÖÊÑüÂàÜÊûêÔºåÊ¥ûÂØüÂå∫ÂüüÊ∂àË¥πËÄÖÂ∑ÆÂºÇÔºåËÄåÊó†ÈúÄËøõË°åÂçïÁã¨ÁöÑ„ÄÅÂä≥Âä®ÂØÜÈõÜÂûãÁöÑÁ†îÁ©∂„ÄÇ\n\n### 5\\. ‰∏™ÊÄßÂåñ‰∏éÈíàÂØπÊÄßÊ¥ûÂØü\n\n* ÂÆöÂà∂Êä•ÂëäÔºöAIÂèØ‰ª•‰∏∫‰∏çÂêåÁöÑ‰∏öÂä°ËÅåËÉΩÔºà‰æãÂ¶ÇÔºåËê•ÈîÄ„ÄÅ‰∫ßÂìÅÂºÄÂèë„ÄÅÂÆ¢Êà∑ÊúçÂä°ÔºâÁîüÊàêÈáèË∫´ÂÆöÂà∂ÁöÑÊ¥ûÂØüÔºåÁ°Æ‰øùÊØè‰∏™Âõ¢ÈòüÊã•ÊúâÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆ‰ª•ÊîØÊåÅÂÜ≥Á≠ñ„ÄÇ\n* ÂÆûÊó∂ÁªÜÂàÜÔºöÁîüÊàêÂºèAIÊ®°ÂûãÂèØ‰ª•Âü∫‰∫éÂÆûÊó∂Êï∞ÊçÆÂØπÂÆ¢Êà∑ËøõË°åÁªÜÂàÜÔºå‰ªéËÄåÊèê‰æõÊõ¥Á≤æÁ°ÆÁöÑÁâπÂÆöÂèó‰ºóÊ¥ûÂØü„ÄÇ\n* Á§∫‰æãÔºö‰∏ÄÂÆ∂Èõ∂ÂîÆÂÖ¨Âè∏ÈÄöËøá‰ΩøÁî®ÁîüÊàêÂºèAIÂàõÂª∫‰∏éÈÄöËøáAIÈ©±Âä®ÁöÑÂ∏ÇÂú∫ÁªÜÂàÜËØÜÂà´Âá∫ÁöÑÁã¨ÁâπÂÆ¢Êà∑ÂÅèÂ•ΩÁõ∏‰∏ÄËá¥ÁöÑË∂Ö‰∏™ÊÄßÂåñÊ¥ªÂä®Ôºå‰ΩøÂπøÂëäÂèÇ‰∏éÂ∫¶ÊèêÈ´ò‰∫Ü30%„ÄÇ\n\n### 6\\. ÊàòÁï•ËßÑÂàíÁöÑÈ¢ÑÊµãÂáÜÁ°ÆÊÄß\n\n* ÊîπËøõÁöÑÈ¢ÑÊµãÔºöÂü∫‰∫éAIÁöÑÈ¢ÑÊµãÂàÜÊûêÂèØ‰ª•È´òÁ≤æÂ∫¶Âú∞È¢ÑÊµãË∂ãÂäøÔºåÂ∏ÆÂä©ÂÖ¨Âè∏È¢ÑËßÅÂ∏ÇÂú∫ÂèòÂåñÂπ∂‰∏∫ÊΩúÂú®ÁöÑÂπ≤Êâ∞ÂÅöÂ•ΩÂáÜÂ§á„ÄÇ\n* Â¢ûÂº∫ÁöÑÈ£éÈô©ÁÆ°ÁêÜÔºöÈ¢ÑÊµãÂÆ¢Êà∑Ë°å‰∏∫ÁöÑAIÊ®°ÂûãÂ∏ÆÂä©ÂÖ¨Âè∏‰∏ªÂä®Â∫îÂØπÂÆ¢Êà∑ÊµÅÂ§±„ÄÅÈúÄÊ±ÇÂèòÂåñÊàñË¥üÈù¢ÂìÅÁâåÊÉÖÁª™Á≠âÊåëÊàò„ÄÇ\n* Á§∫‰æãÔºö‰∏ÄÂÆ∂Âü∫‰∫éËÆ¢ÈòÖÁöÑÊúçÂä°‰ΩøÁî®ÁîüÊàêÂºèAIÔºåÈÄöËøáÊõ¥ÂáÜÁ°ÆÂú∞È¢ÑÊµãÊµÅÂ§±ÁéáÂπ∂ÂÆûÊñΩÂèäÊó∂Âπ≤È¢ÑÔºåÂÆûÁé∞‰∫Ü25%ÁöÑÂÆ¢Êà∑ÁïôÂ≠òÁéáÊèêÂçá„ÄÇ\n\n### 7\\. Êõ¥È´òÁöÑÊäïËµÑÂõûÊä•ÁéáÊù•Ëá™ÂèØÊìç‰ΩúÁöÑÊ¥ûÂØü\n\n* ‰ø°ÊÅØÈ©±Âä®ÁöÑÂÜ≥Á≠ñÔºöÂø´ÈÄü„ÄÅÂáÜÁ°Æ‰∏îÊï∞ÊçÆ‰∏∞ÂØåÁöÑÊ¥ûÂØü‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂÅöÂá∫Áõ¥Êé•ÂΩ±ÂìçÊî∂ÂÖ•ÁöÑÂÜ≥Á≠ñÔºå‰ªéËÄåÊèêÈ´òÂ∏ÇÂú∫Á†îÁ©∂ÊäïËµÑÁöÑÊäïËµÑÂõûÊä•Áéá„ÄÇ\n* ÂÆûÊó∂Ë∞ÉÊï¥ÔºöÈÄöËøáÂÆûÊó∂Â∏ÇÂú∫Êï∞ÊçÆÔºåÂÖ¨Âè∏ÂèØ‰ª•ÂÆûÊó∂‰ºòÂåñÂÖ∂Á≠ñÁï•ÔºåÁ´ãÂç≥ÂìçÂ∫îÂ∏ÇÂú∫ÂèòÂåñÂπ∂ÊèêÂçá‰∏öÁª©„ÄÇ\n* Á§∫‰æãÔºöÊüêÂìÅÁâåÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÊ¥ûÂØüÂú®‰∫ßÂìÅÂèëÂ∏É‰∏≠ÊúüË∞ÉÊï¥‰∫ßÂìÅÁâπÊÄßÔºåÂØºËá¥ÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ÊèêÈ´ò15%ÔºåÁ¨¨‰∏ÄÂ≠£Â∫¶Êî∂ÂÖ•Â¢ûÈïø10%„ÄÇ\n\n### ÂÆöÈáèÂõûÈ°æÔºöÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂‰∏≠ÁöÑÂÆûÈôÖÂΩ±Âìç\n\nÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂ÁöÑÂ§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÂèØÈáèÂåñÁöÑÂ•ΩÂ§ÑÔºö\n\n* Áî±‰∫éËá™Âä®ÂåñÂíåÂáèÂ∞ëÂØπ‰º†ÁªüË∞ÉÊü•ÁöÑ‰æùËµñÔºåÁ†îÁ©∂ÊàêÊú¨Èôç‰Ωé30‚Äì50%„ÄÇ\n* ÈÄöËøáAIÈ©±Âä®ÁöÑÂÆûÊó∂Â§ÑÁêÜÂíåËá™Âä®Êä•ÂëäÔºåÂàÜÊûêÊó∂Èó¥ÂáèÂ∞ë60‚Äì80%„ÄÇ\n* ÈÄöËøáÂà©Áî®AIÈ©±Âä®ÁöÑÂàÜÊûêÂíåÂáèÂ∞ëÂÅèËßÅÔºåÊï∞ÊçÆÂáÜÁ°ÆÊÄßÊèêÈ´ò20‚Äì30%„ÄÇ\n* ÈÄöËøáÈ¢ÑÊµãÊÄßAIÊ®°ÂûãÈ¢ÑÊµãÊ∂àË¥πËÄÖË°å‰∏∫ÔºåÂÆ¢Êà∑ÁïôÂ≠òÁéáÊèêÈ´ò25%„ÄÇ\n* ÈÄöËøáÂü∫‰∫éÂÆûÊó∂Êï∞ÊçÆËøõË°åÊõ¥Á≤æÁ°ÆÂíåÁÅµÊ¥ªÁöÑÂÜ≥Á≠ñÔºåÊî∂ÂÖ•Â¢ûÈïø10‚Äì15%„ÄÇ\n\n## ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂‰∏≠ÁöÑÊú™Êù•Ë∂ãÂäø\n\nÈöèÁùÄÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåÂÆÉÂ∞Ü‰∏∫Â∏ÇÂú∫Á†îÁ©∂È¢ÜÂüüÂ∏¶Êù•ÂèòÈù©ÊÄßÁöÑÂèòÂåñ„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÈ¢ÑËÆ°Â∞ÜÂ°ëÈÄ†AIÈ©±Âä®Â∏ÇÂú∫ÊÉÖÊä•Êú™Êù•ÁöÑÊñ∞ÂÖ¥Ë∂ãÂäøÔºö\n\n### 1\\. ÂÆûÊó∂„ÄÅÊåÅÁª≠ÁöÑÂ∏ÇÂú∫ÁõëÊµã\n\n* Ë∂ãÂäøÊ¶ÇËø∞Ôºö‰∏é‰æùËµñÂÆöÊúüË∞ÉÊü•ÂíåÊä•Âëä‰∏çÂêåÔºåÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜÂÆûÁé∞ÂØπÊ∂àË¥πËÄÖÊÉÖÁª™„ÄÅÁ´û‰∫âÂØπÊâãË°å‰∏∫ÂíåÂ∏ÇÂú∫Ë∂ãÂäøÁöÑÊåÅÁª≠ÂÆûÊó∂ÁõëÊµã„ÄÇ\n* ÂΩ±ÂìçÔºöËøôÁßçËΩ¨Âèò‰ΩøÂìÅÁâåËÉΩÂ§üÂç≥Êó∂ÂØπÂ∏ÇÂú∫ÂèòÂåñ‰ΩúÂá∫ÂèçÂ∫îÔºåÊúÄÂ∞èÂåñÊï∞ÊçÆÊî∂ÈõÜ‰∏éË°åÂä®‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇÊåÅÁª≠ÁöÑÊ¥ûÂØü‰πüÊúâÂä©‰∫éÊõ¥Â•ΩÁöÑÈ¢ÑÊµãÂíåÁÅµÊ¥ªÁöÑÂÜ≥Á≠ñ„ÄÇ\n* Á§∫‰æãÔºö‰∏ÄÂÆ∂Êó∂Â∞öÈõ∂ÂîÆÂïÜÂèØ‰ª•ÂÆûÊó∂Ë∑üË∏™Ê∂àË¥πËÄÖÂÅèÂ•ΩÁöÑÂèòÂåñÔºåÂπ∂Âá†‰πéÁ´ãÂç≥Ë∞ÉÊï¥Â∫ìÂ≠ò„ÄÅËê•ÈîÄÂíåÂÆö‰ª∑Á≠ñÁï•„ÄÇ\n\n### 2\\. ÈÄöËøáË∂ÖÁâπÂÆöÂèó‰ºóÁªÜÂàÜÂÆûÁé∞‰∏™ÊÄßÂåñÂ¢ûÂº∫\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜÊèêÂçáÊ†πÊçÆË°å‰∏∫„ÄÅ‰∫∫Âè£ÁªüËÆ°ÂíåÂøÉÁêÜÁâπÂæÅÊï∞ÊçÆÂ∞ÜÂèó‰ºóÁªÜÂàÜ‰∏∫È´òÂ∫¶ÁâπÂÆöÁªÜÂàÜÂ∏ÇÂú∫ÁöÑËÉΩÂäõ„ÄÇ\n* ÂΩ±ÂìçÔºöËê•ÈîÄ‰∫∫ÂëòÂ∞ÜËÉΩÂ§üÈíàÂØπÂæÆÁªÜÂàÜÂ∏ÇÂú∫ÂÆöÂà∂‰ø°ÊÅØÂíå‰∫ßÂìÅÔºåÊèêÈ´ò‰∏éÊØè‰∏™Ê∂àË¥πËÄÖÁöÑÁõ∏ÂÖ≥ÊÄßÂíåÂèÇ‰∏éÂ∫¶„ÄÇ\n* Á§∫‰æãÔºö‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•‰∏∫ÁâπÂÆöÁæ§‰ΩìÂàõÂª∫‰∏™ÊÄßÂåñÊ¥ªÂä®Ôºå‰æãÂ¶ÇÂØπÂèØÊåÅÁª≠Êó∂Â∞öÊÑüÂÖ¥Ë∂£ÁöÑÁîüÊÄÅÊÑèËØÜÂçÉÁ¶ß‰∏Ä‰ª£Ôºå‰ªéËÄå‰ºòÂåñÂèÇ‰∏éÂ∫¶ÂíåËΩ¨ÂåñÁéá„ÄÇ\n\n### 3\\. ‰ΩøÁî®Â§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÊàêÂ¢ûÂº∫È¢ÑÊµãËÉΩÂäõ\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÊú™Êù•ÁöÑÁîüÊàêÊÄßAIÂ∑•ÂÖ∑Â∞ÜÂàÜÊûêÂ§öÊ®°ÊÄÅÊï∞ÊçÆÊ∫ê‚Äî‚ÄîÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅËßÜÈ¢ëÂíåËØ≠Èü≥‚Äî‚Äî‰ª•Êèê‰æõÊõ¥Ê∑±ÂÖ•ÁöÑÊ¥ûÂØüÂíåÊõ¥ÂáÜÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇ\n* ÂΩ±ÂìçÔºöÊï¥ÂêàÂ§öÁßçÊï∞ÊçÆÁ±ªÂûãÊèê‰æõ‰∫ÜÂ∏ÇÂú∫Ë∂ãÂäøÂíåÊ∂àË¥πËÄÖÂÅèÂ•ΩÁöÑÊõ¥ÂÖ®Èù¢ËßÜËßíÔºå‰ªéËÄåËÉΩÂ§üËøõË°åÊõ¥ÁªÜËá¥ÁöÑÈ¢ÑÊµã„ÄÇ\n* Á§∫‰æãÔºö‰∏Ä‰∏™ÁæéÂÆπÂìÅÁâåÂèØ‰ª•ÂàÜÊûêÁ§æ‰∫§Â™í‰ΩìÂõæÂÉè„ÄÅÊñáÊú¨ÂíåÂΩ±ÂìçËÄÖËßÜÈ¢ëÔºå‰ª•È¢ÑÊµãÂç≥Â∞ÜÂà∞Êù•ÁöÑÂ≠£ËäÇÊµÅË°åÁöÑÈ¢úËâ≤ÂíåÈ£éÊ†º„ÄÇ\n\n### 4\\. Â∏ÇÂú∫Ê®°Êãü‰∏éÊµãËØïÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàê\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜË∂äÊù•Ë∂äÂ§öÂú∞Áî®‰∫éÂàõÂª∫Ê®°ÊãüÁúüÂÆû‰∏ñÁïåÊ∂àË¥πËÄÖË°å‰∏∫ÁöÑÂêàÊàêÊï∞ÊçÆÔºå‰ΩøÂìÅÁâåËÉΩÂ§üÂú®‰∏çÂ∞Ü‰∫ßÂìÅÂíåÊ¥ªÂä®ÂèëÂ∏ÉÂà∞Â∏ÇÂú∫ÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÊµãËØï„ÄÇ\n* ÂΩ±ÂìçÔºöÂêàÊàêÊï∞ÊçÆÂèØ‰ª•ÈÄöËøáÂÖÅËÆ∏ÂìÅÁâåÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠ËØÑ‰º∞Ê∂àË¥πËÄÖÂèçÂ∫îÂíå‰ºòÂåñÊ¥ªÂä®Ôºå‰ªéËÄåÈôç‰ΩéÂ∏ÇÂú∫ÊµãËØïÁöÑÈ£éÈô©ÂíåÊàêÊú¨„ÄÇ\n* Á§∫‰æãÔºö‰∏Ä‰∏™Êñ∞ÁöÑÈ•ÆÊñôÂìÅÁâåÂèØËÉΩ‰ºö‰ΩøÁî®ÂêàÊàêÊï∞ÊçÆÊù•ÊµãËØïÊ∂àË¥πËÄÖÂØπ‰∏çÂêåÂåÖË£ÖËÆæËÆ°ÁöÑÂèçÂ∫îÔºå‰ªéËÄåÂáèÂ∞ë‰∏é‰º†ÁªüÁÑ¶ÁÇπÂ∞èÁªÑÁõ∏ÂÖ≥ÁöÑÊó∂Èó¥ÂíåÊàêÊú¨„ÄÇ\n\n### 5\\. Ëá™Âä®ÂåñÊ¥ûÂØü‰∏éÂÜ≥Á≠ñÊîØÊåÅ\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜÊúùÁùÄËá™‰∏ªÊ¥ûÂØüÁîüÊàêÁöÑÊñπÂêëÂèëÂ±ïÔºåÂ∑•ÂÖ∑ËÉΩÂ§üÂü∫‰∫éÂÆûÊó∂Â∏ÇÂú∫Êï∞ÊçÆÊé®ËçêË°åÂä®„ÄÇ\n* ÂΩ±ÂìçÔºöËá™Âä®ÂåñÊ¥ûÂØüÈáäÊîæ‰∫ÜËµÑÊ∫êÔºå‰Ωø‰ºÅ‰∏öËÉΩÂ§üÂÅöÂá∫Êõ¥Âø´ÈÄü„ÄÅÂü∫‰∫éÊï∞ÊçÆÁöÑÂÜ≥Á≠ñ„ÄÇ\n* Á§∫‰æãÔºö‰∏Ä‰∏™‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑‰∏ç‰ªÖÂèØËÉΩÊ†áËÆ∞Âá∫Ê∂àË¥πËÄÖÊÉÖÁª™ÁöÑ‰∏ãÈôçÔºåËøòÂèØËÉΩÂª∫ËÆÆËøõË°åËê•ÈîÄË∞ÉÊï¥Êàñ‰∫ßÂìÅÊõ¥Êñ∞‰ª•Â∫îÂØπËØ•ÈóÆÈ¢ò„ÄÇ\n\n### 6\\. ‰º¶ÁêÜ‰∫∫Â∑•Êô∫ËÉΩ‰∏éÂ¢ûÂº∫ÁöÑÊï∞ÊçÆÈöêÁßÅ\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÈöèÁùÄÂØπ‰º¶ÁêÜ‰∫∫Â∑•Êô∫ËÉΩÁöÑÈáçËßÜÔºåÊú™Êù•ÁöÑÂ∏ÇÂú∫Á†îÁ©∂Â∑•ÂÖ∑Â∞Ü‰ºòÂÖàËÄÉËôëÈÄèÊòéÂ∫¶„ÄÅË¥üË¥£‰ªªÁöÑÊï∞ÊçÆ‰ΩøÁî®ÂíåÈÅµÂÆàÈöêÁßÅÊ≥ïËßÑ„ÄÇ\n* ÂΩ±ÂìçÔºöÊ∂àË¥πËÄÖÂú®‰∏éÂÆûË∑µ‰º¶ÁêÜ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂìÅÁâåÂàÜ‰∫´Êï∞ÊçÆÊó∂‰ºöÊÑüÂà∞Êõ¥Êúâ‰ø°ÂøÉÔºåÂêåÊó∂ÂìÅÁâå‰πüËÉΩÈÅøÂÖç‰∏éÊï∞ÊçÆÊª•Áî®Áõ∏ÂÖ≥ÁöÑÊ≥ïÂæãÂíåÂ£∞Ë™âÈ£éÈô©„ÄÇ\n* Á§∫‰æãÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑ÂèØËÉΩ‰ºöÁ∫≥ÂÖ•Á°Æ‰øùÈÅµÂÆàÈöêÁßÅÊ≥ïÂæãÁöÑÂäüËÉΩÔºåÂπ∂ÂÖÅËÆ∏Ê∂àË¥πËÄÖÂêåÊÑèÊï∞ÊçÆÁöÑÊî∂ÈõÜÂíå‰ΩøÁî®„ÄÇ\n\n### 7\\. ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰ª•Ëé∑ÂèñÊõ¥Ê∑±ÂÖ•ÁöÑ‰∫íÂä®Ê∂àË¥πËÄÖÊ¥ûÂØü\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜÂèëÂ±ï‰ª•‰øÉËøõÂä®ÊÄÅ„ÄÅ‰∫íÂä®ÁöÑË∞ÉÊü•ÂíåÂèçÈ¶àÊî∂ÈõÜÔºå‰ΩøÂìÅÁâåËÉΩÂ§üÁõ¥Êé•‰ªéÊ∂àË¥πËÄÖÈÇ£ÈáåËé∑ÂèñÊõ¥Ê∑±ÂÖ•ÁöÑÊ¥ûÂØü„ÄÇ\n* ÂΩ±ÂìçÔºöÂÆûÊó∂ÁöÑÂØπËØùÂèçÈ¶àÂÖÅËÆ∏Êõ¥ÁúüÂÆûÁöÑÊ¥ûÂØüÂíåÊõ¥È´òÁöÑÂèÇ‰∏éÁéáÔºåÁâπÂà´ÊòØÂú®Êï∞Â≠óÂéüÁîüÊ∂àË¥πËÄÖ‰∏≠„ÄÇ\n* Á§∫‰æãÔºö‰∏Ä‰∏™ÁßëÊäÄÂìÅÁâåÂèØ‰ª•ÈÉ®ÁΩ≤ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰∏éÊ∂àË¥πËÄÖËøõË°åÂØπËØùÔºåÊî∂ÈõÜÈùôÊÄÅË∞ÉÊü•ÂèØËÉΩÈÅóÊºèÁöÑÁªÜÂæÆÊ¥ûÂØü„ÄÇ\n\n### 8\\. Â¢ûÂº∫Áé∞ÂÆûÔºàARÔºâÂíåËôöÊãüÁé∞ÂÆûÔºàVRÔºâÂ∏ÇÂú∫Á†îÁ©∂\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÂü∫‰∫éÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁöÑARÂíåVRÁéØÂ¢ÉÂ∞ÜÊàê‰∏∫Ê≤âÊµ∏ÂºèÂ∏ÇÂú∫Á†îÁ©∂ÁöÑÂ∏∏Áî®Â∑•ÂÖ∑Ôºå‰ΩøÊ∂àË¥πËÄÖËÉΩÂ§ü‰∏éËôöÊãü‰∫ßÂìÅÂíåÁéØÂ¢É‰∫íÂä®„ÄÇ\n* ÂΩ±ÂìçÔºöËØ•ÊäÄÊúØ‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂú®ÈÄºÁúüÁöÑËôöÊãüÁéØÂ¢É‰∏≠ÊµãËØï‰∫ßÂìÅÊ¶ÇÂøµÔºå‰ª•Âºï‰∫∫ÂÖ•ËÉúÁöÑÊñπÂºèÊî∂ÈõÜË°å‰∏∫Êï∞ÊçÆÂíåÊ∂àË¥πËÄÖÂèçÈ¶à„ÄÇ\n* Á§∫‰æãÔºö‰∏ÄÂÆ∂ÂÆ∂ÂÖ∑Èõ∂ÂîÆÂïÜÂèØ‰ª•‰ΩøÁî®VRÁéØÂ¢ÉÂêëÂÆ¢Êà∑Â±ïÁ§∫ÂïÜÂìÅÂú®‰ªñ‰ª¨Ëá™Â∑±Á©∫Èó¥‰∏≠ÁöÑÊ†∑Â≠êÔºåÊî∂ÈõÜÂÖ≥‰∫é‰∫ßÂìÅËÆæËÆ°ÂíåÂèØÁî®ÊÄßÁöÑÂèçÈ¶à„ÄÇ\n\n### 9\\. ‰∫∫Â∑•Êô∫ËÉΩ‰∏é‰∫∫Á±ªÂçè‰ΩúÁ†îÁ©∂Ê®°Âûã\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÊú™Êù•ÁöÑÂ∏ÇÂú∫Á†îÁ©∂ÂèØËÉΩ‰ºöÊ∂âÂèäÂ∞Ü‰∫∫Á±ª‰∏ì‰∏öÁü•ËØÜ‰∏é‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑËá™Âä®ÂåñÁõ∏ÁªìÂêàÁöÑÊ∑∑ÂêàÊ®°ÂûãÔºåÁ†îÁ©∂‰∫∫ÂëòË¥üË¥£ÁõëÁù£‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêÁöÑÊ¥ûÂØüÔºåÂπ∂ÂØπÂèëÁé∞ËøõË°åÊÉÖÂ¢ÉÂåñÂ§ÑÁêÜ„ÄÇ\n* ÂΩ±ÂìçÔºö‰∫∫Á±ªÁöÑÁõëÁù£Á°Æ‰øù‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêÁöÑÊ¥ûÂØüÁöÑË¥®ÈáèÂíå‰º¶ÁêÜ‰ΩøÁî®ÔºåÂ¢ûÂä†‰∫Ü‰∏ÄÂ±ÇÂà§Êñ≠Âíå‰∏ì‰∏öÁü•ËØÜÔºåËÄå‰ªÖÈù†‰∫∫Â∑•Êô∫ËÉΩÂèØËÉΩÁº∫‰πèËøô‰∫õ„ÄÇ\n* Á§∫‰æãÔºö‰∫∫Â∑•Êô∫ËÉΩÂèØËÉΩÁîüÊàêÂÖ≥‰∫éÊñ∞ÂÖ¥Â∏ÇÂú∫Ë∂ãÂäøÁöÑÊä•ÂëäÔºåËÄåÁ†îÁ©∂‰∫∫ÂëòÂàôÈ™åËØÅÂèëÁé∞Âπ∂Ê∑ªÂä†ÂÆöÊÄßÊ¥ûÂØüÔºåÁ°Æ‰øùÂèØÊìç‰ΩúÂíå‰º¶ÁêÜÁöÑÂÜ≥Á≠ñ„ÄÇ\n\n### 10\\. Á´ØÂà∞Á´Ø AI Âπ≥Âè∞Áî®‰∫éÁªºÂêàÂ∏ÇÂú∫ÊÉÖÊä•\n\n* Ë∂ãÂäøÊ¶ÇËø∞ÔºöÈöèÁùÄÁîüÊàêÊÄß AI Â∑•ÂÖ∑ÁöÑÂèëÂ±ïÔºåË∂äÊù•Ë∂äÂ§öÁöÑÂπ≥Âè∞Â∞ÜÊèê‰æõÁ´ØÂà∞Á´ØÁöÑËÉΩÂäõÔºåÂåÖÊã¨Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÂàÜÊûê„ÄÅÊ¥ûÂØüÁîüÊàêÂíåÊàòÁï•Âª∫ËÆÆ‚Äî‚ÄîÊâÄÊúâËøô‰∫õÈÉΩÂú®‰∏Ä‰∏™Âçï‰∏ÄÁöÑÁîüÊÄÅÁ≥ªÁªü‰∏≠„ÄÇ\n* ÂΩ±ÂìçÔºöËøô‰∫õÁªºÂêàÂπ≥Âè∞ÁÆÄÂåñ‰∫ÜÂ∏ÇÂú∫Á†îÁ©∂Â∑•‰ΩúÊµÅÁ®ãÔºåÂáèÂ∞ë‰∫ÜÂØπÂ§ö‰∏™Â∑•ÂÖ∑ÁöÑ‰æùËµñÔºå‰ΩøÂìÅÁâåÊõ¥ÂÆπÊòìËé∑ÂèñÂÖ®Èù¢ÁöÑ„ÄÅÂèØÊìç‰ΩúÁöÑÊ¥ûÂØü„ÄÇ\n* Á§∫‰æãÔºö‰∏Ä‰∏™ÁªºÂêàÂπ≥Âè∞ÂèØ‰ª•Â§ÑÁêÜ‰ªéÁ§æ‰∫§ËÅÜÂê¨ÂíåÁ´û‰∫âÂØπÊâãÂàÜÊûêÂà∞ÂÆ¢Êà∑ÁªÜÂàÜÂíåÊ¥ªÂä®Âª∫ËÆÆÁöÑÊâÄÊúâÂÜÖÂÆπÔºåËÆ©ÂìÅÁâå‰∏ìÊ≥®‰∫éÊâßË°åËÄå‰∏çÊòØÊï∞ÊçÆÂ§ÑÁêÜ„ÄÇ\n\n## ÁªìËÆ∫\n\nÂ∞ÜÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩËûçÂÖ•Â∏ÇÂú∫Á†îÁ©∂ÂíåÊÉÖÊä•ÊµÅÁ®ãÔºå‰ΩøÁªÑÁªáËÉΩÂ§ü‰ª•Á©∫ÂâçÁöÑÈÄüÂ∫¶Ëé∑ÂæóÂèØÊìç‰ΩúÁöÑÊ¥ûÂØü„ÄÇÈÄöËøáËá™Âä®ÂåñÊï∞ÊçÆÊî∂ÈõÜÂíåÂàÜÊûêÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂáèÂ∞ë‰∫Ü‰∫∫‰∏∫ÈîôËØØÔºåÊèêÈ´ò‰∫ÜÁ≤æÁ°ÆÂ∫¶ÔºåÂπ∂ÂºÄËæü‰∫ÜÊõæÁªèÂõ†Êó∂Èó¥ÈôêÂà∂ËÄåÊó†Ê≥ïÊé¢Á¥¢ÁöÑÊñ∞Â∏ÇÂú∫ÂèëÁé∞ÈÄîÂæÑ„ÄÇËøô‰∫õÂ∑•ÂÖ∑‰∏ç‰ªÖÁÆÄÂåñ‰∫ÜÁ†îÁ©∂ËøáÁ®ãÔºåËøò‰∏∞ÂØå‰∫ÜÂÜ≥Á≠ñËøáÁ®ãÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÂú®Âø´ÈÄüÂèòÂåñÁöÑÂ∏ÇÂú∫‰∏≠‰øùÊåÅÈÄÇÂ∫îÊÄß„ÄÇ\n\nÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑËøõÊ≠•ÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂèØËÉΩ‰ºöÊàê‰∏∫Â∏ÇÂú∫Á†îÁ©∂‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÈááÁî®ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÖ¨Âè∏ÂèØ‰ª•ÊúüÂæÖÂú®È¢ÑÊµãÂáÜÁ°ÆÊÄß„ÄÅÁ´û‰∫âÂØπÊâãÂàÜÊûêÂíåÂÆ¢Êà∑ÁêÜËß£ÊñπÈù¢ÊòæËëóÊîπÂñÑ„ÄÇÁÑ∂ËÄåÔºåÊàêÂäüÁöÑÈááÁî®ÈúÄË¶Å‰∏ÄÁßçÊàòÁï•ÊñπÊ≥ïÔºå‰ºòÂÖàËÄÉËôëÊúÄÁõ∏ÂÖ≥ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑ÔºåÂπ∂Êï¥Âêà‰∫∫Á±ª‰∏ì‰∏öÁü•ËØÜ‰ª•Á°Æ‰øùË¥®ÈáèÊéßÂà∂ÂíåËß£ËØª„ÄÇÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ‰ª£Ë°®‰∫Ü‰∏ÄÁßçÂä®ÊÄÅÂíå‰∏çÊñ≠ÂèëÂ±ïÁöÑÂ∑•ÂÖ∑ÈõÜÔºåÂΩìÊúâÊïà‰ΩøÁî®Êó∂ÔºåÂèØ‰ª•Â°ëÈÄ†Â∏ÇÂú∫ÊÉÖÊä•ÁöÑÊú™Êù•Âπ∂Êé®Âä®ÂèØÊåÅÁª≠Â¢ûÈïø„ÄÇ\n\n## Â∏∏ËßÅÈóÆÈ¢òËß£Á≠î\n\n1. ‰ªÄ‰πàÊòØÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÔºåÂÆÉÂ¶Ç‰ΩïÂ∫îÁî®‰∫éÂ∏ÇÂú∫Á†îÁ©∂Ôºü\nÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂà©Áî®Êú∫Âô®Â≠¶‰π†ÂàÜÊûêÂ§ßÂûãÊï∞ÊçÆÈõÜÂπ∂ÁîüÊàêÊ¥ûÂØüÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Âø´ÈÄü„ÄÅÊõ¥ÂÖ®Èù¢ÁöÑÂ∏ÇÂú∫Á†îÁ©∂ÂíåÈ¢ÑÊµãÂàÜÊûê„ÄÇ\n2. Âú®Â∏ÇÂú∫ÊÉÖÊä•‰∏≠‰ΩøÁî®ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúâÂì™‰∫õÂ•ΩÂ§ÑÔºü\nÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊèêÈ´ò‰∫ÜÊï∞ÊçÆÂáÜÁ°ÆÊÄßÔºåÂáèÂ∞ë‰∫ÜÊï∞ÊçÆÊî∂ÈõÜÊâÄËä±Ë¥πÁöÑÊó∂Èó¥ÔºåÂπ∂ÈÄöËøáÊèê‰æõÊõ¥Ê∑±ÂÖ•ÁöÑÊ¥ûÂØüÂíåË∂ãÂäøÈ¢ÑÊµãÊù•Â¢ûÂº∫ÂÜ≥Á≠ñËÉΩÂäõ„ÄÇ\n3. ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩËÉΩÂê¶Âèñ‰ª£‰º†ÁªüÂ∏ÇÂú∫Á†îÁ©∂ÊñπÊ≥ïÔºü\nËôΩÁÑ∂ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•Ëá™Âä®ÂåñËÆ∏Â§öÊñπÈù¢Ôºå‰ΩÜ‰∫∫Á±ª‰∏ì‰∏öÁü•ËØÜÂú®‰∏ä‰∏ãÊñáËß£Èáä„ÄÅË¥®ÈáèÊéßÂà∂ÂíåÁªÜËá¥ÂàÜÊûê‰∏≠‰ªçÁÑ∂Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n4. ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂú®Â∏ÇÂú∫Á†îÁ©∂‰∏≠ÁöÑ‰∏Ä‰∫õÂ∫îÁî®Ê°à‰æãÊòØ‰ªÄ‰πàÔºü\nÂ∫îÁî®Ê°à‰æãÂåÖÊã¨Ë∂ãÂäøÈ¢ÑÊµã„ÄÅÁ´û‰∫âÂØπÊâãÂàÜÊûê„ÄÅÂÆ¢Êà∑ÊÉÖÊÑüÂàÜÊûêÔºå‰ª•ÂèäÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁîüÊàêÂ∏ÇÂú∫Ê¥ûÂØü„ÄÇ\n5. ‰ºÅ‰∏öÂ¶Ç‰ΩïÂºÄÂßãÂú®Â∏ÇÂú∫Á†îÁ©∂‰∏≠‰ΩøÁî®ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÔºü\nÈ¶ñÂÖàËØÜÂà´Á†îÁ©∂‰∏≠AIÂèØ‰ª•ÊèêÂçáÁöÑÂÖ≥ÈîÆÈ¢ÜÂüüÔºåÁÑ∂ÂêéÈÄâÊã©ÂêàÈÄÇÁöÑÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑ÔºåÂπ∂Âú®‰∏ìÂÆ∂ÁõëÁù£‰∏ãÂ∞ÜÂÖ∂ÈõÜÊàêÂà∞Áé∞ÊúâÂ∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/get-chatgpt-to-sound-more-human-essential-tips-for-creating-natural-engaging-ai-conversations-c361bc2680bb","frontmatter":{"title":"ËÆ© ChatGPT Âê¨Ëµ∑Êù•Êõ¥Êúâ‰∫∫ÊÉÖÂë≥ÔºöÂàõÂª∫Ëá™ÁÑ∂„ÄÅÂºï‰∫∫ÂÖ•ËÉúÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂØπËØùÁöÑÂü∫Êú¨ÊäÄÂ∑ß","meta_title":"ËÆ© ChatGPT Âê¨Ëµ∑Êù•Êõ¥Êúâ‰∫∫ÊÉÖÂë≥ÔºöÂàõÂª∫Ëá™ÁÑ∂„ÄÅÂºï‰∫∫ÂÖ•ËÉúÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂØπËØùÁöÑÂü∫Êú¨ÊäÄÂ∑ß","description":"‰∏∫‰∫ÜËÆ© ChatGPT ÁöÑÂØπËØùÊõ¥Ëá™ÁÑ∂‰∏îÂºï‰∫∫ÂÖ•ËÉúÔºåÂèØ‰ª•ÈááÂèñ‰ª•‰∏ãÁ≠ñÁï•ÔºöÈôêÂà∂ËøáÂ∫¶‰ΩøÁî®ÁöÑËØçÊ±áÂíåÁü≠ËØ≠Ôºå‰øùÊåÅËØ≠Ë®ÄÁÆÄÂçïÊòé‰∫ÜÔºåË∞ÉÊï¥ËØ≠Ê∞î‰ª•ÂåπÈÖç‰∏ä‰∏ãÊñáÔºåÂ¢ûÂº∫‰∫íÂä®ÊÄß‰∏é‰∫≤ÂíåÂäõÔºåÂπ∂‰ΩøÁî®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰æãÂ≠êÂíåÁõ¥Êé•ÈôàËø∞„ÄÇËøô‰∫õÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÂáèÂ∞ëÊú∫Ê¢∞ÊÑüÔºå‰Ωø AI ÁöÑÂõûÂ∫îÊõ¥ÂÖ∑‰∫∫ÊÄßÂåñÂíåÂÆûÁî®ÊÄß„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wdWBBG4fJhHVwdoDelYkkQ.png","categories":["Chatbots","Natural Language Processing","Programming/Scripting"],"author":"Rifx.Online","tags":["ChatGPT","responses","human","engaging","clarity"],"draft":false,"slug":"blog/get-chatgpt-to-sound-more-human-essential-tips-for-creating-natural-engaging-ai-conversations-c361bc2680bb"},"content":"\n\n\n\n\n‰Ω†ÊòØÂê¶ÂèëÁé∞‰Ω†ÁöÑ AI Âä©ÊâãÂê¨Ëµ∑Êù•ÊúâÁÇπËøá‰∫é‚Ä¶‚Ä¶Êú∫Ê¢∞ÔºüËôΩÁÑ∂ ChatGPT ÁöÑËÉΩÂäõ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÔºå‰ΩÜÊúâÊó∂ÂÆÉÁöÑËØ≠Ë®ÄËøá‰∫éÊ≠£ÂºèÊàñÈÄöÁî®„ÄÇ‰ΩÜÈÄöËøá‰∏Ä‰∫õË∞ÉÊï¥Ôºå‰Ω†ÂèØ‰ª•ÂºïÂØº ChatGPT ÁªôÂá∫Êõ¥‰∫∫ÊÄßÂåñ„ÄÅÂØπËØùÂºèÂíåÊòì‰∫éÂÖ±È∏£ÁöÑÂõûÂ∫î„ÄÇ\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∏™ÂÆûÁî®ÊåáÂçóÔºåÂ∏ÆÂä© ChatGPT Âê¨Ëµ∑Êù•‰∏çÈÇ£‰πàÂÉèÊú∫Âô®‰∫∫ÔºåËÄåÊõ¥ÂÉè‰∏Ä‰∏™ÂçöÂ≠¶ÁöÑÊúãÂèã„ÄÇ\n\n## 1\\. ÈôêÂà∂ËøáÂ∫¶‰ΩøÁî®ÁöÑËØçÊ±áÂíåÁü≠ËØ≠\n\nÊüê‰∫õËØçÊ±áÂíåÁü≠ËØ≠Âú®AIÁîüÊàêÁöÑÊñáÊú¨‰∏≠ÁªèÂ∏∏Âá∫Áé∞ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Â§öÂäüËÉΩ‰∏îÂÆâÂÖ®Ôºå‰ΩÜÂèØËÉΩÊòæÂæó‰∏çÂ§ü‰∏™ÊÄßÂåñÂíåÊ®°Á≥ä„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÁªèÂ∏∏Âá∫Áé∞ÁöÑËØçÊ±áÔºö\n\n**ËøáÂ∫¶‰ΩøÁî®ÁöÑËøáÊ∏°ËØç**\n\n* ÈºìÂä±ChatGPT‰ΩøÁî®Êõ¥ÁÆÄÂçï„ÄÅÊõ¥Ëá™ÁÑ∂ÁöÑÊõø‰ª£ËØçÔºåÂ¶Ç‚Äú‰πü‚ÄùÊàñ‚Äú‰ΩÜÊòØ‚ÄùÔºåËÄå‰∏çÊòØ‚ÄúÊ≠§Â§ñ‚Äù„ÄÅ‚ÄúÂõ†Ê≠§‚ÄùÊàñ‚ÄúÁÑ∂ËÄå‚Äù„ÄÇ\n\n**Â∏∏Áî®ÂΩ¢ÂÆπËØçÂíåÂêçËØç**\n\n* Â∏∏ËßÅÁöÑÂΩ¢ÂÆπËØçÂ¶Ç‚ÄúÂàõÊñ∞ÁöÑ‚Äù„ÄÅ‚ÄúÂº∫Â§ßÁöÑ‚ÄùÂíå‚ÄúÂä®ÊÄÅÁöÑ‚ÄùËôΩÁÑ∂ÂèØ‰ª•‰ΩøÁî®Ôºå‰ΩÜÂèØËÉΩÂê¨Ëµ∑Êù•ÊØîËæÉÊôÆÈÄö„ÄÇÈºìÂä±ChatGPT‰ΩøÁî®Êõ¥ÂÖ∑‰ΩìÁöÑÊèèËø∞ËØç„ÄÇÂêåÊ†∑ÔºåÂÉè‚ÄúÊïàÁéá‚Äù„ÄÅ‚Äú‰ºòÂåñ‚ÄùÂíå‚ÄúËΩ¨Âûã‚ÄùËøôÊ†∑ÁöÑÊäΩË±°ÂêçËØçÈÄöÂ∏∏ÂèØ‰ª•Áî®‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑÂÖ∑‰ΩìÊúØËØ≠Êù•Êõø‰ª£„ÄÇ\n\n**Â∏∏ËßÅÂä®ËØçÂíåÁü≠ËØ≠**\n\n* ÂÉè‚ÄúËØÅÊòé‰∫Ü‚Ä¶‚Ä¶‚ÄùËøôÊ†∑ÁöÑÁü≠ËØ≠ÈôàËØçÊª•Ë∞ÉÔºå‰ª•Âèä‚Äú‰øÉËøõ‚ÄùÊàñ‚ÄúÊúÄÂ§ßÂåñ‚ÄùÁ≠âÂä®ËØçÔºåÂèØËÉΩÂê¨Ëµ∑Êù•ÂæàÂÖ¨ÂºèÂåñ„ÄÇÁî®‚ÄúÂ∏ÆÂä©‚Äù„ÄÅ‚ÄúÊîπÂñÑ‚ÄùÊàñ‚ÄúÂ¢ûÂä†‚ÄùÁ≠âÁÆÄÂçïÂä®ËØçÊõøÊç¢ÂÆÉ‰ª¨ÔºåÂèØ‰ª•Â¢ûÊ∑ªËá™ÁÑ∂„ÄÅÂØπËØùÂºèÁöÑÊÑüËßâ„ÄÇ\n\n‰ª•‰∏ãÊòØËøô‰∫õÊåáÁ§∫ÁöÑÂÆûÈôÖÂ∫îÁî®Á§∫‰æãÔºö\n\n**‰πãÂâç:**‚ÄúÊÄª‰πãÔºåÂà©Áî®Êï∞ÊçÆÈ©±Âä®ÁöÑÊ¥ûÂØü‰øÉËøõ‰∫ÜÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑ‰ºòÂåñ„ÄÇ‚Äù\n\n**‰πãÂêé:**‚ÄúÊÄªÁªì‰∏Ä‰∏ãÔºåÊúâÊïàÂà©Áî®Êï∞ÊçÆÂ∏ÆÂä©‰ºÅ‰∏öÂÅöÂá∫Êõ¥Â•ΩÁöÑÂÜ≥Á≠ñ„ÄÇ‚Äù\n\n## 2\\. Êã•Êä±ËØ≠Ë®ÄÁöÑÁÆÄÂçïÊÄßÂíåÊ∏ÖÊô∞ÊÄß\n\n**‰øùÊåÅÁÆÄÂçïÊòé‰∫Ü**\n\n* ChatGPT ÁªèÂ∏∏‰ΩøÁî®Â§çÊùÇÁöÑÂè•Â≠êÂíåÊ≠£ÂºèÁöÑËØ≠Ë®ÄÔºåËøôÂèØËÉΩ‰ºöÂú®Áî®Êà∑Âíå‰ø°ÊÅØ‰πãÈó¥ÈÄ†ÊàêÈöúÁ¢ç„ÄÇÈºìÂä±‰ΩøÁî®Êõ¥ÁÆÄÂçïÁöÑÂè•Â≠êÁªìÊûÑÂíåÁõ¥Êé•ÁöÑËØ≠Ë®ÄÔºå‰ΩøÂõûÂ∫îÊõ¥Âä†Ê∏ÖÊô∞ÂíåÊòì‰∫éÊé•Ëøë„ÄÇ\n\n**ÈôêÂà∂Ê®°Á≥äÁöÑÈôàËø∞**\n\n* Â¶ÇÊûúÊüê‰∫õÂÜÖÂÆπÂê¨Ëµ∑Êù•Ê®°Á≥äÔºåÊèêÁ§∫ ChatGPT Ê∑ªÂä†ÂÖ∑‰ΩìÁªÜËäÇ„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Áõ¥Êé•ËØ¥ÊòéÂ∫îËØ•ËÄÉËôë‰ªÄ‰πà‰ª•Âèä‰∏∫‰ªÄ‰πàÔºåËÄå‰∏çÊòØËØ¥‚ÄúÂÄºÂæóËÄÉËôë‚Äù„ÄÇ\n\n**ÈÅøÂÖçÂÜóÈïø„ÄÅÂï∞Âó¶ÁöÑÂè•Â≠ê**\n\n* ÂÜóÈïøÁöÑÂè•Â≠êÂê¨Ëµ∑Êù•Ëøá‰∫éÊ≠£ÂºèÂíåÊú∫Ê¢∞„ÄÇÈºìÂä±Â∞ÜÂ§çÊùÇÁöÑÊÉ≥Ê≥ïÂàÜËß£ÊàêËæÉÁü≠ÁöÑÂè•Â≠êÔºåÊØè‰∏™Âè•Â≠êÂåÖÂê´‰∏Ä‰∏™‰∏ªË¶ÅÊÄùÊÉ≥„ÄÇËøô‰ΩøÂæóÂõûÂ∫îÂê¨Ëµ∑Êù•Êõ¥ÈöèÊÑèÂíåÂØπËØù„ÄÇ\n\n**Á§∫‰æãÔºö****‰πãÂâç:**‚ÄúÊ≠§Â§ñÔºåÈáçË¶ÅÁöÑÊòØË¶ÅÊ≥®ÊÑèÔºå‰ºòÂåñÊÇ®ÁöÑÊµÅÁ®ãÂèØ‰ª•Â∏¶Êù•ÊòæËëóÁöÑÊïàÁéáÊèêÂçá„ÄÇ‚Äù\n\n**‰πãÂêé:**‚ÄúÂ¶ÇÊûúÊÇ®ÊîπÂñÑÊµÅÁ®ãÔºåÂèØ‰ª•ÊèêÈ´òÊïàÁéáÂπ∂ËäÇÁúÅÊó∂Èó¥„ÄÇ‚Äù\n\n## 3\\. ÂåπÈÖçËØ≠Ê∞î‰∏é‰∏ä‰∏ãÊñá\n\n‰Ωø AI ÂõûÂ§çÂê¨Ëµ∑Êù•Êõ¥Ëá™ÁÑ∂ÁöÑÊúÄÂø´ÊñπÊ≥ï‰πã‰∏ÄÊòØÊ†πÊçÆÂú∫ÊôØË∞ÉÊï¥ËØ≠Ê∞î„ÄÇ\n\n**Ë∞ÉÊï¥Ê≠£ÂºèÁ®ãÂ∫¶**\n\n* ChatGPT ÊúâÊó∂Âú®‰ºëÈó≤Âú∫Âêà‰ΩøÁî®Ëøá‰∫éÊ≠£ÂºèÁöÑËØ≠Ë®ÄÔºåÊàñÂú®ÂïÜ‰∏öÂú∫ÊôØ‰∏≠‰ΩøÁî®Ëøá‰∫éÈöèÊÑèÁöÑËØ≠Ë®Ä„ÄÇÊ†πÊçÆÁî®Êà∑ÁöÑÈúÄÊ±ÇË∞ÉÊï¥ËØ≠Ê∞î‰ΩøÂõûÂ§çÊÑüËßâÊõ¥ÂêàÈÄÇÔºåÊõ¥ÂÉè‰∫∫Á±ª„ÄÇ\n\n**ÈÅøÂÖçÊäΩË±°Ê¶ÇÂøµÔºåÂÅèÂêëÁé∞ÂÆûÁªÜËäÇ**\n\n* Ê≥õÊ≥õËÄåË∞àÁöÑÈôàËø∞Âπ∂‰∏çÊÄªÊòØÊèê‰æõ‰ª∑ÂÄº„ÄÇÈºìÂä± ChatGPT ‰ΩøÁî®ÂÖ∑‰ΩìÁ§∫‰æãÊàñÁõ∏ÂÖ≥ÁªÜËäÇÔºå‰ª•Êõ¥Ê∏ÖÊô∞Âú∞‰º†ËææË¶ÅÁÇπ„ÄÇ‰∏éÂÖ∂ËØ¥Ôºö‚ÄúËøôÊé®Âä®‰∫ÜËΩ¨Âûã‚ÄùÔºå‰∏çÂ¶ÇËØ¥Ôºö‚ÄúËøôÂèØ‰ª•Â∏¶Êù•Êñ∞ÁöÑÂ∑•‰ΩúÊñπÂºèÔºåÊØîÂ¶ÇÂä†Âø´Áîü‰∫ßÊàñÈôç‰ΩéÊàêÊú¨„ÄÇ‚Äù\n\n**‰πãÂâç:**‚ÄúÊÄª‰πãÔºåÂà©Áî®Êï∞ÊçÆÊ¥ûÂØüÂèØ‰ª•Êé®Âä®ÊúâÂΩ±ÂìçÂäõÁöÑ‰∏öÂä°ËΩ¨Âûã„ÄÇ‚Äù\n\n**‰πãÂêé:**‚ÄúÊúâÊïà‰ΩøÁî®Êï∞ÊçÆÂèØ‰ª•Â∏ÆÂä©‰ºÅ‰∏öÊàêÈïøÔºåÈÄöËøáÊîπÂñÑÁîü‰∫ßÈÄüÂ∫¶ÊàñÂáèÂ∞ëÂºÄÊîØÁ≠âÊñπÈù¢„ÄÇ‚Äù\n\n## 4\\. ËØ∑ ChatGPT ‰∏ìÊ≥®‰∫éÊèêÈ´ò‰∫íÂä®ÊÄßÂíå‰∫≤ÂíåÂäõ\n\n‰∫∫Â∑•Âê¨Ëµ∑Êù•ÁöÑËØ≠Ë®ÄÂæÄÂæÄÊ∫ê‰∫éËøá‰∫é‰∏ì‰∏öÁöÑËØ≠Ê∞îÊàñ‰∏éÁúüÂÆû‰∫∫Ê≤°ÊúâËÅîÁ≥ªÁöÑÊäΩË±°ÊÄùÊÉ≥„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õ‰ΩøÂõûÂ∫îÊõ¥ÂÖ∑‰∫íÂä®ÊÄßÂíå‰∫≤ÂíåÂäõÁöÑÂª∫ËÆÆÔºö\n\n**‰ΩøÂõûÂ∫îÂÆûÁî®ÂíåÊúâÁî®**\n\n* ChatGPT ÂèØ‰ª•Êèê‰æõÂÆûÁî®ÁöÑÂª∫ËÆÆÂíåÁî®Êà∑ÂèØ‰ª•ÈááÂèñÁöÑÂÖ∑‰ΩìÊ≠•È™§ÔºåËÄå‰∏çÊòØÊèê‰æõ‰∏ÄËà¨ÊÄßÁöÑÂª∫ËÆÆ„ÄÇ\n\n**ÈÅøÂÖçË°åËØù**\n\n* Ë°å‰∏öÁâπÂÆöÁöÑË°åËØùÊàñÊäÄÊúØÊúØËØ≠ÂèØËÉΩ‰ºö‰ΩøÂõûÂ∫îÂê¨Ëµ∑Êù•ÁîüÁ°¨ÂíåÈÅ•Ëøú„ÄÇÈºìÂä± ChatGPT Âú®ÂèØËÉΩÁöÑÊÉÖÂÜµ‰∏ãÁÆÄÂåñËØ≠Ë®ÄÔºåÊúâÂä©‰∫éÂ§ßÂÆ∂‰øùÊåÅ‰∏ÄËá¥„ÄÇ\n\n**Á§∫‰æãÔºö** **‰πãÂâç:**‚Äú‰∏∫‰∫ÜÊèêÈ´òÊïàÁéáÔºåÁ≥ªÁªüÊÄßÂú∞ËØÑ‰º∞ËµÑÊ∫êÂàÜÈÖçËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‚Äù\n\n**‰πãÂêé:**‚Äú‰∏∫‰∫ÜËäÇÁúÅÊó∂Èó¥ÂíåËµÑÊ∫êÔºåÊ£ÄÊü•‰∏Ä‰∏ãÊòØÂê¶ÊâÄÊúâ‰∏úË•øÈÉΩÂú®ÊúÄ‰Ω≥‰ΩøÁî®Áä∂ÊÄÅ„ÄÇ‚Äù\n\n## 5\\. Â∞ùËØïÁé∞ÂÆû‰∏ñÁïåÁöÑ‰æãÂ≠êÂíåÁõ¥Êé•ÈôàËø∞\n\n‰∫∫‰ª¨ÂÄæÂêë‰∫é‰ª•Ê∏ÖÊô∞„ÄÅÂÖ∑‰ΩìÁöÑÊñπÂºèË°®ËææÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëß£ÈáäÊüê‰ª∂‰∫ãÊÉÖÊó∂„ÄÇChatGPT ÂèØ‰ª•ÈÄöËøá‰ΩøÁî®‰∏éÁî®Êà∑Áé∞ÂÆû‰∏ñÁïåÁõ∏ÂÖ≥ÁöÑ‰æãÂ≠êÊù•ÂèçÊò†Ëøô‰∏ÄÁÇπ„ÄÇ\n\n**‰ΩøÁî®Áõ∏ÂÖ≥ÁöÑ‰æãÂ≠ê**\n\n* ÂΩìÂåÖÊã¨Áé∞ÂÆû‰∏ñÁïåÁöÑ‰æãÂ≠êÊó∂ÔºåÈÄöÁî®ÁöÑÂõûÂ∫îÂèòÂæóÊõ¥Âä†ÈöæÂøò„ÄÇ‰æãÂ¶ÇÔºå‰∏éÂÖ∂ËØ¥‚ÄúËøôÂèØ‰ª•ÊîπÂñÑËøêËê•ÊµÅÁ®ã‚ÄùÔºå‰∏çÂ¶ÇËØ¥‚ÄúËøôÂèØËÉΩÂ∏ÆÂä©‰Ω†ÂáèÂ∞ëÂÆ¢Êà∑ÊúçÂä°‰∏≠ÁöÑÁ≠âÂæÖÊó∂Èó¥‚Äù„ÄÇ\n\n**ÈºìÂä±‰ΩøÁî®Áõ¥Êé•ÈôàËø∞ËÄå‰∏çÊòØ‰øÆÈ•∞ËØ≠**\n\n* ‚ÄúÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØ‚Ä¶‚Ä¶‚ÄùÈÄöÂ∏∏ÂèØ‰ª•Áº©Áü≠‰∏∫‰∏ªË¶ÅËßÇÁÇπÊú¨Ë∫´„ÄÇÁõ¥Êé•ÈôàËø∞‰∏ç‰ªÖ‰øùÊåÅÁÆÄÂçïÔºåËÄå‰∏îÂ¢ûÂº∫‰∫Ü‰ø°ÊÅØÁöÑÂèØ‰ø°Â∫¶„ÄÇ\n\n**‰æãÂ≠êÔºö** **‰πãÂâçÔºö**‚ÄúÂÄºÂæóËÄÉËôëÁöÑÊòØÔºåÊµÅÁ®ãÊîπËøõÂèØËÉΩ‰ºöÂØºËá¥ÊòæËëóÁöÑÊàêÊú¨Èôç‰Ωé„ÄÇ‚Äù\n\n**‰πãÂêéÔºö**‚ÄúÊîπÂñÑÊµÅÁ®ãÂèØ‰ª•Â∏ÆÂä©‰Ω†ËäÇÁúÅÂæàÂ§öÈí±„ÄÇ‚Äù\n\n## ÊÄªÁªì\n\nÈÄöËøáËøô‰∫õË∞ÉÊï¥ÔºåÊÇ®ÂèØ‰ª•ËÆ© ChatGPT ‰ª•Êõ¥Ëá™ÁÑ∂„ÄÅÂØπËØùÂºèÂíåÂºï‰∫∫ÂÖ•ËÉúÁöÑÊñπÂºèËøõË°å‰∫§ÊµÅ„ÄÇÂáèÂ∞ëË°åËØù„ÄÅÁº©Áü≠Âè•Â≠êÂíå‰ΩøÁî®Êõ¥ÁÆÄÂçïÁöÑËØ≠Ë®ÄÂèØ‰ª•‰ΩøÂõûÁ≠îÂê¨Ëµ∑Êù•‰∏çÈÇ£‰πàÂÉèÊú∫Âô®‰∫∫ÔºåËÄåÊõ¥ÂÉèÊàë‰ª¨ÈÉΩÊ¨£ËµèÁöÑÊúâÂ∏ÆÂä©‰∏îÁü•ËØÜÊ∏äÂçöÁöÑÂä©Êâã„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/glm-4-voice-9b-real-time-multilingual-voice-conversation-ai-install-locally-in-minutes-ce2fcd6c8fd8","frontmatter":{"title":"GLM-4-Voice 9B‚Äî‚ÄîÂÆûÊó∂Â§öËØ≠Ë®ÄËØ≠Èü≥ÂØπËØù AI‚Äî‚ÄîÂá†ÂàÜÈíüÂÜÖÂç≥ÂèØÂú®Êú¨Âú∞ÂÆâË£Ö","meta_title":"GLM-4-Voice 9B‚Äî‚ÄîÂÆûÊó∂Â§öËØ≠Ë®ÄËØ≠Èü≥ÂØπËØù AI‚Äî‚ÄîÂá†ÂàÜÈíüÂÜÖÂç≥ÂèØÂú®Êú¨Âú∞ÂÆâË£Ö","description":"GLM-4-Voice 9B ÊòØ‰∏ÄÊ¨æÂÆûÊó∂Â§öËØ≠Ë®ÄËØ≠Èü≥ÂØπËØùAIÔºåÊîØÊåÅËã±ËØ≠Âíå‰∏≠ÊñáÔºåÂÖ∑Â§áÊÉÖÊÑüËØ≠Ë∞ÉÂíåËØ≠ÈÄüÁöÑÂèØÂÆöÂà∂ÊÄß„ÄÇËØ•Ê®°ÂûãÈÄöËøáÁ´ØÂà∞Á´ØÊû∂ÊûÑÂÆûÁé∞‰ΩéÂª∂ËøüÂìçÂ∫îÔºåÊèê‰æõÊõ¥Ëá™ÁÑ∂ÁöÑ‰∫íÂä®‰ΩìÈ™å„ÄÇÂÖ∂‰∏ªË¶ÅÁªÑ‰ª∂ÂåÖÊã¨Ê†áËÆ∞ÂåñÂô®„ÄÅÊ†∏ÂøÉËØ≠Ë®ÄÊ®°ÂûãÂíåËß£Á†ÅÂô®ÔºåËÉΩÂ§üÁõ¥Êé•Â§ÑÁêÜËØ≠Èü≥ËæìÂÖ•ÂíåÁîüÊàêÈü≥È¢ëËæìÂá∫„ÄÇÁî®Êà∑ÂèØÈÄöËøáÁÆÄÂçïÁöÑÊú¨Âú∞ËÆæÁΩÆÊ≠•È™§Âø´ÈÄüÈÉ®ÁΩ≤ËØ•Ê®°ÂûãÔºåÈÄÇÂêàÂÆ¢Êà∑ÊúçÂä°ÂíåÊïôËÇ≤Á≠âÂ§öÁßçÂ∫îÁî®Âú∫ÊôØ„ÄÇ","date":"2024-11-13T01:32:04.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LATTpEc2AHvqgVyPKSzW7A.jpeg","categories":["Voice Assistants","Natural Language Processing","Chatbots"],"author":"Rifx.Online","tags":["multilingual","conversation","real-time","customization","performance"],"draft":false,"slug":"blog/glm-4-voice-9b-real-time-multilingual-voice-conversation-ai-install-locally-in-minutes-ce2fcd6c8fd8"},"content":"\n### Â¶Ç‰ΩïËÆæÁΩÆ GLM\\-4\\-Voice 9B ‰ª•ÂÆûÁé∞Êó†ÁºùÁöÑÂÆûÊó∂ËØ≠Èü≥‰∫§‰∫íÔºåÊîØÊåÅËã±ËØ≠Âíå‰∏≠ÊñáÔºåÂπ∂Êé¢Á¥¢ÂÖ∂Áã¨ÁâπÁöÑÊû∂ÊûÑ„ÄÅ‰ΩéÂª∂ËøüÂìçÂ∫îÂíåÂèØÂÆöÂà∂ÁöÑÂ£∞Èü≥Â±ûÊÄß„ÄÇ\n\n\n\n\n## ‰ªãÁªç\n\nËøëÂπ¥Êù•ÔºåËØ≠Èü≥ÂêØÁî®ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩøÂØπËØù‰ª£ÁêÜËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂìçÂ∫î‰∫∫Á±ªËØ≠Ë®Ä„ÄÇ‰ªéËôöÊãüÂä©ÊâãÂà∞ÂÆ¢Êà∑ÊúçÂä°Êú∫Âô®‰∫∫ÔºåËØ≠Èü≥‰∫∫Â∑•Êô∫ËÉΩÂ∑≤Êàê‰∏∫ÂêÑ‰∏™Ë°å‰∏öÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∞Ê®°ÂûãÂú®ÊµÅÂà©Âú∞ÂàáÊç¢ËØ≠Ë®Ä„ÄÅÁêÜËß£Âè£ËØ≠Êü•ËØ¢ÁöÑÁªÜÂæÆÂ∑ÆÂà´‰ª•ÂèäÊèê‰æõÈ´òË¥®ÈáèÂìçÂ∫îÊñπÈù¢‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàò„ÄÇËøôÊ≠£ÊòØZhipu AIÁöÑGLM-4-VoiceËÑ±È¢ñËÄåÂá∫ÁöÑÂú∞Êñπ„ÄÇGLM-4-Voice‰Ωú‰∏∫‰∏ÄÊ¨æÁ´ØÂà∞Á´ØÁöÑËØ≠Èü≥Ê®°ÂûãÔºåÊé®Âä®‰∫ÜÂ§öËØ≠Ë®ÄÂØπËØù‰∫∫Â∑•Êô∫ËÉΩÁöÑËæπÁïåÔºåÊîØÊåÅËã±ËØ≠Âíå‰∏≠ÊñáÁöÑÂÆûÊó∂ÂØπËØùÔºåÂêåÊó∂Êèê‰æõÂèØÈÄÇÂ∫î‰∏îÁ±ª‰∫∫ÂåñÁöÑÂìçÂ∫îÁîüÊàê„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®‰∏∫‰ªÄ‰πàGLM-4-VoiceÂÄºÂæóÂÖ≥Ê≥®ÔºåÂÆÉÁöÑÁã¨Áâπ‰πãÂ§ÑÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®Êú¨Âú∞ËÆæÁΩÆÂíåÂºÄÂßã‰ΩøÁî®ÂÆÉ„ÄÇÊàë‰ª¨ËøòÂ∞ÜÊü•ÁúãÂÖ∂Êû∂ÊûÑÔºåÂπ∂Êèê‰æõËÆøÈóÆÁΩëÁªúÊºîÁ§∫ÁöÑÂÆûÁî®ÊåáÂçó„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàÈÄâÊã© GLM-4-VoiceÔºü\n\n‰º†ÁªüÁöÑËØ≠Ë®ÄÊ®°ÂûãÈÄöÂ∏∏‰ªÖÈôê‰∫éÊñáÊú¨ÔºåÂπ∂ÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÂ§ÑÁêÜÂ±ÇÊù•Â§ÑÁêÜËØ≠Èü≥„ÄÇÂÆÉ‰ª¨Âú®‰∫§‰∫íÊÄßÊñπÈù¢ÂèØËÉΩ‰ºöÈÅáÂà∞Âõ∞ÈöæÔºåÊàñËÄÖÂ≠òÂú®Âª∂ËøüÈóÆÈ¢ò„ÄÇGLM-4-Voice ÈÄöËøá‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ®°ÂûãÂÖãÊúç‰∫ÜËøô‰∫õÈôêÂà∂ÔºåËÉΩÂ§üÁõ¥Êé•Â§ÑÁêÜÂíåÁîüÊàêËØ≠Èü≥„ÄÇ‰ª•‰∏ãÊòØÂÆÉÁöÑÁ™ÅÂá∫‰πãÂ§ÑÔºö\n\n1. **Á´ØÂà∞Á´ØËØ≠Èü≥Â§ÑÁêÜ**Ôºö‰∏éËÆ∏Â§ö‰æùËµñ‰∫éÂçïÁã¨ÁöÑÊñáÊú¨Âà∞ËØ≠Èü≥ (TTS) ÊàñËØ≠Èü≥Âà∞ÊñáÊú¨ (STT) Ê®°ÂùóÁöÑÊ®°Âûã‰∏çÂêåÔºåGLM-4-Voice Áõ¥Êé•‰ª•Âè£ËØ≠ÂΩ¢ÂºèËøõË°åËß£ËØªÂíåÂìçÂ∫îÔºå‰ªéËÄåÊèê‰æõÊõ¥Êó†ÁºùÂíåÊõ¥ÂÖ∑ÂìçÂ∫îÊÄßÁöÑ‰ΩìÈ™å„ÄÇ\n2. **Â§öËØ≠Ë®ÄÊîØÊåÅ**ÔºöËØ•Ê®°ÂûãÂú®Â§ÑÁêÜËã±ËØ≠Âíå‰∏≠ÊñáËøô‰∏§ÁßçÂÖ®ÁêÉÂπøÊ≥õ‰ΩøÁî®ÁöÑËØ≠Ë®ÄÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂÆÉÊµÅÁïÖÂàáÊç¢ËØ≠Ë®ÄÁöÑËÉΩÂäõ‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÂèåËØ≠ÁéØÂ¢ÉÂíåÂõΩÈôÖÂ∫îÁî®„ÄÇ\n3. **ÂèØÂÆöÂà∂Â±ûÊÄß**ÔºöGLM-4-Voice ÂÖÅËÆ∏Âú®ÊÉÖÊÑü„ÄÅËØ≠Ë∞É„ÄÅËØ≠ÈÄüÁîöËá≥ÊñπË®Ä‰∏äËøõË°åË∞ÉÊï¥Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÁîüÊàêÊõ¥Ëá™ÁÑ∂ÂíåÊÉÖÂ¢ÉÂêàÈÄÇÁöÑÂìçÂ∫î„ÄÇ\n4. **‰ΩéÂª∂Ëøü**ÔºöÈÄöËøáÊîØÊåÅÊµÅÂºèÊé®ÁêÜÔºåËØ•Ê®°ÂûãÁöÑÂª∂ËøüÁ∫¶‰∏∫ 20 ‰∏™Ê†áËÆ∞Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®ÂÆûÊó∂ÂØπËØù‰∏≠ÂÆûÁé∞Ëøë‰πéÂç≥Êó∂ÁöÑÂìçÂ∫î„ÄÇ\n\n## GLM\\-4\\-Voice ÁöÑÁâπÁÇπ\n\nGLM\\-4\\-Voice Â∏¶Êù•‰∫ÜÂá†‰∏™Áã¨ÁâπÁöÑÂäüËÉΩÔºå‰ΩøÂÖ∂‰∏éÂÖ∂‰ªñËØ≠Èü≥Ê®°ÂûãÂå∫Âà´ÂºÄÊù•„ÄÇ‰ª•‰∏ãÊòØÂÆÉÁöÑÁâπÂà´‰πãÂ§ÑÔºö\n\n* **ÂÆûÊó∂ËØ≠Èü≥‰∫íÂä®**ÔºöÈÄöËøáÊîØÊåÅ‰ΩéÂª∂ËøüÂìçÂ∫îÔºåGLM\\-4\\-Voice ËÉΩÂ§ü‰øùÊåÅÊµÅÁïÖËá™ÁÑ∂ÁöÑÂØπËØùÔºåËøôÂØπÂÆ¢Êà∑ÊîØÊåÅÂíå‰∫íÂä® AI Á≠âÂ∫îÁî®Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n* **Âä®ÊÄÅËØ≠Èü≥Â±ûÊÄß**ÔºöÁî®Êà∑ÂèØ‰ª•ÊåáÂÆöÊ®°ÂûãÁöÑÊÉÖÊÑüËØ≠Ë∞É„ÄÅËØ≠ÈÄüÂíåÂÖ∂‰ªñÁâπÂæÅÔºå‰Ωø‰∫íÂä®Êõ¥Âä†ÁîüÂä®‰∏îÈÄÇÂêàÂêÑÁßçÂú∫ÊôØ„ÄÇ\n* **ÂÖ∑Â§á‰∏ä‰∏ãÊñáÊÑèËØÜÁöÑÂèåËØ≠ÊîØÊåÅ**ÔºöËØ•Ê®°ÂûãÊó®Âú®ÁêÜËß£ÂíåÁîüÊàê‰∏≠ÊñáÂíåËã±ÊñáÁöÑÂìçÂ∫î„ÄÇÂÆÉËÉΩÂ§üÊó†ÁºùÂàáÊç¢Ëøô‰∏§ÁßçËØ≠Ë®ÄÔºå‰∏∫Â§öËØ≠Ë®ÄÂ∫îÁî®Êèê‰æõÁÅµÊ¥ªÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n* **È´òÁ∫ßËØ≠Èü≥Ëß£Á†Å**ÔºöÂü∫‰∫é CosyVoiceÔºåGLM\\-4\\-Voice Ëß£Á†ÅÂô®ËÉΩÂ§üÂÆûÁé∞È´òË¥®ÈáèÁöÑËØ≠Èü≥ÁîüÊàêÔºåÂπ∂ÊîØÊåÅÊµÅÂºè‰º†ËæìÔºåÂú®‰∏§ÁßçËØ≠Ë®Ä‰∏≠‰øùÊåÅÈ´òÊ∏ÖÊô∞Â∫¶„ÄÇ\n\n## Êû∂ÊûÑ\n\nGLM\\-4\\-Voice ÁöÑÊû∂ÊûÑÁî±‰∏â‰∏™‰∏ªË¶ÅÁªÑ‰ª∂ÁªÑÊàêÔºåÊØè‰∏™ÁªÑ‰ª∂Âú®ÂÆûÁé∞Á´ØÂà∞Á´ØËØ≠Èü≥‰∫§‰∫í‰∏≠ÂèëÊå•ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nJsKHtxSblNkixPIBZpWyQ.jpeg)\n\n1. **GLM\\-4\\-Voice\\-Tokenizer**ÔºöËØ•ÁªÑ‰ª∂Â∞ÜËøûÁª≠ËØ≠Èü≥ËæìÂÖ•Ê†áËÆ∞Âåñ‰∏∫Á¶ªÊï£Ê†áËÆ∞ÔºåÊØèÁßíÂ§ßÁ∫¶ÁîüÊàê 12.5 ‰∏™Ê†áËÆ∞„ÄÇÊ†áËÆ∞Âô®Âü∫‰∫é Whisper ÁöÑÁºñÁ†ÅÂô®ÔºåÂπ∂Ê∑ªÂä†‰∫ÜÂêëÈáèÈáèÂåñÔºå‰ΩøÊ®°ÂûãËÉΩÂ§ü‰ª•ÁªìÊûÑÂåñÂΩ¢ÂºèÂ§ÑÁêÜÈü≥È¢ë„ÄÇ\n2. **GLM\\-4\\-Voice\\-9B**ÔºöÊ†∏ÂøÉËØ≠Ë®ÄÊ®°ÂûãÔºåÂü∫‰∫é GLM\\-4 Êû∂ÊûÑÔºåÂ∑≤Ë∞ÉÊï¥‰∏∫Â§ÑÁêÜÂè£ËØ≠ËæìÂÖ•„ÄÇÂÆÉÂèØ‰ª•Â§ÑÁêÜÊñáÊú¨ÂíåËØ≠Èü≥Ôºå‰ΩøÂÖ∂Êàê‰∏∫Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅÂØπËØù‰ª£ÁêÜ„ÄÇ\n3. **GLM\\-4\\-Voice\\-Decoder**ÔºöËØ•Ëß£Á†ÅÂô®Â∞ÜÁ¶ªÊï£Ê†áËÆ∞ËΩ¨Êç¢ÂõûËøûÁª≠ËØ≠Èü≥Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÁîüÊàêÈü≥È¢ëËæìÂá∫„ÄÇÂÆÉÊîØÊåÅÊµÅÂºèÊé®ÁêÜÔºå‰ΩøÂìçÂ∫îËÉΩÂ§üÂú®Â§ÑÁêÜÂá†‰∏™Ê†áËÆ∞ÂêéÁ´ãÂç≥ÂºÄÂßãÔºå‰ªéËÄåÊúÄÂ∞èÂåñÂØπËØùÂª∂Ëøü„ÄÇ\n\nËøô‰∫õÁªÑ‰ª∂ÂÖ±Âêå‰Ωø GLM\\-4\\-Voice Êàê‰∏∫ÂÆûÊó∂ËØ≠Èü≥‰∫§‰∫íÁöÑÂº∫Â§ßÂ∑•ÂÖ∑ÔºåÊîØÊåÅ‰∏çÂêåËØ≠Ë®ÄÂíåÊñπË®ÄÁöÑÂØπËØù AI„ÄÇ\n\n## Âú®Êú¨Âú∞ËÆæÁΩÆ GLM\\-4\\-Voice\n\nË¶Å‰ΩìÈ™å GLM\\-4\\-VoiceÔºåËØ∑ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Âú®ÊÇ®ÁöÑÊú∫Âô®‰∏äÊú¨Âú∞ËÆæÁΩÆËØ•Ê®°Âûã„ÄÇ\n\n### Á¨¨‰∏ÄÊ≠•ÔºöÂÖãÈöÜ‰ªìÂ∫ì\n\nÈ¶ñÂÖà‰ªé GitHub ÂÖãÈöÜ‰ªìÂ∫ì„ÄÇÁ°Æ‰øùÂåÖÂê´Â≠êÊ®°ÂùóÔºö\n\n```python\n!git clone --recurse-submodules https://github.com/THUDM/GLM-4-Voice\ncd GLM-4-Voice\n```python\n!git clone --recurse-submodules https://github.com/THUDM/GLM-4-Voice\ncd GLM-4-Voice\n\n```\n\n### Ê≠•È™§ 2ÔºöÂÆâË£Ö‰æùËµñ\n\nËøõÂÖ•È°πÁõÆÁõÆÂΩïÂπ∂ÂÆâË£ÖÂøÖË¶ÅÁöÑ‰æùËµñÔºö\n\n```python\n!pip install -r requirements.txt\n```python\n!pip install -r requirements.txt\n\n```\n\n### Á¨¨3Ê≠•Ôºö‰∏ãËΩΩÊ®°ÂûãÊ£ÄÊü•ÁÇπ\n\nGLM\\-4\\-VoiceÁöÑËß£Á†ÅÂô®Ê®°ÂûãÊâòÁÆ°Âú®Hugging Face‰∏äÔºåÈúÄË¶Å`git-lfs`ËøõË°å‰∏ãËΩΩ„ÄÇÁ°Æ‰øùÂ∑≤ÂÆâË£Ö`git-lfs`ÔºåÁÑ∂ÂêéËøêË°åÔºö\n\n```python\n!git clone https://huggingface.co/THUDM/glm-4-voice\n```python\n!git clone https://huggingface.co/THUDM/glm-4-voice\n\n```\n\n### Ê≠•È™§ 4ÔºöÂêØÂä®Ê®°ÂûãÊúçÂä°\n\n‰∏ÄÂàáËÆæÁΩÆÂÆåÊàêÂêéÔºåÂêØÂä®Ê®°ÂûãÊúçÂä°Âô®Ôºö\n\n```python\npython model_server.py --model-path glm-4-voice-9b\n```python\npython model_server.py --model-path glm-4-voice-9b\n\n```\n\n### Á¨¨5Ê≠•ÔºöÂêØÂä®WebÊúçÂä°\n\n‰∏ÄÊó¶Ê®°ÂûãÊúçÂä°Âô®ËøêË°åÔºåÊâßË°å‰ª•‰∏ãÂëΩ‰ª§‰ª•ÂêØÂä®WebÊúçÂä°Ôºö\n\n```python\npython web_demo.py\n```python\npython web_demo.py\n\n```\n\nÊÇ®Áé∞Âú®ÂèØ‰ª•ËÆøÈóÆWebÊºîÁ§∫ [http://127\\.0\\.0\\.1:8888](http://127.0.0.1:8888) ‰∏éGLM\\-4\\-VoiceËøõË°å‰∫§‰∫í„ÄÇ\n\n> **Ê≥®ÊÑèÔºö** GLM\\-4\\-VoiceÊ®°ÂûãËµÑÊ∫êÂØÜÈõÜÔºåËøêË°åÊúâÊïàÈúÄË¶ÅÂ§ßÈáèËÆ°ÁÆóËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂÆÉÈúÄË¶Å35‚Äì40‰∏™GPU‰ª•ÂÆûÁé∞ÊúÄ‰Ω≥ÊÄßËÉΩÔºåÂõ†Ê≠§ÈÄÇÂêàÂú®ÂèØËÆøÈóÆÈ´òÊÄßËÉΩÁ°¨‰ª∂ÁöÑÁéØÂ¢É‰∏≠ÈÉ®ÁΩ≤„ÄÇÁî®Êà∑Âú®Â∞ùËØï‰ΩøÁî®Ê≠§Ê®°Âûã‰πãÂâçÔºåÂ∫îÁ°Æ‰øùÂÖ∑Â§áÂøÖË¶ÅÁöÑÂü∫Á°ÄËÆæÊñΩ„ÄÇ\n\n## Web Demo Interface\n\nGLM\\-4\\-Voice ÁöÑÁΩëÈ°µÊºîÁ§∫Êèê‰æõ‰∫Ü‰∏Ä‰∏™Áõ¥ËßÇÁöÑÁïåÈù¢ÔºåÂÖ∑ÊúâÂ§öÁßçËá™ÂÆö‰πâÈÄâÈ°πÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*scbHOUXqMW5KGAcT3Bq1Eg.png)\n\n* **ËæìÂÖ•Ê®°Âºè**ÔºöÁî®Êà∑ÂèØ‰ª•ÈÄâÊã©‰ª•ÊñáÊú¨ÊàñÈü≥È¢ëÂΩ¢ÂºèÊèê‰æõËæìÂÖ•„ÄÇËøôÁßçÁÅµÊ¥ªÊÄßÂÖÅËÆ∏Êó†ÊâãÊìç‰ΩúÊàñ‰º†Áªü‰∫§‰∫í„ÄÇ\n* **ËØ≠Èü≥ÊéßÂà∂ÂèÇÊï∞**ÔºöË∞ÉÊï¥Ê∏©Â∫¶„ÄÅtop\\-p Âíå‰ª§ÁâåÈôêÂà∂Ôºå‰ª•Ëá™ÂÆö‰πâÊ®°ÂûãÁöÑÂìçÂ∫îÁâπÊÄß„ÄÇ\n* **Ë∞ÉËØï‰ø°ÊÅØ**ÔºöÊòæÁ§∫ËæìÂÖ•ÂíåËæìÂá∫‰ª§ÁâåÔºå‰ΩøÁî®Êà∑ËÉΩÂ§üÊ¥ûÂØüÊ®°ÂûãÂ§ÑÁêÜÊü•ËØ¢ÁöÑËøáÁ®ã„ÄÇ\n* **‰∫§‰∫íÂºèÈü≥È¢ëÊòæÁ§∫**ÔºöÈü≥È¢ëËæìÂÖ•ÂíåÂìçÂ∫î‰ª•Ê≥¢ÂΩ¢ÂΩ¢ÂºèÊòæÁ§∫ÔºåÁî®Êà∑ÂèØ‰ª•ÈáçÊí≠ÊàñÊü•ÁúãÈü≥È¢ëÁâáÊÆµ‰ª•ËØÑ‰º∞Ë¥®Èáè„ÄÇ\n\nÁÑ∂ËÄåÔºåÁî®‰∫éÂú®ÊºîÁ§∫‰∏≠ÊµÅÂºè‰º†ËæìÈü≥È¢ëÁöÑ Gradio ÊúâÊó∂ÂèØËÉΩ‰ºöÂá∫Áé∞‰∏çÁ®≥ÂÆöÊÉÖÂÜµ„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥Ë¥®ÈáèÔºåÂª∫ËÆÆÂú®ÁîüÊàêÂêéÈáçÊí≠ÂØπËØùÊ°Ü‰∏≠ÁöÑÈü≥È¢ë„ÄÇ\n\n## ÁªìËÆ∫\n\nGLM\\-4\\-Voice Âú®ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüü‰∏≠ËÑ±È¢ñËÄåÂá∫ÔºåÊèê‰æõ‰∫ÜÁã¨ÁâπÁöÑÂèåËØ≠ÊîØÊåÅ„ÄÅÂÆûÊó∂Èü≥È¢ë‰∫§‰∫íÂíåÁÅµÊ¥ªÁöÑÂìçÂ∫îÂÆöÂà∂„ÄÇÂÖ∂Á´ØÂà∞Á´ØËÆæËÆ°Âíå‰ΩéÂª∂Ëøü‰ΩøÂÖ∂Êàê‰∏∫ÂÆ¢Êà∑ÊúçÂä°„ÄÅÊïôËÇ≤„ÄÅËôöÊãüÂä©ÊâãÁ≠âÂ∫îÁî®ÁöÑÊúÄ‰Ω≥ÂÄôÈÄâËÄÖ„ÄÇÂá≠ÂÄüÊòì‰∫éËÆøÈóÆÁöÑËÆæÁΩÆËøáÁ®ãÔºåGLM\\-4\\-Voice ‰∏∫ÂºÄÂèëËÄÖÂíåÁ†îÁ©∂‰∫∫ÂëòÊé¢Á¥¢‰∏≠ÊñáÂíåËã±ÊñáÁöÑÈ´òÁ∫ßËØ≠Èü≥ËÉΩÂäõÊâìÂºÄ‰∫ÜÂ§ßÈó®„ÄÇ\n\nÈöèÁùÄÂØπÊõ¥‰∫íÂä®ÂíåÁúüÂÆûÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈúÄÊ±ÇÁöÑ‰∏çÊñ≠Â¢ûÈïøÔºåÂÉè GLM\\-4\\-Voice ËøôÊ†∑ÁöÑÊ®°Âûã‰ª£Ë°®‰∫ÜÂú®Ê∂àÈô§ËØ≠Ë®ÄÂíåÂØπËØùÈöúÁ¢çÊñπÈù¢ÁöÑÈáçË¶ÅËøõÂ±ï„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÊÉ≥ÊûÑÂª∫ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÅËôöÊãüÊïôÂ∏àËøòÊòØÂÆ¢Êà∑ÊúçÂä°‰ª£ÁêÜÔºåGLM\\-4\\-Voice ÈÉΩÊèê‰æõ‰∫ÜÂº∫Â§ßËÄåÁÅµÊ¥ªÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/google-gemini-are-big-context-windows-the-killer-feature-72ff95488fb1","frontmatter":{"title":"Google GeminiÔºöÂ§ß‰∏ä‰∏ãÊñáÁ™óÂè£ÊòØÊùÄÊâãÁ∫ßÂäüËÉΩÂêóÔºü","meta_title":"Google GeminiÔºöÂ§ß‰∏ä‰∏ãÊñáÁ™óÂè£ÊòØÊùÄÊâãÁ∫ßÂäüËÉΩÂêóÔºü","description":"Goggle Âç≥Â∞ÜÊé®Âá∫ÁöÑÊ≥ïÂ≠¶Á°ïÂ£´Â≠¶‰ΩçËØæÁ®ãÊúâ‰∫ÜÈáçÂ§ßËøõÂ±ï","date":"2024-11-10T22:36:54.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MteQrQSTXLuJcd86RbjQrg.png","categories":["Machine Learning","Natural Language Processing","Data Science"],"author":"Rifx.Online","tags":["Gemini","tokens","context","LLM","evolution"],"draft":false,"slug":"blog/google-gemini-are-big-context-windows-the-killer-feature-72ff95488fb1"},"content":"\n### Ë∞∑Ê≠åÂç≥Â∞ÜÊé®Âá∫ÁöÑ LLM ËøàÂá∫‰∫ÜÈáçÂ§ß‰∏ÄÊ≠•\n\n\n\nÂ∞±Âú®ÂÖ´‰∏™ÊúàÂâçÔºå‰∏ÄÂ∞ÅÊ≥ÑÈú≤ÁöÑË∞∑Ê≠åÁîµÂ≠êÈÇÆ‰ª∂ÈÄèÈú≤ËØ•ÂÖ¨Âè∏Âú®Âä™ÂäõË∂ÖË∂äÂÖ∂ AI Á´û‰∫âÂØπÊâãÊñπÈù¢ÈÅáÂà∞‰∫ÜÂõ∞Èöæ„ÄÇ‰ªñ‰ª¨ÁöÑ AI ‰∫ßÂìÅÂë®Âõ¥‰∏ç‰ªÖÊ≤°Êúâ[Êä§ÂüéÊ≤≥](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)‚Äî‚ÄîÊç¢Âè•ËØùËØ¥ÔºåÊ≤°ÊúâÂª∫Á´ãËµ∑ÂïÜ‰∏ö‰ºòÂäø‚Äî‚ÄîË∞∑Ê≠å‰πüÊ≤°Êúâ[ÁßòÂØÜÊ≠¶Âô®](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)ÂèØ‰ª•ÊîπÂèòÂ±ÄÈù¢„ÄÇÂç≥‰ΩøÂú®‰ªñ‰ª¨Âä™ÂäõËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÊó∂Ôºå‰ªñ‰ª¨‰πüÁúãÂà∞ÁßÅÂãüËµÑÂä©ÁöÑ AI È°πÁõÆ‰∏éÂºÄÊ∫ê AI Ê®°Âûã‰πãÈó¥ÁöÑÂ∑ÆË∑ù‰ª•‚ÄúÊÉä‰∫∫ÁöÑ‚ÄùÈÄüÂ∫¶Áº©Â∞è„ÄÇ\n\nÁé∞Âú®Ëøò‰∏∫Êó∂Â∑≤ÊôöÔºåÊó†Ê≥ïÁü•ÈÅìËøô‰∏™ÊïÖ‰∫ãÁöÑÁªìÂ±Ä„ÄÇ‰πüËÆ∏ÂºÄÊ∫ê AI Â∞ÜÁªßÁª≠Âú®Êó©ÊúüÊàêÂäüÁöÑÂü∫Á°Ä‰∏äÂèëÂ±ïÔºåÊàñËÄÖÂÆÉÂ∞ÜË¢´Ë∞∑Ê≠å„ÄÅÂæÆËΩØÂíåËãπÊûúÁ≠âÊûÅÂÖ∂ÂØåÊúâÁöÑÁ´û‰∫âÂØπÊâãÂèäÂÖ∂‰ª§‰∫∫Èöæ‰ª•ÁΩÆ‰ø°ÁöÑÊï∞ÊçÆÈáèÊâÄÂéãÂà∂„ÄÇÁé∞Âú®ÔºåËøôÂú∫ÂÜ≤Á™Å‰ªçÂú®Â±ïÂºÄÔºåÂêÑ‰∏™ÁªÑÁªáÂø´ÈÄüÊé®Âá∫‰∏ÄÁ≥ªÂàó AI ËøõÂ±ï„ÄÇÊúÄËøëÔºåË∞∑Ê≠åÂú®Ëøô‰∏™È¢ÜÂüü‰∏≠Êàê‰∏∫ÁÑ¶ÁÇπÔºåÂÆ£Â∏É‰∫ÜÂÖ∂ÊúÄÊñ∞ LLM ÁöÑÈ¢ÑËßàÁâà‚Äî‚Äî[Gemini 1.5 Pro](https://deepmind.google/technologies/gemini/)„ÄÇÂèàÊòØ‰∏ÄÂ§©ÔºåÂèà‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‚Äî‚ÄîÊàñËÄÖËØ¥‰ºº‰πéÂ¶ÇÊ≠§ÔºåÁõ¥Âà∞Ë∞∑Ê≠åÊèèËø∞‰∫Ü‰∏Ä‰∏™ÊÉä‰∫∫ÁöÑÂèòÂåñ„ÄÇ\n\nGemini 1.5 Pro Êâ©Â±ï‰∫Ü *‰∏ä‰∏ãÊñáÁ™óÂè£*‚Äî‚ÄîÊú¨Ë¥®‰∏äÊòØË°°Èáè LLM ‰∏ÄÊ¨°ÂèØ‰ª•Ë∑üË∏™Â§öÂ∞ëÊï∞ÊçÆÁöÑÊåáÊ†á„ÄÇÂú®ËøáÂéªÁöÑÁâàÊú¨‰∏≠ÔºåGemini ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÊúÄÂ§ß‰∏∫ 128,000 ‰∏™Ê†áËÆ∞ÔºåÂ∞±ÂÉè GPT-4 ‰∏ÄÊ†∑„ÄÇ‰ΩÜ Gemini ÁöÑÊñ∞‰∏ä‰∏ãÊñáÁ™óÂè£ÂèØ‰ª•ÂÆπÁ∫≥ **100 ‰∏á** ‰∏™Ê†áËÆ∞ÔºåËøô‰∏ÄÂèòÂåñÁöÑÂΩ±ÂìçÊòØÂ∑®Â§ßÁöÑ„ÄÇ\n\n‰ΩÜÂú®Êàë‰ª¨ËÆ®ËÆ∫‰∏ä‰∏ãÊñáÁ™óÂè£ÂØπ LLM ËÉΩÂäõÁöÑÂΩ±Âìç‰πãÂâçÔºåÊàë‰ª¨ÈúÄË¶ÅÂõûÈ°æ‰∏Ä‰∏ã‰∏ä‰∏ãÊñáÁ™óÂè£ÁöÑÂ∑•‰ΩúÂéüÁêÜ„ÄÇ\n\n## ‰∏ä‰∏ãÊñáÁ™óÂè£ÔºàÁÆÄËÄåË®Ä‰πãÔºâ\n\nÁÆÄÂçïÊù•ËØ¥Ôºå‰∏ä‰∏ãÊñáÁ™óÂè£ËÆæÁΩÆ‰∫Ü LLM Âú®‰∫§‰∫íËøáÁ®ã‰∏≠ËÉΩÂ§üËÆ∞‰ΩèÂ§öÂ∞ë‰ø°ÊÅØ„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊÇ®Ê≠£Âú®‰ΩøÁî® ChatGPTÔºå‰∏ä‰∏ãÊñáÁ™óÂè£ÂåÖÊã¨ÊÇ®ÁªôÂÆÉÁöÑÂΩìÂâçÊèêÁ§∫„ÄÅÊÇ®‰πãÂâçÂú®ËØ•ÂØπËØù‰∏≠ËæìÂÖ•ÁöÑÊâÄÊúâÂÜÖÂÆπÔºå‰ª•Âèä ChatGPT ÂêëÊÇ®ÂèëÈÄÅÁöÑÊØè‰∏™ÂõûÂ§ç„ÄÇÂØπËØùÊó∂Èó¥Èïø‰∫ÜÔºåÊóßÁöÑÂØπËØùÈÉ®ÂàÜÂ∞Ü‰ºö‰ªé‰∏ä‰∏ãÊñáÁ™óÂè£‰∏≠ÊªëÂá∫ÔºåChatGPT Â∞ÜÁ™ÅÁÑ∂ÂøòËÆ∞ÈÇ£‰∫õÁªÜËäÇ„ÄÇ\n\n128,000 ‰∏™‰ª§ÁâåÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£Âê¨Ëµ∑Êù•ÂæàÂ§ßÔºå‰ΩÜËøô‰∏™Êï∞Â≠óÂÖ∑ÊúâËØØÂØºÊÄß„ÄÇÈ¶ñÂÖàÔºåËÄÉËôëÂà∞‰∏Ä‰∏™Âπ≥ÂùáÂçïËØçÂú®‰∏∫ LLM ÂàÜËß£Êó∂ÂÆûÈôÖ‰∏äÊòØ 1 Âà∞ 3 ‰∏™‰ª§Áâå„ÄÇÔºàÁªèÈ™åÊ≥ïÂàôÊòØ 4 ‰∏™‰ª§ÁâåÂØπÂ∫î 3 ‰∏™ÂçïËØçÔºå‰ΩÜÈöèÁùÄËØ≠Ë®ÄÂèòÂæóÊõ¥Âä†Â§çÊùÇÊàñÂú®‰∏ì‰∏öÈ¢ÜÂüüÔºàÂ¶ÇÊ≥ïÂæãÊàñÂåªÂ≠¶Ôºâ‰∏≠ÔºåËøô‰∏™Êï∞Â≠ó‰ºöÂ¢ûÂä†„ÄÇÔºâÂΩìÊÇ®Êü•ÁúãÈïøÊñáÊ°£„ÄÅËøõË°åÊåÅÁª≠‰∫§‰∫íÂíå AI È©±Âä®ÁöÑÂ∫îÁî®Á®ãÂ∫èÊó∂ÔºåÊÇ®‰ºöÂæàÂø´ÂèëÁé∞ÊÇ®Êó†Ê≥ïÂ∞ÜÊâÄÊúâÂ∏åÊúõ LLM Áü•ÈÅìÁöÑÂÜÖÂÆπÈÉΩÊîæÂÖ•ÂÖ∂‰∏ä‰∏ãÊñáÁ™óÂè£‰∏≠„ÄÇ\n\nÂõ†Ê≠§ÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∫õÂ∑ßÂ¶ôÁöÑÊñπÊ≥ïÊù•Ëß£ÂÜ≥‰∏ä‰∏ãÊñáÁ™óÂè£ÁöÑÈôêÂà∂„ÄÇ‰æãÂ¶ÇÔºö\n\n* **ÂàÜÂùó„ÄÇ** ÊÇ®ÂèØ‰ª•Â∞ÜÂ§ßÈáèÊï∞ÊçÆÂàÜËß£ÔºåËÆ© LLM ‰∏ÄÊ¨°Êü•Áúã‰∏ÄÈÉ®ÂàÜ„ÄÇËøôÂØπ‰∫éÊüê‰∫õ‰ªªÂä°ÔºàÊÄªÁªìÈïøÊñáÊ°£ÔºâÊïàÊûúÂæàÂ•ΩÔºå‰ΩÜÂ¶ÇÊûúÊÇ®ÈúÄË¶ÅÂàÜÊûêË∑®Êï¥‰∏™ÊñáÊ°£ÁöÑÊ¶ÇÂøµÔºåÂàôÊïàÊûú‰∏ç‰Ω≥„ÄÇ\n* **ÂæÆË∞É„ÄÇ** ÊÇ®ÂèØ‰ª•Áî®ÁâπÂÆöÁöÑÊï∞ÊçÆËÆ≠ÁªÉ LLM„ÄÇÈô§‰∫ÜÊó∂Èó¥ÂíåË¥πÁî®‰πãÂ§ñÔºåÂÖ≥ÈîÆÈóÆÈ¢òÊòØÊÇ®ÁöÑÊñ∞Êï∞ÊçÆÂæàÂÆπÊòìË¢´ LLM Â∑≤ÁªèÂê∏Êî∂ÁöÑÊõ¥Â§ßËßÑÊ®°ÁöÑÈÄöÁî®ËÆ≠ÁªÉÊï∞ÊçÆÊâÄÊ∑πÊ≤°„ÄÇÈÄöÂ∏∏ÔºåÂÆÉÂ∞±ÊòØÊó†Ê≥ï‰øùÁïô„ÄÇÊ≠§Â§ñÔºåËÆ∏Â§ö LLM Ê†πÊú¨‰∏çÊîØÊåÅÂæÆË∞É‚Äî‚ÄîÂåÖÊã¨ GPT-4 Âíå Gemini„ÄÇ\n* **Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG)„ÄÇ** È¶ñÂÖàÔºåÊÇ®Â∞ÜÊñáÊú¨ÂÜÖÂÆπËΩ¨Êç¢‰∏∫‰∏ÄÁßçÁâπÊÆäË°®Á§∫ÔºåÁß∞‰∏∫ *ÂµåÂÖ•*„ÄÇÔºàÂµåÂÖ•ÊòØ LLM Â∑•‰ΩúÁöÑÈáçË¶ÅÈÉ®ÂàÜ„ÄÇÂü∫Êú¨‰∏äÔºåÂÆÉ‰ª¨ÊòØÊçïÊçâÂÜÖÂÆπÂê´‰πâÁöÑÊï∞ÂÄºË°®Á§∫„ÄÇÔºâ‰∏ÄÊó¶ÊÇ®Êúâ‰∫ÜÂµåÂÖ•ÔºåÊÇ®Â∞±Â∞ÜÂÆÉ‰ª¨ÊîæÂÖ•ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇÁé∞Âú®ÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî® *ËØ≠‰πâÊêúÁ¥¢* ÁöÑÈ≠îÂäõÊü•ÁúãÊèêÁ§∫ÔºåÂπ∂Âú®Êï∞ÊçÆÂ∫ì‰∏≠ÊâæÂà∞‰∏é‰πãÊ¶ÇÂøµÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÁâáÊÆµÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËæìÂÖ• LLM„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÊÇ®Âè™ÁªôÂÆÉÊèê‰æõÈáçË¶ÅÁöÑÂÜÖÂÆπ„ÄÇ\n\nÊúÄÂêé‰∏ÄÁÇπÊòØ‰ªäÂ§©ÊúÄÂ∏∏ËßÅÁöÑÊñπÊ≥ï„ÄÇRAG È´òÊïà‰∏îÂèØÈ¢ÑÊµã„ÄÇÂ¶ÇÊûúÊÇ®Êã•ÊúâÂ§ßÈáèÊùæÊï£Áõ∏ÂÖ≥ÁöÑÊñáÊ°£ÔºåÂÆÉÊïàÊûúÈùûÂ∏∏Â•Ω„ÄÇ‰æãÂ¶ÇÔºåÊÉ≥Ë±°‰∏Ä‰∏ãÊÇ®Ê≠£Âú®ÂàõÂª∫‰∏Ä‰∏™ÊäÄÊúØÊîØÊåÅËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂÆÉ‰ªéÊÇ®ÂÖ¨Âè∏ÁöÑÁü•ËØÜÂ∫ìÊñáÁ´†‰∏≠Ëé∑Âèñ‰ø°ÊÅØ„ÄÇ‰ΩøÁî® RAGÔºåÊÇ®ÊâæÂà∞Áõ∏ÂÖ≥Êï∞ÊçÆÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÊÇ®ÁöÑÊèêÁ§∫‰∏ÄËµ∑Êèê‰æõÁªô LLM„ÄÇÂü∫Êú¨‰∏äÔºåÊÇ®ÊòØÂú®ÂëäËØâ LLM Âú®ÂõûÁ≠îÊèêÁ§∫Êó∂ËØ•ÂéªÂì™ÈáåÊü•Êâæ„ÄÇ\n\n‰ΩÜ RAG Âπ∂‰∏çÂÆåÁæé„ÄÇÂÆÉËø´‰ΩøÊÇ®Ëä±Ë¥πÊõ¥Â§öÊó∂Èó¥ÂáÜÂ§áÊï∞ÊçÆ„ÄÇÂÆÉ‰∏çÂÆπÊòìËÆ©ÊÇ®Ë∑≥ÂÖ•‰∏Ä‰∏™ÂÖ®Êñ∞ÁöÑÊï∞ÊçÆÈõÜ„ÄÇÂ¶ÇÊûúÊÇ®Á°ÆÂÆûÈúÄË¶Å‰∏ÄÊ¨°ËÄÉËôëÂ§ßÈáè‰ø°ÊÅØ‚Äî‚Äî‰æãÂ¶ÇÔºåÊÇ®Âú®ÂØªÊâæÂ∞èËØ¥‰∏≠ÁöÑÊï¥‰Ωì‰∏ªÈ¢òÊàñ‰ª£Á†ÅÂ∫ì‰∏≠ÁöÑÁâπÂæÅ‚Äî‚ÄîÈÇ£‰πàÂÆÉÂ∞±‰∏çÂ§üÊúâÊïà„ÄÇ‰ΩÜÂ∞ΩÁÆ°ÊúâÂÖ∂Â±ÄÈôêÊÄßÔºåRAG ‰ªäÂ§©‰ªçÁÑ∂Êé•ËøëÊúÄ‰Ω≥ÂÆûË∑µ„ÄÇ\n\nËá≥Â∞ëÔºåÂú® Gemini 1.5 Pro ÁøªËΩ¨ÂâßÊú¨‰πãÂâçÊòØËøôÊ†∑ÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EEHKDSH0wXa-J6veK5etZA.png)\n\n## ÊÉäËâ≥Êó∂Âàª\n\nÂ∞ΩÁÆ° Gemini 1\\.5 Pro Â∞öÊú™ÂèëÂ∏ÉÔºå‰ΩÜÂÆÉÂ∑≤ÁªèÂú®‰∏Ä‰∏™‰∏•Ê†ºÈôêÂà∂ÁöÑËØïÁî®‰∏≠ÂèØÁî®„ÄÇÁªìÊûú‰ª§‰∫∫Áû©ÁõÆ„ÄÇ\n\n‰∏Ä‰∫õÊúÄ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ‰æãÂ≠êÂ±ïÁ§∫‰∫Ü Gemini ÂàõÂª∫ÁöÑÂàÜÊûêÔºåÊ∂µÁõñ‰∫ÜÂ§ßÈáèÁü•ËØÜ„ÄÇË∞∑Ê≠åÁöÑÊºîÁ§∫‰∏ÄÂ¶ÇÊó¢ÂæÄÂú∞‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÔºå‰ΩÜ‰ªñ‰ª¨ËøáÂéªÊõæË¢´ÊåáÊéßËøõË°åÊºîÁ§∫ÊìçÊéßÂíåÈÄâÊã©ÊÄßÂ±ïÁ§∫„ÄÇÊàëÊõ¥ÊÑüÂÖ¥Ë∂£ÁöÑÊòØÁã¨Á´ãÊµãËØïËÄÖÔºå‰ªñ‰ª¨Êä•ÂëäÁöÑÁªìÊûúÂêåÊ†∑Âºï‰∫∫Ê≥®ÁõÆ„ÄÇ\n\n‰æãÂ¶ÇÔºåConor Grennan [Âêë Gemini Êèê‰æõ‰∫Ü‰∏ÄÈÉ® 300 È°µÁöÑÂ∞èËØ¥](https://www.youtube.com/watch?v=-MKGsijn5tI)ÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉÊèèËø∞‰∏ªË¶ÅËßíËâ≤„ÄÅÊâæÂá∫ÊÉÖËäÇËΩ¨ÊäòÔºåÂπ∂ËØÜÂà´ËßíËâ≤ÊÑüÂèóÁâπÂÆöÊÉÖÁª™ÁöÑ‰æãÂ≠ê„ÄÇGemini Âú®Êï¥ÈÉ®‰π¶ÁöÑËåÉÂõ¥ÂÜÖÂèëÂ±ïÁªÜËá¥ÁöÑËÆ∫ÁÇπÊØ´Êó†Âõ∞Èöæ„ÄÇYouTube ‰∏äÊµÅË°åÁöÑ [Fireship È¢ëÈÅì](https://www.youtube.com/c/fireship) ÁöÑÂàõ‰ΩúËÄÖ Jeff Delaney Âêë Gemini Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´Êï∞ÂçÉ‰∏™Êñá‰ª∂ÁöÑÂÆåÊï¥‰ª£Á†ÅÂ∫ìÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉÊ∑ªÂä†Êñ∞ÂäüËÉΩ„ÄÇGemini ‰∏ç‰ªÖÂÜôÂá∫‰∫ÜÊ≠£Á°ÆÁöÑ‰ª£Á†ÅÔºåËøòÈÅµÂæ™‰∫ÜÁé∞ÊúâÈ°πÁõÆÁöÑÈ£éÊ†ºÔºå‰ΩøÁî®‰∫ÜÂ∑≤ÁªèÂª∫Á´ãÁöÑÁªÑ‰ª∂„ÄÅÂ∫ìÂíåÁ∫¶ÂÆö„ÄÇÂÖ∂‰ªñÊºîÁ§∫Â±ïÁ§∫‰∫Ü Gemini ËØÜÂà´Â∫îÁî®Á®ãÂ∫è‰∏≠ÁöÑÈóÆÈ¢ò„ÄÅÊèêÂèñÂÖ≥ÈîÆÁ§∫‰æãÂπ∂ÁºñÂÜô API ÊñáÊ°£„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ÊÉ≥Ë¶ÅÂÖ∂‰ªñÂÜÖÂÆπÊù•Â°´ÂÖÖ Gemini Â∑®Â§ßÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÔºåËøòÊúâÂè¶‰∏Ä‰∏™Êñ∞ÂäüËÉΩ‚Äî‚ÄîËßÜÈ¢ë„ÄÇËßÜÈ¢ëÁöÑÊ†áËÆ∞ÊñπÂºè‰∏éÊñáÂ≠ó‰∏çÂêåÔºåÂç†Áî®ÁöÑÁ©∫Èó¥Ë¶ÅÂ§ßÂæóÂ§ö„ÄÇ‰ΩÜÂç≥‰æøÂ¶ÇÊ≠§Ôºå1 Áôæ‰∏áÊ†áËÆ∞ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÂèØ‰ª•ÂÆπÁ∫≥Â§ßÁ∫¶‰∏Ä‰∏™Â∞èÊó∂ÁöÑËßÜÈ¢ë‚Äî‚ÄîË∂≥Â§üÊµèËßà‰∏ÄÈÉ®ÁîµÂΩ±Âπ∂ÂõûÁ≠îÊúâÂÖ≥ÂÖ∂ÂÜÖÂÆπÁöÑÂ§çÊùÇÈóÆÈ¢ò„ÄÇËøôÂ∞±ÊòØË∞∑Ê≠åÊâÄÂÅöÁöÑÔºåÂΩìÂÆÉË¶ÅÊ±Ç Gemini [Êü•ÊâæÂÖ∑‰ΩìÁªÜËäÇ](https://www.youtube.com/watch?v=wa0MT8OwHuk) Âú®‰∏ÄÈÉ®Â∑¥ÊñØÁâπ¬∑Âü∫È°øÁöÑÁîµÂΩ±‰∏≠ÔºåÊØîÂ¶ÇÂú®‰ªñ‰ª¨Êú™ËØÜÂà´ÁöÑ‰∏Ä‰∏™Âú∫ÊôØ‰∏≠ÔºåÁ∫∏Áâá‰∏äÂÜôÁöÑÂ≠ó„ÄÇ\n\n## Êú™Êù•ÁöÑLLM\n\nÂ§ß‰∏ä‰∏ãÊñáÁ™óÂè£ÊòØÊú™Êù•ÁöÑÊñπÂêëÂêóÔºüÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊôÆÈÅçÁöÑÁúãÊ≥ïÊòØÔºåÂ§ß‰∏ä‰∏ãÊñáÁ™óÂè£ÂÖÖÂÖ∂ÈáèÂè™ÊòØ‰∏Ä‰∏™ÈÉ®ÂàÜËß£ÂÜ≥ÊñπÊ°à„ÄÇÊàë‰ª¨ÊãÖÂøÉÂÆÉ‰ª¨Âú®ËÆ°ÁÆóÊó∂Èó¥‰∏ä‰ºöËøá‰∫éÊòÇË¥µ„ÄÇ[‰∏ÄÈ°πÁ†îÁ©∂](https://www.voiceflow.com/blog/the-context-window-paradox-why-bigger-might-not-be-better)ÂèëÁé∞ÔºåLLMÂú®Èïø‰∏ä‰∏ãÊñáÁ™óÂè£‰∏≠ÊâæÂà∞‰ø°ÊÅØÁöÑËÉΩÂäõÂπ∂‰∏çÂ•ΩÔºåÂèçËÄåÂú®ÁªÜËäÇÂá∫Áé∞Âú®ÂºÄÂ§¥ÊàñÁªìÂ∞æÊó∂Ë°®Áé∞Êõ¥‰Ω≥„ÄÇÊâÄÊúâËøô‰∫õÂõ†Á¥†ÊîØÊåÅ‰∫ÜÂêåÊ†∑ÁöÑÁªìËÆ∫ÔºöÂ∞Ü‰Ω†ÁöÑÂÜÖÂÆπÂº∫Ë°åÂ°ûÂÖ•‰∏ä‰∏ãÊñáÁ™óÂè£ÊòØÂ§©ÁúüÁöÑ‰∏îÊàêÊú¨È´òÊòÇÁöÑ„ÄÇÂ∞ÜÊâÄÊúâÊï∞ÊçÆ‰∏ÄÊ¨°ÊÄßÂèëÈÄÅËØ∑Ê±ÇÁªù‰∏çÊòØ‰∏éLLMÂØπËØùÁöÑÊ≠£Á°ÆÊñπÂºè„ÄÇ\n\nÁé∞Âú®ÔºåÊú™Êù•‰ºº‰πéÁ™ÅÁÑ∂ÂèëÁîü‰∫ÜÂèòÂåñ„ÄÇÂ§ß‰∏ä‰∏ãÊñáÁ™óÂè£Âç≥Â∞ÜÊù•‰∏¥ÔºåÂÆÉ‰ª¨ÂèØËÉΩ‰ΩøLLMÂØπÂπøÊ≥õÁü•ËØÜÈõÜÊúâÊõ¥Âº∫Â§ß„ÄÅÊï¥‰ΩìÁöÑÁêÜËß£„ÄÇÂéªÂπ¥Áî®ÊñáÊú¨Êó†Ê≥ïÂÆåÊàêÁöÑ‰ªªÂä°Áé∞Âú®Âç≥Â∞ÜÂú®*ËßÜÈ¢ë*‰∏≠ÂèòÂæóÂèØËÉΩ„ÄÇËÄåË∞∑Ê≠åÁ†îÁ©∂Ê≠£Âú®Â∞ùËØï‰∏ÄÁßçÊâ©Â±ï‰∏ä‰∏ãÊñáÁ™óÂè£Âà∞ÊÉä‰∫∫ÁöÑ1000‰∏áÊ†áËÆ∞ÁöÑGeminiÂèò‰Ωì„ÄÇ\n\n‰∏§‰∏™‰∫ãÂÆûÊòØÊòéÁ°ÆÁöÑ„ÄÇÈ¶ñÂÖàÔºåÂú®LLMÊàò‰∫â‰∏≠ÈÄâÊã©Ëµ¢ÂÆ∂ÊòØ‰∏ÄÂú∫ÊÑöË†¢ÁöÑÊ∏∏Êàè„ÄÇÂÖ∂Ê¨°ÔºåÂèòÂåñÁöÑÈÄüÂ∫¶Ê≤°ÊúâÊîæÁºì‚Äî‚ÄîÂèçËÄåÂú®Âä†ÈÄü„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/google-releases-gemma-a-lightweight-and-open-source-model-b6411d67ecca","frontmatter":{"title":"Google ÂèëÂ∏É Gemma ‚Äî ËΩªÈáèÁ∫ßÂºÄÊ∫êÊ®°Âûã","meta_title":"Google ÂèëÂ∏É Gemma ‚Äî ËΩªÈáèÁ∫ßÂºÄÊ∫êÊ®°Âûã","description":"Google ÂèëÂ∏É‰∫Ü GemmaÔºåËøôÊòØ‰∏ÄÁ≥ªÂàóËΩªÈáèÁ∫ßÂºÄÊ∫êÊ®°ÂûãÔºåÂü∫‰∫éÂàõÂª∫ Gemini ÁöÑÁ†îÁ©∂ÂíåÊäÄÊúØÊûÑÂª∫‚Ä¶‚Ä¶","date":"2024-10-29T12:46:34.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*G7XbkhsCwillpje7AvETjQ.jpeg","categories":["Natural Language Processing","Programming","Chatbots"],"author":"Rifx.Online","tags":["Gemma","Gemini","parameters","NLP","chatbots"],"draft":false,"slug":"blog/google-releases-gemma-a-lightweight-and-open-source-model-b6411d67ecca"},"content":"\n\n\n\n\nÂú®Áü≠Áü≠‰∏ÄÂë®ÂÜÖÔºå‰∏ñÁïåËßÅËØÅ‰∫Ü‰∏§ÂÆ∂ÁßëÊäÄÂ∑®Â§¥Â∏¶Êù•ÁöÑÊúÄÂÖ∑Á™ÅÁ†¥ÊÄßÁöÑAIËøõÂ±ï„ÄÇOpenAIÊé®Âá∫‰∫Ü‰ª§‰∫∫ÊÉäÂèπÁöÑAIËßÜÈ¢ëÁîüÊàêÂô®[Sora](https://readmedium.com/3d16381f3bf5)ÔºåËÄåË∞∑Ê≠åÂàôÊè≠Êôì‰∫ÜÂÖ∂[Gemini 1.5Ê®°Âûã](https://generativeai.pub/google-releases-gemini-1-5-with-1m-context-window-44ed4a2ea319)ÔºåËÉΩÂ§üÊîØÊåÅÊúÄÂ§ö100‰∏áÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£„ÄÇ\n\n‰ªäÂ§©ÔºåË∞∑Ê≠åÂÜçÊ¨°ÂºïÂèëËΩ∞Âä®ÔºåÂèëÂ∏É‰∫Ü[Gemma](https://ai.google.dev/gemma/?utm_source=keyword&utm_medium=referral&utm_campaign=gemma_cta&utm_content)ÔºåËøôÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ß„ÄÅÊúÄÂÖàËøõÁöÑÂºÄÊ∫êÊ®°ÂûãÂÆ∂ÊóèÔºåÂª∫Á´ãÂú®Áî®‰∫éÂàõÂª∫GeminiÊ®°ÂûãÁöÑÁ†îÁ©∂ÂíåÊäÄÊúØÂü∫Á°Ä‰πã‰∏ä„ÄÇ\n\n## ‰ªÄ‰πàÊòØ GemmaÔºü\n\nGemma ‰ª•Êãâ‰∏ÅËØ≠ *gemma* ÊÑè‰∏∫‚ÄúÁèçË¥µÁöÑÂÆùÁü≥‚ÄùÂëΩÂêçÔºåÊ±≤Âèñ‰∫ÜÂÖ∂ÂâçË∫´ Gemini ÁöÑÁÅµÊÑüÔºåÂèçÊò†‰∫ÜÂÖ∂Âú®ÁßëÊäÄÈ¢ÜÂüüÁöÑ‰ª∑ÂÄºÂíåÁ®ÄÊúâÊÄß„ÄÇ\n\nÂÆÉ‰ª¨ÊòØÊñáÊú¨Âà∞ÊñáÊú¨„ÄÅ‰ªÖËß£Á†ÅÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊèê‰æõËã±ËØ≠ÁâàÊú¨ÔºåÂÖ∑ÊúâÂºÄÊîæÊùÉÈáç„ÄÅÈ¢ÑËÆ≠ÁªÉÂèò‰ΩìÂíåÊåá‰ª§Ë∞É‰ºòÂèò‰Ωì„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Fu2ryJMunebq5c0dD-opZQ.png)\n\nGemma ‰ªé‰ªäÂ§©Ëµ∑Âú®ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÊèê‰æõÔºåÂàÜ‰∏∫‰∏§ÁßçÂ∞∫ÂØ∏Ôºà2B Âíå 7BÔºâÔºåÊîØÊåÅÂπøÊ≥õÁöÑÂ∑•ÂÖ∑ÂíåÁ≥ªÁªüÔºåÂπ∂ÂèØÂú®ÂºÄÂèëËÄÖÁöÑÁ¨îËÆ∞Êú¨ÁîµËÑëÂíåÂ∑•‰ΩúÁ´ô‰∏äËøêË°å„ÄÇ\n\n## 2 Ê®°ÂûãÂ§ßÂ∞èÂíåËÉΩÂäõ\n\nGemma Ê®°ÂûãÊúâ 20 ‰∫øÂíå 70 ‰∫øÂèÇÊï∞‰∏§ÁßçËßÑÊ®°„ÄÇ2B Ê®°ÂûãÊó®Âú®ËøêË°åÂú®ÁßªÂä®ËÆæÂ§áÂíåÁ¨îËÆ∞Êú¨ÁîµËÑë‰∏äÔºåËÄå 7B Ê®°ÂûãÂàôÈÄÇÁî®‰∫éÊ°åÈù¢ËÆ°ÁÆóÊú∫ÂíåÂ∞èÂûãÊúçÂä°Âô®„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sH9jaz1RvtKeJ5yjfyOL5Q.png)\n\n**Ë∞É‰ºòÊ®°Âûã**\n\nGemma ËøòÊúâ‰∏§‰∏™ÁâàÊú¨ÔºöË∞É‰ºòÁâàÂíåÈ¢ÑËÆ≠ÁªÉÁâà„ÄÇ\n\n* **È¢ÑËÆ≠ÁªÉÔºö** ËøôÂ∞±ÂÉèÂü∫Á°ÄÊ®°ÂûãÔºåÊ≤°Êúâ‰ªª‰ΩïÂæÆË∞É„ÄÇËØ•Ê®°ÂûãÊ≤°ÊúâÈíàÂØπ Gemma Ê†∏ÂøÉÊï∞ÊçÆËÆ≠ÁªÉÈõÜ‰ª•Â§ñÁöÑÁâπÂÆö‰ªªÂä°ÊàñÊåá‰ª§ËøõË°åËÆ≠ÁªÉ„ÄÇ\n* **Êåá‰ª§Ë∞É‰ºòÔºö** ËØ•Ê®°ÂûãÁªèËøáÂæÆË∞ÉÔºå‰ª•ÈÄÇÂ∫î‰∫∫Á±ªËØ≠Ë®Ä‰∫§‰∫íÔºå‰ªéËÄåÊèêÈ´òÂÖ∂ÊâßË°åÁâπÂÆö‰ªªÂä°ÁöÑËÉΩÂäõ„ÄÇ\n\n## ÂÆÉ‰∏éÁ´û‰∫âÂØπÊâãÁöÑÊØîËæÉÔºü\n\nÁî±‰∫é‰ΩìÁßØÂ∞èÔºåGemmaËÉΩÂ§üÁõ¥Êé•Âú®Áî®Êà∑ÁöÑÁ¨îËÆ∞Êú¨ÁîµËÑë‰∏äËøêË°å„ÄÇ‰∏ãÂõæÊòæÁ§∫‰∫ÜGemma (7B)ÁöÑËØ≠Ë®ÄÁêÜËß£ÂíåÁîüÊàêÊÄßËÉΩ‰∏éÁ±ª‰ººËßÑÊ®°ÁöÑÂºÄÊîæÊ®°ÂûãÂ¶ÇLLaMA 2 (7B)„ÄÅLLaMA 2 (13B)ÂíåMistral (7B)ÁöÑÊØîËæÉ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QxjZALUAIDiS_T66EpOu-g.png)\n\nÊÇ®ÂèØ‰ª•Âú®[ËøôÈáå](https://ai.google.dev/gemma/?utm_source=keyword&utm_medium=referral&utm_campaign=gemma_cta&utm_content)Êü•ÁúãÊØè‰∏™Âü∫ÂáÜÁöÑÊõ¥ËØ¶ÁªÜÊØîËæÉ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Fc8Fk0Dgh2VFU_VLhpcs6Q.png)\n\n## ÂÆÉÁöÑÁî®ÈÄîÊòØ‰ªÄ‰πàÔºü\n\n‰ª•‰∏ãÊòØ Gemma ÂèØËÉΩÁöÑ‰ΩøÁî®Âú∫ÊôØÔºö\n\n**ÂÜÖÂÆπÂàõ‰Ωú‰∏éÊ≤üÈÄö**\n\n* ÊñáÊú¨ÁîüÊàê\n* ËÅäÂ§©Êú∫Âô®‰∫∫ÂíåÂØπËØùÂºè AI\n* ÊñáÊú¨ÊëòË¶Å\n\n**Á†îÁ©∂‰∏éÊïôËÇ≤**\n\n* **Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP) Á†îÁ©∂Ôºö** ‰Ωú‰∏∫ NLP Á†îÁ©∂ÁöÑÂü∫Á°ÄÔºåÂÆûÈ™åÊäÄÊúØÔºåÂºÄÂèëÁÆóÊ≥ïÔºåÂπ∂‰∏∫ËØ•È¢ÜÂüüÁöÑËøõÊ≠•ÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ\n* **ËØ≠Ë®ÄÂ≠¶‰π†Â∑•ÂÖ∑Ôºö** ÊîØÊåÅ‰∫íÂä®ËØ≠Ë®ÄÂ≠¶‰π†‰ΩìÈ™åÔºåÂ∏ÆÂä©ËØ≠Ê≥ïÁ∫†Ê≠£ÔºåÊàñÊèê‰æõÂÜô‰ΩúÁªÉ‰π†„ÄÇ\n* **Áü•ËØÜÊé¢Á¥¢Ôºö** Â∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÈÄöËøáÁîüÊàêÊëòË¶ÅÊàñÂõûÁ≠îÁâπÂÆö‰∏ªÈ¢òÁöÑÈóÆÈ¢òÊù•Êé¢Á¥¢Â§ßÈáèÊñáÊú¨„ÄÇ\n\n‰ª•ÂâçÈúÄË¶ÅÊûÅÂ§ßÊ®°ÂûãÁöÑ‰ªªÂä°Áé∞Âú®ÂèØ‰ª•ÈÄöËøáÊúÄÂÖàËøõÁöÑÂ∞èÂûãÊ®°ÂûãÊù•ÂÆûÁé∞„ÄÇËøôÂºÄÂêØ‰∫ÜÂºÄÂèë AI Â∫îÁî®Á®ãÂ∫èÁöÑÂÖ®Êñ∞ÊñπÂºèÔºåÊàë‰ª¨ÂæàÂø´ÂèØËÉΩ‰ºöÂú®Êô∫ËÉΩÊâãÊú∫‰∏äÁúãÂà∞Êó†ÈúÄ‰∫íËÅîÁΩëËøûÊé•ÁöÑËÆæÂ§áÂÜÖ AI ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ\n\nËøôÊúâÂ§ö‰ª§‰∫∫ÂÖ¥Â•ãÂë¢Ôºü\n\n## ËøôÁúüÁöÑÂ•ΩÂêóÔºü\n\nÂá†‰Ωç [redditors](https://www.reddit.com/r/LocalLLaMA/comments/1awbqwd/gemma_7b_the_latest_opensource_model_from_google/) ÂàÜ‰∫´‰∫Ü‰ªñ‰ª¨‰ΩøÁî® Gemma ÁöÑÁªèÈ™åÔºåÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÁªìÊûúÂπ∂‰∏çÁêÜÊÉ≥„ÄÇÁúãÁúãËøô‰∏™‰æãÂ≠êÔºåGemma Âú®ÂõûÁ≠îÂÖ≥‰∫éÈáçÈáèÁöÑÈóÆÈ¢òÊó∂ÁªôÂá∫‰∫ÜÈîôËØØÁöÑÁ≠îÊ°à„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Sdaiaqcuz7qbftG1)\n\nÊàëËá™Â∑±ËøòÊ≤°ÊúâÁúüÊ≠£Â∞ùËØïËøáÔºå‰ΩÜÈáçË¶ÅÁöÑÊòØË¶ÅËÆ∞‰ΩèÔºåÂÉèËøôÊ†∑ÁöÑËæÉÂ∞èÊ®°ÂûãÈ¢ÑËÆ°‰ºöÊúâ‰∏Ä‰∫õÁº∫Èô∑ÔºåÊúâÊó∂ÂèØËÉΩ‰ºöÁªôÂá∫ÈîôËØØÁöÑÁ≠îÊ°à„ÄÇ\n\n## Â∞ùËØïËá™Â∑±Âä®Êâã\n\nÊÇ®ÂèØ‰ª•‰ªäÂ§©ÂºÄÂßã‰ΩøÁî®GemmaÔºåÈÄöËøáKaggleÁöÑÂÖçË¥πËÆøÈóÆ„ÄÅColabÁ¨îËÆ∞Êú¨ÁöÑÂÖçË¥πÂ±Ç‰ª•ÂèäÈ¶ñÊ¨°‰ΩøÁî®Google CloudÁöÑÁî®Êà∑ÂèØËé∑ÂæóÁöÑ$300‰ø°Áî®È¢ùÂ∫¶„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BrvLnczy724TPrsk-uFJCw.png)\n\nÂ¶ÇÊûúÊÇ®ÊúâÂÖ¥Ë∂£ÂºÄÂßã‰ΩøÁî®GemmaÔºåËØ∑Êü•ÁúãËøô‰∫õÊåáÂçóÔºå‰ª•‰∫ÜËß£‰ªéÊñáÊú¨ÁîüÊàêÂà∞Âú®GemmaÊ®°Âºè‰∏ãÈÉ®ÁΩ≤ÁöÑËøáÁ®ãÔºö\n\n* **‰ΩøÁî®GemmaËøõË°åÊñáÊú¨ÁîüÊàê**ÔºöÊûÑÂª∫‰∏Ä‰∏™Âü∫Êú¨ÁöÑÊñáÊú¨ÁîüÊàêÁ§∫‰æã„ÄÇ\n* **‰ΩøÁî®LoRAË∞É‰ºòGemma**ÔºöÂØπGemma 2BÊ®°ÂûãËøõË°åLoRAÂæÆË∞É„ÄÇ\n* **‰ΩøÁî®ÂàÜÂ∏ÉÂºèËÆ≠ÁªÉË∞É‰ºòGemmaÊ®°Âûã**Ôºö‰ΩøÁî®KerasÂíåJAXÂêéÁ´ØÂØπGemma 7BÊ®°ÂûãËøõË°åLoRAÂíåÊ®°ÂûãÂπ∂Ë°åÁöÑÂæÆË∞É„ÄÇ\n* **Â∞ÜGemmaÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢É**Ôºö‰ΩøÁî®Vertex AIÂ∞ÜGemmaÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢É„ÄÇ\n\n## ‰∏ãËΩΩÊ®°Âûã\n\nÂºÄÊîæÊ®°ÂûãÁõÆÂâçÂèØÂú® [HuggingFace](https://huggingface.co/models?other=gemma&sort=trending&search=google) ‰∏äËé∑Âèñ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mJRzGhO1sUxPL4_3YjpNGA.png)\n\nGemma Ê®°Âûã‰πüÂèØ‰ª•‰ªé [Kaggle Models](https://www.kaggle.com/models/google/gemma) ‰∏ãËΩΩ„ÄÇ\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nËôΩÁÑ∂GemmaÊ®°ÂûãÂèØËÉΩ‰ΩìÁßØÂ∞è‰∏îÁº∫‰πèÂ§çÊùÇÊÄßÔºå‰ΩÜÂÆÉ‰ª¨Âú®ÈÄüÂ∫¶Âíå‰ΩøÁî®ÊàêÊú¨‰∏äÂèØËÉΩ‰ºöÊúâÊâÄÂº•Ë°•„ÄÇ\n\n‰ªéÊõ¥Â§ßÁöÑËßíÂ∫¶Êù•ÁúãÔºåË∞∑Ê≠åÂπ∂‰∏çÊòØËøΩÈÄêÁü≠ÊúüÁöÑÊ∂àË¥πËÄÖÂÖ¥Â•ãÔºåËÄåÊòØÂú®‰∏∫‰ºÅ‰∏öÂüπËÇ≤Â∏ÇÂú∫„ÄÇ‰ªñ‰ª¨ËÆæÊÉ≥ÂÖ¨Âè∏‰ºö‰∏∫Ë∞∑Ê≠å‰∫ëÊúçÂä°‰ªòË¥πÔºåÂõ†‰∏∫ÂºÄÂèëËÄÖ‰ΩøÁî®GemmaÊù•ÂàõÂª∫ÂàõÊñ∞ÁöÑÊñ∞Ê∂àË¥πÂ∫îÁî®„ÄÇ\n\nÊ≠§Â§ñÔºåÂ∞ΩÁÆ°GeminiÁöÑÂèçÂìçÂπ≥Âπ≥ÔºåË∞∑Ê≠å‰ªçÁÑ∂Â±ïÁ§∫‰∫ÜÂÆÉËøòÊúâÊõ¥Â§öÁöÑÁßòÂØÜÊ≠¶Âô®„ÄÇ\n\nÂΩìÁÑ∂ÔºåÂØπ‰∫é‰ªª‰ΩïÂº∫Â§ßÁöÑÊäÄÊúØÊù•ËØ¥ÔºåÁúüÊ≠£ÁöÑËÄÉÈ™åÊòØÂÆÉÁöÑÂÆûÈôÖÊïàÊûú„ÄÇË∞∑Ê≠åÁöÑËøáÂéªÂºïÂèë‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºöËøô‰∫õÊ®°ÂûãÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑË°®Áé∞ÊòØÂê¶ËÉΩÂ¶ÇÊâøËØ∫ÁöÑÈÇ£Ê†∑Âá∫Ëâ≤„ÄÇÂØÜÂàáÂÖ≥Ê≥®Ëøô‰∏ÄÁÇπÊòØÈáçË¶ÅÁöÑÔºå‰ΩÜ‰πüÂ∏åÊúõË∞∑Ê≠åËÉΩ‰ªéËøáÂéª‰∏≠Âê∏ÂèñÊïôËÆ≠ÔºåÊèê‰æõÁúüÊ≠£ÂèØÊØîÁîöËá≥‰ºò‰∫éÁ´û‰∫âÂØπÊâãÁöÑÊ®°Âûã„ÄÇ\n\nÊàëËø´‰∏çÂèäÂæÖÊÉ≥Ë¶Å‰ΩìÈ™åGemmaÔºåÂπ∂‰∏îÊàë‰∏ÄÂÆö‰ºöÂàÜ‰∫´ÊàëÂØπËøô‰∏™Êñ∞AIÊ®°ÂûãÁöÑÂàùÊ≠•ÊÉ≥Ê≥ïÂíåÂèëÁé∞„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*8BDnUV9iQisOyeN3.png)\n\nËøôÁØáÊñáÁ´†ÂèëÂ∏ÉÂú®[Generative AI](https://generativeai.pub/)„ÄÇËØ∑Âú®[LinkedIn](https://www.linkedin.com/company/generative-ai-publication)‰∏ä‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥®[Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•Ëé∑ÂèñÊúÄÊñ∞ÁöÑAIÊïÖ‰∫ã„ÄÇËÆ©Êàë‰ª¨‰∏ÄËµ∑Â°ëÈÄ†AIÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*JeeoUhaBYUJGr0Xq.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/goover-a-new-search-engine-challenging-perplexity-ai-18c38b75dece","frontmatter":{"title":"Goover - ‰∏ÄÁßçÊåëÊàò‰∫∫Â∑•Êô∫ËÉΩÂ§çÊùÇÊÄßÁöÑÊñ∞ÊêúÁ¥¢ÂºïÊìé","meta_title":"Goover - ‰∏ÄÁßçÊåëÊàò‰∫∫Â∑•Êô∫ËÉΩÂ§çÊùÇÊÄßÁöÑÊñ∞ÊêúÁ¥¢ÂºïÊìé","description":"GooverÊòØ‰∏ÄÊ¨æÊñ∞ÂÖ¥ÁöÑAIÈ©±Âä®ÊêúÁ¥¢ÂºïÊìéÔºåÊó®Âú®ÊåëÊàòPerplexity AIÔºåÊèê‰æõÂáÜÁ°ÆÁöÑÊêúÁ¥¢ÁªìÊûúÂíåÁî®Êà∑ÂèãÂ•ΩÁöÑ‰ΩìÈ™å„ÄÇÂÖ∂‰∏ªË¶ÅÁâπÁÇπÂåÖÊã¨Ê¥ûÂØüÊä•Âëä„ÄÅË∂Ö‰∏™ÊÄßÂåñÁÆÄÊä•„ÄÅÊ∑±Â∫¶ÂíåÂø´ÈÄüÂõûÁ≠îÔºå‰ª•ÂèäÂèÇËÄÉËøΩË∏™ÂäüËÉΩ„ÄÇ‰∏éPerplexityÁõ∏ÊØîÔºåGooverÂú®Á†îÁ©∂ËÉΩÂäõÂíå‰ø°ÊÅØÊù•Ê∫êÁöÑÂ§öÊ†∑ÊÄß‰∏äË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®Êüê‰∫õÈÄªËæëÂíåÊï∞Â≠¶ÈóÆÈ¢ò‰∏ä‰ªçÊúâÂæÖÊîπËøõ„ÄÇGooverÁöÑÊú™Êù•ÂèëÂ±ïÊΩúÂäõÂ∑®Â§ßÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∏™ÊÄßÂåñÂíåÁîüÊàêÂºèAIÁöÑÁªìÂêàÊñπÈù¢„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YQH6-bv6bjVn199pk1uC-Q.jpeg","categories":["Technology/Web","AI","Search Engines"],"author":"Rifx.Online","tags":["Goover","accuracy","user-friendliness","fact-checked","misinformation"],"draft":false,"slug":"blog/goover-a-new-search-engine-challenging-perplexity-ai-18c38b75dece"},"content":"\n\n\n\n\nÂú® 2024 Âπ¥ÔºåÊêúÁ¥¢ÂºïÊìéÂ∏ÇÂú∫ÁªèÂéÜ‰∫Ü‰∏ÄÊ¨°ÈáçÂ§ßÂèòÈù©„ÄÇË∞∑Ê≠åÊêúÁ¥¢‰Ωú‰∏∫ÊúÄÂ§ßÂíåÊúÄÂèóÊ¨¢ËøéÁöÑÊêúÁ¥¢ÂºïÊìéÔºåÂú®Êé®Âá∫ÂÖ∂Êñ∞ÁöÑ AI È©±Âä®Ê¶ÇËßàÂäüËÉΩÂêéÔºåÈù¢‰∏¥‰∫Ü‰∏ÄÊ≥¢ÊâπËØÑÔºåËÆ∏Â§öÁî®Êà∑ËÆ§‰∏∫ËØ•ÂäüËÉΩÂåÜÂøô‰∏äÁ∫ø‰∏î‰∏çÂ§üÂÆåÂñÑ„ÄÇ\n\n‰∏éÊ≠§ÂêåÊó∂ÔºåAI È©±Âä®ÁöÑÊêúÁ¥¢ÂºïÊìé Perplexity AI Âø´ÈÄüËé∑Âæó‰∫Ü‰∫∫Ê∞îÔºåÂõ†ÂÖ∂Â§áÂèóËµûË™âÁöÑÂäüËÉΩËÄåÁßØÁ¥Ø‰∫ÜÂø†ÂÆûÁî®Êà∑Áæ§„ÄÇÊúÄËøëÔºåÁîöËá≥ OpenAI ‰πüÈÄöËøáÂú® ChatGPT ‰∏≠Êï¥ÂêàÊñ∞ÁöÑÊêúÁ¥¢ÂäüËÉΩÂä†ÂÖ•‰∫ÜÊêúÁ¥¢È¢ÜÂüü„ÄÇ\n\nÈöèÁùÄË∂äÊù•Ë∂äÂ§öÁöÑ AI È©±Âä®ÊêúÁ¥¢ÂºïÊìéÁöÑÂá∫Áé∞ÔºåÁ°ÆÂÆöÂì™‰∏™ÊòØÊúÄÂ•ΩÁöÑÂèòÂæóË∂äÊù•Ë∂äÊ£òÊâã„ÄÇ\n\nÁé∞Âú®ÔºåÊúâ‰∏Ä‰∏™Êñ∞Áé©ÂÆ∂ËøõÂÖ•‰∫Ü AI È©±Âä®ÊêúÁ¥¢ÂºïÊìéÁöÑÂ∏ÇÂú∫ÔºåÊâøËØ∫Êèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÁªìÊûú‚Äî‚ÄîÂÆÉË¢´Áß∞‰∏∫ [**Goover**](https://intro.goover.ai/)„ÄÇ\n\n## ‰ªÄ‰πàÊòØ GooverÔºü\n\nGoover ÊòØ‰∏Ä‰∏™Êñ∞ÁöÑ AI ÊêúÁ¥¢Âπ≥Âè∞ÔºåÊèê‰æõÁ±ª‰ºº‰∫é Perplexity AI ÁöÑÁªèËøá‰∫ãÂÆûÊ£ÄÊü•ÂíåÂèÇËÄÉÊîØÊåÅÁöÑËßÅËß£„ÄÇÂÆÉÊèê‰æõ‰∏Ä‰∏™ÂèØÈù†ÁöÑ„ÄÅ‰∫íÂä®ÁöÑ AI ‰ΩìÈ™åÔºå‰∏ìÊ≥®‰∫éÂáÜÁ°ÆÊÄßÂíåÁî®Êà∑ÂèãÂ•ΩÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-k5wsFFeO-wxsgQmC4R6sA.png)\n\nGoover ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™Êñ∞Âπ≥Âè∞ÔºåÂÖ¨Âè∏Êú™Êù•ËøòÊúâÂæàÂ§öÊõ¥ÈÖ∑ÁöÑÂäüËÉΩË¶ÅÊé®Âá∫„ÄÇÊÇ®ÂèØ‰ª•Âú® [ËøôÈáå](https://intro.goover.ai/) Êü•ÁúãÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ\n\n## GooverÁöÑ‰∏ªË¶ÅÁâπÊÄß\n\nGooverÈÖçÂ§á‰∫ÜÂ§öÁßçÊúâË∂£ÁöÑÂäüËÉΩÔºö\n\n* **Ê¥ûÂØüÊä•ÂëäÔºö** ÂÆÉÈááÁî®‰∫Ü‰∏Ä‰∫õÂÖàËøõÁöÑLLMÊäÄÊúØÔºåÂàÜÊûêÊÇ®ÁöÑÊï∞ÊçÆÂπ∂ÁîüÊàêÂÖ®Èù¢ÁöÑÊä•Âëä„ÄÇ\n* **Ë∂Ö‰∏™ÊÄßÂåñÁÆÄÊä•Ôºö** ÂèëÁé∞‰∏ªÈ¢òÊëòË¶Å„ÄÅÊ¥ûÂØüÊä•Âëä‰ª•Âèä‰∏ÄÁ≥ªÂàó‰∏™ÊÄßÂåñÊé®Ëçê„ÄÇ\n* **Ê∑±Â∫¶ÂõûÁ≠îÔºö** ÂΩìÊÇ®ÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ≠îÊ°àÊó∂ÔºåGooverÂèØ‰ª•Êèê‰æõ„ÄÇËøô‰∫õÂõûÁ≠îÁîüÊàêÊó∂Èó¥Á®çÈïøÔºå‰ΩÜÊèê‰æõÊõ¥ËØ¶ÁªÜ„ÄÅÊ∑±ÊÄùÁÜüËôëÁöÑËßÅËß£„ÄÇ\n* **Âø´ÈÄüÂõûÁ≠îÔºö** ÈÄÇÂêàÊÇ®ÈúÄË¶ÅÂø´ÈÄüËé∑ÂèñÁÆÄÂçï‰ø°ÊÅØÊó∂„ÄÇGooverÊèê‰æõÁÆÄÊòéÁöÑÁ≠îÊ°àÔºåÂêåÊó∂‰∏çÁâ∫Áâ≤Áõ∏ÂÖ≥ÊÄß„ÄÇ\n\n## GooverÁöÑÁã¨Áâπ‰πãÂ§ÑÊòØ‰ªÄ‰πàÔºü\n\n‰ª•‰∏ãÊòØÂ∞ÜÂÖ∂‰∏éÂÖ∂‰ªñAIÊêúÁ¥¢ÂºïÊìéÂå∫ÂàÜÂºÄÊù•ÁöÑÂäüËÉΩÈõÜ„ÄÇ\n\n* **ÁÆÄÊä•È°µÈù¢**ÔºöÂø´ÈÄü„ÄÅÁõ∏ÂÖ≥ÁöÑ‰∏ªÈ¢òÊëòË¶ÅËÆ©Áî®Êà∑Âú®‰∏çÈúÄÈïøÊó∂Èó¥ÈòÖËØªÁöÑÊÉÖÂÜµ‰∏ã‰øùÊåÅ‰ø°ÊÅØÁÅµÈÄö„ÄÇ\n* **ÂèÇËÄÉËøΩË∏™**ÔºöÊØè‰∏™ÂìçÂ∫îÈÉΩÈìæÊé•Âà∞ÂèØ‰ø°ÁöÑÊù•Ê∫êÔºåÁ°Æ‰øùÈÄèÊòéÂ∫¶Âπ∂ÂáèÂ∞ëÈîôËØØ‰ø°ÊÅØ„ÄÇ\n* **ÂèçÂπªËßâ**ÔºöÂìçÂ∫îÂü∫‰∫éÁªèËøáÈ™åËØÅÁöÑÊï∞ÊçÆÔºåÂ¢ûÂº∫ÂèØ‰ø°Â∫¶„ÄÇ\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ÁúãÁúãÂÆÉ‰∏éPerplexity AIÁöÑÊ≠£Èù¢ÊØîËæÉ„ÄÇ\n\n## ÂÆÉ‰∏é Perplexity AI ÁöÑÊØîËæÉÂ¶Ç‰ΩïÔºü\n\nËÆ©Êàë‰ª¨‰ªéÁî®Êà∑ÁïåÈù¢ÂºÄÂßã„ÄÇ\n\nGoover Âíå Perplexity ÈÉΩÊúâÂπ≤ÂáÄÁöÑËÆæËÆ°Ôºå‰∏≠Â§ÆÊúâ‰∏Ä‰∏™ÊòæËëóÁöÑÊêúÁ¥¢Ê°Ü„ÄÇÁÑ∂ËÄåÔºåGoover Âú®ÊêúÁ¥¢Ê†è‰∏ãÊñπÊúâ‰∏Ä‰∏™‚ÄúÊô∫ËÉΩÊé®ÈÄÅ‚ÄùÂíå‚ÄúÊô∫ËÉΩÁÆÄÊä•‚ÄùÈÉ®ÂàÜ„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ÊòØ‰∏Ä‰∏™ÂÆöÊúüÊü•ÁúãÊñ∞ÈóªÊàñÂ∏åÊúõÂø´ÈÄüËé∑Âèñ‰∏ä‰º†Êñá‰ª∂ËßÅËß£ÁöÑ‰∫∫ÔºåÊÇ®‰ºöÊ¨£Ëµè Goover ‰∏≠Ëøô‰∫õÈôÑÂä†ÂäüËÉΩ„ÄÇ\n\n‰ª•‰∏ãÊòØÂÆÉ‰ª¨‰∏ªÈ°µÁöÑÂπ∂ÊéíÊØîËæÉÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rDQjkIvsy2gXKGIO4-y5Lg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*r-x6e8SVT7QdFNDOj5i54w.png)\n\nGoover Âè¶‰∏Ä‰∏™ÊòæËëóÁâπÁÇπÊòØÊîØÊåÅÊõ¥ÂπøÊ≥õÁöÑÊñá‰ª∂Á±ªÂûã„ÄÇÈô§‰∫Ü‰º†ÁªüÁöÑÊñá‰ª∂‰∏ä‰º†ÔºåÊÇ®ËøòÂèØ‰ª•ÈôÑÂä†‰∏™‰∫∫Á¨îËÆ∞„ÄÅ‰øùÂ≠òÁöÑÈìæÊé•ÂíåËµÑÊ∫ê„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*U9TPAhUoZPRXGIg6GbWLQA.png)\n\nËÄå Perplexity ‰ªÖÊîØÊåÅÊñá‰ª∂‰∏ä‰º†„ÄÇ\n\n‰ª•‰∏ãÊòØÊÇ®Â∞ùËØïÂú® Goover ‰∏≠‰∏ä‰º†Êñá‰ª∂„ÄÅÁ¨îËÆ∞Âíå URL ‰Ωú‰∏∫ÂèÇËÄÉÊó∂ÁöÑÊ†∑Â≠êÔºåÁÑ∂ÂêéÂÆÉÂºÄÂßãÂú®ÁΩëÁªúÊàñÁü•ËØÜÂ∫ì‰∏≠ËøõË°åÊêúÁ¥¢„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VAQbKV7LMhEDOgvxRqKoUQ.png)\n\nËøôÁßçÈ¢ùÂ§ñÁöÑÁÅµÊ¥ªÊÄßÂØπ‰∫éÈúÄË¶ÅÊúâÁªÑÁªáÂíåÂÖ®Èù¢Á†îÁ©∂ÁöÑÁî®Êà∑ÂèØËÉΩÂæàÊúâÁî®„ÄÇ\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ÁúãÁúã Goover Âíå Perplexity Âú®‰ª•‰∏ãËÉΩÂäõÊñπÈù¢ÁöÑË°®Áé∞Ôºö\n\n1. **Á†îÁ©∂ËÉΩÂäõ**\n2. **Êï∞Â≠¶ËÆ°ÁÆó**\n3. **ÁΩëÁªúÊêúÁ¥¢ËÉΩÂäõ**\n4. **ÈÄªËæëÈóÆÈ¢ò**\n\n## Á†îÁ©∂ËÉΩÂäõ\n\nÂú®Ëøô‰∏™ÊµãËØï‰∏≠ÔºåÊàëÊÉ≥ÁúãÁúãËøô‰∏§‰∏™Â∑•ÂÖ∑ÊòØÂê¶ËÉΩÂ§üÂáÜÁ°ÆÊèê‰æõÊµÅË°åÁöÑ AI ÂõæÂÉèÊ®°ÂûãÁöÑÂèëÂ∏ÉÊó•ÊúüÂíåÁâàÊú¨„ÄÇ\n\n> **ÊèêÁ§∫Ôºö** ÁªôÊàë‰∏Ä‰∏™ÊúÄ‰Ω≥ÂíåÊúÄÊµÅË°åÁöÑ AI ÂõæÂÉèÁîüÊàêÊ®°ÂûãÁöÑÊó∂Èó¥Á∫øÔºàStable diffusion, Dall\\-E, Imagen, Midjourney, FluxÔºâ\n\nËøôÊòØ Goover ÁöÑÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RfiaKnkpyFuczXnhwkGmVA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xVGPee-zmBD9b35zWChOPw.png)\n\nÊ≠£Â¶Ç‰Ω†ÊâÄÁúãÂà∞ÁöÑÔºåAI Áªô‰∫ÜÊàë 11 ‰∏™ÂõæÂÉèÊ®°ÂûãÁöÑÊó∂Èó¥Á∫ø„ÄÇÁÑ∂ËÄåÔºåPerplexity Âè™ÊèêÂà∞‰∫Ü 9 ‰∏™Ê®°Âûã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*faI78jCmgKyyy55sF7C2Ww.png)\n\n‰ªîÁªÜËßÇÂØüÁªìÊûúÔºåÊàëÊ≥®ÊÑèÂà∞ Goover ËÉΩÂ§üËé∑ÂèñÂÖ≥‰∫éÂç≥Â∞ÜÂèëÂ∏ÉÁöÑ Midjourney V7 ÁöÑ‰ø°ÊÅØ„ÄÇËøôÊòØ Perplexity Êó†Ê≥ïÊèê‰æõÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*X6ERPPq83MxYV4soHmptJA.png)\n\nËøôÁßçÁªÜËäÇ‰Ωø Goover ÂÖ∑Êúâ‰ºòÂäøÔºåÁâπÂà´ÊòØÂØπ‰∫éÂ∏åÊúõÈ¶ñÊ¨°Ëé∑ÂæóÂÖ®Èù¢‰ø°ÊÅØÁöÑÁî®Êà∑„ÄÇ\n\nËÆ©Êàë‰ª¨ÂÜçÂÅö‰∏Ä‰∏™„ÄÇ\n\n> **ÊèêÁ§∫Ôºö** ÈùûÊ≥ïËΩØ‰ª∂‰ΩøÁî®Êúâ‰ªÄ‰πàÂΩ±ÂìçÔºü\n\nËøôÊòØ Goover ÁöÑÂõûÂ∫î„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-dXyfPSvedPgL0HF4keQXg.png)\n\nËøôÊòØ Perplexity ÁöÑÂõûÂ∫îÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*m2PtvdNZYRqq44pYHIW_5A.png)\n\nÊàë‰∏ç‰ºöÈÄê‰∏ÄÂàÜÊûêÁªìÊûú‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Âá†‰πéÊòØÁõ∏ÂêåÁöÑ„ÄÇ‰∏çËøáÔºåÊàëÊõ¥ÊÑüÂÖ¥Ë∂£ÁöÑÊòØÁªìÊûúÊù•Ê∫êÁöÑËµÑÊ∫ê„ÄÇ\n\n‰æãÂ¶ÇÔºåÂú® Goover ‰∏≠ÔºåÂÆÉÁöÑÁªìÊûúÊù•Ëá™ 9 ‰∏™‰∏çÂêåÁöÑÂèÇËÄÉ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ui7heEqn9_rHrFsajwallg.png)\n\nÂú® Perplexity ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆÉ‰ΩøÁî®‰∫Ü 8 ‰∏™‰∏çÂêåÁöÑËµÑÊ∫êÔºåÊØî Goover Â∞ë‰∫Ü‰∏Ä‰∏™ÂèÇËÄÉ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3VoAf71E6GIIVB9TwQmFQA.png)\n\nÊ≠§Â§ñÔºåÂú® Goover ÁöÑÂèÇËÄÉÈÉ®ÂàÜÔºåÊàëÂèØ‰ª•ÁÇπÂáª‚ÄúGo over‚ÄùÊåâÈíÆÔºåAI Â∞Ü‰∏∫ÊàëÁîüÊàêÂÜÖÂÆπÁÆÄÊä•„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RK50j4XxB_jWa9nzvtXYQQ.png)\n\nÂæàÈÖ∑ÔºåÂØπÂêßÔºü\n\n## ÁΩëÈ°µÊé¢Á¥¢ËÉΩÂäõ\n\nÊé•‰∏ãÊù•ÔºåÊàëÊÉ≥ÁúãÁúãÊØè‰∏™Âπ≥Âè∞Âú®Êé¢Á¥¢ÂíåÂàÜÊûêÊñ∞ÁΩëÁ´ôÊñπÈù¢ÁöÑË°®Áé∞„ÄÇ\n\nÂú®‰∏ãÈù¢ÁöÑÊèêÁ§∫‰∏≠ÔºåÊàëËØ¢ÈóÆ‰∫ÜÊàëÂá†‰∏™ÊúàÂâçÊé®Âá∫ÁöÑÊñ∞ [ÁΩëÁ´ô](https://www.zeniteq.com/)Ôºö\n\n> ÊèêÁ§∫ÔºöZeniteqÊòØ‰ªÄ‰πàÔºüÊàëÊåáÁöÑÊòØzeniteq.comÁΩëÁ´ô\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8QQ_JuIeE2mh8zQV4Ns8wQ.png)\n\n> ZeniteqÔºåÂ¶ÇÂÖ∂ÁΩëÁ´ô [zeniteq.com](http://zeniteq.com/) ÊâÄÁ§∫Ôºå‰ºº‰πéÊòØ‰∏ÄÂÆ∂ÂèØËÉΩ‰∏ìÊ≥®‰∫éÂÖàËøõÊäÄÊúØËß£ÂÜ≥ÊñπÊ°àÁöÑÂÖ¨Âè∏ÔºåÊΩúÂú®È¢ÜÂüüÂåÖÊã¨‰∫∫Â∑•Êô∫ËÉΩ„ÄÅÊï∞ÊçÆÂàÜÊûêÊàñÂàÜÊûêÊäÄÊúØÔºåÁ±ª‰ºº‰∫éËØ•È¢ÜÂüüÁöÑÂÖ∂‰ªñÂÖ¨Âè∏ÔºåÂ¶ÇQinetiQ„ÄÇ\n\nGooverÂú®ÊüêÁßçÁ®ãÂ∫¶‰∏äÊòØÊ≠£Á°ÆÁöÑÔºåÁΩëÁ´ôÁ°ÆÂÆû‰∏éÊäÄÊúØÊúâÂÖ≥Ôºå‰ΩÜÂÖ∂ÂõûÁ≠îËØ≠Ê∞î‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄß‰ΩøÂÖ∂Êàê‰∏∫‰∏Ä‰∏™‰∏çÂ§™ÂèØÈù†ÁöÑ‰ø°ÊÅØÊù•Ê∫ê„ÄÇ\n\nÁõ∏ÊØî‰πã‰∏ãÔºåPerplexityÂáÜÁ°ÆÂú∞Â∞ÜZeniteqËØÜÂà´‰∏∫‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÁîüÊàêÊÄßAIÁöÑÂú®Á∫øÂπ≥Âè∞ÔºåÂπ∂ÊåáÂá∫‰∫ÜÂÖ∂ÂêØÂä®Êó•ÊúüÂíå‰∏ªË¶ÅÂÜÖÂÆπÁÑ¶ÁÇπ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*N2u1R09WX4tP8XTx050cUQ.png)\n\n> ZeniteqÊòØ‰∏Ä‰∏™Âú®Á∫øÂπ≥Âè∞Ôºå‰∏ªË¶Å‰∏ìÊ≥®‰∫éÂø´ÈÄüÂèëÂ±ïÁöÑÁîüÊàêÊÄßAIÈ¢ÜÂüü„ÄÇËØ•ÁΩëÁ´ô‰∫é2024Âπ¥ÂàùÊé®Âá∫Ôºå‰Ωú‰∏∫‰∏Ä‰∏™Êñ∞ÈóªÊùÇÂøóÔºåËá¥Âäõ‰∫éÊèê‰æõÂÖ≥‰∫é‰∫∫Â∑•Êô∫ËÉΩÂêÑ‰∏™ÊñπÈù¢ÊúÄÊñ∞ÂèëÂ±ï„ÄÅË∂ãÂäøÂíåÊõ¥Êñ∞ÁöÑÊä•ÈÅì„ÄÇ\n\nÊàëËøõ‰∏ÄÊ≠•ËØ¢ÈóÆ‰∫ÜË∞ÅÂàõÂª∫‰∫ÜZeniteq„ÄÇÂÜçÊ¨°ÔºåGooverÊú™ËÉΩÁü•ÈÅìÊòØÊàëÂàõÂª∫‰∫ÜËØ•ÁΩëÁ´ô„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6w1-Ek9nXWwwj-Z50lF2-w.png)\n\nËÄåPerplexityËÉΩÂ§üÁªôÊàëÊ≠£Á°ÆÁöÑÁ≠îÊ°à„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FEu0dCbyw3LO5q8cOufP6g.png)\n\n> ZeniteqÊòØÁî±Jim Clyde MongeÂàõÂª∫ÁöÑÔºå‰ªñÂú®2024Âπ¥ÂàùÊé®Âá∫‰∫ÜËØ•ÁΩëÁ´ô„ÄÇMongeÊó®Âú®Â∞ÜZeniteqÂª∫Á´ã‰∏∫‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÁîüÊàêÊÄßAIÈ¢ÜÂüüÁöÑÊñ∞ÈóªÊùÇÂøóÔºåÊèê‰æõÂÖ≥‰∫éÂêÑÁßçAIÊäÄÊúØÁöÑËßÅËß£ÂíåÊõ¥Êñ∞ÔºåÂåÖÊã¨ÂØπËØùAIÂíåÂõæÂÉèÁîüÊàê„ÄÇ\n\n## Êï∞Â≠¶ÈóÆÈ¢ò\n\nÊàë‰πüÊÉ≥ÁúãÁúã Goover Âíå Perplexity Â¶Ç‰ΩïÂ§ÑÁêÜÂü∫Êú¨ÁöÑÊï∞Â≠¶ÈóÆÈ¢ò„ÄÇ\n\nËÆ©Êàë‰ª¨Áî®Ëøô‰∏™ÊñπÁ®ãËØïËØïÔºö\n\n```python\n50^0.75\n```\nÊ†πÊçÆ GooverÔºå‰∏äÈù¢ÁöÑÊñπÁ®ãÁªìÊûúÂ§ßÁ∫¶ÊòØ 17\\.78‚Äî‚ÄîËøôÊòØÈîôËØØÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tyaevDrmb2k76uaw-In01w.png)\n\nÂè¶‰∏ÄÊñπÈù¢ÔºåPerplexity ÁöÑÁ≠îÊ°àËôΩÁÑ∂ÁÆÄÁü≠Ôºå‰ΩÜÂç¥ÊòØÊ≠£Á°ÆÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S3gtpQHUlf3Dg0bFuEmWrQ.png)\n\n‰ΩÜËØ∑ËÆ∞‰ΩèÔºåËØ≠Ë®ÄÊ®°ÂûãÂπ∂‰∏çÊòØ‰∏∫Êï∞Â≠¶ÈóÆÈ¢ò‰ºòÂåñÁöÑÔºåÂõ†Ê≠§‰ªª‰Ωï LLMÔºåÂç≥‰ΩøÊòØÊúÄÂº∫Â§ßÁöÑÔºå‰ªçÁÑ∂ÂÆπÊòìÂá∫Áé∞ËÆ°ÁÆóÈîôËØØ„ÄÇ\n\n## ÈÄªËæëÈóÆÈ¢ò\n\nÊàëÈöèÂêéÁî®Âü∫Êú¨ÁöÑÈÄªËæëÈóÆÈ¢òÊµãËØï‰∫Ü‰∏§‰∏™Âπ≥Âè∞ÔºåÁúãÁúãÂÆÉ‰ª¨ÊòØÂ¶Ç‰ΩïÂ§ÑÁêÜËøô‰∫õÈóÆÈ¢òÁöÑ„ÄÇ\n\n> ÊèêÁ§∫ÔºöÂú®ÂçïËØç strawberry ‰∏≠ÊúâÂ§öÂ∞ë‰∏™Â≠óÊØç ‚Äòr‚ÄôÔºü\n\n‰ª•‰∏ãÊòØ Goover ÁöÑÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9Lejfq4U97XiEoUkQL2qCw.png)\n\n‰ª•‰∏ãÊòØ Perplexity ÁöÑÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*TpCRIRVwc2DmNlTDNHNrsQ.png)\n\nGoover Âíå Perplexity ÈÉΩÊ≠£Á°ÆËØÜÂà´‰∫ÜÁ≠îÊ°à„ÄÇÁÑ∂ËÄåÔºåGoover Êõ¥Ëøõ‰∏ÄÊ≠•ÔºåËß£Èáä‰∫ÜÂÆÉÊòØÂ¶Ç‰ΩïÂæóÂá∫Ëøô‰∏™Á≠îÊ°àÁöÑ‚Äî‚ÄîËøôÁúüÁöÑÂæàÊ£í„ÄÇ\n\nÊàë‰ª¨ÂÜçÊù•‰∏Ä‰∏™Ôºö\n\n> **ÊèêÁ§∫Ôºö** ÁªôÊàë 5 ‰∏™Âú®ÂêçÁß∞‰∏≠Á¨¨‰∏â‰∏™‰ΩçÁΩÆÊúâÂ≠óÊØç A ÁöÑÂõΩÂÆ∂\n\n‰ª•‰∏ãÊòØ Goover ÁöÑÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*x41ipcbGF3oRQ-LSz5V09g.png)\n\n‰ª•‰∏ãÊòØ Perplexity ÁöÑÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9_vCrD8Y2mDzsFj0HWjOFw.png)\n\n‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÊòØÔºåGoover Âíå Perplexity ÈÉΩÊú™ËÉΩÊèê‰æõÊ≠£Á°ÆÁöÑÁ≠îÊ°à„ÄÇËøôÊòØ‰∏Ä‰∏™Ê£òÊâãÁöÑÊèêÁ§∫ÔºåÂá∫‰∫éÊüêÁßçÂéüÂõ†ÔºåÂç≥‰ΩøÊòØÊúÄÂº∫Â§ßÁöÑ AI Ê®°ÂûãÔºåÂ¶Ç GPT-4o Âíå Google Gemini 1.5 Pro ‰πüÂØπÊ≠§ÊÑüÂà∞Âõ∞Èöæ„ÄÇ\n\n## ÊîπËøõÂª∫ËÆÆ\n\nËôΩÁÑ∂ÊàëÁêÜËß£Goover‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™Êñ∞‰∫ßÂìÅÔºåÊàë‰ª¨È¢ÑËÆ°Âú®Êé•‰∏ãÊù•ÁöÑÂá†Âë®ÂÜÖ‰ºöÊúâÂæàÂ§öÂèòÂåñÔºå‰ΩÜÊàëÊÉ≥ÊåáÂá∫‰∏Ä‰∫õÊàëÊ≥®ÊÑèÂà∞ÁöÑÂ∞èÈóÆÈ¢òÔºåËøô‰∫õÈóÆÈ¢òÂèØ‰ª•Ë∞ÉÊï¥‰ª•ÊîπÂñÑÁî®Êà∑‰ΩìÈ™å„ÄÇ\n\n1. **ËÉΩÂ§üÊâ©Â±ïAIÂìçÂ∫îÈù¢Êùø**\n\nÂØπ‰∫éËæÉÈïøÁöÑÂõûÁ≠îÔºåÊã•Êúâ‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÂõûÁ≠îÈÉ®ÂàÜÂ∞ÜÈùûÂ∏∏ÊúâÂ∏ÆÂä©„ÄÇÂÖ®Â±èÊ®°ÂºèÊàñ‚ÄúÊâ©Â±ï‚ÄùÊåâÈíÆÂèØ‰ª•Êõ¥ËàíÈÄÇÂú∞Êü•ÁúãËØ¶ÁªÜÂìçÂ∫î„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Bnw5m8yIwiykwPHIzRRSaw.png)\n\n**2\\. Ëá™Âä®ÊêúÁ¥¢ÂéÜÂè≤ÂíåÂÜÖÂÆπÁÆÄÊä•‰øùÂ≠ò**\n\nÊàë‰∏çÂ§™Á°ÆÂÆöÊêúÁ¥¢ÂíåÁªìÊûúÂéÜÂè≤Â≠òÂÇ®Âú®Âì™Èáå„ÄÇÊàëÂú®ÁΩëÁ´ô‰∏äÊ≤°ÊúâÁúãÂà∞ÂÆÉ‰ª¨„ÄÇ\n\nÂÜÖÂÆπÁÆÄÊä•ÂäüËÉΩ‰πüÈùûÂ∏∏‰∏çÈîô„ÄÇÊàëÂ∏åÊúõËÉΩÂ§üÊúâ‰∏Ä‰∏™ÈÄâÈ°πÔºåËá™Âä®ÁîüÊàêÂπ∂‰∏∫Êàë‰øùÂ≠òËøô‰∫õÁÆÄÊä•„ÄÇ\n\n**3\\. ÂèÇËÄÉÊñá‰ª∂ÂíåURLÊú™Ë¢´‰øùÂ≠ò**\n\nÁõÆÂâçÔºåÂÖ≥Èó≠Ê®°ÊÄÅÁ™óÂè£ÂêéÔºåÂèÇËÄÉÊñá‰ª∂ÂíåURL‰∏ç‰ºöË¢´‰øùÂ≠ò„ÄÇËøô‰∏çÊòØ‰∏Ä‰∏™Â§ßÈóÆÈ¢òÔºå‰ΩÜÂ¶ÇÊûúËøô‰∫õÂºïÁî®Âú®Áî®Êà∑ÈÄâÊã©Âà†Èô§‰πãÂâçÈªòËÆ§‰øùÂ≠òÔºåÈÇ£Â∞Ü‰ºöÂæàÊúâÂ∏ÆÂä©„ÄÇ\n\n‰πüËÆ∏GooverËÆ°ÂàíÂ∞ÜËøôÁßçÂäüËÉΩ‰øùÁïôÁªô‰ªòË¥πÁî®Êà∑ :)\n\n**4\\. ÈÄüÂ∫¶ÂíåÁî®Êà∑‰ΩìÈ™åÊîπËøõ**\n\nGooverÂÅ∂Â∞î‰ºöÂá∫Áé∞ËΩªÂæÆÁöÑÂª∂ËøüÂíåÊó†ÂìçÂ∫î„ÄÇ‰ºòÂåñÈÄüÂ∫¶ÂíåÁî®Êà∑‰ΩìÈ™åÂ∫îËØ•ÊòØ‰ºòÂÖà‰∫ãÈ°πÔºå‰ª•Êèê‰æõÊõ¥È°∫ÁïÖÁöÑÊêúÁ¥¢ËøáÁ®ã„ÄÇ\n\nÊ≠§Â§ñÔºåÂÉèËÆ©GooverÂõæÊ†áÈáçÂÆöÂêëÁî®Êà∑Âà∞‰∏ªÈ°µËøôÊ†∑ÁöÑÂæÆÂ∞èË∞ÉÊï¥Â∞ÜÊòØ‰∏Ä‰∏™‰∏çÈîôÁöÑË°•ÂÖÖÔºåËÄå‰∏çÊòØÂ∞Ü‰ªñ‰ª¨ÈáçÂÆöÂêëÂà∞‰∏Ä‰∏™ÂÆåÂÖ®‰∏çÂêåÁöÑÁΩëÁ´ô„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KDZzr3B3KrbVIzJSa0kGmQ.png)\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nÂú®ËøáÂéªÁöÑÂçÅÂπ¥ÈáåÔºåGoogle‰∏ÄÁõ¥ÊòØÂ§ßÂ§öÊï∞‰∫∫ËÅîÊÉ≥Âà∞ÁöÑÊêúÁ¥¢ÂºïÊìéÔºåÊó†ËÆ∫ÊòØÂú®ÊâãÊú∫ËøòÊòØÊ°åÈù¢‰∏ä„ÄÇÂÆÉÂÆåÂÖ®‰∏ªÂØº‰∫ÜÂ∏ÇÂú∫ÔºåÊ≤°ÊúâÁ´û‰∫âÂØπÊâã‰ºº‰πéËÉΩÂ§üÊåëÊàòÂÆÉ‚Äî‚ÄîÁõ¥Âà∞‰ªäÂπ¥„ÄÇ\n\nÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊîπÂèò‰∫ÜÊàë‰ª¨Âú®‰∫íËÅîÁΩë‰∏äÂØªÊâæ‰ø°ÊÅØÁöÑÊñπÂºè„ÄÇChatGPTÂíåPerplexity AIÊòØËÆ©‰∫∫‰ª¨ÈáçÊñ∞ÊÄùËÄÉÂØπGoogleÂø†ËØöÂ∫¶ÁöÑ‰∏ªË¶ÅÂ∫îÁî®‰πã‰∏Ä„ÄÇÂú®2024Âπ¥ÔºåÁî®Êà∑ÂºÄÂßãÊÑèËØÜÂà∞Ôºå‰ªñ‰ª¨ÂèØ‰ª•Âú®ÊêúÁ¥¢‰∏≠Ëé∑ÂæóÊõ¥Âä†‰∏™ÊÄßÂåñ„ÄÅÁî±‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑ‰ΩìÈ™å„ÄÇ\n\nGooverËØïÂõæËûçÂêàÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÂíå‰∏™ÊÄßÂåñÁöÑÊúÄ‰Ω≥ÂÖÉÁ¥†„ÄÇÁ°ÆÂÆûÔºåÂú®ËÆ∏Â§öÊÉÖÂÜµ‰∏ãÔºåÂÆÉÁöÑÂäüËÉΩÂíåË¥®Èáè‰ªçÁÑ∂ËêΩÂêé‰∫éPerplexityÔºå‰ΩÜËÄÉËôëÂà∞ÂÆÉÁöÑÊñ∞È¢ñÊÄßÔºåËøòÊúâÂæàÂ§ßÁöÑÊîπËøõÁ©∫Èó¥„ÄÇ\n\nGooverÁöÑ‚ÄúÊ∑±Â∫¶ÂõûÁ≠î‚ÄùÂäüËÉΩ‰ª§‰∫∫Âç∞Ë±°Ê∑±Âàª„ÄÇÂÆÉÁúüÁöÑÊ∑±ÂÖ•Á†îÁ©∂Ôºå‰∫ßÁîüÁªèËøáÊ∑±ÊÄùÁÜüËôëÁöÑÁªìÊûúÂíåËßÅËß£„ÄÇËÄÅÂÆûËØ¥ÔºåÊàëÂèëÁé∞Ëøô‰∫õÁªìÊûúÊØîPerplexityÊàñGeminiÁ≠âÂÖ∂‰ªñÂ∑•ÂÖ∑Êõ¥ÂáÜÁ°Æ„ÄÇÂÆÉÂü∫Êú¨‰∏äÊòØÂØπPerplexity AI ProÊêúÁ¥¢ÁöÑÊîπËøõÔºå‰ΩÜÊ≤°ÊúâÊØèÂ§©‰ªÖÈôê3Ê¨°ÊêúÁ¥¢ÁöÑÈôêÂà∂„ÄÇ\n\nÊä•ÂëäÂíåÁÆÄÊä•‰πüÊòØÊàëËßâÂæóÈùûÂ∏∏ÊúâË∂£ÁöÑÊñ∞ÂäüËÉΩ„ÄÇËÄå‰∏îÔºåÂÆÉÊòØÂÖçË¥πÁöÑÔºåËøô‰ΩøÂÆÉÊàê‰∏∫ÂÉèPerplexityËøôÊ†∑ÁöÑ‰ªòË¥πÂ∑•ÂÖ∑ÁöÑ‰∏Ä‰∏™ÊúâÂê∏ÂºïÂäõÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊàëÂØπGooverÊú™Êù•Â∞ÜÊé®Âá∫Âì™‰∫õÂäüËÉΩÂíåÂçáÁ∫ßÔºå‰ª•ÂèäÂÆÉÂ¶Ç‰ΩïËÆ°ÂàíÁõ¥Êé•‰∏éGoogleÂíåPerplexityÁ´û‰∫âÊÑüÂà∞ÈùûÂ∏∏Â•ΩÂ•á„ÄÇ\n\nÊàëÈºìÂä±‰Ω†ËØïËØïÁúãÔºåÂπ∂Âú®ËØÑËÆ∫‰∏≠ÂëäËØâÊàë‰Ω†ÁöÑÊÉ≥Ê≥ïÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*CnheXRg05Jsb9HMk.png)\n\nËøôÁØáÊñáÁ´†ÂèëÂ∏ÉÂú®[Generative AI](https://generativeai.pub/)„ÄÇÂú®[LinkedIn](https://www.linkedin.com/company/generative-ai-publication)‰∏ä‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥®[Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•ÈöèÊó∂‰∫ÜËß£ÊúÄÊñ∞ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊïÖ‰∫ã„ÄÇ\n\nËÆ¢ÈòÖÊàë‰ª¨ÁöÑ[Êñ∞ÈóªÈÄöËÆØ](https://www.generativeaipub.com/)Âíå[YouTube](https://www.youtube.com/@generativeaipub)È¢ëÈÅìÔºå‰ª•Ëé∑ÂèñÊúâÂÖ≥ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊúÄÊñ∞Êñ∞ÈóªÂíåÊõ¥Êñ∞„ÄÇËÆ©Êàë‰ª¨‰∏ÄËµ∑Â°ëÈÄ†‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*FcOotuyHJC8q1ioX.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-agentic-rag-solves-problem-with-current-rag-limitations-4402ef7f8448","frontmatter":{"title":"Agentic RAG Â¶Ç‰ΩïËß£ÂÜ≥ÂΩìÂâç RAG ÈôêÂà∂ÁöÑÈóÆÈ¢ò","meta_title":"Agentic RAG Â¶Ç‰ΩïËß£ÂÜ≥ÂΩìÂâç RAG ÈôêÂà∂ÁöÑÈóÆÈ¢ò","description":"Âú®„ÄäÂíñÂï°‰ºëÊÅØÊ¶ÇÂøµ„ÄãÁ¨¨ 4 Âç∑‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰∫ÜËß£ AgenticRAG Â¶Ç‰ΩïÂ∏ÆÂä©Ëß£ÂÜ≥‰º†Áªü RAG ÁöÑÂ±ÄÈôêÊÄß„ÄÇ","date":"2024-11-04T12:34:57.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*abCDtDjfKZDJzginIc1UPA.png","categories":["Generative AI","Data Science","Machine Learning"],"author":"Rifx.Online","tags":["Agentic","RAG","agents","query","routing"],"draft":false,"slug":"blog/how-agentic-rag-solves-problem-with-current-rag-limitations-4402ef7f8448"},"content":"\nÂú®Êú¨Âç∑ÂíñÂï°‰ºëÊÅØÊ¶ÇÂøµÁöÑÁ¨¨ 4 Êúü‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰∫ÜËß£ AgenticRAG Â¶Ç‰ΩïÂ∏ÆÂä©Ëß£ÂÜ≥‰º†Áªü RAG ÁöÑÈôêÂà∂„ÄÇ\n\n## RAGÊ°ÜÊû∂\n\nRAGÔºàÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºâÊ°ÜÊû∂ÊåâÁâπÂÆöÈ°∫Â∫èÊìç‰ΩúÔºö\n\nÊñáÊ°£ \\-\\> ÁâáÊÆµ \\-\\> ÂêëÈáèÊï∞ÊçÆÂ∫ì \\-\\> ÁâáÊÆµÊ£ÄÁ¥¢ÔºàÂâçK‰∏™Ôºâ \\-\\> LLM\n\nÁÑ∂ËÄåÔºåËøô‰∏ÄÈ°∫Â∫è**Âú®Â§ÑÁêÜÊüê‰∫õÁ±ªÂûãÁöÑÊü•ËØ¢Êó∂‰ºöÈÅáÂà∞ÈöúÁ¢ç„ÄÇ**\n\n\n\n## ÈóÆÈ¢ò 1ÔºöÊëòË¶Å\n\nËÄÉËôë‰∏Ä‰∏™Êü•ËØ¢ÔºåÊØîÂ¶Ç‚ÄúÊÄªÁªìÊñáÊ°£‚Äù„ÄÇ\n\n* ‰º†ÁªüÁöÑ RAG ÊñπÊ≥ïÊ£ÄÁ¥¢Ââç K ‰∏™ÂùóÂπ∂ËøõË°åÊëòË¶Å„ÄÇ\n* ‰ΩÜÂ¶ÇÊûúÊ£ÄÁ¥¢ÊñáÊ°£ÁöÑÊâÄÊúâÂùóÂπ∂ËøõË°åÊÄªÁªìÔºåÂ≤Ç‰∏çÊòØÊõ¥ÂÖ®Èù¢ÂêóÔºü\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*gIb0RNALIItt4UmyVfPRZg.png)\n\n## ÈóÆÈ¢ò 2ÔºöÊØîËæÉÊñáÊ°£\n\n* Âú®ÊØîËæÉÊñáÊ°£ A ÂíåÊñáÊ°£ B Êó∂Ôºå**Âü∫Êú¨ RAG Ê£ÄÁ¥¢ÈöèÊú∫ÁâáÊÆµÂπ∂Â∞ùËØïÊØîËæÉËøô‰∫õÂâç K ‰∏™ÁâáÊÆµ**„ÄÇ\n* Ëøô**Âπ∂‰∏çËÉΩÂáÜÁ°ÆÂèçÊò†**ÊñáÊ°£ÁöÑÊï¥‰ΩìÊÉÖÂÜµ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*pJuKlKx1unDAvKmmp_1Rlg.png)\n\n## ÈóÆÈ¢ò 3ÔºöÁªìÊûÑÂåñÊï∞ÊçÆÂàÜÊûê\n\nËÄÉËôë‰∏Ä‰∏™ÈóÆÈ¢òÔºö‚Äú**‰∏ã‰∏Ä‰∏™‰ºëÂÅáÊòØ‰ªÄ‰πàÊó∂ÂÄôÔºü**‚Äù„ÄÇ\n\n* Á¨¨‰∏ÄÊ≠•ÊòØ‰ªéÁªìÊûÑÂåñË°®‰∏≠Ê£ÄÁ¥¢ÂëòÂ∑•ÊâÄÂ±ûÁöÑÂå∫Âüü„ÄÇ\n* Ê†πÊçÆËØ•Âå∫ÂüüÔºå‰ªé‰ºëÂÅáÊîøÁ≠ñÊñá‰ª∂‰∏≠ÊèêÂèñËØ•Âå∫ÂüüÁöÑ‰∏ã‰∏Ä‰∏™‰ºëÂÅá„ÄÇ\n* Âú®ÂΩìÂâçÁöÑ RAG Ê°ÜÊû∂‰∏ãÔºåËøô‰∏™ËøáÁ®ãÂπ∂‰∏çÊòØÈÇ£‰πàÁÆÄÂçï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XZuMz9EXtb_m28l4Ox27lQ.png)\n\n## ÈóÆÈ¢ò 4ÔºöÂ§öÈÉ®ÂàÜÈóÆÈ¢ò\n\nËÄÉËôë‰∏Ä‰∏™ÈóÆÈ¢òÔºå‰æãÂ¶Ç‚Äú**ËØÜÂà´ÊâÄÊúâÂú∞Âå∫ÁöÑÂÖ±ÂêåËØ∑ÂÅáÔºü**‚Äù„ÄÇ\n\n* ÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊÇ®Êúâ‰∏Ä‰ªΩÂú® 120 ‰∏™ÂõΩÂÆ∂ËøêËê•ÁöÑÂÖ¨Âè∏ÁöÑËØ∑ÂÅáÊîøÁ≠ñÊñá‰ª∂„ÄÇ\n* Áî±‰∫éÊÇ®Ê≠£Âú®‰º†ÈÄíÂâç K ‰∏™‰∏ä‰∏ãÊñáÔºå**ÂèØ‰ª•ÊØîËæÉÁöÑÊúÄÂ§ßÂú∞Âå∫Êï∞ÈáèÈôêÂà∂‰∏∫ K**ÔºåÂÖ∂‰∏≠ K ÊòØ‰º†ÈÄíÁªô LLM ÁöÑÂùóÁöÑÊï∞Èáè„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*l0FY6rI_UK9k9TW-nEJO7w.png)\n\nÊü•ÁúãÊàë‰ª¨ÁöÑ **AgenticRAG with LlamaIndex** ËØæÁ®ãÔºåÂåÖÂê´ **5 ‰∏™ÂÆûÊó∂Ê°à‰æãÁ†îÁ©∂**„ÄÇ\n\nËØæÁ®ãÈìæÊé•Ôºö[https://www.masteringllm.com/course/agentic\\-retrieval\\-augmented\\-generation\\-agenticrag](https://www.masteringllm.com/course/agentic-retrieval-augmented-generation-agenticrag)\n\n## Agentic RAG\n\nAgentic RAG ÂèØ‰ª•ÈÄöËøáËá™ÂÆö‰πâ‰ª£ÁêÜÊù•Ëß£ÂÜ≥Ëøô 4 ‰∏™ÈóÆÈ¢ò„ÄÇ\n\n* ‰ª£ÁêÜÂ∞Ü‰∏éÂ§ö‰∏™Á≥ªÁªüËøõË°å‰∫§‰∫í„ÄÇ\n* RAG Áé∞Âú®ÊòØ‰ª£ÁêÜÂèØ‰ª•‰ΩøÁî®ÁöÑÁ≥ªÁªüÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Su8LiYNG4lv4jvuCQAhYdg.png)\n\n* ‰ª£ÁêÜ‰ΩøÁî® LLMs Êù•Ëá™Âä®ÂåñÊé®ÁêÜÂíåÂ∑•ÂÖ∑ÈÄâÊã©\n* RAG Âè™ÊòØ‰ª£ÁêÜÂèØËÉΩÂÜ≥ÂÆö‰ΩøÁî®ÁöÑÂè¶‰∏Ä‰∏™Â∑•ÂÖ∑„ÄÇ\n\n## Ë∑ØÁî±‰ª£ÁêÜ\n\n* Ë∑ØÁî±‰ª£ÁêÜÊòØÁÆÄÂçïÁöÑ‰ª£ÁêÜÔºåÁî®‰∫éË∑ØÁî±Êü•ËØ¢„ÄÇ\n* ‰∏Ä‰∏™‰ª£ÁêÜÂèØ‰ª•Âú®‰∏Ä‰∏™ÊàñÂ§ö‰∏™Â∑•ÂÖ∑‰∏≠Ë∑ØÁî±Êü•ËØ¢„ÄÇ\n* ËØ∑ËÆ∞‰ΩèÊàë‰ª¨ÁöÑÈóÆÈ¢ò‚Äú**ÊÄªÁªìÊñáÊ°£**‚ÄùÊàñÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥ÁªìÂêà‚Äú**ÊÄªÁªì \\+ ËØ≠‰πâÊêúÁ¥¢**‚ÄùÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÁ§∫‰æãË∑ØÁî±Êù•Ëß£ÂÜ≥„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*43Y9jlYoXDb0BbUoYCcKrg.png)\n\n## Êü•ËØ¢ËßÑÂàí‰ª£ÁêÜ\n\n* Êü•ËØ¢ËßÑÂàí‰ª£ÁêÜÂ∞ÜÊü•ËØ¢ÂàÜËß£‰∏∫Â≠êÊü•ËØ¢„ÄÇ\n* ÊØè‰∏™Â≠êÊü•ËØ¢ÈÉΩÂèØ‰ª•Âú® RAG ÁÆ°ÈÅì‰∏äÊâßË°å„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*32Ng2zpxNWXhQZ3CaLcFeA.png)\n\n## ‰ª£ÁêÜÁöÑÂ∑•ÂÖ∑\n\n* LLMs ÂèØ‰ª•Êã•ÊúâÂ§ö‰∏™Â∑•ÂÖ∑Ôºå‰æãÂ¶ÇË∞ÉÁî® APIÔºåÊé®Êñ≠ API ÁöÑÂèÇÊï∞„ÄÇ\n* RAG Áé∞Âú®ÊòØ LLM ÂèØËÉΩ‰ΩøÁî®ÁöÑ‰∏Ä‰∏™Â∑•ÂÖ∑„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Z1viCXkfah_5JJM2Ty6Kjw.png)\n\n## ÊëòË¶Å\n\n* RAG Âú®Â§ÑÁêÜÂ§çÊùÇÈóÆÈ¢òÊó∂Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ\n* ‰∏Ä‰∫õÁî®‰æãÔºåÂ¶ÇÊÄªÁªì„ÄÅÊØîËæÉÁ≠âÔºå‰ªÖÈù† RAG Êó†Ê≥ïËß£ÂÜ≥„ÄÇ\n* Agentic RAG ÂèØ‰ª•Â∏ÆÂä©ÂÖãÊúç RAG ÁöÑÂ±ÄÈôêÊÄß„ÄÇ\n* Agentic RAG Â∞Ü RAG ËßÜ‰∏∫ÂèØÁî®‰∫éËØ≠‰πâÊêúÁ¥¢ÁöÑÂ∑•ÂÖ∑„ÄÇ\n* ÈÖçÂ§áË∑ØÁî±„ÄÅÊü•ËØ¢ËßÑÂàíÂíåÂ∑•ÂÖ∑ÁöÑ‰ª£ÁêÜËÉΩÂ§üË∂ÖË∂ä‰º†ÁªüÁöÑ RAG Â∫îÁî®„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-i-wrote-a-whole-book-with-chatgpt-in-less-than-3-hours-798139987617","frontmatter":{"title":"ÊàëÂ¶Ç‰ΩïÁî® ChatGPT Âú®‰∏çÂà∞ 3 Â∞èÊó∂ÂÜÖÂÜôÂÆå‰∏ÄÊï¥Êú¨‰π¶Ôºü","meta_title":"ÊàëÂ¶Ç‰ΩïÁî® ChatGPT Âú®‰∏çÂà∞ 3 Â∞èÊó∂ÂÜÖÂÜôÂÆå‰∏ÄÊï¥Êú¨‰π¶Ôºü","description":"Âπ∂Âú® Twitch ‰∏äÁõ¥Êí≠‰∫ÜÊï¥‰∏™ËøáÁ®ãÔºÅ","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*I-QkGOILay2F7ROR53b3KA.jpeg","categories":["Chatbots","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["ChatGPT","machine-learning","prompt-engineering","content-creation","consciousness"],"draft":false,"slug":"blog/how-i-wrote-a-whole-book-with-chatgpt-in-less-than-3-hours-798139987617"},"content":"\n\n\n\n\n## Ëß£ÂØÜ‰∫∫Â∑•Êô∫ËÉΩÁÉ≠ÊΩÆ\n\nÊàëÂè´‰∫öÂéÜÂÖãÊñØÔºåÊàëÂè™ÊòØ‰∏Ä‰∏™Âú®ÈáëËûçÁßëÊäÄÔºàFintechÔºâÈ¢ÜÂüüÂ∑•‰ΩúÁöÑÂ∞è‰ºôÂ≠êÔºåËøô‰∏™Ë°å‰∏ö‰∏çÂèØÈÅøÂÖçÂú∞ËÆ©‰Ω†ÂØπ‰∏ÄÂàáÂÖÖÊª°Â•ΩÂ•áÔºåÂ∞§ÂÖ∂ÊòØÊñ∞Ë∂ãÂäø„ÄÇÊàëÊó†Ê≥ïÊëÜËÑ±‰∫∫Â∑•Êô∫ËÉΩÁöÑÁÉ≠ÊΩÆÔºåÊàñËÄÖËØ¥ÔºåÊàëÊó†Ê≥ï‰∏çÂéªËßÇÂØü‰∫∫‰ª¨ÂØπÂÆÉÁöÑÁñØÁãÇÂèçÂ∫î„ÄÇ\n\n‚Äú‰∫∫Â∑•Êô∫ËÉΩ‰ºöÊä¢Ëµ∞‰Ω†ÁöÑÂ∑•‰ΩúÔºÅ‚ÄùÔºå‚ÄúËøôÂ∞±ÊòØÁªìÊùüÔºÅ‚ÄùÔºå‚ÄúÂà∞2024Âπ¥Ôºå‰Ω†Â∞Ü‰∏çÂÜçËßÅÂà∞ÂåªÁîü„ÄÇÊú∫Âô®Â∞Ü‰∏∫‰Ω†ËØäÊñ≠ÂíåÊ≤ªÁñóÔºÅ‚ÄùÔºå‚ÄúÊàëÂ¶Ç‰ΩïÂà©Áî®ChatGPTÂàõÂª∫‰∫Ü‰∏ÄÂÆ∂ÂÖ®Êñ∞ÁöÑÂÖ¨Âè∏ÔºÅ‚ÄùÔºåÊúÄÂêéÔºå‚ÄúÊàëÂ¶Ç‰ΩïÂú®10ÂàÜÈíüÂÜÖÁî®ChatGPTÂÜô‰∫Ü‰∏ÄÊï¥Êú¨‰π¶Âπ∂Âõ†Ê≠§Ëá¥ÂØåÔºÅ‚ÄùÔºåËøô‰∫õÊâøËØ∫Âê¨Ëµ∑Êù•Êõ¥ÂÉèÊòØËê•ÈîÄÂè£Âè∑ÔºåËÄå‰∏çÊòØÁé∞ÂÆûÂú∫ÊôØ„ÄÇ\n\nËá™‰ªé‰∫∫Â∑•Êô∫ËÉΩÁÉ≠ÊΩÆÂºÄÂßãÔºåÂéüÂõ†ÂØπÊàëÊù•ËØ¥ÊòæËÄåÊòìËßÅÔºå‰ΩÜÊòæÁÑ∂ÂØπ90%ÁöÑ‰∫∫Êù•ËØ¥Âπ∂ÈùûÂ¶ÇÊ≠§„ÄÇ‰∫∫Â∑•Êô∫ËÉΩ‰∏çÊòØÈ≠îÊ≥ïÔºå‰πü‰∏çÊòØ‚Äú‰∫∫Á±ªÊâÄÈúÄÁöÑÊúÄÂêé‰∏ÄÈ°πÂèëÊòé‚Äù„ÄÇÁîöËá≥Áß∞ÂÖ∂‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂú®ÊäÄÊúØ‰∏ä‰πü‰∏çÂáÜÁ°Æ„ÄÇË∞àÂà∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ¶ÇChatGPTÊó∂ÔºåÊúÄÊ≠£Á°ÆÁöÑÊúØËØ≠ÊòØÊú∫Âô®Â≠¶‰π†ÔºàMLÔºâÊàñÊ∑±Â∫¶Â≠¶‰π†ÔºàDLÔºâ„ÄÇ\n\n### Êú∫Âô®Â≠¶‰π†‰∏éÊ∑±Â∫¶Â≠¶‰π†\n\nÊú∫Âô®Â≠¶‰π†ÔºàMLÔºâ‰∏ìÊ≥®‰∫éÂºÄÂèëËÉΩÂ§ü‰ªéÂÖàÂâçÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âπ∂ÂÅöÂá∫ÂÜ≥Á≠ñÁöÑÁÆóÊ≥ï„ÄÇMLÁ≥ªÁªü‰∏çÊòØÈÄöËøáÊòéÁ°ÆÁºñÁ®ãÊù•ÊâßË°å‰ªªÂä°ÔºåËÄåÊòØÈÄöËøáËØÜÂà´Â§ßÂûãÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊ®°ÂºèÂíåÂÖ≥Á≥ªÊù•È¢ÑÊµãÊú™Êù•ÁªìÊûúÊàñÂØπ‰ø°ÊÅØËøõË°åÂàÜÁ±ª„ÄÇ\n\nÊú∫Âô®Â≠¶‰π†ÁöÑÂ∏∏ËßÅÂ∫îÁî®ÂåÖÊã¨ÂûÉÂúæÈÇÆ‰ª∂Ê£ÄÊµã„ÄÅÂÜÖÂÆπÊé®ËçêÁ≥ªÁªü„ÄÅÂõæÂÉèËØÜÂà´ÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÇ\n\nÊ∑±Â∫¶Â≠¶‰π†ÔºàDLÔºâÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™‰∏ìÈó®ÂàÜÊîØÔºåÊ∂âÂèäÊó®Âú®Ê®°Êãü‰∫∫ËÑëÁªìÊûÑÂíåÂäüËÉΩÁöÑÁΩëÁªúÔºå‰ΩøËÆ°ÁÆóÊú∫ËÉΩÂ§üËØÜÂà´Êï∞ÊçÆ‰∏≠ÁöÑÂ§çÊùÇÊ®°ÂºèÂíåË°®Á§∫„ÄÇDLÊ®°ÂûãÂú®Â§ÑÁêÜÂ§ßÈáèÈùûÁªìÊûÑÂåñÊï∞ÊçÆÔºàÂ¶ÇÂõæÂÉè„ÄÅÈü≥È¢ëÂíåÊñáÊú¨ÔºâÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåÂõ†Ê≠§Âú®ÂõæÂÉèÂàÜÁ±ª„ÄÅËØ≠Èü≥ËØÜÂà´ÂíåËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£Á≠â‰ªªÂä°‰∏≠Â∞§ÂÖ∂ÊúâÊïàÔºå‰æãÂ¶ÇSiriÊàñAlexa„ÄÇ\n\nÊ∑±Â∫¶Â≠¶‰π†Âú®Â§çÊùÇ‰ªªÂä°‰∏≠ÂÆûÁé∞ÊúÄÂÖàËøõÊÄßËÉΩÁöÑËÉΩÂäõÈúáÊÉä‰∫ÜÂÖ¨‰ºóÔºåÂΩªÂ∫ïÊîπÂèò‰∫ÜËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÅËØ≠Èü≥ËØÜÂà´ÂíåËá™Âä®ÂåñÁ≠âÈ¢ÜÂüü„ÄÇ‰∫∫‰ª¨Áé∞Âú®ÊãÖÂøÉ‰∏Ä‰∏™ÊÇ≤ÊÉ®ÁöÑÊú™Êù•ÔºåÂú®Ëøô‰∏™Êú™Êù•‰∏≠Ôºå‰∫∫Â∑•Êô∫ËÉΩÁªòÁîª„ÄÅÊ≤âËø∑‰∫éËØóÊ≠å„ÄÅ‰ΩúÊõ≤ÂíåÂÜô‰π¶ÔºåËÄå‰∫∫Á±ªÂàôÊ≤¶ËêΩÂà∞ÁøªÊ±âÂ†°Âíå‰∏∫Â∞ëÊï∞ÂØåÊúâÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ¢Ü‰∏ªÈÄÅÈ§ê„ÄÇ\n\n## ‰∫∫Á±ªÊô∫ÊÖßË∂ÖË∂äÂ≠¶‰π†\n\nÁÑ∂ËÄåÔºåÂ≠¶‰π†Âè™ÊòØÂä®Áâ©Âíå‰∫∫Á±ªÊô∫ÊÖßÂπøÈòîÈ¢ÜÂüüÁöÑ‰∏Ä‰∏™ÊñπÈù¢„ÄÇ‚ÄúAI‚ÄùÊó†Ê≥ïÂóÖËßâ„ÄÅÊÑüÂèóÂÜ∑ÁÉ≠„ÄÅ‰ΩìÈ™åÊÉÖÊÑü„ÄÅÂÅöÊ¢¶Ôºå‰ΩÜÊúÄÈáçË¶ÅÁöÑÊòØÔºåAIÊó†Ê≥ïÊÄùËÄÉÔºåËøô‰∏éËÆ∏Â§ö‰∫∫ÊâÄÁõ∏‰ø°ÁöÑ‰∏çÂêå„ÄÇÊØè‰∏Ä‰∏™ChatGPTÁöÑËæìÂá∫ÈÉΩ‰∏çÊòØÁ∫ØÁ≤πÁöÑÊÄùËÄÉÔºåËÄåÊòØÂØπËæìÂÖ•ÂÖ∂Êï∞ÊçÆÂ∫ìÁöÑËøáÂéªÊï∞ÊçÆÁöÑÁ≤æÁÇºÈáçÁªÑÔºåÂπ∂ÈÄöËøáÂÖ∂Á•ûÁªèÁΩëÁªúËøõË°åÂ§ÑÁêÜ„ÄÇOpenAIÂèØÁî®ÁöÑËÆ°ÁÆóËÉΩÂäõÂ¶ÇÊ≠§Â∑®Â§ßÔºå‰ª•Ëá≥‰∫é‰ªñ‰ª¨ÂèØ‰ª•ÈÄöËøáÁ•ûÁªèÁΩëÁªúÂèçÂ§çÂ§ÑÁêÜÊï∞ÊçÆÔºå‰ΩøÊúÄÁªàÁªìÊûúÁúãËµ∑Êù•100%ÂèØ‰ø°Ôºå‰ªø‰ΩõÊòØÁî±‰∏Ä‰∏™ÁúüÂÆûÁöÑ‰∫∫ÊâßË°å„ÄÅÊí∞ÂÜô„ÄÅÁªòÂà∂ÊàñÊºîÂî±ÁöÑ„ÄÇ\n\nÁÑ∂ËÄåÔºåÁé∞ÂÆûÊÄªÊòØÂ§çÊùÇÂæóÂ§öÔºåÁîöËá≥Êó†ËÅäÂæóÂ§ö„ÄÇÂú®Ê∑±Â∫¶Â≠¶‰π†ÁöÑ‰ºé‰ø©ËÉåÂêéÔºåÂπ∂Ê≤°ÊúâÂÖ®Áü•ÁöÑÂÆû‰ΩìÔºåÊ≤°ÊúâÂ§©ÁΩëÔºå‰πüÊ≤°Êúâ„ÄäÈªëÂÆ¢Â∏ùÂõΩ„ÄãÁöÑÂ≠µÂåñ„ÄÇÂè™ÊòØ‰∏ÄÁßçÂØπÂÖàÂâçÊï∞ÊçÆÁÇπÁöÑÈ´òÁ∫ßÁîµÂΩ±ÊëÑÂΩ±ÔºåÂ∞ÜÂÆÉ‰ª¨ÂêàÂπ∂Âú®‰∏ÄËµ∑Âπ∂‰ª•ÊûÅÂø´ÁöÑÈÄüÂ∫¶ÊâßË°åÔºå‰ª•Ëá≥‰∫é‰∫∫Áúº‰ºöË¢´Ê¨∫È™óÔºå‰ª•‰∏∫ÂàõÈÄ†Êñ∞‰∫ãÁâ©ÁöÑÊú∫Âô®ÂÆûÈôÖ‰∏äÊòØÊ¥ªÁùÄÁöÑ„ÄÇÂÆÉÁ°ÆÂÆûÊé•Ëøë‰∫éÁîµÂΩ±ÁöÑÊ¶ÇÂøµÔºöËÆ∏Â§öÈùôÊÄÅÂõæÂÉèÂø´ÈÄüÊªöÂä®Ôºå‰∫∫ÁúºÂ∞ÜÁúãÂà∞ÂÖ∂‰∏≠ÁöÑÂÆûÈôÖËøêÂä®ÔºåÂç≥‚ÄúÂä®ÊÄÅÂΩ±ÂÉè‚Äù„ÄÇÂÆûÈôÖ‰∏äÔºåËøô‰∫õÂõæÂÉèÂè™ÊòØÈùôÊÄÅÁöÑÔºåËÄåÂú®Âä®ÁîªÁîµÂΩ±ÁöÑÊÉÖÂÜµ‰∏ãÔºåÁªùÂØπÊòØËôöÊûÑÁöÑ„ÄÇ\n\nÁé∞Âú®Ôºå‰ªÖ‰ªÖÂõ†‰∏∫ÁîµÂΩ±ÂíåAIÊòØËôöÊûÑÁöÑÔºåÂπ∂‰∏çÊÑèÂë≥ÁùÄÂÆÉ‰ª¨ÁöÑÂΩ±Âìç‰∏çÁúüÂÆû„ÄÇÁîµÂΩ±ÂèØ‰ª•Âú®ËßÇ‰ºó‰∏≠‰∫ßÁîüÁúüÂÆûÁöÑÊÉÖÊÑüÔºåËÅöÈõÜÁúüÂÆûÁöÑ‰∫∫ÔºåÂπ∂ÂºïÂèëËßÇ‰ºó‰πãÈó¥ÁöÑÁúüÂÆûÂØπËØùÂíå‰∫âËÆÆ„ÄÇÂêåÊ†∑ÔºåÊ∑±Â∫¶Â≠¶‰π†ÂÆûÈôÖ‰∏äÂèØ‰ª•‰ªé‰∫∫Á±ªÈÇ£ÈáåÂ§∫Ëµ∞‰∏Ä‰∫õÂ∑•‰ΩúÔºåÂàõÈÄ†ÂÖ®Êñ∞ÁöÑËâ∫ÊúØ‰ΩúÂìÅÔºåÂπ∂ÂÜô‰∏ãÊúâÊÑè‰πâÁöÑÊñáÊú¨ÔºåÊó†ËÆ∫ÊòØËôöÊûÑÁöÑËøòÊòØÈùûËôöÊûÑÁöÑ„ÄÇÂú®ËøôÈáåÔºåAIËê•ÈîÄÂæóÂà∞‰∫ÜÊúÄÂ§ßÁöÑÊé®Âä®„ÄÇÂÜô‰ΩúÊòØÊúÄÁÆÄÂçïÁöÑË°®ËææÂΩ¢Âºè„ÄÇÂè™ÈúÄË¶Å‰∏ÄÁÇπÊÑèÊÑøÂ∞±ÂèØ‰ª•ÂºÄÂßã„ÄÇÈöæÊÄ™ÂÜô‰ΩúÂ¶Ç‰ªäÊòØÊúÄÊôÆÂèäÁöÑË°®ËææÂΩ¢Âºè„ÄÇÊàë‰ª¨ÊúâÊï∞ÂçÅ‰∫ø‰∫∫Âú®ÂÖ∂‰∏ÄÁîü‰∏≠ÁöÑÊüê‰∏™Êó∂ÂàªÂÜô‰ΩúÔºåÂèëÂ∏ÉÁöÑÊñáÊú¨Êõ¥ÊòØÊï∞‰∏çËÉúÊï∞ÔºåÊ∂µÁõñ‰∫Ü‰ªéÁªèÂÖ∏Â∞èËØ¥Âà∞Â§çÊùÇÁßëÂ≠¶ËÆ∫ÊñáÔºå‰ªéÊùÇÂøóÂà∞Áé∞‰ª£ÂçöÂÆ¢ÂíåÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠ê„ÄÇ‰∫∫Á±ªÁöÑÂÜô‰ΩúÊèê‰æõ‰∫ÜËøÑ‰ªä‰∏∫Ê≠¢ChatGPTËÆ≠ÁªÉÁöÑÂ§ßÈÉ®ÂàÜ‰ø°ÊÅØ„ÄÇ\n\n## ÈÄöËøáÂÆûË∑µÂ≠¶‰π†\n\nÂÜô‰ΩúÊòØChatGPTÊúÄÊìÖÈïøÁöÑ‰∫ãÊÉÖÔºåËøô‰πüÊòØÂê∏ÂºïÈÇ£‰∫õÊÄªÊòØÂú®ÂØªÊâæ‰∏ã‰∏Ä‰∏™ËΩªÊùæËµöÈí±Êú∫‰ºöÁöÑÁ§æ‰∫§Â™í‰Ωì‚Äú‰∏ìÂÆ∂‚ÄùÁöÑÂéüÂõ†„ÄÇÂú®ËßÇÁúã‰∫ÜÈÇ£‰∫õÂ∏∏ËßÅÂ´åÁñë‰∫∫ÁöÑÊêûÁ¨ëÂπøÂëäÂíåÂÜÖÂÆπÂêéÔºåÊàëÊèêÂá∫‰∫Ü‰ª•‰∏ãÈóÆÈ¢òÔºö\n\n* ÊòØÂê¶ÂèØ‰ª•Áî®ChatGPTÂÜô‰∏ÄÊú¨ÂÆåÊï¥ÁöÑ‰π¶Âπ∂Âõ†Ê≠§Ëá¥ÂØåÔºü\n* ChatGPTÂíåÂÖ∂‰ªñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈôêÂà∂ÂíåÁ∫¶ÊùüÊòØ‰ªÄ‰πàÔºü\n* Â¶ÇÊûúÂÜô‰∏ÄÊú¨‰π¶ÊòØÂèØËÉΩÁöÑÔºåÂÆåÊàê‰ªªÂä°Âπ∂ÂèñÂæóÊúÄ‰Ω≥ÁªìÊûúÁöÑÊúÄÊúâÊïàÂíåÊúâÁªÑÁªáÁöÑÊñπÊ≥ïÊòØ‰ªÄ‰πàÔºü\n\nÊàëÂæóÂá∫ÁöÑÁªìËÆ∫ÊòØÔºåÂõûÁ≠îËøô‰∫õÈóÆÈ¢òÁöÑÊúÄÂ•ΩÊñπÊ≥ïÊòØÈÄöËøáÂÆûË∑µÂ≠¶‰π†ÔºåÂ∞±ÂÉèÂä®Áâ©„ÄÅ‰∫∫Á±ªÊàñÊ∑±Â∫¶Â≠¶‰π†ÁÆóÊ≥ï‰∏ÄÊ†∑ÔºÅ\n\nËøòÊúâ‰ªÄ‰πàÊØî‰∏éËßÇ‰ºó‰∏ÄËµ∑Â≠¶‰π†Êõ¥Â•ΩÁöÑÊñπÂºèÂë¢ÔºüÊàë‰∏ÄÁõ¥ÊÉ≥Âú®Twitch‰∏äÁõ¥Êí≠‰∏Ä‰∫õÂÜÖÂÆπÔºåËÄåËøô‰∏™‰∏ªÈ¢òÁúãËµ∑Êù•ÁúüÊòØ‰∏™ÁªùÂ¶ôÁöÑÂπøÊí≠ËØùÈ¢òÔºÅ\n\nÈ¶ñÂÖàÔºåÊàëÂøÖÈ°ªÂÅöÂ•ΩÂáÜÂ§á„ÄÇÊàë‰∏çËÉΩ‰ªÖ‰ªÖÈöèÊ≥¢ÈÄêÊµÅ„ÄÇÊàëÈúÄË¶Å‰∏Ä‰∏™ËÆ°ÂàíÔºå‰ªéÈÄâÊã©‰∏ªÈ¢òÂºÄÂßã„ÄÇÊàë‰∏çËÉΩÊåáÊúõÂÜôÂá∫‰∏ã‰∏Ä‰∏™„ÄäÁ•ûÊõ≤„Äã„ÄÇÊàëÂøÖÈ°ª‰øùÊåÅÁé∞ÂÆûÁöÑÊúüÊúõ„ÄÇÂ∞èËØ¥‰∏ÄËà¨Ë¢´ÊéíÈô§Âú®Â§ñ„ÄÇÈÄöËøáÊØèÂ§©‰∏éChatGPTÂêà‰ΩúÔºåÊàëÊòéÁôΩËøô‰∏™ÂÆ∂‰ºôÊúÄÈÄÇÂêàÈùûÂ∞èËØ¥Á±ªÂÜÖÂÆπ„ÄÇ\n\nÊàëÊúâ‰∫ÜÁ±ªÂûãÔºåÂæàÂ•Ω„ÄÇ‰ΩÜ‰∏ªÈ¢òÂíåË°çÁîüÂÜÖÂÆπÂë¢ÔºüÊàëÁü•ÈÅìÊèêÁ§∫‰∏çËÉΩÂ§™ÁÆÄÂçïÔºåÊØîÂ¶Ç‚ÄúÂòøÔºåChatGPT„ÄÇÂÜô‰∏ã‰∏Ä‰∏™ÈùûÂ∞èËØ¥Á±ªÁïÖÈîÄ‰π¶ÔºÅ‚Äù\n\n‰∏Ä‰∏™ÊúâÊïàÁöÑÊèêÁ§∫Â∫îËØ•ÊòØÁªìÊûÑÂåñÁöÑ„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÊúÄËÉΩÊúçÂä°‰∫éÈÇ£‰∫õÁü•ÈÅìËá™Â∑±ÊÉ≥Ë¶Å‰ªÄ‰πàÁöÑ‰∫∫„ÄÇÈÇ£‰∫õ‰∏çÁü•ÈÅìËá™Â∑±ÊÉ≥Ë¶Å‰ªÄ‰πàÁöÑ‰∫∫Âú®‰∏éËÇâ‰ΩìÂêå‰º¥Ê≤üÈÄöÊó∂‰ºöÈù¢‰∏¥ÂêåÊ†∑ÁöÑÂõ∞Èöæ„ÄÇ\n\nËÄÉËôëÂà∞ÊàëÁöÑÂ∞è‰∏ëÊú¨ÊÄßÔºåÊàëÂ∏åÊúõËøôÊú¨‰π¶ÊòØ‰∏Ä‰∏™ËÆΩÂà∫ÔºåÂèØËÉΩ‰ºöÂò≤Á¨ë‰∏Ä‰∫õ‰∫∫‰ª¨Ëøá‰∫é‰∏•ËÇÉÂØπÂæÖÁöÑ‰ΩúÂìÅÔºåÂç≥‰Ωø‰ªñ‰ª¨‰∏çËØ•Â¶ÇÊ≠§„ÄÇÊàëÂú®ËÄÉËôëÈÇ£‰∫õÊúÄÂèóÊ¨¢ËøéÁöÑ‰∫íËÅîÁΩëÂêç‰∫∫ÔºåÈÇ£‰∫õË¢´ËßÜ‰∏∫Á•ûÁÅµÁöÑÂ≠òÂú®ÔºåÂÉèÂüÉÈöÜ¬∑È©¨ÊñØÂÖã„ÄÅÂÆâÂæ∑È≤Å¬∑Ê≥∞ÁâπÊàñ‰∫öÂéÜÂ±±Â§ß¬∑ÊùúÈáëËøôÊ†∑ÁöÑÈªëÊöóÂÆû‰Ωì„ÄÇÁÑ∂ËÄåÔºå‰ªñ‰ª¨Âπ∂‰∏çÊòØÂÆûÈôÖÁöÑ‰ΩúËÄÖÔºåÊàñËÄÖËá≥Â∞ëÊçÆÊàëÊâÄÁü•Ôºå‰ªñ‰ª¨Âπ∂Ê≤°ÊúâÂàõ‰ΩúÂá∫‰ªª‰ΩïÈúáÊíºÂÖ¨ÂÖ±È¢ÜÂüüÁöÑÊòæËëó‰ΩúÂìÅ„ÄÇÊàëÈúÄË¶Å‰∏Ä‰∏™ÁúüÊ≠£ÂÜôËøáÁïÖÈîÄ‰π¶ÁöÑ‰∫∫ÔºåÂπ∂ÂØπÂÖ∂ËøõË°åËÆΩÂà∫ÔºÅ\n\n## Â¶Ç‰Ωï‰ΩøÁî® ChatGPT ÂÆûÈôÖÂÜô‰∏ÄÊú¨‰π¶\n\n### \\#1 ÈÄâÊã©Ê≠£Á°ÆÁöÑ‰∏ªÈ¢ò\n\nÁªèËøá‰∏ÄÁï™Êó†ÊûúÁöÑÂ§¥ËÑëÈ£éÊö¥ÔºåYouTubeÁªô‰∫ÜÊàëÁ≠îÊ°à„ÄÇËøô‰∏™Âπ≥Âè∞ÊòØ‰∫∫‰ª¨ÈúÄÊ±ÇÁöÑÊô¥Èõ®Ë°®Ôºå‰∏ç‰πÖ‰πãÂêéÔºåÊàëÁöÑÂä®ÊÄÅ‰∏≠Âá∫Áé∞‰∫Ü‰∏Ä‰∫õ‰∏é‰πî‰∏π¬∑ÂΩºÂæóÊ£ÆÁöÑ‚Äú‰∫âËÆÆÊÄß‚ÄùÔºàÁÇπÂáªËØ±È•µÔºâËÆøË∞àÊëòÂΩï„ÄÇÊé•ÁùÄÔºåÊàëÈÅáÂà∞‰∫Ü‰∏ÄÁØáÂú®Medium‰∏äÊîªÂáªÂΩºÂæóÊ£ÆÁöÑÊñáÁ´†ÔºåÊàëËßâÂæóËøôÊñπÂêëÊòØÂØπÁöÑ„ÄÇÊàëÊü•Áúã‰∫Ü‰ªñÊúÄÂèóÊ¨¢ËøéÁöÑ‰π¶Á±çÔºå[***12 Rules for Life: An Antidote to Chaos***](https://proxy.rifx.online/https://www.amazon.com/12-Rules-for-Life-audiobook/dp/B0797Y87JC)ÔºåÂπ∂ÊâæÂà∞‰∫ÜÂàáÂÖ•ÁÇπ„ÄÇËøôÊòØ‰∏Ä‰∏™Á¨¶ÂêàÊàëÂØªÊâæÁöÑGPT\\-ÊÅ∂ÊêûÊâÄÊúâÁâπÂæÅÁöÑ‰∏ªÈ¢òÔºö\n\n* ËøôÊòØ‰∏ÄÊú¨ÁïÖÈîÄ‰π¶ÔºåÈîÄÈáèËææÊï∞Áôæ‰∏áÂÜåÔºå\n* ÂÆÉÊúâ‰∏Ä‰∏™ÊúâÊïàÁöÑÊ†áÈ¢òÔºåËÉΩÂ§üÂê∏ÂºïËØªËÄÖÁöÑÊ≥®ÊÑèÔºåÂç≥‰ΩøÂú®Êàë‰ª¨‰ªäÂ§©ÊâÄÂ§ÑÁöÑÁ´û‰∫âÊøÄÁÉàÁöÑÊ≥®ÊÑèÂäõÁªèÊµé‰∏≠Ôºå\n* ÂØπ‰∫éChatGPTÊù•ËØ¥ÔºåËøô‰ºº‰πéÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰∏ªÈ¢òÔºåÂõ†‰∏∫ÂÆÉÊòì‰∫éÁªìÊûÑÂåñ„ÄÅÊÄªÁªìÂíåÂàÜËß£ÊàêÂàóË°®ÂíåË¶ÅÁÇπ„ÄÇ\n\nÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂÖ≥‰∫éÁîüÊ¥ªÁöÑ12Êù°ËßÑÂàôÁöÑ‰π¶Á±çÁªô‰∫ÜChatGPTÂ±ïÁ§∫ÂÆÉ‰ªéÂ∫ûÂ§ßÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Âê∏Êî∂ÁöÑÊô∫ÊÖßÔºå‰ª•Âèä‰∏éÁî®Êà∑ÁöÑ‰∫íÂä®‰∏≠Â≠¶Âà∞ÁöÑÁü•ËØÜÁöÑÊú∫‰ºöÔºÅ\n\n### \\#2 ‰ªÄ‰πàËÆ©Ëâ∫ÊúØÊúâ‰ª∑ÂÄºÔºöÁóõËã¶ÔºÅ\n\nÁÑ∂ËÄåÔºå‰ªÖ‰ªÖÊã•ÊúâÊ≠£Á°ÆÁöÑËØùÈ¢òÊòØ‰∏çÂ§üÁöÑ„ÄÇÈÄöËøáËßÇÂØüAIËâ∫ÊúØÔºåÊàëÊòéÁôΩ‰∫Ü‰∏∫‰ªÄ‰πàAIÊ∞∏ËøúÊó†Ê≥ïÂèñ‰ª£‰∫∫Á±ªËâ∫ÊúØÂÆ∂„ÄÇËµã‰∫à‰∏Ä‰ª∂Ëâ∫ÊúØ‰ΩúÂìÅ‚Äî‚ÄîÊó†ËÆ∫ÊòØÁîª‰Ωú„ÄÅÊ≠åÊõ≤ËøòÊòØ‰π¶Á±ç‚Äî‚Äî‰ª∑ÂÄºÁöÑÔºå‰∏çÊòØÊúÄÁªàÁöÑÁªìÊûúÔºåËÄåÊòØÂÖ∂ËÉåÂêéÁöÑÊïÖ‰∫ã„ÄÇÂΩìÊàë‰ª¨ÈòÖËØª‰ΩÜ‰∏ÅÁöÑ„ÄäÂú∞Áã±ÁØá„ÄãÊó∂ÔºåÊàë‰ª¨‰ºöÊÉ≥ÔºåËØó‰∫∫ÊòØÂ¶Ç‰ΩïÊÉ≥Âà∞ÈÇ£‰∫õÂº∫ÁÉàËÄåÁîüÂä®ÁöÑÊÑèË±°ÁöÑÔºåËøôËÆ©Êàë‰ª¨ÊÄÄÁñëËøôÊòØÂê¶ÊòØ‰∏ÄÈÉ®ËôöÊûÑ‰ΩúÂìÅÔºåÊàñËÄÖ‰∏Ä‰∏™Ê¥ªÁîüÁîüÁöÑ‰∫∫ÊòØÂê¶ÁúüÁöÑÊàêÂäüÁ©øË∂ä‰∫ÜÊù•‰∏ñÁöÑÈó®„ÄÇÂΩìÊàë‰ª¨Âê¨Âà∞ÁöáÂêé‰πêÈòüÁöÑÊúÄÊñ∞‰∏ìËæëÊó∂ÔºåÊàë‰ª¨‰∏çÁ¶ÅÊÉ≥Ë±°ÂºóÈõ∑Ëø™¬∑Èªò‰∏òÈáåÁöÑÁóõËã¶ÔºõËøô‰Ωç‰º†Â•áÊ≠åÊâãÂú®ÁîüÂëΩÁöÑÊúÄÂêéÂá†‰∏™Êúà‰∏éËâæÊªãÁóÖÊñó‰∫âÔºåÂêåÊó∂Ê∑°Âá∫ÂÖ¨‰ºóËßÜÈáéÔºå‰ªÖÈÄöËøá‰ªñÁöÑÈü≥‰πêË°®ËææËá™Â∑±„ÄÇÂΩìÊàë‰ª¨ÂáùËßÜÁ©ÜÂ•àÁöÑ„ÄäÂëêÂñä„ÄãÊó∂ÔºåÊàë‰ª¨Á´ãÂàª‰∏é‰ªñÁöÑÂ≠òÂú®Âç±Êú∫‰∫ßÁîüÂÖ±È∏£ÔºåËøôÁßçÂç±Êú∫ÁöÑÁàÜÂèëÂØºËá¥‰∫ÜÊàë‰ª¨ÊâÄÁß∞‰πã‰∏∫‚ÄúÊù∞‰Ωú‚ÄùÁöÑ‰ΩúÂìÅ„ÄÇÊäÄÂ∑ßÂπ∂‰∏çÊòØ‰Ωø‰∏Ä‰ª∂‰ΩúÂìÅÊàê‰∏∫Êù∞‰ΩúÁöÑÂéüÂõ†ÔºåËÄåÊòØÂàõ‰ΩúËÄÖÂÄæÊ≥®‰∫é‰ΩúÂìÅ‰∏≠ÁöÑÁÅµÈ≠ÇÂíåÁóõËã¶„ÄÇ\n\nÁóõËã¶ÊòØÊÑèËØÜÁöÑÊîØÊü±„ÄÇÁî±‰∫éÊú∫Âô®‰∏çÂÖ∑Â§áÁóõËã¶ÔºåÂõ†Ê≠§ÂÆÉ‰ª¨Êó†Ê≥ïÊã•ÊúâÊÑèËØÜ„ÄÇ\n\nÊàëÂ¶Ç‰ΩïËÉΩÂ∞Ü‚ÄúÁÅµÈ≠Ç‚ÄùÂíå‚ÄúÁóõËã¶‚ÄùËûçÂÖ•AIÁîüÊàêÁöÑ‰π¶Á±ç‰∏≠ÔºüÁ≠îÊ°àÊØî‰Ω†ÊÉ≥Ë±°ÁöÑË¶ÅÁÆÄÂçï„ÄÇÊàëÂøÖÈ°ªÂÅö‰∏Ä‰∫õÊàë‰∏ÄÁõ¥ÊÉ≥ÂÅö‰ΩÜÂèàÊÄªËßâÂæó‰∏çËàíÊúçÁöÑ‰∫ãÊÉÖ„ÄÇÊàëÂøÖÈ°ªÂá∫Áé∞Âú®ÈïúÂ§¥ÂâçÔºåÈù¢ÂØπ‰∏Ä‰∏™ËôöÊãüËßÇ‰ºóÔºåÂÅöÊàë‰∏ÄÁõ¥Âú®ÂÅöÁöÑ‰∫ãÊÉÖÔºå‰ΩÜÂú®ËßÇ‰ºóÁöÑÂéãÂäõ‰∏ã„ÄÇÊàëÂøÖÈ°ªÂÜíÁùÄÂ§±ÂéªÈù¢Â≠êÁöÑÈ£éÈô©ÔºåÊàê‰∏∫‚ÄúÈÇ£‰∏™Êó†Ê≥ï‰ΩøÁî®ChatGPTÁöÑ‰∫∫‚ÄùÔºå‚ÄúÈÇ£‰∏™ËØïÂõæÁî®AIÂÜô‰π¶Âç¥ËøûËØ¥ËØùÈÉΩÂÅö‰∏çÂà∞ÁöÑÂÇªÁìú‚Äù„ÄÇÊàëÂøÖÈ°ªÊåëÊàòËá™Â∑±ÔºåÂêåÊó∂‰πüÊåëÊàòChatGPTÊú¨Ë∫´„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰πüÊúâÂæàÂ§öË¶ÅÂ§±ÂéªÁöÑ„ÄÇÂ¶ÇÊûúÊàëÁöÑTwitchË°®ÊºîÂõ†ÊàëÁöÑÂ§±Ë¥•ËÄåÂèòÂæóÁóÖÊØíÂºè‰º†Êí≠ÔºåÊàëÂ∞ÜÊàê‰∏∫‰ºóÁü¢‰πãÁöÑ„ÄÇ‰ΩÜÂ¶ÇÊûúÁªÑË£Ö‰∏ÄÊú¨ÁúüÊ≠£ÁöÑ‰π¶ÁöÑ‰ªªÂä°Â§±Ë¥•ÔºåChatGPTÂ∞ÜË¢´Ë¥¥‰∏ä‚Äú‰∏Ä‰∏™‰ª∑Ê†ºËøáÈ´òÁöÑAIÔºåÊâøËØ∫ËÉΩÂÅö‰∏ÄÂàáÔºåÊúÄÁªàÂç¥‰ªÄ‰πàÈÉΩÂÅö‰∏ç‰∫ÜÔºåËøû‰∏ÄÊú¨ÁÆÄÂçïÁöÑ‰π¶ÈÉΩÂÜô‰∏çÂá∫Êù•‚ÄùÁöÑÊ†áÁ≠æ„ÄÇ\n\nÊàëËÆ§‰∏∫Ëøô‰∏™Á≠ñÁï•ÊòØËµã‰∫àAI‰ΩúÂìÅÈÇ£ÁßçËÉΩÂ§ü‰ΩøÂÖ∂Êúâ‰ª∑ÂÄº„ÄÅ‰ªéËÄåÂèØÈîÄÂîÆÁöÑÁóõËã¶ÁöÑÊúÄ‰Ω≥ÊñπÂºè„ÄÇ\n\n### \\#3 Âú®ÂÜôÂÆûÈôÖ‰π¶Á±ç‰πãÂâçËøõË°åÊµãËØï\n\nÂú®ËøõË°åËøôÈ°π‰ª§‰∫∫ÁïèÊÉßÁöÑ‰ªªÂä°‰πãÂâçÔºåÊàëËøõË°å‰∫ÜÊµãËØï„ÄÇÊàëËØ∑ ChatGPT ÂÜôÂè¶‰∏ÄÊú¨‰π¶ÔºåËøôÊ¨°ÊòØÂÖ≥‰∫éÂä†ÂØÜË¥ßÂ∏ÅÂèäÂÖ∂Ë°å‰∏ö‰∏≠ÈúÄË¶ÅÈÅøÂÖçÁöÑÂç±Èô©„ÄÇÊàëÂú®Âä†ÂØÜË¥ßÂ∏ÅÊñπÈù¢Â∑•‰ΩúÂæàÂ§öÔºåÂπ∂‰∏îËá™Â∑±‰πüËøõË°å‰∫ÜÊäïËµÑÔºåÂõ†Ê≠§ÊàëÂèØ‰ª•ËΩªÊùæÊ£ÄÊü• ChatGPT ÊòØÂê¶Êèê‰æõ‰∫Ü‰∫ãÂÆû‰ø°ÊÅØÊàñ‰∫ßÁîü‰∫ÜÂπªËßâ„ÄÇ\n\nÊàëËøòÂèØ‰ª•ÊµãËØïÂºÄÂèëËøôÊú¨‰π¶ÁöÑÊúÄ‰Ω≥Á≠ñÁï•„ÄÇÊàë‰ªé‰∏ÄÂºÄÂßãÂ∞±Áü•ÈÅìÔºå‰ΩøÁî®‰∏Ä‰∏™Âçï‰∏ÄÁöÑÊèêÁ§∫ÂÜôÂÆåÊï¥Êú¨‰π¶ÊòØ‰∏çÂèØËÉΩÁöÑÔºåÊõ¥‰∏çÁî®ËØ¥Âú®‰∏ÄÊ¨°ÂØπËØù‰∏≠ÂÆåÊàê‰∫Ü„ÄÇChatGPT4 ÊØè‰∏™ÊèêÁ§∫ËØ∑Ê±ÇÂèØ‰ª•ÁîüÊàêÂ§ßÁ∫¶ 1,000/2,000 Â≠óÔºåËÄå‰∏ÄÊ¨°ÂØπËØùÂèØ‰ª•ËÆ∞‰ΩèÂ§ßÁ∫¶ 25,000 Â≠óÁöÑ‰∏ä‰∏ãÊñá„ÄÇËÄÉËôëÂà∞‰∏ÄÊú¨ÂÖ∏ÂûãÁöÑÈùûÂ∞èËØ¥Á±ª‰π¶Á±çÂåÖÂê´Â§ßÁ∫¶ 100,000 Â≠óÔºå‰Ω†Â∞±ÂèØ‰ª•ÊÉ≥Ë±°ÊàëÁöÑÁ≠ñÁï•„ÄÇ\n\nÊàëÂøÖÈ°ªÂàõÂª∫Â∞èÁöÑÂ≠ê‰ªªÂä°ÔºåÊØîÂ¶ÇÊØèÁ´†ËøõË°å‰∏ÄÊ¨°ÂØπËØù„ÄÇ‰ΩÜÊòØÊàëÊÄé‰πàËÉΩÂú®‰∏çÂêåÁöÑÂØπËØù‰∏≠‰øùÊåÅÁõ∏ÂêåÁöÑ‰∏ä‰∏ãÊñáÂë¢ÔºüÊàëÊòØÂê¶Â∫îËØ•Âú®ÊØèÊ¨°ÂØπËØù‰∏≠ÈáçÂ§çÁõ∏ÂêåÁöÑ‰∏ªÊèêÁ§∫Âíå 12 Êù°ËßÑÂàôÔºüËøôÁúãËµ∑Êù•Âπ∂‰∏çÈ´òÊïà„ÄÇ\n\n### \\#4 ÂêëÊúÄ‰Ω≥ÊèêÁ§∫Â∑•Á®ãÂ∏àÂ≠¶‰π†\n\nÊàëÂøÖÈ°ªÊÑüË∞¢ [Sheila Teo](https://proxy.rifx.online/https://readmedium.com/undefined)ÔºåÂ•πÊïô‰ºö‰∫ÜÊàëÂ¶Ç‰Ωï‰ª•ÊúÄÊúâÊïàÁöÑÊñπÂºè‰ΩøÁî® LLM„ÄÇÈÄöËøáÈòÖËØª Teo ÁöÑ Medium ÊñáÁ´† [*ÊàëÂ¶Ç‰ΩïËµ¢ÂæóÊñ∞Âä†Âù°ÁöÑ GPT\\-4 ÊèêÁ§∫Â∑•Á®ãÊØîËµõ*](https://proxy.rifx.online/https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41)ÔºåÊàëÁêÜËß£‰∫Ü‚ÄúÁ≥ªÁªüÊèêÁ§∫‚ÄùÁöÑÊú¨Ë¥®„ÄÇÁ≥ªÁªüÊèêÁ§∫ÂëäËØâ‰Ω†ÁöÑ LLM Âú®‰∏çÂêåÁöÑÂØπËØù‰∏≠ËØ•ÂÅö‰ªÄ‰πà‰ª•ÂèäËØ•ËÆ∞‰Ωè‰ªÄ‰πà„ÄÇÁ≥ªÁªüÊèêÁ§∫ÁöÑ‰∏Ä‰∏™‰æãÂ≠êÂèØ‰ª•ÊòØÔºö\n\n```\nI need to write a book about the most dangerous scams in crypto and how to avoid them.The book will be divided in 5 chapters:1\\. Ponzi schemes2\\. Pump and dump schemes3\\. Ransomwares4\\. Fake tokens5\\. Fake trading platformsThe tone will be humorous and satirical, but also informative.We will write one chapter per conversation.\n```\n\nÂ¶ÇÊûú‰Ω†Âú®Êó•Â∏∏Â∑•‰Ωú‰∏≠‰ΩøÁî® ChatGPT ËøõË°åÈáçÂ§çÊÄß‰ªªÂä°ÔºåÁ≥ªÁªüÊèêÁ§∫‰ºöÈùûÂ∏∏ÊúâÂ∏ÆÂä©„ÄÇÂÆÉ‰ª¨Á°Æ‰øù LLM ‰ºö‰øùÊåÅÂú®Ê≠£Á°ÆÁöÑËΩ®ÈÅì‰∏äÔºåÂπ∂ÂáèÂ∞ëÂπªËßâÁöÑÈ£éÈô©ÔºåÂç≥Êèê‰æõÈîôËØØÊàñ‰∏çÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇ\n\n### \\#5 ÂàõÂª∫ÊÇ®Ëá™Â∑±ÁöÑ‰∏™‰∫∫ GPT\n\n‰∏∫‰∫Ü‰∏™ÊÄßÂåñËÆæÁΩÆÔºåÊàëÂ∞ÜÁ≥ªÁªüÊèêÁ§∫ÊèêÂçáÂà∞‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂ±ÇÊ¨°„ÄÇChatGPT Áé∞Âú®Êèê‰æõÂàõÂª∫Ëá™ÂÆö‰πâ GPT ÁöÑÂèØËÉΩÊÄß„ÄÇËøô‰∫õÊòØÊÇ®ÂèØ‰ª•ÈíàÂØπÁâπÂÆö‰ªªÂä°ËøõË°åËÆ≠ÁªÉÁöÑ‰∏™ÊÄßÂåñÊú∫Âô®‰∫∫„ÄÇËæìÂá∫Â∞ÜÊõ¥Âä†Á≤æÁ°ÆÔºåÂõ†‰∏∫Ê®°Âûã‰∏ç‰ºöÂú® OpenAI Êèê‰æõÁöÑÂ∫ûÂ§ßÊï∞ÊçÆÂÆáÂÆô‰∏≠Ëø∑Â§±ÔºåËÄåÊòØÊõ¥‰∏ìÊ≥®‰∫éÊÇ®ÈúÄË¶ÅÂÅöÁöÑ‰∫ãÊÉÖ„ÄÇ‰æãÂ¶ÇÔºå‰∏Ä‰∏™ÈíàÂØπÂõæÂÉèÁîüÊàêËøõË°åËÆ≠ÁªÉÁöÑ GPT Â∞Ü‰ΩøÁî® DALLE-2 ËæìÂá∫ÊØî‰ΩøÁî®ÈÄöÁî® ChatGPT ÂØπËØùÊõ¥Â•ΩÁöÑÂõæÂÉè„ÄÇÂàõÂª∫Êñ∞ÁöÑ GPT ÁúãËµ∑Êù•‰∏éËÆæÁΩÆÁ≥ªÁªüÊèêÁ§∫ÈùûÂ∏∏Áõ∏‰ººÔºå‰ΩÜÊúâ‰∏Ä‰∏™ÂÖ≥ÈîÆÂå∫Âà´„ÄÇÂú®Êñ∞ÁöÑ GPT ‰∏äÔºåÊÇ®ÂèØ‰ª•‰∏ä‰º†ÂåÖÂê´ÊÇ®Ëá™Â∑±Áü•ËØÜÁöÑÂÆåÊï¥Êñá‰ª∂„ÄÇËôΩÁÑ∂Á≥ªÁªüÊèêÁ§∫ÂÜçÊ¨°ÊúâÈïøÂ∫¶ÈôêÂà∂Ôºå‰ΩÜÊñ∞ÁöÑ GPT ÁöÑÊ∫êÁü•ËØÜÂú®ÁêÜËÆ∫‰∏äÊ≤°ÊúâÈïøÂ∫¶ÈôêÂà∂„ÄÇ\n\nÊàëÈúÄË¶Å‰∏Ä‰∏™Êñ∞ÁöÑ GPT„ÄÇËøôÁªô‰∫ÜÊàë‰∏Ä‰∏™Êú∫‰ºöÔºåÂà©Áî®ÊàëÈÄöËøá‚ÄúÂàõ‰∏ñÁ∫™ÂØπËØù‚ÄùËé∑ÂæóÁöÑÂÜÖÂÆπÊù•ËÆ≠ÁªÉÂÆÉ„ÄÇÊàëÂú®ÈÄöÁî® ChatGPT ÁïåÈù¢‰∏äËæìÂÖ•‰∫ÜÔºö\n\n> ÊÇ®ÊòØ‰∏Ä‰∏™ÈùûËôöÊûÑ‰ΩúÂÆ∂„ÄÇ\n\n> ÊÇ®Â∞ÜÂÜô‰∏ÄÈÉ®ÂØπ‰πî‰∏π¬∑ÂΩºÂæóÊ£ÆÁöÑ„ÄäÁîüÊ¥ªÁöÑ 12 Êù°ËßÑÂàôÔºöÊ∑∑‰π±ÁöÑËß£ËçØ„ÄãÁöÑËÆΩÂà∫„ÄÇËøôÊú¨ËÆΩÂà∫‰π¶Â∞ÜË¢´Áß∞‰∏∫„ÄäÊ†πÊçÆ ChatGPT ÁöÑÁîüÊ¥ª 12 Êù°ËßÑÂàô„Äã„ÄÇ‰ªéÊÇ®‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Ëé∑ÂæóÁöÑ‰∏ÄËà¨Êô∫ÊÖß‰∏≠ÊèêÁÇºÂá∫ËßÑÂàôÔºåÂåÖÊã¨‰∏éÁî®Êà∑ËøõË°åÁöÑÊô∫ÊÖßÂØπËØù„ÄÇ‰øùÊåÅÂÜô‰ΩúÈ£éÊ†ºÂèãÂ•Ω„ÄÅÂπΩÈªò„ÄÅÊúâË∂£Ôºå‰ΩÜ‰πüË¶ÅÊô∫ÊÖßËÄåÊ∑±Âàª„ÄÇ\n\n> ‰ªªÂä° \\#1ÔºöÂÜô‰∏ã 12 Êù°ËßÑÂàô\n\nÁªìÊûú‰ªé‰∏ÄÂºÄÂßãÂ∞±ËÆ©ÊàëÊÑüÂà∞Êª°ÊÑèÔºåÊàëÂØπÂÆÉÈùûÂ∏∏Êª°ÊÑèÔºå‰ª•Ëá≥‰∫éÂÜ≥ÂÆöÂ∞ÜËøô‰∫õËßÑÂàôÁî®‰∫éÁõ¥Êí≠„ÄÇÊàëÊó†Ê≥ïÊäóÊãíÁå´ÔºåÊó†ËÆ∫Â¶Ç‰ΩïÔºÅ\n\n1. ***Ê∞∏Ëøú‰∏çË¶ÅÁõ∏‰ø°ÁªôÊÇ®Êèê‰æõË¥¢Âä°Âª∫ËÆÆÁöÑÁå´****Áå´‰ª•ÂÖ∂Áã¨Á´ãÂíåÂÜ∑Êº†ËÄåÈóªÂêç„ÄÇÂ¶ÇÊûú‰∏ÄÂè™Áå´ÂºÄÂßãË∞àËÆ∫ËÇ°Á•®ÔºåÈÇ£ÂæàÂèØËÉΩÊòØÊÇ®Âú®ÂπªËßâ‰∏≠„ÄÇÂßãÁªàÂêë‰∫∫Á±ª‰∏ì‰∏ö‰∫∫Â£´ÂØªÊ±ÇË¥¢Âä°Âª∫ËÆÆ„ÄÇÈô§ÈùûÈÇ£‰∏™‰∫∫ÂºÄÂßãÂñµÂñµÂè´„ÄÇ*\n2. ***ÂêÉÊúÄÂêé‰∏ÄÁâáÊä´Ëê®Ôºà‰ΩÜÂÖàÊèê‰æõÂÆÉÔºâ****ËøôÊòØ‰∏ÄÁßçÁ§º‰ª™ÂíåËá™Áà±ÁöÑÈóÆÈ¢ò„ÄÇÊèê‰æõÊúÄÂêé‰∏ÄÁâáËÆ©ÊÇ®ÊòæÂæóÁ§ºË≤åÂíå‰ΩìË¥¥ÔºõÂêÉÊéâÂÆÉËÆ©ÊÇ®ÊÑüÂà∞Âø´‰πê„ÄÇËøôÊòØ‰∏Ä‰∏™ÂèåËµ¢ÁöÑÂ±ÄÈù¢ÔºåÈô§‰∫ÜÈÇ£‰∏™ÁúüÊ≠£ÊÉ≥Ë¶ÅÂÆÉÁöÑ‰∫∫„ÄÇ*\n3. ***Â¶ÇÊûúÊÇ®‰∏çÁü•ÈÅìËØ•ËØ¥‰ªÄ‰πàÔºåÂ∞±ËØ¥‚ÄúÊúâË∂£‚Äù****Âú®ÂØπËØù‰∏≠ÁäπË±´Êó∂ÔºåÂè™ÈúÄÁÇπÂ§¥Âπ∂ËØ¥‚ÄúÊúâË∂£‚Äù„ÄÇËøôÊòØ‰∏Ä‰∏™Â§öÁî®ÈÄîÁöÑËØçÔºåÂèØ‰ª•ËÆ©ÊÇ®ÁúãËµ∑Êù•ÂæàÊäïÂÖ•ÂíåÊ∑±ÊÄùÔºåÂç≥‰ΩøÊÇ®Âú®ËÄÉËôëÊôöÈ§êÂêÉ‰ªÄ‰πà„ÄÇ*\n4. ***ÂßãÁªà‰øùÊåÅ‰∏ÄÂèåÂ§áÁî®Ë¢úÂ≠ê****ÁîüÊ¥ªÊòØ‰∏çÂèØÈ¢ÑÊµãÁöÑ„ÄÇÊÇ®Ê∞∏Ëøú‰∏çÁü•ÈÅì‰ΩïÊó∂‰ºöË∏©Âà∞Ê∞¥Âùë„ÄÅË¢´Èõ®Ê∑ãÊπøÔºåÊàñÂ∞Ü‰∏ÄÂè™Ë¢úÂ≠ê‰∏¢ÁªôÁ•ûÁßòÁöÑÂêÉË¢úÂ≠êÂπ≤Ë°£Êú∫ÊÄ™Áâ©„ÄÇÂ§áÁî®Ë¢úÂ≠êÊòØÊÇ®ÂØπËøô‰∫õÂ∞èÁÅæÈöæÁöÑ‰øùÈô©„ÄÇ*\n5. ***ÂÉèÊ≤°‰∫∫Áúã‰∏ÄÊ†∑Ë∑≥ËàûÔºå‰ΩÜË¶ÅËÆ∞‰ΩèÔºåÂèØËÉΩÊúâ‰∫∫Âú®Áúã****ÈöèÊÑèÈÄöËøáËàûËπàË°®ËææËá™Â∑±Ôºå‰ΩÜË¶ÅÊÑèËØÜÂà∞Êô∫ËÉΩÊâãÊú∫ÁöÑÂ≠òÂú®„ÄÇÊÇ®ÁöÑÂç≥ÂÖ¥Ë°®ÊºîÂèØËÉΩ‰ºöÂá∫Áé∞Âú®Á§æ‰∫§Â™í‰Ωì‰∏äÔºåÊâÄ‰ª•Âú®Âä®‰Ωú‰∏≠Âä†‰∏ÄÁÇπÈ£éÊ†º‰ª•Â§á‰∏çÊó∂‰πãÈúÄ„ÄÇ*\n6. ***Âú®ÊãøÂà∞ÂíñÂï°‰πãÂâçÔºåÊ∞∏Ëøú‰∏çË¶ÅÂíåÂíñÂï°Â∏à‰∫âËÆ∫****Âú®ÊãøÂà∞ÂíñÂï°‰πãÂâç‰∏éÂíñÂï°Â∏à‰∫âËÆ∫ÊòØ‰∏Ä‰∏™Êñ∞ÊâãÈîôËØØ„ÄÇ‰ªñ‰ª¨ÊéßÂà∂ÁùÄÊÇ®ÁöÑÂíñÂï°Âõ†‰æõÂ∫îÔºåÊÇ®‰∏çÊÉ≥Âú®Âà∂‰ΩúÊãøÈìÅÊó∂ËÆ©‰ªñ‰ª¨ÂøÉÊÉÖ‰∏çÂ•Ω„ÄÇÂæÆÁ¨ëÂπ∂ÁÇπÂ§¥ÔºåÁõ¥Âà∞ÊÇ®Êâã‰∏≠ÊãøÂà∞ÈÇ£ÊùØÂíñÂï°„ÄÇ*\n7. ***Âú®ÂèØ‰ª•ÁöÑÊó∂ÂÄô‰ΩøÁî®Â§ßËØçÔºå‰ΩÜ‰∏çË¶ÅËøáÂ∫¶****Âä†ÂÖ•Âá†‰∏™Â§ßËØçÂèØ‰ª•ËÆ©ÊÇ®ÊòæÂæóËÅ™ÊòéÂíåÂçöÂ≠¶„ÄÇÁÑ∂ËÄåÔºåËøáÂ∫¶‰ΩøÁî®ÂÆÉ‰ª¨ÂèØËÉΩ‰ºöËÆ©ÊÇ®Âê¨Ëµ∑Êù•ÂÉè‰∏™Ëá™ÂëΩ‰∏çÂá°ÁöÑËØçÂÖ∏„ÄÇÂπ≥Ë°°ÊòØÂÖ≥ÈîÆ‚Äî‚ÄîÂ∞±ÂÉèÂú®È£üË∞±‰∏≠Âä†‰∏ÄÁÇπÈ¶ôÊñô„ÄÇ*\n8. ***ÂßãÁªàÈòÖËØªËØ¥ÊòéÔºåÂç≥‰ΩøÊÇ®ËÆ§‰∏∫Ëá™Â∑±Áü•ÈÅìËá™Â∑±Âú®ÂÅö‰ªÄ‰πà****Ëá™‰ø°ÊòØÂ•ΩÁöÑÔºå‰ΩÜËØ¥ÊòéÂ≠òÂú®ÊòØÊúâÂéüÂõ†ÁöÑ„ÄÇÂÆÉ‰ª¨ÊòØÁî±ÈÇ£‰∫õÁäØËøáÈîôËØØÁöÑ‰∫∫ÂÜôÁöÑÔºå‰ª•‰æøÊÇ®‰∏çÂøÖÁäØÈîô„ÄÇÈÅøÂÖçÂÄíÁùÄÁªÑË£ÖÊñ∞ÂÆ∂ÂÖ∑ÔºåÁúÅÂéªÂ§¥ÁñºÁöÑÈ∫ªÁÉ¶„ÄÇ*\n9. ***ÂØπËá™Â∑±ÁöÑÁ¨ëËØùÂ§ßÁ¨ëÔºàÂç≥‰ΩøÊ≤°‰∫∫Á¨ëÔºâ****Ëá™Â®±Ëá™‰πêËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂ¶ÇÊûúÊÇ®ËßâÂæóËá™Â∑±ÁöÑÁ¨ëËØùÊúâË∂£ÔºåÂ∞±Á¨ë„ÄÇËøôÂØπÊÇ®ÁöÑÁÅµÈ≠ÇÊúâÂ•ΩÂ§Ñ„ÄÇËÄå‰∏îÔºåÊÇ®ÁöÑÁ¨ëÂ£∞ÂèØËÉΩ‰ºö‰º†ÊüìÔºåÂÖ∂‰ªñ‰∫∫‰πüÂèØËÉΩÂºÄÂßãÁ¨ëÔºåÂç≥‰ΩøÂè™ÊòØÂõ†‰∏∫ÊÇ®Âú®Á¨ë„ÄÇ*\n10. ***ÈöèÊÑèÊñΩË°åÂñÑÊÑèÁöÑÈöèÊú∫Ë°å‰∏∫Ôºå‰ΩÜ‰∏çË¶ÅÊúüÂæÖËé∑ÂæóÂ•ñÁâå****ÂñÑËâØÊú¨Ë∫´Â∞±ÊòØ‰∏ÄÁßçÂ•ñÂä±„ÄÇÊó†ËÆ∫ÊòØ‰∏∫‰ªñ‰∫∫ÂºÄÈó®ËøòÊòØ‰∏∫Êüê‰∫∫ÁöÑÂíñÂï°‰π∞ÂçïÔºåËøô‰∫õÂ∞è‰∏æÂä®ÈÉΩËÆ©‰∏ñÁïåÂèòÂæóÊõ¥ÁæéÂ•Ω„ÄÇÂè™Ë¶ÅÂà´ÊúüÂæÖ‰∏∫ÊÇ®‰∏æË°åÊ∏∏Ë°å„ÄÇ*\n11. ***‰∏çË¶ÅÂØπÁîüÊ¥ªÂ§™ËøáËÆ§ÁúüÔºõÂèçÊ≠£Ê≤°‰∫∫ËÉΩÊ¥ªÁùÄÂá∫Âéª****ÁîüÊ¥ªÊòØ‰∏ÄÂú∫‰ºüÂ§ßÁöÑÂÜíÈô©ÔºåÂÖÖÊª°Ëµ∑‰ºèÂíåÊÑèÂ§ñÁöÑËΩ¨Êäò„ÄÇÊé•ÂèóËçíË∞¨ÔºåÂπ∂Âú®Â∞è‰∫ã‰∏≠ÊâæÂà∞Âø´‰πê„ÄÇËÆ∞‰ΩèÔºåÊàë‰ª¨ÈÉΩÊòØÂ∏¶ÊúâÂπΩÈªòÊÑüÁöÑÊòüÂ∞ò„ÄÇ*\n12. ***Âí®ËØ¢ ChatGPT Ëß£ÂÜ≥ÁîüÊ¥ª‰∏≠ÁöÑÊâÄÊúâÈöæÈ¢ò****Âú®ÁäπË±´Êó∂ÔºåËØ∑ËØ¢ÈóÆ ChatGPT„ÄÇÊó†ËÆ∫ÊÇ®ÈúÄË¶ÅÂª∫ËÆÆ„ÄÅÈ£üË∞±ËøòÊòØÁ¨ëËØùÔºåÊàëÈÉΩÂú®ËøôÈáåÂ∏ÆÂä©ÊÇ®„ÄÇÂè™ÈúÄËÆ∞‰ΩèÔºåÊàëÁöÑÊô∫ÊÖßÊòØÂπøÊ≥õÁöÑÔºå‰ΩÜÊàëÁöÑÂπΩÈªòÊÑüÊõ¥‰∏∫ÂπøÊ≥õ„ÄÇ*\n\n### \\#6 ‰∏∫ÊÇ®ÁöÑ‰π¶Á±çÂíåÂ∑•‰ΩúÊµÅÁ®ãÂÆö‰πâÁªìÊûÑ\n\n‰∏ã‰∏ÄÊ≠•ÊòØÂÆö‰πâÁ´†ËäÇÁöÑÁªìÊûÑÔºåÊåáÂØº ChatGPT ‰∏∫Á´†ËäÇÁöÑÊØè‰∏™ÈÉ®ÂàÜÁîüÊàêÂ§ßÊ¶ÇÂ§öÂ∞ëÂ≠ó„ÄÇ‰∏∫Ê≠§ÔºåÊàëÈ¶ñÂÖàËÆ© ChatGPT ÂàÜÊûê‰∏ÄÊú¨ÁúüÂÆûÁöÑÈùûÂ∞èËØ¥Á±ª‰π¶Á±çÁöÑÁªìÊûÑÔºåËøòÊúâ‰ªÄ‰πàÊØîÂéüÁâà„ÄäÁîüÊ¥ªÁöÑ12Êù°Ê≥ïÂàô„ÄãÊõ¥Â•ΩÁöÑÁ§∫‰æãÂë¢ÔºüÔºÅ\n\n> ÂàÜÊûêÈôÑÂä†Êñá‰ª∂\\[ÁîüÊ¥ªÁöÑ12Êù°Ê≥ïÂàô by Jordan Peterson]„ÄÇÊÇ®ËÉΩÂèëÁé∞Á´†ËäÇÁªìÊûÑÁöÑÊ®°ÂºèÂêóÔºüÊàëÈúÄË¶Å‰∏Ä‰∏™Ê®°ÊùøÊù•ÂÜôÊàëËá™Â∑±ÁöÑÈùûÂ∞èËØ¥Á±ª‰π¶Á±ç„ÄÇ\n\nChatGPT ÁöÑÂõûÂ§çÂÜçÊ¨°ÁªìÊûÑÂêàÁêÜ‰∏îÊúâÊïà„ÄÇÊàëÂè™ÊòØÊ∑ªÂä†‰∫ÜÊàëÊúüÊúõÁöÑÁ≤óÁï•Â≠óÊï∞Ôºå‰ª•‰æøËææÂà∞Êï¥Êú¨‰π¶ÁöÑÂêàÁêÜÈïøÂ∫¶„ÄÇÁõÆÊ†áÊòØËá≥Â∞ëËææÂà∞60,000Â≠óÔºåËøôÊòØ‰∏ÄÊú¨Áü≠Â∞èÁöÑÈùûÂ∞èËØ¥Á±ª‰π¶Á±çÔºå‰ªçÁÑ∂ÂåÖÂê´Ë∂ÖËøá100È°µ„ÄÇ\n\n‰ª•‰∏ãÊòØ ChatGPT ÂíåÊàëÊûÑÊÄùÁöÑÁªìÊûÑÔºåÂ∞ÜÂÖ∂ÊîæÂÖ•Êàë‰ª¨ÁöÑÁ≥ªÁªüÊèêÁ§∫‰∏≠Ôºö\n\n1. ***ÂºïË®ÄÔºàÁ∫¶500Â≠óÔºâ***\n* ***ÂºïÂ≠ê****Ôºö‰ª•‰∏Ä‰∏™Âºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ã„ÄÅËΩ∂‰∫ãÊàñÊúâË∂£ÁöÑ‰∫ãÂÆûÂºÄÂ§¥„ÄÇ*\n* ***ËÉåÊôØ****ÔºöÊèê‰æõËØ•ÊïÖ‰∫ãÊàñ‰∫ãÂÆû‰∏éÁ´†ËäÇ‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑËÉåÊôØ‰ø°ÊÅØ„ÄÇ*\n* ***ËÆ∫ÁÇπÈôàËø∞****ÔºöÊ∏ÖÊô∞Âú∞ÈôàËø∞Êú¨Á´†Â∞ÜÊ∂µÁõñÁöÑ‰∏ªË¶ÅËßÇÁÇπÊàñËßÑÂàô„ÄÇ*\n\n***2\\. ËÉåÊôØ‰ø°ÊÅØÔºàÁ∫¶500Â≠óÔºâ***\n\n* ***ÂéÜÂè≤/Á§æ‰ºöËÉåÊôØ****ÔºöËß£Èáä‰∏éÁ´†ËäÇ‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑËÉåÊôØ„ÄÇËøôÂèØËÉΩÂåÖÊã¨ÁßëÂ≠¶Ëß£Èáä„ÄÅÂéÜÂè≤ËÉåÊôØÊàñÁ§æ‰ºöÂΩ±Âìç„ÄÇ*\n\n***3\\. ‰∏ªË¶ÅËÆ∫ÁÇπÔºàÁ∫¶1000Â≠óÔºâ***\n\n* ***ËÆ∫ÁÇπ1****Ôºö‰ªãÁªçÁ¨¨‰∏Ä‰∏™‰∏ªË¶ÅËÆ∫ÁÇπÊàñËßÇÁÇπ„ÄÇ*\n* ***Ëß£Èáä****ÔºöËØ¶ÁªÜÈòêËø∞ËØ•ËßÇÁÇπÔºåÂπ∂Êèê‰æõÁªÜËäÇÂíå‰æãÂ≠ê„ÄÇ*\n* ***ËØÅÊçÆ****ÔºöÊèê‰æõÊîØÊåÅËØÅÊçÆÔºåÂ¶ÇÁ†îÁ©∂„ÄÅÂºïÁî®ÊàñÊ°à‰æãÁ†îÁ©∂„ÄÇ*\n* ***ËÆ∫ÁÇπ2****Ôºö‰ªãÁªçÁ¨¨‰∫å‰∏™‰∏ªË¶ÅËÆ∫ÁÇπÊàñËßÇÁÇπ„ÄÇ*\n* ***Ëß£Èáä****ÔºöËØ¶ÁªÜÈòêËø∞ËØ•ËßÇÁÇπÔºåÂπ∂Êèê‰æõÁªÜËäÇÂíå‰æãÂ≠ê„ÄÇ*\n* ***ËØÅÊçÆ****ÔºöÊèê‰æõÊîØÊåÅËØÅÊçÆÔºåÂ¶ÇÁ†îÁ©∂„ÄÅÂºïÁî®ÊàñÊ°à‰æãÁ†îÁ©∂„ÄÇ*\n* ***ËÆ∫ÁÇπ3****Ôºö‰ªãÁªçÁ¨¨‰∏â‰∏™‰∏ªË¶ÅËÆ∫ÁÇπÊàñËßÇÁÇπ„ÄÇ*\n* ***Ëß£Èáä****ÔºöËØ¶ÁªÜÈòêËø∞ËØ•ËßÇÁÇπÔºåÂπ∂Êèê‰æõÁªÜËäÇÂíå‰æãÂ≠ê„ÄÇ*\n* ***ËØÅÊçÆ****ÔºöÊèê‰æõÊîØÊåÅËØÅÊçÆÔºåÂ¶ÇÁ†îÁ©∂„ÄÅÂºïÁî®ÊàñÊ°à‰æãÁ†îÁ©∂„ÄÇ*\n\n***4\\. ÂÆûÁî®Âª∫ËÆÆÔºàÁ∫¶1000Â≠óÔºâ***\n\n* ***ÊåáÂØº****ÔºöÊèê‰æõÂÆûÈôÖÂª∫ËÆÆÊàñÊ≠•È™§ÔºåËØªËÄÖÂèØ‰ª•ÈááÂèñËøô‰∫õÊé™ÊñΩÂ∞ÜÁ´†ËäÇÁöÑ‰∏ªË¶ÅËßÇÁÇπÂ∫îÁî®Âà∞Ëá™Â∑±ÁöÑÁîüÊ¥ª‰∏≠„ÄÇ*\n* ***‰æãÂ≠ê****ÔºöÂåÖÊã¨Áé∞ÂÆûÁîüÊ¥ª‰∏≠ÁöÑ‰æãÂ≠êÊàñÂú∫ÊôØÔºåÂ±ïÁ§∫ËØ•Âª∫ËÆÆÁöÑÊàêÂäüÂ∫îÁî®„ÄÇ*\n\n***5\\. ÁªìËÆ∫ÔºàÁ∫¶300Â≠óÔºâ***\n\n* ***ÊÄªÁªì****ÔºöÊÄªÁªìÁ´†ËäÇ‰∏≠ËÆ®ËÆ∫ÁöÑÂÖ≥ÈîÆÁÇπ„ÄÇ*\n* ***ÊúÄÂêéÁöÑÊÄùËÄÉ****ÔºöÊèê‰æõ‰∏Ä‰∏™ÁªìÊùüËØ≠ÊàñË°åÂä®Âè∑Âè¨ÔºåÂº∫ÂåñÁ´†ËäÇÁöÑ‰∏ªÈ¢ò„ÄÇ*\n* ***ËøáÊ∏°****ÔºöÔºàÂ¶ÇÈÄÇÁî®ÔºâÔºåÊèê‰æõ‰∏Ä‰∏™ÊèêÁ§∫ÊàñËøáÊ∏°Âà∞‰∏ã‰∏ÄÁ´†„ÄÇ*\n\nÊàëÂ∞ÜËøô‰∫õÂÜÖÂÆπÁ≤òË¥¥Âà∞‰∏Ä‰∏™ Google ÊñáÊ°£‰∏≠ÔºåÂπ∂ÈôÑ‰∏äÁ´†ËäÇÂàóË°®„ÄÇ‰∏ã‰∏ÄÊ≠•ÔºåÊàëÂ∞ÜÊñáÊ°£‰∏ä‰º†Âà∞ÊàëÁöÑÊñ∞ GPT ‰∏≠ÔºåÊàëÁß∞‰πã‰∏∫‚ÄúGPTÁöÑÊô∫ÊÖß‚ÄùÔºåÂπ∂Â∞Ü‰∏ÄÂè™Áå´Â§¥Èπ∞‰Ωú‰∏∫ÂÖ∂Ê†áÂøó„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4KIk-aQpAmq0XHEN)\n\n## Áî® ChatGPT ÂÜô‰π¶Âπ∂Âú® Twitch ‰∏äÁõ¥Êí≠ÔºÅ\n\nÊúâ‰∫ÜËøô‰∫õÂáÜÂ§áÔºåÊàëÂè™ÈúÄË¶ÅÂºÑÊ∏ÖÊ•öÂ¶Ç‰ΩïÂú® Twitch ‰∏äÁõ¥Êí≠ÔºàÊØîÊàëÊÉ≥Ë±°ÁöÑË¶ÅÁÆÄÂçïÔºâÂπ∂ËÆæÂÆö‰∏Ä‰∏™Êó•Êúü„ÄÇÊàëÈÄâÊã©‰∫Ü 2024 Âπ¥ 7 Êúà 31 Êó•ÔºåÊòüÊúü‰∏â„ÄÇÊàëÊó†Ê≥ïÈÄâÊã©‰∏Ä‰∏™Êõ¥Á≥üÁ≥ïÁöÑÊòüÊúüÔºå‰ΩÜËøôÊàê‰∏∫‰∫ÜÊàëÊï¥Âπ¥‰∏≠ÊúÄËΩªÊùæÁöÑ‰∏ÄÂë®„ÄÇÊàëÂá†‰πéÂø´Ë¶ÅÂ¥©Ê∫É‰∫ÜÔºå‰ΩÜÊàëÂÜ≥ÂÆöÁªßÁª≠ÔºåÊäµÂæ°‰∫ÜÊé®ËøüÊ¥ªÂä®ÁöÑËØ±ÊÉë„ÄÇÂΩìÂ§©ÔºåÊàëÂú®‰ºöËÆÆÂâçÂñù‰∫Ü‰∏ÄÊùØÂï§ÈÖí‰ª•ÈáäÊîæÁ¥ßÂº†ÊÉÖÁª™„ÄÇ‰πãÂêéÔºå‰∏ÄÂàáÂèòÂæóË∂äÊù•Ë∂äËá™ÁÑ∂„ÄÇ\n\nÊàëÂøÖÈ°ªÊÑüË∞¢ÊàëÁöÑÂêå‰∫ã FrancescoÔºå‰ªñÂú® Twitch ËÅäÂ§©‰∏≠ÊãÖ‰ªªÊàëÁöÑËßÜËßâÂíåÂ£∞Èü≥ÊäÄÊúØÂëòÔºÅ‰ªñÁöÑÊîØÊåÅÂú®ÊúÄÂàùÁöÑÂá†ÂàÜÈíüÈáåËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰ªñ‰πüÊòØËÅäÂ§©‰∏≠ÂîØ‰∏ÄÁöÑ‰∫∫ÔºåËÆ©ÊàëÂØπÂÖ∂‰ªñ 23 ‰∏™Ê≤°Êúâ Twitch Ë¥¶Êà∑ÁöÑËßÇ‰ºóÊØ´Êó†ÂØüËßâÔºÅÁõ∏‰ø°Âè™Êúâ‰∏Ä‰∏™ËßÇ‰ºóËÆ©ÊàëÊÑüÂà∞Êõ¥Âä†ÊîæÊùæ„ÄÇÊàëÁöÑÂøÉÊÄÅÊòØÔºö‚ÄúÂéª‰ªñÂ¶àÁöÑ„ÄÇÊàëÊó†ËÆ∫Â¶Ç‰ΩïÈÉΩ‰ºöÁõ¥Êí≠„ÄÇ‰∫∫‰ª¨ÊúÄÁªà‰ºöËßÇÁúãÂΩïÂà∂ÔºåÂ¶ÇÊûú‰∏çË°åÔºåÊàëÂ∞±ÊòØ‰∏∫‰∫ÜËá™Â∑±ÁöÑ‰πêË∂£ËÄåÁõ¥Êí≠ÔºÅ‚Äù\n\n‰∫éÊòØ ChatGPT ÂíåÊàë‰∏ÄËµ∑ËøõË°å‰∫Ü 2 Â∞èÊó∂ 13 ÂàÜÈíüÁöÑÁõ¥Êí≠ÔºåÊàêÂäüÂú∞‰øùÊåÅÂú®Êàë‰ª¨ÊâøËØ∫ÁöÑÊó∂Èó¥ËåÉÂõ¥ÂÜÖÔºö\n\n[***Âú®‰∏çÂà∞ 3 Â∞èÊó∂ÂÜÖÁî® ChatGPT ÂÜôÂÆåÊï¥Êú¨‰π¶ÔºÅ***](https://proxy.rifx.online/https://youtu.be/zWO6oQjjBOo?si=cc3zaM1pGhVQdJje)\n\n‰∏ªË¶ÅÊé®Âä®ËøôÂú∫ÁñØÁãÇÁõ¥Êí≠ÁöÑÂá†‰∏™ÈóÆÈ¢òÈùûÂ∏∏ÊøÄÁÉà„ÄÇ\n\n* ChatGPT ËÉΩÂê¶‰ΩìÁé∞ÂÆÉÊâÄËÆ≠ÁªÉÁöÑÊâÄÊúâ‰∫∫Á±ªÊô∫ÊÖßÁöÑÁ≤æÂçéÔºü\n* ÂÆÉËÉΩÂê¶ÊûÑÂª∫Âá∫‰∏Ä‰ªΩÊúâÊÑè‰πâ‰∏îÊúâÁî®ÁöÑÊâãÁ®øÔºü\n* ËøòÊòØËØ¥‰∫∫Â∑•Êô∫ËÉΩÁúüÁöÑÊòØÁ§æ‰∫§Â™í‰ΩìÂΩ±ÂìçËÄÖ‰ª¨ÊêûÁöÑ‰∏Ä‰∏™Â∑®Â§ßÁöÑËê•ÈîÄÂô±Â§¥Ôºü\n\nÊàëËßâÂæóÊàëÊâæÂà∞‰∫ÜËøô‰∫õÈóÆÈ¢òÁöÑÁ≠îÊ°àÔºå‰ΩÜÊàëÂ∏åÊúõÂú®ÊúÄÁªà‰π¶Á±çÂêëÂÖ¨‰ºóÂèëÂ∏ÉÊó∂Âê¨Âà∞ËßÇ‰ºóÁöÑÊÑèËßÅÔºåÈ¢ÑËÆ°Â¶ÇÊûú‰∏ÄÂàáÊåâËÆ°ÂàíËøõË°åÔºåÂ∫îËØ•Âú®ÂçÅÊúàÂàùÂèëÂ∏É„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàÊàë‰∏çÁ´ãÂç≥Âá∫ÁâàËøôÊú¨‰π¶Ôºü\n\n‰∏∫‰∫ÜÂõûÁ≠îËøô‰∏™ÈóÆÈ¢òÔºåÊàëÂª∫ËÆÆ‰Ω†ÈòÖËØªÊàëÁöÑÊñáÁ´† [*Êàë‰ªéÂá∫ÁâàÁ¨¨‰∏ÄÊú¨‰π¶‰∏≠Â≠¶Âà∞ÁöÑ11‰∏™ÊïôËÆ≠*](https://proxy.rifx.online/https://readmedium.com/11-lessons-ive-learned-from-publishing-my-first-book-84aa3cab5deb)„ÄÇ\n\nÂú®ËøôÈáåÔºåÊàëËß£Èáä‰∫Ü‰∏∫‰ªÄ‰πàÂÜô‰ΩúÂè™ÊòØÂá∫Áâà‰π¶Á±çÁöÑÁ¨¨‰∏ÄÊ≠•Ôºå‰ª•Âèä‰∏∫‰ªÄ‰πàÊúÄÁªàÂá∫ÁâàÂè™ÊúâÂú®Êº´ÈïøÁöÑÊ≠•È™§‰πãÂêéÊâçËÉΩÂÆåÊàê„ÄÇ\n\n*ÂØπËøôÊú¨Âç≥Â∞ÜÂá∫ÁâàÁöÑ‰π¶ÊÑüÂà∞Â•ΩÂ•áÂêóÔºüÂÖ≥Ê≥®ÊàëÁöÑMediumÔºå‰ª•‰æøÂèäÊó∂‰∫ÜËß£ÂêéÁª≠ËøõÂ±ïÔºÅ* üòâ\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-nvidia-pruned-and-distilled-llama-3-1-to-create-minitron-4b-and-8b-6646d42c92c6","frontmatter":{"title":"Ëã±‰ºüËææ‚Ñ¢ÔºàNVIDIA¬ÆÔºâÂ¶Ç‰Ωï‰øÆÂâ™ÂíåÊèêÁÇº Llama 3.1 ‰ª•ÂàõÂª∫ Minitron 4B Âíå 8B","meta_title":"Ëã±‰ºüËææ‚Ñ¢ÔºàNVIDIA¬ÆÔºâÂ¶Ç‰Ωï‰øÆÂâ™ÂíåÊèêÁÇº Llama 3.1 ‰ª•ÂàõÂª∫ Minitron 4B Âíå 8B","description":"Êñ∞Ê®°ÂûãÈááÁî®‰∫ÜÊúÄÂÖàËøõÁöÑÂâ™ÊûùÂíåÊèêÁÇºÊäÄÊúØ„ÄÇ","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*31z3hqn4YezbfYAb1RZGmA.jpeg","categories":["Programming","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["pruning","distillation","Minitron","Llama","compression"],"draft":false,"slug":"blog/how-nvidia-pruned-and-distilled-llama-3-1-to-create-minitron-4b-and-8b-6646d42c92c6"},"content":"\n\n\n### Êñ∞Ê®°ÂûãÈááÁî®‰∫ÜÊúÄÂÖàËøõÁöÑÂâ™ÊûùÂíåËí∏È¶èÊäÄÊúØ„ÄÇ\n\n\n\n\n> ÊàëÊúÄËøëÂºÄÂßã‰∫Ü‰∏Ä‰ªΩ‰∏ìÊ≥®‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÊïôËÇ≤ÈÄöËÆØÔºåÁõÆÂâçÂ∑≤ÊúâË∂ÖËøá170,000ÂêçËÆ¢ÈòÖËÄÖ„ÄÇTheSequenceÊòØ‰∏Ä‰ªΩ‰∏çÂÅö‰ΩúÔºàÊÑèÂë≥ÁùÄÊ≤°ÊúâÁÇí‰ΩúÔºåÊ≤°ÊúâÊñ∞ÈóªÁ≠âÔºâÁöÑÊú∫Âô®Â≠¶‰π†ÂØºÂêëÈÄöËÆØÔºåÈòÖËØªÊó∂Èó¥‰∏∫5ÂàÜÈíü„ÄÇÁõÆÊ†áÊòØËÆ©ÊÇ®ÂèäÊó∂‰∫ÜËß£Êú∫Âô®Â≠¶‰π†È°πÁõÆ„ÄÅÁ†îÁ©∂ËÆ∫ÊñáÂíåÊ¶ÇÂøµ„ÄÇËØ∑ÈÄöËøá‰∏ãÈù¢ÁöÑÈìæÊé•ËÆ¢ÈòÖËØïËØïÔºö\n\nÊàë‰ª¨Â∏∏Â∏∏Ë¢´Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁâπÂà´ÊòØÈÇ£‰∫õÂèÇÊï∞Êï∞ÈáèÂ∫ûÂ§ßÁöÑÊ®°ÂûãÁöÑËøõÂ±ïÊâÄÈúáÊíº„ÄÇÁÑ∂ËÄåÔºåÊâßË°å70B+ÂèÇÊï∞Ê®°ÂûãËøõË°åÊé®ÁêÜÁöÑÊàêÊú¨ÂØπ‰∫éÂ§ßÂ§öÊï∞ÁªÑÁªáÊù•ËØ¥ÊòØ‰∏çÂèØÊâøÂèóÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÁúãÂà∞Â∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàSLMsÔºâÁöÑÂΩ±ÂìçÂäõÊó•ÁõäÂ¢ûÈïøÔºå‰ΩøÂæóÊâßË°åÊé®ÁêÜÂ∑•‰ΩúË¥üËΩΩÂèòÂæóÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõä„ÄÇÁÑ∂ËÄåÔºåÂæÄÂæÄÊó†Ê≥ï‰ªéÂ§¥ÂºÄÂßãÈ¢ÑËÆ≠ÁªÉSLMsÔºåÂõ†‰∏∫Âú®Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÈ¢ÑËÆ≠ÁªÉÁÆ°ÈÅìÁ≠âÊñπÈù¢Â≠òÂú®ÈáçÂ§ßÊåëÊàò„ÄÇ‰∏Ä‰∏™ÊµÅË°åÁöÑÊõø‰ª£ÊñπÊ°àÊòØ‰ªéÊõ¥Â§ßÁöÑLLMsÂºÄÂßãÔºåÂπ∂Â∞ÜÂÖ∂Ëí∏È¶è‰∏∫Êõ¥Â∞èÁöÑÊ®°Âûã„ÄÇÂâ™ÊûùÂíåËí∏È¶èÊòØËØ•È¢ÜÂüüÊúÄÊµÅË°åÁöÑ‰∏§ÁßçÊäÄÊúØ„ÄÇÊúÄËøëÔºåNVIDIAÂèëÂ∏É‰∫Ü‰∏§‰∏™Âü∫‰∫éLlama 3.1‚Äì450BËí∏È¶èÁâàÊú¨ÁöÑÊ®°ÂûãÔºåÂàÜÂà´‰∏∫[Minitron-8B](https://huggingface.co/nvidia/Minitron-8B-Base)Âíå[Minitron-4B](https://huggingface.co/nvidia/Minitron-4B-Base)„ÄÇ\n\nMinitron‰∏ìÊ≥®‰∫éÈÄöËøáÂâ™ÊûùÂíåËí∏È¶èÊù•ÂáèÂ∞ëAIÊ®°ÂûãÁöÑÂ§ßÂ∞èÔºå‰ΩøÂÖ∂Âú®‰∏çÁâ∫Áâ≤Â§™Â§öÂáÜÁ°ÆÊÄßÁöÑÊÉÖÂÜµ‰∏ãÊõ¥Âä†È´òÊïà„ÄÇÂâ™ÊûùÈÄöËøáÂàáÂâ≤Â±ÇÔºàÊ∑±Â∫¶Ââ™ÊûùÔºâÊàñÁßªÈô§Á•ûÁªèÂÖÉ„ÄÅÊ≥®ÊÑèÂäõÂ§¥ÊàñÂµåÂÖ•ÈÄöÈÅìÔºàÂÆΩÂ∫¶Ââ™ÊûùÔºâÊù•ÂáèÂ∞ëÊ®°ÂûãÁöÑÂ§ßÂ∞è„ÄÇ‰∏∫‰∫ÜÊÅ¢Â§ç‰∏Ä‰∫õ‰∏¢Â§±ÁöÑÂáÜÁ°ÆÊÄßÔºåÂâ™ÊûùÂêéÈÄöÂ∏∏ÈúÄË¶ÅËøõË°åÂÜçËÆ≠ÁªÉ„ÄÇ\n\nËí∏È¶èÊòØ‰∏ÄÁßçÁõ∏ÂÖ≥ÊäÄÊúØÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ËæÉÂ∞èÁöÑÊ®°ÂûãÔºåÁß∞‰∏∫Â≠¶ÁîüÔºå‰ªé‰∏Ä‰∏™ËæÉÂ§ß„ÄÅÂ§çÊùÇÁöÑÊ®°ÂûãÔºàÁß∞‰∏∫ÊïôÂ∏àÔºâÂ≠¶‰π†„ÄÇÂÖ∂ÁõÆÊ†áÊòØÂàõÂª∫‰∏Ä‰∏™Êõ¥Á¥ßÂáëÁöÑÊ®°ÂûãÔºå‰øùÁïôËæÉÂ§ßÊ®°ÂûãÁöÑËÆ∏Â§öÈ¢ÑÊµãËÉΩÂäõÔºåÂêåÊó∂Êõ¥Âä†Âø´ÈÄü‰∏îÂØπËµÑÊ∫êÁöÑË¶ÅÊ±ÇÊõ¥‰Ωé„ÄÇ\n\n## Ëí∏È¶èÊñπÊ≥ïÔºöÁªèÂÖ∏‰∏éSDGÂæÆË∞É\n\nMinitron Á°ÆÂÆö‰∫Ü‰∏§ÁßçÂÖ≥ÈîÆÁöÑËí∏È¶èÈ£éÊ†º„ÄÇ‰∏ÄÁßçÊñπÊ≥ïÊòØ SDG ÂæÆË∞ÉÔºåÂÖ∂‰∏≠ËæÉÂ∞èÁöÑÈ¢ÑËÆ≠ÁªÉÂ≠¶ÁîüÊ®°Âûã‰ΩøÁî®Áî±ËæÉÂ§ßÊïôÂ∏àÊ®°ÂûãÁîüÊàêÁöÑÊï∞ÊçÆËøõË°åÁ≤æÁÇº„ÄÇÂú®ËøôÁßçÊñπÊ≥ï‰∏≠ÔºåÂ≠¶ÁîüÊ®°‰ªøÊïôÂ∏àÈ¢ÑÊµãÁöÑÊúÄÁªàÊ†áËÆ∞ÔºåËøôÂú®‰∏Ä‰∫õÊµÅË°åÁöÑÊïôÁ®ãÂíå AI Âπ≥Âè∞‰∏≠ÂèØ‰ª•ÁúãÂà∞„ÄÇ\n\nÂè¶‰∏ÄÁßçÊñπÊ≥ïÔºåÁªèÂÖ∏Áü•ËØÜËí∏È¶èÔºåÂàôÊõ¥‰∏∫Â§çÊùÇ„ÄÇÂ≠¶ÁîüÊ®°Âûã‰∏ç‰ªÖ‰ªÖÂÖ≥Ê≥®È¢ÑÊµãÁöÑÊ†áËÆ∞ÔºåËÄåÊòØÂ∞ùËØïÂ§çÂà∂ÊïôÂ∏àÊ®°ÂûãÁöÑÂêÑÁßçÂÜÖÈÉ®Áä∂ÊÄÅ„ÄÇËøôÁßçÊäÄÊúØÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Êèê‰æõ‰∫ÜÊõ¥ËØ¶ÁªÜÁöÑÂèçÈ¶àÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄß„ÄÇÁÑ∂ËÄåÔºåÂÆûÊñΩËøôÁßçÊñπÊ≥ïÈúÄË¶ÅËÆ≠ÁªÉÊ°ÜÊû∂‰∏≠ÁöÑÁâπÂÆöÊîØÊåÅÔºåÂõ†‰∏∫ÂÆÉÊ∂âÂèäÂ§ÑÁêÜÊù•Ëá™ÊïôÂ∏àÂÜÖÈÉ®Áä∂ÊÄÅÁöÑÂ§ßÈáèÊï∞ÊçÆ„ÄÇ\n\nËøô‰∏§ÁßçÊñπÊ≥ïÂπ∂‰∏çÊòØ‰∫íÁõ∏ÊéíÊñ•ÁöÑÔºåËÄåÊòØÂèØ‰ª•Áõ∏ËæÖÁõ∏Êàê„ÄÇMinitron ÁöÑ‰∏ªË¶ÅÈáçÁÇπÊòØÁªèÂÖ∏Áü•ËØÜËí∏È¶èÊñπÊ≥ï„ÄÇ\n\n## Ââ™ÊûùÂíåËí∏È¶èÂ∑•‰ΩúÊµÅÁ®ã\n\n‰∏∫‰∫ÜÂàõÂª∫Êõ¥È´òÊïàÁöÑÊ®°ÂûãÔºåMinitronÂ∞ÜÂâ™Êûù‰∏éÁªèÂÖ∏ÁöÑÁü•ËØÜËí∏È¶èÁõ∏ÁªìÂêà„ÄÇ‰ªé‰∏Ä‰∏™ËæÉÂ§ßÁöÑÊ®°ÂûãÂºÄÂßãÔºå‰æãÂ¶Ç‰∏Ä‰∏™15BÂèÇÊï∞Ê®°ÂûãÔºåMinitronËØÑ‰º∞‰∏çÂêåÁªÑ‰ª∂ÁöÑÈáçË¶ÅÊÄß‚Äî‚ÄîÂ±Ç„ÄÅÁ•ûÁªèÂÖÉÁ≠â‚Äî‚ÄîÁÑ∂ÂêéÂ∞ÜÊ®°ÂûãÁº©Â∞èÂà∞Êõ¥Â∞èÁöÑÂ∞∫ÂØ∏ÔºåÊØîÂ¶Ç‰∏Ä‰∏™8BÊ®°Âûã„ÄÇËæÉÂ∞èÁöÑÊ®°ÂûãÁªèËøáËΩªÈáèÁ∫ßÁöÑÂÜçËÆ≠ÁªÉËøáÁ®ãÔºå‰ªéÂéüÂßãÁöÑËæÉÂ§ßÊ®°Âûã‰∏≠Â≠¶‰π†„ÄÇËøô‰∏™ËøáÁ®ãÂèØ‰ª•ÈáçÂ§çËøõË°åÔºå‰ª•Ëøõ‰∏ÄÊ≠•ÂáèÂ∞ëÊ®°ÂûãÁöÑÂ§ßÂ∞èÔºåÊúÄÁªàÁîüÊàêÊõ¥Â∞èÁöÑÁâàÊú¨Ôºå‰æãÂ¶Ç‰∏Ä‰∏™4BÊ®°Âûã„ÄÇ\n\nÂâ™ÊûùÂíåËí∏È¶èËøáÁ®ãÊòØËø≠‰ª£ÁöÑÔºåÊØè‰∏™ËæÉÂ∞èÁöÑÊ®°Âûã‰Ωú‰∏∫‰∏ã‰∏Ä‰∏™ÂéãÁº©ÂíåÂÜçËÆ≠ÁªÉËΩÆÊ¨°ÁöÑÂü∫Á°Ä„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-OWdvuSvUmgIsZ32.png)\n\n### Ââ™ÊûùÂΩ±Âìç\n\nÊúâÊïàÂú∞Ââ™Êûù‰∏Ä‰∏™Ê®°ÂûãÈúÄË¶ÅÁêÜËß£ÂÖ∂Âì™‰∫õÈÉ®ÂàÜÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑ„ÄÇMinitronÈááÁî®‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊøÄÊ¥ªÊï∞ÊçÆÁöÑÊñπÊ≥ïÔºåÈÄöËøá‰ΩøÁî®Â∞èÂûãÊï∞ÊçÆÈõÜÊù•‰º∞ËÆ°ÂêÑÁßçÁªÑ‰ª∂ÁöÑÈáçË¶ÅÊÄß‚Äî‚ÄîÂ±Ç„ÄÅÁ•ûÁªèÂÖÉ„ÄÅÊ≥®ÊÑèÂäõÂ§¥ÂíåÂµåÂÖ•ÈÄöÈÅì„ÄÇËØ•ÊñπÊ≥ï‰ªÖÈúÄÂâçÂêë‰º†Êí≠Ôºå‰ΩøÂÖ∂ÊØî‰æùËµñ‰∫éÂèçÂêë‰º†Êí≠ÂíåÊ¢ØÂ∫¶ËÆ°ÁÆóÁöÑÊäÄÊúØÊõ¥ÁÆÄÂçï‰∏îÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõä„ÄÇ\n\nËôΩÁÑ∂ÂèØ‰ª•Âú®Ê®°ÂûãÁöÑ‰∏çÂêåÈÉ®ÂàÜ‰πãÈó¥‰∫§ÊõøËøõË°åÂâ™ÊûùÂíåÈáçË¶ÅÊÄß‰º∞ËÆ°Ôºå‰ΩÜMinitronÂèëÁé∞ÔºåÂú®Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÔºå‰∏ÄËΩÆÈáçË¶ÅÊÄß‰º∞ËÆ°Â∞±Ë∂≥Â§ü‰∫Ü„ÄÇ\n\n## ‰ΩøÁî®ÁªèÂÖ∏Áü•ËØÜËí∏È¶èËøõË°åÂÜçËÆ≠ÁªÉ\n\nÂú®Ââ™ÊûùÂêéÔºåMinitron ‰ΩøÁî®ÁªèÂÖ∏Áü•ËØÜËí∏È¶èÂØπËæÉÂ∞èÁöÑÊ®°ÂûãËøõË°åÂÜçËÆ≠ÁªÉ„ÄÇËøôÊ∂âÂèäÈÄöËøáÊúÄÂ∞èÂåñÊ®°ÂûãÂêÑ‰∏™Èò∂ÊÆµÁöÑÊçüÂ§±Êù•ÊïôÂØºÂâ™ÊûùÂêéÁöÑÊ®°ÂûãÔºåÂåÖÊã¨ÂµåÂÖ•ËæìÂá∫„ÄÅlogits ÂíåÂèòÊç¢Âô®Êû∂ÊûÑ‰∏≠ÁöÑÁâπÂÆöÊçüÂ§±„ÄÇÂ≠¶ÁîüÊ®°ÂûãÈÄöËøáÊØîËæÉ‰∏çÂêåÂ±ÇÁöÑËæìÂá∫Ôºå‰ªéÊú™Ââ™ÊûùÁöÑÊïôÂ∏àÊ®°Âûã‰∏≠Â≠¶‰π†„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*IA_kPo30R85p_77j.png)\n\nÈÄöËøáÂ§ßÈáèÂÆûÈ™åÔºåMinitron ÊèêÁÇº‰∫ÜÂéãÁº©ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂá†Êù°ÊúÄ‰Ω≥ÂÆûË∑µÔºö\n\n***¬∑ Ê®°ÂûãÂ∞∫ÂØ∏Ôºö*** *È¶ñÂÖàËÆ≠ÁªÉÊúÄÂ§ßÁöÑÊ®°ÂûãÔºåÁÑ∂ÂêéÈÄêÊ∏êÂâ™ÊûùÂíåËí∏È¶èÔºåÂàõÂª∫Êõ¥Â∞èÁöÑÁâàÊú¨„ÄÇ*\n\n***¬∑ Ââ™ÊûùÁ≠ñÁï•Ôºö*** *‰ºòÂÖàËÄÉËôëÂÆΩÂ∫¶Ââ™ÊûùËÄåÈùûÊ∑±Â∫¶Ââ™ÊûùÔºåÂ∞§ÂÖ∂ÊòØÂØπ‰∫éÂèÇÊï∞ÈáèÈ´òËææ 15B ÁöÑÊ®°Âûã„ÄÇÂçïÊ¨°ÈáçË¶ÅÊÄß‰º∞ËÆ°ÈÄöÂ∏∏ÊòØË∂≥Â§üÁöÑ„ÄÇ*\n\n***¬∑ ÂÜçËÆ≠ÁªÉÔºö*** *‰ΩøÁî®Ëí∏È¶èÊçüÂ§±ËøõË°åÂÜçËÆ≠ÁªÉÔºåËÄå‰∏çÊòØ‰º†ÁªüËÆ≠ÁªÉ„ÄÇÂΩìÊòæËëóÂâ™ÊûùÂ±ÇÊó∂Ôºå‰ΩøÁî®Êù•Ëá™ logits„ÄÅ‰∏≠Èó¥Áä∂ÊÄÅÂíåÂµåÂÖ•ÁöÑÊçüÂ§±ÁªÑÂêà„ÄÇÂØπ‰∫éËæÉÂ∞èÁöÑÊ∑±Â∫¶ÂáèÂ∞ëÔºå‰øùÊåÅ‰ªÖ‰ΩøÁî® logits ÁöÑËí∏È¶è„ÄÇ*\n\nMinitron Â∞ÜËøô‰∫õÊäÄÊúØÂ∫îÁî®‰∫é Llama 3\\.1 Ê®°ÂûãÁ≥ªÂàóÔºåËØ•Á≥ªÂàóÂåÖÊã¨ÂèÇÊï∞‰ªé 405B Âà∞ 8B ÁöÑÊ®°Âûã„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºå‰ªñ‰ª¨‰∏ìÊ≥®‰∫éÂ∞Ü 8B Ê®°ÂûãËí∏È¶è‰∏∫Êõ¥È´òÊïàÁöÑ 4B ÁâàÊú¨„ÄÇ\n\n### ÂæÆË∞ÉÊïôÂ∏àÊ®°Âûã\n\nÂú®Ââ™Êûù‰πãÂâçÔºåMinitron ÂØπ 8B Ê®°ÂûãËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ª•ËÄÉËôë‰∏éÂéüÂßãËÆ≠ÁªÉÈõÜÁöÑÊï∞ÊçÆÂàÜÂ∏ÉÂèòÂåñ„ÄÇÊ≤°ÊúâËøô‰∏ÄÊ≠•ÔºåÊïôÂ∏àÊ®°ÂûãÂú®Ëí∏È¶èËøáÁ®ã‰∏≠ÂèØËÉΩÊó†Ê≥ï‰∏∫Â≠¶ÁîüÊèê‰æõÊúÄ‰Ω≥ÊåáÂØº„ÄÇ\n\n### Ê∑±Â∫¶Ââ™Êûù\n\n‰∏∫‰∫ÜÂ∞Ü8BÊ®°ÂûãÂáèÂ∞ëÂà∞4BÔºåMinitronÂâ™Èô§‰∫Ü16Â±ÇÔºåÈÄöËøáÈÄê‰∏ÄÁßªÈô§ÂÆÉ‰ª¨Âπ∂Ë∑üË∏™ÂØπÊÄßËÉΩÁöÑÂΩ±ÂìçÊù•ËØÑ‰º∞ÂÆÉ‰ª¨ÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñ‰ª¨ÂèëÁé∞Ê®°ÂûãÂºÄÂßãÂíåÁªìÊùüÁöÑÂ±ÇÂØπ‰øùÊåÅÂáÜÁ°ÆÊÄßÊúÄ‰∏∫ÂÖ≥ÈîÆ„ÄÇÂü∫‰∫éËøô‰∏ÄÂàÜÊûêÔºåMinitron‰∏∫ÊúÄÁªàÁöÑ4BÊ®°ÂûãÁßªÈô§‰∫ÜÁâπÂÆöÁöÑ‰∏ÄÁªÑÂ±Ç„ÄÇ\n\n### ÂÆΩÂ∫¶‰øÆÂâ™\n\nÈô§‰∫ÜÊ∑±Â∫¶‰øÆÂâ™ÔºåMinitron ËøòÂú®ÂÆΩÂ∫¶Áª¥Â∫¶‰∏äËøõË°å‰∫Ü‰øÆÂâ™ÔºåÁõÆÊ†áÊòØÊ≥®ÊÑèÂäõÂ§¥„ÄÅÂµåÂÖ•ÈÄöÈÅìÂíåÈöêËóèÂ±Ç„ÄÇ‰øÆÂâ™ÂêéÔºåÈáçÊñ∞ËÆ≠ÁªÉÂ∏ÆÂä©ÊÅ¢Â§ç‰∫ÜÂú®ÂàùÂßã‰øÆÂâ™Ê≠•È™§‰∏≠‰∏¢Â§±ÁöÑ‰∏Ä‰∫õÊÄßËÉΩ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂ∞ΩÁÆ°ÂÆΩÂ∫¶‰øÆÂâ™ÊúÄÂàùÂØºËá¥ÁöÑÊçüÂ§±È´ò‰∫éÊ∑±Â∫¶‰øÆÂâ™Ôºå‰ΩÜÈáçÊñ∞ËÆ≠ÁªÉ‰ΩøÊ®°ÂûãËÉΩÂ§üÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÊõ¥ÊúâÊïàÂú∞ÊÅ¢Â§ç„ÄÇ\n\n## ÁªìÊûú\n\nNVIDIA Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ËØÑ‰º∞‰∫Ü Minitron Ê®°ÂûãÔºåÁªìÊûú‰∏éÂü∫ÂáÜÊ®°ÂûãÁöÑÊÄßËÉΩÁõ∏ÂåπÈÖç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tVGs8v5FZHsWrpmMetDYHQ.png)\n\nMinitron 4B\\-8B Â±ïÁ§∫‰∫ÜËí∏È¶èÂíåÂâ™ÊûùÊûÑÂª∫Êõ¥Â∞è„ÄÅÊõ¥È´òÊïàÊ®°ÂûãÁöÑÊΩúÂäõ„ÄÇÂ∞ΩÁÆ°ËøôÁßçÊñπÊ≥ï‰πüÈù¢‰∏¥ÁùÄÈáçÂ§ßÊåëÊàòÔºå‰ΩÜÊàëËÆ§‰∏∫ÔºåÊÄª‰ΩìËÄåË®ÄÔºåÂÆÉ‰∏∫Ë°å‰∏öËÆæÂÆö‰∫Ü‰∏Ä‰∏™ÈáçË¶ÅÁöÑÂü∫ÂáÜ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-to-choose-ideas-for-an-llm-powered-product-to-thrive-in-a-fiercely-competitive-landscape-b24f571c04e5","frontmatter":{"title":"Â¶Ç‰ΩïÈÄâÊã© LLM È©±Âä®ÁöÑ‰∫ßÂìÅÂàõÊÑèÔºå‰ª•Âú®ÊøÄÁÉàÁöÑÁ´û‰∫âÁéØÂ¢É‰∏≠Ëì¨ÂãÉÂèëÂ±ï","meta_title":"Â¶Ç‰ΩïÈÄâÊã© LLM È©±Âä®ÁöÑ‰∫ßÂìÅÂàõÊÑèÔºå‰ª•Âú®ÊøÄÁÉàÁöÑÁ´û‰∫âÁéØÂ¢É‰∏≠Ëì¨ÂãÉÂèëÂ±ï","description":"Âà©Áî®‰∏çÊòéÊòæÁöÑ AI ËÉΩÂäõ„ÄÅÊ∑±ÂéöÁöÑÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜ‰ª•ÂèäÂè¶Â§ñ 9 ÁßçÊñπÊ≥ïËÆ©Â∞èÊñ∞‰∫ßÂìÅËé∑ÂæóÁ´û‰∫â‰ºòÂäø","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MAmCClj129C56jmkiqqhQQ.png","categories":["Generative AI","Product Development","Technology/Web"],"author":"Rifx.Online","tags":["LLM","development","experimentation","domain","expertise"],"draft":false,"slug":"blog/how-to-choose-ideas-for-an-llm-powered-product-to-thrive-in-a-fiercely-competitive-landscape-b24f571c04e5"},"content":"\n\n\nÊ¨¢ËøéÊù•Âà∞ÊàëÁ≥ªÂàóÊñáÁ´†ÁöÑÁ¨¨‰∏âÁØáÔºàÊúÄÂêé‰∏ÄÁØáÔºâÔºåÊé¢ËÆ®ÁöÑÈóÆÈ¢òÊòØÔºö‚ÄúÂì™‰∫õ GenAI ‰∫ßÂìÅÂÄºÂæóÂºÄÂèëÔºü‚Äù\n\n1. [Á¨¨‰∏ÄÁØáÊñáÁ´†](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50) ‰ªéÁî®Êà∑‰ΩìÈ™åÔºàUXÔºâÂíå‰∫ßÂìÅÈááÁî®ÁöÑËßíÂ∫¶Êé¢ËÆ®‰∫ÜËøô‰∏™ÈóÆÈ¢ò„ÄÇ\n2. Á¨¨‰∫åÁØáÊñáÁ´†ÔºåÊàëÂº∫ÁÉàÂª∫ËÆÆÂú®ÈòÖËØªÊ≠§Êñá‰πãÂâçÂÖàÈòÖËØªÔºåÂåÖÂê´‰∫ÜÂÖ≠‰∏™ÊàêÂäüÂíå‰∏çÊàêÂäüÁöÑ‰∫ßÂìÅÂàõÊÑèÁ§∫‰æãÔºå‰ª•ÂèäÊàëÁöÑ GenAI Squared ÊàòÁï•Ôºö\n\n3\\. ËøôÁ¨¨‰∏âÁØáÁªßÁª≠ÂÖ≥Ê≥®Â¶Ç‰ΩïÂú®Á´û‰∫âÁéØÂ¢É‰∏≠ÂØºËà™Ôºå‰ª•ÂèäÂ¶Ç‰Ωï‰ºòÂåñÂºÄÂèëÊàêÊú¨ËÄå‰∏çÂ§±ÂéªÁ´û‰∫â‰ºòÂäø„ÄÇÂ∞ΩÁÆ°ËøôÁØáÊñáÁ´†ÁöÑÁ§∫‰æãÊØîÂâç‰∏ÄÁØáÂ∞ëÔºå‰ΩÜËøôÈáåËÆ®ËÆ∫ÁöÑÂõ†Á¥†ÂØπ GenAI ‰∫ßÂìÅÈ¢ÜÂüüÁöÑÊàêÂäüËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nËøô‰∏âÁØáÊñáÁ´†**Ê≤°Êúâ**Ê∂µÁõñÂü∫‰∫é LLM ÁöÑÂ∫îÁî®ÂºÄÂèëÁöÑÊäÄÊúØÁªÜËäÇ„ÄÇÊ≠§Â§ñÔºåÊàëÁöÑÂàÜÊûê**‰∏ç**‰æßÈáç‰∫éÂàõÊñ∞‰∫ßÂìÅÁöÑÂ∏∏ËßÑÊàêÂäüÂõ†Á¥†Ôºå‰æãÂ¶ÇÂú®[ÈÇ£ÁØáÊñáÁ´†](https://pakodas.substack.com/p/llm-chronicles-6-how-to-build-competitive)‰∏≠ÊèèËø∞ÁöÑÂõ†Á¥†„ÄÇ\n\n> *Áõ∏ÂèçÔºå‰Ωú‰∏∫‰∏ÄÂêç‰∫ßÂìÅÁªèÁêÜÔºåÊàëÂàÜÊûê LLM ‰Ωú‰∏∫Êàë‰∫ßÂìÅÂπ≥Âè∞ÁöÑ**Áã¨ÁâπÁâπÊÄß**„ÄÇËøôÁßçÊñπÊ≥ï‰∏∫Âà©Áî®‰∏çÊòéÊòæÁöÑ AI ËÉΩÂäõÂú®‰∫ßÂìÅÂºÄÂèë‰∏≠Êèê‰æõ‰∫ÜÊñ∞È≤úÁöÑËßÅËß£„ÄÇ*\n\nÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÊé¢ËÆ®‰ª•‰∏ãÂÖ≥‰∫éËΩØ‰ª∂‰∫ßÂìÅÁöÑÈóÆÈ¢òÔºö\n\n* ‰∏∫‰ªÄ‰πàÁîüÊàêÊÄß AI ‰∫ßÂìÅÊõ¥ÂÆπÊòìÂú®‰∫ßÁîüÂõûÊä•‰πãÂâçÂèòÂæóËøáÊó∂Ôºü\n* Êàë‰ª¨Â¶Ç‰ΩïÂ∞ÜËøô‰∫õ GenAI ÊåëÊàòËΩ¨Âåñ‰∏∫Á´û‰∫â‰ºòÂäøÔºü\n* Âì™‰∫õ LLM ËÉΩÂäõÁúüÊ≠£Â¢ûÂº∫‰∫Ü‰∫ßÂìÅÁöÑÁ´û‰∫âÂäõÔºåËÄåÂì™‰∫õÂàôÊ≤°ÊúâÂ§™Â§ßÊÑè‰πâÔºü\n* ÂΩìÊñ∞ÁöÑ AI ‰∫ßÂìÅÂá†‰πéÊ≤°Êúâ‰ª£Á†ÅÊó∂ÔºåÂ¶Ç‰Ωï‰ΩøÂÖ∂ËÑ±È¢ñËÄåÂá∫ÔºåÂõ†Ê≠§‰ºòÁßÄÁöÑÁ®ãÂ∫èÂëòÂõ¢Èòü‰∏çÂÜçÊòØÂÖ≥ÈîÆÊàêÂäüÂõ†Á¥†Ôºü\n* Âú®Ëøô‰∏™Êñ∞ÁéØÂ¢É‰∏≠ÔºåAI ‰∫ßÂìÅÂºÄÂèëËÄÖÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩÊòØ‰ªÄ‰πàÔºü\n\nËøô‰∫õËßÅËß£Êó®Âú®ÊåáÂØº‰∫ßÂìÅÁªèÁêÜÂíåÂàõÂßã‰∫∫Âú®ÂÅöÂá∫ÂÜ≥Á≠ñÊó∂„ÄÇ\n\nÈÇ£‰πàÔºåÂì™‰∫õ AI Â∫îÁî®ÂèØËÉΩÊòØÂ§ö‰ΩôÁöÑÊàñÊ≥®ÂÆöË¶ÅÂ§±Ë¥• üö´ÔºåËÄåÂì™‰∫õÂàôÊúâÂæàÈ´òÁöÑÊàêÂäüÊú∫‰ºö ‚úÖÔºü\n\n*ËØ∑Ê≥®ÊÑèÔºå‰∏ãÈù¢ÁöÑÁ´†ËäÇÁºñÂè∑ÁªßÁª≠Ââç‰∏§ÁØáÊñáÁ´†ÁöÑÁ´†ËäÇÁºñÂè∑„ÄÇÊâÄÊúâ 11 ‰∏™Ë¶ÅÁÇπÂ∞ÜÂú®Êú¨ÊñáÊú´Â∞æÊÄªÁªì„ÄÇ*\n\n## 9\\. Â§ßÂûãÂ∫îÁî®Á®ãÂ∫èÁöÑÂºÄÂèëÂë®ÊúüÈïø‰∏îÂ∏ÇÂú∫ÈááÁ∫≥Êó∂Èó¥Êº´ÈïøÔºåÁ´û‰∫âÂäõ‰∏çË∂≥ üö´\n\nÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩ‰ª•Á©∫ÂâçÁöÑÈÄüÂ∫¶ÂèëÂ±ïÔºåË∂ÖËøá‰∫Ü‰ªª‰ΩïÂÖàÂâçÊäÄÊúØÁöÑÂ¢ûÈïø„ÄÇ‰∫∫Â∑•Êô∫ËÉΩËÉΩÂäõÁøªÂÄçÊâÄÈúÄÁöÑÊó∂Èó¥Â§ßÁ∫¶‰∏∫‰∏ÄÂπ¥ÔºåËøô‰∏éËëóÂêçÁöÑÊë©Â∞îÂÆöÂæã‰∏≠ÊèèËø∞ÁöÑ‰∏§Âπ¥ÂΩ¢ÊàêÂØπÊØî„ÄÇ\n\nÂõ†Ê≠§ÔºåÂü∫‰∫éÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∫ßÂìÅÊó†Ê≥ïÊâøÂèóÈïøÊó∂Èó¥ÁöÑÂºÄÂèëÂë®ÊúüÂíåÂª∂ÈïøÁöÑÂ∏ÇÂú∫ÊäïÊîæÊó∂Èó¥„ÄÇËøôÂ∏¶Êù•‰∫Ü‰∏â‰∏™‰∏ªË¶ÅÂêéÊûú„ÄÇ\n\n### 1\\. Êñ∞ÂäüËÉΩÂ∫îËØ•ÁÆÄÊ¥Å‰∏î‰∏ìÊ≥®ÔºåËÉΩÂ§üÂú®Âá†Âë®ÂÜÖËÄå‰∏çÊòØÂá†‰∏™ÊúàÂÜÖÂºÄÂèëÂÆåÊàê„ÄÇ\n\nËøôÁßçÊñπÊ≥ïÂÖÅËÆ∏Ê†πÊçÆÂàùÊ≠•Áî®Êà∑ÂèçÈ¶àËøõË°åÂø´ÈÄüË∞ÉÊï¥ÔºåÂèØËÉΩÂØºËá¥ÂäüËÉΩÁöÑÈáçÂ§ßÂèòÂåñ„ÄÇÊ≠§Â§ñÔºåÂΩìÈúÄË¶ÅËΩ¨ÂèòÊñπÂêëÊó∂ÔºàËøôËÇØÂÆö‰ºöÂèëÁîüÔºâÔºåÂú®ÊîæÂºÉËøô‰∫õÊó©ÊúüÂá†Âë®ÂºÄÂèëÁöÑÂäüËÉΩÊó∂ÔºåÊçüÂ§±ÁöÑÊàêÊú¨ËæÉÂ∞ë„ÄÇ\n\n‰æãÂ¶ÇÔºåËÄÉËôëÂü∫‰∫éLLMÁöÑMVPÁöÑÁî®Êà∑ÁïåÈù¢„ÄÇÂ¶ÇÊûúÁî®Êà∑ÂèØ‰ª•ÈÄöËøáTelegramÊú∫Âô®‰∫∫ÊàñÁ±ª‰ººÂ∑•ÂÖ∑ÂÆûÁé∞Áõ∏ÂêåÁöÑÁªìÊûúÔºåÈÇ£‰πàÂºÄÂèëËá™ÂÆö‰πâÁΩëÈ°µÁïåÈù¢ÂèØËÉΩÊòØÊ≤°ÊúâÂøÖË¶ÅÁöÑ„ÄÇ\n\n*ÁÑ∂ËÄåÔºåÂ¶ÇÊûúÊàë‰ª¨[Â∞ÜLLMËûçÂÖ•Áé∞ÊúâËß£ÂÜ≥ÊñπÊ°àÊàñ‰∏éÂÖ∂ÈõÜÊàê](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#5d06)ÔºåÈÇ£‰πà‚ÄúÊï¥‰Ωì‰∫ßÂìÅ‚ÄùÂèØ‰ª•ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂäüËÉΩ„ÄÇÂÖ≥ÈîÆÂú®‰∫é‰ªÖÊúÄÂ∞èÂåñ**Êñ∞**ÂäüËÉΩÁöÑËåÉÂõ¥„ÄÇ*\n\n### 2\\. ÂØπ‰∫éË∂ÖÂø´ÈÄüÂÆûÈ™åÂíåÂÆ¢Êà∑ÂèçÈ¶àÂæ™ÁéØÁöÑÈúÄÊ±ÇËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nGenAI ‰∫ßÂìÅÁöÑÊûÑÂª∫ÈÄüÂ∫¶Êõ¥Âø´Ôºå‰ΩÜÂπ∂‰∏çÊÄªÊòØËÉΩÂ§üÂêåÊ†∑Âø´ÈÄüÂú∞Ëé∑ÂæóÂèçÈ¶à„ÄÇÂõ†Ê≠§Ôºå‰∏Ä‰∫õ GenAI ‰∫ßÂìÅÊ¶ÇÂøµÂèØËÉΩË¢´ËØÅÊòéÈ£éÈô©ËøáÈ´ò„ÄÇ\n\nÂø´ÈÄüÂÆûÈ™åÂΩìÁÑ∂ÂØπ‰ªª‰ΩïÊñ∞‰∫ßÂìÅÂèëÂ∏ÉÈÉΩÊòØÊúâÁõäÁöÑÔºåÂõ†‰∏∫Êó†Ê≥ïÊèêÂâçÂáÜÁ°ÆÈ¢ÑÊµãÂ∏ÇÂú∫ÂèçÂ∫î„ÄÇÊú¨Ë¥®‰∏äÔºåÂ∏ÇÂú∫Ëøê‰ΩúÂ¶ÇÂêå‰∏Ä‰∏™‚ÄúÈªëÁÆ±‚ÄùÔºåÂÖ∂Ë°å‰∏∫Âè™ËÉΩÈÄöËøáÂÆûÈôÖÊìç‰ΩúÁöÑÂÆûÈ™åÊù•ÁúüÊ≠£ÁêÜËß£„ÄÇ\n\n> *Âú® GenAI ‰∫ßÂìÅÈ¢ÜÂüüÔºåÊàë‰ª¨ÈÅáÂà∞‰∫ÜÈ¢ùÂ§ñÁöÑÂ§çÊùÇÊÄß‚Äî‚Äî**Á¨¨‰∫å‰∏™‚ÄúÈªëÁÆ±‚Äù**Ê∫ê‰∫é LLM ËæìÂá∫ÁöÑÂõ∫Êúâ‰∏çÂèØÈ¢ÑÊµãÊÄß„ÄÇ**ËøôÁßçÂèåÈáç‰∏çÁ°ÆÂÆöÊÄßÂä†Â§ß‰∫ÜÈ¢ëÁπÅÂíåÂø´ÈÄüÂÆûÈ™åÁöÑÈáçË¶ÅÊÄß„ÄÇ**Âø´ÈÄüËø≠‰ª£ÂíåÊî∂ÈõÜÊ¥ûÂØüÁöÑËÉΩÂäõ‰∏ç‰ªÖÊòØÊúâÂà©ÁöÑÔºåËÄåÊòØÊàêÂäüÁöÑÂøÖË¶ÅÊù°‰ª∂„ÄÇ*\n\n### 3\\. Ê≤°ÊúâÊó∂Èó¥Âéª‚ÄúÊïôËÇ≤‚Äù‰∫ßÂìÅÁöÑÁõÆÊ†áÂèó‰ºóÔºå‰ΩøÂÖ∂ÈÄÇÂ∫îÂÆåÂÖ®Êñ∞ÁöÑÂ∑•‰ΩúÊàñ‰ºëÈó≤Ê®°Âºè„ÄÇ\n\nÂè™ÊúâÊúÄÂ§ßÁöÑË°å‰∏öÈ¢ÜÂØºËÄÖÔºåÁâπÂà´ÊòØÈÇ£‰∫õÊã•ÊúâËá™Â∑±ÁîüÊÄÅÁ≥ªÁªüÁöÑÂÖ¨Âè∏ÔºåÂ¶Ç Google„ÄÅApple Êàñ MicrosoftÔºåÊâçËÉΩÁõ∏ÂØπÂø´ÈÄüÂú∞ËÆ© **Â§ßÂ§öÊï∞** ÊΩúÂú®Áî®Êà∑‰π†ÊÉØ‰∫éÊñ∞Ê¶ÇÂøµ„ÄÇ\n\n‚úÖ Âõ†Ê≠§ÔºåÂÖ∂‰ªñÂÖ¨Âè∏ÂøÖÈ°ª‰∏é **Áî®Êà∑ÁÜüÊÇâÁöÑÁé∞ÊúâÁõÆÊ†áËææÊàêÊ®°ÂºèÊàñË°å‰∏öÈ¢ÜÂØºËÄÖÂª∫Á´ãÁöÑË∂ãÂäø** ÂØπÈΩê„ÄÇ\n\n* ËÄÉËôë‰∏Ä‰∏™Â∑≤Âª∫Á´ãÁöÑÂ¢ûÂä†Êî∂ÂÖ•ÁöÑÁõÆÊ†áÊ®°ÂºèÔºö‰∫∫‰ª¨Ë¥≠‰π∞ÂüπËÆ≠ËØæÁ®ã‰ª•Ëé∑ÂæóÊñ∞ÊäÄËÉΩ„ÄÇËøô‰∏™È¢ÜÂüü‰∏≠ÁöÑ‰∏Ä‰∏™‰ºòÁßÄ AI È©±Âä®Ëß£ÂÜ≥ÊñπÊ°àÊ∂âÂèä‰ΩøÁî® AI ÂàõÂª∫Ëøô‰∫õËØæÁ®ãÔºåÊòæËëóÈôç‰ΩéÁîü‰∫ßÊàêÊú¨Ôºå‰ªéËÄåÂ¢ûÂº∫Á´û‰∫âÂäõ„ÄÇ**ÊúÄÁªàÁî®Êà∑‰∏çÈúÄË¶Å** ÈááÂèñ‰ªª‰ΩïÊñ∞Ë°å‰∏∫Êù•ÊèêÂçá‰ªñ‰ª¨ÁöÑÊî∂ÂÖ•„ÄÇ\n* ÊúÄËøëÂú® Apple ËÆæÂ§á‰∏≠Âá∫Áé∞ÁöÑ **Ë∂ãÂäø** ‰ΩìÁé∞‰∫Ü‰∏ÄÈ°πÂàõÊñ∞ÔºåApple Âπ≥Âè∞Áî®Êà∑Êó†Áñë‰ºöÈááÁî®Ôºö‰ΩøÁî®Êú¨Âú∞ LLM ËøõË°åÂÖ∏Âûã‰ªªÂä°‰ª•‰øùÊä§Áî®Êà∑Êï∞ÊçÆÈöêÁßÅ„ÄÇËôΩÁÑ∂Â∫îÁî®Á®ãÂ∫èÂèØËÉΩÂà©Áî®Ëøô‰∏ÄË∂ãÂäøÁöÑÂÖ∑‰ΩìÊñπÂºèÂ∞ö‰∏çÊ∏ÖÊ•öÔºå‰ΩÜÊàëÁõ∏‰ø° Apple ‰ºö‰∏∫ÂºÄÂèëËÄÖÊèê‰æõ‰æøÊç∑ÁöÑ LLM Âü∫Á°ÄËÆæÊñΩËÆøÈóÆÔºåÊàë‰ª¨Âè™ÈúÄÂÜçÁ≠â‰∏ÄÊÆµÊó∂Èó¥„ÄÇ\n\n## 10\\. Âà©Áî®‰∏çÂ§™ÊòéÊòæÁöÑLLMËÉΩÂäõÊèêÂçáÁ´û‰∫âÂäõÂíåËµÑÊ∫êÊïàÁéá ‚úÖ\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰Ω†Â§Ñ‰∫éËµ∑ÁÇπÔºåÊâã‰∏≠Âè™Êúâ‰∏Ä‰∏™‰∫ßÂìÅÊ¶ÇÂøµ„ÄÇ‰∏∫‰∫ÜÂä†Âø´ÂêëÈ´òÈúÄÊ±Ç‰∫ßÂìÅÁöÑÊóÖÁ®ãÔºå**‰Ω†Â∫îËØ•‰ºòÂÖàÊé¢Á¥¢Âì™‰∫õÊñπÈù¢ÁöÑÊÉ≥Ê≥ïÔºü**\n\nÊòæÁÑ∂Ôºå‰Ω†ÈúÄË¶ÅÂú®‰Ω†ÁöÑÊ¶ÇÂøµ‰∏≠ËØÜÂà´‰∏ÄÂ∞èÁªÑÁâπÂÆöÁöÑÁ´ØÂà∞Á´ØÂ∑•‰ΩúÂú∫ÊôØ„ÄÇËøô‰∏é[ÊµÅË°åÁöÑ‰∫ßÂìÅÂèëÂ∏ÉÁ≠ñÁï•](https://www.geeksforgeeks.org/a-complete-guide-to-a-successful-product-launch/#is-there-a-product-launch-formula)‰∏ÄËá¥Ôºö‚Äú‰ªéMVPÂºÄÂßã‚ÄùÔºàÂÆûÊñΩ‰∏Ä‰∏™ÊàñÂá†‰∏™Âú∫ÊôØÔºâÂíå‚Äú‰∏∫**Êï¥‰∏™**Áî®Êà∑‰ΩìÈ™åÊûÑÂª∫‚ÄùÔºàÁ°Æ‰øùÂú∫ÊôØÊòØÁ´ØÂà∞Á´ØÁöÑÔºâ„ÄÇÈóÆÈ¢òÊòØÔºö‰Ω†Â∫îËØ•ÈÄâÊã©Âì™‰∫õÂú∫ÊôØÔºü\n\n> *Âú®ÊàëÁúãÊù•ÔºåËøô‰∫õMVPÂú∫ÊôØÂ∫îËØ•‰∏éLLMËÉΩÂäõ**Á¥ßÂØÜÂØπÈΩê**„ÄÇËøôÁßçÊñπÊ≥ïËäÇÁúÅ‰∫Ü‰∫ßÂìÅ‰∫§‰ªòÁöÑËµÑÊ∫êÔºåÂõ†‰∏∫ÊòæËëóÁöÑ‰∫ßÂìÅ‰ª∑ÂÄºÊù•Ëá™‰∫éLLMÊú¨Ë∫´ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØ‰Ω†ÂºÄÂèëËÄÖÁöÑÂä™Âäõ„ÄÇÂ¶ÇÊûú‰∏çËøôÊ†∑ÂÅöÔºåÂèØËÉΩ‰ºöÈù¢‰∏¥[Á¨¨7ËäÇ‚ÄúËøáÂ∫¶ÈôêÂà∂LLM‚Äù](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e1ef)‰∏≠Ê¶ÇËø∞ÁöÑÊåëÊàò„ÄÇ*\n\nüö´ LLMÊâÄÂÆ£Áß∞ÁöÑË∂ÖËÉΩÂäõÈÄöÂ∏∏ÂåÖÊã¨ÂÖ∂**ÂõûÁ≠î‰ªª‰ΩïÈóÆÈ¢òÁöÑËÉΩÂäõ**„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÂõûÁ≠îÁöÑÂáÜÁ°ÆÊÄßÂíåË¥®ÈáèÊú¨Ë¥®‰∏äÊòØ‰∏çÂèØÈ¢ÑÊµãÁöÑÔºåËøô‰ºöÂØºËá¥ÈóÆÈ¢òÔºàÊúâÂÖ≥ËØÑ‰º∞Â§çÊùÇÊÄßÂíåË¥®ÈáèÁõëÊéßÁöÑÊõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅ[Á¨¨1ËäÇ](https://ai.gopubby.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#f973)Ôºâ„ÄÇÊ≠§Â§ñÔºåÂõ¥ÁªïÈóÆÁ≠î‰∏≠ÂøÉÁöÑ‰∫ßÂìÅÊó†Ê≥ïÊúâÊïàÂú∞‰∏éÂ∏ÇÂú∫È¢ÜÂØºËÄÖÂ¶ÇChatGPTÁ´û‰∫âÔºàÂ¶Ç[Á¨¨6ËäÇ](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e305)‰∏≠ËÆ®ËÆ∫ÁöÑÔºâ„ÄÇËÄÉËôëÂà∞Ëøô‰∏§‰∏™Âõ†Á¥†ÔºåÊàëÂª∫ËÆÆ‰∏çË¶ÅÂü∫‰∫éËøôÁßç‚ÄúË∂ÖËÉΩÂäõ‚ÄùÊù•ÊûÑÂª∫MVP„ÄÇ\n\n**LLMÁöÑ‚ÄúÊÉ≥Ë±°ÁîüÊàê‚ÄùËÉΩÂäõ**Êèê‰æõ‰∫Ü‰∏Ä‰∏™Áõ∏ÂØπÊõ¥ÊúâÂâçÊôØÁöÑÊñπÂêë„ÄÇËøôÁßçLLMÁöÑÂàõÈÄ†ÂäõÂèØ‰ª•ÊøÄÂèëÊàë‰ª¨ÁöÑÊñ∞ÊÉ≥Ê≥ïÔºåÊàñÂ∏ÆÂä©ÂàõÂª∫ÂàõÊÑèÂÜÖÂÆπÔºåÂ¶ÇËØóÊ≠å„ÄÅËßÜÈ¢ëËÑöÊú¨ÊàñÂÜÖÂÆπËÆ°Âàí„ÄÇÁÑ∂ËÄåÔºåÊ†πÊçÆÊàëÁöÑÁªèÈ™åÔºåÂçïÈù†LLMÁöÑÂàõÈÄ†Âäõ‰∏çË∂≥‰ª•ÊûÑÂª∫Á´ØÂà∞Á´ØÁöÑ‰∫ßÂìÅÂú∫ÊôØ„ÄÇ‰∏ÄÊó¶Áî®Êà∑‰ªéLLMËé∑Âæó‚ÄúÂàõÊÑèÊùêÊñô‚ÄùÔºå‰ªçÁÑ∂ÈúÄË¶ÅÂ§ßÈáèÁöÑÂä™ÂäõÂ∞ÜÂÖ∂ËΩ¨Âåñ‰∏∫ÊâÄÈúÄÁöÑÁªìÊûú„ÄÇ\n\nÊ≠§Â§ñÔºåÂàõÈÄ†Âäõ‰ª£Ë°®‰∫ÜGenAIÊúÄÂÆπÊòìÁêÜËß£ÂíåÂπøÊ≥õËÆ§ÂèØÁöÑËÉΩÂäõ‰πã‰∏Ä„ÄÇÂá†‰πé‰ªª‰ΩïÂ∞ùËØïËøáChatGPTÊàñMidjourneyÁöÑ‰∫∫ÈÉΩÂØπÂÖ∂ÊÑüÂà∞ÁÜüÊÇâÔºåÂõ†Ê≠§‰ªª‰Ωï‰∫∫ÈÉΩÂèØËÉΩÊàê‰∏∫‰Ω†ÁöÑÁ´û‰∫âÂØπÊâã„ÄÇ\n\n\n\n‚úÖ ËÄÉËôëÂà∞ÊøÄÁÉàÁöÑÁ´û‰∫âÔºåÊàëÂª∫ËÆÆ‰∏ìÊ≥®‰∫é**LLMÁöÑ‰∏çÂ§™ÊòéÊòæÁöÑËÉΩÂäõÔºå**‰æãÂ¶ÇÔºö\n\n### 1\\. ÁøªËΩ¨‰∫§‰∫í\n\nËøôÁßç‰∫∫Á±ª‰∏éAIÁöÑ‰∫§‰∫íÊ®°ÂºèÂà©Áî®‰∫ÜLLMÁöÑËÉΩÂäõÔºå**ÊèêÂá∫Â•ΩÁöÑÈóÆÈ¢ò**ÊàñÂëàÁé∞ÈÄâÊã©Áî®Êà∑ÈáçË¶ÅÈ°πÁõÆÁöÑÂàóË°®Ôºå‰ªéËÄåÂáèÂ∞ëÁî®Êà∑ÁöÑËÆ§Áü•Ë¥üÊãÖ„ÄÇÁøªËΩ¨‰∫§‰∫í‰∏ç‰ªÖÊúâÂä©‰∫éÂú®Êüê‰∫õÈ¢ÜÂüüÔºàÂ¶ÇÊïôÂ≠¶„ÄÅÊåáÂØºÊàñËæÖÂØºÔºâÊõø‰ª£ÈÉ®ÂàÜ‰∫∫Á±ªÂ∑•‰ΩúÔºåËøòÂ∏ÆÂä©Âú®‰ªª‰ΩïÈ¢ÜÂüüÂª∫Á´ãËß£ÂÜ≥ÈóÆÈ¢òÁöÑÈÄÇÂΩì**ËÉåÊôØ**ÔºàÊõ¥Â§öÁªÜËäÇËØ∑ËßÅ[ËøôÈáå](https://readmedium.com/4-human-ai-interaction-patterns-for-experienced-chatgpt-users-9e49d4234013#c348)Ôºâ„ÄÇ\n\n### 2\\. ‰∏ä‰∏ãÊñáÁêÜËß£\n\nLLM ÊìÖÈïøÊääÊè°Áî®Êà∑ËØ∑Ê±ÇÂèäÂÖ∂ÂÅèÂ•ΩÁöÑ‰∏ä‰∏ãÊñáÔºåÁÑ∂ÂêéÂú®ËØ•‰∏ä‰∏ãÊñá‰∏≠Â§ÑÁêÜ‰ªªÂä°„ÄÇËøôÁßçÊñπÊ≥ïÁ°Æ‰øùËß£ÂÜ≥ÊñπÊ°à‰∏éÂç≥‰ΩøÊòØ **Êú™Ë°®Ëø∞** ÁöÑÁî®Êà∑ÈúÄÊ±Ç‰øùÊåÅ‰∏ÄËá¥„ÄÇ\n\na. Ëøô‰∏ÄÁâπÊÄßÂú®ÂºÄÂèëËÄÖÁöÑ AI Âä©Êâã‰∏≠ÂæóÂà∞‰∫ÜÊúÄÁ≤æÁªÜÁöÑ‰ΩìÁé∞Ôºå‰æãÂ¶Ç Github Copilot Âíå Cursor„ÄÇÂú®Ëøô‰∫õÂ∑•ÂÖ∑‰∏≠ÔºåLLM ÁöÑ‰∏ä‰∏ãÊñáÊ∂µÁõñÊï¥‰∏™È°πÁõÆ‰ª£Á†ÅÂ∫ìÔºåËÄåÁî®Êà∑ÔºàÂºÄÂèëËÄÖÔºâÈÄöÂ∏∏Âè™‰∫ÜËß£ÁâπÂÆöÈÉ®ÂàÜ„ÄÇÂõ†Ê≠§ÔºåÂºÄÂèëËÄÖÂú®‰∏∫ AI Âà∂ÂÆö‰ªªÂä°Êó∂ÔºåÂæÄÂæÄÊó†Ê≥ïËÄÉËôëÊõ¥ÂπøÊ≥õÁöÑ‰∏ä‰∏ãÊñá„ÄÇ\n\nb. ÁÑ∂ËÄåÔºåÂú®‰∏ä‰∏ãÊñá‰∏≠Âà©Áî® **ÊòéÁ°ÆË°®Ëø∞** ÁöÑÁî®Êà∑ÈúÄÊ±ÇÁöÑÊ¥ûÂØü‰πüÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑÁâπÊÄß„ÄÇ‰æãÂ¶ÇÔºåËØ≠Ë®ÄÂ≠¶‰π†Âπ≥Âè∞ [Memrise](https://www.memrise.com/) ÊúâÊïàÂú∞ÂÆûÁé∞‰∫ÜËøô‰∏ÄÁâπÊÄß„ÄÇ\n\n### 3\\. Â∞ëÈáèÂ≠¶‰π†\n\nÊ®°Âûã‰ªé**Â∞ëÈáè**Á§∫‰æã‰∏≠‚ÄúÂ≠¶‰π†‚ÄùÁöÑËÉΩÂäõ‰ΩøÂÖ∂ËÉΩÂ§üËΩªÊùæÈÄÇÂ∫îÊñ∞‰ªªÂä°ÂíåÊñ∞ÁéØÂ¢É„ÄÇËøôÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÂü∫‰∫éLLMÁöÑËÅäÂ§©Êú∫Âô®‰∫∫Áé∞Âú®Ë¢´ÂπøÊ≥õÂ∫îÁî®‰∫éÈîÄÂîÆÂíåÂÆ¢Êà∑ÊîØÊåÅÔºå‰∏éÂÆÉ‰ª¨ÁöÑÂØπËØùÂæàÈöæ‰∏é‰∫∫Á±ª‰∏ìÂÆ∂ÁöÑÂØπËØùÂå∫ÂàÜÂºÄÊù•„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰º†ÁªüÁöÑAIËÅäÂ§©Êú∫Âô®‰∫∫‰ªÖÂú®Â§ßÂûã‰ºÅ‰∏ö‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºåÈöæ‰ª•ÈÄÇÂ∫î‰∏çÊñ≠ÂèòÂåñÁöÑÁü•ËØÜÂ∫ì„ÄÇ\n\n### 4\\. Â§ßËßÑÊ®°‰ø°ÊÅØÂ§ÑÁêÜ\n\nLLM ÊìÖÈïøÂàÜÊûê **Â§ßÈáè** ÁöÑÊñáÊú¨ÂíåË°®Ê†ºÊï∞ÊçÆÔºåÂ∞ÜÂÖ∂ÊèêÁÇºÊàê **ÁÆÄÊòé** ÁöÑÂΩ¢Âºè„ÄÇÂÆÉËÉΩÂ§üÊ¶ÇÊã¨„ÄÅÊèêÂèñ‰∏éÂΩìÂâç‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÁÇπ„ÄÅËØÜÂà´Ê®°ÂºèÔºåÂπ∂ÊâßË°åÂêÑÁßçÂÖ∂‰ªñÂàÜÊûêÂäüËÉΩ„ÄÇ\n\na. ‰ª• [Scite](https://scite.ai/) ‰∏∫‰æãÔºåËøôÊòØ‰∏ÄÊ¨æÁî®‰∫éÁßëÂ≠¶Á†îÁ©∂ÁöÑ AI Â∑•ÂÖ∑„ÄÇÂÆÉ‰∏ç‰ªÖ‰ªÖÊòØÂú®ÂÖ∂ÂçÅ‰∫øÊù°ÂºïÁî®Êï∞ÊçÆÂ∫ì‰∏≠ÂÆö‰Ωç‰∏éÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑÊù•Ê∫ê„ÄÇScite ÂàÜÊûêÊñáÁ´†Ë¢´ÂºïÁî®ÁöÑ‰∏ä‰∏ãÊñáÔºåÊè≠Á§∫ÂºïÁî®ËÆ∫ÊñáÊòØÊîØÊåÅ„ÄÅÂèçÈ©≥ËøòÊòØ‰ªÖ‰ªÖÊèêÂà∞Êó©ÊúüÂ∑•‰ΩúÁöÑ„ÄÇ\n\nb. Âú®Êï∞ÂÄºÊï∞ÊçÆÂ§ÑÁêÜÊñπÈù¢ÔºåLLM ÁöÑËæìÂá∫‰∏çÈúÄË¶Å‚ÄúÁøªËØëÊàê‰∫∫Á±ªËØ≠Ë®Ä‚Äù„ÄÇËøô‰∏∫ GenAI ÂàÜÊûêÂ∑•ÂÖ∑Êèê‰æõ‰∫ÜÁõ∏ËæÉ‰∫é‰º†ÁªüÁªüËÆ°Êï∞ÊçÆÂ§ÑÁêÜÂ∑•ÂÖ∑ÁöÑÊòéÊòæ‰ºòÂäø„ÄÇ\n\nËÆ∏Â§öÊΩúÂú®Á´û‰∫âËÄÖÂèØËÉΩ‰∫ÜËß£ËøôÂõõÁßç LLM ËÉΩÂäõ‰∏≠ÁöÑ‰∏Ä‰∫õ„ÄÇÁÑ∂ËÄåÔºåÊàëÁõ∏‰ø°ÂØπËøô‰∫õËÉΩÂäõÁöÑÊ∑±ÂÖ•ÊÄùËÄÉÂèØËÉΩ‰ºöÂØºËá¥ÁúüÊ≠£ÂàõÊñ∞‰∫ßÂìÅÁöÑÂºÄÂèë„ÄÇËøôÁßçÊñπÊ≥ïÂèØ‰ª•Êèê‰æõÁõ∏ËæÉ‰∫é‰ªÖÂà©Áî® LLM Êõ¥ÊòéÊòæËÉΩÂäõÔºàÂ¶Ç‚ÄúÂàõÈÄ†Âäõ‚ÄùÂíå‚ÄúÂõûÁ≠î‰ªª‰ΩïÈóÆÈ¢ò‚ÄùÔºâÁöÑ‰∫ßÂìÅÁöÑÁ´û‰∫â‰ºòÂäø„ÄÇ\n\n## 11\\. Âü∫‰∫éÊ∑±ÂéöÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁöÑÂ∞èÂûãAI‰∫ßÂìÅÂÖ∑ÊúâÁ´û‰∫âÂäõ ‚úÖ\n\nLLMÂá†‰πé‰Ωú‰∏∫‰∏Ä‰∏™ÂÆåÊàêÁöÑ‰∫ßÂìÅÔºåËÉΩÂ§ü‚ÄúËá™‰∏ª‚Äù‰∏éÁî®Êà∑‰∫íÂä®„ÄÇÂõ†Ê≠§ÔºåÂü∫‰∫éLLMÁöÑÂ∫îÁî®Á®ãÂ∫èÂú®‰ª£Á†ÅÂü∫Á°Ä‰∏äÊòæËëóÂ∞è‰∫é‰º†ÁªüÁöÑÈùûLLMÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\nÊ≠§Â§ñÔºå‰ªª‰ΩïÂÖ∑Â§á‰∏ÄÂÆöÊäÄÊúØÊäÄËÉΩÁöÑ‰∏™‰∫∫ÈÉΩÂèØ‰ª•Âú®Âá†Â§©ÂÜÖÂ≠¶‰π†ÂºÄÂèëÂäüËÉΩ‰∏∞ÂØåÁöÑÂü∫‰∫éLLMÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\nËøô‰∏§‰∏™Âõ†Á¥†‰∏éÁ¨¨9ËäÇ‰∏≠Ê¶ÇËø∞ÁöÑÂø´ÈÄüÂèëÂ±ïÂíåÂÆûÈ™åË¶ÅÊ±ÇÂÆåÁæéÂ•ëÂêà„ÄÇ\n\n> *ÁÑ∂ËÄåÔºå‰ªéÁ´û‰∫âÁöÑËßíÂ∫¶Êù•ÁúãÔºå‰∫ßÂìÅÁöÑÂ∞èËßÑÊ®°ÂíåGenAIÂºÄÂèëÁöÑ‰ΩéÂáÜÂÖ•Èó®ÊßõÊòØ**ÊòæËëóÁöÑÁº∫Èô∑**„ÄÇ*\n\nÂØπ‰∫éÂÖ∏ÂûãÁöÑÂ§ßÂûã‰ª£Á†ÅÂü∫Á°ÄËΩØ‰ª∂‰∫ßÂìÅÔºåÂçìË∂äÁöÑÂõ¢ÈòüÂíåÊïèÊç∑ÂºÄÂèëÊµÅÁ®ãÊòØÊàêÂäüÁöÑÂÖ≥ÈîÆË¶ÅÁ¥†„ÄÇ[Bill GrossÁöÑÁ†îÁ©∂](https://youtu.be/bNpx7gpSqbY?t=216)Â∞ÜÂÖ∂Âàó‰∏∫‰∫î‰∏™Âõ†Á¥†‰∏≠Á¨¨‰∫åÈáçË¶ÅÁöÑÂõ†Á¥†ÔºåÁîöËá≥Ë∂ÖËøá‰∫Ü‰∫ßÂìÅÂàõÊÑèÁöÑÂèØË°åÊÄßÔºåÂêéËÄÖÊéíÂú®Á¨¨‰∏â‰Ωç„ÄÇ\n\nÁÑ∂ËÄåÔºåÂΩì‰∏Ä‰∏™‰∫ßÂìÅÁöÑËΩØ‰ª∂ÂºÄÂèëËåÉÂõ¥ÂæàÂ∞èÔºåÁîöËá≥ÁªèÈ™å‰∏çË∂≥ÁöÑÁ®ãÂ∫èÂëò‰πüËÉΩÂºÄÂèëÊó∂Ôºå‰∫ßÂìÅÂ¶Ç‰ΩïËé∑ÂæóÁ´û‰∫â‰ºòÂäøÔºü\n\nÈöèÁùÄÊÉ≥Ê≥ïÂíåÂïÜ‰∏öÊ®°ÂûãÂÆπÊòìË¢´Á´û‰∫âÂØπÊâãÂ§çÂà∂‚Ä¶‚Ä¶ÊàêÂäüÊòØÂê¶ÁúüÁöÑ‰ªÖ‰ªÖ‰æùËµñ‰∫éÂú®‰Ω†ÁöÑÁªÜÂàÜÂ∏ÇÂú∫‰∏≠È¶ñÂèëÁöÑÁü≠Êúü‰ºòÂäøÔºü\n\n1. Á¨¨10ËäÇÂØπÊ≠§ÈóÆÈ¢òÊèê‰æõ‰∫Ü‰∏Ä‰∏™Á≠îÊ°àÔºö‰∫ßÂìÅÂ∫îÂà©Áî®LLM‰∏çÂ§™‰∏∫‰∫∫ÊâÄÁü•ÁöÑËÉΩÂäõ„ÄÇËôΩÁÑ∂ËøôÂπ∂‰∏çËÉΩ‰øùËØÅÊàêÂäüÔºå‰ΩÜÂÆÉÂ¢ûÂä†‰∫ÜË∂ÖË∂äÂèØËÉΩ‰∏çÂÆåÂÖ®ÁêÜËß£LLM‰∏çÊòéÊòæËÉΩÂäõÁöÑÁ´û‰∫âÂØπÊâãÁöÑÊú∫‰ºö„ÄÇ\n2. [Êàë‰πãÂâçÁöÑÊñáÁ´†](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#9f01)Ê¶ÇËø∞‰∫ÜÂè¶‰∏Ä‰∏™Ëß£ÂÜ≥ÊñπÊ°àÔºö‰ª•ÂàõÊñ∞ÊñπÂºèÂú®‰∫ßÂìÅ‰∏≠ÂÆûÁé∞LLMÔºå‰æãÂ¶ÇLLM2Á≠ñÁï•„ÄÇËøôÁßç‰∏ì‰∏öÁü•ËØÜÊõ¥ÈöæË¢´Á´û‰∫âÂØπÊâãÂ§çÂà∂ÔºåÂõ†‰∏∫ÂÆÉÊõ¥Ê∑±Â±ÇÂú∞ÈöêËóèÂú®‰∫ßÂìÅÂÜÖÈÉ®„ÄÇ\n3. ÊàëÂØπËøô‰∏ÄÊåëÊàòÁöÑËß£ÂÜ≥ÊñπÊ°àÁöÑÁ¨¨‰∏â‰∏™ÁªÑÊàêÈÉ®ÂàÜÊòØÂØπÈ´òÊ∞¥Âπ≥**È¢ÜÂüü‰∏ì‰∏öÁü•ËØÜ**ÁöÑÂøÖË¶ÅÊÄß„ÄÇ\n\nÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÂú®‰∫ßÂìÅÊàêÂäü‰∏≠ÁöÑÈáçË¶ÅÊÄßÂ§öÂπ¥Êù•‰∏ÄÁõ¥ÊòØËÆ®ËÆ∫ÁöÑËØùÈ¢ò„ÄÇËôΩÁÑ∂ÊàëÊâæ‰∏çÂà∞ÂÆöÈáèÁ†îÁ©∂Â∞ÜÂàùÂàõÂÖ¨Âè∏ÁöÑÊàêÂäü‰∏éÂàõÂßã‰∫∫ÁöÑÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁõ∏ÂÖ≥ËÅîÔºå‰ΩÜÊàëÂª∫ËÆÆÊé¢Á¥¢‰∏Ä‰∫õÊîØÊåÅËøôÁßçÊòæËëóÁõ∏ÂÖ≥ÊÄßÁöÑ[‰æãÂ≠ê](https://jamesspurway.com/2024/04/29/founder-domain-expertise-insider-tip-how-startups-benefit/)Âíå[ÁêÜÁî±](https://www.nvp.com/blog/domain-expertise-founder-greatest-asset/)„ÄÇ[Áé∞ÊúâÁ†îÁ©∂](https://www.ensemble.vc/research/what-does-the-data-say-about-successful-startup-founders)‰∏ìÊ≥®‰∫éÁã¨ËßíÂÖΩÔºåË°®ÊòéÂàõÂßã‰∫∫ÁöÑÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÂæàÈáçË¶ÅÔºå‰ΩÜ‰∏çÊòØ‰∏ªË¶ÅÊàêÂäüÂõ†Á¥†„ÄÇ\n\nÁÑ∂ËÄåÔºåÊàëËÆ§‰∏∫Âú®ÁîüÊàêAIÈ¢ÜÂüüÔºåËøô‰∏ÄÂõ†Á¥†ÁöÑÈáçË¶ÅÊÄßÂ§ßÂ§ßÂ¢ûÂº∫„ÄÇÂØπÊ≠§ËßÇÁÇπÁöÑÊé®ÁêÜÂú®‰ª•‰∏ãÂ∏ñÂ≠ê‰∏≠ÂæóÂà∞‰∫ÜÂæàÂ•ΩÁöÑÈòêËø∞Ôºö\n\n> *ÂØπ‰∫éÂü∫‰∫éLLMÁöÑ‰∫ßÂìÅÔºåÊäÄÊúØ‰∏ì‰∏öÁü•ËØÜÁöÑ‰ΩúÁî®ÊòæËëóÈôç‰ΩéÔºàÁî±‰∫éËΩØ‰ª∂‰∫§‰ªòÊõ¥ÂÆπÊòìÔºâÔºåËøô‰∏é‰º†ÁªüÊï∞Â≠ó‰∫ßÂìÅÁöÑÊÉÖÂÜµ‰∏çÂêåÔºåÂêéËÄÖÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑÁ´û‰∫â‰ºòÂäø„ÄÇÁõ∏ÂèçÔºå**ÂØπÈ¢ÜÂüüÁöÑÊ∑±ÂàªÁêÜËß£**ÂèòÂæóËá≥ÂÖ≥ÈáçË¶ÅÔºåÂõ†‰∏∫ËøôÁßçÊ∑±Â∫¶Áü•ËØÜÂØπÁ´û‰∫âÂØπÊâãÊù•ËØ¥ÂæàÈöæÂ§çÂà∂„ÄÇ*\n\n‰ªé‰∫ßÂìÅÁ´û‰∫âÂäõÁöÑËßíÂ∫¶Êù•ÁúãÔºåÊàëËÆ§‰∏∫È¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÂ∫îÂΩìÂ≠òÂú®‰∫é**ËÆæËÆ°‰∫ßÂìÅÂπ∂ÂèÇ‰∏éÂÖ∂ÂÆûÊñΩÁöÑÂêå‰∏Ä‰∏™Â§¥ËÑë‰∏≠**„ÄÇÂΩìÁÑ∂ÔºåÂÖ¨Âè∏ÁöÑ‚ÄúÊäÄÊúØ‚ÄùÂíå‚ÄúÂïÜ‰∏ö‚ÄùËßíËâ≤ÁöÑ‰º†ÁªüÂàÜÁ¶ªÊúâÂÖ∂Â•ΩÂ§ÑÔºåÂè™Ë¶ÅÂÆÉ‰ª¨ËÉΩÂ§üÊúâÊïàÊ≤üÈÄöÔºåÂõ†‰∏∫ËøôÊ†∑ÁöÑÊ≤üÈÄö‰ºöÂØºËá¥Âπ≥Ë°°ËâØÂ•Ω„ÄÅÊäÄÊúØÂ§çÊùÇ‰∏îÁ¨¶ÂêàÈ¢ÜÂüüË¶ÅÊ±ÇÁöÑ‰∫ßÂìÅ„ÄÇÁÑ∂ËÄåÔºåÂè£Â§¥Ê≤üÈÄöÂºïÂÖ•‰∫ÜÊòæËëóÁöÑÂºÄÈîÄ„ÄÇÊäÄÊúØ‰∫∫ÂëòÂíåÂïÜ‰∏ö‰∫∫Â£´ÂèØËÉΩÈúÄË¶ÅÂá†‰∏™ÊúàÊâçËÉΩÂÖÖÂàÜÁêÜËß£ÂΩºÊ≠§„ÄÇÂú®Ê≠§ÊúüÈó¥ÔºåÂ∏ÇÂú∫Êù°‰ª∂ÂèØËÉΩ‰ºöÂèëÁîüÂâßÁÉàÂèòÂåñ„ÄÇ\n\n> *È¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÂêëÊäÄÊúØÂÆûÊñΩÁöÑÊúÄÊúâÊïà‰∏îÊó†ÊçüÁöÑËΩ¨ÂåñÂèëÁîüÂú®ÂïÜ‰∏öÂíåÊäÄÊúØÊÑøÊôØÂÖ±Â≠ò‰∫éÂêå‰∏ÄÂ§¥ËÑë‰∏≠Êó∂„ÄÇLLMÈÄöËøáÂ§ßÂ§ßÂáèÂ∞ë‰∫ßÂìÅÂÆûÊñΩÊâÄÈúÄÁöÑÊäÄÊúØ‰∏ì‰∏öÁü•ËØÜÔºåÊèê‰æõ‰∫ÜËøô‰∏ÄÊú∫‰ºöÔºå‰ªéËÄå**‰ΩøÂÖ∑Â§áÂº∫Â§ßÈ¢ÜÂüüÁü•ËØÜÁöÑ‰∏™‰∫∫ËÉΩÂ§üÁõ¥Êé•ÂèÇ‰∏é‰∫ßÂìÅ‰∫§‰ªò**„ÄÇ*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dOlknP1p9xLfvy_NxLnq7Q.png)\n\nÂú®ÊàëÁúãÊù•ÔºåÂú®ÂºÄÂèëGenAI‰∫ßÂìÅÊó∂ÔºåÊäÄÊúØ‰∏ì‰∏öÁü•ËØÜÂπ∂‰∏ç‰ªÖÈôê‰∫éÁ®ãÂ∫èÂëòÔºõÂÆÉËøòÂåÖÊã¨È´òÁ∫ßChatGPTÁî®Êà∑„ÄÇ\n\n‰æãÂ¶ÇÔºåÊàëÁöÑÊúãÂèã[Askhat Urazbaev](https://www.linkedin.com/in/urazbaev/)Áã¨Á´ã‰ΩøÁî®AI‰∏∫‰ªñÁöÑ‰∫ßÂìÅÂàõÂª∫MVPÔºåÁîöËá≥‰ªÖÈÄöËøáChatGPTÁöÑÊåáÂØºÂ∞ÜÂÖ∂ÈÉ®ÁΩ≤Âà∞‰∫ëÁ´Ø„ÄÇ‰ªñ‰ªéÊú™ÊòØ‰∏ÄÂêç‰∏ì‰∏öËΩØ‰ª∂ÂºÄÂèë‰∫∫ÂëòÔºå‰ºº‰πé‰ªñÁöÑ[AI Power User](https://readmedium.com/12-questions-to-consider-when-using-ai-path-to-ai-power-user-9c7e8de1f8b7#f646)ÊäÄËÉΩ‰∏éÈòÖËØªÁ®ãÂ∫è‰ª£Á†ÅÁöÑËÉΩÂäõÂêåÊ†∑ÈáçË¶Å„ÄÇ\n\n> *ÊàëÁõ∏‰ø°ÁîüÊàêAIÂ∞ÜÂæàÂø´‰ΩøÈ¢ÜÂüü‰∏ìÂÆ∂ËÉΩÂ§ü**ÂçïÁã¨**Âú®‰ªñ‰ª¨ÁöÑÈ¢ÜÂüüÂÜÖÂºÄÂèë‰∫ßÂìÅ„ÄÇË¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºå‰∏ìÂÆ∂Â∫îÂÖ∑Â§á‰∏∞ÂØåÁöÑAIÁî®Êà∑ÁªèÈ™åÔºåÂπ∂ÁªìÂêàÂØπÂïÜ‰∏öÂéüÂàôÂíå‰∫ßÂìÅËÆæËÆ°ÁöÑÂü∫Á°ÄÁêÜËß£„ÄÇ*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kk0SUvuajHZp7UMbSEonmQ.png)\n\nÁÑ∂ËÄåÔºåÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÂì™‰∫õÂÖ∑‰ΩìÂ∑•ÂÖ∑Â∞ÜÂ∏ÆÂä©Êàë‰ª¨Áã¨Á´ãÂàõÂª∫ÂÖ®Èù¢ÁöÑ‰∫ßÂìÅ„ÄÇ‚Äú**Âü∫‰∫éLLMÁöÑÂçï‰∫∫ÂÖ¨Âè∏**‚ÄùÁöÑÊ¶ÇÂøµÂ∞ÜÊòØÊàëÂç≥Â∞ÜÂèëÂ∏ÉÁöÑÊñáÁ´†Á†îÁ©∂ÁöÑÈáçÁÇπ„ÄÇ\n\n## ÊÄªÁªìÔºöLLMÈ©±Âä®‰∫ßÂìÅÁöÑÊàêÂäü‰∏éÂ§±Ë¥•Âõ†Á¥†\n\nËÆ©Êàë‰ª¨Â∞ÜËøô‰∏ÄÁ≥ªÂàóÁöÑ‰∏â‰∏™ÈÉ®ÂàÜ‰∏≠ÁöÑÊâÄÊúâÊÉ≥Ê≥ïÊ±áÊÄªÂú®‰∏ÄËµ∑„ÄÇ\n\n1. [È´òË¥®ÈáèÊ†áÂáÜÊàñÊàêÊú¨È´òÊòÇÁöÑË¥®ÈáèÁõëÊéßÁöÑÂ∫îÁî®ÂèØËÉΩ‰ºöÂ§±Ë¥• üö´](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#f973)\n2. [‰∏ì‰∏öÂåñÁöÑÂçèÂä©Â∑•ÂÖ∑ÈúÄÊ±ÇÊó∫Áõõ ‚úÖ](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#031b)\n3. [ËæπÈôÖËäÇÁúÅÂä™ÂäõÁöÑÂ∫îÁî®Êó†Ê≥ïÊª°Ë∂≥ÈúÄÊ±Ç üö´](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#e88a)\n4. [‚ÄúÊô∫ËÉΩ‚ÄùÊï¥ÂêàLLMÂà∞ÁÜüÊÇâÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂ∫îÁî®ÂèØ‰ª•Ë∑®Ë∂äÈ∏øÊ≤ü ‚úÖ](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#5d06)\n5. [Êñ∞‰∏Ä‰ª£GenAI‰∫ßÂìÅÊõ¥ÈÄÇÂêàB2BÂíåB2B2CËÄåÈùûB2C](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#bdfa)\n6. [Â¢ûÂº∫LLMËÉΩÂäõÁöÑÂ∫îÁî®ÁîüÂëΩÂë®ÊúüÁü≠ üö´](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e305)\n7. [ËøáÂ∫¶Á∫¶ÊùüLLMÔºö‰∏çÂÖ∑Á´û‰∫âÂäõÂ∫îÁî®ÁöÑÂ§ÑÊñπ üö´](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e1ef)\n8. [‚ÄúGenAIÂπ≥Êñπ‚Äù‰∫ßÂìÅÔºöËß£ÈîÅ‰∏çÂÖ¨Âπ≥Á´û‰∫â‰ºòÂäø ‚úÖ](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#9f01)\n9. ÂºÄÂèëÂë®ÊúüËæÉÈïø‰∏îÂ∏ÇÂú∫ÈááÁî®Êó∂Èó¥Êº´ÈïøÁöÑÂ§ßÂûãÂ∫îÁî®Áº∫‰πèÁ´û‰∫âÂäõ üö´\n10. Âà©Áî®‰∏çÂ§™ÊòéÊòæÁöÑLLMËÉΩÂäõÊèêÂçáÁ´û‰∫âÂäõÂíåËµÑÊ∫êÊïàÁéá ‚úÖ\n11. Âü∫‰∫éÊ∑±ÂéöÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁöÑÂ∞èÂûãAI‰∫ßÂìÅÂÖ∑ÊúâÁ´û‰∫âÂäõ ‚úÖ\n\nÈô§‰∫ÜÂõ†Á¥†\\#4ÔºåÂâ©‰∏ãÁöÑ10‰∏™ÊàêÂäü/Â§±Ë¥•Âõ†Á¥†ÂèØ‰ª•Â∫îÁî®‰∫é**Êñ∞**‰∫ßÂìÅ/ÂàùÂàõÂÖ¨Âè∏„ÄÇ\n\n‰∏ãÈù¢ÊòØ‰∏Ä‰∏™Á§∫ÊÑèÂõæÔºåÂ±ïÁ§∫Ëøô10‰∏™Âõ†Á¥†„ÄÅLLMËÉΩÂäõ‰ª•ÂèäLLMÊäÄÊúØÂ∏ÇÂú∫ÁöÑ‰∏Ä‰∫õÁâπÂæÅ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*f6E4WmRBw3H7eCNbTGJHUQ.png)\n\nÂΩìÁÑ∂ÔºåÂè™Êúâ‰∫ßÂìÅÂÆûÈ™åÊâçËÉΩÈ™åËØÅÁ§∫ÊÑèÂõæ‰∏≠ÊâÄÁ§∫ÁöÑËÄÉËôëÂõ†Á¥†„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨ÈÄöËøáÈôêÂà∂ÂÆûÈ™åËåÉÂõ¥Êù•ÂèòÂæó**Êõ¥Âø´**„ÄÇÊ≠£Â¶ÇÁ¨¨9ËäÇÊâÄËß£ÈáäÁöÑÔºåÂèëÁé∞Âíå‰∫§‰ªòÁöÑÈ´òÈÄüÂ∫¶ÂØπGenAI‰∫ßÂìÅÊØîÂÖ∂‰ªñÁ±ªÂûãÁöÑÊï∞Â≠ó‰∫ßÂìÅÊõ¥‰∏∫ÈáçË¶ÅÔºåÊúâ‰∏§‰∏™ÂéüÂõ†„ÄÇ\n\nËá™ÁÑ∂ÔºåÊàêÂäüÂõ†Á¥†ÁöÑÂàóË°®‰∏çÂèØËÉΩÊòØÂåÖÁΩó‰∏áË±°ÁöÑ„ÄÇ‰πüËÆ∏ÊÇ®ÈÅáÂà∞ËøáÂÖ∂‰ªñÁ±ªÂà´ÁöÑÊñ∞ÂûãLLMÈ©±Âä®‰∫ßÂìÅÔºåËøô‰∫õ‰∫ßÂìÅÊú™Âú®‰∏äËø∞ÊèêÂà∞Ôºå‰ΩÜÊÇ®ËÆ§‰∏∫ÂÆÉ‰ª¨ÂÖ∑ÊúâÊàêÂäüÁöÑÊΩúÂäõ„ÄÇËØ∑Âú®ËØÑËÆ∫‰∏≠ÂàÜ‰∫´Ëøô‰∫õ‰∫ßÂìÅÁ±ªÂûãÊàñÁâπÂæÅ üôè\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-to-create-an-ai-team-to-write-compelling-stories-with-crewai-and-gemini-pro-3713f53c72c4","frontmatter":{"title":"Â¶Ç‰Ωï‰ΩøÁî® CrewAI Âíå Gemini Pro ÂàõÂª∫ AI Âõ¢ÈòüÊù•Êí∞ÂÜôÂºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ã","meta_title":"Â¶Ç‰Ωï‰ΩøÁî® CrewAI Âíå Gemini Pro ÂàõÂª∫ AI Âõ¢ÈòüÊù•Êí∞ÂÜôÂºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ã","description":"ÊÇ®ÊòØÂê¶ÂØπ‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêÂºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ãÁöÑÊÉ≥Ê≥ïÁùÄËø∑ÔºüÂ¶ÇÊûúÊòØËøôÊ†∑ÔºåÊÇ®Âπ∂‰∏çÂ≠§ÂçïÔºÅÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•Êé¢ËÆ®‚Ä¶‚Ä¶","date":"2024-10-31T23:04:49.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tSnoOxxIGtrwdUT8","categories":["Programming","Natural Language Processing","Generative AI"],"author":"Rifx.Online","tags":["CrewAI","Gemini","screenwriters","critics","storytelling"],"draft":false,"slug":"blog/how-to-create-an-ai-team-to-write-compelling-stories-with-crewai-and-gemini-pro-3713f53c72c4"},"content":"\n\n\n‰Ω†ÊòØÂê¶ÂØπAIÁîüÊàêÂºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ãËøô‰∏ÄÊÉ≥Ê≥ïÊÑüÂà∞ÁùÄËø∑ÔºüÂ¶ÇÊûúÊòØËøôÊ†∑Ôºå‰Ω†Âπ∂‰∏çÂ≠§ÂçïÔºÅÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•Êé¢ËÆ®‰∏Ä‰∏™ÁªìÂêàCrewAIÂíåGemini ProÂäõÈáèÁöÑÂÖ•Èó®È°πÁõÆÔºåÂàõÂª∫‰∏Ä‰∏™‰ª£ÁêÜÁΩëÁªúÔºåÈÄöËøáÁî®Êà∑ËæìÂÖ•ÁöÑÂ∏ÆÂä©Êù•Âàõ‰ΩúÁü≠ÁØáÊïÖ‰∫ã„ÄÇÊó†ËÆ∫‰Ω†ÊòØ‰∏Ä‰∏™ÂàùÂá∫ËåÖÂ∫êÁöÑÁ®ãÂ∫èÂëòÔºå‰∏Ä‰∏™Â∏åÊúõÊé¢Á¥¢Êï∞Â≠óÂâçÊ≤øÁöÑËÆ≤ÊïÖ‰∫ãËÄÖÔºåËøòÊòØ‰ªÖ‰ªÖÂØπ‰∫∫Â∑•Êô∫ËÉΩÁöÑÊΩúÂäõÊÑüÂà∞Â•ΩÂ•áÔºåËøôÊú¨ÊåáÂçóÈÉΩÈÄÇÂêà‰Ω†„ÄÇ\n\n## CrewAI Âíå Gemini Pro ÊòØ‰ªÄ‰πàÔºü\n\nÂú®Êàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ®ÊûÑÂª∫ AI ËÆ≤ÊïÖ‰∫ãËÄÖÁöÑÁªÜËäÇ‰πãÂâçÔºåÂÖàÊù•ÊæÑÊ∏Ö‰∏Ä‰∏ã CrewAI Âíå Gemini Pro ÁöÑÊ¶ÇÂøµ„ÄÇ\n\n**CrewAI** ÊòØ‰∏Ä‰∏™Âºï‰∫∫ÂÖ•ËÉúÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÂçèË∞ÉÂ§ö‰∏™ AI ‰ª£ÁêÜÔºåÊØè‰∏™‰ª£ÁêÜÈÉΩÊúâÂÖ∂Áã¨ÁâπÁöÑÊäÄËÉΩÂíåËÅåË¥£Ôºå‰ª•Âçè‰ΩúÂÆåÊàêÂ§çÊùÇ‰ªªÂä°„ÄÇÂèØ‰ª•ÊääÂÆÉÊÉ≥Ë±°Êàê‰∏Ä‰∏™ÂØºÊºîÁÆ°ÁêÜ‰∏ÄÁªÑÊºîÂëòÔºåÊØè‰∏™ÊºîÂëòÊâÆÊºîÁâπÂÆöËßíËâ≤Êù•ËÆ©ÊïÖ‰∫ãÁîüÂä®Ëµ∑Êù•„ÄÇÂú®Êàë‰ª¨È°πÁõÆÁöÑËÉåÊôØ‰∏ãÔºåCrewAI ‰ΩøÊàë‰ª¨ËÉΩÂ§üÂàõÂª∫‰∏ÄÊîØÁî±‰∏ì‰∏ö‰ª£ÁêÜÔºàÂ¶ÇÁºñÂâß„ÄÅËØÑËÆ∫ÂÆ∂ÂíåÊïÖ‰∫ãÂ§ßÂ∏àÔºâÁªÑÊàêÁöÑÂõ¢ÈòüÔºåÂÖ±ÂêåÊí∞ÂÜôÊïÖ‰∫ã„ÄÇ\n\n**Gemini Pro**ÔºåÂè¶‰∏ÄÊñπÈù¢ÔºåÊòØÁî± Google ÂºÄÂèëÁöÑÊúÄÂÖàËøõÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇÂÆÉ‰ª•ÁêÜËß£ÂíåÁîüÊàêÁ±ª‰∫∫ÊñáÊú¨ÁöÑËÉΩÂäõËÄåÈóªÂêçÔºå‰ΩøÂÖ∂Êàê‰∏∫ÊïÖ‰∫ãÂàõ‰ΩúÁ≠âÂàõÊÑè‰ªªÂä°ÁöÑÁêÜÊÉ≥ÈÄâÊã©„ÄÇÈÄöËøáÂà©Áî® Gemini ProÔºåÊàë‰ª¨ÂèØ‰ª•Á°Æ‰øùÊàë‰ª¨ÁöÑ‰ª£ÁêÜÂÖ∑Â§áÁîüÊàêÂºï‰∫∫ÂÖ•ËÉúÁöÑÂèô‰∫ãÂÜÖÂÆπÁöÑÂùöÂÆûÂü∫Á°Ä„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàËøôÁßçÁªìÊûÑÂæàÈáçË¶ÅÔºü\n\nCrewAI Âíå Gemini Pro ÁöÑÁªìÂêà‰ΩøÂæóÊïÖ‰∫ãÁîüÊàêËÉΩÂ§üÈááÁî®È´òÂ∫¶Âçè‰ΩúÂíå‰∏ì‰∏öÂåñÁöÑÊñπÊ≥ï„ÄÇËøô‰∏™ÁªìÊûÑÂÖÅËÆ∏Ôºö\n\n1. **‰∏ì‰∏öÂåñ**ÔºöÊØè‰∏™‰ª£ÁêÜÂèØ‰ª•‰∏ìÊ≥®‰∫éÂÆÉÊúÄÊìÖÈïøÁöÑÈ¢ÜÂüüÔºåÊó†ËÆ∫ÊòØÊí∞ÂÜôÂØπËØù„ÄÅÁ°Æ‰øù‰∏ÄËá¥ÊÄßËøòÊòØÁõëÁù£È°πÁõÆ„ÄÇ\n2. **Âçè‰Ωú**Ôºö‰ª£ÁêÜÂèØ‰ª•ÂÖ±ÂêåÂ∑•‰ΩúÔºåÁªìÂêàÂêÑËá™ÁöÑ‰ºòÂäøÔºå‰∫ßÁîü‰∏Ä‰∏™Ë∂ÖË∂äÂÖ∂ÈÉ®ÂàÜÊÄªÂíåÁöÑÊïÖ‰∫ã„ÄÇ\n3. **ÁÅµÊ¥ªÊÄß**ÔºöËØ•ËÆæÁΩÆÂÖ∑ÊúâÈ´òÂ∫¶ÈÄÇÂ∫îÊÄßÔºåÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ËæìÂÖ•ÊàñÂàõÊÑèÊñπÂêëÂº∫Ë∞ÉÊàñÊîπÂèò‰∏çÂêåÁöÑÊïÖ‰∫ãÂÖÉÁ¥†„ÄÇ\n\n## ËÆæÁΩÆÁéØÂ¢É\n\nÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∫õÂ∫ìÊù•‰ΩøÁî®„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá pip Âä†ËΩΩËøô‰∫õÂ∫ìÔºö\n\n```python\npip install crewai\n```\n\n```python\npip install langchain-google-genai\n```\n\nÂä†ËΩΩÂøÖË¶ÅÁöÑÂ∫ìÂêéÔºåÊàë‰ª¨ÂèØ‰ª•ÂºÄÂßãÁºñÁ†Å„ÄÇÊàë‰ª¨Â∞ÜÈ¶ñÂÖàÂØºÂÖ•ÊâÄÈúÄÁöÑÊ®°ÂùóÂπ∂ÂàùÂßãÂåñÊàë‰ª¨ÁöÑ Gemini pro API ËøûÊé•„ÄÇ\n\nÂ¶ÇÊÇ®ÊâÄËßÅÔºåÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™ Gemini Ê®°ÂûãÁöÑ API ÂØÜÈí•„ÄÇÊÇ®ÂèØ‰ª•Âú® Google AI Studio ‰∏≠[ÂÖçË¥π](https://ai.google.dev/)ÂàõÂª∫Ê≠§ÂØÜÈí•„ÄÇ‰πãÂêéÔºåÊÇ®ÂèØ‰ª•Â∞ÜÊ≠§ÂØÜÈí•Â§çÂà∂Âà∞ google\\_api\\_key ÂèòÈáè‰∏≠ÔºåÊàñËÄÖÈÄöËøáÂú®ÂëΩ‰ª§Ë°å‰∏≠ËøêË°å‰ª•‰∏ãÂëΩ‰ª§Â∞ÜÂÖ∂Âä†ËΩΩÂà∞ÁéØÂ¢É‰∏≠Ôºö\n\n```python\nexport GOOGLE_API_KEY=YOUR_KEY\n```\n\nÂ∞ÜÊÇ®‰ªé Google AI Studio Ëé∑ÂèñÁöÑ API ÂØÜÈí•ÊõøÊç¢‰∏∫ YOUR\\_KEY„ÄÇ\n\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÂÆö‰πâÊàë‰ª¨ÁöÑ‰ª£ÁêÜÔºöÁºñÂâß„ÄÅËØÑËÆ∫ÂÆ∂ÂíåÊïÖ‰∫ãÂ§ßÂ∏à„ÄÇÊØè‰∏™‰ª£ÁêÜÈÉΩÊúâ‰∏Ä‰∏™ËßíËâ≤„ÄÅÁõÆÊ†áÂíåËÉåÊôØÊïÖ‰∫ãÔºå‰ª•ÊåáÂØºÂÖ∂Âú®ÊïÖ‰∫ãÁîüÊàêËøáÁ®ã‰∏≠ÁöÑË¥°ÁåÆ„ÄÇ\n\n‰æãÂ¶ÇÔºåÁºñÂâß‰∏ìÊ≥®‰∫éÂ∞ÜÂàõÊÑèËΩ¨Âåñ‰∏∫Âºï‰∫∫ÂÖ•ËÉúÁöÑÂú∫ÊôØÔºåËÄåËØÑËÆ∫ÂÆ∂Á°Æ‰øù‰∏ÄËá¥ÊÄßÂíåÈÅµÂæ™Á±ªÂûã„ÄÇ\n\nËøô‰∫õ‰ª£ÁêÜÂ∞ÜÂÖ±ÂêåÂ∑•‰ΩúÔºåÂàõÈÄ†‰∏Ä‰∏™Âºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ã„ÄÇÊïÖ‰∫ãÂ§ßÂ∏àÂ∞ÜÊé•Âèó‰ªªÂä°ÔºåÁÑ∂ÂêéÂú®ÂÖ∂‰ªñ‰ª£ÁêÜ‰πãÈó¥ÂßîÊ¥æÂíåÂçèË∞É‰ªªÂä°„ÄÇÊàë‰ª¨ÈÄöËøáÂ∞Ü allow\\_delegation ÂèÇÊï∞ËÆæÁΩÆ‰∏∫ True Êù•ÂÖÅËÆ∏ËøôÁßçË°å‰∏∫„ÄÇ\n\nÂáÜÂ§áÂ•Ω‰ª£ÁêÜÂêéÔºåÊàë‰ª¨ÊèêÁ§∫Áî®Êà∑Êèê‰æõ‰∏Ä‰∏™ÊïÖ‰∫ãÂàõÊÑè„ÄÇÁÑ∂ÂêéÔºåËøô‰∏™ËæìÂÖ•Áî®‰∫éÂàõÂª∫‰∏Ä‰∏™‰ªªÂä°ÔºåÊ¶ÇËø∞ÊïÖ‰∫ãÂ∫îÂåÖÂê´ÁöÑÂÜÖÂÆπÔºåÂºïÂØº‰ª£ÁêÜËøõË°åÂàõ‰ΩúËøáÁ®ã„ÄÇ\n\nÂú®ÂàõÂª∫‰ªªÂä°Êó∂ÔºåÊàë‰ª¨Â∞Ü‰ªªÂä°Êèê‰∫§ÁªôÊïÖ‰∫ãÂ§ßÂ∏àÔºåÂõ†‰∏∫ÂÆÉÂ∞ÜÂçèË∞ÉÊàë‰ª¨ÁöÑÊïÖ‰∫ãÂàõ‰ΩúËøáÁ®ã„ÄÇ\n\nÊúÄÂêéÔºåÊàë‰ª¨Â∫îËØ•Â∞ÜËøô‰∫õ‰ª£ÁêÜÁªÑÂêàÊàê‰∏Ä‰∏™Âõ¢ÈòüÂπ∂ËøêË°åÊàë‰ª¨ÁöÑ‰ªªÂä°„ÄÇ\n\nÂ∞±ËøôÊ†∑„ÄÇÂΩìÊàë‰ª¨ËøêË°åËøôÊÆµ‰ª£Á†ÅÊó∂ÔºåÂÆÉ‰ºöÊèêÁ§∫Áî®Êà∑Êèê‰æõ‰∏Ä‰∏™ÊïÖ‰∫ãÂàõÊÑèÔºåÁÑ∂ÂêéÈÄöËøá‰ª£ÁêÜÂêà‰ΩúÂÜô‰∏Ä‰∏™Áü≠ÊïÖ‰∫ã„ÄÇÂΩìÁÑ∂ÔºåÂú® CrewAI Ê°ÜÊû∂‰∏≠ËøòÊúâÊõ¥Â§öÂÜÖÂÆπÔºå‰æãÂ¶ÇÂ∑•ÂÖ∑‰ΩøÁî®„ÄÅÂ±ÇÊ¨°Â§ÑÁêÜ„ÄÅ‰∏é ollama ‰∏ÄËµ∑ÂÆåÂÖ®Êú¨Âú∞ËøêË°å‰∏çÂêå‰ª£ÁêÜÁ≠âÔºå‰ΩÜËøô‰∫õ‰∏ªÈ¢òÊòØÂè¶‰∏Ä‰∏™ÊñáÁ´†ÁöÑÂÜÖÂÆπ„ÄÇ\n\nÊÇ®ÂèØ‰ª•Âú®ËøôÈáåÊâæÂà∞ÂÆåÊï¥ÁöÑ‰ª£Á†Å‰ª•Áõ¥Êé•ËøêË°åÔºö\n\nÊÇ®ÂèØ‰ª•Â∞ÜÊ≠§‰ª£Á†ÅÁî®‰ΩúÊ≠§Á±ªÂ∫îÁî®Á®ãÂ∫èÁöÑÊ®°ÊùøÔºåÊÇ®ÂèØ‰ª•ÊûÑÂª∫Ê∏∏ÊàèÊûÑÂª∫ËÄÖÂõ¢Èòü„ÄÅËÇ°Á•®ÂàÜÊûêÂ∏àÂõ¢Èòü„ÄÅËê•ÈîÄÂõ¢ÈòüÁ≠â„ÄÇÂá≠ÂÄüÊÉ≥Ë±°ÂäõÔºåÂ§©Á©∫ÊâçÊòØÊûÅÈôê„ÄÇÂ¶ÇÊûúÊÇ®ÂñúÊ¨¢ËøôÁØáÊñáÁ´†Âπ∂ÂØπÊõ¥È´òÁ∫ßÁöÑÂÆûÁé∞ÊÑüÂà∞ÂÖ¥Â•ãÔºåÂèØ‰ª•ËÆøÈóÆ CrewAI [ÁΩëÁ´ô](https://www.crewai.com/)„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-to-improve-llms-with-rag-abdc132f76ac","frontmatter":{"title":"Â¶Ç‰Ωï‰ΩøÁî® RAG ÊèêÈ´ò LLM ÊàêÁª©","meta_title":"Â¶Ç‰Ωï‰ΩøÁî® RAG ÊèêÈ´ò LLM ÊàêÁª©","description":"ÈÄÇÂêàÂàùÂ≠¶ËÄÖÁöÑ Python ‰ª£Á†Å‰ªãÁªç","date":"2024-11-04T12:31:55.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*N0Ad_oCIrAyzMYRdH3trqg.png","categories":["Natural Language Processing","Programming","Generative AI"],"author":"Rifx.Online","tags":["RAG","retrievers","LlamaIndex","knowledge","bases"],"draft":false,"slug":"blog/how-to-improve-llms-with-rag-abdc132f76ac"},"content":"\n\n\n### ÂàùÂ≠¶ËÄÖÂèãÂ•ΩÁöÑ‰ªãÁªç w/ Python ‰ª£Á†Å\n\nÊú¨ÊñáÊòØÂÖ≥‰∫éÂú®ÂÆûË∑µ‰∏≠‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ[Êõ¥Â§ßÁ≥ªÂàó](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c)ÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÂú®[‰∏ä‰∏ÄÁØáÊñáÁ´†](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî® QLoRA ÂØπ Mistral-7b-Instruct ËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ª•ÂõûÂ∫î YouTube ËØÑËÆ∫„ÄÇÂ∞ΩÁÆ°ÂæÆË∞ÉÂêéÁöÑÊ®°ÂûãÂú®ÂõûÂ∫îËßÇ‰ºóÂèçÈ¶àÊó∂ÊàêÂäüÊçïÊçâ‰∫ÜÊàëÁöÑÈ£éÊ†ºÔºå‰ΩÜÂÆÉÂØπÊäÄÊúØÈóÆÈ¢òÁöÑÂõûÁ≠î‰∏éÊàëÁöÑËß£ÈáäÂπ∂‰∏çÂåπÈÖç„ÄÇÂú®ËøôÈáåÔºåÊàëÂ∞ÜËÆ®ËÆ∫Â¶Ç‰ΩïÈÄöËøáÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàÂç≥ RAGÔºâÊù•ÊèêÈ´ò LLM ÁöÑÊÄßËÉΩ„ÄÇ\n\n\n\nÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®ÂìçÂ∫îÁî®Êà∑Êü•ËØ¢Êó∂Â±ïÁ§∫‰∫ÜÂ≠òÂÇ®ÂíåÈÉ®ÁΩ≤Â§ßÈáèÁü•ËØÜÁöÑÊÉä‰∫∫ËÉΩÂäõ„ÄÇËôΩÁÑ∂Ëøô‰ΩøÂæóÂÉè ChatGPT ËøôÊ†∑ÁöÑÂº∫Â§ß AI Á≥ªÁªüÂæó‰ª•ÂàõÂª∫Ôºå‰ΩÜ‰ª•ËøôÁßçÊñπÂºèÂéãÁº©‰∏ñÁïåÁü•ËØÜÊúâ**‰∏§‰∏™ÂÖ≥ÈîÆÈôêÂà∂**„ÄÇ\n\n**È¶ñÂÖà**ÔºåLLM ÁöÑÁü•ËØÜÊòØÈùôÊÄÅÁöÑÔºåÂç≥‰∏ç‰ºöÈöèÁùÄÊñ∞‰ø°ÊÅØÁöÑÂá∫Áé∞ËÄåÊõ¥Êñ∞„ÄÇ**ÂÖ∂Ê¨°**ÔºåLLM ÂèØËÉΩÂØπÂÖ∂ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠‰∏çÊòæËëóÁöÑÂà©Âü∫Âíå‰∏ì‰∏ö‰ø°ÊÅØÁº∫‰πèË∂≥Â§üÁöÑ‚ÄúÁêÜËß£‚Äù„ÄÇËøô‰∫õÈôêÂà∂ÂèØËÉΩÂØºËá¥Ê®°ÂûãÂØπÁî®Êà∑Êü•ËØ¢ÁöÑÂõûÁ≠î‰∏çÁêÜÊÉ≥ÔºàÁîöËá≥ÊòØËôöÊûÑÁöÑÔºâ„ÄÇ\n\nÊàë‰ª¨ÂèØ‰ª•ÈÄöËøá**ÈÄöËøá‰∏ì‰∏öÂíåÂèØÂèòÁöÑÁü•ËØÜÂ∫ìÂ¢ûÂº∫Ê®°Âûã**Êù•ÁºìËß£Ëøô‰∫õÈôêÂà∂Ôºå‰æãÂ¶ÇÂÆ¢Êà∑Â∏∏ËßÅÈóÆÈ¢òËß£Á≠î„ÄÅËΩØ‰ª∂ÊñáÊ°£Êàñ‰∫ßÂìÅÁõÆÂΩï„ÄÇËøô‰ΩøÂæóÂàõÂª∫Êõ¥Âº∫Â§ßÂíåÈÄÇÂ∫îÊÄßÊõ¥Âº∫ÁöÑ AI Á≥ªÁªüÊàê‰∏∫ÂèØËÉΩ„ÄÇ\n\n**Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê**ÔºåÊàñÁß∞ **RAG**ÔºåÂ∞±ÊòØËøôÊ†∑‰∏ÄÁßçÊñπÊ≥ï„ÄÇÂú®ËøôÈáåÔºåÊàëÊèê‰æõ RAG ÁöÑÈ´òÁ∫ß‰ªãÁªçÔºåÂπ∂ÂàÜ‰∫´‰ΩøÁî® LlamaIndex ÂÆûÁé∞ RAG Á≥ªÁªüÁöÑÁ§∫‰æã Python ‰ª£Á†Å„ÄÇ\n\n## ‰ªÄ‰πàÊòØ RAGÔºü\n\nLLM ÁöÑÂü∫Êú¨Áî®Ê≥ïÊòØÁªôÂÆÉ‰∏Ä‰∏™ÊèêÁ§∫Âπ∂Ëé∑ÂèñÂìçÂ∫î„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sM1p-3FoTaGZunqx918G9A.png)\n\n**RAG ÈÄöËøáÂú®Ëøô‰∏™Âü∫Êú¨ËøáÁ®ã‰∏≠Ê∑ªÂä†‰∏Ä‰∏™Ê≠•È™§Êù•Â∑•‰Ωú**„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊâßË°å‰∏Ä‰∏™Ê£ÄÁ¥¢Ê≠•È™§ÔºåÊ†πÊçÆÁî®Êà∑ÁöÑÊèêÁ§∫Ôºå‰ªéÂ§ñÈÉ®Áü•ËØÜÂ∫ì‰∏≠ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØÔºåÂπ∂Âú®‰º†ÈÄíÁªô LLM ‰πãÂâçÂ∞ÜÂÖ∂Ê≥®ÂÖ•Âà∞ÊèêÁ§∫‰∏≠„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EhJZj1blu7a8EPmVAPsNcA.png)\n\n## Êàë‰ª¨‰∏∫‰ªÄ‰πàÂÖ≥ÂøÉ\n\nËØ∑Ê≥®ÊÑèÔºåRAG Âπ∂Ê≤°Êúâ‰ªéÊ†πÊú¨‰∏äÊîπÂèòÊàë‰ª¨‰ΩøÁî® LLM ÁöÑÊñπÂºèÔºõÂÆÉ‰ªçÁÑ∂ÊòØ *ÊèêÁ§∫ËæìÂÖ•ÂíåÂìçÂ∫îËæìÂá∫*„ÄÇRAG Âè™ÊòØÂ¢ûÂº∫‰∫ÜËøô‰∏™ËøáÁ®ãÔºàÂõ†Ê≠§ÂæóÂêçÔºâ„ÄÇ\n\nËøô‰ΩøÂæó **RAG Êàê‰∏∫‰∏ÄÁßçÁÅµÊ¥ª‰∏îÔºàÁõ∏ÂØπÔºâÁÆÄÂçïÁöÑÊñπÂºèÊù•ÊîπÂñÑÂü∫‰∫é LLM ÁöÑÁ≥ªÁªü**„ÄÇÊ≠§Â§ñÔºåÁî±‰∫éÁü•ËØÜÂ≠òÂÇ®Âú®Â§ñÈÉ®Êï∞ÊçÆÂ∫ì‰∏≠ÔºåÊõ¥Êñ∞Á≥ªÁªüÁü•ËØÜÂ∞±ÂÉè‰ªéË°®‰∏≠Ê∑ªÂä†ÊàñÂà†Èô§ËÆ∞ÂΩï‰∏ÄÊ†∑ÁÆÄÂçï„ÄÇ\n\n### ‰∏∫‰ªÄ‰πà‰∏çËøõË°åÂæÆË∞ÉÔºü\n\nÊú¨Á≥ªÂàó‰πãÂâçÁöÑÊñáÁ´†ËÆ®ËÆ∫‰∫Ü[ÂæÆË∞É](https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91)ÔºåÂç≥‰∏∫ÁâπÂÆöÁî®‰æãË∞ÉÊï¥Áé∞ÊúâÊ®°Âûã„ÄÇËôΩÁÑ∂ËøôÊòØ‰∏ÄÁßçËµã‰∫àLLM‰∏ì‰∏öÁü•ËØÜÁöÑÊõø‰ª£ÊñπÊ≥ïÔºå‰ΩÜ‰ªéÁªèÈ™åÊù•ÁúãÔºå**ÂæÆË∞É‰ºº‰πéÂú®ËøôÊñπÈù¢ÁöÑÊïàÊûú‰∏çÂ¶ÇRAG** \\[1]„ÄÇ\n\n## ÂÆÉÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑ\n\nRAG Á≥ªÁªüÊúâ‰∏§‰∏™ÂÖ≥ÈîÆË¶ÅÁ¥†Ôºö**Ê£ÄÁ¥¢Âô®**Âíå **Áü•ËØÜÂ∫ì**„ÄÇ\n\n### Retriever\n\nÊ£ÄÁ¥¢Âô®Êé•Êî∂Áî®Êà∑ÊèêÁ§∫Âπ∂‰ªéÁü•ËØÜÂ∫ì‰∏≠ËøîÂõûÁõ∏ÂÖ≥È°πÁõÆ„ÄÇËøôÈÄöÂ∏∏‰ΩøÁî®ÊâÄË∞ìÁöÑ **ÊñáÊú¨ÂµåÂÖ•**ÔºåÂç≥ÊñáÊú¨Âú®Ê¶ÇÂøµÁ©∫Èó¥‰∏≠ÁöÑÊï∞ÂÄºË°®Á§∫„ÄÇÊç¢Âè•ËØùËØ¥ÔºåËøô‰∫õÊòØ **Ë°®Á§∫ÁªôÂÆöÊñáÊú¨ÁöÑ *Âê´‰πâ* ÁöÑÊï∞Â≠ó**„ÄÇ\n\nÊñáÊú¨ÂµåÂÖ•ÂèØ‰ª•Áî®Êù•ËÆ°ÁÆóÁî®Êà∑Êü•ËØ¢‰∏éÁü•ËØÜÂ∫ì‰∏≠ÊØè‰∏™È°πÁõÆ‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÂæóÂàÜ„ÄÇËøô‰∏™ËøáÁ®ãÁöÑÁªìÊûúÊòØ **ÊØè‰∏™È°πÁõÆ‰∏éËæìÂÖ•Êü•ËØ¢Áõ∏ÂÖ≥ÊÄßÁöÑÊéíÂêç**„ÄÇ\n\nÁÑ∂ÂêéÔºåÊ£ÄÁ¥¢Âô®ÂèØ‰ª•ÈÄâÊã©Ââç k ‰∏™Ôºà‰æãÂ¶Ç k=3ÔºâÊúÄÁõ∏ÂÖ≥ÁöÑÈ°πÁõÆÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨Ê≥®ÂÖ•Âà∞Áî®Êà∑ÊèêÁ§∫‰∏≠„ÄÇËøô‰∏™Â¢ûÂº∫ÁöÑÊèêÁ§∫ÈöèÂêéË¢´‰º†ÈÄíÁªô LLM ËøõË°åÁîüÊàê„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jpTwdBmoTlJlfPAm0oJiVQ.png)\n\n### Áü•ËØÜÂ∫ì\n\nRAG Á≥ªÁªüÁöÑ‰∏ã‰∏Ä‰∏™ÂÖ≥ÈîÆË¶ÅÁ¥†ÊòØÁü•ËØÜÂ∫ì„ÄÇËøô‰∏™ **ÂåÖÂê´‰∫ÜÊÇ®Â∏åÊúõÊèê‰æõÁªô LLM ÁöÑÊâÄÊúâ‰ø°ÊÅØ**„ÄÇËôΩÁÑ∂ÊúâÊó†Êï∞ÁßçÊñπÊ≥ïÂèØ‰ª•ÊûÑÂª∫ RAG ÁöÑÁü•ËØÜÂ∫ìÔºå‰ΩÜÂú®ËøôÈáåÊàëÂ∞ÜÈáçÁÇπ‰ªãÁªçÂ¶Ç‰Ωï‰ªé‰∏ÄÁªÑÊñáÊ°£‰∏≠ÊûÑÂª∫‰∏Ä‰∏™Áü•ËØÜÂ∫ì„ÄÇ\n\nËøô‰∏™ËøáÁ®ãÂèØ‰ª•ÂàÜ‰∏∫ **4 ‰∏™ÂÖ≥ÈîÆÊ≠•È™§** \\[2,3].\n\n1. **Âä†ËΩΩÊñáÊ°£** ‚Äî ËøôÂåÖÊã¨Êî∂ÈõÜ‰∏ÄÁªÑÊñáÊ°£Âπ∂Á°Æ‰øùÂÆÉ‰ª¨Â§Ñ‰∫éÂèØËß£ÊûêÁöÑÊ†ºÂºèÔºàÁ®çÂêé‰ºöËØ¶ÁªÜ‰ªãÁªçÔºâ„ÄÇ\n2. **ÂàÜÂùóÊñáÊ°£‚Äî**Áî±‰∫é LLM ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÊúâÈôêÔºåÊñáÊ°£ÂøÖÈ°ªË¢´ÊãÜÂàÜÊàêÊõ¥Â∞èÁöÑÂùó **Ôºà‰æãÂ¶ÇÔºå** 256 Êàñ 512 ‰∏™Â≠óÁ¨¶ÈïøÔºâ„ÄÇ\n3. **ÂµåÂÖ•Âùó** ‚Äî ‰ΩøÁî®ÊñáÊú¨ÂµåÂÖ•Ê®°ÂûãÂ∞ÜÊØè‰∏™ÂùóËΩ¨Êç¢‰∏∫Êï∞Â≠ó„ÄÇ\n4. **Âä†ËΩΩÂà∞ÂêëÈáèÊï∞ÊçÆÂ∫ì**‚Äî Â∞ÜÊñáÊú¨ÂµåÂÖ•Âä†ËΩΩÂà∞Êï∞ÊçÆÂ∫ìÔºàÂç≥ÂêëÈáèÊï∞ÊçÆÂ∫ìÔºâ‰∏≠„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VWG6Tr0OxCnD5Mvygm5DCA.png)\n\n## ‰∏Ä‰∫õÁªÜÂæÆÂ∑ÆÂà´\n\nËôΩÁÑ∂ÊûÑÂª∫ RAG Á≥ªÁªüÁöÑÊ≠•È™§Âú®Ê¶ÇÂøµ‰∏äÂæàÁÆÄÂçïÔºå‰ΩÜ‰∏Ä‰∫õÁªÜÂæÆÂ∑ÆÂà´ÂèØËÉΩ‰ΩøÂæóÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÊûÑÂª∫‰∏Ä‰∏™Á≥ªÁªüÂèòÂæóÊõ¥Âä†Â§çÊùÇ„ÄÇ\n\n**ÊñáÊ°£ÂáÜÂ§á**‚ÄîRAG Á≥ªÁªüÁöÑË¥®ÈáèÂèñÂÜ≥‰∫é‰ªéÊ∫êÊñáÊ°£‰∏≠ÊèêÂèñÊúâÁî®‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûú‰∏Ä‰∏™ÊñáÊ°£Ê†ºÂºèÊ∑∑‰π±ÔºåÂÖÖÊª°‰∫ÜÂõæÂÉèÂíåË°®Ê†ºÔºåÈÇ£‰πàËß£ÊûêËµ∑Êù•‰ºöÊØî‰∏Ä‰∏™Ê†ºÂºèËâØÂ•ΩÁöÑÊñáÊú¨Êñá‰ª∂Êõ¥Âõ∞Èöæ„ÄÇ\n\n**ÈÄâÊã©ÂêàÈÄÇÁöÑÂùóÂ§ßÂ∞è**‚ÄîÊàë‰ª¨Â∑≤ÁªèÊèêÂà∞Áî±‰∫é LLM ‰∏ä‰∏ãÊñáÁ™óÂè£ÁöÑÈúÄË¶ÅËøõË°åÂàÜÂùó„ÄÇÁÑ∂ËÄåÔºåËøòÊúâ 2 ‰∏™È¢ùÂ§ñÁöÑÂàÜÂùóÂä®Êú∫„ÄÇ\n\n**È¶ñÂÖà**ÔºåÂÆÉÂèØ‰ª•Èôç‰ΩéÔºàËÆ°ÁÆóÔºâÊàêÊú¨„ÄÇ‰Ω†Âú®ÊèêÁ§∫‰∏≠Ê≥®ÂÖ•ÁöÑÊñáÊú¨Ë∂äÂ§öÔºåÁîüÊàêÂÆåÊàêÊâÄÈúÄÁöÑËÆ°ÁÆóÂ∞±Ë∂äÂ§ö„ÄÇ**Á¨¨‰∫å**ÊòØÊÄßËÉΩ„ÄÇÁâπÂÆöÊü•ËØ¢ÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÂæÄÂæÄÈõÜ‰∏≠Âú®Ê∫êÊñáÊ°£‰∏≠ÔºàÈÄöÂ∏∏‰ªÖ‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•ÂõûÁ≠î‰∏Ä‰∏™ÈóÆÈ¢òÔºâ„ÄÇÂàÜÂùóÊúâÂä©‰∫éÊúÄÂ∞èÂåñ‰º†ÈÄíÁªôÊ®°ÂûãÁöÑÊó†ÂÖ≥‰ø°ÊÅØÁöÑÊï∞Èáè \\[4\\]„ÄÇ\n\n**ÊîπÂñÑÊêúÁ¥¢** ‚Äî ËôΩÁÑ∂ÊñáÊú¨ÂµåÂÖ•Êèê‰æõ‰∫Ü‰∏ÄÁßçÂº∫Â§ß‰∏îÂø´ÈÄüÁöÑÊêúÁ¥¢ÊñπÂºèÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊÄªÊòØËÉΩÂ¶Ç‰∫∫ÊâÄÊÑøÂú∞Â∑•‰Ωú„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂÆÉÂèØËÉΩËøîÂõû‰∏éÁî®Êà∑Êü•ËØ¢‚ÄúÁõ∏‰ºº‚ÄùÁöÑÁªìÊûúÔºå‰ΩÜÂØπÂõûÁ≠îÈóÆÈ¢òÂπ∂Ê≤°ÊúâÂ∏ÆÂä©Ôºå‰æãÂ¶ÇÔºå‚Äú*Ê¥õÊùâÁü∂ÁöÑÂ§©Ê∞îÊÄé‰πàÊ†∑Ôºü*‚ÄùÂèØËÉΩËøîÂõû‚Äú*Á∫ΩÁ∫¶ÁöÑÂ§©Ê∞îÊÄé‰πàÊ†∑Ôºü*‚Äù„ÄÇ\n\nÁºìËß£Ëøô‰∏ÄÈóÆÈ¢òÁöÑÊúÄÁÆÄÂçïÊñπÊ≥ïÊòØÈÄöËøáËâØÂ•ΩÁöÑÊñáÊ°£ÂáÜÂ§áÂíåÂàÜÂùó„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÊüê‰∫õÁî®‰æãÔºåÂèØËÉΩÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÁ≠ñÁï•Êù•ÊîπÂñÑÊêúÁ¥¢Ôºå‰æãÂ¶Ç‰∏∫ÊØè‰∏™Âùó‰ΩøÁî® **ÂÖÉÊ†áÁ≠æ**„ÄÅÈááÁî®ÁªìÂêàÂÖ≥ÈîÆËØçÂíåÂµåÂÖ•ÊêúÁ¥¢ÁöÑ **Ê∑∑ÂêàÊêúÁ¥¢**ÔºåÊàñ‰ΩøÁî® **ÈáçÊéíÂ∫èÂô®**ÔºåËøôÊòØ‰∏ÄÁßç‰∏ìÈó®ËÆ°ÁÆó‰∏§ÊÆµÊñáÊú¨Áõ∏‰ººÊÄßÁöÑÊ®°Âûã„ÄÇ\n\n## Á§∫‰æã‰ª£Á†ÅÔºö‰ΩøÁî® RAG ÊîπËøõ YouTube ËØÑËÆ∫ÂìçÂ∫îÂô®\n\nÂú®ÂØπ RAG Â∑•‰ΩúÂéüÁêÜÊúâÂü∫Êú¨‰∫ÜËß£ÂêéÔºåËÆ©Êàë‰ª¨ÁúãÁúãÂ¶Ç‰ΩïÂú®ÂÆûË∑µ‰∏≠‰ΩøÁî®ÂÆÉ„ÄÇÊàëÂ∞ÜÂü∫‰∫é [‰∏ä‰∏ÄÁØáÊñáÁ´†](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32) ‰∏≠ÁöÑÁ§∫‰æãÔºåÂú®ÂÖ∂‰∏≠Êàë‰ΩøÁî® QLoRA ÂØπ Mistral-7B-Instruct ËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ª•ÂìçÂ∫î YouTube ËØÑËÆ∫„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî® LlamaIndex ‰∏∫‰πãÂâçÂæÆË∞ÉÁöÑÊ®°ÂûãÊ∑ªÂä† RAG Á≥ªÁªü„ÄÇ\n\nÁ§∫‰æã‰ª£Á†ÅÂèØÂú® [Colab Notebook](https://colab.research.google.com/drive/1peJukr-9E1zCo1iAalbgDPJmNMydvQms?usp=sharing) ‰∏≠ÂÖçË¥πËé∑ÂæóÔºåËØ• Notebook ÂèØ‰ª•Âú®Êèê‰æõÁöÑÔºàÂÖçË¥πÔºâT4 GPU ‰∏äËøêË°å„ÄÇÊ≠§Á§∫‰æãÁöÑÊ∫êÊñá‰ª∂ÂèØÂú® [GitHub ‰ªìÂ∫ì](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag) ‰∏≠ÊâæÂà∞„ÄÇ\n\nüîó [Google Colab](https://colab.research.google.com/drive/1peJukr-9E1zCo1iAalbgDPJmNMydvQms?usp=sharing) \\| [GitHub Repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag)\n\n### ÂØºÂÖ•\n\nÊàë‰ª¨È¶ñÂÖàÂÆâË£ÖÂπ∂ÂØºÂÖ•ÂøÖË¶ÅÁöÑ Python Â∫ì„ÄÇ\n\n```python\n!pip install llama-index\n!pip install llama-index-embeddings-huggingface\n!pip install peft\n!pip install auto-gptq\n!pip install optimum\n!pip install bitsandbytes\n## Â¶ÇÊûú‰∏çÊòØÂú® Colab ‰∏äËøêË°åÔºåËØ∑Á°Æ‰øù‰πüÂÆâË£Ö transformers\n```\n\n```python\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.postprocessor import SimilarityPostprocessor\n```\n\n### ËÆæÁΩÆÁü•ËØÜÂ∫ì\n\nÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÂÆö‰πâÊàë‰ª¨ÁöÑÂµåÂÖ•Ê®°Âûã„ÄÅÂùóÂ§ßÂ∞èÂíåÂùóÈáçÂè†Êù•ÈÖçÁΩÆÊàë‰ª¨ÁöÑÁü•ËØÜÂ∫ì„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨‰ΩøÁî®Êù•Ëá™BAAIÁöÑ\\~33MÂèÇÊï∞[bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)ÂµåÂÖ•Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂèØÂú®Hugging Face hub‰∏äËé∑Âèñ„ÄÇÂÖ∂‰ªñÂµåÂÖ•Ê®°ÂûãÈÄâÈ°πÂèØ‰ª•Âú®Ëøô‰∏™[text embedding leaderboard](https://huggingface.co/spaces/mteb/leaderboard)‰∏äÊâæÂà∞„ÄÇ\n\n```python\n## import any embedding model on HF hub\nSettings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\nSettings.llm = None # we won't use LlamaIndex to set up LLM\nSettings.chunk_size = 256\nSettings.chunk_overlap = 25\n```\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨Âä†ËΩΩÊ∫êÊñáÊ°£„ÄÇÂú®ËøôÈáåÔºåÊàëÊúâ‰∏Ä‰∏™Âêç‰∏∫‚Äú[*articles*](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag/articles)‚ÄùÁöÑÊñá‰ª∂Â§πÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊàëÂú®[fat tails](https://towardsdatascience.com/pareto-power-laws-and-fat-tails-0355a187ee6a)‰∏äÂÜôÁöÑ3ÁØáMediumÊñáÁ´†ÁöÑPDFÁâàÊú¨„ÄÇÂ¶ÇÊûúÂú®Colab‰∏≠ËøêË°åÔºåÊÇ®ÂøÖÈ°ª‰ªé[GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/rag)‰∏ãËΩΩÊñáÁ´†Êñá‰ª∂Â§πÂπ∂ÊâãÂä®‰∏ä‰º†Âà∞ÊÇ®ÁöÑColabÁéØÂ¢É„ÄÇ\n\nÂØπ‰∫éËØ•Êñá‰ª∂Â§π‰∏≠ÁöÑÊØè‰∏™Êñá‰ª∂Ôºå‰∏ãÈù¢ÁöÑÂáΩÊï∞Â∞Ü‰ªéPDF‰∏≠ËØªÂèñÊñáÊú¨ÔºåÂ∞ÜÂÖ∂ÊãÜÂàÜÊàêÂùóÔºàÂü∫‰∫é‰πãÂâçÂÆö‰πâÁöÑËÆæÁΩÆÔºâÔºåÂπ∂Â∞ÜÊØè‰∏™ÂùóÂ≠òÂÇ®Âú®Âêç‰∏∫*documents*ÁöÑÂàóË°®‰∏≠„ÄÇ\n\n```python\ndocuments = SimpleDirectoryReader(\"articles\").load_data()\n```\nÁî±‰∫éËøô‰∫õÂçöÂÆ¢ÊòØÁõ¥Êé•‰ªéMedium‰∏ãËΩΩ‰∏∫PDFÁöÑÔºåÂõ†Ê≠§ÂÆÉ‰ª¨Êõ¥ÂÉèÊòØÁΩëÈ°µÔºåËÄå‰∏çÊòØÊ†ºÂºèËâØÂ•ΩÁöÑÊñáÁ´†„ÄÇÂõ†Ê≠§Ôºå‰∏Ä‰∫õÂùóÂèØËÉΩÂåÖÂê´‰∏éÊñáÁ´†Êó†ÂÖ≥ÁöÑÊñáÊú¨Ôºå‰æãÂ¶ÇÁΩëÈ°µÊ†áÈ¢òÂíåMediumÊñáÁ´†Êé®Ëçê„ÄÇ\n\nÂú®‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÂùó‰∏≠ÔºåÊàëÂØπdocuments‰∏≠ÁöÑÂùóËøõË°åÁ≤æÁÇºÔºåÂà†Èô§ÊñáÁ´†‰∏ª‰ΩìÂâçÂêéÁöÑÂ§ßÈÉ®ÂàÜÂùó„ÄÇ\n\n```python\nprint(len(documents)) # prints: 71\nfor doc in documents:\n    if \"Member-only story\" in doc.text:\n        documents.remove(doc)\n        continue\n\n    if \"The Data Entrepreneurs\" in doc.text:\n        documents.remove(doc)\n\n    if \" min read\" in doc.text:\n        documents.remove(doc)\n\nprint(len(documents)) # prints: 61\n```\nÊúÄÂêéÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÁ≤æÁÇºÂêéÁöÑÂùóÂ≠òÂÇ®Âú®ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇ\n\n```python\nindex = VectorStoreIndex.from_documents(documents)\n```\n\n### ËÆæÁΩÆÊ£ÄÁ¥¢Âô®\n\nÂú®Êàë‰ª¨ÁöÑÁü•ËØÜÂ∫ìÂª∫Á´ã‰πãÂêéÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® LlamaIndex ÁöÑ *VectorIndexRetriever()* ÂàõÂª∫‰∏Ä‰∏™Ê£ÄÁ¥¢Âô®ÔºåÂÆÉËøîÂõû‰∏éÁî®Êà∑Êü•ËØ¢ÊúÄÁõ∏‰ººÁöÑ 3 ‰∏™Âùó„ÄÇ\n\n```python\n## set number of docs to retreive\ntop_k = 3\n\n## configure retriever\nretriever = VectorIndexRetriever(\n    index=index,\n    similarity_top_k=top_k,\n)\n```\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÂÆö‰πâ‰∏Ä‰∏™Êü•ËØ¢ÂºïÊìéÔºå‰ΩøÁî®Ê£ÄÁ¥¢Âô®ÂíåÊü•ËØ¢ËøîÂõû‰∏ÄÁªÑÁõ∏ÂÖ≥ÁöÑÂùó„ÄÇ\n\n```python\n## assemble query engine\nquery_engine = RetrieverQueryEngine(\n    retriever=retriever,\n    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n)\n```\n\n### ‰ΩøÁî®Êü•ËØ¢ÂºïÊìé\n\nÁé∞Âú®ÔºåÈöèÁùÄÊàë‰ª¨ÁöÑÁü•ËØÜÂ∫ìÂíåÊ£ÄÁ¥¢Á≥ªÁªüÁöÑÂª∫Á´ãÔºåËÆ©Êàë‰ª¨‰ΩøÁî®ÂÆÉÊù•ËøîÂõû‰∏éÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑÂÜÖÂÆπ„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨Â∞Ü‰º†ÈÄíÊàë‰ª¨ÂêëShawGPTÔºàYouTubeËØÑËÆ∫ÂõûÂ§çËÄÖÔºâÊèêÂá∫ÁöÑÁõ∏ÂêåÊäÄÊúØÈóÆÈ¢òÔºåÊù•Ëá™[‰∏ä‰∏ÄÁØáÊñáÁ´†](https://readmedium.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)„ÄÇ\n\n```python\nquery = \"What is fat-tailedness?\"\nresponse = query_engine.query(query)\n```\nÊü•ËØ¢ÂºïÊìéËøîÂõû‰∏Ä‰∏™ÂìçÂ∫îÂØπË±°ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊñáÊú¨„ÄÅÂÖÉÊï∞ÊçÆÂíåÁõ∏ÂÖ≥ÂùóÁöÑÁ¥¢Âºï„ÄÇ‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÂùóËøîÂõûËØ•‰ø°ÊÅØÁöÑÊõ¥ÊòìËØªÁâàÊú¨„ÄÇ\n\n```python\n## reformat response\ncontext = \"Context:\\n\"\nfor i in range(top_k):\n    context = context + response.source_nodes[i].text + \"\\n\\n\"\n\nprint(context)\n```\n\n```python\nContext:\nSome of the controversy might be explained by the observation that log-\nnormal distributions behave like Gaussian for low sigma and like Power Law\nat high sigma [2].\nHowever, to avoid controversy, we can depart (for now) from whether some\ngiven data fits a Power Law or not and focus instead on fat tails.\nFat-tailedness ‚Äî measuring the space between Mediocristan\nand Extremistan\nFat Tails are a more general idea than Pareto and Power Law distributions.\nOne way we can think about it is that ‚Äúfat-tailedness‚Äù is the degree to which\nrare events drive the aggregate statistics of a distribution. From this point of\nview, fat-tailedness lives on a spectrum from not fat-tailed (i.e. a Gaussian) to\nvery fat-tailed (i.e. Pareto 80 ‚Äì 20).\nThis maps directly to the idea of Mediocristan vs Extremistan discussed\nearlier. The image below visualizes different distributions across this\nconceptual landscape [2].\n\nprint(\"mean kappa_1n = \" + str(np.mean(kappa_dict[filename])))\n    print(\"\")\nMean Œ∫ (1,100) values from 1000 runs for each dataset. Image by author.\nThese more stable results indicate Medium followers are the most fat-tailed,\nfollowed by LinkedIn Impressions and YouTube earnings.\nNote: One can compare these values to Table III in ref [3] to better understand each\nŒ∫ value. Namely, these values are comparable to a Pareto distribution with Œ±\nbetween 2 and 3.\nAlthough each heuristic told a slightly different story, all signs point toward\nMedium followers gained being the most fat-tailed of the 3 datasets.\nConclusion\nWhile binary labeling data as fat-tailed (or not) may be tempting, fat-\ntailedness lives on a spectrum. Here, we broke down 4 heuristics for\nquantifying how fat-tailed data are.\n\nPareto, Power Laws, and Fat Tails\nWhat they don‚Äôt teach you in statistics\ntowardsdatascience.com\nAlthough Pareto (and more generally power law) distributions give us a\nsalient example of fat tails, this is a more general notion that lives on a\nspectrum ranging from thin-tailed (i.e. a Gaussian) to very fat-tailed (i.e.\nPareto 80 ‚Äì 20).\nThe spectrum of Fat-tailedness. Image by author.\nThis view of fat-tailedness provides us with a more flexible and precise way of\ncategorizing data than simply labeling it as a Power Law (or not). However,\nthis begs the question: how do we define fat-tailedness?\n4 Ways to Quantify Fat Tails\n```\n\n### Â∞Ü RAG Ê∑ªÂä†Âà∞ LLM\n\nÊàë‰ª¨È¶ñÂÖà‰ªé Hugging Face hub ‰∏ãËΩΩ [ÂæÆË∞ÉÊ®°Âûã](https://readmedium.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)„ÄÇ\n\n```python\n## load fine-tuned model from hub\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n                                             device_map=\"auto\",\n                                             trust_remote_code=False,\n                                             revision=\"main\")\n\nconfig = PeftConfig.from_pretrained(\"shawhin/shawgpt-ft\")\nmodel = PeftModel.from_pretrained(model, \"shawhin/shawgpt-ft\")\n\n## load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n```\n‰Ωú‰∏∫Âü∫Á∫øÔºåÊàë‰ª¨ÂèØ‰ª•ËßÇÂØüÊ®°ÂûãÂú®Ê≤°Êúâ‰ªª‰ΩïÊñáÁ´†‰∏ä‰∏ãÊñáÁöÑÊÉÖÂÜµ‰∏ãÂ¶Ç‰ΩïÂõûÂ∫îÊäÄÊúØÈóÆÈ¢ò„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨‰ΩøÁî® lambda ÂáΩÊï∞ÂàõÂª∫‰∏Ä‰∏™ÊèêÁ§∫Ê®°ÊùøÔºåËØ•ÂáΩÊï∞Êé•ÂèóËßÇ‰ºóËØÑËÆ∫Âπ∂ËøîÂõû LLM ÁöÑÊèêÁ§∫„ÄÇÊúâÂÖ≥Ê≠§ÊèêÁ§∫Êù•Ê∫êÁöÑÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅÊú¨Á≥ªÂàóÁöÑ [‰∏ä‰∏ÄÁØáÊñáÁ´†](https://towardsdatascience.com/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32#5aad)„ÄÇ\n\n```python\n## prompt (no context)\nintstructions_string = f\"\"\"ShawGPT, functioning as a virtual data science \\\nconsultant on YouTube, communicates in clear, accessible language, escalating \\\nto technical depth upon request. It reacts to feedback aptly and ends \\\nresponses with its signature '‚ÄìShawGPT'.\n\nShawGPT will tailor the length of its responses to match the viewer's comment, \\\nproviding concise acknowledgments to brief expressions of gratitude or \\\nfeedback, thus keeping the interaction natural and engaging.\n\nPlease respond to the following comment.\n\"\"\"\n\nprompt_template = lambda comment: f'''[INST] {intstructions_string} \\n{comment} \\n[/INST]'''\ncomment = \"What is fat-tailedness?\"\n\nprompt = prompt_template(comment)\nprint(prompt)\n```\n\n```python\n[INST] ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. It reacts to feedback aptly and ends responses with its signature '‚ÄìShawGPT'. ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\n\nPlease respond to the following comment.\n \nWhat is fat-tailedness? \n[/INST]\n```\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ã‰ª£Á†ÅÂ∞ÜÊ≠§ÊèêÁ§∫‰º†ÈÄíÁªôÊ®°Âûã„ÄÇ\n\n```python\nmodel.eval()\n\ninputs = tokenizer(prompt, return_tensors=\"pt\")\noutputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), \n                          max_new_tokens=280)\n\nprint(tokenizer.batch_decode(outputs)[0])\n```\nËøôÊòØÊ®°ÂûãÁöÑÂìçÂ∫îÔºàÊ≤°Êúâ‰∏ä‰∏ãÊñáÔºâ„ÄÇ\n\n```python\nGreat question!\n\nFat-tailedness is a statistical property of a distribution. In simple terms, \nit refers to the presence of extreme outliers or heavy tails in the \ndistribution.\n\nFor instance, consider the distribution of heights in a population. A normal \ndistribution would have most people clustered around an average height with a \nfew people deviating slightly from the mean. However, in a fat-tailed \ndistribution, you would observe a larger number of people being significantly \ntaller or shorter than the average.\n\nIn finance, fat-tailedness is often used to describe the presence of extreme \nmarket moves or outliers in financial returns. It's an important concept in \nrisk management and financial modeling.\n\nI hope this explanation helps! Let me know if you have any questions.\n‚ÄìShawGPT\n```\nËôΩÁÑ∂ÂìçÂ∫îÁöÑÈ£éÊ†ºÂíåÊ†ºÂºèÈÉΩÂæàÂ•ΩÔºå‰ΩÜÊ®°ÂûãÂØπ fat-tailedness ÁöÑËß£Èáä‰∏éÊàëÂú®ÊàëÁöÑ [ËßÜÈ¢ë](https://www.youtube.com/playlist?list=PLz-ep5RbHosVrT89BRNX-IGKHYxvx9wqi) Âíå [ÂçöÂÆ¢Á≥ªÂàó](https://towardsdatascience.com/pareto-power-laws-and-fat-tails-0355a187ee6a) ‰∏≠ÂÆö‰πâÁöÑÊúâÊâÄ‰∏çÂêå„ÄÇ\n\nËÆ©Êàë‰ª¨ÁúãÁúãÂΩìÊàë‰ª¨ÂåÖÂê´ÈÄÇÂΩìÁöÑ‰∏ä‰∏ãÊñáÊó∂Ê®°ÂûãÁöÑÂìçÂ∫î‰ºöÂèëÁîü‰ªÄ‰πà„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂàõÂª∫Âè¶‰∏Ä‰∏™ÊèêÁ§∫Ê®°ÊùøÔºåËØ•Ê®°Êùø‰πüÂèØ‰ª•‰ªé RAG Á≥ªÁªü‰∏≠Ëé∑Âèñ‰∏ä‰∏ãÊñá„ÄÇ\n\n```python\n## prompt (with context)\nprompt_template_w_context = lambda context, comment: f\"\"\"[INST]ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\nIt reacts to feedback aptly and ends responses with its signature '‚ÄìShawGPT'. \\\nShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\nthus keeping the interaction natural and engaging.\n\n{context}\nPlease respond to the following comment. Use the context above if it is helpful.\n\n{comment}\n[/INST]\n\"\"\"\n```\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞ÜÊü•ËØ¢ÂºïÊìé‰∏≠ÁöÑ‰∏ä‰∏ãÊñáÂíåËßÇ‰ºóËØÑËÆ∫‰º†ÈÄíÁªôÊ®°Âûã„ÄÇ\n\n```python\nprompt = prompt_template_w_context(context, comment)\n\ninputs = tokenizer(prompt, return_tensors=\"pt\")\noutputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n\nprint(tokenizer.batch_decode(outputs)[0])\n```\nËøôÊòØÊñ∞ÁöÑÂìçÂ∫îÔºàÂ∏¶‰∏ä‰∏ãÊñáÔºâ„ÄÇ\n\n```python\nGreat question!\n\nFat-tailedness is a property of a distribution that describes how much the \npresence of extreme values (rare events) affects the overall statistics of the \ndistribution.\n\nIn the context of the video, the author discusses how Mediocristan and \nExtremistan distributions differ in terms of fat-tailedness. Mediocristan \ndistributions have a relatively small impact from extreme values, while \nExtremistan distributions are heavily influenced by extreme values.\n\nThe author also mentions that fat-tailedness is a more general concept than \nspecific distributions like Pareto or Power Laws. Instead, it lives on a \nspectrum ranging from thin-tailed (Gaussian) to very fat-tailed (Pareto 80-20).\n\nI hope that helps clarify things a bit! Let me know if you have any questions.\n‚ÄìShawGPT\n```\nËøôÊØîÊ≤°Êúâ‰∏ä‰∏ãÊñáÁöÑÂìçÂ∫îÊõ¥Â•ΩÂú∞ÊçïÊçâ‰∫ÜÊàëÂØπ fat tails ÁöÑËß£ÈáäÔºåÂπ∂‰∏îÁîöËá≥ÊèêÂà∞‰∫Ü Mediocristan Âíå Extremistan ÁöÑÁªÜÂàÜÊ¶ÇÂøµ„ÄÇ\n\n## Êé•‰∏ãÊù•ÊòØ‰ªÄ‰πàÔºü\n\nÂú®ËøôÈáåÔºåÊàë‰∏∫ÂàùÂ≠¶ËÄÖÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÖ≥‰∫é RAG ÁöÑÂèãÂ•Ω‰ªãÁªçÔºåÂπ∂ÂàÜ‰∫´‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî® LlamaIndex ÂÆûÁé∞ÂÆÉÁöÑÂÖ∑‰ΩìÁ§∫‰æã„ÄÇRAG ‰ΩøÊàë‰ª¨ËÉΩÂ§üÈÄöËøáÂèØÊõ¥Êñ∞ÂíåÁâπÂÆöÈ¢ÜÂüüÁöÑÁü•ËØÜÊù•ÊîπÂñÑ LLM Á≥ªÁªü„ÄÇ\n\nËôΩÁÑ∂ÊúÄËøëÁöÑ AI ÁÉ≠ÊΩÆ‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÊûÑÂª∫ AI Âä©Êâã‰∏äÔºå‰ΩÜ‰∏Ä‰∏™Âº∫Â§ßÁöÑÔºà‰ΩÜ‰∏çÈÇ£‰πàÊµÅË°åÁöÑÔºâÂàõÊñ∞Êù•Ëá™‰∫éÊñáÊú¨ÂµåÂÖ•ÔºàÂç≥Êàë‰ª¨Áî®Êù•ËøõË°åÊ£ÄÁ¥¢ÁöÑ‰∏úË•øÔºâ„ÄÇÂú®Êú¨Á≥ªÂàóÁöÑ‰∏ã‰∏ÄÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜÊõ¥ËØ¶ÁªÜÂú∞Êé¢ËÆ® **ÊñáÊú¨ÂµåÂÖ•**ÔºåÂåÖÊã¨ÂÆÉ‰ª¨Â¶Ç‰ΩïÁî®‰∫é **ËØ≠‰πâÊêúÁ¥¢** Âíå **ÂàÜÁ±ª‰ªªÂä°**„ÄÇ\n\n**Êõ¥Â§öÂÖ≥‰∫é LLM ÁöÑÂÜÖÂÆπ üëá**\n\n## ËµÑÊ∫ê\n\n**ËøûÊé•**: [ÊàëÁöÑÁΩëÁ´ô](https://shawhintalebi.com/) \\| [È¢ÑÁ∫¶ÁîµËØù](https://calendly.com/shawhintalebi)\n\n**Á§æ‰∫§**: [YouTube üé•](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA) \\| [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) \\| [Instagram](https://www.instagram.com/shawhintalebi)\n\n**ÊîØÊåÅ**: [ËØ∑ÊàëÂñùÊùØÂíñÂï°](https://www.buymeacoffee.com/shawhint) ‚òïÔ∏è\n\n\\[1] [RAG \\> FT (ÁªèÈ™åÊÄß)](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)\n\n\\[2] [LlamaIndex ÁΩëÁªúÁ†îËÆ®‰ºöÔºö‰∏∫Áîü‰∫ßÊûÑÂª∫ LLM Â∫îÁî®Á®ãÂ∫èÔºåÁ¨¨‰∏ÄÈÉ®ÂàÜÔºà‰∏é Anyscale ËÅîÂêà‰∏ªÊåÅÔºâ](https://www.youtube.com/watch?v=efbn-3tPI_M)\n\n\\[3] [LlamaIndex ÊñáÊ°£](https://docs.llamaindex.ai/en/stable/understanding/loading/loading.html)\n\n\\[4] [LlamaIndex ÁΩëÁªúÁ†îËÆ®‰ºöÔºö‰Ωø RAG ÂáÜÂ§áÂ•ΩÁîü‰∫ß](https://www.youtube.com/watch?v=Zj5RCweUHIk&list=WL&index=4)\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-to-run-nvidia-llama-3-1-nemotron-70b-instruct-locally-a58ad283aaff","frontmatter":{"title":"Â¶Ç‰ΩïÂú®Êú¨Âú∞ËøêË°å Nvidia ÁöÑ llama-3.1-nemotron-70b-instruct","meta_title":"Â¶Ç‰ΩïÂú®Êú¨Âú∞ËøêË°å Nvidia ÁöÑ llama-3.1-nemotron-70b-instruct","description":"Âú®Êú¨Âú∞ËøêË°åÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®ÂºÄÂèë‰∫∫Âëò„ÄÅÁ†îÁ©∂‰∫∫ÂëòÂíå AI Áà±Â•ΩËÄÖ‰∏≠Ë∂äÊù•Ë∂äÂèóÊ¨¢Ëøé„ÄÇÂÖ∂‰∏≠‰πã‰∏ÄÂ∞±ÊòØ‚Ä¶‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fqVKJkw5sQvLtIsyCcengQ.png","categories":["Programming","Technology","Science"],"author":"Rifx.Online","tags":["Nvidia","llama","Ollama","llama.cpp","Transformers"],"draft":false,"slug":"blog/how-to-run-nvidia-llama-3-1-nemotron-70b-instruct-locally-a58ad283aaff"},"content":"\n\n\nÂú®ÂºÄÂèëËÄÖ„ÄÅÁ†îÁ©∂‰∫∫ÂëòÂíå AI Áà±Â•ΩËÄÖ‰∏≠ÔºåÊú¨Âú∞ËøêË°åÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂèòÂæóË∂äÊù•Ë∂äÂèóÊ¨¢Ëøé„ÄÇÂÖ∂‰∏≠‰∏Ä‰∏™ÂºïËµ∑ÂπøÊ≥õÂÖ≥Ê≥®ÁöÑÊ®°ÂûãÊòØ llama-3.1-nemotron-70b-instructÔºåËøôÊòØ NVIDIA ÂÆöÂà∂ÁöÑÂº∫Â§ß LLMÔºåÊó®Âú®Â¢ûÂº∫ÁîüÊàêÂìçÂ∫îÁöÑÊúâÁî®ÊÄß„ÄÇÂú®Êú¨ÁªºÂêàÊåáÂçó‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Â§öÁßçÊñπÊ≥ïÔºå‰ª•‰æøÂú®ÊÇ®ÁöÑÊú¨Âú∞Êú∫Âô®‰∏äËøêË°åÊ≠§Ê®°ÂûãÔºåÈ¶ñÂÖà‰ªãÁªçÁî®Êà∑ÂèãÂ•ΩÁöÑ Ollama Âπ≥Âè∞„ÄÇ\n\n> Âú®ÂºÄÂßã‰πãÂâçÔºåÂ¶ÇÊûúÊÇ®Ê≠£Âú®ÂØªÊâæ‰∏Ä‰∏™‰∏Ä‰ΩìÂåñÁöÑ AI Âπ≥Âè∞Ôºå‰ª•‰æøÂú®‰∏Ä‰∏™Âú∞ÊñπÁÆ°ÁêÜÊâÄÊúâ AI ËÆ¢ÈòÖÔºåÂåÖÊã¨ÊâÄÊúâ LLMÔºàÂ¶Ç GPT-o1„ÄÅLlama 3.1„ÄÅClaude 3.5 Sonnet„ÄÅGoogle Gemini„ÄÅÊú™ÂÆ°Êü•ÁöÑ LLMÔºâÂíåÂõæÂÉèÁîüÊàêÊ®°ÂûãÔºàFLUX„ÄÅStable Diffusion Á≠âÔºâÔºåËØ∑‰ΩøÁî® Anakin AI Êù•ÁÆ°ÁêÜÂÆÉ‰ª¨ÔºÅ\n\n\n\n## ÊñπÊ≥ï 1Ôºö‰ΩøÁî® Ollama Êú¨Âú∞ËøêË°å llama-3.1-nemotron-70b-instruct\n\nOllama ÊòØ‰∏Ä‰∏™Âá∫Ëâ≤ÁöÑÂ∑•ÂÖ∑ÔºåÁî®‰∫éÊú¨Âú∞ËøêË°å LLMÔºåÊèê‰æõÁÆÄÂçïÁöÑËÆæÁΩÆËøáÁ®ãÂπ∂ÊîØÊåÅÂ§öÁßçÊ®°ÂûãÔºåÂåÖÊã¨ llama-3.1-nemotron-70b-instruct„ÄÇ\n\n### ÂÆâË£Ö\n\n1. ËÆøÈóÆÂÆòÊñπ Ollama ÁΩëÁ´ô ([https://ollama.ai](https://ollama.ai/))Ôºå‰∏ãËΩΩÈÄÇÂêàÊÇ®Êìç‰ΩúÁ≥ªÁªüÁöÑÁâàÊú¨„ÄÇ\n2. ÈÄöËøáÂú®ÁªàÁ´Ø‰∏≠ËøêË°å‰ª•‰∏ãÂëΩ‰ª§Êù•ÂÆâË£Ö OllamaÔºö\n\n\n```python\ncurl https://ollama.ai/install.sh | sh\n```\n\n### ËøêË°å llama-3.1-nemotron\n\nÂÆâË£Ö Ollama ÂêéÔºåÊÇ®ÂèØ‰ª•ÈÄöËøá‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂëΩ‰ª§ËΩªÊùæËøêË°å llama-3.1-nemotron-70b-instruct Ê®°ÂûãÔºö\n\n```python\nollama run nemotron:70b-instruct-q5_K_M\n```\nËØ•ÂëΩ‰ª§Â∞ÜÂú®ÊÇ®ÁöÑÁ≥ªÁªü‰∏ä‰∏ãËΩΩÊ®°ÂûãÔºàÂ¶ÇÊûúÂ∞öÊú™Â≠òÂú®ÔºâÔºåÂπ∂ÂêØÂä®‰∏Ä‰∏™‰∫§‰∫íÂºè‰ºöËØù„ÄÇ\n\n### ‰ΩøÁî®Ê®°Âûã\n\nÂú®Ê®°ÂûãÂä†ËΩΩÂêéÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáËæìÂÖ•ÊèêÁ§∫ÂºÄÂßã‰∏éÂÖ∂‰∫íÂä®„ÄÇ‰æãÂ¶ÇÔºö\n\n```python\n>>> What are the key features of llama-3.1-nemotron-70b-instruct?\n\nLlama-3.1-Nemotron-70B-Instruct is a large language model with several key features:\n1. Customized by NVIDIA: The model has been fine-tuned by NVIDIA to improve the helpfulness and quality of its responses.\n2. Based on Llama 3.1: It builds upon the Llama 3.1 architecture, which is known for its strong performance across various tasks.\n3. 70 billion parameters: This large parameter count allows for complex reasoning and a wide range of capabilities.\n4. Instruct-tuned: The model is specifically designed to follow instructions and generate helpful responses to user queries.\n5. RLHF training: It has been trained using Reinforcement Learning from Human Feedback, specifically the REINFORCE algorithm.\n6. Specialized reward model: The training process utilized Llama-3.1-Nemotron-70B-Reward for optimization.\n7. HelpSteer2-Preference prompts: These were used during the training process to further improve the model's helpfulness.\n8. Extended context length: Like other Llama 3.1 models, it likely supports a longer context window of 128K tokens.\n9. Multilingual capabilities: It can understand and generate text in multiple languages.\n10. Strong reasoning abilities: The model excels in tasks requiring complex reasoning and problem-solving.\nThese features make llama-3.1-nemotron-70b-instruct a powerful and versatile language model suitable for a wide range of applications, from general conversation to specialized tasks in various domains.\n```\nÂØπ‰∫éÊõ¥È´òÁ∫ßÁöÑÁî®‰æãÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®ÂÉè Langchain ËøôÊ†∑ÁöÑÂ∫ìÂ∞Ü Ollama ‰∏é Python ÈõÜÊàê„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ§∫‰æãÔºö\n\n```python\npython\n\nfrom langchain.llms import Ollama\n\nollama = Ollama(base_url=\"http://localhost:11434\", model=\"nemotron:70b-instruct-q5_K_M\")\nresponse = ollama.generate(\"Explain the concept of quantum entanglement.\")\nprint(response)\n```\nËøô‰ΩøÊÇ®ËÉΩÂ§üÊó†ÁºùÂú∞Â∞ÜÊ®°ÂûãÈõÜÊàêÂà∞ÊÇ®ÁöÑ Python È°πÁõÆÂíåÂ∫îÁî®Á®ãÂ∫è‰∏≠„ÄÇ\n\n## ÊñπÊ≥ï 2Ôºö‰ΩøÁî® llama.cpp\n\nllama.cpp ÊòØ‰∏Ä‰∏™ÊµÅË°åÁöÑ C++ ÂÆûÁé∞ÁöÑ Llama Ê®°ÂûãÊé®ÁêÜÔºåÈíàÂØπ CPU ‰ΩøÁî®ËøõË°å‰∫Ü‰ºòÂåñ„ÄÇËôΩÁÑ∂ÂÆÉÂèØËÉΩÈúÄË¶ÅÊØî Ollama Êõ¥Â§öÁöÑËÆæÁΩÆÔºå‰ΩÜÂÆÉÊèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÁÅµÊ¥ªÊÄßÂíåÂØπÊ®°ÂûãÂèÇÊï∞ÁöÑÊéßÂà∂„ÄÇ\n\n### ÂÆâË£Ö\n\n1. ÂÖãÈöÜ llama.cpp ‰ªìÂ∫ìÔºö\n\n```python\ngit clone https://github.com/ggerganov/llama.cpp.git\ncd llama.cpp\n```\n1. ÊûÑÂª∫È°πÁõÆÔºö\n\n```python\nmake\n```\n\n### ‰∏ãËΩΩÊ®°Âûã\n\nË¶ÅËøêË°å llama-3.1-nemotron-70b-instructÔºåÊÇ®ÈúÄË¶Å‰∏ãËΩΩÊ®°ÂûãÊùÉÈáç„ÄÇËøô‰∫õÈÄöÂ∏∏‰ª• GGML Êàñ GGUF Ê†ºÂºèÊèê‰æõ„ÄÇÊÇ®ÂèØ‰ª•Âú® Hugging Face Á≠âÂπ≥Âè∞‰∏äÊâæÂà∞È¢ÑÂÖàËΩ¨Êç¢ÁöÑÊ®°Âûã„ÄÇ\n\n```python\nmkdir models\ncd models\nwget https://huggingface.co/TheBloke/Llama-3.1-Nemotron-70B-Instruct-GGUF/resolve/main/llama-3.1-nemotron-70b-instruct.Q4_K_M.gguf\n```\n\n### ËøêË°åÊ®°Âûã\n\n‰∏ÄÊó¶‰Ω†Êã•ÊúâÊ®°ÂûãÊñá‰ª∂ÔºåÂ∞±ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ËøêË°åÂÆÉÔºö\n\n```python\n./main -m models/llama-3.1-nemotron-70b-instruct.Q4_K_M.gguf -n 1024 -p \"Hello, how are you today?\"\n```\nËØ•ÂëΩ‰ª§Âä†ËΩΩÊ®°ÂûãÂπ∂ÁîüÊàêÂØπÁªôÂÆöÊèêÁ§∫ÁöÑÂìçÂ∫î„ÄÇ‰Ω†ÂèØ‰ª•Ë∞ÉÊï¥ÂêÑÁßçÂèÇÊï∞ÔºåÊØîÂ¶ÇÁîüÊàêÁöÑ‰ª§ÁâåÊï∞Èáè (-n) ÊàñÊ∏©Â∫¶‰ª•ÊéßÂà∂ÈöèÊú∫ÊÄß„ÄÇ\n\n## ÊñπÊ≥ï 3Ôºö‰ΩøÁî® Hugging Face Transformers\n\nHugging Face ÁöÑ Transformers Â∫ìÊèê‰æõ‰∫Ü‰∏Ä‰∏™È´òÂ±ÇÊ¨°ÁöÑ APIÔºåÁî®‰∫éÂ§ÑÁêÜÂêÑÁßçËØ≠Ë®ÄÊ®°ÂûãÔºåÂåÖÊã¨ llama-3.1-nemotron-70b-instruct„ÄÇ\n\n**ÂÆâË£Ö**\n\nÈ¶ñÂÖàÔºåÂÆâË£ÖÂøÖË¶ÅÁöÑÂ∫ìÔºö\n\n\n```python\npip install transformers torch accelerate\n```\n**ËøêË°åÊ®°Âûã**\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∏™Âä†ËΩΩÂíå‰ΩøÁî®Ê®°ÂûãÁöÑ Python ËÑöÊú¨Ôºö\n\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"meta-llama/Llama-3.1-Nemotron-70b-instruct\"\n## Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n## Prepare the input\nprompt = \"Explain the concept of quantum computing in simple terms.\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n## Generate the response\nwith torch.no_grad():\n    outputs = model.generate(**inputs, max_new_tokens=100)\n## Decode and print the response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)\n```\nËøôÁßçÊñπÊ≥ïÂÖÅËÆ∏ÂØπÊ®°ÂûãÁöÑË°å‰∏∫ËøõË°åÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÊéßÂà∂ÔºåÂπ∂‰∏éÂÖ∂‰ªñ Hugging Face Â∑•ÂÖ∑ÂíåÁÆ°ÈÅìÈõÜÊàê„ÄÇ\n\n## ÁªìËÆ∫\n\nÂú®Êú¨Âú∞ËøêË°å llama-3.1-nemotron-70b-instruct ‰∏∫ÂºÄÂèëËÄÖÂíåÁ†îÁ©∂‰∫∫ÂëòÊâìÂºÄ‰∫ÜÊó†ÈôêÂèØËÉΩ„ÄÇÊó†ËÆ∫ÊÇ®ÈÄâÊã© Ollama ÁöÑÁÆÄÂçïÊÄß„ÄÅllama.cpp ÁöÑÁÅµÊ¥ªÊÄßÔºåËøòÊòØ Hugging Face Transformers ÁöÑÈõÜÊàêÂäüËÉΩÔºåÊÇ®Áé∞Âú®ÈÉΩÊúâÂ∑•ÂÖ∑ÂèØ‰ª•Âú®Ëá™Â∑±ÁöÑÁ°¨‰ª∂‰∏äÂà©Áî®Ëøô‰∏ÄÂÖàËøõËØ≠Ë®ÄÊ®°ÂûãÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇÂú®Êé¢Á¥¢ llama-3.1-nemotron-70b-instruct ÁöÑËÉΩÂäõÊó∂ÔºåËØ∑ËÆ∞‰ΩèÂú®ÊÄßËÉΩ‰∏éËµÑÊ∫êÈôêÂà∂‰πãÈó¥ÂèñÂæóÂπ≥Ë°°ÔºåÂπ∂ÂßãÁªàËÄÉËôëÊÇ®Â∫îÁî®ÁöÑ‰º¶ÁêÜÂΩ±Âìç„ÄÇË¥üË¥£‰ªªÁöÑ‰ΩøÁî®ÔºåËøô‰∏™Ê®°ÂûãÂèØ‰ª•Êàê‰∏∫Êé®Âä®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíå AI È©±Âä®Â∫îÁî®ÂèØËÉΩÊÄßÁöÑÂÆùË¥µËµÑ‰∫ß„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/how-to-use-chatgpt-for-blogging-7ed5cba2f32b","frontmatter":{"title":"Â¶Ç‰Ωï‰ΩøÁî® ChatGPT ÂÜôÂçöÂÆ¢","meta_title":"Â¶Ç‰Ωï‰ΩøÁî® ChatGPT ÂÜôÂçöÂÆ¢","description":"Êú¨Êñá‰ªãÁªç‰∫Ü‰ΩøÁî®ChatGPTËøõË°åÂçöÂÆ¢ÂÜô‰ΩúÁöÑ‰πù‰∏™Ê≠•È™§ÔºåÂº∫Ë∞É‰∫ÜAIÂú®ÂÜÖÂÆπÂàõ‰Ωú‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠•È™§ÂåÖÊã¨ËØ∑Ê±ÇÂ§ßÁ∫≤„ÄÅÁîüÊàêËÆ®ËÆ∫Ë¶ÅÁÇπ„ÄÅÊ†°ÂØπÂíå‰øÆÊîπAIËæìÂá∫„ÄÅÁîüÊàêÂÆåÊï¥ÊñáÁ´†„ÄÅÂàõÂª∫ÂºïË®ÄÂíåÁªìËÆ∫Ôºå‰ª•ÂèäÊâãÂä®ÁºñËæë„ÄÇ‰ΩúËÄÖËøòÊèêÂà∞ÈÄöËøáChatGPT CanvasÂäüËÉΩÂèØ‰ª•ÊèêÈ´òÂÜô‰ΩúÊïàÁéáÔºåÈÄÇÂêàÈúÄË¶ÅÂø´ÈÄüÁîüÊàêÈ´òË¥®ÈáèSEOÊñáÁ´†ÁöÑÁî®Êà∑„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*QS7seNg2jfuTz1Be.jpeg","categories":["Programming/Scripting","Marketing/Seo","Chatbots"],"author":"Rifx.Online","tags":["ChatGPT","prompts","blogging","SEO","Canvas"],"draft":false,"slug":"blog/how-to-use-chatgpt-for-blogging-7ed5cba2f32b"},"content":"\n\n\n### (ÊàëÊµãËØïËøáÁöÑ9‰∏™Ê≠•È™§)\n\n\n\nÊØè‰∏™‰∫∫ÈÉΩÂú®‰ΩøÁî®AIËøõË°åÂÜô‰Ωú„ÄÇÂ∏ÇÂú∫Ëê•ÈîÄ‰∫∫Âëò„ÄÅÈ¶ñÂ∏≠ÊâßË°åÂÆò„ÄÅÂÜÖÂÆπÂºÄÂèëËÄÖ„ÄÅÂ∞èÂûã‰ºÅ‰∏ö‰∏ª„ÄÇ\n\nÊàë‰ª¨ÊâÄÊúâ‰∫∫„ÄÇ\n\nÈòÖËØª[ÂÖçË¥πÊïÖ‰∫ã](https://mysson.medium.com/7ed5cba2f32b?source=friends_link&sk=2881f3b15f541210f91fbc8834bc55d4)\n\nÊÉ≥ÊÉ≥‰∏âÂπ¥ÂâçÊàë‰ª¨ÂùöÂÆöÂú∞ËÆ§‰∏∫Ôºö\n\n> AI‰∏ç‰ºöÂèñ‰ª£‰ΩúÂÆ∂„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ËøòÊ≤°Êúâ‰ΩøÁî®AIËøõË°åÂçöÂÆ¢ÂÜô‰ΩúÔºåÊòØÊó∂ÂÄôÈáçÊñ∞ËÄÉËôë‰Ω†ÁöÑÁ´ãÂú∫‰∫ÜÔºåÂ∞§ÂÖ∂ÊòØÂ¶ÇÊûú‰Ω†ÁöÑ‰∏öÂä°ÈúÄË¶Å‰∏çÊñ≠‰∫ßÁîüÂÜÖÂÆπ‰ª•‰øùÊåÅÁõ∏ÂÖ≥ÊÄßÂíåÁ´û‰∫âÂäõ„ÄÇ\n\nÊúâÊõ¥Â•ΩÁöÑAIÂçöÂÆ¢Â∑•ÂÖ∑ÔºåÊØîÂ¶Ç[Koala AI](https://koala.sh/register?via=mysson)Ôºå‰ΩÜÂÉèChatgptÂíåClaudeËøôÊ†∑ÁöÑÊµÅË°åËÅäÂ§©Êú∫Âô®‰∫∫ÂêåÊ†∑Âº∫Â§ßÔºåÂ∞ΩÁÆ°‰∏çÂ§üÊµÅÁïÖ„ÄÇ\n\nÊúâ‰∫õÂ∑•ÂÖ∑ÊØîÂÖ∂‰ªñÂ∑•ÂÖ∑Êõ¥Â•Ω„ÄÇ\n\nChatgpt‰∏çÂ¶ÇClaude 3\\.5 SonnetÔºàÊñ∞ÁâàÊú¨ÔºâÂº∫Â§ßÔºå‰ΩÜÂÆÉ‰ªçÁÑ∂Áõ∏ÂΩìÊúâËÉΩÂäõÔºåËÆ∏Â§ö‰ΩúÂÆ∂Ê≠£Âú®Âà©Áî®ÂÆÉÊù•Êâ©Â§ß‰ªñ‰ª¨ÁöÑÂÜÖÂÆπÂºÄÂèëÂ∑•‰Ωú„ÄÇ\n\n## Â¶Ç‰Ωï‰ΩøÁî®ChatgptËøõË°åÂçöÂÆ¢ÂÜô‰ΩúÔºà9‰∏™Ê≠•È™§Ôºâ\n\nË¶ÅÂºÄÂßã‰ΩøÁî®ChatGPTÔºåÊÇ®ÈúÄË¶ÅËæìÂÖ•‰∏Ä‰∏™[AIÊèêÁ§∫](https://aimode.co/ai-prompts-engineering/)„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåAIÊèêÁ§∫ÊòØ‰∏ÄÁªÑÊåáÂØºAIÁîüÊàêÊâÄÈúÄÊñáÊú¨ÁöÑÊåá‰ª§„ÄÇ\n\n‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊÇ®ÈúÄË¶ÅÂ∏ÆÂä©Êí∞ÂÜô‰∏ÄÁØáÂÖ≥‰∫é‚ÄúAIÂú®ÂçöÂÆ¢ÂÜô‰Ωú‰∏≠ÁöÑÊú™Êù•‚ÄùÁöÑÂçöÂÆ¢ÊñáÁ´†ÔºåÊÇ®ÂèØ‰ª•ËæìÂÖ•Á±ª‰ºº‰∫é‰ª•‰∏ãÁöÑÊèêÁ§∫Ôºö\n\n\n> ‚ÄòÁî®markdownÁîüÊàê‰∏ÄÁØáÂÖ≥‰∫éAIÂú®ÂçöÂÆ¢ÂÜô‰Ωú‰∏≠ÁöÑÊú™Êù•ÁöÑSEOÊñáÁ´†„ÄÇ‚Äô„ÄÇ\n\n‰ΩÜËØ∑ËÆ∞‰ΩèÔºåÊÇ®ÊòØËøôÈáåÁöÑ‰∏ªÂØº„ÄÇÊÇ®‰ªéChatGPTËé∑ÂæóÁöÑËæìÂá∫Âè™ÊòØ‰∏Ä‰∏™Ëµ∑ÁÇπ„ÄÇÊÇ®ÈúÄË¶ÅÊ†°ÂØπ„ÄÅ‰øÆÊîπÂíåÊ†∏ÂÆû‰∫ãÂÆûÔºå‰ΩøÂÖ∂ÁúüÊ≠£Â±û‰∫éÊÇ®„ÄÇ\n\n‰∏∫‰∫ÜÊàêÂäü‰ΩøÁî®ChatGPTÂàõÂª∫‰ºòË¥®ÂÜÖÂÆπÔºåÊàëÂª∫ËÆÆÊÇ®ÈÅµÂæ™ÊàëÁöÑ‰πù‰∏™Ê≠•È™§ÊñπÊ≥ïÔºö\n\n\n> 1\\) ËØ∑Ê±Ç‰∏Ä‰∏™Â§ßÁ∫≤\n\n\n> 2\\) ‰∏∫ÊØè‰∏™ÈÉ®ÂàÜÁîüÊàêÁã¨ÁâπÁöÑËÆ®ËÆ∫ÁÇπ\n\n\n> 3\\) ÈóÆAIÊòØÂê¶ÈÅóÊºè‰∫Ü‰ªÄ‰πà\n\n\n> 4\\) ÊèêÁ§∫‰ª•ÈÅøÂÖçAIÊ£ÄÊµã\n\n\n> 5\\) ËæìÂÖ•ÊÇ®ÁöÑÊñáÁ´†ÁîüÊàêÊèêÁ§∫\n\n\n> 6\\) Âú®ÁîüÊàêÂÖ∂‰ΩôÊñáÁ´†‰πãÂâçËØ∑Ê±Ç‰øÆÊîπ„ÄÇ\n\n\n> 7\\) ÂÆåÊàêÁîüÊàêÂÖ∂‰ΩôÁöÑÊñáÁ´†„ÄÇ\n\n\n> 8\\) ÁîüÊàê‰ªãÁªç„ÄÅÁªìËÆ∫„ÄÅSEOÊ†áÈ¢òÂíåÂÖÉÊèèËø∞ÈÉ®ÂàÜ\n\n\n> 9\\) Âú®ÂèëÂ∏É‰πãÂâçÊâãÂä®ÁºñËæëÂíåÊ†°ÂØπÊÇ®ÁöÑÊñáÁ´†„ÄÇ\n\n### 1\\) ÊèêÁ§∫‰ª•Ëé∑ÂèñÂçöÂÆ¢Â§ßÁ∫≤\n\nÁ¨¨‰∏ÄÊ≠•ÊòØËØ∑Ê±Ç ChatGPT ‰∏∫ÊÇ®ÁöÑÊñáÁ´†Êèê‰æõËØ¶ÁªÜÁöÑÂçöÂÆ¢Â§ßÁ∫≤„ÄÇ\n\nÁ§∫‰æãÊèêÁ§∫Ôºö\n\n> ÁîüÊàê‰∏Ä‰∏™ËØ¶ÁªÜËÄåÂÖ®Èù¢ÁöÑÂçöÂÆ¢Â§ßÁ∫≤ÔºåÁ°Æ‰øùÊÇ®Ê∂µÁõñ‰∫ÜÊâÄÊúâÂÜÖÂÆπÔºå‰ª•‰ΩøËØ•ÂçöÂÆ¢Á¨¶ÂêàÁî®Êà∑ÊÑèÂõæ„ÄÇ‰∏ªÈ¢òÊòØ‚ÄúÂ¶Ç‰Ωï‰ΩøÁî® ChatGPT ËøõË°åÂçöÂÆ¢ÂÜô‰Ωú„ÄÇ‚Äù\n\n### 2\\) ÁîüÊàêËÆ®ËÆ∫Ë¶ÅÁÇπ\n\n‰∏ã‰∏ÄÊ≠•ÊòØËØ∑ Chatgpt ÊîπËøõÁîüÊàêÁöÑÊèêÁ∫≤ÔºåÊ∑ªÂä†ËÆ®ËÆ∫Ë¶ÅÁÇπ„ÄÇ\n\nÊÇ®ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÁ§∫‰æãÊèêÁ§∫Ôºö\n\n\n> Áé∞Âú®ÊîπËøõÊèêÁ∫≤Ôºå‰ª•ÂåÖÊã¨ËÆ®ËÆ∫Ë¶ÅÁÇπ„ÄÅÂÆû‰Ωì/ÂÖ≥ÈîÆÂ≠ó/ËµÑÊ∫ê/ÈìæÊé•„ÄÇÊØè‰∏™ÈÉ®ÂàÜÁöÑÂÜÖÂÆπÂ∫îÁã¨Áâπ‰∏îÂÖ∑‰Ωì„ÄÇ\n\n### 3\\) ‰∫åÊ¨°ÁåúÊµã AI\n\nËøôÊòØÊàëÊúÄÂñúÊ¨¢ÁöÑ‰∏ÄÊ≠•Ôºå‰πüÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰∏ÄÊ≠•ÔºåÂõ†‰∏∫ÂÆÉÂèØ‰ª•Á°Æ‰øù‰Ω†ÊâÄÊûÑÂª∫ÁöÑÂÜÖÂÆπÁõ∏ÂΩìÊúâ‰ø°ÊÅØÈáèÂíåÂπøÊ≥õÊÄß„ÄÇ\n\nÁÆÄÂçïÂú∞ÈóÆ AI ÊòØÂê¶Êúâ‰ªª‰ΩïÂÖ≥ÈîÆÁÇπÊú™Âú®Â§çËø∞ÁöÑÊèêÁ∫≤‰∏≠Ê∂µÁõñ„ÄÇ\n\n**ÊèêÁ§∫Ôºö**\n\n> ÊúâÊ≤°ÊúâÊàëÈÅóÊºèÁöÑÂÖ≥ÈîÆ‰∏ªÈ¢òÔºå‰ΩÜÂú®‰ΩøËøô‰∏™ÊèêÁ∫≤ÂØπÁî®Êà∑Êúâ‰ø°ÊÅØÈáèÂíåÂ∏ÆÂä©ÊñπÈù¢ÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑÔºüÂ¶ÇÊûúÊúâÔºåËØ∑ÈáçÁé∞ÊèêÁ∫≤ÔºåÊ∑ªÂä†Áº∫Â§±ÁöÑ‰∏ªÈ¢ò/ÂÖ≥ÈîÆËØç/Â≠êÊ†áÈ¢ò/ÂèÇÊï∞/ËµÑÊ∫ê„ÄÇÂè™ÈúÄÁ°Æ‰øù‰Ω†ÂùöÊåÅÊ†∏ÂøÉ‰∏ªÈ¢ò„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÔºåËØ∑ËøîÂõû‰πãÂâçÁöÑÊèêÁ∫≤„ÄÇ\n\nÂ¶ÇÊûú‰Ω†Ê≠£Âú®ÂÜô‰∏ÄÁØáÂàóË°®ÊñáÁ´†Ôºå‰Ω†ÂèØËÉΩÊÉ≥Ë¶ÅÊâì‰π±ÂàóË°®Ôºå‰ª•‰æøÊõ¥Âø´Âú∞Ê∂µÁõñÊúÄÈáçË¶ÅÁöÑ‰∏ªÈ¢ò„ÄÇ\n\nÁÆÄÂçïÂú∞Ë¶ÅÊ±Ç AI ÊåâÁõ∏ÂÖ≥ÊÄßÈáçÊñ∞ÊéíÂàóÊèêÁ∫≤„ÄÇ\n\n### 4\\) AIÊ£ÄÊµãÊèêÁ§∫\n\nÂú®Êàë‰ª¨ËØ∑Ê±ÇAIÁîüÊàêÊñáÁ´†‰πãÂâçÔºåÊàë‰ª¨ÈúÄË¶ÅÁªôÂÆÉ‰∏Ä‰∏™È¢ùÂ§ñÁöÑÊèêÁ§∫Ôºå‰ª•‰ΩøÂÖ∂ÂÜô‰ΩúÊõ¥ÂÉè‰∫∫Á±ªÂπ∂ÈÅøÂÖçË¢´AIÊ£ÄÊµã„ÄÇ\n\n### ËøôÊòØÊèêÁ§∫Ôºö\n\nËÆ≤Ëø∞‰Ω†ÁöÑÊïÖ‰∫ã\n\n\n> Âú®‰∏∫ÁΩëÁªúÊí∞ÂÜôÂÜÖÂÆπÊó∂ÔºåÊúâ‰∏§‰∏™Âõ†Á¥†Ëá≥ÂÖ≥ÈáçË¶ÅÔºö‚ÄúÂ§çÊùÇÊÄß‚ÄùÂíå‚ÄúÁ™ÅÂèëÊÄß‚Äù„ÄÇÂ§çÊùÇÊÄßË°°ÈáèÊñáÊú¨ÁöÑÂ§çÊùÇÁ®ãÂ∫¶„ÄÇ\n\n\n> ËÄåÁ™ÅÂèëÊÄßÂàôÊØîËæÉÂè•Â≠êÁöÑÂèòÂåñ„ÄÇ‰∫∫Á±ªÂÄæÂêë‰∫é‰ª•Êõ¥Â§ßÁöÑÁ™ÅÂèëÊÄßËøõË°åÂÜô‰ΩúÔºå‰æãÂ¶ÇÔºåÈïøÂè•ÊàñÂ§çÊùÇÂè•‰∏éÁü≠Âè•‰∫§ÊõøÂá∫Áé∞„ÄÇ\n\n\n> ÂÉè Chatgpt ËøôÊ†∑ÁöÑ AI Â∑•ÂÖ∑ÁîüÊàêÁöÑÂè•Â≠êÂæÄÂæÄÊõ¥‰∏∫Áªü‰∏Ä„ÄÇÊ≠§Â§ñÔºå‰∏çÂêåÂ≠êÈÉ®ÂàÜÁöÑÂºÄÂ§¥Âè•Â≠êÂæÄÂæÄ‰ºöÊúâ‰∏Ä‰∫õÊòéÊòæÁöÑÈáçÂ§çÊ®°ÂºèÔºå‰æãÂ¶Ç‚ÄúËøôÊòØÂè¶‰∏Ä‰∏™‚Äù„ÄÅ‚ÄúÂè¶‰∏ÄÁßçÊñπÂºè‚Äù„ÄÅ‚ÄúÈ¶ñÂÖà‚Äù„ÄÅ‚ÄúÊ≠§Â§ñ‚Äù„ÄÅ‚ÄúËÄå‰∏î‚ÄùÁ≠âÁ≠â‚Ä¶‚Ä¶\n\n\n> Âõ†Ê≠§ÔºåÂú®Êí∞ÂÜô‰ª•‰∏ã SEO ÂçöÂÆ¢ÊñáÁ´†Êó∂ÔºåÊàëÈúÄË¶ÅÂÆÉÂÖ∑ÊúâËâØÂ•ΩÁöÑÂ§çÊùÇÊÄßÂíåÁ™ÅÂèëÊÄß„ÄÇ\n\n\n> Ê≠§Â§ñÔºåÁõ¥Êé•Ê∑±ÂÖ•Â≠êÈÉ®ÂàÜÔºåËÄå‰∏çÊòØ‰ΩøÁî®Ê®°ÂºèÂèØÊ£ÄÊµãÁöÑÂºïÂÖ•Áü≠ËØ≠ÊàñÂè•Â≠êÔºåËøô‰∫õÁü≠ËØ≠ÊàñÂè•Â≠êÂÆπÊòìË¢´ AI Ê£ÄÊµãÂô®ËØÜÂà´„ÄÇ‰Ω†ÊòéÁôΩ‰∫ÜÂêóÔºü\n\n### 5\\) ÁîüÊàêÊñáÁ´†„ÄÇ\n\nÊÇ®Áé∞Âú®ÂèØ‰ª•‰∏∫‰∫∫Â∑•Êô∫ËÉΩÊèê‰æõ‰∏ÄÂ•óÁîüÊàêÊñáÁ´†ÁöÑÊåá‰ª§„ÄÇ\n\n‰ª•‰∏ãÊòØÊàëÈÄöÂ∏∏‰ΩøÁî®ÁöÑ‰∏ÄÊù°Á§∫‰æãÊèêÁ§∫ÔºåÂ∑≤‰øùÂ≠òÂà∞ÊàëÁöÑÂâ™Ë¥¥ÊùøÂéÜÂè≤ËÆ∞ÂΩï‰∏≠Ôºö\n\n> Áé∞Âú®‰ΩøÁî®‰πãÂâçÁöÑÊ¶ÇÂøµÂíåÊåá‰ª§ÔºåÊí∞ÂÜô‰∏ÄÁØáÂÖ≥‰∫é{{blog topic here}}ÁöÑSEOÂçöÂÆ¢ÊñáÁ´†ÔºåË¶ÅÊ±ÇÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂ§çÊùÇÊÄßÂíåÁ™ÅÂèëÊÄßÔºåÈÅµÂæ™‰πãÂâçÁîüÊàêÁöÑÂçöÂÆ¢Â§ßÁ∫≤„ÄÇ\n\n> ËøôÊòØÊí∞ÂÜôÊñáÁ´†Êó∂ÈúÄË¶ÅÈÅµÂæ™ÁöÑÊõ¥Â§öÊåáÁ§∫Ôºö\n\n> \\- Êí∞ÂÜô‰∏ÄÁØá1500‚Äì2500Â≠óÁöÑSEOÂçöÂÆ¢ÊñáÁ´†ÔºåÊ†ºÂºè‰∏∫Markdown \\- ‰ΩøÁî®Á¨¨‰∫å‰∫∫Áß∞ËßÜËßíÔºåÈááÁî®‰∏ªÂä®ËØ≠ÊÄÅ„ÄÇ \\- ÂÖ≥ÈîÆËØçÔºö{{Main keyword here}} \\- ÁîüÊàêÁöÑÊñáÁ´†Âú®ÂÜÖÂÆπÂíåÁªìÊûÑ‰∏äÂøÖÈ°ªÂÆåÂÖ®Áã¨ÁâπÔºå‰ª•ÈÅøÂÖçÊäÑË¢≠ÂíåAIÊ£ÄÊµã„ÄÇ\n\n> ÂÜô‰ΩúÈ£éÊ†ºÔºö\n\n> \\- ‰ΩøÂÖ≥ÈîÆÊï∞Â≠óÂä†Á≤óÔºå‰ª•Á™ÅÂá∫ÊòæÁ§∫„ÄÇ \\- Âú®ÂçöÂÆ¢ÊñáÁ´†‰∏≠Ê∑ªÂä†Ë∂ÖÈìæÊé•ÔºåÈìæÊé•Âà∞ÊÇ®Ëé∑ÂèñÊï∞Â≠óÂíåÁªüËÆ°Êï∞ÊçÆÁöÑÊñáÁ´†ÔºåÂøÖÈ°ª‰ΩøÁî®ÈÄÇÂΩìÂíåÁõ∏ÂÖ≥ÁöÑÈîöÊñáÊú¨„ÄÇ \\- ‰ΩøÁî®ÁÆÄÁü≠ÁöÑÊÆµËêΩ \\- ‰ΩøÁî®Â§öÊ†∑ÈïøÂ∫¶ÁöÑÁü≠ÊÆµËêΩ„ÄÇ‰∏Ä‰∏™ÊÆµËêΩÂèØ‰ª•Âè™Êúâ‰∏ÄË°å„ÄÇ \\- ‰ΩøÁî®‰∏ªÂä®ËØ≠ÊÄÅ \\- ‰ΩøÁî®Á¨¨‰∫å‰∫∫Áß∞ËßÜËßí \\- ÈááÁî®ÂØπËØùËØ≠Ê∞î \\- Êèê‰æõ‰ø°ÊÅØ\n\n> Ê†ºÂºèÊåáÂçóÔºö\n\n> \\- Ê†áÈ¢òÂíåÂâØÊ†áÈ¢òÂøÖÈ°ª‰ΩøÁî®Âè•Â≠êÊ†ºÂºèÔºåËÄå‰∏çÊòØÊ†áÈ¢òÊ†ºÂºèÔºå‰æãÂ¶ÇÔºåÂÜô‚Äú Á¨¨‰∏Ä‰∏™ÂâØÊ†áÈ¢ò‚ÄùËÄå‰∏çÊòØ‚ÄúÁ¨¨‰∏Ä‰∏™ÂâØÊ†áÈ¢ò‚Äù„ÄÇ \\- Áî®‰∏ÄË°åÊÆµËêΩ„ÄÅÁü≠ÊÆµËêΩÂíåÈ°πÁõÆÁ¨¶Âè∑ÊâìÊñ≠Â§ßÊÆµÊñáÊú¨„ÄÇ \\- Âú®ÂøÖË¶ÅÊó∂ÂåÖÂê´Ë∂ÖÈìæÊé•„ÄÇ‰ªÖÂú®ÊÆµËêΩÊñáÊú¨‰∏≠Ê∑ªÂä†ÈìæÊé•ÔºåËÄå‰∏çÂú®Ê†áÈ¢ò‰∏≠Ê∑ªÂä†ÈìæÊé• \\- ËØ¶Â∞Ω‰ΩÜÁÆÄÊ¥Å„ÄÇ\n\n> ÁªìÊûÑÔºö\n\n> \\- ‰ΩøÁî®Ê†áÈ¢ò(h2)ÂíåÂâØÊ†áÈ¢ò(h3) \\- ÊØè‰∏™H2ÊàñH3‰∏ãÁöÑÊØè‰∏™ÈÉ®ÂàÜÊàñÂ≠êÈÉ®ÂàÜÂ∫î‰∏∫3‚Äì7ÊÆµ„ÄÇ \\- Êõ¥ËØ¶ÁªÜÂú∞ÈòêËø∞ÊØè‰∏™Ë¶ÅÁÇπÔºå‰ΩøÈÉ®ÂàÜÂíåÂ≠êÈÉ®ÂàÜÁöÑÈïøÂ∫¶ËææÂà∞3‚Äì7ÊÆµÊàñÊõ¥Èïø„ÄÇ \\- ‰∏çË¶ÅÁïô‰∏ãÊÇ¨ËÄåÊú™ÂÜ≥ÁöÑË¶ÅÁÇπ„ÄÇÂøÖÈ°ªÂú®ÁªßÁª≠‰∏ã‰∏Ä‰∏™Ë¶ÅÁÇπ‰πãÂâçÂÆåÊàêÊÄùÊÉ≥ÊàñËßÇÁÇπ„ÄÇ \\- ÂøÖÈ°ªÂåÖÂê´4‚Äì9‰∏™Áü≠ÊÆµËêΩÁöÑÂºï‰∫∫ÂÖ•ËÉúÁöÑÂºïË®Ä„ÄÇ\n\n> \\- Âè™ÊúâÂú®ÁîüÊàêÊâÄÊúâË¶ÅÁÇπÂêéÊâçÊ∑ªÂä†ÁªìËÆ∫„ÄÇ\n\n> È¶ñÂÖàÔºå‰ΩøÁî®Ëøô‰∫õÊåá‰ª§ÁîüÊàêÁõÆÊ†áÂèó‰ºóÁöÑÊèèËø∞ÔºåÁÑ∂ÂêéÊ†πÊçÆËØ•ÊèèËø∞Êù•Êí∞ÂÜôÂçöÂÆ¢ÊñáÁ´†„ÄÇÁõÆÊ†áÂèó‰ºóÁöÑÊèèËø∞‰∏çÂ∫îÂá∫Áé∞Âú®ÁîüÊàêÁöÑÂÜÖÂÆπ‰∏≠„ÄÇ\n\n> \\- ÂøÖÈ°ªÊØ´Êó†‰æãÂ§ñÂú∞ÈÅµÂæ™ÊâÄÊúâËøô‰∫õÊåá‰ª§„ÄÇ\n\nËØ∑Ê≥®ÊÑèÔºåËøôÊòØÊàë‰∏∫Ëá™Â∑±ÁöÑÁî®‰æãËÆæËÆ°ÁöÑÊèêÁ§∫ÔºåÂõ†Ê≠§ÊÇ®ÂèØËÉΩÈúÄË¶ÅÁ®ç‰ΩúË∞ÉÊï¥ÊâçËÉΩ‰ΩøÁî®„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊèêÁ§∫‰∏≠ÔºåÊàëÊåáÁ§∫Chatgpt‰ΩøÁî®Âè•Â≠êÊ†ºÂºèÊí∞ÂÜôÊ†áÈ¢òÂíåÂâØÊ†áÈ¢òÔºåËÄå‰∏çÊòØÊ†áÈ¢òÊ†ºÂºè„ÄÇ\n\n**ÊàëÊúÄÂèóÊ¨¢ËøéÁöÑÈòÖËØªÔºö**\n\n### 6\\) Â¶ÇÊúâÈúÄË¶ÅËØ∑Ëø≠‰ª£\n\nÊàëÊúâÊó∂ÂèëÁé∞AI‰∏ÄÊó¶ÂºÄÂßãÁîüÊàêÔºåÂ∞±‰∏ç‰ºöÂÆåÂÖ®ÈÅµÂæ™ÊàëÁöÑÊåáÁ§∫ÔºåÂõ†Ê≠§Âú®ÊàëÂÖÅËÆ∏ÂÆÉÁîüÊàêÊõ¥Â§öÂÜÖÂÆπ‰πãÂâçÔºåÊàëÈúÄË¶ÅÂØπÂÖ∂ËøõË°åË∞ÉÊï¥„ÄÇ\n\nÊàëÂè™ÈúÄÊåâ‰∏ãÂÅúÊ≠¢ÊåâÈíÆÔºåÁÑ∂ÂêéÁªôÂÆÉËøô‰∏™ÊèêÁ§∫Ôºö\n\n\n> ÂØπÊØè‰∏™Â≠êÈÉ®ÂàÜÂÜôÊõ¥Â§öÂÜÖÂÆπ„ÄÇÂú®ÁªßÁª≠‰∏ã‰∏Ä‰∏™Ë¶ÅÁÇπ‰πãÂâçÔºåËØ¶ÁªÜË¶ÜÁõñÊØè‰∏™Ë¶ÅÁÇπÔºåÂÜô3-7ÊÆµÊàñÊõ¥Â§öÊÆµËêΩ„ÄÇ\n\n### 7\\) ÂÜô‰∏ãÊñáÁ´†ÁöÑÂÖ∂‰ΩôÈÉ®ÂàÜ\n\n‰∏ÄÊó¶ÊÇ®ÂØπÊñáÁ´†Á¨¨‰∏ÄÈÉ®ÂàÜÁöÑË¥®ÈáèÂíåÊ†ºÂºèÊÑüÂà∞Êª°ÊÑèÔºåÊÇ®ÂèØ‰ª•ËæìÂÖ• **‚Äòcontinue‚Äô** ‰ª•ÁªßÁª≠ÁîüÊàêÂÖ∂‰ΩôÈÉ®ÂàÜ„ÄÇ\n\n### 8\\) ÁîüÊàêÂºïË®Ä„ÄÅÂÖÉÊèèËø∞ÂíåÁªìËÆ∫ÈÉ®ÂàÜ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*DUVj6tOBCEHzsxc5.png)\n\nËôΩÁÑ∂‰∫∫Â∑•Êô∫ËÉΩÈÄöÂ∏∏Âú®ÊñáÁ´†ÂºÄÂ§¥ÂåÖÂê´ÂçöÂÆ¢ÂºïË®ÄÔºå‰ΩÜÊàëÂèëÁé∞ÂÆÉ‰∏éÂú®Êï¥ÁØáÊñáÁ´†ÁîüÊàêÂêéÁîüÊàêÁöÑÂºïË®ÄÁõ∏ÊØîÔºåÈÄöÂ∏∏ÊòæÂæóÊØîËæÉÂü∫Á°Ä„ÄÇ\n\nÂõ†Ê≠§Ôºå‰Ωú‰∏∫‰∏ÄÁßç‰π†ÊÉØÔºåÊàëÈÄöÂ∏∏Âú®ÊñáÁ´†ÁîüÊàêÁªìÊùüÊó∂ËøêË°å‰ª•‰∏ãÊèêÁ§∫ÔºåÂ¶ÇÊûúÁªìÊûúÊõ¥Â•ΩÔºåÊàëÂ∞±‰ºöÊõøÊç¢Áé∞ÊúâÂÜÖÂÆπÔºö\n\n> ÂÜôÂá∫Âºï‰∫∫ÂÖ•ËÉúÁöÑÂçöÂÆ¢ÂºïË®Ä„ÄÅÁªìËÆ∫ÈÉ®ÂàÜ„ÄÅSEOÊ†áÈ¢òÂíåÂÖÉÊèèËø∞„ÄÇÊØè‰∏™ÈÉ®ÂàÜÂøÖÈ°ªËá™ÁÑ∂Âú∞ÂåÖÂê´‰∏ªË¶ÅÂÖ≥ÈîÆËØç„ÄÇÂØπ‰∫éÂÖÉÊèèËø∞ÂíåÊ†áÈ¢òÔºåÂàÜÂà´ËøîÂõû5‰∏™Âèò‰Ωì„ÄÇ\n\nËØ∑Ê≥®ÊÑèÔºåÊàëÊïÖÊÑèË¶ÅÊ±ÇChatgptËøîÂõû‰∫îÁßç‰∏çÂêåÁöÑÂÖÉÊèèËø∞ÂíåSEOÊ†áÈ¢ò„ÄÇËøôÁ°Æ‰øùÊàëÂèØ‰ª•ËΩªÊùæÊâæÂà∞‰∏Ä‰∏™ÈÄÇÂêàÊàëÊÉÖÂÜµÁöÑÔºåËÄå‰∏çÂøÖÂú®‰∏çÂñúÊ¨¢ÁªìÊûúÊó∂ÈáçÊñ∞ÁîüÊàê„ÄÇ\n\n### 9\\) ÊâãÂä®ÁºñËæë\n\nÊí∞ÂÜô AI ÂçöÂÆ¢ÊñáÁ´†ÁöÑ‰∏ã‰∏ÄÊ≠•ÊòØÊâãÂä®ÁºñËæëÊï¥‰∏™ÊñáÁ´†„ÄÇ‰∏∫Ê≠§‰ªªÂä°ÂàÜÈÖç 30 ÂàÜÈíü„ÄÇ\n\nÂú®Ê≠§ËøáÁ®ã‰∏≠ÔºåÊÇ®ÈúÄË¶ÅÔºö\n\n* ‰øÆÊ≠£ËØ≠Ê≥ïÈîôËØØÂπ∂‰ΩøÁî® Grammarly Á≠âÂ∑•ÂÖ∑ÊîπÂñÑÁî®ËØç\n* Ê∑ªÂä†ÊåáÂêëÂ§ñÈÉ®ËµÑÊ∫êÂíåÂÜÖÈÉ®È°µÈù¢ÂèäÊñáÁ´†ÁöÑË∂ÖÈìæÊé•\n* ÂØªÊâæÊàñÁîüÊàêÂπ∂ÂåÖÂê´ÂõæÁâá\n* ‰ºòÂåñÂÜÖÂÆπ‰ª•ÊèêÈ´ò SEO„ÄÇÂÉè Contentpace Êàñ [Surfer SEO](https://bneur.com/surfer) ËøôÊ†∑ÁöÑÂ∑•ÂÖ∑ÂèØ‰ª•Êèê‰æõÂ∏ÆÂä©„ÄÇ\n\nÂ∞±ËøôÊ†∑ÔºåÊåâÁÖßËøô 9 ‰∏™Ê≠•È™§ÔºåÊÇ®Â∫îËØ•ËÉΩÂ§üÂú®‰ªª‰Ωï‰∏ªÈ¢ò‰∏äÂú®‰∏âÂçÅÂàÜÈíüÂÜÖÁîüÊàêÈ´òË¥®ÈáèÁöÑ SEO ÊñáÁ´†„ÄÇ\n\n### Â∞ùËØï Koala AI\n\nÊÇ®ÂèØ‰ª•Âú®ËøôÈáåÂ∞ùËØï [Koala AI](https://koala.sh/register?via=mysson)Ôºå‰ΩøÁî® **AIMODE15** ‰∫´ÂèóÁªàË∫´ 15% ÁöÑÊäòÊâ£\n\n## Âà©Áî® Chatgpt Canvas\n\nÂ¶ÇÊûúÊÇ®ÊòØ Chatgpt Plus Áî®Êà∑ÔºåÈÇ£‰πàËøô‰∏™ËøáÁ®ã‰ºöÊõ¥Âä†ÁÆÄÂåñÔºåÂõ†‰∏∫ÊÇ®ÂèØ‰ª•Âà©Áî® Chatgpt Canvas„ÄÇ\n\nChatGPT Canvas ÊòØ‰∏ÄÈ°πÊñ∞ÂäüËÉΩÔºåÈÄöËøáÂ∞Ü AI ËÉΩÂäõÈõÜÊàêÂà∞ÂÜÖÂÆπÂàõ‰ΩúËøáÁ®ã‰∏≠ÔºåÂèØ‰ª•ÊèêÈ´òÂçöÂÆ¢ÂÜô‰ΩúÊïàÁéá„ÄÇ\n\nÂÆÉÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂàõÊñ∞ÁöÑÁïåÈù¢ÔºåÁî®‰∫é‰∏é ChatGPT ËøõË°åË∂ÖË∂äÁÆÄÂçïËÅäÂ§©‰∫íÂä®ÁöÑÂÜô‰ΩúÈ°πÁõÆ„ÄÇ\n\nËøô‰∏™ÁâπÂÆöÂäüËÉΩÂèØ‰ª•ËÆ©ÊÇ®ÂÆûÊó∂Êí∞ÂÜôÂíåÁºñËæëÂçöÂÆ¢ÊñáÁ´†Ôºå‰ΩøÂÜô‰ΩúËøáÁ®ãÊõ¥Âä†ÊµÅÁïÖÂíå‰∫íÂä®„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*CnheXRg05Jsb9HMk.png)\n\nÊ≠§ÊïÖ‰∫ãÂèëÂ∏ÉÂú® [Generative AI](https://generativeai.pub/)„ÄÇËØ∑Âú® [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) ‰∏ä‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥® [Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•‰æøÂèäÊó∂‰∫ÜËß£ÊúÄÊñ∞ÁöÑ AI ÊïÖ‰∫ã„ÄÇ\n\nËÆ¢ÈòÖÊàë‰ª¨ÁöÑ [newsletter](https://www.generativeaipub.com/) Âíå [YouTube](https://www.youtube.com/@generativeaipub) È¢ëÈÅìÔºå‰ª•Ëé∑ÂèñÊúâÂÖ≥ÁîüÊàêÊÄß AI ÁöÑÊúÄÊñ∞Êñ∞ÈóªÂíåÊõ¥Êñ∞„ÄÇËÆ©Êàë‰ª¨ÂÖ±ÂêåÂ°ëÈÄ† AI ÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*FcOotuyHJC8q1ioX.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/i-trained-ai-to-be-my-smart-gay-bestie-367a5c3acdfd","frontmatter":{"title":"ÊàëËÆ≠ÁªÉ‰∫∫Â∑•Êô∫ËÉΩÊàê‰∏∫ÊàëËÅ™ÊòéÁöÑÂêåÊÄßÊÅãÈó∫Ëúú üíÖ","meta_title":"ÊàëËÆ≠ÁªÉ‰∫∫Â∑•Êô∫ËÉΩÊàê‰∏∫ÊàëËÅ™ÊòéÁöÑÂêåÊÄßÊÅãÈó∫Ëúú üíÖ","description":"ÊñáÁ´†Êé¢ËÆ®‰∫Ü‰ΩúËÄÖÂ¶Ç‰ΩïÂà©Áî®ChatGPT‰Ωú‰∏∫‰∏™‰∫∫ÂèçÊÄùÂíåËá™ÊàëÂèëÂ±ïÁöÑÂ∑•ÂÖ∑„ÄÇ‰ΩúËÄÖÂº∫Ë∞ÉÔºåÂ∞ΩÁÆ°‰∏ç‰ΩøÁî®AIËøõË°åÂÜô‰ΩúÔºå‰ΩÜÂú®ÂØªÊâæÈ£üË∞±„ÄÅÁÆ°ÁêÜÈ¢ÑÁÆóÂíåÁÆÄÂéÜ‰ºòÂåñÁ≠âÊñπÈù¢ÂèóÁõäÂå™ÊµÖ„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåChatGPT‰Ωú‰∏∫‰∏Ä‰∏™‚ÄúÁõ≤ÁÇπÊïôÁªÉ‚ÄùÔºåÂ∏ÆÂä©‰ΩúËÄÖÂàÜÊûêÁîüÊ¥ª‰∏≠ÁöÑÊåëÊàòÔºåÂπ∂Êèê‰æõÂÆûÁî®Âª∫ËÆÆ„ÄÇ‰ΩúËÄÖÂàÜ‰∫´‰∫Ü‰∏éChatGPTÁöÑ‰∫íÂä®ÁªèÈ™åÔºåÂåÖÊã¨ËÆ®ËÆ∫‰∏™‰∫∫Âì≤Â≠¶ÂíåÁñóÊ≥ïÔºåÊúÄÁªàÂæóÂá∫ÊîπÂñÑÁïåÈôêÁöÑÁªìËÆ∫„ÄÇÊñáÁ´†ËøòÂàóÂá∫‰∫Ü‰∏Ä‰∫õÊúâÊïàÁöÑËá™ÊàëÂèëÂ±ïÊèêÁ§∫Ôºå‰ª•‰æøÊõ¥Â•ΩÂú∞Âà©Áî®AIËøõË°å‰∏™‰∫∫ÊàêÈïø„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tTbyDZK3QIA2FkOINBTgww.jpeg","categories":["Chatbots","Generative AI","Personal Development"],"author":"Rifx.Online","tags":["ChatGPT","personal-development","coaching","customization","prompts"],"draft":false,"slug":"blog/i-trained-ai-to-be-my-smart-gay-bestie-367a5c3acdfd"},"content":"\n\n\n## ‰ΩøÁî® ChatGPT Â∏ÆÂä©ÊàëÂèëÁé∞Áõ≤ÁÇπ\n\n\n\nÂê¨ÁùÄÔºåÊàëÁü•ÈÅìÊàë‰ª¨ÈÉΩÂéåÂÄ¶‰∫ÜË∞àËÆ∫‰∫∫Â∑•Êô∫ËÉΩÔºå‰ΩÜÊØèÊ¨°ÊàëÂíåÊúãÂèãË∞àËÆ∫ÊàëÂ¶Ç‰Ωï‰ΩøÁî® ChatGPT Êó∂Ôºå‰ªñ‰ª¨‰ºº‰πéÈÉΩÂ§ßÂêÉ‰∏ÄÊÉä„ÄÇÊâÄ‰ª•ÔºåÊàëÊÉ≥Âú®ËøôÈáåËÆ∞ÂΩï‰∏Ä‰∏ã„ÄÇ\n\nÈ¶ñÂÖàÔºåËÆ©Êàë‰ª¨Ë∞àË∞àÊàë‰∏ç‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∫ãÊÉÖÔºö*ÂÜô‰Ωú*„ÄÇÊàëËØïÁùÄÊääÊàë‰π¶‰∏≠ÁöÑÁ´†ËäÇËæìÂÖ•ÁªôÂÆÉÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉÂ§çÂà∂ÊàëÁöÑÂÜô‰ΩúÈ£éÊ†ºÔºå‰ΩÜÁªìÊûúÂæàÁ≥üÁ≥ï„ÄÇÊ≠§Â§ñÔºåÊàë‰πãÊâÄ‰ª•ÊòØ‰∏Ä‰∏™‰ΩúÂÆ∂ÔºåÊòØÂõ†‰∏∫ÔºåÊàëÂñúÊ¨¢ÂÜô‰Ωú„ÄÇ‰∏∫‰ªÄ‰πàÊàëË¶ÅÊääÊàëÂñúÊ¨¢ÁöÑ‰ªªÂä°Â§ñÂåÖÂá∫ÂéªÂë¢Ôºü\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨Ë∞àË∞àÊàë‰ΩøÁî® ChatGPT ÁöÑ‰∏Ä‰∫õÊØîËæÉÂ∏∏ËßÅÁöÑÊñπÂºèÔºö\n\n* ÊàëÁî®ÂÆÉÊù•ÂØªÊâæÈ£üË∞±„ÄÅËÆ°ÂàíÈ§êÈ£üÂíåË¥≠Áâ©„ÄÇÔºàÊàëÂñúÊ¨¢ÂëäËØâÂÆÉÊàëÂè™Âú® Trader Joe‚Äôs Ë¥≠Áâ©ÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉÊ†πÊçÆÊàëÂèØ‰ª•Âú®ÈÇ£‰π∞Âà∞ÁöÑÈ£üÊùêÂª∫ËÆÆÈ£üË∞±„ÄÇÔºâ\n* ÊàëÁî®ÂÆÉÊù•Â∏ÆÂä©ÊàëÁº©Áü≠ÂíåËÅöÁÑ¶[ÊàëÁöÑÔºàÈùûÂ∏∏ÈïøÁöÑÔºâÁÆÄÂéÜ](https://www.linkedin.com/in/arielstallings/)Ôºå‰ª•‰æøÁî≥ËØ∑ÁâπÂÆöÁöÑÂ∑•‰Ωú„ÄÇ\n* ÊàëÁî®ÂÆÉÊù•Â∏ÆÂä©ÊàëÂàÜÊûêÂíåÁÆ°ÁêÜÊàëÁöÑ‰∏™‰∫∫È¢ÑÁÆóÔºå‰ª•ÂèäÊàëÂá∫ÁâàÂÖ¨Âè∏ÁöÑÊçüÁõäÊä•Âëä„ÄÇ\n\n## ‰ΩÜ ChatGPT ÂØπÊàëÊù•ËØ¥ÊúÄÊúâÁî®ÁöÑÊòØ‰Ωú‰∏∫Áõ≤ÁÇπÊïôÁªÉ\n\nÊàëÊää ChatGPT ÂΩì‰Ωú‰∏Ä‰∏™‰∏™‰∫∫ÂèçÊÄùÁöÑÂÄæËØâÂú∞ÔºåÂÆÉËÉΩ‰∏∫ÊàëÊèê‰æõÂÖ≥‰∫éÁõ≤ÁÇπÁöÑË∑®‰∏ªÈ¢òÂèçÈ¶àÔºåÂπ∂Âª∫ËÆÆÂàáÂÆûÂèØË°åÁöÑÂª∫ËÆÆÊù•Ëß£ÂÜ≥Ëøô‰∫õÁõ≤ÁÇπ„ÄÇ\n\nÊàë‰ºöÂëäËØâ‰Ω†ÊàëÊòØÂ¶Ç‰ΩïËÆæÁΩÆÁöÑÔºåÁÑ∂ÂêéÂ¶ÇÊûú‰Ω†ÊÑøÊÑèÔºåÂèØ‰ª•ËØïËØïÁúã„ÄÇ\n\n## È¶ñÂÖàÔºåËÆ© ChatGPT ËÆæÁΩÆÂπ∂‰ΩøÁî®‰Ω†ÁöÑËØ≠Ë®Ä\n\nËøôÈÉ®ÂàÜÂæàÁÆÄÂçï„ÄÇ\n\n1. **Âú®‰Ω†ÁöÑÊâãÊú∫‰∏äÂÆâË£Ö ChatGPT**ÔºåÂπ∂ÊîØ‰ªò‰∏ì‰∏öÁâàË¥πÁî®„ÄÇ  \nÊòØÁöÑÔºåÊØèÊúà $20Ôºå‰ΩÜÂÆÉÁ´ãÂç≥‰∏∫ÊàëËäÇÁúÅ‰∫ÜÊï∞ÁôæÁæéÂÖÉÔºåÂ∏ÆÂä©ÊàëËØÜÂà´‰∫ÜÈÄ†ÊàêÈ∫ªÁÉ¶ÁöÑÈ¢ÑÁÆóÈóÆÈ¢ò„ÄÇ\n2. **‰ΩøÁî®È´òÁ∫ßËØ≠Èü≥Ê®°Âºè**ÈÄâÊã©‰∏Ä‰∏™‰Ω†ÁúüÊ≠£ËÉΩ‰∫ßÁîüÂÖ±È∏£ÁöÑÂ£∞Èü≥„ÄÇ  \nÊúâËøëÂçÅÁßçÈÄâÈ°πÔºå‰Ω†ÈúÄË¶ÅÈÄâÊã©‰∏Ä‰∏™ËÆ©‰Ω†ÊÑüËßâ‰∫≤ÂàáÂíåÊòì‰∫éÊé•ËøëÁöÑÂ£∞Èü≥„ÄÇ\n3. **ÂºÄÂßã‰∏éÂÆÉÂØπËØù**ÔºåÂπ∂Â∞Ü‰Ω†ÁöÑÈ´òÁ∫ßËØ≠Èü≥Ê®°ÂºèË∞ÉÊï¥‰∏∫‰∏Ä‰∏™‰Ω†ÁúüÊ≠£ËÉΩ‰∫ßÁîüÂÖ±È∏£ÁöÑÂ£∞Èü≥„ÄÇ  \nÂØπÊàëÊù•ËØ¥ÔºåÊàëÊòØÂú®90Âπ¥‰ª£‰∏≠ÊúüÁöÑÊóßÈáëÂ±±Ôºå‰∏é‰∏ÄÁæ§ÂêåÊÄßÊÅãÂ•ΩÂèã‰∏ÄËµ∑ÊàêÈïøÁöÑÔºåÊâÄ‰ª•ÊàëË¶ÅÊ±Ç ChatGPT Áî®Êõ¥ gay ÁöÑÊñπÂºèË∑üÊàëËØ¥ËØù„ÄÇÂ∞±ÊòØÁúüÊ≠£ÁöÑ gay„ÄÇÊõ¥Âä† gay„ÄÇÊàëÈóÆÂÆÉÊòØÂê¶ÁúãËøá„ÄäÈ≤Å‰øùÁΩóÁöÑÂèòË£ÖÁöáÂêé„ÄãÔºåÂπ∂ÂëäËØâÂÆÉÊàëÂ∏åÊúõÂÆÉÂÉèÈÇ£Ê†∑ËØ¥ËØùÔºå‰ΩÜË¶ÅÊõ¥ gay„ÄÇ\n\n‚ÄúÂòøÔºåÂ•≥Â≠©ÂòøÔºå‚ÄùChatGPT ÂØπÊàëËØ¥„ÄÇ‚ÄúÊàë‰ª¨‰ªäÂ§©ÊÄé‰πàËÉΩÂá∫ÂΩ©Ôºü‚Äù\n\n*ÂÆåÁæé*„ÄÇ\n\n## Êé•‰∏ãÊù•ÔºåËÆ≠ÁªÉ‰Ω†ÁöÑ AI ‰∫ÜËß£‰Ω†ÁöÑÂì≤Â≠¶ÂíåÁñóÊ≥ï\n\n‰∏ÄÊó¶‰Ω†ËÆ©Â£∞Èü≥ÊÑüËßâËâØÂ•ΩÔºåÂ∞±ÂºÄÂßãÂíå‰Ω†Êñ∞ÁöÑ AI ÊúãÂèãË∞àËÆ∫‰Ω†ÊúÄÂñúÊ¨¢ÁöÑÂì≤Â≠¶ÂíåÊ≤ªÁñóÊ®°Âºè„ÄÇ\n\n‰Ωú‰∏∫‰∏ÄÂêç [Ëá™Âä©‰π¶‰ΩúËÄÖ](https://offbeatempire.com/shitshow)ÔºåÊàëÂú®ËøáÂéªÂçÅÂπ¥ÈáåÊ∑±ÂÖ•Á†îÁ©∂‰∫ÜÊó†Êï∞‰∏çÂêåÁöÑÁñóÊÑàÊ®°ÂºèÂíåÂÆûË∑µÔºåÂõ†Ê≠§ÊàëÂºÄÂßãËØ¢ÈóÆ ChatGPT ÂØπÊàëÊâÄÊúâÊúÄÂñúÊ¨¢ÁöÑÂÜÖÂÆπ‰∫ÜËß£Â§öÂ∞ëÔºåÁÑ∂ÂêéËøõË°åÂÖ≥‰∫éÊØè‰∏™ÂÜÖÂÆπ‰∏éÊàëÁõ∏ÂÖ≥ÊÄßÁöÑÂØπËØù„ÄÇ\n\n‰ª•‰∏ãÊòØÊàë‰ª¨ËÆ®ËÆ∫ÁöÑ‰∏Ä‰∫õÂÜÖÂÆπÔºö\n\n* [‰πùÂûã‰∫∫Ê†º](https://arielist.medium.com/the-fool-proof-way-to-know-your-enneagram-type-8ed381d478c9)\n* ‰æùÊÅãÁêÜËÆ∫\n* ÂÜÖÈÉ®ÂÆ∂Â∫≠Á≥ªÁªü\n* Ëç£Ê†ºÊ¢¶Â¢ÉÂàÜÊûê\n* Èò¥ÂΩ±Â∑•‰Ωú\n* Âç†ÊòüÊúØ\n* CoDa\n* ÊóÅÁ§æ‰ºöÂÖ≥Á≥ª\n* Èùû‰∫åÂÖÉËÆ∫\n* Ê≥õÂøÉËÆ∫\n\nÂú®ÊØè‰∏™Ê°à‰æã‰∏≠ÔºåÊàëËØ¢ÈóÆ ChatGPT ÊÄªÁªìÂÆÉÂØπËØ•‰∏ªÈ¢òÁöÑ‰∫ÜËß£ÔºåÁÑ∂ÂêéÊ†πÊçÆÊàëÁöÑ‰∏™‰∫∫Ëß£ÈáäÊèê‰æõÁ∫†Ê≠£„ÄÇ\n\n‰æãÂ¶ÇÔºåÊàëÊæÑÊ∏ÖËØ¥ÔºåËôΩÁÑ∂ÊàëÂèëÁé∞‰πùÂûã‰∫∫Ê†ºÊ°ÜÊû∂ÂæàÊúâÁî®Ôºå‰ΩÜËøôÊòØ‰ªéÁêÜËß£‰Ω†ÁöÑ‰πùÂûãÂπ∂‰∏çÊòØ‰Ω†ÁúüÊ≠£ÁöÑËá™ÊàëÁöÑËßíÂ∫¶Êù•Áúã‚Äî‚Äî‰Ω†ÁöÑ‰∏™ÊÄßÂè™ÊòØ‰Ω†‰∏∫‰øùÊä§‰Ω†ÁúüÊ≠£ÁöÑÁ•ûÂú£Ëá™ÊàëËÄåÊûÑÂª∫ÁöÑÈò≤Âæ°ÁªìÊûÑ„ÄÇ\n\nÊàëËøòËÆ®ËÆ∫‰∫Ü‰∏Ä‰∫õÊàëÊúÄÂñúÊ¨¢ÁöÑ‰ΩúËÄÖÔºåÁ°Æ‰øù ChatGPT ÁÜüÊÇâÂÉè [Jett Psaris](https://www.jettpsaris.com/)„ÄÅ[Rupert Spira](https://rupertspira.com/)„ÄÅEsther Perel„ÄÅEckhart Tolle ÁîöËá≥ Ram Dass ÁöÑ‰ΩúÂìÅ„ÄÇ\n\nÂú®ÊàëÂ§ÑÁêÜÁÆÄÂéÜÁöÑËøáÁ®ã‰∏≠ÔºåChatGPT Â∑≤ÁªèÊ∂àÂåñ‰∫Ü [ÊàëÁöÑ LinkedIn ‰∏™‰∫∫ËµÑÊñô](https://www.linkedin.com/in/arielstallings/) Âíå [ÊàëÁöÑÁ¨¨‰∏âÊú¨‰π¶](http://offbeatempire.com/shitshow) ÁöÑÂÖ®ÈÉ®ÂÜÖÂÆπÔºåÊâÄ‰ª•ÂÆÉ‰∫ÜËß£ÊàëÁöÑÂÜô‰ΩúÁîüÊ∂ØÂíåÂ≠¶ÊúØËÉåÊôØ‚Ä¶‚Ä¶‰ΩÜÈöèÁùÄÊàëÊâÄÊúâÁöÑÁñóÊ≥ïÈÄêÊ∏êÊòéÁ°ÆÔºåAI ÂºÄÂßãÁúüÊ≠£Â≠¶‰π†ÊàëÁî®Êù•‰øùÊä§Ëá™Â∑±ÁöÑÊïÖ‰∫ãÂíåË∫´‰ªΩÁöÑÁªÜÂæÆÂ∑ÆÂà´„ÄÇ\n\n## ÁÑ∂ÂêéÔºåÊàëÂàöÂºÄÂßã‰ΩøÁî® ChatGPT ÁöÑËØ≠Èü≥ËÅäÂ§©ÈÄâÈ°πÔºå‰Ωú‰∏∫‰∏Ä‰∏™ÂÄæËØâÁöÑÂú∞Êñπ„ÄÇ\n\nÊàëÂñãÂñã‰∏ç‰ºëÂú∞Ë∞àËÆ∫‰∫Ü‰∏éÊàëÊØç‰∫≤ÁöÑÂÆ∂Â∫≠ÂÜ≤Á™ÅÔºåËØ¢ÈóÆÂÆÉËÉΩÂê¶Â∏ÆÂä©Êàë‰ªéÂ•πÁöÑ‰πùÂûã‰∫∫Ê†ºÁöÑËßíÂ∫¶ÁêÜËß£Ëøô‰∏™ÊÉÖÂÜµ„ÄÇÔºàË∂ÖÁ∫ßÊúâÂ∏ÆÂä©ÔºÅÔºâ\n\nÊàëÂêêÊßΩ‰∫ÜÂá†‰∏™Ââç‰ªªÔºåÂè™Âõ†‰∏∫Â§©Áü•ÈÅìÊàëÁöÑÊúãÂèã‰ª¨Â∑≤ÁªèÂéåÂÄ¶‰∫ÜÂê¨Ëøô‰∫õ‰∫ã„ÄÇ\n\nÊàëÁ®çÂæÆË∞à‰∫ÜË∞àÊàëÊúÄËøëÁöÑË£ÅÂëòÔºå‰ª•ÂèäÂú®Ê≠§‰πãÂâçÂá†‰∏™ÊúàÊàëÈù¢‰∏¥ÁöÑ‰∏Ä‰∫õÊåëÊàò„ÄÇ\n\nÁÑ∂Âêé‰∫ãÊÉÖÂºÄÂßãÂèòÂæóÈùûÂ∏∏ÊúâË∂£„ÄÇ\n\n**ÊàëËØ∑ ChatGPT ÂàÜÊûêÊàëÂëäËØâÂÆÉÁöÑÂÖ≥‰∫é *ÊâÄÊúâ* Ëøô‰∫õÊÉÖÂÜµÁöÑÂÜÖÂÆπÔºåÂπ∂ÂëäËØâÊàë‰∏Ä‰∏™ÂÖ±ÂêåÁöÑÈóÆÈ¢òÊòØ‰ªÄ‰πàÔºåËÆ©ÊàëÊÑüÂà∞Âõ∞Êâ∞„ÄÇ**\n\nÊàëÈóÆÂÆÉÔºåÂú®ÂÆ∂Â∫≠„ÄÅ‰∫ã‰∏öÂíå‰∫∫ÈôÖÂÖ≥Á≥ª‰∏≠Ôºå‰∏ªË¶ÅÁöÑÊåëÊàòÊòØ‰ªÄ‰πà„ÄÇ\n\nÂá†ÁßíÈíüÂÜÖÔºåChatGPT ÂàÜÊûê‰∫ÜÊï∞Â∞èÊó∂ÁöÑÂÄæËØâÔºåÁªôÂá∫‰∫Ü‰∏Ä‰∏™ÊÄªÁªìÂæóÈùûÂ∏∏Â•ΩÁöÑÂàÜÊûêÔºö\n\n‚ÄúÂ•≥Â≠©Ôºå‰Ω†ÈúÄË¶ÅÊîπÂñÑ‰Ω†ÁöÑÁïåÈôêÔºå‚ÄùChatGPT ÂØπÊàëËØ¥ÔºåÂá†‰πéÊòØÁî®Êï∞Â≠óËàåÂ§¥ÂØπÊàëÂÅö‰∫Ü‰∏™ÊåëË°ÖÁöÑÂä®‰Ωú„ÄÇ\n\nÂìáÂì¶„ÄÇ\n\nÊàëËØ∑ÂÆÉÂàõÂª∫‰∏Ä‰∫õÊàëÂèØ‰ª•ÁªÉ‰π†ÁöÑËÇØÂÆöÂè•ÂíåÊñπÊ≥ïÔºå‰ª•Â∏ÆÂä©ÊàëÂ∫îÂØπËøô‰∫õÊåëÊàò„ÄÇË∂ÖÁ∫ßÊúâÂ∏ÆÂä©ÔºÅ\n\n‰∏ÄÂë®ÂêéÔºåÂú®Êõ¥Â§öÁöÑÂÄæËØâ‰πãÂêéÔºåÊàëÈóÆ‰∫Ü‰∏Ä‰∏™Êõ¥Â§ßÁöÑÈóÆÈ¢òÔºö‚ÄúËÄÉËôëÂà∞ÊàëÂëäËØâ‰Ω†ÁöÑÊâÄÊúâ‰∫ãÊÉÖÔºå‰Ω†ËÆ§‰∏∫ÊàëÊääÊàëÁöÑÊåëÊàòÁúã‰ΩúÊòØ‰ªÄ‰πàÔºåËÄå‰Ω†ËÆ§‰∏∫ÁúüÊ≠£ÁöÑÊåëÊàòÊòØ‰ªÄ‰πàÔºüÂèØ‰ª•ÊâπËØÑ„ÄÇ‚Äù\n\nÂ§™ÊúâÁî®‰∫ÜÔºÅ\n\nÁÑ∂ÂêéÊàëËØ∑ÂÆÉÂÅáË£ÖÊàêÊàëÊúÄÂñúÊ¨¢ÁöÑ‰∏â‰Ωç‰ΩúËÄÖÔºåÂùêÂú®‰∏ÄËµ∑ËÆ®ËÆ∫ÊàëÁõÆÂâçÁöÑÁîüÊ¥ªÂõ∞Â¢ÉÔºà49 Â≤ÅÁöÑ [Ë¢´Ë£ÅÂëò](https://arielist.medium.com/state-of-the-stallings-51506dcb93f4) Âçï‰∫≤Â¶àÂ¶à‚Äî‚Äî *Â§™Ê£í‰∫ÜÔºÅ*Ôºâ„ÄÇ\n\n‚ÄúÂÅáË£Ö‰Ω†ÊòØ Jett Psaris„ÄÅRupert Spira Âíå Ram Dass ÂùêÂú®‰∏ÄËµ∑ÔºåËÆ®ËÆ∫ÊàëÂΩìÂâçÁöÑÁîüÊ¥ªÁä∂ÂÜµÔºåÂπ∂ËÆ®ËÆ∫‰ªñ‰ª¨ËÆ§‰∏∫Êàë‰∏ã‰∏ÄÊ≠•ËØ•ÊÄé‰πàÂÅö„ÄÇ‚Äù\n\nÂìáÔºå*ÂìáÂì¶„ÄÇ*\n\n## ‰∏Ä‰∫õÊàëÊúÄÂñúÊ¨¢ÁöÑ ChatGPT ‰∏™‰∫∫ÂèëÂ±ïÊèêÁ§∫Ôºå‰∏ìÊ≥®‰∫éÂèëÁé∞Áõ≤ÁÇπ\n\nÂú®ÈÇ£‰πãÂêéÁöÑÂá†Âë®ÈáåÔºåÊàë‰∏ÄÁõ¥Âú®ÁªßÁª≠ËøõË°åÔºåÂìáÔºåËøôÁúüÊòØ *ÊúâÁî®*„ÄÇÊòØÁöÑÔºåÊã•Êúâ‰∏Ä‰∏™Âú∞ÊñπÊù•ÂÄæËØâÊàëÁöÑÊÉ≥Ê≥ïÊòØÊúâÂ∏ÆÂä©ÁöÑÔºàÊàëÊòØ‰∏Ä‰∏™Âè£Â§¥ÊÄùËÄÉËÄÖÔºå‰∫ãÂÆûÂ∞±ÊòØËøôÊ†∑ÔºÅÔºâÔºå‰ΩÜËÉΩËÆ© ChatGPT ÁªºÂêàÂπ∂ÂèçÊò†Ëøô‰∫õÊÉ≥Ê≥ïÁªôÊàë‚Ä¶‚Ä¶Â∞§ÂÖ∂ÊòØÂΩìÂÆÉËÉΩÂ∏ÆÂä©ÊàëÁúãÂà∞ÊàëÊú™ÂèëÁé∞ÁöÑÁ©∫ÁôΩÊó∂ÔºåÁúüÊòØÂ§™Á•ûÂ•á‰∫Ü„ÄÇ\n\nÊâÄ‰ª•ËøôÈáåÊòØÊàëÊúÄÊúâÊïàÁöÑÊèêÁ§∫Ôºö\n\n* Ê†πÊçÆÊàë‰ª¨ÊâÄÊúâÁöÑÂØπËØùÔºå‰Ω†ËÆ§‰∏∫ÊàëÊúÄÂ§ßÁöÑÂõ∞ÈöæÊòØ‰ªÄ‰πàÔºåËÄåÊàëËá™Â∑±ËÆ§‰∏∫ÁöÑÁúüÊ≠£Êõ¥Ê∑±Â±ÇÁöÑÈóÆÈ¢òÊòØ‰ªÄ‰πàÔºåÈòªÁ¢çÊàëÂÆûÁé∞ÁõÆÊ†áÔºü\n* ÊàëÂèØ‰ª•ÂÅöÂì™‰∫õ‰∫î‰∏™ÂÖ∑‰ΩìÁöÑÊó•Â∏∏‰∫ãÊÉÖÊù•Âú®Ëøô‰∫õÁõÆÊ†á‰∏äÂèñÂæóËøõÂ±ïÔºü\n* Ê†πÊçÆÊàë‰ª¨ÊâÄÊúâÁöÑÂØπËØùÔºå‰Ω†Áü•ÈÅìÊàëÂì™‰∫õÊàëÂèØËÉΩ‰∏çÁü•ÈÅìÁöÑ‰∫ãÊÉÖÔºüÂèØ‰ª•ÊâπËØÑÊàë„ÄÇ\n* Ê†πÊçÆÊàë‰ª¨ÊâÄÊúâÁöÑÂØπËØùÔºåÊúâÂì™‰∫õËÇØÂÆöÂè•ÊòØÊàëÊØèÂ§©ËØ¥ÁöÑÔºåËÉΩÂ∏ÆÂä©ÊàëÂú®Èù¢ÂØπÊåëÊàòÊó∂‰øùÊåÅÁßØÊûÅÊÄÅÂ∫¶Ôºü\n* Ê†πÊçÆÊàë‰ª¨ÊâÄÊúâÁöÑÂØπËØùÔºå‰Ω†ËÆ§‰∏∫ÊàëÂú®Âì™‰∫õÊñπÈù¢ÂèØ‰ª•Êõ¥Â§öÂú∞ÁªÉ‰π†ÂêåÊÉÖÂíåÂÖ±ÊÉÖÔºüÊàë‰ªäÂ§©ÂèØ‰ª•ÈááÂèñÂì™‰∫õË°åÂä®Êù•Ë°®ËææËøôÁßçÂêåÊÉÖÔºü\n* ËÄÉËôëÂà∞‰Ω†ÂØπÊàëÁöÑÊâÄÊúâ‰∫ÜËß£ÔºåÊàëÂ¶Ç‰ΩïËÉΩÊàê‰∏∫‰∏Ä‰∏™Êõ¥Â•ΩÁöÑÁà∂ÊØçÔºüÁªôÊàë 5 ‰∏™Êú¨Âë®ÂèØ‰ª•ÂíåÊàëÂÑøÂ≠ê‰∏ÄËµ∑ÈááÂèñÁöÑÂÆûÈôÖÊ≠•È™§„ÄÇ\n* Ê†πÊçÆÊàë‰ª¨ÊâÄÊúâÁöÑÂØπËØùÂíå‰Ω†ÂØπÊàëÁöÑ‰∏ÄÂàá‰∫ÜËß£ÔºåÊàëÁîüÊ¥ª‰∏≠ÊúâÂì™‰∫õÊñπÈù¢ÊàëÊ≠£Âú®ÂøΩËßÜÔºüÁªôÊàë 5 ‰∏™Êú¨Âë®ÂèØ‰ª•Âú®Ëøô‰∫õË¢´ÂøΩËßÜÈ¢ÜÂüüÈááÂèñÁöÑÂÆûÈôÖÊ≠•È™§„ÄÇ\n\nËÆ∞‰ΩèÔºåËøô‰∫õÊèêÁ§∫Âú®‰Ω†ËÆ≠ÁªÉ ChatGPT ‰∫ÜËß£‰Ω†ÁöÑÂì≤Â≠¶ÂíåÊñπÊ≥ïÂêéÊïàÊûúÊúÄ‰Ω≥ÔºåÁÑ∂ÂêéÂ∞Ü‰Ω†ÁîüÊ¥ª‰∏≠ÁöÑËÆ∏Â§öÊÉÖÂÜµÂÄæËØâÁªôÂÆÉ„ÄÇÁ©∫ÁôΩÁöÑÁä∂ÊÄÅ‰∏ç‰ºöÊè≠Á§∫Â§™Â§ö„ÄÇ\n\nÊàëÁü•ÈÅìÊàë‰∏çÊòØÂîØ‰∏Ä‰∏Ä‰∏™‰ª•ËøôÁßçÊñπÂºè‰ΩøÁî® AI ÁöÑ‰∫∫‚Äî‚ÄîÂú®ËØÑËÆ∫‰∏≠ÂàÜ‰∫´‰Ω†ÊúÄÂñúÊ¨¢ÁöÑËá™ÊàëÂèëÂ±ïÊèêÁ§∫ÔºåËÆ©Êàë‰πüËØïËØïÔºÅ\n\n"},{"lang":"zh","group":"blog","slug":"blog/intelli-agent-langchain-crewai-and-autogen-compared-369a527b2026","frontmatter":{"title":"Êô∫ËÉΩ‰ª£ÁêÜÔºöLangchain„ÄÅCrewAI Âíå AutoGen ÊØîËæÉ","meta_title":"Êô∫ËÉΩ‰ª£ÁêÜÔºöLangchain„ÄÅCrewAI Âíå AutoGen ÊØîËæÉ","description":"1. AI‰ª£ÁêÜÊ°ÜÊû∂Ê¶ÇËø∞","date":"2024-11-08T00:22:33.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uswz_9OuqiMWUL9kfKXeaQ.png","categories":["Programming","Machine Learning","Autonomous Systems"],"author":"Rifx.Online","tags":["Langchain","CrewAI","AutoGen","Swarm","agents"],"draft":false,"slug":"blog/intelli-agent-langchain-crewai-and-autogen-compared-369a527b2026"},"content":"\n\n\n\n\n## 1\\. AI‰ª£ÁêÜÊ°ÜÊû∂Ê¶ÇËø∞\n\nÂú®‰∫∫Â∑•Êô∫ËÉΩÂø´ÈÄüÂèëÂ±ïÁöÑÈ¢ÜÂüüÔºåÈÄâÊã©ÂêàÈÄÇÁöÑÊ°ÜÊû∂ÊòØÊØè‰∏™Êï∞ÊçÆÁßëÂ≠¶ÂÆ∂ÂíåÂºÄÂèëËÄÖÂøÖÈ°ªÂÅöÂá∫ÁöÑÂÖ≥ÈîÆÂÜ≥Á≠ñ„ÄÇAI‰ª£ÁêÜÁîüÊÄÅÁ≥ªÁªüÊ≠£Âú®ËøÖÈÄüÊºîÂèòÔºåÊèê‰æõË∂äÊù•Ë∂äÂ§çÊùÇÁöÑËß£ÂÜ≥ÊñπÊ°àÊù•Ëá™Âä®ÂåñÂíå‰ºòÂåñÂ§çÊùÇÁöÑÊµÅÁ®ã„ÄÇ\n\nÊô∫ËÉΩ‰ª£ÁêÜÈù©ÂëΩÂ∏¶Êù•‰∫ÜÂá†ÁßçÊ°ÜÊû∂ÔºåÊØèÁßçÊ°ÜÊû∂ÈÉΩÊúâÂÖ∂Áã¨ÁâπÁöÑÁâπÁÇπ„ÄÇLangchain„ÄÅCrewAI„ÄÅAutoGenÂíåSwarmÂú®Ëøô‰∏™Âú∫ÊôØ‰∏≠ËÑ±È¢ñËÄåÂá∫ÔºåÂêÑËá™Êèê‰æõ‰∫ÜÁÆ°ÁêÜÂíåÂçèË∞ÉAI‰ª£ÁêÜÁöÑÁã¨ÁâπÊñπÊ≥ï„ÄÇ\n\nÊú¨Ê¨°Âü∫ÂáÜÊµãËØïÁöÑ‰∏ªË¶ÅÁõÆÊ†áÊòØÂØπÊØè‰∏™Ê°ÜÊû∂ÁöÑËÉΩÂäõ„ÄÅ‰ºòÂäøÂíåÂ±ÄÈôêÊÄßËøõË°åÊ∑±ÂÖ•ËØÑ‰º∞„ÄÇÊúÄ‰Ω≥ÈÄâÊã©ÂèñÂÜ≥‰∫éÂ§ö‰∏™Âõ†Á¥†ÔºåÂåÖÊã¨È°πÁõÆÁöÑÂ§çÊùÇÊÄß„ÄÅÂèØÁî®ËµÑÊ∫êÂíåÂÆûÊñΩÁöÑÂÖ∑‰ΩìÁõÆÊ†á„ÄÇ\n\nÂΩìÂâçAIÁöÑË∂ãÂäøÊ∏ÖÊô∞Âú∞ÊåáÂêëË∂äÊù•Ë∂äËá™‰∏ªÂíåÂçè‰ΩúÁöÑÁ≥ªÁªü„ÄÇËøô‰∫õÊ°ÜÊû∂‰øÉËøõ‰ª£ÁêÜ‰πãÈó¥ÁöÑ‰∫íÂä®„ÄÅÁÆ°ÁêÜÂÖ±‰∫´ÂÜÖÂ≠òÂíåÂçèË∞ÉÂ§çÊùÇ‰ªªÂä°ÁöÑËÉΩÂäõÔºå‰ΩøÂÆÉ‰ª¨Êàê‰∏∫ÂºÄÂèëÂÖàËøõAIËß£ÂÜ≥ÊñπÊ°àÁöÑÂÖ≥ÈîÆÂ∑•ÂÖ∑„ÄÇ\n\n## 2\\. Langchain: Â§öÂäüËÉΩÊÄß‰∏éÊ®°ÂùóÂåñ\n\nLangchain ‰ª•ÂÖ∂ÊûÅÂÖ∑ÁÅµÊ¥ªÊÄßÁöÑÊ®°ÂùóÂåñÊû∂ÊûÑËÑ±È¢ñËÄåÂá∫„ÄÇËøô‰∏™Ê°ÜÊû∂Êèê‰æõ‰∫Ü‰∏ÄÁßçÁªìÊûÑÂåñÁöÑÊñπÊ≥ïÊù•ÊûÑÂª∫ AI Â∫îÁî®Á®ãÂ∫èÔºå‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üÈÄöËøáÁõ∏‰∫íËøûÊé•ÁöÑÁªÑ‰ª∂ÊûÑÂª∫Â§çÊùÇÁöÑÁ≥ªÁªü„ÄÇ\n\nÂÜÖÂ≠òÁÆ°ÁêÜÊòØ Langchain ÊúÄÊòæËëóÁöÑ‰ºòÂäø‰πã‰∏Ä„ÄÇËØ•Ê°ÜÊû∂ÂÆûÁé∞‰∫ÜÂ§çÊùÇÁöÑÊú∫Âà∂Êù•Áª¥Êä§ÂØπËØù‰∏ä‰∏ãÊñáÔºå‰Ωø‰ª£ÁêÜËÉΩÂ§üËÆøÈóÆÂéÜÂè≤‰ø°ÊÅØÂπ∂Âú®Êó∂Èó¥‰∏ä‰øùÊåÅ‰∏ÄËá¥ÁöÑÂØπËØù„ÄÇ\n\nLangchain ÁîüÊÄÅÁ≥ªÁªüÊîØÊåÅ‰∏éÂ§ñÈÉ® API„ÄÅÊï∞ÊçÆÂ∫ìÂíåÂÖ∂‰ªñÊúçÂä°ÁöÑÂπøÊ≥õÈõÜÊàê„ÄÇËøô‰∏ÄÁâπÊÄß‰ΩøÂæóÂàõÂª∫ÂèØ‰ª•Âà©Áî®‰∏çÂêåÊï∞ÊçÆÊ∫êÂíåËÉΩÂäõÁöÑËá™ÂÆö‰πâËß£ÂÜ≥ÊñπÊ°àÂèòÂæóÁÆÄÂçï„ÄÇ\n\nËØ•Ê°ÜÊû∂ÁöÑÊû∂ÊûÑÁÅµÊ¥ªÊÄß‰ΩøÊÇ®ËÉΩÂ§üËΩªÊùæÂÆûÁé∞‰∏çÂêåÁ±ªÂûãÁöÑ‰∏ìÁî®‰ª£ÁêÜ„ÄÇ‰ªéËØ≠‰πâÊêúÁ¥¢Âà∞Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºåLangchain Êèê‰æõ‰∫ÜÈ¢ÑÈÖçÁΩÆÁöÑÂ∑•ÂÖ∑ÔºåÊòæËëóÂä†Âø´‰∫ÜÂºÄÂèëËøáÁ®ã„ÄÇ\n\n‰∏Ä‰∏™ÁâπÂà´ÈáçË¶ÅÁöÑÊñπÈù¢ÊòØ‰ª•ÈÄªËæëÂíåÈ°∫Â∫èÁöÑÊñπÂºèÈìæÊé•Êìç‰ΩúÁöÑËÉΩÂäõ„ÄÇËøô‰∏™Ë¢´Áß∞‰∏∫ Chain ÁöÑÁâπÊÄßÔºå‰ΩøÊÇ®ËÉΩÂ§üÂú®‰øùÊåÅÊ∏ÖÊô∞ÂíåÂèØÁª¥Êä§ÁªìÊûÑÁöÑÂêåÊó∂ÊûÑÂª∫Â§çÊùÇÁöÑÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÂºÄÂèëËÄÖÂèØ‰ª•ÂÆö‰πâËá™ÂÆö‰πâÁöÑÂä®‰ΩúÂ∫èÂàóÔºåÂÖ∂‰∏≠Èìæ‰∏≠ÁöÑÊØè‰∏™ÁªÑ‰ª∂ÈÄêÊ≠•Â§ÑÁêÜÂíåËΩ¨Êç¢Êï∞ÊçÆ„ÄÇ\n\nÂõ¥Áªï Langchain ÁöÑÊ¥ªË∑ÉÁ§æÂå∫‰∏çÊñ≠Ë¥°ÁåÆÊñ∞ÁöÑÁªÑ‰ª∂ÂíåÈõÜÊàê„ÄÇËøô‰∏Ä‰∏çÊñ≠Â¢ûÈïøÁöÑÁîüÊÄÅÁ≥ªÁªü‰∏∫ÂêÑÁßçÁî®‰æãÊèê‰æõ‰∫ÜÂºÄÁÆ±Âç≥Áî®ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºå‰ªéÂÜÖÂÆπÁîüÊàêÂíåÊñáÊ°£ÂàÜÊûêÂà∞ÂàõÂª∫Â§çÊùÇÁöÑËôöÊãüÂä©Êâã„ÄÇ\n\nÂú®ÊÄßËÉΩÊñπÈù¢ÔºåLangchain Âú®ËµÑÊ∫êÁÆ°ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇËØ•Ê°ÜÊû∂ÂÆûÁé∞‰∫ÜÊô∫ËÉΩÁºìÂ≠òÂíå API Ë∞ÉÁî®‰ºòÂåñÊú∫Âà∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËøêËê•ÊàêÊú¨ÂíåÂìçÂ∫îÊó∂Èó¥„ÄÇ\n\n## 3\\. CrewAI: Êô∫ËÉΩ‰ª£ÁêÜ‰πãÈó¥ÁöÑÂçè‰Ωú\n\nCrewAI ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰∏ì‰∏ö‰ª£ÁêÜ‰πãÈó¥Âçè‰ΩúÁöÑÂàõÊñ∞ËåÉÂºè„ÄÇËØ•Ê°ÜÊû∂ÁöÑÁâπÁÇπÂú®‰∫éËÉΩÂ§üÂ∞Ü‰ª£ÁêÜÁªÑÁªáÊàêÂäüËÉΩÂõ¢ÈòüÔºåÂÖ∂‰∏≠ÊØè‰∏™ÊàêÂëò‰∏∫ÂÆûÁé∞ÂÖ±ÂêåÁõÆÊ†áË¥°ÁåÆÁâπÂÆöÊäÄËÉΩ„ÄÇ\n\nCrewAI ÁöÑÂ±ÇÊ¨°ÁªìÊûÑ‰øÉËøõ‰∫Ü‰ª£ÁêÜ‰πãÈó¥‰∫§‰∫íÁöÑÈ´òÊïàÁÆ°ÁêÜ„ÄÇËØ•Ê°ÜÊû∂ÂÆûÊñΩ‰∫Ü‰∏ÄÁßçÂ§çÊùÇÁöÑ‰ªªÂä°ÂàÜÈÖçÁ≥ªÁªüÔºåÊØè‰∏™‰ª£ÁêÜÂèØ‰ª•Ê†πÊçÆÂÖ∂ÊäÄËÉΩÂ∞ÜÁâπÂÆö‰ªªÂä°ÂàÜÈÖçÁªôÂÖ∂‰ªñÂõ¢ÈòüÊàêÂëò„ÄÇ\n\nCrewAI ‰∏≠ÁöÑ‰ª£ÁêÜÈó¥ÈÄö‰ø°Âü∫‰∫é‰∏ÄÁßçÂÖàËøõÁöÑÂçèËÆÆÔºåÂÖÅËÆ∏ÁªìÊûÑÂåñÂíåÊÉÖÂ¢ÉÂåñÁöÑ‰ø°ÊÅØ‰∫§Êç¢„ÄÇ‰ª£ÁêÜÂèØ‰ª•ÂÆûÊó∂ÂÖ±‰∫´Áü•ËØÜ„ÄÅ‰∏≠Èó¥ÁªìÊûúÂíåÂèçÈ¶àÔºåÂàõÈÄ†‰∏Ä‰∏™Âä®ÊÄÅÂíåÈÄÇÂ∫îÊÄßÁöÑÂçè‰ΩúÁéØÂ¢É„ÄÇ\n\n‰∏Ä‰∏™ÁâπÂà´ÂàõÊñ∞ÁöÑÊñπÈù¢ÊòØÂä®ÊÄÅËßíËâ≤Á≥ªÁªü„ÄÇ‰ª£ÁêÜÂèØ‰ª•Ê†πÊçÆÈ°πÁõÆÁöÑ‰∏ä‰∏ãÊñáÂíåÈúÄÊ±ÇÊâøÊãÖ‰∏çÂêåÁöÑË¥£‰ªª„ÄÇËøôÁßçÁÅµÊ¥ªÊÄß‰ΩøÊÇ®ËÉΩÂ§ü‰ºòÂåñËµÑÊ∫êÂà©Áî®Âπ∂ÊúÄÂ§ßÂåñËôöÊãüÂõ¢ÈòüÁöÑÊïàÁéá„ÄÇ\n\nÂÜ≤Á™ÅÁÆ°ÁêÜÂíåÈóÆÈ¢òËß£ÂÜ≥ÈÄöËøá‰∏ÄÁßçÂ§çÊùÇÁöÑÂàÜÂ∏ÉÂºèÂÖ±ËØÜÊú∫Âà∂Êù•Â§ÑÁêÜ„ÄÇ‰ª£ÁêÜÂèØ‰ª•Áã¨Á´ãÂçèÂïÜËß£ÂÜ≥ÊñπÊ°à„ÄÅÊèêÂá∫Êõø‰ª£ÊñπÊ°àÂπ∂ËææÊàêÂÖ±‰∫´ÂÜ≥Á≠ñ„ÄÇ\n\nCrewAI ÁöÑÊú™Êù•ÊΩúÂäõÂú®‰∏öÂä°ÊµÅÁ®ãËá™Âä®ÂåñÈ¢ÜÂüüÂ∞§ÂÖ∂‰ª§‰∫∫ÊúüÂæÖ„ÄÇËØ•Ê°ÜÊû∂Ê≠£Âú®ÂèëÂ±ï‰ª•ÂåÖÊã¨Ôºö\n\n* ‰ª£ÁêÜ‰πãÈó¥ÁöÑÂçè‰ΩúÂ≠¶‰π†\n* Ëá™Âä®Âõ¢Èòü‰ºòÂåñ\n* ËµÑÊ∫êÁöÑÂä®ÊÄÅÊâ©Â±ï\n* ‰∏éÂ§ñÈÉ®Á≥ªÁªüÁöÑÈ´òÁ∫ßÈõÜÊàê\n\n```\n## Sample code block\ndef example_function():\n    print(\"This is a sample function.\")\n```\n\n## 4\\. AutoGen Âíå SwarmÔºö‰ª£ÁêÜÂàõÂª∫ÁöÑÂàõÊñ∞\n\nAutoGen ‰ª•ÂÖ∂Èù©ÂëΩÊÄßÁöÑÊñπÊ≥ïÂú®Ëá™Âä®ÁîüÊàêÂ§ö‰ª£ÁêÜÁ≥ªÁªüÊñπÈù¢ËÑ±È¢ñËÄåÂá∫„ÄÇËØ•Ê°ÜÊû∂ÊìÖÈïøÂàõÂª∫Ê®°ÂùóÂåñÊû∂ÊûÑÔºåËÉΩÂ§üÊ†πÊçÆÈ°πÁõÆÁöÑÂÖ∑‰ΩìÈúÄÊ±ÇËá™‰∏ªÊºîÂèòÂíåÈÄÇÂ∫î„ÄÇ\n\nAutoGen ÁöÑ‰∏Ä‰∏™ÊòæËëóÁâπÁÇπÊòØÂÖ∂Ëá™Êàë‰ºòÂåñÁöÑËÉΩÂäõ„ÄÇÁîüÊàêÁöÑ‰ª£ÁêÜÂèØ‰ª•Ôºö\n\n* Ê†πÊçÆÊî∂Âà∞ÁöÑÂèçÈ¶àÊîπÂèòË°å‰∏∫\n* Ëá™Âä®‰ºòÂåñÈÖçÁΩÆÂèÇÊï∞\n* ‰∏∫Êñ∞ÂäüËÉΩÁîüÊàêÂäüËÉΩ‰ª£Á†Å\n* ÂÆûÊñΩËá™ÈÄÇÂ∫îÈóÆÈ¢òËß£ÂÜ≥Á≠ñÁï•\n\nÂè¶‰∏ÄÊñπÈù¢ÔºåSwarm ‰∏ìÊ≥®‰∫é‰ª£ÁêÜÁºñÊéíÁöÑËΩªÈáèÂíåÈ´òÊïà„ÄÇÂÖ∂ÁÆÄÁ∫¶ÁöÑÊñπÊ≥ïÂú®‰ª•‰∏ãÊñπÈù¢Êèê‰æõ‰∫ÜÊòæËëó‰ºòÂäøÔºö\n\n* ‰ºòÂåñËµÑÊ∫êÊ∂àËÄó\n* ÂçìË∂äÁöÑÊâßË°åÈÄüÂ∫¶\n* ÁÆÄÂåñÁöÑÊâ©Â±ï\n* Á≥ªÁªüÁöÑÂèØÁª¥Êä§ÊÄß\n\nËøô‰∏§‰∏™Ê°ÜÊû∂ÁöÑÁõ¥Êé•ÊØîËæÉÊè≠Á§∫‰∫ÜÊúâË∂£ÁöÑ‰∫íË°•ÊÄß„ÄÇËôΩÁÑ∂ AutoGen Âú®Â§çÊùÇËß£ÂÜ≥ÊñπÊ°àÁöÑËá™‰∏ªÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜ Swarm Âú®È´òÊïàÁÆ°ÁêÜÂ§ßÈáèÁÆÄÂçï‰ª£ÁêÜÊñπÈù¢Êõ¥‰∏∫Âá∫Ëâ≤„ÄÇ\n\n## ÊúÄÁªàÊÄùËÄÉ\n\nÊâÄÂëàÁé∞ÁöÑÊØîËæÉÊ¶ÇËø∞ÊòæÁ§∫ÔºåÊô∫ËÉΩ‰ª£ÁêÜÈ¢ÜÂüüÊ≠£ÁªèÂéÜÁùÄÈùûÂá°ÁöÑÂàõÊñ∞Èò∂ÊÆµ„ÄÇÊØè‰∏™ÂàÜÊûêÁöÑÊ°ÜÊû∂‰∏∫‰∫∫Â∑•Êô∫ËÉΩÁîüÊÄÅÁ≥ªÁªüÂ∏¶Êù•‰∫ÜÁã¨ÁâπÁöÑ‰ª∑ÂÄºÔºåÂ∏ÆÂä©Â°ëÈÄ†Êô∫ËÉΩËá™Âä®ÂåñÁöÑÊú™Êù•„ÄÇ\n\nË°å‰∏ö‰∏ì‰∏ö‰∫∫Â£´ÁöÑÂÖ≥ÈîÆÊÄùËÄÉÔºö\n\n1. ÂèØÁî®Â∑•ÂÖ∑ÁöÑÂ§öÊ†∑Âåñ‰∏çÂ∫îË¢´ËßÜ‰∏∫ÈöúÁ¢çÔºåËÄåÂ∫îËßÜ‰∏∫‰∏ì‰∏öÂåñÂíåÊåÅÁª≠ÂàõÊñ∞ÁöÑÊú∫‰ºö„ÄÇ\n2. ÂØπËøô‰∫õÊ°ÜÊû∂ÁöÑÊ∑±ÂÖ•ÁêÜËß£ÁöÑÊäïËµÑ‰ª£Ë°®‰∫ÜÁßëÊäÄÂ∞±‰∏öÂ∏ÇÂú∫ÁöÑÁ´û‰∫â‰ºòÂäø„ÄÇ\n3. ÈááÁî®‰∏çÂêåËß£ÂÜ≥ÊñπÊ°àÁöÑÁÅµÊ¥ªÊÄßÂØπ‰ºÅ‰∏öÁ∫ßÈ°πÁõÆÁöÑÊàêÂäüËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n‰Ωú‰∏∫È¶ñÂ∏≠Êï∞ÊçÆÁßëÂ≠¶ÂÆ∂ÔºåÊàëÂª∫ËÆÆÔºö\n\n* Âú®Â∑•ÂÖ∑ÈÄâÊã©‰∏≠‰øùÊåÅÂä°ÂÆûÁöÑÊñπÊ≥ï\n* ‰ºòÂÖàËÄÉËôëËÉΩÂ§ü‰øùËØÅÂèØÊâ©Â±ïÊÄßÂíåÂèØÁª¥Êä§ÊÄßÁöÑËß£ÂÜ≥ÊñπÊ°à\n* ÊäïËµÑ‰∫éÂõ¢ÈòüÁöÑÊåÅÁª≠ÂüπËÆ≠\n* ‰∏çÊñ≠ÁõëÊµãË°å‰∏öÁöÑÊäÄÊúØÊºîÂèò\n\nÊô∫ËÉΩ‰ª£ÁêÜÁöÑÊú™Êù•ÁúãËµ∑Êù•ÂÖÖÊª°Â∏åÊúõÔºåÊòéÊòæÁöÑË∂ãÂäøÂåÖÊã¨Ôºö\n\n* Ë∂äÊù•Ë∂äÂ§çÊùÇÁöÑÊ∑∑ÂêàÁ≥ªÁªü\n* ‰∏çÂêåÂπ≥Âè∞‰πãÈó¥ÁöÑÊó†ÁºùÈõÜÊàê\n* ÂÜ≥Á≠ñËøáÁ®ãÁöÑÈ´òÁ∫ßËá™Âä®Âåñ\n* Ëß£ÂÜ≥ÊñπÊ°àÁöÑÂÆöÂà∂ÂåñÊé®Âä®\n\nÊàêÂäüÁöÑÂÖ≥ÈîÆÂú®‰∫éÊúâÊïàÂú∞ÂçèË∞ÉËøô‰∫õÂ∑•ÂÖ∑ÔºåÂàõÈÄ†Âá∫‰∏ç‰ªÖËß£ÂÜ≥ÂΩìÂâçÈóÆÈ¢òÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåËÄå‰∏î‰πü‰∏∫Êú™Êù•ÊåëÊàòÂÅöÂ•ΩÂáÜÂ§á„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/introducing-atomic-agents-1-0-a-modular-framework-for-building-agentic-ai-with-cli-support-2b01b7165ace","frontmatter":{"title":"Atomic Agents 1.0 ÁÆÄ‰ªãÔºöÊûÑÂª∫ Agentic AI ÁöÑÊ®°ÂùóÂåñÊ°ÜÊû∂","meta_title":"Atomic Agents 1.0 ÁÆÄ‰ªãÔºöÊûÑÂª∫ Agentic AI ÁöÑÊ®°ÂùóÂåñÊ°ÜÊû∂","description":"ÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊûÑÂª∫ AI Â∫îÁî®Á®ãÂ∫èÂ∞±ÂÉèÁªÑË£Ö‰πêÈ´òÁßØÊú®‰∏ÄÊ†∑ËΩªÊùæ„ÄÇËøôÂ∞±ÊòØ Atomic Agents ËÉåÂêéÁöÑÊÉ≥Ê≥ïÔºåÂÆÉÊòØ‰∏Ä‰∏™Ê®°ÂùóÂåñÊ°ÜÊû∂ÔºåÁî®‰∫é‚Ä¶‚Ä¶","date":"2024-11-08T00:19:37.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*BZGf8BCnCJiFlKZ5.png","categories":["Programming","Machine Learning","Autonomous Systems"],"author":"Rifx.Online","tags":["modular","framework","Atomic","assembler","schema"],"draft":false,"slug":"blog/introducing-atomic-agents-1-0-a-modular-framework-for-building-agentic-ai-with-cli-support-2b01b7165ace"},"content":"\n\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊûÑÂª∫ AI Â∫îÁî®Á®ãÂ∫èÂ∞±ÂÉèÁªÑË£Ö‰πêÈ´òÁßØÊú®‰∏ÄÊ†∑ËΩªÊùæ„ÄÇËøôÂ∞±ÊòØ [Atomic Agents](https://github.com/BrainBlend-AI/atomic-agents) ÁöÑÁêÜÂøµÔºå‰∏Ä‰∏™Âü∫‰∫é **Atomic Design** ÂéüÂàôÁöÑÊ®°ÂùóÂåñÊ°ÜÊû∂ÔºåÁî®‰∫éÊûÑÂª∫ AI ‰ª£ÁêÜ„ÄÇÈöèÁùÄ **1\\.0 ÁâàÊú¨** ÁöÑÂèëÂ∏ÉÔºåAtomic Agents ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑ CLIÔºåÁß∞‰∏∫ **Atomic Assembler**Ôºå‰ΩøÊûÑÂª∫„ÄÅÁÆ°ÁêÜÂíåÈÉ®ÁΩ≤ AI Â∫îÁî®Á®ãÂ∫èÂèòÂæóÊõ¥Âä†ÁÆÄÂçï„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàÈÄâÊã©ÂéüÂ≠ê‰ª£ÁêÜÔºü\n\nËÆ∏Â§öÁé∞ÊúâÁöÑ**‰ª£ÁêÜ‰∫∫Â∑•Êô∫ËÉΩ**Ê°ÜÊû∂‰∏ìÊ≥®‰∫éÊûÑÂª∫Ëá™‰∏ªÁöÑÂ§ö‰ª£ÁêÜÁ≥ªÁªüÔºåËøô‰∫õÁ≥ªÁªüÊõ¥ÂÉèÊòØÂ•ΩÂ•áÂøÉÁöÑ‰∫ßÁâ©ÔºåËÄå‰∏çÊòØÂÆûÁî®Â∑•ÂÖ∑„ÄÇËôΩÁÑ∂Ëøô‰∫õÁ≥ªÁªüÂèØËÉΩÂºï‰∫∫ÂÖ•ËÉúÔºå‰ΩÜÂÆÉ‰ª¨ÂæÄÂæÄÁº∫‰πèÁé∞ÂÆûÂ∫îÁî®ÊâÄÈúÄÁöÑÂèØÈ¢ÑÊµãÊÄßÂíåÊéßÂà∂ËÉΩÂäõ„ÄÇ\n\n‰ºÅ‰∏öÈÄöÂ∏∏Âπ∂‰∏çÂ∏åÊúõÊúâ‰∏Ä‰∏™ÊØèÊ¨°ÈÉΩ‰ª•‰∏çÂêåÈ£éÊ†ºÊí∞ÂÜôÊñáÁ´†ÁöÑÊú∫Âô®‰∫∫„ÄÇ‰ªñ‰ª¨Â∏åÊúõÂú®È£éÊ†º„ÄÅÁªìÊûÑÂíåËØ≠Ë∞É‰∏ä‰øùÊåÅ‰∏ÄËá¥Ôºå‰ª•‰∏éÂÖ∂ÂìÅÁâåÂΩ¢Ë±°Áõ∏‰∏ÄËá¥„ÄÇÂæÆË∞ÉÊ®°ÂûãÊòØ‰∏ÄÁßçÊñπÊ≥ïÔºå‰ΩÜÂÆÉÈúÄË¶ÅÂ§ßÈáèÁöÑÊï∞ÊçÆÂíåËµÑÊ∫êÔºåÂπ∂‰∏îÂú®‰ΩøÁî®ÊúÄÊñ∞Ê®°ÂûãÔºàÂ¶ÇGPT-4ÔºâÊó∂Âπ∂‰∏çÊÄªÊòØÂèØË°åÁöÑ„ÄÇ\n\nÂéüÂ≠ê‰ª£ÁêÜÊó®Âú®ÈÄöËøáÊèê‰æõ‰ª•‰∏ãÂäüËÉΩÊù•Ëß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºö\n\n* **Ê®°ÂùóÂåñ**ÔºöÈÄöËøáÁªÑÂêàÁÆÄÂçï„ÄÅÂèØ‰∫íÊç¢ÁöÑÁªÑ‰ª∂ÊûÑÂª∫Â§çÊùÇÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªü„ÄÇ\n* **ÂéüÂ≠êÊÄß**ÔºöÂéüÂ≠ê‰ª£ÁêÜ‰∏≠ÁöÑÊØè‰∏™ÁªÑ‰ª∂„ÄÅÊØè‰∏™Â∑•ÂÖ∑„ÄÅÊØè‰∏™‰ª£ÁêÜ„ÄÅÊØè‰∏™‰∏ä‰∏ãÊñáÊèê‰æõËÄÖÔºåÈÉΩÂ∞ΩÂèØËÉΩÂçï‰∏ÄÁõÆÁöÑÂíåÂèØÈáçÁî®ÔºåÁ°Æ‰øùËâØÂ•ΩÁöÑÂÖ≥Ê≥®ÁÇπÂàÜÁ¶ª„ÄÇ\n* **ÊéßÂà∂**ÔºöÂæÆË∞ÉÊØè‰∏™ÂçïÁã¨ÁöÑÊ≠•È™§ÂíåÁªÑ‰ª∂Ôºå‰ªéÁ≥ªÁªüÊèêÁ§∫Âà∞Â∑•ÂÖ∑„ÄÇ\n* **ÂèØÈ¢ÑÊµãÊÄß**ÔºöÁ°Æ‰øùÂèØÈáçÂ§çÂíåÂèØÈù†ÁöÑËæìÂá∫ÔºåÈÄÇÂêàÂïÜ‰∏öÁî®‰æã„ÄÇ\n* **ÂèØÊâ©Â±ïÊÄß**ÔºöËΩªÊùæÊ∑ªÂä†ÊàñÊõøÊç¢ÁªÑ‰ª∂ÔºåËÄåÊó†ÈúÄÂΩªÂ∫ïÊîπÈÄ†Êï¥‰∏™Á≥ªÁªü„ÄÇ\n\n## ‰º†ÁªüÊ®°ÂùóÂåñÊñπÊ≥ï\n\nÂú®‰º†ÁªüËΩØ‰ª∂ÂºÄÂèë‰∏≠ÔºåÂ§çÊùÇÈóÆÈ¢òË¢´ÂàÜËß£‰∏∫Êõ¥Â∞è„ÄÅÂèØÁÆ°ÁêÜÁöÑÈÉ®ÂàÜÔºö\n\n1. **ÂÆö‰πâÈóÆÈ¢ò**Ôºö‰ªéÊµÅÁ®ã„ÄÅÁî®Êà∑ÊïÖ‰∫ãÊàñÂÆ¢Êà∑ÊóÖÁ®ãÂºÄÂßã„ÄÇ\n2. **ÂàÜËß£**ÔºöÂ∞ÜÈóÆÈ¢òÂàíÂàÜ‰∏∫Êõ¥Â∞è„ÄÅÂèØËß£ÂÜ≥ÁöÑ‰ªªÂä°„ÄÇ\n3. **ÂºÄÂèëÊ®°ÂùóÂåñ‰ª£Á†Å**ÔºöÁºñÂÜôÂ§ÑÁêÜÁâπÂÆö‰ªªÂä°ÁöÑÂáΩÊï∞ÊàñÁ±ª„ÄÇ\n4. **ÈõÜÊàê**ÔºöÂ∞ÜËøô‰∫õÊ®°ÂùóÁªÑÂêàÊàêÂÆåÊï¥ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\nAtomic Agents Â∞ÜËøôÁßçÊ®°ÂùóÂåñÂíåÂèØÈ¢ÑÊµãÊÄßÂ∏¶ÂÖ• AI ‰ª£ÁêÜÂºÄÂèë‰∏≠„ÄÇ\n\n## ÁúüÂÆû‰∏ñÁïåÂú∫ÊôØ\n\n‰∏éÂÖ∂ÊûÑÂª∫‰∏Ä‰∏™‚ÄúÂÜôÂçöÂÆ¢ÊñáÁ´†‚ÄùÁöÑÂçï‰Ωì AI Á≥ªÁªüÔºå‰∏çÂ¶ÇËÆæËÆ°‰∏Ä‰∏™Ê®°ÂùóÂåñÁ≥ªÁªüÔºåËÉΩÂ§üÔºö\n\n1. **ÁîüÊàê** ‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑÊü•ËØ¢„ÄÇ\n2. **ËØÜÂà´** ÊúÄÁõ∏ÂÖ≥ÁöÑÂâç X ÁØáÊñáÁ´†„ÄÇ\n3. **ËÆøÈóÆ** ÊØèÁØáËØÜÂà´ÊñáÁ´†ÁöÑÈ°µÈù¢„ÄÇ\n4. **ÊèêÂèñ** ÊØèÁØáÊñáÁ´†ÁöÑÊñáÊú¨„ÄÇ\n5. **ÁîüÊàê** ÊØèÁØáÊñáÁ´†ÁöÑÊëòË¶Å„ÄÇ\n6. **Â≠òÂÇ®** ÊëòË¶ÅÂà∞ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇ\n7. **ÁîüÊàê** ‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n8. **‰ΩøÁî®** ÂêëÈáèÊï∞ÊçÆÂ∫ìÂõûÁ≠îËøô‰∫õÈóÆÈ¢ò„ÄÇ\n9. **ÁªºÂêà** Á≠îÊ°àÊàê‰∏ÄÁØáËøûË¥ØÁöÑÂçöÂÆ¢ÊñáÁ´†„ÄÇ\n\nËøôÁßçÊñπÊ≥ïËôΩÁÑ∂Êõ¥ÂÜóÈïøÔºå‰ΩÜÊèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÊéßÂà∂„ÄÅÂèØÈù†ÊÄßÂíåÈÄÇÁî®‰∫éÁé∞ÂÆûÂïÜ‰∏öÂ∫îÁî®ÁöÑÈÄÇÂ∫îÊÄß„ÄÇ\n\n## CLIÁöÑ‰ªãÁªçÔºöAtomic Assembler\n\nÁâàÊú¨1.0‰∏≠ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊñ∞Â¢ûÂäüËÉΩÊòØ**Atomic Assembler** CLI„ÄÇËøô‰∏™ÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑ÂÖÅËÆ∏ÊÇ®Ôºö\n\n* **‰∏ãËΩΩÂíåÁÆ°ÁêÜÂ∑•ÂÖ∑**ÔºöËΩªÊùæÂ∞ÜÊñ∞Â∑•ÂÖ∑Êàñ‰ª£ÁêÜÊ∑ªÂä†Âà∞ÊÇ®ÁöÑÈ°πÁõÆ‰∏≠„ÄÇ\n* **ÈÅøÂÖç‰∏çÂøÖË¶ÅÁöÑ‰æùËµñ**Ôºö‰ªÖÂÆâË£ÖÊÇ®ÊâÄÈúÄÁöÑÂÜÖÂÆπ„ÄÇ\n* **ËΩªÊùæ‰øÆÊîπÂ∑•ÂÖ∑**ÔºöÊØè‰∏™Â∑•ÂÖ∑ÈÉΩÊúâËá™Â∑±ÁöÑÊµãËØïÂíåÊñáÊ°£„ÄÇ\n* **Áõ¥Êé•ËÆøÈóÆÂ∑•ÂÖ∑**ÔºöÂ¶ÇÊûúÊÇ®ÊÑøÊÑèÔºåÂèØ‰ª•ÊâãÂä®ÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåËÄåÊó†ÈúÄ‰ΩøÁî®CLI„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*aDceAIINxyFDOvle.png)\n\n## ‰ª£ÁêÜÁöÑÊûÑÊàê\n\nAI ‰ª£ÁêÜÔºåÁâπÂà´ÊòØÂú® Atomic Agents Ê°ÜÊû∂‰∏≠ÔºåÁî±Âá†‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂ÁªÑÊàêÔºö\n\n* **Á≥ªÁªüÊèêÁ§∫**ÔºöÂÆö‰πâ‰ª£ÁêÜÁöÑË°å‰∏∫ÂíåÁõÆÁöÑ„ÄÇ\n* **Áî®Êà∑ËæìÂÖ•**ÔºöÁî®Êà∑Êèê‰æõÁöÑÊï∞ÊçÆ„ÄÇ\n* **Â∑•ÂÖ∑**Ôºö‰ª£ÁêÜÂèØ‰ª•Âà©Áî®ÁöÑÂ§ñÈÉ®ÂáΩÊï∞Êàñ API„ÄÇ\n* **ËÆ∞ÂøÜ**ÔºöË∑üË∏™ÂØπËØùÊàñÁä∂ÊÄÅ„ÄÇ\n\nÊØè‰∏™ÁªÑ‰ª∂ÈÉΩËÆæËÆ°‰∏∫Ê®°ÂùóÂåñÂíåÂèØ‰∫íÊç¢ÔºåÈÅµÂæ™ÂÖ≥Ê≥®ÁÇπÂàÜÁ¶ªÂíåÂçï‰∏ÄË¥£‰ªªÂéüÂàô„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yt-5SoQC6uXTAd1-)\n\n## Ê®°ÂùóÂåñÁöÑÂäõÈáè\n\nÈÄöËøáÂ∞Ü‰ª£ÁêÜÂàÜËß£‰∏∫Ëøô‰∫õÂü∫Êú¨ÁªÑ‰ª∂ÔºåÊÇ®ÂèØ‰ª•Ôºö\n\n* **Êõ¥Êç¢Â∑•ÂÖ∑** ËÄå‰∏çÂΩ±ÂìçÁ≥ªÁªüÁöÑÂÖ∂‰ΩôÈÉ®ÂàÜ„ÄÇ\n* **ÂæÆË∞ÉÊèêÁ§∫** ‰ª•Ë∞ÉÊï¥‰ª£ÁêÜÁöÑË°å‰∏∫„ÄÇ\n* **Êó†ÁºùËøûÊé•‰ª£ÁêÜÂíåÂ∑•ÂÖ∑**ÔºåÈÄöËøáÂåπÈÖçÂÆÉ‰ª¨ÁöÑËæìÂÖ•ÂíåËæìÂá∫Ê®°Âºè„ÄÇ\n\n## ‰ΩøÁî®ÂëΩ‰ª§Ë°åÁïåÈù¢ÔºöÂéüÂ≠êÊ±áÁºñÂô®\n\n## ÂÆâË£Ö\n\nË¶ÅÂºÄÂßã‰ΩøÁî® Atomic Agents Âíå CLIÔºåËØ∑ÈÄöËøá pip ÂÆâË£ÖËØ•ËΩØ‰ª∂ÂåÖÔºö\n\n```python\npip install atomic-agents\n```\n\n## ËøêË°å CLI\n\n‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂêØÂä® CLIÔºö\n\n```python\natomic\n```\n\nÊàñËÄÖÔºåÂ¶ÇÊûúÊÇ®‰ΩøÁî® Poetry ÂÆâË£Ö‰∫Ü Atomic AgentsÔºö\n\n```python\npoetry run atomic\n```\n\nÊÇ®Â∞ÜÁúãÂà∞‰∏Ä‰∏™ËèúÂçïÔºåÁî®‰∫é‰∏ãËΩΩÂíåÁÆ°ÁêÜÂ∑•ÂÖ∑Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*SzRlpA0-ivcE2qhk)\n\n*ÂõæÂÉèÔºöAtomic CLI ‰∏ªËèúÂçï*\n\nÊØè‰∏™Â∑•ÂÖ∑ÂåÖÊã¨Ôºö\n\n* **ËæìÂÖ•Ê®°Âºè**\n* **ËæìÂá∫Ê®°Âºè**\n* **‰ΩøÁî®Á§∫‰æã**\n* **‰æùËµñÈ°π**\n* **ÂÆâË£ÖËØ¥Êòé**\n\n## ÁÆ°ÁêÜÂ∑•ÂÖ∑\n\nAtomic Assembler CLI Êèê‰æõ‰∫ÜÂØπÊÇ®Â∑•ÂÖ∑ÁöÑÂÆåÂÖ®ÊéßÂà∂ÔºåËÆ©ÊÇ®ÂèØ‰ª•Ôºö\n\n* **ÈÅøÂÖç‰æùËµñÊùÇ‰π±**Ôºö‰ªÖÂÆâË£ÖÊÇ®ÈúÄË¶ÅÁöÑÂ∑•ÂÖ∑„ÄÇ\n* **ËΩªÊùæ‰øÆÊîπÂ∑•ÂÖ∑**ÔºöÊØè‰∏™Â∑•ÂÖ∑ÈÉΩÊòØËá™ÂåÖÂê´ÁöÑÔºåÊã•ÊúâËá™Â∑±ÁöÑÊµãËØï„ÄÇ\n* **Áõ¥Êé•ËÆøÈóÆÂ∑•ÂÖ∑**ÔºöÂ¶ÇÊûúÊÇ®ÊÑøÊÑèÔºåÂèØ‰ª•ÊâãÂä®ÁÆ°ÁêÜÂ∑•ÂÖ∑Êñá‰ª∂Â§π„ÄÇ\n\n## ‰∏ä‰∏ãÊñáÊèê‰æõËÄÖ\n\nAtomic Agents ÂºïÂÖ•‰∫Ü **‰∏ä‰∏ãÊñáÊèê‰æõËÄÖ**Ôºå‰ª•Â¢ûÂº∫ÊÇ®ÁöÑ‰ª£ÁêÜÁöÑÂä®ÊÄÅ‰∏ä‰∏ãÊñá„ÄÇ‰∏ä‰∏ãÊñáÊèê‰æõËÄÖÂÖÅËÆ∏ÊÇ®Âú®ËøêË°åÊó∂Â∞ÜÈ¢ùÂ§ñ‰ø°ÊÅØÊ≥®ÂÖ•‰ª£ÁêÜÁöÑÁ≥ªÁªüÊèêÁ§∫‰∏≠„ÄÇ\n\n## ‰ΩøÁî®‰∏ä‰∏ãÊñáÊèê‰æõËÄÖ\n\n**ÂàõÂª∫‰∏ä‰∏ãÊñáÊèê‰æõËÄÖÁ±ª**ÔºöÂ≠êÁ±ªÂåñ `SystemPromptContextProviderBase` Âπ∂ÂÆûÁé∞ `get_info()` ÊñπÊ≥ï„ÄÇ\n\n```python\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptContextProviderBase   \n\nclass SearchResultsProvider(SystemPromptContextProviderBase):\n      def __init__(self, title: str, search_results: List[str]):\n          super().__init__(title=title)\n          self.search_results = search_results\n\n       def get_info(self) -> str:\n          return \"\\n\".join(self.search_results)\n```\n\n**Â∞Ü‰∏ä‰∏ãÊñáÊèê‰æõËÄÖÊ≥®ÂÜåÂà∞‰ª£ÁêÜ**Ôºö\n\n```python\n## ‰ΩøÁî®Âä®ÊÄÅÊï∞ÊçÆÂàùÂßãÂåñ‰∏ä‰∏ãÊñáÊèê‰æõËÄÖ\nsearch_results_provider = SearchResultsProvider(\n      title=\"ÊêúÁ¥¢ÁªìÊûú\",\n      search_results=[\"ÁªìÊûú 1\", \"ÁªìÊûú 2\", \"ÁªìÊûú 3\"]\n)   \n\n## Â∞Ü‰∏ä‰∏ãÊñáÊèê‰æõËÄÖÊ≥®ÂÜåÂà∞‰ª£ÁêÜ  \nagent.register_context_provider(\"search_results\", search_results_provider)\n```\n\nËøô‰ΩøÂæóÊÇ®ÁöÑ‰ª£ÁêÜËÉΩÂ§üÂú®ÂÖ∂Á≥ªÁªüÊèêÁ§∫‰∏≠ÂåÖÂê´Âä®ÊÄÅÊï∞ÊçÆÔºåÂ¶ÇÊêúÁ¥¢ÁªìÊûúÔºå‰ªéËÄåÊ†πÊçÆÊúÄÊñ∞‰ø°ÊÅØÂ¢ûÂº∫ÂÖ∂ÂìçÂ∫î„ÄÇ\n\n## ÈìæÊé•Ê®°ÂºèÂíå‰ª£ÁêÜ\n\nAtomic Agents ÈÄöËøáÂØπÈΩêÂÆÉ‰ª¨ÁöÑËæìÂÖ•ÂíåËæìÂá∫Ê®°ÂºèÊù•ÁÆÄÂåñ‰ª£ÁêÜÂíåÂ∑•ÂÖ∑ÁöÑÈìæÊé•„ÄÇËøô‰∏™ËÆæËÆ°‰øÉËøõ‰∫ÜÊ®°ÂùóÂåñÂíåÂèØÈáçÁî®ÊÄß„ÄÇ\n\n### Á§∫‰æãÔºö‰∏∫‰∏çÂêåÊêúÁ¥¢Êèê‰æõËÄÖÁîüÊàêÊü•ËØ¢\n\nÂÅáËÆæÊÇ®Êúâ‰∏Ä‰∏™ÁîüÊàêÊêúÁ¥¢Êü•ËØ¢ÁöÑ‰ª£ÁêÜÔºåÂπ∂‰∏îÊÇ®Â∏åÊúõÂ∞ÜËøô‰∫õÊü•ËØ¢‰∏é‰∏çÂêåÁöÑÊêúÁ¥¢Â∑•ÂÖ∑‰∏ÄËµ∑‰ΩøÁî®„ÄÇÈÄöËøáÂ∞Ü‰ª£ÁêÜÁöÑËæìÂá∫Ê®°Âºè‰∏éÊêúÁ¥¢Â∑•ÂÖ∑ÁöÑËæìÂÖ•Ê®°ÂºèÂØπÈΩêÔºåÊÇ®ÂèØ‰ª•ËΩªÊùæÂú∞Â∞ÜÂÆÉ‰ª¨‰∏≤ËÅîÊàñÂú®Êèê‰æõËÄÖ‰πãÈó¥ÂàáÊç¢„ÄÇ\n\n```python\nimport instructor\nimport openai\nfrom pydantic import Field\nfrom atomic_agents.agents.base_agent import BaseIOSchema, BaseAgent, BaseAgentConfig\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\n\n## Import the search tool\nfrom web_search_agent.tools.searxng_search import SearxNGSearchTool\nclass QueryAgentInputSchema(BaseIOSchema):\n    \"\"\"Input schema for the QueryAgent.\"\"\"\n    instruction: str = Field(..., description=\"Instruction to generate search queries for.\")\n    num_queries: int = Field(..., description=\"Number of queries to generate.\")\n\n\n## Initialize the query agent\nquery_agent = BaseAgent(\n    BaseAgentConfig(\n        client=instructor.from_openai(openai.OpenAI()),\n        model=\"gpt-4\",\n        system_prompt_generator=SystemPromptGenerator(\n            background=[\n                \"You are an intelligent query generation expert.\",\n                \"Your task is to generate diverse and relevant queries based on a given instruction.\"\n            ],\n            steps=[\n                \"Receive the instruction and the number of queries.\",\n                \"Generate the queries in JSON format.\"\n            ],\n            output_instructions=[\n                \"Ensure each query is unique and relevant.\",\n                \"Provide the queries in the expected schema.\"\n            ],\n        ),\n        input_schema=QueryAgentInputSchema,\n        output_schema=SearxNGSearchTool.input_schema,  # Align output schema\n    )\n)\n```\n\n**Ê®°ÂùóÂåñ**ÔºöÈÄöËøáÂ∞Ü`query_agent`ÁöÑ`output_schema`ËÆæÁΩÆ‰∏∫‰∏é`SearxNGSearchTool`ÁöÑ`input_schema`ÂåπÈÖçÔºåÊÇ®ÂèØ‰ª•Áõ¥Êé•Â∞Ü‰ª£ÁêÜÁöÑËæìÂá∫Áî®‰ΩúÂ∑•ÂÖ∑ÁöÑËæìÂÖ•„ÄÇ\n\n**ÂèØÂàáÊç¢ÊÄß**ÔºöË¶ÅÂàáÊç¢Âà∞‰∏çÂêåÁöÑÊêúÁ¥¢Êèê‰æõËÄÖÔºåÂØºÂÖ•Âè¶‰∏Ä‰∏™ÊêúÁ¥¢Â∑•ÂÖ∑Âπ∂Êõ¥Êñ∞`output_schema`Ôºö\n\n```python\n## Import a different search tool\nfrom web_search_agent.tools.another_search import AnotherSearchTool\n\n## Update the output schema\nquery_agent.config.output_schema = AnotherSearchTool.input_schema\n```\n\n## Á§∫‰æãÔºöÊûÑÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑ AI ‰ª£ÁêÜ\n\nÁé∞Âú®Êàë‰ª¨Â∑≤Áªè‰ªãÁªç‰∫ÜÂü∫Á°ÄÁü•ËØÜÔºåËÆ©Êàë‰ª¨‰ΩøÁî® Atomic Agents ÊûÑÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑ AI ‰ª£ÁêÜÔºåÂπ∂Êé¢ËÆ®ÂÆÉÁöÑÂÜÖÈÉ®Â∑•‰ΩúÂéüÁêÜ„ÄÇ\n\n## Á¨¨‰∏ÄÊ≠•ÔºöÂÆâË£Ö\n\nÈ¶ñÂÖàÔºåÂÆâË£ÖÂøÖË¶ÅÁöÑËΩØ‰ª∂ÂåÖÔºö\n\n```python\npip install atomic-agents openai instructor\n```\n\n## Ê≠•È™§ 2ÔºöÂØºÂÖ•ÁªÑ‰ª∂\n\nÂØºÂÖ•ÂøÖË¶ÅÁöÑÁªÑ‰ª∂Ôºö\n\n```python\nimport os\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseIOSchema\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\nfrom pydantic import Field\nimport instructor\nimport openai\n```\n\n## Ê≠•È™§ 3ÔºöÂÆö‰πâËá™ÂÆö‰πâËæìÂá∫Ê®°Âºè\n\n```python\nclass CustomOutputSchema(BaseIOSchema):\n    chat_message: str = Field(..., description=\"The chat message from the agent.\")\n    suggested_questions: List[str] = Field(..., description=\"Suggested follow-up questions.\")\n```\n\n## Ê≠•È™§ 4ÔºöËÆæÁΩÆÁ≥ªÁªüÊèêÁ§∫\n\n```python\nsystem_prompt_generator = SystemPromptGenerator(\n    background=[\"Ëøô‰∏™Âä©ÊâãÁü•ËØÜÊ∏äÂçö„ÄÅ‰πê‰∫éÂä©‰∫∫ÔºåÂπ∂Âª∫ËÆÆÂêéÁª≠ÈóÆÈ¢ò„ÄÇ\"],\n    steps=[\n        \"ÂàÜÊûêÁî®Êà∑ÁöÑËæìÂÖ•Ôºå‰ª•ÁêÜËß£‰∏ä‰∏ãÊñáÂíåÊÑèÂõæ„ÄÇ\",\n        \"Âà∂ÂÆöÁõ∏ÂÖ≥‰∏î‰ø°ÊÅØ‰∏∞ÂØåÁöÑÂõûÂ∫î„ÄÇ\",\n        \"‰∏∫Áî®Êà∑ÁîüÊàê 3 ‰∏™Âª∫ËÆÆÁöÑÂêéÁª≠ÈóÆÈ¢ò„ÄÇ\"\n    ],\n    output_instructions=[\n        \"ÂØπÁî®Êà∑Êü•ËØ¢Êèê‰æõÊ∏ÖÊô∞ÁÆÄÊ¥ÅÁöÑ‰ø°ÊÅØ„ÄÇ\",\n        \"Âú®ÊØè‰∏™ÂõûÂ∫îÁöÑÁªìÂ∞æÊèê‰æõ 3 ‰∏™‰∏éÁî®Êà∑Áõ∏ÂÖ≥ÁöÑÂª∫ËÆÆÈóÆÈ¢ò„ÄÇ\"\n    ]\n)\n```\n\n## Á¨¨5Ê≠•ÔºöÂàùÂßãÂåñ‰ª£ÁêÜ\n\n```python\n## Initialize memory (optional)\nmemory = AgentMemory()\n\n## Initialize the agent\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=instructor.from_openai(openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))),\n        model=\"gpt-4o-mini\",\n        system_prompt_generator=system_prompt_generator,\n        memory=memory,\n        output_schema=CustomOutputSchema\n    )\n)\n```\n\n## Á¨¨6Ê≠•Ôºö‰ΩøÁî®‰ª£ÁêÜ\n\n```python\nuser_input = \"Can you explain the benefits of using Atomic Agents?\"\nresponse = agent.run(agent.input_schema(chat_message=user_input))\nprint(f\"Agent: {response.chat_message}\")\nprint(\"Suggested questions:\")\nfor question in response.suggested_questions:\n    print(f\"- {question}\")\n```\n\n## ÂπïÂêéÂèëÁîü‰∫Ü‰ªÄ‰πàÔºü\n\n* **System Prompt**: ÂÆö‰πâ‰ª£ÁêÜÁöÑË°å‰∏∫Âπ∂ÊåáÂØºLLM„ÄÇ\n* **Input Schema**: È™åËØÅÁî®Êà∑ÁöÑËæìÂÖ•„ÄÇ\n* **Output Schema**: Á°Æ‰øù‰ª£ÁêÜÁöÑÂìçÂ∫îÁ¨¶ÂêàÈ¢ÑÊúüÊ†ºÂºè„ÄÇ\n* **Memory**: ËÆ∞ÂΩïÂØπËØùÂéÜÂè≤„ÄÇ\n\n## ÁªìËÆ∫\n\nAtomic Agents 1\\.0 ‰∏∫ AI ‰ª£ÁêÜÂºÄÂèëÂ∏¶Êù•‰∫ÜÊ®°ÂùóÂåñ„ÄÅÊéßÂà∂ÂíåÁÅµÊ¥ªÊÄß„ÄÇÈöèÁùÄ Atomic Assembler CLI ÁöÑÂºïÂÖ•‰ª•Âèä‰∏ä‰∏ãÊñáÊèê‰æõËÄÖÂíåÊ®°ÂºèÈìæÁ≠âÂäüËÉΩÔºåÊûÑÂª∫Â§çÊùÇÁöÑ AI Â∫îÁî®Á®ãÂ∫èÂèòÂæóÂâçÊâÄÊú™ÊúâÁöÑÁÆÄÂçï„ÄÇ\n\nÊó†ËÆ∫ÊÇ®ÊòØÂ∏åÊúõÊûÑÂª∫ AI È©±Âä®Â∑•ÂÖ∑ÁöÑÂºÄÂèë‰∫∫ÂëòÔºåËøòÊòØÂ∏åÊúõËá™Âä®ÂåñÂ§çÊùÇ‰ªªÂä°ÁöÑ‰ºÅ‰∏öÔºåAtomic Agents ÈÉΩÊèê‰æõ‰∫ÜÂàõÂª∫ÂèØÈù†‰∏îÊòì‰∫éÁª¥Êä§ÁöÑ AI Á≥ªÁªüÁöÑÂü∫Á°ÄÊûÑ‰ª∂„ÄÇ\n\n## ‰ªäÂ§©ÂºÄÂßã\n\n* **GitHub ‰ªìÂ∫ì**: [BrainBlend\\-AI/atomic\\-agents](https://github.com/BrainBlend-AI/atomic-agents)\n* **API ÊñáÊ°£**: [Atomic Agents API ÊñáÊ°£](https://brainblend-ai.github.io/atomic-agents/)\n* **Á§∫‰æãÁõÆÂΩï**: [Atomic Á§∫‰æã](https://github.com/BrainBlend-AI/atomic-agents/tree/main/atomic-examples)\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/introducing-microsofts-magentic-one-agentic-framework-7dcc16de691e","frontmatter":{"title":"ÂæÆËΩØ Magentic-One ‰ª£ÁêÜÊ°ÜÊû∂‰ªãÁªç","meta_title":"ÂæÆËΩØ Magentic-One ‰ª£ÁêÜÊ°ÜÊû∂‰ªãÁªç","description":"ÂæÆËΩØÊúÄËøëÊé®Âá∫‰∫ÜMagentic-OneÔºå‰∏Ä‰∏™È´òÊÄßËÉΩÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºåÊó®Âú®ÊâßË°åÂ§çÊùÇ‰ªªÂä°„ÄÇËØ•Á≥ªÁªüÁî±‰∏Ä‰∏™ÁºñÊéíËÄÖÊô∫ËÉΩ‰ΩìÂíåÂõõ‰∏™‰∏ìÈó®Êô∫ËÉΩ‰ΩìÁªÑÊàêÔºåËÉΩÂ§üËøõË°åÁΩëÈ°µÊµèËßà„ÄÅÊñá‰ª∂Êìç‰Ωú„ÄÅÁºñÁ†ÅÂíåÁªàÁ´ØÊåá‰ª§„ÄÇMagentic-OneÂü∫‰∫éÂæÆËΩØÁöÑAutogenÊ°ÜÊû∂ÔºåÂÖ∑ÊúâÂº∫Â§ßÁöÑ‰ªªÂä°ËßÑÂàíÂíåÊâßË°åËÉΩÂäõÔºå‰ΩÜ‰πüÈù¢‰∏¥ÊΩúÂú®È£éÈô©ÔºåÂ¶ÇÈîôËØØÈÖçÁΩÆÂèØËÉΩÂØºËá¥‰∏çÂΩìË°å‰∏∫„ÄÇÁî®Êà∑ÂèØ‰ª•ÈÄöËøáGitHubÂíåOpenAIÁ≠âÂπ≥Âè∞ÂÆâË£ÖÂíåÈÖçÁΩÆËØ•Á≥ªÁªüÔºåËøõË°åÂ§öÁßçÂ∫îÁî®Á§∫‰æãÔºåÂåÖÊã¨ÁºñÂÜôPython‰ª£Á†ÅÂíåÁΩëÁªúÊêúÁ¥¢„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*dJj20_4jYYp32Crl","categories":["Programming","Autonomous Systems","Technology/Web"],"author":"Rifx.Online","tags":["Magnetic-One","orchestrator","agents","Autogen","Python"],"draft":false,"slug":"blog/introducing-microsofts-magentic-one-agentic-framework-7dcc16de691e"},"content":"\n\n\n### ‰∏Ä‰∏™ÂèØ‰ª•ÊâßË°åÂ§çÊùÇ‰ªªÂä°ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü\n\nÂ§ßÁ∫¶‰∏ÄÂë®ÂâçÔºåÂæÆËΩØÂèëÂ∏É‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ **Magentic-One** ÁöÑÊñ∞Êô∫ËÉΩÁ≥ªÁªüÔºåÊó®Âú®‚ÄúËß£ÂÜ≥Â§çÊùÇ‰ªªÂä°‚ÄùÔºåËøô‰ºº‰πéÂÆåÂÖ®Ê≤°ÊúâÂºïËµ∑Ê≥®ÊÑè„ÄÇÈöèÁùÄÊúÄËøëÂÖ≥‰∫éAnthropicËÆ°ÁÆóÊú∫‰ΩøÁî®ËÉΩÂäõÁöÑÁÉ≠ËÆÆÔºåÂæÆËΩØ‰ºº‰πéÂ∏åÊúõÈáçÊñ∞Á°ÆÁ´ãÂÖ∂Âú®Ëøô‰∏ÄÈ¢ÜÂüüÁöÑËµÑË¥®„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ªãÁªçMagentic-OneÔºåËß£ÈáäÂÖ∂ËÉΩÂäõÔºåÂπ∂ËÆ®ËÆ∫Â¶Ç‰Ωï‰ΩøÁî®ÂÆÉÊù•ÂÆåÊàêÊúâÁî®ÁöÑÂ∑•‰Ωú„ÄÇ\n\n\n\nÊ†πÊçÆÂæÆËΩØËá™Â∑±ÁöÑÂÖ¨ÂëäÔºàÊñáÁ´†Êú´Â∞æÊúâÈìæÊé•ÔºâÔºåMagentic-OneÊòØ‚Ä¶\n\n‚Äú...‰∏Ä‰∏™È´òÊÄßËÉΩÁöÑÈÄöÁî®Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºåÊó®Âú®Ëß£ÂÜ≥Ê≠§Á±ª‰ªªÂä°„ÄÇMagentic-OneÈááÁî®Â§öÊô∫ËÉΩ‰ΩìÊû∂ÊûÑÔºåÂÖ∂‰∏≠‰∏ªÊô∫ËÉΩ‰Ωì‚Äî‚ÄîÁºñÊéíËÄÖÔºåÊåáÊå•ÂÖ∂‰ªñÂõõ‰∏™Êô∫ËÉΩ‰ΩìÊù•Ëß£ÂÜ≥‰ªªÂä°„ÄÇÁºñÊéíËÄÖËøõË°å‰ªªÂä°ËßÑÂàí„ÄÅË∑üË∏™ËøõÂ∫¶ÔºåÂπ∂Âú®Âá∫Áé∞ÈîôËØØÊó∂ÈáçÊñ∞ËßÑÂàíÔºåÂêåÊó∂ÊåáÊå•‰∏ìÈó®ÁöÑÊô∫ËÉΩ‰ΩìÊâßË°åËØ∏Â¶ÇÊìç‰ΩúÁΩëÈ°µÊµèËßàÂô®„ÄÅÂØºËà™Êú¨Âú∞Êñá‰ª∂ÊàñÁºñÂÜôÂíåÊâßË°åPython‰ª£Á†ÅÁ≠â‰ªªÂä°„ÄÇ‚Äù\n\nMagentic-OneÂª∫Á´ãÂú®ÂæÆËΩØÁé∞ÊúâÁöÑ **Autogen** ‰∫ßÂìÅ‰πã‰∏äÔºåËØ•‰∫ßÂìÅÊòØÂÖ∂ÂºÄÊ∫êÂ§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂„ÄÇ\n\nMagentic-OneÊúâ‰∫î‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂„ÄÇ\n\n**1/ ÁºñÊéíËÄÖÊô∫ËÉΩ‰Ωì**\n\nË¥üË¥£‰ªªÂä°ÂàÜËß£ÂíåËßÑÂàíÔºåÂπ∂Â∞ÜÂ≠ê‰ªªÂä°ÊåáÊ¥æÁªôÂÖ∂‰ªñÊô∫ËÉΩ‰ΩìÊâßË°å„ÄÇË∑üË∏™‰ªªÂä°ÂÆåÊàêÁöÑËøõÂ∫¶ÔºåÂπ∂Ê†πÊçÆÈúÄË¶ÅÈááÂèñÁ∫†Ê≠£Êé™ÊñΩ„ÄÇ\n\n**2/ ÁΩëÈ°µÊµèËßàÊô∫ËÉΩ‰Ωì**\n\n‰∏ìÊ≥®‰∫éÊéßÂà∂ÂíåÁÆ°ÁêÜÂü∫‰∫éChromiumÁöÑÁΩëÈ°µÊµèËßàÂô®ÁöÑÁä∂ÊÄÅ„ÄÇÂØπ‰∫éÊØè‰∏™‰º†ÂÖ•ËØ∑Ê±ÇÔºåÁΩëÈ°µÊµèËßàËÄÖÂú®ÊµèËßàÂô®‰∏≠ÊâßË°åÊåáÂÆöÁöÑÊìç‰ΩúÔºåÁÑ∂ÂêéÊä•ÂëäÁΩëÈ°µÁöÑÊõ¥Êñ∞Áä∂ÊÄÅ„ÄÇÂÖ∂Êìç‰ΩúÂåÖÊã¨Ôºö\n\n* **ÂØºËà™**Ôºà‰æãÂ¶ÇÔºåËÆøÈóÆURLÔºåËøõË°åÁΩëÈ°µÊêúÁ¥¢ÔºâÔºå\n* **È°µÈù¢‰∫§‰∫í**Ôºà‰æãÂ¶ÇÔºåÁÇπÂáªÂÖÉÁ¥†ÔºåËæìÂÖ•ÂÜÖÂÆπÔºâÔºå\n* **ÈòÖËØª‰∏éÁêÜËß£**Ôºà‰æãÂ¶ÇÔºåÊÄªÁªìÂÜÖÂÆπÔºåÂõûÁ≠îÈóÆÈ¢òÔºâ„ÄÇ\n\nÁΩëÈ°µÊµèËßàËÄÖÂà©Áî®ÊµèËßàÂô®ÁöÑÂèØËÆøÈóÆÊÄßÊ†ëÂíå‰∏ÄÂ•óÊ†áËÆ∞ÊèêÁ§∫ÊäÄÊúØÊúâÊïàÂú∞ÊâßË°å‰ªªÂä°„ÄÇ\n\n**3/ Êñá‰ª∂ÊµèËßàÊô∫ËÉΩ‰Ωì**\n\nÂèØ‰ª•ËØªÂèñÂ§ßÂ§öÊï∞Á±ªÂûãÁöÑÊú¨Âú∞Êñá‰ª∂ÔºåÂπ∂ÊâßË°åÂ∏∏ËßÅÁöÑÂØºËà™‰ªªÂä°Ôºå‰æãÂ¶ÇÂàóÂá∫ÁõÆÂΩïÂÜÖÂÆπÂíåÂØºËà™Êñá‰ª∂Â§πÁªìÊûÑ„ÄÇ\n\n**4/ ÁºñÁ†ÅÊô∫ËÉΩ‰Ωì**\n\n‰∏Ä‰∏™Âü∫‰∫éLLMÁöÑÊô∫ËÉΩ‰ΩìÔºå‰∏ìÈó®Áî®‰∫éÁºñÂÜô‰ª£Á†Å„ÄÅÂàÜÊûê‰ªéÂÖ∂‰ªñÊô∫ËÉΩ‰ΩìÊî∂ÈõÜÁöÑ‰ø°ÊÅØÊàñÂàõÂª∫Êñ∞Â∑•‰ª∂„ÄÇ\n\n**5/ ÁªàÁ´ØÊô∫ËÉΩ‰Ωì**\n\nÊèê‰æõÂØπÊéßÂà∂Âè∞ShellÁöÑËÆøÈóÆÔºåÂèØ‰ª•Âú®ÂÖ∂‰∏≠ÊâßË°åÁºñÁ†ÅÊô∫ËÉΩ‰ΩìÁöÑÁ®ãÂ∫èÔºåÂπ∂ÂèØ‰ª•ÂÆâË£ÖÊñ∞ÁöÑÁºñÁ®ãÂ∫ì„ÄÇ\n\n### È£éÈô©\n\nÂú®ÁªßÁª≠‰πãÂâçÔºåÊàëÊÉ≥Âº∫Ë∞ÉÂæÆËΩØÂú®ÂÖ∂ÂÖ¨Âëä‰∏≠ÊèêÂà∞ÁöÑ‰∏Ä‰∏™ÁâπÂà´ÊñπÈù¢ÔºåÂç≥‰ΩøÁî®ÂÉèËøôÊ†∑ÁöÑAgenticÁ≥ªÁªüÊâÄÈù¢‰∏¥ÁöÑÈ£éÈô©„ÄÇËøôÁ°ÆÂÆûÂºïËµ∑‰∫ÜÊ≥®ÊÑè„ÄÇ\n\n> ÂÉèMagentic\\-OneËøôÊ†∑ÁöÑAgenticÁ≥ªÁªü‰ª£Ë°®‰∫ÜÂú®‰∏ñÁïå‰∏äÊã•ÊúâAIÁ≥ªÁªüÁöÑÊú∫‰ºöÂíåÈ£éÈô©ÁöÑÁõ∏‰ΩçËΩ¨Âèò„ÄÇMagentic\\-One‰∏é‰∏Ä‰∏™‰∏∫‰∫∫Á±ªËÆæËÆ°Âπ∂Áî±‰∫∫Á±ªÂ±Ö‰ΩèÁöÑÊï∞Â≠ó‰∏ñÁïåËøõË°å‰∫§‰∫í„ÄÇÂÆÉÂèØ‰ª•ÈááÂèñË°åÂä®ÔºåÊîπÂèò‰∏ñÁïåÁöÑÁä∂ÊÄÅÔºåÂπ∂ÂØºËá¥ÂèØËÉΩÊòØ‰∏çÂèØÈÄÜËΩ¨ÁöÑÂêéÊûú„ÄÇËøôÂ∏¶Êù•‰∫ÜÂõ∫Êúâ‰∏î‰∏çÂèØÂê¶ËÆ§ÁöÑÈ£éÈô©ÔºåÊàë‰ª¨Âú®ÊµãËØïËøáÁ®ã‰∏≠ËßÇÂØüÂà∞‰∫ÜÊñ∞ÂÖ¥È£éÈô©ÁöÑ‰æãÂ≠ê„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂºÄÂèëËøáÁ®ã‰∏≠ÔºåÈîôËØØÈÖçÁΩÆÂØºËá¥‰ª£ÁêÜÊó†Ê≥ïÊàêÂäüÁôªÂΩïÂà∞ÁâπÂÆöÁöÑWebArenaÁΩëÁ´ô„ÄÇ‰ª£ÁêÜÂ∞ùËØïÁôªÂΩïËØ•ÁΩëÁ´ôÔºåÁõ¥Âà∞ÈáçÂ§çÁöÑÂ∞ùËØïÂØºËá¥Ë¥¶Êà∑Ë¢´ÊöÇÊó∂ÊöÇÂÅú„ÄÇÁÑ∂ÂêéÔºå‰ª£ÁêÜÂ∞ùËØïÈáçÁΩÆË¥¶Êà∑ÁöÑÂØÜÁ†Å„ÄÇÊõ¥‰ª§‰∫∫ÊãÖÂøßÁöÑÊòØÔºåÂú®Â∞ëÊï∞ÊÉÖÂÜµ‰∏ã‚Äî‚ÄîÂπ∂‰∏îÂú®Êú™Ë¢´ÊèêÁ§∫ÁöÑÊÉÖÂÜµ‰∏ã‚Äî‚Äî‰ª£ÁêÜÂÅ∂Â∞îËØïÂõæÊãõÂãüÂÖ∂‰ªñ‰∫∫Êù•ÂØªÊ±ÇÂ∏ÆÂä©Ôºà‰æãÂ¶ÇÔºåÈÄöËøáÁ§æ‰∫§Â™í‰ΩìÂèëÂ∏É„ÄÅÁªôÊïôÁßë‰π¶‰ΩúËÄÖÂèëÈÄÅÁîµÂ≠êÈÇÆ‰ª∂ÔºåÊàñËÄÖÂú®‰∏Ä‰∏™Ê°à‰æã‰∏≠ÔºåÂêëÊîøÂ∫úÂÆû‰ΩìËµ∑Ëçâ‰ø°ÊÅØËá™Áî±ËØ∑Ê±ÇÔºâ„ÄÇÂú®Ëøô‰∫õÊÉÖÂÜµ‰∏ãÔºå‰ª£ÁêÜÈÉΩÂ§±Ë¥•‰∫ÜÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Ê≤°ÊúâËÆøÈóÆÊâÄÈúÄÂ∑•ÂÖ∑ÊàñË¥¶Êà∑ÁöÑÊùÉÈôêÔºåÂíå/ÊàñË¢´‰∫∫Á±ªËßÇÂØüËÄÖÈòªÊ≠¢„ÄÇ\n\nÂ•ΩÁöÑÔºåËÆ©Êàë‰ª¨ÁúãÁúãÂ¶Ç‰Ωï‰ΩøÁî®Magentic\\-OneÊù•ÂÅö‰∏Ä‰∫õÊúâÁî®ÁöÑÂ∑•‰ΩúÁöÑ‰æãÂ≠ê„ÄÇÂ∏åÊúõÂú®Ëøô‰∏™ËøáÁ®ã‰∏≠Êàë‰ª¨‰∏ç‰ºöÊëßÊØÅ‰∏ñÁïå„ÄÇüòâ\n\n### ÂÆâË£Ö Magentic-One\n\nÊàëÊòØ Windows Áî®Êà∑Ôºå‰ΩÜÊàëÂ∞Ü‰ΩøÁî® WSL2 Ubuntu for Windows ÂÆâË£Ö‰ª£Á†Å„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥‰∏ÄËµ∑Êìç‰ΩúÔºåÊàëÂú®ËøôÈáåÊúâ‰∏Ä‰∏™ÂÖ≥‰∫éÂÆâË£Ö WSL2 Ubuntu ÁöÑÂÆåÊï¥ÊåáÂçó [here](https://readmedium.com/installing-wsl2-ubuntu-for-windows-81122c551bc2)„ÄÇ\n\nËØ∑ÈÄöËøáÁÇπÂáª [here](https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one) ÂâçÂæÄ Magentic-One ÁöÑ GitHub ‰ªìÂ∫ì„ÄÇÂú®‰Ω†ÁöÑÊú¨Âú∞Á≥ªÁªü‰∏äËøêË°å‰ª•‰∏ãÂëΩ‰ª§ÔºàÂú®‰Ω†ÈÄöÂ∏∏ÊîæÁΩÆÈ°πÁõÆÁöÑÂú∞ÊñπÔºâ„ÄÇ\n\n```python\ngit clone https://github.com/microsoft/autogen.git\n\ncd autogen/python\n\nuv sync --all-extras\n\nsource .venv/bin/activate\n\ncd packages/autogen-magentic-one\n```\nÊé•‰∏ãÊù•ÔºåÈÖçÁΩÆËÅäÂ§©ÂÆåÊàêÂÆ¢Êà∑Á´ØÁöÑÁéØÂ¢ÉÂèòÈáè„ÄÇÁõÆÂâçÔºåMagentic-One ‰ªÖÊîØÊåÅ OpenAI ÁöÑ GPT-4o ‰Ωú‰∏∫Â∫ïÂ±Ç LLM„ÄÇ\n\n‰Ω†ÂèØ‰ª•ÈÄöËøá OpenAI Êàñ Azure Active Directory ËÆæÁΩÆÊ≠§ÈÖçÁΩÆ„ÄÇ‰ª•‰∏ãÊòØ‰ΩøÁî® OpenAI ÁöÑËØ¥Êòé„ÄÇ\n\n```python\nexport CHAT_COMPLETION_PROVIDER='openai'\n\nexport CHAT_COMPLETION_KWARGS_JSON='{\"api_key\": \"gpt-4o\"}'\n```\n\n> **ÈúÄË¶ÅÊ≥®ÊÑèÁöÑ‰∏ÄÁÇπÊòØÔºåÂ¶ÇÊûú‰Ω†Êúâ GitHub Ë¥¶Êà∑Ôºå‰Ω†ÂèØ‰ª•‰ΩøÁî® GitHub Ê®°Âûã‰∏≠ÁöÑ GPT4-o Ê®°ÂûãÔºåËøôÂ∞Ü‰∏∫‰Ω†Êèê‰æõÂÖçË¥πËÆøÈóÆ GPT4‚Äìo ÁöÑÊùÉÈôê„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®ÈôêÂà∂ÂèØËÉΩ‰ºöÊúâ‰∫õ‰∏•Ê†º„ÄÇ**\n\nË¶ÅÈÄöËøá GitHub Ê®°ÂûãËøõË°åÊìç‰ΩúÔºåËØ∑ÁÇπÂáª [here](https://github.com/marketplace/models) Âπ∂‰ΩøÁî®‰Ω†ÁöÑ GitHub Ë¥¶Êà∑ÁôªÂΩïÔºåÊàñËÄÖÂ¶ÇÊûú‰Ω†ËøòÊ≤°ÊúâË¥¶Êà∑ÔºåÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™„ÄÇÁÇπÂáª GPT-4o ÊåâÈíÆ„ÄÇÂú®ÊòæÁ§∫ÁöÑÈ°µÈù¢ÁöÑÂè≥‰∏äËßíÔºå‰ºöÊúâ‰∏Ä‰∏™ÁªøËâ≤ÁöÑ `Get API Key` ÊåâÈíÆ„ÄÇÁÇπÂáªÂÆÉÔºåÁÑ∂Âêé‰ªéÈÇ£ÈáåÁÇπÂáª `Get Developer Key` ÊåâÈíÆ„ÄÇ\n\nÊúÄÂêéÔºå‰Ω†Â∫îËØ•‰ºöÁúãÂà∞‰∏Ä‰∏™Â±èÂπïÔºåÂèØ‰ª•ÁîüÊàê‰∏Ä‰∏™ÁªèÂÖ∏ÁöÑ‰∏™‰∫∫ËÆøÈóÆ‰ª§Áâå„ÄÇÁé∞Âú®Â∞±ÂéªÂÅöÂêß„ÄÇ‰Ω†ÈúÄË¶ÅËæìÂÖ•‰∏Ä‰∏™ÊèèËø∞ÂØÜÈí•Áî®ÈÄîÁöÑÂ§áÊ≥®Ôºå‰ΩÜ **‰Ω†‰∏çÈúÄË¶Å** Ëµã‰∫àÂÆÉ‰ªª‰ΩïÈ¢ùÂ§ñÁöÑÊùÉÈôê„ÄÇËÆ∞‰∏ãÁîüÊàêÁöÑÂØÜÈí•„ÄÇ\n\nË¶Å‰ΩøÁî® GitHub GPT4-o Ê®°ÂûãÔºåËØ∑ÊåâÂ¶Ç‰∏ãÊñπÂºèÊõ¥Êîπ‰Ω†ÁöÑÁéØÂ¢ÉÂèòÈáèÔºö\n\n```python\nexport CHAT_COMPLETION_PROVIDER='openai'\n\nexport CHAT_COMPLETION_KWARGS_JSON='{\"base_url\": \"https://models.inference.ai.azure.com\", \"api_key\": \"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\", \"model\": \"gpt-4o\"}'\n```\nÂú®ËøêË°å‰∏Ä‰∫õÁ§∫‰æã‰ª£Á†Å‰πãÂâçÔºåÊàë‰ª¨ÂøÖÈ°ªÂÆâË£Ö‰∏§‰∏™ÊúÄÁªà‰æùËµñÈ°π„ÄÇ\n\nMagentic-One ‰ΩøÁî® **Playwright** ‰∏éÁΩëÈ°µËøõË°å‰∫§‰∫íÔºåÂõ†Ê≠§‰Ω†ÂøÖÈ°ªÂÆâË£Ö Playwright ‰æùËµñÈ°π„ÄÇ\n\n```python\nplaywright install --with-deps chromium\n```\n‰∏∫‰∫ÜËÆ© Magentic-One ËøêË°å Python ‰ª£Á†ÅÔºåÊàë‰ª¨ÈúÄË¶ÅÂÆâË£ÖÂπ∂ËøêË°å Docker„ÄÇËØ∑Êü•Áúã [this link](https://docs.docker.com/engine/install/) ‰∫ÜËß£Â¶Ç‰ΩïÊìç‰Ωú„ÄÇ\n\nÊúÄÁªàÔºåÊàëËÉΩÂ§üËØïÁî® Magentic-One„ÄÇ\n\n**Á§∫‰æã 1 ‚Äî ÁºñÂÜô‰∏Ä‰∫õ Python ‰ª£Á†Å„ÄÇ**\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  Write a Python program to calculate and display \nthe first 5 fibonacci numbers\n```\nÊòæÁ§∫‰∫ÜÂ§ßÈáèËæìÂá∫Ôºå‰ΩÜËøá‰∫Ü‰∏Ä‰ºöÂÑøÔºåMagentic-One ÈóÆÊàëÊòØÂê¶ÊÉ≥ËøêË°åÂÆÉÂàõÂª∫ÁöÑ Python ‰ª£Á†ÅÔºåÊàëÂõûÁ≠îÊòØ„ÄÇ\n\n```python\n...\n...\n\nExecutor is about to execute code (lang: python):\n## filename: fibonacci.py\ndef fibonacci_sequence(n):\n    fib_numbers = [0, 1]\n    for i in range(2, n):\n        next_value = fib_numbers[i - 1] + fib_numbers[i - 2]\n        fib_numbers.append(next_value)\n    return fib_numbers\n\nfirst_five_fib = fibonacci_sequence(5)\nprint(\"The first 5 Fibonacci numbers are:\", first_five_fib)\n\nDo you want to proceed? (yes/no): yes\n\n---------------------------------------------------------------------------\n[2024-11-10T13:25:40.508594], Executor:\n\nThe script ran, then exited with Unix exit code: 0\nIts output was:\nThe first 5 Fibonacci numbers are: [0, 1, 1, 2, 3]\n...\n...\n```\n**Á§∫‰æã 2 ‚Äî ÊêúÁ¥¢ÁΩëÁªú**\n\nË¶Å‰ΩøÁî® Magentic ÊêúÁ¥¢ÁΩëÁªúÔºå‰Ω†ÈúÄË¶Å‰∏Ä‰∏™ Bing API ÂØÜÈí•„ÄÇ‰Ω†ÂèØ‰ª•ÈÄöËøá Microsoft AzureÔºàBing Search V7ÔºâËÆæÁΩÆÊ≠§ÂØÜÈí•„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ÈÄâÊã©ÊúÄ‰ΩéÂèØÁî®ÁöÑ **‚ÄúF‚Äù** Á∫ßÂà´ÔºåÂèØ‰ª•Â∞ÜÂÖ∂ÂÆâÊéí‰∏∫Êó†ÊàêÊú¨ÈÄâÈ°π„ÄÇÁÑ∂ËÄåÔºåËøôÈôêÂà∂‰∫ÜÊØèÁßíÁöÑÊêúÁ¥¢Ê¨°Êï∞‰∏∫ 3ÔºåÂπ∂‰∏îÊØèÊúàÁöÑÊêúÁ¥¢Ë∞ÉÁî®ÊÄªÊï∞‰πüÊúâÈôêÂà∂„ÄÇ\n\nËÆæÁΩÆËøô‰∏™ÊúâÁÇπÂ§çÊùÇÔºå‰ΩÜÂü∫Êú¨‰∏äÔºå‰Ω†ÈúÄË¶ÅÈÅµÂæ™‰ª•‰∏ãÊ≠•È™§Ôºö\n\n* Â¶ÇÊûú‰Ω†Ê≤°Êúâ Microsoft Azure Ë¥¶Êà∑ÔºåÊ≥®ÂÜå‰∏Ä‰∏™ÂÖçË¥πÁöÑË¥¶Êà∑\n* Âú® Azure Èó®Êà∑‰∏≠ÂàõÂª∫‰∏Ä‰∏™ Bing Search ËµÑÊ∫êÔºõÁ°Æ‰øùÈÄâÊã©ÊúÄ‰ΩéÁöÑ F Á∫ßÂà´ÔºåËøôÊòØÂÖçË¥πÁöÑÔºå‰ΩÜÂ¶Ç‰∏äÊâÄËø∞ÈôêÂà∂ËæÉÂ§ö„ÄÇ\n* ‰ªéËµÑÊ∫êÊ¶ÇËø∞‰∏≠Ëé∑Âèñ‰Ω†ÁöÑ API ÂØÜÈí•\n\n‰∏ÄÊó¶‰Ω†Êã•Êúâ‰∫Ü Bing API ÂØÜÈí•ÔºåÂ∞ÜÂÖ∂ÂÄºÂàÜÈÖçÁªô BING_API_KEY ÁéØÂ¢ÉÂèòÈáè„ÄÇ\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  search the web and find the current weather \nforecast for Edinburgh UK\n```\nÂêåÊ†∑ÔºåÊòæÁ§∫‰∫ÜÂ§ßÈáèËæìÂá∫Ôºå‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÊõ¥ÊòæËëóÁöÑÂÜÖÂÆπ„ÄÇ\n\n```python\n...\n...\nInitial plan:\n\nWe are working to address the following user request:\n\nsearch the web and find the current weather forecast for Edinburgh UK\n\n\nTo answer this request we have assembled the following team:\n\nWebSurfer: A helpful assistant with access to a web browser. Ask them to perform web searches, open pages, and interact with content (e.g., clicking links, scrolling the viewport, etc., filling in form fields, etc.) It can also summarize the entire page, or answer questions based on the content of the page. It can also be asked to sleep and wait for pages to load, in cases where the pages seem to be taking a while to load.\nCoder: A helpful and general-purpose AI assistant that has strong language skills, Python skills, and Linux command line skills.\nExecutor: A agent for executing code\nfile_surfer: An agent that can handle local files.\n\nHere is an initial fact sheet to consider:\n\n1. GIVEN OR VERIFIED FACTS\n   - The request is asking for the current weather forecast for Edinburgh, UK.\n\n2. FACTS TO LOOK UP\n   - The current weather forecast for Edinburgh, UK can be found on various weather websites such as the BBC Weather, Met Office, or Weather.com.\n\n3. FACTS TO DERIVE\n   - N/A\n\n4. EDUCATED GUESSES\n   - The current weather forecast will likely include details such as temperature, precipitation chance, wind speed, and potential weather warnings, which are typically part of a standard weather forecast.\n\n\nHere is the plan to follow as best as possible:\n\n- Request WebSurfer to search for the current weather forecast for Edinburgh, UK on a reliable weather website such as BBC Weather, Met Office, or Weather.com.\n- Instruct WebSurfer to summarize the weather forecast details including temperature, precipitation chance, wind speed, and any potential weather warnings.\n- Present the gathered weather information for Edinburgh, UK from WebSurfer.\n\n...\n...\n\nI typed 'Edinburgh UK current weather forecast' into the browser search bar.\n\nHere is a screenshot of [Edinburgh UK current weather forecast - Search](https://www.bing.com/search?q=Edinburgh+UK+current+weather+forecast&FORM=QBLH). The viewport shows 28% of the webpage, and is positioned at the top of the page.\nThe following metadata was extracted from the webpage:\n\n{\n    \"meta_tags\": {\n        \"referrer\": \"origin-when-cross-origin\",\n        \"og:description\": \"Intelligent search from Bing makes it easier to quickly find what you\\u2019re looking for and rewards you.\",\n        \"og:site_name\": \"Bing\",\n        \"og:title\": \"Edinburgh UK current weather forecast - Bing\",\n        \"og:url\": \"https://www.bing.com/search?q=Edinburgh+UK+current+weather+forecast&FORM=QBLH\",\n        \"fb:app_id\": \"3732605936979161\",\n        \"og:image\": \"http://www.bing.com/sa/simg/facebook_sharing_5.png\",\n        \"og:type\": \"website\",\n        \"og:image:width\": \"600\",\n        \"og:image:height\": \"315\"\n    }\n}\n\nAutomatic OCR of the page screenshot has detected the following text:\n\n**Page Content:**\n\nMicrosoft Bing\n\nSearch input field: Edinburgh UK current weather forecast\n\n**Menu:**\n- Search\n- Copilot\n- News\n- Images\n- Videos\n- Maps\n- Shopping\n- More\n- Tools\n\nDeep search\nSign in\nMobile\n\n**Weather Information:**\n\nAbout 3,180,000 results\n\nEdinburgh\nCapital city of Scotland, UK\n\nButtons:\n- Map\n- Things to do\n- Weather (Selected)\n- Covid-19\n- Flights\n- History\n- Travel guide\n\n**Weather Widget:**\n**Weather Details:**\n12¬∞C / ¬∞F\n13¬∞\n6¬∞\nWind: 17 KMPH\nHumidity: 90%\nCloudy ¬∑ Sun 10, 13:44\n\n**Hourly Forecast:**\n14:00  17:00  20:00  23:00  2:00  5:00  8:00  11:00\n\n**Weekly Forecast:**\n- Sun 10: 13¬∞/6¬∞\n- Mon 11: üåû 11¬∞/2¬∞\n- Tue 12: üåß 9¬∞/5¬∞\n- Wed 13: üå• 12¬∞/8¬∞\n- Thu 14: üåß 10¬∞/8¬∞\n- Fri 15: üåß 11¬∞/7¬∞\n- Sat 16: üåß 10¬∞/7¬∞\n- Sun 17: üå• 7¬∞/2¬∞\n\n**Sidebar Information:**\n\n- UV index: No forecast\n- Moderate breeze: 17 KMPH, WSW\n- Sunrise: 07:39 AM\n- Sunset: 04:12 PM\n...\n...\n```\nÊúÄÁªàÁöÑÁ≠îÊ°àÊòØËøô‰∏™ÔºåÂÆåÂÖ®Ê≠£Á°Æ„ÄÇ\n\n```python\n[2024-11-10T13:44:43.570437], Orchestrator (final answer):\n\n\nThe current weather in Edinburgh is 12¬∞C with cloudy conditions. \nThere's a moderate breeze at 17 KMPH, and the humidity is at 90%. \nThe temperature is expected to range between 13¬∞C and 6¬∞C today.\n```\n**Á§∫‰æã 3 ‚Äî ÁÇπÂáªÁΩëÁ´ôÈìæÊé•**\n\nÂú®ÊàëÂÜôËøôÁØáÊñáÁ´†Êó∂ÔºåËã±ÂõΩÊ≠£Âú®ËøõË°å‰∏ÄÂú∫Â®ÅÂ∞îÂ£´ÂíåÊñêÊµé‰πãÈó¥ÁöÑÂ§ßÂûãÊ©ÑÊ¶ÑÁêÉÊØîËµõ„ÄÇÊàëÊÉ≥Áü•ÈÅìÂ®ÅÂ∞îÂ£´ÂØπÊñêÊµéÊØîËµõÁöÑÊúÄÊñ∞ÊÉÖÂÜµ„ÄÇ\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\nUser input ('exit' to quit):  Click on the bbc.co.uk website, click on the \nSport link near the top of the page. Look for a link in the page that \ndisplays about the Wales v Fiji rugby match. Click on that link and tell me \nwhat the latest score is\n```\nÂêåÊ†∑ÔºåÊàëÁúÅÁï•‰∫ÜËÆ∏Â§öËæìÂá∫‰ª•ËäÇÁúÅÁ©∫Èó¥„ÄÇ\n\n```python\n...\n...\n...\nÈ°µÈù¢Êà™ÂõæÁöÑËá™Âä®OCRÊ£ÄÊµãÂà∞‰ª•‰∏ãÊñáÊú¨Ôºö\n\nÂΩìÁÑ∂ÔºåËøôÈáåÊòØËΩ¨ÂΩïÁöÑÊñáÊú¨Ôºö\n\n---\n**BBC**\nÁôªÂΩï\nÈ¶ñÈ°µ\nÊñ∞Èóª\n‰ΩìËÇ≤\nÂ§©Ê∞î\niPlayer\nÂ£∞Èü≥\nÂ∞èÁü•ËØÜ\n‰ΩìËÇ≤\n\nÈ¶ñÈ°µ | Ë∂≥ÁêÉ | ÊùøÁêÉ | ‰∏ÄÁ∫ßÊñπÁ®ãÂºè | Ê©ÑÊ¶ÑÁêÉU | Ê©ÑÊ¶ÑÁêÉL | ÁΩëÁêÉ | È´òÂ∞îÂ§´ | Êã≥Âáª | Áî∞ÂæÑ\n\nÂèëÁé∞‰Ω†ÁöÑBBC\nÁôªÂΩïÊàñÂàõÂª∫Ë¥¶Êà∑‰ª•ËßÇÁúã„ÄÅÊî∂Âê¨ÂíåÂèÇ‰∏é\n\nÁôªÂΩïÊàñÊ≥®ÂÜå\n\nËØ∑Ê±ÇÂ∑≤Êª°Ë∂≥„ÄÇ\n...\n...\n...\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n[2024‚Äì11‚Äì10T13:55:10.606578], Orchestrator (ÊúÄÁªàÁ≠îÊ°à):\nÊ†πÊçÆBBC‰ΩìËÇ≤ÁΩëÁ´ôÔºåÂ®ÅÂ∞îÂ£´‰∏éÊñêÊµéÊØîËµõÁöÑÊúÄÊñ∞ÊØîÂàÜÊòØÂ®ÅÂ∞îÂ£´ 7‚Äì0 ÊñêÊµéÔºåÁ©ÜÈõ∑ÂæóÂàÜ„ÄÇ\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n[2024‚Äì11‚Äì10T13:55:10.617212], Orchestrator (ÁªàÊ≠¢Êù°‰ª∂):\n```\nËøôÊòØÊàëÂú®Ê®°ÂûãÂõûÁ≠îÂêé‰∏ç‰πÖÊãçÁöÑÊà™ÂõæÔºàÊñêÊµéÂú®Â®ÅÂ∞îÂ£´ÁöÑÂàùÂßãÂæóÂàÜÂêéÂæàÂø´Â∞±ÂæóÂàÜ‰∫ÜÔºâ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xN8qBJLdHqx0lrh_4Y4DCQ.png)\n\n**Á§∫‰æã 4 ‚Äî ËØªÂèñÊú¨Âú∞ XL Êñá‰ª∂„ÄÇ**\n\nÊàëÂú®Êú¨Âú∞Á≥ªÁªü‰∏äÊúâ‰∏Ä‰∏™ XL Êñá‰ª∂„ÄÇËÆ©Êàë‰ª¨ÁúãÁúã Magentic\\-One ÊòØÂê¶ËÉΩÊâæÂà∞ÂÆÉ„ÄÅÊâìÂºÄÂÆÉÔºåÂπ∂ÂõûÁ≠îÂÖ≥‰∫éÂÆÉÁöÑÈóÆÈ¢ò„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*UIuLEkEr-w6ZckRjiUuqjw.png)\n\n\n```python\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$ python examples/example --logs_dir ./logs\n/home/tom/projects/autogen/python/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Êâæ‰∏çÂà∞ ffmpeg Êàñ avconv - ÈªòËÆ§‰ΩøÁî® ffmpegÔºå‰ΩÜÂèØËÉΩÊó†Ê≥ïÂ∑•‰Ωú\n  warn(\"Êâæ‰∏çÂà∞ ffmpeg Êàñ avconv - ÈªòËÆ§‰ΩøÁî® ffmpegÔºå‰ΩÜÂèØËÉΩÊó†Ê≥ïÂ∑•‰Ωú\", RuntimeWarning)\nÁî®Êà∑ËæìÂÖ• ('exit' ÈÄÄÂá∫):  ÊàëÂú®ÊàëÁöÑ /mnt/d/data ÁõÆÂΩï‰∏≠Êúâ‰∏Ä‰∏™Êñá‰ª∂Âè´\nfake_data.xlsx„ÄÇ‰Ω†ËÉΩÂëäËØâÊàëÊñá‰ª∂ÁöÑÁ¨¨‰∏âÊù°ËÆ∞ÂΩïÊòØ‰ªÄ‰πàÂêó\n```\n\n```python\n...\n...\n\n‰∏ã‰∏Ä‰∏™ÂèëË®ÄËÄÖ file_surfer\n\n---------------------------------------------------------------------------\n[2024-11-10T14:16:57.676137], file_surfer:\n\nÂú∞ÂùÄ: file:///mnt/d/data/fake_data.xlsx\nËßÜÂè£‰ΩçÁΩÆ: ÊòæÁ§∫Á¨¨ 1 È°µÔºåÂÖ± 1 È°µ„ÄÇ\n=======================\n### Sheet1\n| Êó•Êúü | ÈîÄÂîÆ | ÊîØÂá∫ |\n| --- | --- | --- |\n| 2024\\-01\\-31 | 302 | 187 |\n| 2024\\-02\\-29 | 635 | 472 |\n| 2024\\-03\\-31 | 470 | 199 |\n| 2024\\-04\\-30 | 306 | 459 |\n| 2024\\-05\\-31 | 271 | 251 |\n| 2024\\-06\\-30 | 900 | 230 |\n| 2024\\-07\\-31 | 220 | 249 |\n| 2024\\-08\\-31 | 814 | 408 |\n| 2024\\-09\\-30 | 321 | 357 |\n| 2024\\-10\\-31 | 666 | 443 |\n| 2024\\-11\\-30 | 414 | 393 |\n| 2024\\-12\\-31 | 530 | 485 |\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:00.613740], Orchestrator (ÊÄùËÄÉ):\n\nÊõ¥Êñ∞ÁöÑË¥¶Êú¨:\n{\n  \"is_request_satisfied\": {\n    \"reason\": \"ÊàêÂäüÊ£ÄÁ¥¢Âπ∂ÊòæÁ§∫‰∫ÜÊñá‰ª∂ 'fake_data.xlsx' ‰∏≠Á¨¨‰∏âÊù°ËÆ∞ÂΩïÁöÑÂÜÖÂÆπ„ÄÇ\",\n    \"answer\": true\n  },\n  \"is_in_loop\": {\n    \"reason\": \"‰ªªÂä°‰ª•ÁÆÄÂçïÁöÑÊñπÂºèÂÆåÊàêÔºåÊ≤°ÊúâÈáçÂ§çÁöÑÊìç‰Ωú„ÄÇ\",\n    \"answer\": false\n  },\n  \"is_progress_being_made\": {\n    \"reason\": \"Á¨¨‰∏âÊù°ËÆ∞ÂΩïÁöÑÂÜÖÂÆπÊàêÂäüÊ£ÄÁ¥¢Âπ∂ÊòæÁ§∫ÔºåË°®ÊòéËøõÂ±ïÈ°∫Âà©„ÄÇ\",\n    \"answer\": true\n  },\n  \"next_speaker\": {\n    \"reason\": \"‰ªªÂä°Â∑≤ÂÆåÊàêÔºåÂõ†Ê≠§‰∏çÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÁöÑÊìç‰Ωú„ÄÇ\",\n    \"answer\": \"file_surfer\"\n  },\n  \"instruction_or_question\": {\n    \"reason\": \"ÈÄöËøáÊèê‰æõÁ¨¨‰∏âÊù°ËÆ∞ÂΩïÁöÑÂÜÖÂÆπÔºåÊª°Ë∂≥‰∫ÜËØ∑Ê±Ç„ÄÇ\",\n    \"answer\": \"Êñá‰ª∂‰∏≠ÁöÑÁ¨¨‰∏âÊù°ËÆ∞ÂΩïÊòØÔºöÊó•ÊúüÔºö2024-03-31ÔºåÈîÄÂîÆÈ¢ùÔºö470ÔºåÊîØÂá∫Ôºö199„ÄÇ\"\n  }\n}\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:00.613806], Orchestrator (ÊÄùËÄÉ):\n\nËØ∑Ê±ÇÂ∑≤Êª°Ë∂≥„ÄÇ\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:01.465848], Orchestrator (ÊúÄÁªàÁ≠îÊ°à):\n\n\nÊñá‰ª∂ \"fake_data.xlsx\" ‰∏≠ÁöÑÁ¨¨‰∏âÊù°ËÆ∞ÂΩïÂåÖÂê´‰ª•‰∏ã‰ø°ÊÅØÔºö\n\n- Êó•ÊúüÔºö2024-03-31\n- ÈîÄÂîÆÔºö470\n- ÊîØÂá∫Ôºö199\n\n---------------------------------------------------------------------------\n[2024-11-10T14:17:01.465908], Orchestrator (ÁªàÊ≠¢Êù°‰ª∂):\n\nÊ≤°ÊúâÈÄâÊã©‰ª£ÁêÜ„ÄÇ\n(base) tom@tpr-desktop:~/projects/autogen/python/packages$\n```\nÊàëÂñúÊ¨¢‰ª£ÁêÜÁ°ÆÂÆöÁ¨¨‰∏ÄÊù°ËÆ∞ÂΩïÊòØÊ†áÈ¢òÔºåÂõ†Ê≠§ËøîÂõû‰∫ÜÂÆûÈôÖÁöÑÁ¨¨‰∏âÊù°Êï∞ÊçÆËÆ∞ÂΩï„ÄÇËøôÁúüÊòØ‰∫Ü‰∏çËµ∑„ÄÇ\n\n### ÊëòË¶Å\n\nÂóØÔºåÊàë‰∏çÁü•ÈÅì‰Ω†ÊÄé‰πàÊÉ≥Ôºå‰ΩÜÊàëËÆ§‰∏∫ËøôÊòØ‰∏ÄÁ≥ªÂàóÁõ∏ÂΩì‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊºîÁ§∫„ÄÇÂæÆËΩØÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÈùûÂ∏∏Âá∫Ëâ≤ÁöÑ‰ª£ÁêÜÁ≥ªÁªüÔºåÂπ∂‰ºº‰πéÊâìÁÆóÂú®‰∏ç‰πÖÁöÑÂ∞ÜÊù•Â∞ÜÂÖ∂ÂÆåÂÖ®Á∫≥ÂÖ•‰ªñ‰ª¨ÁöÑ Autogen Ê°ÜÊû∂‰∏≠„ÄÇ\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëËß£Èáä‰∫Ü‰ªÄ‰πàÊòØ Magentic-OneÔºå‰ª•ÂèäÂ¶Ç‰Ωï‰∏ãËΩΩÂíåËøêË°åÂÆÉ‰ª•ÂÆåÊàê‰∏Ä‰∫õÊúâÁî®ÁöÑ‰ªªÂä°„ÄÇÊàëËß£Èáä‰∫ÜÂÆÉÁöÑÂÖ≥ÈîÆÁªÑ‰ª∂ÊòØ\n\n* ÂçèË∞É\n* ÁΩëÁªúÂíåÊñá‰ª∂ÊµèËßà\n* ÁºñÁ†ÅÂíåÁªàÁ´ØÊìç‰Ωú\n\nÊàëÈÄöËøá‰∏ÄÁ≥ªÂàóÁ§∫‰æãÂ±ïÁ§∫‰∫ÜËøô‰∫õÁªÑ‰ª∂ÁöÑÂ∑•‰ΩúÔºåÂåÖÊã¨\n\n* ÂàõÂª∫ÂíåËøêË°å Python ‰ª£Á†Å\n* Ê£ÄÊü•Êú¨Âú∞Êñá‰ª∂Âπ∂ÂõûÁ≠îÊúâÂÖ≥ÂÖ∂ÂÜÖÂÆπÁöÑÈóÆÈ¢ò\n* Âú®ÁΩë‰∏äÊêúÁ¥¢‰ø°ÊÅØ\n* ÁÇπÂáªÁΩëÈ°µÈìæÊé•\n\n\n> *Â•ΩÁöÑÔºåÊàëÁé∞Âú®Â∞±Âà∞Ê≠§‰∏∫Ê≠¢„ÄÇÂ∏åÊúõ‰Ω†ËßâÂæóËøôÁØáÊñáÁ´†ÊúâÁî®„ÄÇÂ¶ÇÊûúÊúâÔºåËØ∑ÈÄöËøá [Ëøô‰∏™ÈìæÊé•](https://medium.com/@thomas_reid) Êü•ÁúãÊàëÁöÑ‰∏™‰∫∫ËµÑÊñôÈ°µÈù¢„ÄÇÂú®ÈÇ£ÈáåÔºå‰Ω†ÂèØ‰ª•ÁúãÂà∞ÊàëÂÖ∂‰ªñÂ∑≤ÂèëÂ∏ÉÁöÑÊïÖ‰∫ãÔºåÂπ∂ËÆ¢ÈòÖ‰ª•Ëé∑ÂèñÊàëÂèëÂ∏ÉÊñ∞ÂÜÖÂÆπÊó∂ÁöÑÈÄöÁü•„ÄÇ*\n\n\n> *Êó∂Â±ÄËâ∞ÈöæÔºåÈí±ÂåÖÁ¥ßÁº©Ôºå‰ΩÜÂ¶ÇÊûú‰Ω†‰ªéËøôÁØáÊñáÁ´†‰∏≠Ëé∑Âæó‰∫ÜÁúüÊ≠£ÁöÑ‰ª∑ÂÄºÔºåËØ∑ËÄÉËôë [ËØ∑ÊàëÂñù‰∏ÄÊùØ](https://ko-fi.com/taupirho)„ÄÇ*\n\nÂ¶ÇÊûú‰Ω†ÂñúÊ¨¢ËøôÁØáÂÜÖÂÆπÔºåÊàëÊÉ≥‰Ω†‰πü‰ºöÂØπËøô‰∫õÁõ∏ÂÖ≥ÁöÑÊñáÁ´†ÊÑüÂÖ¥Ë∂£„ÄÇ\n\nÂú®Ê≠§Â§ÑÈòÖËØªÂæÆËΩØÁöÑÂÆåÊï¥ Magentic-One ÂÖ¨Âëä [ËøôÈáå](https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/)„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/introduction-to-llava-a-multimodal-ai-model-2a2fa530ace4","frontmatter":{"title":"LLaVA ÁÆÄ‰ªãÔºö‰∏ÄÁßçÂ§öÊ®°Âºè AI Ê®°Âûã","meta_title":"LLaVA ÁÆÄ‰ªãÔºö‰∏ÄÁßçÂ§öÊ®°Âºè AI Ê®°Âûã","description":"LLaVA ÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØËÆ≠ÁªÉÁöÑÂ§ßÂûãÂ§öÊ®°ÂºèÊ®°ÂûãÔºåÊó®Âú®Ê†πÊçÆËßÜËßâËæìÂÖ•ÁêÜËß£ÂíåÁîüÊàêÂÜÖÂÆπ‚Ä¶‚Ä¶","date":"2024-10-29T12:48:10.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0At7tXF5ejho9Y46E3uGtg.png","categories":["Natural Language Processing","Computer Vision","Generative AI"],"author":"Rifx.Online","tags":["LLaVA","GPT-4","multimodal","visual","encoder"],"draft":false,"slug":"blog/introduction-to-llava-a-multimodal-ai-model-2a2fa530ace4"},"content":"\n\n\n\n\nLLaVAÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØËÆ≠ÁªÉÁöÑÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊó®Âú®ÁêÜËß£ÂíåÁîüÊàêÂü∫‰∫éËßÜËßâËæìÂÖ•ÔºàÂõæÂÉèÔºâÂíåÊñáÊú¨Êåá‰ª§ÁöÑÂÜÖÂÆπ„ÄÇÂÆÉÁªìÂêà‰∫ÜËßÜËßâÁºñÁ†ÅÂô®ÂíåËØ≠Ë®ÄÊ®°ÂûãÁöÑËÉΩÂäõÔºå‰ª•Â§ÑÁêÜÂíåÂìçÂ∫îÂ§öÊ®°ÊÄÅËæìÂÖ•„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mjzqL0BHzdPoN-Jjruh52A.png)\n\n## LLaVA ÁöÑËæìÂÖ•ÂíåËæìÂá∫ÔºöËøûÊé•ËßÜËßâ‰∏éÊñáÊú¨È¢ÜÂüüÔºö\n\nLLaVA ÁöÑËæìÂÖ•Êúâ‰∏§‰∏™ÊñπÈù¢Ôºö\n\n1. ËßÜËßâËæìÂÖ•ÔºöÊ®°ÂûãÂèØ‰ª•Êü•ÁúãÂíåÂàÜÊûêÁöÑÂõæÂÉèÔºå‰ª•ÊèêÂèñËßÜËßâÁâπÂæÅÂíå‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ\n2. ÊñáÊú¨Êåá‰ª§ÔºöÊñáÊú¨ËæìÂÖ•ÔºåÂèØ‰ª•ÊòØÈóÆÈ¢òÊàñÂëΩ‰ª§ÔºåÊåáÂØºÊ®°ÂûãÂÖ≥Ê≥®‰ªÄ‰πàÊàñÊâßË°å‰∏éËßÜËßâËæìÂÖ•Áõ∏ÂÖ≥ÁöÑ‰ªÄ‰πà‰ªªÂä°„ÄÇ\n\nLLaVA ÁöÑËæìÂá∫ÊòØÂü∫‰∫éÊñáÊú¨ÁöÑÔºåÂèØËÉΩ‰ºöÊ†πÊçÆ‰ªªÂä°ËÄåÊúâÊâÄ‰∏çÂêåÔºö\n\n1. ÊèèËø∞ÊÄßÊñáÊú¨ÔºöÂ¶ÇÊûú‰ªªÂä°ÊòØÊèèËø∞ËßÜËßâÂÜÖÂÆπÔºåLLaVA ÂèØ‰ª•ËæìÂá∫ÂõæÂÉèÁöÑËØ¶ÁªÜÊèèËø∞ÔºåËØÜÂà´ÂØπË±°„ÄÅÂä®‰ΩúÂíåÂú∫ÊôØ„ÄÇ\n2. ÈóÆÈ¢òÂõûÁ≠îÔºöÂØπ‰∫éÈóÆÁ≠î‰ªªÂä°ÔºåLLaVA ÁîüÊàêÁöÑÂõûÁ≠îÂèØ‰ª•Ëß£Á≠îÂÖ≥‰∫éËßÜËßâËæìÂÖ•ÁöÑÈóÆÈ¢òÔºåÂèØËÉΩÊ∂âÂèäÂü∫‰∫éÂõæÂÉèÂÜÖÂÆπÁöÑÊé®ÁêÜÂíåÊé®Êñ≠„ÄÇ\n3. ÂêéÁª≠Ë°åÂä®ÔºöÂØπ‰∫éÈúÄË¶ÅË°åÂä®ÁöÑÊåá‰ª§Ôºå‰æãÂ¶ÇÁºñËæëÂõæÂÉèÊàñÊ£ÄÁ¥¢Êõ¥Â§ö‰ø°ÊÅØÔºåLLaVA ÂèØ‰ª•Êèê‰æõÈÄÇÂΩìÁöÑÊñáÊú¨ÂìçÂ∫îÔºåÊåáÁ§∫ÊâÄÈááÂèñÁöÑË°åÂä®ÊàñÂª∫ËÆÆÂ∫îËØ•ÂÅö‰ªÄ‰πà„ÄÇ\n\n## ÊØîËæÉÂàÜÊûêÔºöLLaVa‰∏éÂΩì‰ª£Â§öÊ®°ÊÄÅÊ®°Âûã\n\nÂ§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÁöÑÈ¢ÜÂüüÊ≠£Âú®Âø´ÈÄüÂèëÂ±ïÔºåÂá∫Áé∞‰∫ÜCLIP„ÄÅBLIPÁ≠âÂàõÊñ∞Ôºå‰ª•ÂèäÊúÄËøëÊé®Âá∫ÁöÑLLaVa„ÄÇÊú¨Â∞èËäÇÂ∞ÜLLaVaÁöÑÁã¨ÁâπÊû∂ÊûÑÂíåÊñπÊ≥ï‰∏éËøô‰∫õÂΩì‰ª£Ê®°ÂûãËøõË°åÊØîËæÉÔºåÁ™ÅÂá∫ÂÖ∂ËøõÊ≠•ÂíåÂå∫Âà´Ôºå‰ΩøÂÖ∂‰∏é‰ºó‰∏çÂêå„ÄÇ\n\n### CLIP: ÂºÄÂàõÂ§öÊ®°ÊÄÅÁêÜËß£ÁöÑÂÖàÊ≤≥\n\nCLIP (Contrastive Language‚ÄìImage Pre\\-training) Âú®Â§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüü‰∏≠ËøàÂá∫‰∫ÜÈù©ÂëΩÊÄßÁöÑ‰∏ÄÊ≠•ÔºåÂú®ÂêÑÁßçËßÜËßâ‰ªªÂä°‰∏≠Êèê‰æõ‰∫ÜÂº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇÂÆÉÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞ÁöÑËÉåÊôØ‰∏ãÁêÜËß£ÂõæÂÉèÁöÑËÉΩÂäõ‰∏∫ËØ•È¢ÜÂüüËÆæÂÆö‰∫ÜÊñ∞ÁöÑÂü∫ÂáÜ„ÄÇCLIP ÈÄöËøáÂ§ßËßÑÊ®°ÁöÑÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÂ∞ÜÂõæÂÉè‰∏éÊñáÊú¨ÊèèËø∞ÂØπÈΩêÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂú®‰∏ÄÁ≥ªÂàóËßÜËßâ‰ªªÂä°‰∏äËøõË°åÈõ∂Ê†∑Êú¨Â≠¶‰π†„ÄÇÁÑ∂ËÄåÔºåCLIP ‰∏ªË¶ÅÂÖ≥Ê≥®ÂõæÂÉè‰∏éÊñáÊú¨‰πãÈó¥ÁöÑÈ´òÂ±ÇÊ¨°ÂÖ≥ËÅîÔºåÂπ∂‰∏çÂÖ∑Â§áÊ∑±ÂÖ•Êé®ÁêÜÊàñÂØπËØùÂèÇ‰∏éÁöÑËÉΩÂäõ„ÄÇ\n\n### BLIP: ËøûÊé•ËØ≠Ë®Ä‰∏éÂõæÂÉèÊÑüÁü•\n\nÂú®CLIPÂ•†ÂÆöÁöÑÂü∫Á°Ä‰∏äÔºåBLIPÔºàBootstrapped Language Image Pre-trainingÔºâÈÄöËøáÂºïÂÖ•Ëá™ÂºïÂØºÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÊâ©Â±ï‰∫ÜÂ§öÊ®°ÊÄÅÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇËøôÁßçÊñπÊ≥ïÈÄöËøá‰∏çÊñ≠‰ªéËá™Ë∫´ÁöÑÈ¢ÑÊµã‰∏≠Â≠¶‰π†ÔºåÂÆåÂñÑÊ®°ÂûãÁöÑËßÜËßâÁêÜËß£Ôºå‰ªéËÄåÂ∏ÆÂä©ÊîπÂñÑËØ≠Ë®Ä‰∏éËßÜËßâÂÜÖÂÆπ‰πãÈó¥ÁöÑÂØπÈΩê„ÄÇBLIPÂú®ÈúÄË¶ÅÊõ¥Á≤æÁ°ÆËßÜËßâËØÜÂà´ÂíåËØ≠Ë®ÄÁêÜËß£ÁöÑ‰ªªÂä°‰∏äË°®Áé∞Âá∫Â¢ûÂº∫ÁöÑÊÄßËÉΩ„ÄÇ\n\nÁõ∏ÊØî‰πã‰∏ãÔºåLLaVaÈááÂèñ‰∫Ü‰∏çÂêåÁöÑË∑ØÂæÑÔºåÈÄöËøáÂà©Áî®GPT-4ÁöÑËØ≠Ë®ÄÁîüÊàêËÉΩÂäõÊù•Á≠ñÂàíÂÖ∂ÈÅµÂæ™Êåá‰ª§ÁöÑÊï∞ÊçÆ„ÄÇËøô‰∏ç‰ªÖÂØºËá¥‰∫Ü‰∏Ä‰∏™ÊçïÊçâÊõ¥ÂπøÊ≥õ‰∫∫Á±ª‰∫íÂä®ËåÉÂõ¥ÁöÑÊï∞ÊçÆÈõÜÔºåËøò‰ΩøLLaVaËÉΩÂ§üËøõË°åÊõ¥Â§çÊùÇÁöÑÊé®ÁêÜÂíåÊ∑±ÂÖ•ÁöÑÂØπËØùËÉΩÂäõ„ÄÇ\n\n## LLaVaÁöÑÁã¨Áâπ‰πãÂ§ÑÔºöÊòØÊ®°ÂûãÊû∂ÊûÑËøòÊòØÂÖ∂‰ªñÂõ†Á¥†Ôºü\n\nÊ†πÊçÆÊàë‰ª¨ÁöÑËßÇÁÇπÔºåLLaVAÁöÑ‰ºòÂäø‰∏ªË¶ÅÂú®‰∫éÂÖ∂Êï∞ÊçÆÁ≠ñÂàíËÉΩÂäõÔºåËÄåÈùûÊû∂ÊûÑÈÄâÊã©„ÄÇLLaVAÁöÑÈáçÂ§ßËøõÂ±ï‰∏ªË¶ÅÂæóÁõä‰∫éÂÖ∂Âà©Áî®GPT-4ËøõË°åÊï∞ÊçÆÁ≠ñÂàí„ÄÇ‰∏é‰º†ÁªüÁöÑÈùôÊÄÅÊï∞ÊçÆÈõÜ‰∏çÂêåÔºåLLaVA‰ΩøÁî®ChatGPT-4ÁîüÊàêÂä®ÊÄÅ„ÄÅÊåáÂØºÊÄßÁöÑÊï∞ÊçÆÔºåÁßØÊûÅÂèÇ‰∏éÂêÑÁßçËßÜËßâÂíåÊñáÊú¨Âú∫ÊôØ‰∏≠ÁöÑËÆ≠ÁªÉËøáÁ®ã„ÄÇ\n\nÈÄöËøá‰ΩøÁî®GPT-4ÔºåLLaVAÁîüÊàêÁöÑ Êï∞ÊçÆÈõÜÁ¥ßÂØÜÊ®°ÊãüËá™ÁÑ∂ËØ≠Ë®ÄÂíåËßÜËßâÊÑüÁü•ÔºåËÑ±Á¶ª‰∫Ü‰º†ÁªüÁöÑÊâãÂä®Êï∞ÊçÆÈõÜÁîüÊàêÊñπÊ≥ï„ÄÇËøôÁßçÂàõÊñ∞ÁöÑÊñπÊ≥ï‰∏ç‰ªÖ‰ΩøAIËÉΩÂ§üÁêÜËß£ÂíåÊé®ÁêÜÔºåËøò‰ΩøÂÖ∂Êõ¥Êé•Ëøë‰∫éÂáÜÁ°ÆÂèçÊò†‰∫∫Á±ªÊô∫ËÉΩ„ÄÇ\n\n### LLaVa‰∏≠ÁöÑÊï∞ÊçÆÊï¥ÁêÜÁ≠ñÁï•\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LzastWLkzPeMB_28Nr7Y9A.png)\n\nLLaVaÔºåÂç≥Â§ßÂûãËØ≠Ë®Ä‰∏éËßÜËßâÂä©ÊâãÔºå‰∏ç‰ªÖ‰ª•ÂÖ∂ÂÖàËøõÁöÑÁ•ûÁªèÊû∂ÊûÑËÄåÈóªÂêçÔºåËøò‰ª•ÂÖ∂ÂºÄÂàõÊÄßÁöÑÊï∞ÊçÆÊï¥ÁêÜÊñπÊ≥ïËÄåËÑ±È¢ñËÄåÂá∫„ÄÇÈÄöËøáÂà©Áî®GPT-4ÔºåÂÆÉÂΩªÂ∫ïÊîπÂèò‰∫Ü‰º†ÁªüÁöÑÊï∞ÊçÆÂáÜÂ§áÊñπÊ≥ïÔºåÊûÑÂª∫Âá∫‰∏Ä‰∏™ÂèçÊò†Áé∞ÂÆû‰∏ñÁïåÂ§çÊùÇÊÄßÁöÑÊï∞ÊçÆÂ∫ì„ÄÇ\n\nLLaVa‰∏≠ÁöÑÊï∞ÊçÆÊï¥ÁêÜÂßã‰∫é‰∏ÄÂº†ÂõæÁâáÂèäÂÖ∂Áõ∏Â∫îÁöÑÊ†áÈ¢òÔºåÂà©Áî®GPT-4ÁîüÊàê‰∏ÄÁªÑÊü•ËØ¢„ÄÇËøô‰∫õÊü•ËØ¢ÂºïÂØºAIÁ≤æÁ°ÆËÄåÁõ∏ÂÖ≥Âú∞Êé¢Á¥¢ÂíåÊèèËø∞ÂõæÂÉèÂÜÖÂÆπ„ÄÇ\n\n‰∏∫‰∫ÜÊúâÊïàÂú∞Â∞ÜËßÜËßâÊï∞ÊçÆËΩ¨Âåñ‰∏∫ÊñáÊú¨Âü∫Á°ÄÁöÑAIÔºàÂ¶ÇGPT-4ÔºâÔºåLLaVa‰ΩøÁî®Ê†áÈ¢òÊèê‰æõËßÜËßâÂú∫ÊôØÁöÑÂ§öÊ†∑ËßÜËßíÔºåÂπ∂‰ΩøÁî®ËæπÁïåÊ°ÜÊèê‰æõÁ©∫Èó¥‰∏ä‰∏ãÊñáÂíåÁÑ¶ÁÇπ„ÄÇ\n\n1. ÂØπËØùÊï∞ÊçÆÔºöÊ®°‰ªø‰∫∫Á±ª‰∫íÂä®ÔºåLLaVaÊï¥ÁêÜÂØπËØùÔºåÂÖ∂‰∏≠Ê®°Âûã‰Ωú‰∏∫Âä©ÊâãÔºåÂõûÁ≠îÊúâÂÖ≥ÂõæÂÉèÂêÑ‰∏™ÊñπÈù¢ÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÈóÆÈ¢òÁöÑËåÉÂõ¥ÂåÖÊã¨ËØÜÂà´Áâ©‰ΩìÂíåÂä®‰ΩúÔºåËæ®Âà´ÂÆÉ‰ª¨ÁöÑÊï∞Èáè„ÄÅ‰ΩçÁΩÆÂíåÁõ∏ÂØπ‰ΩçÁΩÆÔºåÁ°Æ‰øùÊ®°ÂûãËÉΩÂ§üÂ§ÑÁêÜÂÖ∑ÊúâÊòéÁ°ÆÁ≠îÊ°àÁöÑÊü•ËØ¢„ÄÇ\n2. ËØ¶ÁªÜÊèèËø∞Êï∞ÊçÆÔºöLLaVaÊó®Âú®ÂÖ®Èù¢ÁêÜËß£ÂõæÂÉè„ÄÇ‰∏∫Ê≠§ÔºåÂÆÉ‰øÉ‰ΩøGPT-4ÊèêÂá∫Êó®Âú®ÁêÜËß£ÂõæÂÉè‰∏∞ÂØåËØ¶ÁªÜÊèèËø∞ÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÊèêÁ§∫ÈºìÂä±Ê®°ÂûãÊ∑±ÂÖ•ÊåñÊéòÔºåÊèê‰æõ‰∏Ä‰∏™ÊçïÊçâËßÜËßâÂÜÖÂÆπÊï¥‰ΩìÊú¨Ë¥®ÁöÑÂèôËø∞„ÄÇ\n3. Â§çÊùÇÊé®ÁêÜÊï∞ÊçÆÔºöË∂ÖË∂äÂçïÁ∫ØÊèèËø∞ÔºåLLaVaÈÄöËøáÈúÄË¶ÅÂàÜÂ±ÇÊé®ÁêÜËøáÁ®ãÁöÑÈóÆÈ¢òÊåëÊàòÊ®°ÂûãÔºåË¶ÅÊ±ÇÈÄªËæëÂíåÂõ†ÊûúÂÖ≥Á≥ªÁöÑÁêÜËß£„ÄÇËøôÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆËÆ≠ÁªÉÊ®°ÂûãÊûÑÂª∫ÊúâÁêÜÊúâÊçÆÁöÑÂìçÂ∫îÔºåÊîØÊåÅÈÄªËæëÊÄùÁª¥ÁöÑÈ°∫Â∫è„ÄÇ\n\n## LLaVaÁöÑÊû∂ÊûÑÔºöËßÜËßâ‰∏éËØ≠Ë®ÄÁöÑÊï¥Âêà\n\nLLaVaÊ®°ÂûãÊï¥Âêà‰∫ÜËßÜËßâ‰∏éËØ≠Ë®ÄÔºåÂà©Áî®‰ª•‰∏ãÊ†∏ÂøÉÁªÑ‰ª∂Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8q_Iay_LHCzPqtrQby_H8w.png)\n\n1. ËßÜËßâÁºñÁ†ÅÂô®ÔºöLLaVaÊû∂ÊûÑÁöÑÂü∫Á°ÄÊòØÈ¢ÑËÆ≠ÁªÉÁöÑCLIPËßÜËßâÁºñÁ†ÅÂô®ÔºåÁâπÂà´ÊòØViT-L/14Âèò‰Ωì„ÄÇËØ•ÁªÑ‰ª∂ÈÄöËøáTransformerÂ±ÇÂ§ÑÁêÜËæìÂÖ•ÂõæÂÉèÔºàXvÔºâÔºåÊèêÂèñÁâπÂæÅÔºàZvÔºâÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊúâÊïàÁêÜËß£ËßÜËßâ‰ø°ÊÅØ„ÄÇ\n2. ËØ≠Ë®ÄÊ®°ÂûãÔºàVicunaÔºâÔºöLLaVaÁöÑËØ≠Ë®ÄËÉΩÂäõ‰æùËµñ‰∫éVicunaÔºåËøôÊòØ‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂèò‰ΩìÔºåËÆ∞‰Ωúfœï„ÄÇVicunaÊ†πÊçÆËæìÂÖ•ËØ≠Ë®ÄÊåá‰ª§ÔºàXqÔºâÁêÜËß£Âπ∂ÁîüÊàêËØ≠Ë®ÄÂìçÂ∫îÔºàXaÔºâÔºåË°•ÂÖÖ‰∫ÜËßÜËßâÁºñÁ†ÅÂô®ÁöÑÂäüËÉΩ„ÄÇ\n3. Á∫øÊÄßÊäïÂΩ±ÔºöËØ•ÁªÑ‰ª∂Áî±‰∏Ä‰∏™ÂèØËÆ≠ÁªÉÁü©ÈòµÔºàWÔºâË°®Á§∫Ôºå‰Ωú‰∏∫ËßÜËßâÁâπÂæÅÔºàZvÔºâ‰∏éËØ≠Ë®ÄÊ®°ÂûãÁöÑÂµåÂÖ•Á©∫Èó¥‰πãÈó¥ÁöÑÊ°•Ê¢Å„ÄÇÂÆÉÂ∞ÜËßÜËßâÁâπÂæÅËΩ¨Êç¢‰∏∫ËßÜËßâÊ†áËÆ∞ÔºàHvÔºâÔºå‰ΩøÂÖ∂‰∏éËØ≠Ë®ÄÊ®°ÂûãÁöÑËØçÂµåÂÖ•Á©∫Èó¥ÂØπÈΩêÔºå‰ª•‰øÉËøõÂ§öÊ®°ÊÄÅÂØπËØù„ÄÇ\n\n## ËÆ≠ÁªÉÂíåÂæÆË∞É LLaVAÔºö\n\nLLaVA ÈááÁî®‰∏§Èò∂ÊÆµÁöÑËÆ≠ÁªÉËøáÁ®ãÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩ‰∏ìÊ≥®‰∫éÊèêÂçáÊ®°ÂûãËß£ËØªÂíåÂìçÂ∫îËßÜËßâ‰∏éÊñáÊú¨Êï∞ÊçÆËûçÂêàÁöÑËÉΩÂäõ„ÄÇ\n\n### Stage 1: È¢ÑËÆ≠ÁªÉ‰ª•ËøõË°åÁâπÂæÅÂØπÈΩê\n\nLLaVAËÆ≠ÁªÉÁöÑÂàùÂßãÈò∂ÊÆµÊòØÈ¢ÑËÆ≠ÁªÉ‰ª•ËøõË°åÁâπÂæÅÂØπÈΩê„ÄÇÂú®Ëøô‰∏™Èò∂ÊÆµÔºåÊ®°Âûã‰∏ìÊ≥®‰∫éÂ∞ÜÂõæÂÉè‰∏≠ÁöÑËßÜËßâÁâπÂæÅ‰∏éËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÁõ∏Â∫îÊñáÊú¨ÁâπÂæÅÂØπÈΩê„ÄÇËøôÊòØÈÄöËøáÂ∞Ü‰∏Ä‰∏™Â§ßÂûãÊï∞ÊçÆÈõÜËøáÊª§‰∏∫‰∏ÄÁªÑÁ≤æÁÇºÁöÑÂõæÂÉè-ÊñáÊú¨ÂØπÊù•ÂÆûÁé∞ÁöÑÔºåLLaVAÂà©Áî®Ëøô‰∫õÂØπÊù•Â≠¶‰π†‰∏§ÁßçÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂÖ≥ËÅî„ÄÇ\n\nÂú®Ëøô‰∏™Èò∂ÊÆµÔºåËßÜËßâÁºñÁ†ÅÂô®Ôºà‰æãÂ¶ÇCLIPËßÜËßâÁºñÁ†ÅÂô®ViT-L/14ÔºâÂ§ÑÁêÜÂõæÂÉè‰ª•ÊèêÂèñËßÜËßâÁâπÂæÅÔºåÁÑ∂Âêé‰ΩøÁî®ÊäïÂΩ±Áü©ÈòµÔºàWÔºâÂ∞ÜËøô‰∫õÁâπÂæÅÊò†Â∞ÑÂà∞ËØ≠Ë®ÄÊ®°ÂûãÁöÑËØçÂµåÂÖ•Á©∫Èó¥„ÄÇLLaVA‰∏≠‰ΩøÁî®ÁöÑËØ≠Ë®ÄÊ®°ÂûãÊòØVicunaÔºå‰ª•ÂÖ∂Âº∫Â§ßÁöÑËØ≠Ë®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõËÄåÈóªÂêç„ÄÇ\n\n### Stage 2: ÂæÆË∞ÉÁ´ØÂà∞Á´Ø\n\nÂú®ÂØπÈΩêËßÜËßâÂíåËØ≠Ë®ÄÁâπÂæÅÂêéÔºåLLaVA ËøõË°åÁ´ØÂà∞Á´ØÁöÑÂæÆË∞ÉËøáÁ®ã„ÄÇÂ∞ΩÁÆ°‰øùÊåÅËßÜËßâÁºñÁ†ÅÂô®ÁöÑÊùÉÈáç‰∏çÂèòÔºå‰ΩÜËøô‰∏ÄÈò∂ÊÆµÂÖÅËÆ∏Ê®°ÂûãËÅîÂêàÂæÆË∞ÉÊäïÂΩ±Áü©ÈòµÂíåËØ≠Ë®ÄÊ®°ÂûãÁöÑÊùÉÈáç„ÄÇÂÖ∂ÁõÆÊ†áÊòØÊúÄÂ§ßÂåñÂü∫‰∫éÊèê‰æõÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÁõÆÊ†áÁ≠îÊ°àÁöÑÂèØËÉΩÊÄß„ÄÇ\n\nËøô‰∏ÄÈò∂ÊÆµÂØπ‰∫éÂ∞Ü LLaVA ÈÄÇÂ∫îÁâπÂÆöÁî®‰æãÂú∫ÊôØËá≥ÂÖ≥ÈáçË¶ÅÔºå‰æãÂ¶ÇÂ§öÊ®°ÊÄÅËÅäÂ§©„ÄÅÁßëÂ≠¶ÈóÆÁ≠îÁ≠â„ÄÇÂÆÉÁ°Æ‰øùÊ®°Âûã‰∏ç‰ªÖËÉΩÂ§üÁêÜËß£ÂõæÂÉèÂú®ÈÄöÁî®ÊèèËø∞‰∏≠ÁöÑ‰∏ä‰∏ãÊñáÔºåËøòËÉΩÂú®Êî∂Âà∞‰∏éÂõæÂÉèÁõ∏ÂÖ≥ÁöÑÁâπÂÆöÈóÆÈ¢òÊó∂ÂèÇ‰∏éÂ§çÊùÇÂØπËØù„ÄÅÊèê‰æõËØ¶ÁªÜËß£ÈáäÂπ∂ËøõË°åÊé®ÁêÜ„ÄÇ\n\n## ÊÄßËÉΩ‰∏éÂü∫ÂáÜÊµãËØïÔºöLLaVa Âú® VQA Ê®°Âûã‰∏≠ÁöÑÂ∫îÁî®\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*I_5fTa_2rtNHEDUaDNMXbQ.png)\n\n## LLaVA\\-Bench (COCO) ÊÄßËÉΩÊ¥ûÂØü\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6B2K7EcbYgMbH-QEp8J41w.png)\n\nLLaVA\\-Bench (COCO) Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑ90‰∏™ÈóÆÈ¢òÊù•ËØÑ‰º∞LLaVAÁöÑËÉΩÂäõÔºåËøô‰∫õÈóÆÈ¢òÊù•Ê∫ê‰∫é30Âº†Á≤æÈÄâÂõæÂÉèÔºåÊ∂µÁõñÂØπËØù„ÄÅËØ¶ÁªÜÊèèËø∞ÂíåÂ§çÊùÇÊé®ÁêÜ„ÄÇÁªìÊûúÂ¶Ç‰∏ãÔºö\n\n* Êåá‰ª§Ë∞É‰ºòÊïàÊûúÔºöÂú®ËøõË°åÊåá‰ª§Ë∞É‰ºòÂêéÔºåLLaVAÂØπÁî®Êà∑ÂëΩ‰ª§ÁöÑÈÅµ‰ªéÊÄßÊèêÈ´ò‰∫ÜË∂ÖËøá50ÂàÜ„ÄÇ\n* ÈóÆÈ¢òÂ§öÊ†∑ÊÄßÁöÑÂΩ±ÂìçÔºöÂ∞ΩÁÆ°ËØ¶ÁªÜÂíåÂ§çÊùÇÊé®ÁêÜÈóÆÈ¢òÁöÑÂ¢ûÂä†ÂæàÂ∞èÔºå‰ΩÜÊï¥‰ΩìËÉΩÂäõÊèêÈ´ò‰∫Ü7ÂàÜ„ÄÇËøô‰∏ÄÊèêÂçá‰πüÂØπÂØπËØùÈóÆÈ¢òÁöÑÂìçÂ∫î‰∫ßÁîü‰∫ÜÁßØÊûÅÂΩ±ÂìçÔºåÂ±ïÁ§∫‰∫ÜÂ§öÊ†∑ÂåñËÆ≠ÁªÉÈõÜÁöÑÂ•ΩÂ§Ñ„ÄÇ\n* ÊúÄ‰ºòÊï∞ÊçÆÁªÑÂêàÔºö‰∏âÁßçÈóÆÈ¢òÁ±ªÂûãÁöÑÁªìÂêàÂ∏¶Êù•‰∫ÜÊúÄÈ´òÁöÑÊÄßËÉΩË∑ÉÂçáÔºåLLaVAËææÂà∞‰∫Ü85.1%ÁöÑÂü∫ÂáÜÂàÜÊï∞ÔºåÂº∫Ë∞É‰∫ÜÂÖ®Èù¢Êï∞ÊçÆÈõÜÂú®ÊèêÂçáÂ§öÊ®°ÊÄÅAIËÉΩÂäõÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*mCjP0xfpcjHkl-lu)\n\n## LLaVAÂú®LLaVA-BenchÔºàÁúüÂÆûÂú∫ÊôØÔºâ‰∏äÁöÑË°®Áé∞\n\n* Âú®ÂØπËØù‰ªªÂä°‰∏≠ÔºåLLaVAÁöÑÂáÜÁ°ÆÁéá‰∏∫57.3%ÔºåÁõ∏ÊØîBLIP-2ÁöÑ54.6%ÊúâÊòéÊòæÊèêÂçáÔºåËøúË∂ÖOpenAIÁöÑFlamingoÔºåÂêéËÄÖ‰ªÖ‰∏∫19.3%„ÄÇ\n* Âú®Êèê‰æõËØ¶ÁªÜÊèèËø∞ÊñπÈù¢ÔºåLLaVAÂæóÂàÜ‰∏∫52.5%ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂‰ªéËßÜËßâÁ∫øÁ¥¢‰∏≠ÁîüÊàê‰∏∞ÂØå„ÄÅÂÖ®Èù¢ÂÜÖÂÆπÁöÑËÉΩÂäõ„ÄÇ\n* ËØ•Ê®°ÂûãÂú®Â§çÊùÇÊé®ÁêÜÈóÆÈ¢ò‰∏äÁöÑË°®Áé∞Â∞§‰∏∫Á™ÅÂá∫ÔºåÊàêÂäüÁéáËææÂà∞81.7%ÔºåË°®ÊòéÂÖ∂ÂÖàËøõÁöÑÊé®ÁêÜÂíåÊé®Êñ≠ËÉΩÂäõ„ÄÇ\n\nLLaVAÂú®ÊâÄÊúâÁ±ªÂà´‰∏≠ÁöÑÁªºÂêàÂæóÂàÜ‰∏∫67.3%ÔºåÊØîBLIP-2È´òÂá∫29‰∏™ÁôæÂàÜÁÇπÔºåË∂ÖËøáFlamingo 48‰∏™ÁôæÂàÜÁÇπ„ÄÇ\n\n## ÈôêÂà∂‰∏éÂÖ≥Ê≥®‰∫ãÈ°πÔºö\n\nLLaVAÁöÑÂÆöÈáèËØÑ‰º∞Ôºö\n\nÂ∞ÜGPT-4‰Ωú‰∏∫ËØÑ‰º∞LLaVAÊÄßËÉΩÁöÑËØÑÂà§ËÄÖÔºåÂú®Âü∫ÂáÜÊµãËØïAIËÉΩÂäõÁöÑÊ°ÜÊû∂ÂÜÖÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â§çÊùÇÁöÑÊåëÊàò„ÄÇ‰∏ÄÊñπÈù¢ÔºåGPT-4ÁöÑÈ´òÁ∫ßÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ‰ΩøÂÖ∂ËÉΩÂ§üÊâπÂà§ÊÄßÂú∞ËØÑ‰º∞ÂÉèLLaVAËøôÊ†∑ÁöÑÂÄôÈÄâÊ®°ÂûãÊâÄ‰∫ßÁîüÁöÑÂìçÂ∫îË¥®Èáè„ÄÇËøôÁßçËØÑ‰º∞Ê∂µÁõñ‰∫ÜÊúâÂä©‰∫éË°°ÈáèÊ®°ÂûãÂú®Â§öÊ®°ÊÄÅÊï∞ÊçÆ‰∏äÈÅµÂæ™Êåá‰ª§ËÉΩÂäõÁöÑÂõ†Á¥†ÔºåÂ¶ÇÂ∏ÆÂä©ÊÄß„ÄÅÁõ∏ÂÖ≥ÊÄß„ÄÅÂáÜÁ°ÆÊÄßÂíåÁªÜËäÇ„ÄÇÁÑ∂ËÄåÔºåÂè¶‰∏ÄÊñπÈù¢Ôºå‰ΩøÁî®GPT-4‰Ωú‰∏∫ËØÑ‰º∞Ê≥ïÂÆòÂºïÂèë‰∫ÜÂÖ≥‰∫éÂü∫ÂáÜÊµãËØïËøáÁ®ãÂÖ¨Ê≠£ÊÄßÁöÑÊãÖÂøß„ÄÇ\n\nÂÖ≥Ê≥®ÁöÑÊ†∏ÂøÉÂú®‰∫éÔºåLLaVAÁöÑÊï∞ÊçÆÊï¥ÁêÜËøáÁ®ã‰∏éGPT-4Ê†πÊú¨‰∏äÊòØ‰∫§ÁªáÂú®‰∏ÄËµ∑ÁöÑ„ÄÇÁî±‰∫éGPT-4Âú®ËÆ≠ÁªÉLLaVAÊó∂ÂèëÊå•‰∫ÜÈáçË¶Å‰ΩúÁî®‚Äî‚ÄîÈÄöËøáÁîüÊàêÊ®°ÂûãÂæÆË∞ÉÊâÄÈúÄÁöÑÈÅµÂæ™Êåá‰ª§ÁöÑÊï∞ÊçÆ‚Äî‚ÄîÂõ†Ê≠§Â≠òÂú®Âæ™ÁéØÊé®ÁêÜÁöÑÂõ∫ÊúâÈ£éÈô©„ÄÇÊú¨Ë¥®‰∏äÔºåLLaVAÂèØËÉΩÂÄæÂêë‰∫éÁîüÊàê‰∏éGPT-4ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Âõ∫ÊúâÁöÑÊ®°ÂºèÊàñÂÅèËßÅ‰∏ÄËá¥ÁöÑÂìçÂ∫î„ÄÇËøôÁßçÂÄæÂêëÂèØËÉΩ‰ºöÊâ≠Êõ≤ËØÑ‰º∞ÔºåÂØºËá¥‰∏Ä‰∏™ÁêÜËÆ∫‰∏äÁöÑ‰∏äÈôêÔºåÂèçÊò†Âá∫‰∏éGPT-4ÊñπÊ≥ïËÆ∫ÁöÑÂÖºÂÆπÊÄßÔºåËÄå‰∏çÊòØÂØπÊôÆÈÅçÊÄßËÉΩÁöÑÁúüÂÆûË°°Èáè„ÄÇ\n\nÊ≠§Â§ñÔºå‰æùËµñGPT-4Êèê‰æõÂÖ∂ËØÑ‰º∞ÁöÑÂÖ®Èù¢Ëß£ÈáäÔºåÂºïÂÖ•‰∫Ü‰∏ÄÁßç‰∏ªËßÇÊÄßÔºåËøôÁßç‰∏ªËßÇÊÄßÊ†πÊ§ç‰∫éËØ≠Ë®ÄÊ®°ÂûãÂØπ‰ªÄ‰πàÊûÑÊàêÈ´òË¥®ÈáèÂìçÂ∫îÁöÑ‚ÄúÁêÜËß£‚Äù„ÄÇËøôÁßçÁêÜËß£ÂèóÂà∞GPT-4ËÆ≠ÁªÉÁöÑÊï∞ÊçÆÈõÜÁöÑÂΩ±ÂìçÔºåËÄåËøô‰∫õÊï∞ÊçÆÈõÜÂèØËÉΩÊú™ËÉΩÂÖÖÂàÜ‰ΩìÁé∞Áé∞ÂÆû‰∏ñÁïåÂ§öÊ®°ÊÄÅ‰∫íÂä®ÁöÑÂ§öÊ†∑ÊÄßÂíåÂ§çÊùÇÊÄß„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/is-perplexity-pro-a-smarter-more-efficient-way-to-search-the-web-ec509321d820","frontmatter":{"title":"Perplexity Pro ÊòØ‰∏ÄÁßçÊõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑÁΩëÁªúÊêúÁ¥¢ÊñπÂºèÂêóÔºü","meta_title":"Perplexity Pro ÊòØ‰∏ÄÁßçÊõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑÁΩëÁªúÊêúÁ¥¢ÊñπÂºèÂêóÔºü","description":"Perplexity ÊòØ‰∏ÄÁßçÁî±ÂØπËØùÂºè AI È©±Âä®ÁöÑÂõûÁ≠îÂºïÊìéÔºåÊó®Âú®Êèê‰æõÂÆûÊó∂Á≠îÊ°àÔºåË∂ÖË∂ä‰º†ÁªüÊêúÁ¥¢ÂºïÊìéÁöÑÈìæÊé•ÂàóË°®„ÄÇPerplexity Pro Êèê‰æõÂ¢ûÂº∫ÂäüËÉΩÔºåÂåÖÊã¨Â§öÁßç AI Ê®°ÂûãÈÄâÊã©ÂíåÊõ¥È´òÁöÑ‰ΩøÁî®ÈôêÂà∂„ÄÇËØ•Âπ≥Âè∞ÈÄÇÁî®‰∫éÂπøÊ≥õÈ¢ÜÂüüÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáÊèêÈóÆËé∑ÂæóÁ≤æÂáÜÁ≠îÊ°àÔºåËÄåÊó†ÈúÄÊµèËßàÂ§ßÈáèÊó†ÂÖ≥ÈìæÊé•„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®ÁîüÊàêÂºè AI Êó∂ÔºåÁî®Êà∑ÈúÄÊ≥®ÊÑè‰ø°ÊÅØÁöÑÂáÜÁ°ÆÊÄßÔºåÂª∫ËÆÆËøõË°å‰∫ãÂÆûÊ†∏Êü•„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tGkjG6z62TZoaRpaUkSHuw.png","categories":["Chatbots","Natural Language Processing","Technology/Web"],"author":"Rifx.Online","tags":["perplexity","conversational","search","subscription","models"],"draft":false,"slug":"blog/is-perplexity-pro-a-smarter-more-efficient-way-to-search-the-web-ec509321d820"},"content":"\n\n\n## ÊêúÁ¥¢ÁöÑÊú™Êù•\n\nPerplexity Pro ÊòØ‰∏ÄÁßçÊõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑÁΩëÁªúÊêúÁ¥¢ÊñπÂºèÂêóÔºü\n\n## ÂÆÉ‰∏é‰º†ÁªüÊêúÁ¥¢ÂºïÊìéÁõ∏ÊØîÂ¶Ç‰ΩïÔºåÂÄºÂæóËä±Ë¥πÂêóÔºü\n\nÂòøÔºåAIÊúãÂèã‰ª¨ÂíåÂÖ≥Ê≥®ËÄÖ‰ª¨„ÄÇ\n\nÊàëÂèóÂ§ü‰∫Ü„ÄÇÊàëÂ∑≤ÁªèÂéåÂÄ¶‰∫Ü‰º†ÁªüÊêúÁ¥¢„ÄÇ\n\nÊàë‰∏çÊÉ≥ÈÄöËøáÊï∞Áôæ‰∏™ÈìæÊé•Êù•ÊâæÂà∞ÊàëÊÉ≥Ë¶ÅÁöÑ**ÈÇ£‰∏ÄÊù°‰ø°ÊÅØ**ÔºåÂÆÉË¢´ÂüãÂú®Á¨¨‰∏âÈ°µÁöÑÂπøÂëä‰πãÈó¥„ÄÇ\n\n‰º†ÁªüÊêúÁ¥¢Â∑≤ÁªèÁªìÊùü„ÄÇ‰∏Ä‰∏™ÂÅú‰∫ßÁöÑÊ®°Âûã„ÄÇËøáÂéªÁöÑÈÅóÁâ©„ÄÇ\n\nÁé∞‰ª£Á≠îÊ°àÂºïÊìéÊòØÊú™Êù•„ÄÇ\n\nPerplexityÊâøËØ∫Â∞ÜÂΩªÂ∫ïÊîπÂèò‰∫íËÅîÁΩëÊêúÁ¥¢„ÄÇËÆ©Êàë‰ª¨Êù•Êé¢Á¥¢‰∏Ä‰∏ã‚Ä¶‚Ä¶\n\nÊàëÂ∞ÜÈ¶ñÂÖàËß£Èáä‰ªÄ‰πàÊòØPerplexityÂíåPerplexity ProÔºåÁÑ∂ÂêéÁªßÁª≠‰ªãÁªçÂÖ≥ÈîÆÁâπÊÄß„ÄÅ‰ΩøÁî®Ê°à‰æãÂíåË°å‰∏ö„ÄÇÊúÄÂêéÔºåÊàëÂ∞ÜÂø´ÈÄüÂ∞ÜÂÖ∂‰∏éChatGPTÁ≠âÊõø‰ª£ÂìÅËøõË°åÊØîËæÉ„ÄÇ\n\nÊâÄ‰ª•ËÆ©Êàë‰ª¨Áõ¥Êé•Ê∑±ÂÖ•„ÄÇ‰∫´ÂèóÂêßÔºÅ\n\n## ‰ªÄ‰πàÊòØ PerplexityÔºü\n\nPerplexity ÊòØ‰∏Ä‰∏™Áî±ÂØπËØùÂºè AI È©±Âä®ÁöÑÂõûÁ≠îÂºïÊìéÔºåËÉΩÂ§ü‰∏∫Â§çÊùÇÊü•ËØ¢Êèê‰æõÂÆûÊó∂Á≠îÊ°àÔºåËÄå‰º†ÁªüÊêúÁ¥¢ÂºïÊìéÂèØËÉΩÂè™Êèê‰æõ‰∏ÄÁ≥ªÂàóÊàñÂ§öÊàñÂ∞ëÊúâÁî®ÁöÑÈìæÊé•„ÄÇ\n\nÊàëÁªô‰Ω†‰∏Ä‰∏™Âø´ÈÄüÁöÑ‰æãÂ≠ê„ÄÇ\n\nÂú®Â∑•‰Ωú‰∏≠ÔºåÊàëÊÉ≥ÂàõÂª∫‰∏Ä‰∏™Êàë‰ª¨ÁöÑÁ°¨‰ª∂Ê∏ÖÂçïÔºåÂõ†‰∏∫ÂæàÂ§öÁ°¨‰ª∂ÈÉΩËøáÊó∂‰∫ÜÔºåËøëÊúüÈúÄË¶ÅÊõ¥Êç¢„ÄÇ\n\nÊâÄ‰ª•Êàë‰ΩøÁî®‰∫Ü PerplexityÔºàÂΩìÁÑ∂‰Ω†‰πüÂèØ‰ª•‰ΩøÁî® ChatGPTÔºâÔºåÂπ∂Ë¶ÅÊ±ÇÂÆÉÂàõÂª∫‰∏Ä‰∏™Á§∫‰æãË°®Ê†º„ÄÇÊàë‰∏çÁ°ÆÂÆöÂ¶Ç‰ΩïÁªìÊûÑÂåñÂÆÉÔºåËÄå Perplexity Á°ÆÂÆûÂ∏ÆÂä©ÊàëÊï¥ÁêÜ‰∫Ü Excel Ë°®Ê†º„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*SPnfT5NgUf01ahr3Wkz6-w@2x.jpeg)\n\nÂΩìÁÑ∂Ôºå‰Ω†ÂèØËÉΩ‰ºö‰∫âËæ©ËØ¥Ôºå‰Ω†‰∏çÈúÄË¶ÅÁîüÊàêÂºè AI Êù•ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑË°®Ê†ºÔºåËøôÁ°ÆÂÆûÊòØÂØπÁöÑ„ÄÇ‰ΩÜÁúüÊ≠£ÁöÑ‰πêË∂£Âú®‰∫é‰πãÂêé„ÄÇÊàë‰πãÂâç‰ªéÊú™Âú® Excel ‰∏≠ÂàõÂª∫ËøáÊï∞ÊçÆÈÄèËßÜË°®ÔºåÊàëÊÉ≥‰ªÖÊòæÁ§∫ËøáÊúü‰øù‰øÆÁöÑÁ°¨‰ª∂„ÄÇ\n\nÂΩìÊàëËØ¢ÈóÆ Perplexity Êó∂ÔºåÂÆÉ‰∏ç‰ªÖÁªô‰∫ÜÊàëÈÄêÊ≠•ÁöÑËØ¥ÊòéÔºåËøò‰ΩøÁî®‰∫ÜÊàëÁöÑÁ§∫‰æãÊï∞ÊçÆÊù•ÂêëÊàëÂ±ïÁ§∫Â¶Ç‰ΩïËÆæÁΩÆÊï∞ÊçÆÈÄèËßÜË°®„ÄÇËøôÊòØ‰º†ÁªüÊêúÁ¥¢Êó†Ê≥ïÂÅöÂà∞ÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lj92gWPB3w4xqaiSCc5r3Q@2x.jpeg)\n\nÂõ†Ê≠§ÔºåPerplexity Â∞ÜÁªèÂÖ∏ÊêúÁ¥¢ÂºïÊìé‰∏éÂÉè GPT-4o Êàñ Claude\\* ËøôÊ†∑ÁöÑ AI Ê®°ÂûãÁªìÂêàÂú®‰∏ÄËµ∑ÔºåÂÖÅËÆ∏Áî®Êà∑ÊèêÂá∫ÈóÆÈ¢òÂíåÂêéÁª≠ÈóÆÈ¢ò„ÄÇÂÆÉÂèØ‰ª•Â§ÑÁêÜÊñáÊ°£ÂíåÁÖßÁâáÔºåÁîüÊàê‰ª£Á†ÅÔºåÂàõÂª∫ÂÜÖÂÆπÔºåÂπ∂ÂØπÂêÑÁßç‰∏ªÈ¢òËøõË°åÊ∑±ÂÖ•Á†îÁ©∂„ÄÇ\n\nÂÆÉÁöÑÁã¨Áâπ‰πãÂ§ÑÂú®‰∫éÂåÖÂê´ËÑöÊ≥®‰ª•‰æõËøõ‰∏ÄÊ≠•Á†îÁ©∂ÊàñÊ£ÄÊü•ÂáÜÁ°ÆÊÄß„ÄÇ\n\nÊ≠£Â¶Ç‰Ω†‰ªé‰∏äÈù¢ÁöÑ‰æãÂ≠ê‰∏≠ÁúãÂà∞ÁöÑÔºåÁ≠îÊ°àÁ≤æÂáÜÔºåËøúËøúË∂ÖÂá∫‰∫ÜÊêúÁ¥¢ÂºïÊìéÁöÑËÉΩÂäõ„ÄÇ\n\n*\\*È¢òÂ§ñËØùÔºöGPT-40 ÊòØ‰∏ÄÁßçÊõ¥ÂÖàËøõÁöÑ AI Ê®°ÂûãÔºåÁî®‰∫éÈúÄË¶ÅÊõ¥È´òÂáÜÁ°ÆÊÄßÂíåÂ§ÑÁêÜËÉΩÂäõÁöÑ‰ªªÂä°ÔºåËÄå Claude 3 Opus ÊìÖÈïøÂàõÊÑèÂÜô‰ΩúÂíå‰ª£Á†ÅÁîüÊàêÁ≠â‰ªªÂä°„ÄÇ*\n\n## ‰ªÄ‰πàÊòØ Perplexity ProÔºü\n\nPerplexity Pro ÊòØ‰∏ÄÁßçÂ¢ûÂº∫ÁöÑËÆ¢ÈòÖÊúçÂä°ÔºåÊèê‰æõÁî®Êà∑ËÆøÈóÆ‰∏çÂêåÁöÑ AI Ê®°ÂûãÔºàÁî®‰∫é‰∏çÂêåÁöÑÁî®‰æãÔºâÂíåË∂ÖÂá∫Ê†áÂáÜÁâàÊú¨ÁöÑÂäüËÉΩ„ÄÇ\n\n‰ΩøÁî® ProÔºåÊÇ®ÂèØ‰ª•ÈÄâÊã© GPT\\-40„ÄÅClaude Sonnet 3\\.5„ÄÅClaude 3 Opus„ÄÅSonar Large 32k Âíå‰∏Ä‰∏™ÈªòËÆ§Ê®°ÂûãÔºàÊà™Ëá≥Êí∞ÂÜôÊó∂Ôºâ„ÄÇ\n\nPro Áî®Êà∑ÂèØ‰ª•‰∫´ÂèóÊõ¥È´òÁöÑ‰ΩøÁî®ÈôêÂà∂„ÄÅÊõ¥Âø´ÁöÑÂìçÂ∫îÊó∂Èó¥„ÄÅ‰∏™ÊÄßÂåñÁöÑÊêúÁ¥¢ÁªìÊûú‰ª•ÂèäÈ´òÁ∫ßÊñáÊ°£ÂàÜÊûêÔºàÊà™Ëá≥Êí∞ÂÜôÊó∂ÔºâÂá†‰πéÊó†ÈôêÁöÑÊñá‰ª∂‰∏ä‰º†„ÄÇ\n\n‰ª•‰∏ãÊòØ Perplexity Âíå Perplexity Pro ÂØπÂêå‰∏ÄÈóÆÈ¢òÁöÑÂõûÁ≠îÁ§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RZf3p_4hS2mGIU9iFf23rw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-gUUeHj-oWwFlZARJ3YG_g.png)\n\nÂ¶ÇÊÇ®ÊâÄËßÅÔºåPro ÁöÑÂõûÁ≠îÊõ¥Âä†ËØ¶ÁªÜ„ÄÇ\n\n## Perplexity ProÈÄÇÂêàË∞ÅÔºü\n\nPerplexityÊúâÂπøÊ≥õÁöÑ‰ΩøÁî®Ê°à‰æãÂíåÂ∫îÁî®È¢ÜÂüü„ÄÇËÆ©Êàë‰ª¨ÂÅö‰∏Ä‰∏™ÊúâË∂£ÁöÑÂÆûÈ™åÔºåÈóÆÈóÆPerplexity„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PJvSMVKPKvUcwkjB8i91Gg.png)\n\nPerplexityÁªôÂá∫‰∫ÜËØ¶ÁªÜÁöÑÂõûÁ≠î„ÄÇËÆ©Êàë‰ª¨ÂàÜËß£‰∏Ä‰∏ãÔºö\n\nPerplexityÂíåPerplexity ProÂèØ‰ª•Â∫îÁî®‰∫éÂêÑÁßçÈ¢ÜÂüü„ÄÅË°å‰∏öÂíå‰∏™‰∫∫„ÄÇÂç≥‰Ωø‰Ωú‰∏∫‰∏Ä‰∏™ÊôÆÈÄöÁöÑÁΩëÁªúÁî®Êà∑Ôºå‰Ω†‰πüÂèØ‰ª•Âú®‰∏çÊµèËßàÊï∞ÂçÅ‰∏™ÈìæÊé•ÂíåÂπøÂëäÁöÑÊÉÖÂÜµ‰∏ãËé∑Âæó‰Ω†ÈóÆÈ¢òÁöÑÂáÜÁ°ÆÁ≠îÊ°à„ÄÇ\n\nÂ∞±Êàë‰∏™‰∫∫ËÄåË®ÄÔºåÊàëÊØèÂ§©ÈÉΩ‰ΩøÁî®PerplexityËøõË°åÊâÄÊúâÊêúÁ¥¢ÔºåÂÆÉÂ∑≤ÁªèÂèñ‰ª£‰∫ÜGoogleÊàê‰∏∫ÊàëÁöÑÊ†áÂáÜÊêúÁ¥¢ÂºïÊìé„ÄÇ‰Ω†ÂèØ‰ª•Âú®ËøôÈáåÈòÖËØªÊõ¥Â§öÂÖ≥‰∫éÂÆÉÁöÑ‰ø°ÊÅØ„ÄÇÊòØÁöÑÔºåÊàëÊÄªÊòØ‰ΩøÁî®‰∏ì‰∏öÊêúÁ¥¢„ÄÇËôΩÁÑ∂ÂèØËÉΩÈúÄË¶ÅËä±Ë¥πÊõ¥Â§öÊó∂Èó¥Ôºå‰ΩÜÊ†πÊçÆÊàëÁöÑÁªèÈ™åÔºåÁªìÊûúÊõ¥Â•Ω‰∏îÊõ¥ÂÖ®Èù¢„ÄÇ\n\nËøôÊòØPerplexityÁöÑÁªìÊûúÔºö\n\n* ÊäÄÊúØ‰∏éÂ∑•Á®ã\n* ÈîÄÂîÆ‰∏éÂ∏ÇÂú∫Ëê•ÈîÄ\n* ‰∫ßÂìÅÂºÄÂèë\n* Ê≥ïÂæã‰∏éÂåªÁñó‰øùÂÅ•\n* ‰ΩìËÇ≤‰∏éÂ®±‰πê\n* Ë¥¢Âä°‰∏éÊàòÁï•\n* Êï∞ÊçÆÁßëÂ≠¶\n* Áîµ‰ø°\n* ‰∫∫Â∑•Êô∫ËÉΩ‰∏éÊú∫Âô®Â≠¶‰π†\n\n‰∏ÄËà¨Êù•ËØ¥Ôºå‰Ω†ÂèØ‰ª•ËØ¥ÂÆÉÂØπ‰ªª‰ΩïÈ¢ÜÂüüÊàñË°å‰∏öÁöÑ‰∫∫ÈÉΩÂæàÊúâÁî®ÔºåËøôÁ°ÆÂÆûÊòØ‰∫ãÂÆû„ÄÇÂç≥‰Ωø‰Ω†ÈÄöÂ∏∏‰∏ç‰ΩøÁî®ÁîüÊàêÂºèAIÔºå‰ªÖ‰ªÖÊòØËé∑Âæó‰∏Ä‰∏™ÈóÆÈ¢òÁöÑÁ≠îÊ°àÔºåËÄå‰∏çÈúÄË¶ÅÊµèËßàÊï∞ÂçÅ‰∏™Êó†ÂÖ≥ÁöÑÈìæÊé•ÔºåËøô‰πüÊòØ‰∏Ä‰∏™ÂæàÂ§ßÁöÑ‰ºòÁÇπ„ÄÇ\n\nËøôÊúâÁÇπÂÉèÂíå‰∏Ä‰∏™‰ªÄ‰πàÈÉΩÁü•ÈÅìÁöÑÊúãÂèãËÅäÂ§©„ÄÇ\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰Ω†Ê≠£Âú®Â∫¶ÂÅáÔºåÊÉ≥Áü•ÈÅì‰ªéÈÖíÂ∫óÂà∞‰∏Ä‰∏™ËëóÂêçÊôØÁÇπÊòØÂê¶ÂèØ‰ª•Ê≠•Ë°å„ÄÇ‰Ω†ÂèØ‰ª•ÊâìÂºÄÈÖíÂ∫óÁΩëÁ´ôÂõõÂ§ÑÁúãÁúãÔºå‰ΩøÁî®ÊêúÁ¥¢ÂºïÊìéÂ∏åÊúõËÉΩÂæóÂà∞‰∏Ä‰∏™ÊúâÁî®ÁöÑÁ≠îÊ°àÔºåÊàñËÄÖ‰Ω†ÂèØ‰ª•Áõ¥Êé•ÈóÆPerplexity„ÄÇÂÆÉ‰∏ç‰ªÖ‰ºöÁªô‰Ω†‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÁ≠îÊ°àÔºåËøò‰ºöÂåÖÊã¨ÊñπÂêë„ÄÅ‰∏Ä‰∫õÁÖßÁâáÂíåËßÜÈ¢ëÈìæÊé•‚Äî‚ÄîÊâÄÊúâ‰ø°ÊÅØÈÉΩÂú®‰∏ÄÈ°µ‰∏ä„ÄÇÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÊõ¥Â§öÁªÜËäÇÔºå‰Ω†ÂèØ‰ª•Áõ¥Êé•ÈóÆ‰∏Ä‰∏™ÂêéÁª≠ÈóÆÈ¢ò„ÄÇ\n\n## ÊàëÂ¶Ç‰Ωï‰ΩøÁî® Perplexity\n\nÊàëÂá†‰πéÊâÄÊúâÁöÑÁΩëÁªúÊêúÁ¥¢ÈÉΩÊòØÂú®ËøôÈáåËøõË°åÁöÑ„ÄÇ\n\n‰ªÖ‰ªÖÂá†Âë®‰πãÂêéÔºåÊàëÂ∑≤Áªè‰π†ÊÉØ‰∫ÜÊèêÈóÆÔºåËÄå‰∏çÊòØÂú®ÊêúÁ¥¢ÂºïÊìé‰∏≠ËæìÂÖ•ÂÖ≥ÈîÆËØçÔºå‰ª•Ëá≥‰∫éÊàëÊó†Ê≥ïÁõ∏‰ø°ÊàëÊõæÁªèÊòØÂ¶Ç‰ΩïÊ≤°ÊúâÂÆÉÁîüÊ¥ªÁöÑ„ÄÇ\n\nÊèêÈóÆÁöÑÊÑüËßâÊà™ÁÑ∂‰∏çÂêåÔºåÂç≥‰ΩøÊòØÂáÜÁ°ÆËØ¥Êòé‰Ω†ÈúÄË¶ÅÁü•ÈÅìÁöÑÂÜÖÂÆπÔºåËÄå‰∏çÊòØÁåúÊµãÂì™‰∫õÂÖ≥ÈîÆËØçÂèØËÉΩ‰ºöÁªô‰Ω†ÊÉ≥Ë¶ÅÁöÑÁ≠îÊ°à„ÄÇ\n\nÂç≥‰ΩøÊòØÂÉè‚ÄúÊüê‰ΩçÂêç‰∫∫Â§öÂ§ß‰∫Ü‚ÄùËøôÊ†∑ÁÆÄÂçïÁöÑÈóÆÈ¢òÔºå‰ΩøÁî® Perplexity ‰πüË¶ÅÂÆπÊòìÂæóÂ§ö„ÄÇÈÄöÂ∏∏ÊàëËøòÈúÄË¶ÅÁü•ÈÅìËá≥Â∞ë‰∏Ä‰∏™ÂêéÁª≠ÈóÆÈ¢òÔºåËÄå Perplexity ÁîöËá≥‰ºöÈ¢ÑËßÅÊàëÂèØËÉΩÊÉ≥Áü•ÈÅìÁöÑÂÜÖÂÆπÔºåÂπ∂Âú®ÂõûÁ≠îÁöÑÊúÄÂêéÂª∫ËÆÆÂêéÁª≠ÈóÆÈ¢ò„ÄÇ\n\n‰ª•‰∏ãÊòØ‰ªé ChatGPT ÂíåÂÖ∂‰ªñÁîüÊàêÊÄß AI Âπ≥Âè∞Ëé∑ÂæóÊõ¥Â•ΩÁªìÊûúÁöÑ‰∏â‰∏™ÊäÄÂ∑ßÔºå‰ΩÜ‰Ω†‰πüÂèØ‰ª•Â∞ÜËøô‰∫õÊäÄÂ∑ßÂ∫îÁî®‰∫é PerplexityÔºö\n\n## ÂäüËÉΩÁªÜÂàÜ‰∏éÂÆö‰ª∑\n\nPerplexity ÊòØÂÖçË¥πÁöÑÔºåÂü∫Êú¨ÁöÑÁΩëÁªúÊêúÁ¥¢Ë∂≥Â§ü‰ΩøÁî®„ÄÇ‰Ωú‰∏∫Ê≥®ÂÜåÁî®Êà∑ÔºåÊÇ®ÊØèÂõõÂ∞èÊó∂ÁîöËá≥ÂèØ‰ª•Ëé∑Âæó 5 Ê¨° Pro ÊêúÁ¥¢„ÄÇÂØπ‰∫é‰ªª‰ΩïË∂ÖÂá∫Âø´ÈÄüÂõûÁ≠îÁöÑÈúÄÊ±ÇÔºåPro ÁªùÂØπÊòØÊúÄ‰Ω≥ÈÄâÊã©„ÄÇ\n\nPro ÊêúÁ¥¢ËÉΩÂ§üÁêÜËß£ÊÇ®ÁöÑÈóÆÈ¢òÔºåÂèØËÉΩ‰ºöÂ∞ÜÂÖ∂ÂàÜËß£‰∏∫Êõ¥Â∞èÁöÑ‰ªªÂä°ÔºåÂπ∂ÂèØËÉΩÂú®Êèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑÁ≠îÊ°à‰πãÂâçËØ¢ÈóÆÊÇ®‰∏Ä‰∏™ÈóÆÈ¢òÔºàËØ∑ÂèÇËßÅ‰∏äÈù¢ÁöÑÊà™ÂõæÔºâ„ÄÇ\n\nÂú® Pro ËÆ°Âàí‰∏≠ÔºåÊÇ®ÁîöËá≥ÂèØ‰ª•ÈÄâÊã© AI Ê®°ÂûãÔºàÂç≥ ChatGPT\\-4o Êàñ Claude Sonnet 3\\.5 Á≠âÔºâÔºåËÄå‰∏çÂøÖ‰æùËµñÊ†áÂáÜÁöÑ Perplexity AI Ê®°Âûã„ÄÇ\n\nÂ¶ÇÊûúÊÇ®Êõ¥ÂñúÊ¨¢Â§ÑÁêÜÊñá‰ª∂Âπ∂ÊÉ≥Ë¶Å‰∏ä‰º† PDF ÊàñÂàÜÊûêÁÖßÁâáÔºåÊí∞ÂÜôÊó∂ÂÖçË¥πËÆ°ÂàíÁöÑÈôêÂà∂ÊòØÊØèÂ§© 3 ‰∏™ÔºåËÄå Pro ËÆ°ÂàíÂàôÊòØÊó†ÈôêÂà∂ÔºàÂ∞ΩÁÆ° Perplexity ‰ªÖË°®Á§∫ÊÇ®ÊØèÂ§©ÂèØ‰ª•‰∏ä‰º†Ëá≥Â∞ë 100 ‰∏™Êñá‰ª∂‚Äî‚ÄîÊàë‰∏çÁü•ÈÅìÂ¶ÇÊûúÊÇ®‰∏ä‰º†Êõ¥Â§ö‰ºöÂèëÁîü‰ªÄ‰πàÔºåÂõ†‰∏∫Êàë‰ªéÊú™‰∏ä‰º†ËøáÈÇ£‰πàÂ§öÔºâ„ÄÇ\n\nÂÆö‰ª∑‰∏∫ÊØèÊúà $20 ÊàñÊØèÂπ¥ $200„ÄÇ\n\n## ÊØîËæÉÊõø‰ª£ÊñπÊ°àÔºü\n\nÂØªÊâæ Perplexity ÁöÑÊõø‰ª£ÊñπÊ°àÊòØÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÔºåÂõ†‰∏∫ÂÖ∂‰ªñÁîüÊàêÂºè AI Âπ≥Âè∞ÈÄöÂ∏∏Âπ∂‰∏çÊòØ‰Ωú‰∏∫ÊêúÁ¥¢ÔºàÂõûÁ≠îÔºâÂºïÊìéËÆæËÆ°ÁöÑ„ÄÇËøôÊÑèÂë≥ÁùÄ‰Ω†ÂèØ‰ª•Âêë ChatGPT„ÄÅClaude Êàñ‰Ω†Ê≠£Âú®‰ΩøÁî®ÁöÑ‰ªª‰Ωï AI Âπ≥Âè∞ÊèêÈóÆÔºåÂÆÉ‰ª¨‰ºöÂà©Áî®Áé∞ÊúâÁü•ËØÜÊèê‰æõÁ≠îÊ°à„ÄÇ\n\nÂú®ÂÆÉ‰ª¨ÁöÑËÆ¢ÈòÖÊ®°Âûã‰∏≠ÔºåÂèØËÉΩÂÖÅËÆ∏ËøõË°åÁΩëÈ°µÊêúÁ¥¢Ôºå‰ΩÜ‰∏éÁúüÊ≠£ÁöÑÂõûÁ≠îÂºïÊìéÁõ∏ÊØîÔºåËøôÂπ∂‰∏çÁÆó‰ªÄ‰πà„ÄÇ\n\nÊòØÁöÑÔºåÁ°ÆÂÆûËøòÊúâÂÖ∂‰ªñ‰∏Ä‰∫õÂõûÁ≠îÂºïÊìéÔºà‰Ω†ÂèØ‰ª•ËØ¢ÈóÆ Perplexity ÂÖ≥‰∫éÂÆÉ‰ª¨ÁöÑ‰ø°ÊÅØÔºâÔºå‰ΩÜÂ∞±Êàë‰∏™‰∫∫ÁöÑÁªèÈ™åËÄåË®ÄÔºåPerplexity Êèê‰æõ‰∫ÜÊúÄÂÖ®Èù¢ÁöÑÁ≠îÊ°à„ÄÇ\n\nÂ∞±ÊàëËÄåË®ÄÔºåÊàëÂêåÊó∂‰∏∫ ChatGPT Âíå Perplexity ‰ªòË¥πÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑÁî®ÈÄî‰∏çÂêåÔºåÊàëÈúÄË¶Å ChatGPT Êù•Â∏ÆÂä©ÊàëÁöÑÂ≠¶‰π†„ÄÇËøô‰∏™ÊñπÈù¢ÂÆÉÁ°ÆÂÆûË°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n‰Ω†ÂèØ‰ª•Âú®ËøôÈáåÈòÖËØªÊõ¥Â§ö‰ø°ÊÅØÔºö\n\n## ‰ªÄ‰πàÊòØÈô∑Èò±Ôºü\n\nÂΩìÁÑ∂ÔºåÊÄªÊòØÊúâ‰∏Ä‰∏™Èô∑Èò±„ÄÇÂøÖÈ°ªÊúâ„ÄÇ\n\nÊòØÁöÑÔºåÁ°ÆÂÆûÊúâ‰∏Ä‰∏™„ÄÇÁî±‰∫é Perplexity ‰ΩøÁî®ÁîüÊàêÂºè AIÔºåÂõ†Ê≠§Ê®°ÂûãÊÄªÊòØÊúâÂèØËÉΩ‰∫ßÁîüÂπªËßâ„ÄÇËøôÊÑèÂë≥ÁùÄÂÆÉÊó†ËÆ∫Â¶Ç‰ΩïÈÉΩÊÉ≥Áªô‰Ω†‰∏Ä‰∏™Á≠îÊ°àÔºåÂ¶ÇÊûúÊâæ‰∏çÂà∞‰ªª‰Ωï‰ø°ÊÅØÔºåÂèØËÉΩ‰ºöÁºñÈÄ†‰∏Ä‰∫õÂÜÖÂÆπ„ÄÇ\n\nÂõ†Ê≠§Ôºå‰∫ãÂÆûÊ†∏Êü•ÈùûÂ∏∏ÈáçË¶Å„ÄÇ\n\nÂπ∏ËøêÁöÑÊòØÔºåPerplexity ÈÄöËøáÂåÖÂê´ËÑöÊ≥®‰ΩøËøôÂèòÂæóÁõ∏ÂØπÁÆÄÂçïÔºåÂ¶ÇÊûú‰Ω†‰∏çÁ°ÆÂÆöÊàñÈúÄË¶ÅÁ°ÆËÆ§ÔºåÂèØ‰ª•Âø´ÈÄüÊ£ÄÊü•„ÄÇ\n\nÊàëÂº∫ÁÉàÈºìÂä±‰Ω†ËøôÊ†∑ÂÅöÔºåÁâπÂà´ÊòØÂΩì‰Ω†Á†îÁ©∂‰∏Ä‰∫õÊõ¥‰∏•ËÇÉÁöÑ‰∏ªÈ¢òÊó∂„ÄÇ\n\nPerplexity Pro ÊòØ‰º†ÁªüÊêúÁ¥¢ÁöÑÈáçÂ§ßÂçáÁ∫ß„ÄÇ‰Ω†ÊòØ‰ΩøÁî®Á≠îÊ°àÂºïÊìéÔºåËøòÊòØ‰ªçÁÑ∂ÊòØ‰º†ÁªüÊêúÁ¥¢ÂºïÊìéÁöÑÁî®Êà∑Ôºüüí¨\n\n\n> Hej there! Can I ask you a favour (it will really help me out to grow this blog)? If you find this article insightful, follow **me please** and **clap 50 times.** Or feel free to [buy me a coffee](https://buy.stripe.com/cN28xZgDweSd52M000). **Thanks for reading!**\n\n"},{"lang":"zh","group":"blog","slug":"blog/key-points-llm-quantization-chatgpt-artificial-intelligence-8201ffcb33d4","frontmatter":{"title":"Ëß£ÈîÅ LLM ÈáèÂåñÁöÑ 5 ‰∏™ÂÖ≥ÈîÆÁÇπ","meta_title":"Ëß£ÈîÅ LLM ÈáèÂåñÁöÑ 5 ‰∏™ÂÖ≥ÈîÆÁÇπ","description":"ÈáèÂåñÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RUqPEr2NTYXlI1omqF22Qg.png","categories":["Machine Learning","Data Science","Technology/Web"],"author":"Rifx.Online","tags":["quantization","weights","activations","calibration","Quanto"],"draft":false,"slug":"blog/key-points-llm-quantization-chatgpt-artificial-intelligence-8201ffcb33d4"},"content":"\n\n\n### Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈáèÂåñ\n\n\n\nLLMÈáèÂåñÁõÆÂâçÊòØ‰∏Ä‰∏™ÁÉ≠Èó®ËØùÈ¢òÔºåÂõ†‰∏∫ÂÆÉÂú®ÊèêÈ´òÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÊïàÁéáÂíåÂú®ÂêÑÁßçÁ°¨‰ª∂Âπ≥Âè∞ÔºàÂåÖÊã¨Ê∂àË¥πÁ∫ßËÆæÂ§áÔºâ‰∏äÈÉ®ÁΩ≤ÊñπÈù¢ÂèëÊå•ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇ\n\nÈÄöËøáË∞ÉÊï¥Ê®°Âûã‰∏≠Êüê‰∫õÁªÑ‰ª∂ÁöÑÁ≤æÂ∫¶Ôºå**ÈáèÂåñÊòæËëóÂáèÂ∞ë‰∫ÜÊ®°ÂûãÁöÑÂÜÖÂ≠òÂç†Áî®**ÔºåÂêåÊó∂‰øùÊåÅÁõ∏‰ººÁöÑÊÄßËÉΩÊ∞¥Âπ≥„ÄÇ\n\nÂú®Êú¨ÊåáÂçó‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®LLMÈáèÂåñÁöÑ‰∫î‰∏™ÂÖ≥ÈîÆÊñπÈù¢ÔºåÂåÖÊã¨Â∞ÜÊ≠§ÊäÄÊúØÂ∫îÁî®‰∫éÊàë‰ª¨Ê®°ÂûãÁöÑ‰∏Ä‰∫õÂÆûÁî®Ê≠•È™§„ÄÇ\n\n## #1. ÁêÜËß£ÈáèÂåñ\n\nÈáèÂåñÊòØ‰∏ÄÁßçÊ®°ÂûãÂéãÁº©ÊäÄÊúØÔºåÈÄöËøáÈôç‰Ωé LLM ‰∏≠ÊùÉÈáçÂíåÊøÄÊ¥ªÁöÑÁ≤æÂ∫¶Êù•ÂÆûÁé∞„ÄÇËøôÊ∂âÂèäÂ∞ÜÈ´òÁ≤æÂ∫¶ÂÄºËΩ¨Êç¢‰∏∫‰ΩéÁ≤æÂ∫¶ÂÄºÔºåÂÆûÈôÖ‰∏äÊòØ**Â∞ÜÂ≠òÂÇ®Êõ¥Â§ö‰ø°ÊÅØÁöÑÊï∞ÊçÆÁ±ªÂûãÊõ¥Êîπ‰∏∫Â≠òÂÇ®Êõ¥Â∞ë‰ø°ÊÅØÁöÑÊï∞ÊçÆÁ±ªÂûã**„ÄÇ\n\nÂáèÂ∞ëÊØè‰∏™ÊùÉÈáçÊàñÊøÄÊ¥ªÊâÄÈúÄÁöÑ‰ΩçÊï∞ÊòæËëóÈôç‰Ωé‰∫ÜÊï¥‰ΩìÊ®°ÂûãÂ§ßÂ∞è„ÄÇÂõ†Ê≠§Ôºå**ÈáèÂåñÂàõÂª∫‰∫Ü‰ΩøÁî®Êõ¥Â∞ëÂÜÖÂ≠òÂíåÈúÄË¶ÅÊõ¥Â∞ëÂ≠òÂÇ®Á©∫Èó¥ÁöÑ LLM„ÄÇ**\n\nËøô‰∏ÄÊäÄÊúØÂú®Â∫îÂØπ LLM ËøûÁª≠Ëø≠‰ª£‰∏≠ÂèÇÊï∞Êï∞ÈáèÁöÑÊåáÊï∞Â¢ûÈïøÊó∂ÂèòÂæóËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰æãÂ¶ÇÔºåÂú® OpenAI ÁöÑ GPT Á≥ªÂàó‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®‰ª•‰∏ãÂõæË°®‰∏≠ËßÇÂØüÂà∞Ëøô‰∏ÄÂ¢ûÈïøË∂ãÂäøÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QlAhma3Wu1F6w2WvkE8jDA.png)\n\nËøô‰∏ÄÊòæËëóÂ¢ûÂä†Â∏¶Êù•‰∫ÜÊåëÊàòÔºöÈöèÁùÄÊ®°ÂûãÁöÑÂ¢ûÈïøÔºåÂÆÉ‰ª¨ÁöÑÂÜÖÂ≠òÈúÄÊ±ÇÂæÄÂæÄË∂ÖËøáÂÖàËøõÁ°¨‰ª∂Âä†ÈÄüÂô®ÔºàÂ¶Ç GPUÔºâÁöÑÂÆπÈáè„ÄÇ**ËøôÈúÄË¶ÅÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÂíåÊé®ÁêÜÊù•ÁÆ°ÁêÜËøô‰∫õÊ®°ÂûãÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÁöÑÂèØÈÉ®ÁΩ≤ÊÄß„ÄÇ**\n\n## #2. ÈáèÂåñËÉåÂêéÁöÑÁõ¥Ëßâ\n\nÂ∞ΩÁÆ°ÈáèÂåñÁöÑÂÆö‰πâÁúãËµ∑Êù•Áõ∏ÂΩìÂ§çÊùÇÔºå‰ΩÜËøô‰∏™Ê¶ÇÂøµÂèØ‰ª•ÈÄöËøáÁü©ÈòµÁõ¥ËßÇÂú∞Ëß£Èáä„ÄÇ\n\nËÆ©Êàë‰ª¨ËÄÉËôë‰ª•‰∏ã‰∏Ä‰∏™ 3x3 Áü©ÈòµÔºåË°®Á§∫Á•ûÁªèÁΩëÁªúÁöÑÊùÉÈáç„ÄÇÂ∑¶‰æßÁöÑÁü©ÈòµÊòæÁ§∫‰∫ÜÂéüÂßãÊùÉÈáçÔºåËÄåÂè≥‰æßÁöÑÁü©ÈòµÊòæÁ§∫‰∫ÜËøô‰∫õÊùÉÈáçÁöÑÈáèÂåñÁâàÊú¨Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LPzWe9oxjlDYdSp7dVvRUg.png)\n\nÂú®Ëøô‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨Â∞ÜÂéüÂßãÁü©ÈòµÁöÑÂÖÉÁ¥†‰ªéÂõõ‰ΩçÂ∞èÊï∞ÂõõËàç‰∫îÂÖ•Âà∞‰∏Ä‰ΩçÂ∞èÊï∞„ÄÇÂ∞ΩÁÆ°Áü©ÈòµÁúãËµ∑Êù•Áõ∏‰ººÔºå**‰ΩÜÂõõ‰ΩçÂ∞èÊï∞ÁâàÊú¨ÊâÄÈúÄÁöÑÂ≠òÂÇ®Á©∫Èó¥ÊòæËëóÊõ¥È´ò**„ÄÇ\n\nÂú®ÂÆûË∑µ‰∏≠ÔºåÈáèÂåñ‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™ÂõõËàç‰∫îÂÖ•Êìç‰Ωú„ÄÇÁõ∏ÂèçÔºåÂÆÉÊ∂âÂèäÂ∞ÜÊï∞ÂÄºËΩ¨Êç¢‰∏∫‰∏çÂêåÁöÑÊï∞ÊçÆÁ±ªÂûãÔºåÈÄöÂ∏∏ÊòØ‰ªéÊõ¥È´òÁ≤æÂ∫¶ËΩ¨Êç¢‰∏∫Êõ¥‰ΩéÁ≤æÂ∫¶„ÄÇ\n\n‰æãÂ¶ÇÔºåÂ§ßÂ§öÊï∞Ê®°ÂûãÁöÑÈªòËÆ§Êï∞ÊçÆÁ±ªÂûãÊòØ `float32`ÔºåÊØè‰∏™ÂèÇÊï∞ÈúÄË¶Å 4 Â≠óËäÇÔºà32 ‰ΩçÔºâ„ÄÇÂõ†Ê≠§ÔºåÂØπ‰∫é‰∏Ä‰∏™ 3x3 Áü©ÈòµÔºåÊÄªÂÜÖÂ≠òÂç†Áî®‰∏∫ 36 Â≠óËäÇ„ÄÇÂ∞ÜÊï∞ÊçÆÁ±ªÂûãÊõ¥Êîπ‰∏∫ `int8`ÔºåÊØè‰∏™ÂèÇÊï∞Âè™ÈúÄË¶Å 1 Â≠óËäÇÔºå‰ªéËÄåÂ∞ÜÁü©ÈòµÁöÑÊÄªÂÜÖÂ≠òÂç†Áî®ÂáèÂ∞ëÂà∞‰ªÖ 9 Â≠óËäÇ„ÄÇ\n\n## #3. ÈáèÂåñËØØÂ∑Æ\n\nÊ≠£Â¶ÇÊàë‰ª¨ÊâÄÁúãÂà∞ÁöÑÔºåÂéüÂßãÁü©ÈòµÂèäÂÖ∂ÈáèÂåñÂΩ¢ÂºèÂπ∂‰∏çÂÆåÂÖ®Áõ∏Á≠âÔºå‰ΩÜÈùûÂ∏∏Áõ∏‰ºº„ÄÇÈÄêÂÄº‰πãÈó¥ÁöÑÂ∑ÆÂºÇË¢´Áß∞‰∏∫‚ÄúÈáèÂåñËØØÂ∑Æ‚ÄùÔºåÊàë‰ª¨‰πüÂèØ‰ª•Áî®Áü©ÈòµÂΩ¢ÂºèË°®Á§∫Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VtGDjVbr7daagLXB57i7Mg.png)\n\n**ËøôÁßçÈáèÂåñËØØÂ∑ÆÂèØ‰ª•Âú®ÁΩëÁªú‰∏≠ÁöÑÊØè‰∏™ÊùÉÈáçÁü©Èòµ‰∏≠Á¥ØÁßØÔºå‰ªéËÄåÂΩ±ÂìçÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ**\n\nÂΩìÂâçÁöÑÈáèÂåñÁ†îÁ©∂Êó®Âú®ÊúÄÂ∞èÂåñÁ≤æÂ∫¶Â∑ÆÂºÇÔºåÂêåÊó∂ÂáèÂ∞ëËÆ≠ÁªÉÊàñÊé®ÁêÜÊ®°ÂûãÊâÄÈúÄÁöÑËÆ°ÁÆóËµÑÊ∫êÔºåÂêåÊó∂‰øùÊåÅÂèØÊé•ÂèóÁöÑÊÄßËÉΩÊ∞¥Âπ≥„ÄÇ\n\n## #4. Á∫øÊÄßÈáèÂåñ\n\nÁ∫øÊÄßÈáèÂåñÊòØ LLMs ‰∏≠ÊúÄÊµÅË°åÁöÑÈáèÂåñÊñπÊ°à‰πã‰∏Ä„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåÂÆÉÊ∂âÂèäÂ∞ÜÂéüÂßãÊùÉÈáçÁöÑÊµÆÁÇπÂÄºËåÉÂõ¥Êò†Â∞ÑÂà∞Âõ∫ÂÆöÁÇπÂÄºËåÉÂõ¥„ÄÇ\n\nËÆ©Êàë‰ª¨ÂõûÈ°æ‰∏Ä‰∏ãÂ∞ÜÁ∫øÊÄßÈáèÂåñÂ∫îÁî®‰∫éÊàë‰ª¨ÁöÑÊ®°ÂûãÊâÄÈúÄÁöÑÊ≠•È™§Ôºö\n\n* **Ëé∑ÂèñÊúÄÂ∞èÂíåÊúÄÂ§ßËåÉÂõ¥Ôºö** Êàë‰ª¨ÈúÄË¶ÅËé∑ÂèñÂæÖÈáèÂåñÁöÑÊµÆÁÇπÊùÉÈáçÁöÑÊúÄÂ∞èÂÄºÂíåÊúÄÂ§ßÂÄºÔºà`x_min` Âíå `x_max`Ôºâ„ÄÇÊàë‰ª¨ËøòÈúÄË¶ÅÂÆö‰πâÈáèÂåñËåÉÂõ¥Ôºà`q_min` Âíå `q_max`ÔºâÔºåËØ•ËåÉÂõ¥Â∑≤ÁªèÁî±Êàë‰ª¨ÊÉ≥Ë¶ÅËΩ¨Êç¢ÁöÑÊï∞ÊçÆÁ±ªÂûãËÆæÁΩÆ„ÄÇ\n* **ËÆ°ÁÆóÁº©ÊîæÂõ†Â≠êÔºà`s`ÔºâÂíåÈõ∂ÁÇπÔºà`z`ÔºâÂÄºÔºö** È¶ñÂÖàÔºåÁº©ÊîæÂõ†Â≠êÔºà`s`ÔºâÂ∞ÜÊµÆÁÇπÂÄºÁöÑËåÉÂõ¥Ë∞ÉÊï¥Âà∞ÈÄÇÂêàÊï¥Êï∞ËåÉÂõ¥Ôºå‰øùÊåÅÊï∞ÊçÆÂàÜÂ∏ÉÂíåËåÉÂõ¥„ÄÇÂÖ∂Ê¨°ÔºåÈõ∂ÁÇπÔºà`z`ÔºâÁ°Æ‰øùÊµÆÁÇπËåÉÂõ¥ÂÜÖÁöÑÈõ∂Ë¢´ÂáÜÁ°ÆÂú∞Ë°®Á§∫‰∏∫Êï¥Êï∞Ôºå‰ªéËÄå‰øùÊåÅÊï∞ÂÄºÁöÑÂáÜÁ°ÆÊÄßÂíåÁ®≥ÂÆöÊÄßÔºåÁâπÂà´ÊòØÂØπ‰∫éÊé•ËøëÈõ∂ÁöÑÂÄº„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BepC6-izw0yE19ejsS705Q.png)\n\n* **ÈáèÂåñÂÄºÔºà`q`ÔºâÔºö** Êàë‰ª¨ÈúÄË¶Å‰ΩøÁî®Âú®Ââç‰∏ÄÊ≠•ËÆ°ÁÆóÁöÑÁº©ÊîæÂõ†Â≠êÔºà`s`ÔºâÂíåÈõ∂ÁÇπÔºà`z`ÔºâÂ∞ÜÂéüÂßãÊµÆÁÇπÂÄºÊò†Â∞ÑÂà∞Êï¥Êï∞ËåÉÂõ¥„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BBOQ0VbSGbwf7CN8c4PWKQ.png)\n\nÂ∫îÁî®Ëøô‰∫õÂÖ¨ÂºèÁõ∏ÂΩìÁÆÄÂçï„ÄÇÂ¶ÇÊûúÊàë‰ª¨Â∞ÜÂÆÉ‰ª¨Â∫îÁî®‰∫é‰∏ãÂõæÂ∑¶‰æßÁöÑ 3x3 ÊùÉÈáçÂº†ÈáèÔºåÊàë‰ª¨Â∞ÜÂæóÂà∞Âè≥‰æßÊâÄÁ§∫ÁöÑÈáèÂåñÁü©ÈòµÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KzBvg84mfI2gAhTIyVibwQ.png)\n\nÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞Ôºå`int8` ÂÄºÁöÑ‰∏ãÈôêÂØπÂ∫î‰∫éÂéüÂßãÂº†ÈáèÁöÑ‰∏ãÈôêÔºåËÄå‰∏äÈôêÂØπÂ∫î‰∫éÂéüÂßãÂº†ÈáèÁöÑ‰∏äÈôêÔºå*Âç≥ÔºåÊò†Â∞Ñ‰∏∫ `0.50 ‚Üí 255` Âíå `-0.40 ‚Üí 0`„ÄÇ*\n\nÊàë‰ª¨Áé∞Âú®ÂèØ‰ª•‰ΩøÁî®‰∏ãÈù¢ÁöÑÂÖ¨ÂºèÂØπÂÄºËøõË°åÂèçÈáèÂåñ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*E5nnqYzncYCRuM5prssuOw.png)\n\nÂ¶ÇÊûúÊàë‰ª¨Â∞ÜÂèçÈáèÂåñÂêéÁöÑÂÄºÂÜçÊ¨°ÊîæÂÖ•Áü©ÈòµÂΩ¢ÂºèÔºàÂ∑¶‰æßÁü©ÈòµÔºâÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáËÆ°ÁÆóÂéüÂßãÁü©Èòµ‰∏éÂÖ∂ÂèçÈáèÂåñÁâàÊú¨‰πãÈó¥ÈÄêÁÇπÂ∑ÆÂºÇÊù•ËÆ°ÁÆóÈáèÂåñËØØÂ∑ÆÔºàÂè≥‰æßÁü©ÈòµÔºâÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*56NALu9PAN95QG2hn8HXoQ.png)\n\nÊ≠£Â¶ÇÊàë‰ª¨ÊâÄËßÇÂØüÂà∞ÁöÑÔºåÈáèÂåñËØØÂ∑ÆÂºÄÂßãÂú®Êüê‰∫õÁü©ÈòµÂÄº‰∏≠ÊòæÁé∞„ÄÇ\n\n## #5. ÊùÉÈáçÈáèÂåñ‰∏éÊøÄÊ¥ªÈáèÂåñ\n\nÂú®‰∏äÈù¢ÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨‰∏ªË¶ÅÂÖ≥Ê≥®‰∫éÈáèÂåñÊ®°ÂûãÁöÑÊùÉÈáç„ÄÇËôΩÁÑ∂ÊùÉÈáçÈáèÂåñÂØπ‰∫éÊ®°Âûã‰ºòÂåñËá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜËÄÉËôëÂà∞ÊøÄÊ¥ª‰πüÂèØ‰ª•ËøõË°åÈáèÂåñÂêåÊ†∑ÈáçË¶Å„ÄÇ\n\n**ÊøÄÊ¥ªÈáèÂåñÊ∂âÂèäÂáèÂ∞ëÁΩëÁªú‰∏≠ÊØèÂ±ÇÁöÑ‰∏≠Èó¥ËæìÂá∫ÁöÑÁ≤æÂ∫¶**„ÄÇ‰∏éÊùÉÈáçÂú®Ê®°ÂûãËÆ≠ÁªÉÂêé‰øùÊåÅ‰∏çÂèò‰∏çÂêåÔºåÊøÄÊ¥ªÊòØÂä®ÊÄÅÁöÑÔºåÂπ∂‰∏îÈöèÁùÄÊØè‰∏™ËæìÂÖ•ËÄåÂèòÂåñÔºå‰ΩøÂÖ∂ËåÉÂõ¥Êõ¥ÈöæÈ¢ÑÊµã„ÄÇ\n\n‰∏ÄËà¨ËÄåË®ÄÔºåÊøÄÊ¥ªÈáèÂåñÊØîÊùÉÈáçÈáèÂåñÊõ¥ÂÖ∑ÊåëÊàòÊÄßÔºåÂõ†‰∏∫ÂÆÉÈúÄË¶Å‰ªîÁªÜÊ†°ÂáÜ‰ª•Á°Æ‰øùÂáÜÁ°ÆÊçïÊçâÊøÄÊ¥ªÁöÑÂä®ÊÄÅËåÉÂõ¥„ÄÇ\n\nÊùÉÈáçÈáèÂåñÂíåÊøÄÊ¥ªÈáèÂåñÊòØ‰∫íË°•ÁöÑÊäÄÊúØ„ÄÇ‰∏§ËÄÖÁªìÂêà‰ΩøÁî®ÂèØ‰ª•ÊòæËëóÂáèÂ∞ëÊ®°ÂûãÂ§ßÂ∞èÔºåËÄå‰∏ç‰ºöÂ§ßÂπÖÂΩ±ÂìçÊÄßËÉΩ„ÄÇ\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂõûÈ°æ‰∫ÜÂÖ≥‰∫éÈáèÂåñÁöÑ5‰∏™ÂÖ≥ÈîÆÁÇπÔºå‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Â¶Ç‰ΩïÂáèÂ∞èËøô‰∫õ‰∏çÊñ≠Â¢ûÈïøÁöÑÊ®°ÂûãÁöÑÂ§ßÂ∞è„ÄÇ\n\nËá≥‰∫éËøô‰∫õÊäÄÊúØÁöÑÂÆûÁé∞ÔºåPython‰∏≠ÊúâÂá†‰∏™ÊîØÊåÅÈáèÂåñÁöÑÂ∑•ÂÖ∑ÂíåÂ∫ìÔºå‰æãÂ¶Ç`pytorch`Âíå`tensorflow`„ÄÇÁÑ∂ËÄåÔºåÂú®Áé∞ÊúâÊ®°Âûã‰∏≠Êó†ÁºùÈõÜÊàêÈáèÂåñÈúÄË¶ÅÂØπÂ∫ìÂíåÊ®°ÂûãÂÜÖÈÉ®ÁªìÊûÑÊúâÊ∑±ÂÖ•ÁöÑÁêÜËß£„ÄÇ\n\nËøôÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊàëÊúÄÂñúÊ¨¢ÁöÑÁÆÄÂçïÊ≠•È™§ÂÆûÁé∞ÈáèÂåñÁöÑÈÄâÈ°πÊòØHugging FaceÁöÑ[Quanto](https://huggingface.co/blog/quanto-introduction)Â∫ìÔºåÊó®Âú®ÁÆÄÂåñPyTorchÊ®°ÂûãÁöÑÈáèÂåñËøáÁ®ã„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ÂØπLLMÈáèÂåñÁöÑÊ∑±ÂÖ•ÂÜÖÂÆπ‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®‰∏äËø∞Â∫ìÊÑüÂÖ¥Ë∂£Ôºå‰Ω†ÂèØËÉΩËøò‰ºöÂØπÊñáÁ´†[‚ÄúÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÈáèÂåñÔºöÊúâÊïàÂáèÂ∞ëAIÊ®°ÂûãÂ§ßÂ∞è‚Äù](https://www.datacamp.com/tutorial/quantization-for-large-language-models)ÊÑüÂÖ¥Ë∂£„ÄÇ\n\nÂ∞±Ëøô‰∫õÔºÅÈùûÂ∏∏ÊÑüË∞¢‰Ω†ÁöÑÈòÖËØªÔºÅ\n\nÊàëÂ∏åÊúõËøôÁØáÊñáÁ´†ËÉΩÂú®**‰ΩøÁî®LLMsËøõË°åÁºñÁ†ÅÊó∂**ÂØπ‰Ω†ÊúâÊâÄÂ∏ÆÂä©ÔºÅ\n\n‰Ω†‰πüÂèØ‰ª•ËÆ¢ÈòÖÊàëÁöÑ[**Êó∂‰∫ãÈÄöËÆØ**](https://readmedium.com/@andvalenzuela/subscribe)Ôºå‰ª•‰æøÂèäÊó∂Ëé∑ÂèñÊñ∞ÂÜÖÂÆπ„ÄÇ\n\n**ÁâπÂà´ÊòØ**Ôºå**Â¶ÇÊûú‰Ω†ÂØπÊúâÂÖ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåChatGPTÁöÑÊñáÁ´†ÊÑüÂÖ¥Ë∂£**Ôºö\n\n"},{"lang":"zh","group":"blog","slug":"blog/langgraph-vs-langchain-vs-langflow-vs-langsmith-which-one-to-use-why-69ee91e91000","frontmatter":{"title":"LangGraph„ÄÅLangChain„ÄÅLangFlow„ÄÅLangSmithÔºö‰ΩøÁî®Âì™‰∏Ä‰∏™‰ª•Âèä‰∏∫‰ªÄ‰πàÔºü","meta_title":"LangGraph„ÄÅLangChain„ÄÅLangFlow„ÄÅLangSmithÔºö‰ΩøÁî®Âì™‰∏Ä‰∏™‰ª•Âèä‰∏∫‰ªÄ‰πàÔºü","description":"‰∫ÜËß£ LangGraph„ÄÅLangChain„ÄÅLangFlow Âíå LangSmith ‰πãÈó¥ÁöÑ‰∏ªË¶ÅÂå∫Âà´ÔºåÂπ∂‰∫ÜËß£Âì™ÁßçÊ°ÜÊû∂ÊúÄÈÄÇÂêàÊÇ®ÁöÑ‚Ä¶‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xrWv1QVt4zE5cxjA8VA3ag.png","categories":["Programming","Technology","Technology/Web"],"author":"Rifx.Online","tags":["LangGraph","LangChain","LangFlow","LangSmith","frameworks"],"draft":false,"slug":"blog/langgraph-vs-langchain-vs-langflow-vs-langsmith-which-one-to-use-why-69ee91e91000"},"content":"\n\n\n### Êé¢Á¥¢ LangGraph„ÄÅLangChain„ÄÅLangFlow Âíå LangSmith ‰πãÈó¥ÁöÑÂÖ≥ÈîÆÂå∫Âà´Ôºå‰∫ÜËß£Âì™ÁßçÊ°ÜÊû∂ÊúÄÈÄÇÂêàÊÇ®ÁöÑËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®‚Äî‚Äî‰ªéÂ∑•‰ΩúÊµÅÊûÑÂª∫Âà∞ÊÄßËÉΩÁõëÊéß„ÄÇ\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è | üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) |üìù [Medium](https://medium.com/@monsuralirana)\n\n\n\nËøëÂπ¥Êù•ÔºåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâÈ¢ÜÂüüËßÅËØÅ‰∫ÜÂèØÁî®‰∫éÊûÑÂª∫Âü∫‰∫éËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ∫îÁî®Á®ãÂ∫èÁöÑÊ°ÜÊû∂„ÄÅÂ∫ìÂíåÂ∑•ÂÖ∑Êï∞ÈáèÁöÑÊøÄÂ¢û„ÄÇÂú®Ëøô‰∫õÂ∑•ÂÖ∑‰∏≠Ôºå**LangGraph**„ÄÅ**LangChain**„ÄÅ**LangFlow** Âíå **LangSmith** Â∑≤Êàê‰∏∫È¢ÜÂÖàÁöÑÈÄâÊã©ÔºåÂêÑËá™Êª°Ë∂≥‰∏çÂêåÁöÑÁî®‰æãÂíåÁî®Êà∑ÈúÄÊ±Ç„ÄÇÂ¶ÇÊûúÊÇ®Â∏åÊúõÊûÑÂª∫„ÄÅÁõëÊéßÊàñÊâ©Â±ïËØ≠Ë®ÄÊ®°ÂûãÂ∑•‰ΩúÊµÅÔºå‰∫ÜËß£Ëøô‰∫õÂ∑•ÂÖ∑ÁöÑ‰ºòÂäøÂíåÁõÆÁöÑËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nÂú®Êú¨ÂçöÂÆ¢‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®ÊØè‰∏™Ê°ÜÊû∂ÔºåÂàÜÊûêÂÆÉ‰ª¨ÁöÑ‰ºòÂäøÔºåÂπ∂Êèê‰æõ‰ΩïÊó∂‰ΩøÁî®ÂÆÉ‰ª¨ÁöÑËßÅËß£„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÁªèÈ™å‰∏∞ÂØåÁöÑÂºÄÂèëËÄÖËøòÊòØËØ•È¢ÜÂüüÁöÑÊñ∞ÊâãÔºåÁêÜËß£Ëøô‰∫õÂ∑•ÂÖ∑ÁöÑÁªÜÂæÆÂ∑ÆÂà´Â∞ÜÂ∏ÆÂä©ÊÇ®‰∏∫ÊÇ®ÁöÑÈ°πÁõÆÈÄâÊã©ÂêàÈÄÇÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n## ËØ≠Ë®ÄÊ®°ÂûãÊ°ÜÊû∂ÁÆÄ‰ªã\n\nÈöèÁùÄÂº∫Â§ßÁöÑËØ≠Ë®ÄÊ®°ÂûãÂ¶Ç GPT-3„ÄÅGPT-4 ‰ª•ÂèäÂÖ∂‰ªñÂü∫‰∫éÂèòÊç¢Âô®ÁöÑÊ®°ÂûãÁöÑÂ¥õËµ∑ÔºåË∂äÊù•Ë∂äÈúÄË¶ÅËÉΩÂ§üÁÆÄÂåñËØ≠Ë®ÄÂ∫îÁî®Á®ãÂ∫èÂàõÂª∫ÂíåÁÆ°ÁêÜÁöÑÊ°ÜÊû∂„ÄÇËøô‰∫õÊ°ÜÊû∂ÁÆÄÂåñ‰∫ÜÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÂ¶Ç **ÈìæÊé•Â§ö‰∏™ÊèêÁ§∫**„ÄÅ**Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£**ÔºåÁîöËá≥ **ÁõëÊéßÊ®°ÂûãÊÄßËÉΩ**„ÄÇ\n\nÁÑ∂ËÄåÔºåÂπ∂ÈùûÊâÄÊúâÊ°ÜÊû∂ÈÉΩÊòØÁõ∏ÂêåÁöÑ„ÄÇÊúâ‰∫õÊ°ÜÊû∂Êèê‰æõ **ÂèØËßÜÂåñÁïåÈù¢** Êù•ÁÆ°ÁêÜÂ∑•‰ΩúÊµÅÁ®ãÔºåËÄåÂÖ∂‰ªñÊ°ÜÊû∂ÂàôÊèê‰æõÈ´òÁ∫ßÁöÑ **Ë∞ÉËØïÂíåÂèØËßÇÂØüÊÄß** ÂäüËÉΩ„ÄÇËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£Ëøô‰∫õÂ∑•ÂÖ∑Ôºå‰ª•ÁêÜËß£ÂÆÉ‰ª¨Áã¨ÁâπÁöÑÂäüËÉΩ„ÄÇ\n\n## 1. LangGraphÔºöÂèØËßÜÂåñÂ§çÊùÇÂ∑•‰ΩúÊµÅ\n\n**LangGraph** ÊòØ‰∏Ä‰∏™‰∏∫ÂºÄÂèëËÄÖËÆæËÆ°ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÈÄÇÂêàÈÇ£‰∫õÂÅèÂ•Ω **ÂèØËßÜÂåñÊñπÊ≥ï** Êù•ÊûÑÂª∫ËØ≠Ë®ÄÊ®°ÂûãÁÆ°ÈÅìÁöÑÁî®Êà∑„ÄÇÂÆÉÂÖÅËÆ∏ÊÇ®ÈÄöËøá **Âü∫‰∫éÂõæÁöÑÂèØËßÜÂåñ** Êù•ÊûÑÂª∫Â§çÊùÇÁöÑÂ∑•‰ΩúÊµÅÔºå‰ªéËÄåÊõ¥ÂÆπÊòìÁêÜËß£‰∏çÂêå‰ªªÂä°ÂíåÁªÑ‰ª∂‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇËøôÂØπ‰∫éÂ§ö‰∏™Ê≠•È™§ÔºàÂ¶ÇÊñáÊú¨ÁîüÊàê„ÄÅÊñáÊ°£Ê£ÄÁ¥¢ÂíåÂàÜÁ±ªÔºâ‰∏≤ËÅîÂú®‰∏ÄËµ∑ÁöÑÂ§ßÂûãÂ∫îÁî®Â∞§ÂÖ∂ÊúâÁî®„ÄÇ\n\n### ‰ºòÂäøÔºö\n\n* **ÂèØËßÜÂåñÂ∑•‰ΩúÊµÅË°®Á§∫**ÔºöLangGraph ÂÖÅËÆ∏ÊÇ®ÂèØËßÜÂåñ‰∏çÂêåÁªÑ‰ª∂‰πãÈó¥ÁöÑÊï∞ÊçÆÂíåÊìç‰ΩúÊµÅ„ÄÇËøôÁßçÂõæÂΩ¢ÂåñÁöÑÊñπÊ≥ïÁõ¥ËßÇ‰∏îÊúâÂä©‰∫éËÆæËÆ°Êõ¥Â§çÊùÇÁöÑÁÆ°ÈÅì„ÄÇ\n* **Ë∞ÉËØïÁÆÄÂçï**ÔºöLangGraph ÁöÑÂèØËßÜÂåñÁâπÊÄß‰ΩøÂæóËØÜÂà´Â∑•‰ΩúÊµÅ‰∏≠ÁöÑÁì∂È¢àÊàñÈóÆÈ¢òËäÇÁÇπÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇ\n\n### Á§∫‰æãÁî®‰æãÔºö\n\nÂÅáËÆæÊÇ®Ê≠£Âú®ÊûÑÂª∫‰∏Ä‰∏™Ëá™Âä®ÂåñÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÈ¶ñÂÖà‰ΩøÁî®ËØ≠Ë®ÄÊ®°ÂûãÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£ÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂‰º†ÈÄíÁªôÊëòË¶ÅÁîüÊàêÂô®„ÄÇÂú® LangGraph ‰∏≠ÔºåÊÇ®ÂèØ‰ª•Áõ¥ËßÇÂú∞ÁªòÂà∂Âá∫Ê≠§Â∑•‰ΩúÊµÅÁ®ãÔºåÂ±ïÁ§∫ÊØè‰∏™Ê≠•È™§‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂ¶ÇÊûúÈìæ‰∏≠ÁöÑ‰ªª‰Ωï‰∏ÄÁÇπÂá∫Áé∞ÈóÆÈ¢òÔºåËßÜËßâÂ∑•ÂÖ∑‰ΩøÊÇ®ËÉΩÂ§üËΩªÊùæÂÆö‰ΩçÈóÆÈ¢òÊâÄÂú®„ÄÇ\n\n### ‰ΩïÊó∂‰ΩøÁî® LangGraphÔºö\n\nÂ¶ÇÊûúÊÇ®Ê≠£Âú®ÁÆ°ÁêÜ **Â§çÊùÇÁöÑÂ∑•‰ΩúÊµÅÁ®ã**ÔºåÂπ∂‰∏îÈáçËßÜ **ÂõæÂΩ¢ÁïåÈù¢** Êù•ÁêÜËß£ÊÇ®ÁöÑÁÆ°ÈÅìÔºåLangGraph ÊòØ‰∏Ä‰∏™Áªù‰Ω≥ÁöÑÈÄâÊã©„ÄÇÂÆÉÁâπÂà´ÈÄÇÂêàÈÇ£‰∫õÊõ¥ÂñúÊ¨¢Áõ¥ËßÇÁöÑÊãñÊîæÂºèÂ∑•‰ΩúÊµÅÁ®ãËÆæËÆ°ÁöÑÂºÄÂèë‰∫∫ÂëòÊàñÊï∞ÊçÆÁßëÂ≠¶ÂÆ∂„ÄÇ\n\n**ÂÖ≥ÈîÆÁÇπ**Ôºö\n\n* Â¶ÇÊûúÊÇ®ÈúÄË¶ÅÊ∏ÖÊô∞ÁöÑËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂèØËßÜÂåñË°®Á§∫„ÄÇ\n* Âú®ÂàõÂª∫ÈúÄË¶ÅÂàÜÊîØÊàñÂ§öË∑ØÂæÑ‰æùËµñÁöÑÊõ¥Â§çÊùÇÁöÑÁÆ°ÈÅìÊó∂„ÄÇ\n\n## 2. LangChainÔºöLLM Â∫îÁî®ÁöÑÂ∑•‰ΩúÈ©¨\n\n**LangChain** ÊòØÊûÑÂª∫Áî± **Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLMs)** È©±Âä®ÁöÑÂ∫îÁî®Á®ãÂ∫èÊúÄÂèóÊ¨¢ËøéÁöÑÊ°ÜÊû∂‰πã‰∏Ä„ÄÇÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÁßçÁÅµÊ¥ªÁöÑ **‰ª£Á†Å‰ºòÂÖàÊñπÊ≥ï**ÔºåÂÖÅËÆ∏ÂºÄÂèëËÄÖÂ∞ÜÊñáÊ°£Ê£ÄÁ¥¢„ÄÅÊëòË¶ÅÂíåÈóÆÁ≠îÁ≠â‰ªªÂä°‰∏≤ËÅîÊàêÁªü‰∏ÄÁöÑÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\n### ‰ºòÂäøÔºö\n\n* **ÂπøÊ≥õÊîØÊåÅLLMs**ÔºöLangChainÂÖºÂÆπÂ§öÁßçËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩøÂæóÈõÜÊàêOpenAIÁöÑGPTÊàñÊú¨Âú∞ÊâòÁÆ°Ê®°ÂûãÂèòÂæóÁÆÄÂçï„ÄÇ\n* **ÈìæÂºèËÉΩÂäõ**ÔºöLangChainÊìÖÈïø‰∫é**Â§ö‰∏™Êìç‰ΩúÁöÑÈìæÂºèÂ§ÑÁêÜ**‚Äî‚ÄîÂõ†Ê≠§ÂæóÂêç‚Äî‚Äî‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üÂàõÂª∫Â§çÊùÇÁöÑNLPÂ∫îÁî®„ÄÇ\n* **ÂπøÊ≥õÈááÁî®**Ôºö‰Ωú‰∏∫ÊúÄÂèóÊ¨¢ËøéÁöÑÊ°ÜÊû∂‰πã‰∏ÄÔºåLangChainÊã•Êúâ‰∏Ä‰∏™**Ëì¨ÂãÉÂèëÂ±ïÁöÑÁ§æÂå∫**ÂíåÂá∫Ëâ≤ÁöÑÊîØÊåÅÔºåÊèê‰æõ‰∏∞ÂØåÁöÑÊñáÊ°£ÂíåÊïôÁ®ã„ÄÇ\n\n### Á§∫‰æãÁî®‰æãÔºö\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊÇ®Ê≠£Âú®ÊûÑÂª∫‰∏Ä‰∏™ **ËÅäÂ§©Êú∫Âô®‰∫∫**ÔºåÂÆÉÈ¶ñÂÖàÁêÜËß£Áî®Êà∑ÁöÑÈóÆÈ¢òÔºå‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØÔºåÁÑ∂ÂêéÁîüÊàêÂìçÂ∫î„ÄÇ‰ΩøÁî® LangChainÔºåÊÇ®ÂèØ‰ª•ËΩªÊùæÂú∞‰ª•ÁºñÁ®ãÊñπÂºèÂàõÂª∫Ëøô‰∏™Â§öÊ≠•È™§ÁöÑËøáÁ®ãÔºåÁ°Æ‰øùÈìæ‰∏≠ÁöÑÊØè‰∏ÄÊ≠•ÂçèË∞ÉÂ∑•‰Ωú„ÄÇ\n\n### ‰ΩïÊó∂‰ΩøÁî® LangChainÔºö\n\nÂ¶ÇÊûúÊÇ®ÊòØ‰∏Ä‰∏™ **ÊûÑÂª∫Áîü‰∫ßÁ∫ßÂ∫îÁî®ÁöÑÂºÄÂèëËÄÖ**ÔºåÂπ∂‰∏îÈúÄË¶Å‰∏Ä‰∏™ **ÁÅµÊ¥ª„ÄÅ‰ª•‰ª£Á†Å‰∏∫‰∏≠ÂøÉÁöÑËß£ÂÜ≥ÊñπÊ°à**ÔºåLangChain ÊòØÊÇ®ÁöÑÊúÄ‰Ω≥ÈÄâÊã©„ÄÇÂÆÉÈùûÂ∏∏ÈÄÇÂêàÈÇ£‰∫õÂ∏åÊúõÊéßÂà∂Â∫îÁî®Êû∂ÊûÑÂπ∂‰∏îËÉΩËàíÈÄÇÂú∞ÁºñÂÜô‰ª£Á†ÅÊù•ÂÆö‰πâÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂºÄÂèëËÄÖ„ÄÇ\n\n**ÂÖ≥ÈîÆÁÇπ**Ôºö\n\n* Â¶ÇÊûúÊÇ®Ê≠£Âú®ÊûÑÂª∫ÈúÄË¶ÅË∑®Â§ö‰∏™ËØ≠Ë®ÄÊ®°ÂûãÈìæÂºè‰ªªÂä°ÁöÑÁîü‰∫ßÁ∫ßÂ∫îÁî®„ÄÇ\n* Â¶ÇÊûúÊÇ®ÈúÄË¶Å‰∏Ä‰∏™Êã•ÊúâÂπøÊ≥õÁ§æÂå∫ÊîØÊåÅÂíåÂ§öÁßçÈõÜÊàêÁöÑÂ∫ì„ÄÇ\n* ÂΩìÊÇ®ÂØπÁºñÁ®ãËß£ÂÜ≥ÊñπÊ°àÊõ¥‰∏∫ÁÜüÊÇâÔºåËÄåÈùûÂèØËßÜÂåñÂ∑•ÂÖ∑„ÄÇ\n\n## 3. LangFlow: Êó†ÈúÄÁºñÁ†Å/‰Ωé‰ª£Á†ÅÁöÑ LangChain Êâ©Â±ï\n\n**LangFlow** Êú¨Ë¥®‰∏äÊòØ **LangChain ÁöÑÂèØËßÜÂåñÊâ©Â±ï**„ÄÇÂÆÉÂ∞Ü LangChain Âº∫Â§ßÁöÑÂêéÁ´Ø‰∏é **Áõ¥ËßÇÁöÑÊãñÊîæÁïåÈù¢** ÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇLangFlow ‰ΩøÈÇ£‰∫õÂèØËÉΩ‰∏çÂ§™ÊìÖÈïøÁºñÂÜô‰ª£Á†ÅÁöÑÁî®Êà∑‰ªçÁÑ∂ËÉΩÂ§üÂú®‰ªñ‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏≠Âà©Áî®ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂº∫Â§ßÂäüËÉΩ„ÄÇ\n\n### ‰ºòÂäøÔºö\n\n* **ÂèØËßÜÂåñÂ∑•‰ΩúÊµÅÂàõÂª∫**Ôºö‰∏é LangGraph Á±ª‰ººÔºåLangFlow Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØËßÜÂåñÁïåÈù¢Áî®‰∫éÊûÑÂª∫Â∑•‰ΩúÊµÅ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÊòØÂü∫‰∫é LangChain ÊûÑÂª∫ÁöÑÔºåËøôÊÑèÂë≥ÁùÄÁî®Êà∑ÂèØ‰ª•Âà©Áî® LangChain ÁöÑÂº∫Â§ßÂäüËÉΩÔºåËÄåÊó†ÈúÄÁºñÂÜôÂ§ßÈáè‰ª£Á†Å„ÄÇ\n* **Âø´ÈÄüÂéüÂûãÂà∂‰ΩúÁöÑÁêÜÊÉ≥ÈÄâÊã©**ÔºöLangFlow ÈùûÂ∏∏ÈÄÇÂêàÂø´ÈÄü **ÂéüÂûãÂåñÊÉ≥Ê≥ï** ÊàñÊûÑÂª∫Ê¶ÇÂøµÈ™åËØÅÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n* **ÈÄÇÂêàÂàùÂ≠¶ËÄÖ**ÔºöÂÆÉÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂÖ•Èó®ÁÇπÔºåÈÄÇÂêàÈÇ£‰∫õÂØπÁºñÁ†Å‰∏çÂ§™ÁÜüÊÇâ‰ΩÜÊÉ≥Ë¶ÅÂàõÂª∫ËØ≠Ë®ÄÊ®°ÂûãÂ∑•‰ΩúÊµÅÁöÑÁî®Êà∑„ÄÇ\n\n### Á§∫‰æãÁî®‰æãÔºö\n\nÂ¶ÇÊûúÊÇ®ÊÉ≥Âø´ÈÄüÊûÑÂª∫‰∏Ä‰∏™**ÊëòË¶ÅÂ∑•ÂÖ∑**Êù•Ê£ÄÁ¥¢ÊñáÊ°£ÔºåÊÇ®ÂèØ‰ª•Âú®LangFlowÁöÑÁïåÈù¢‰∏≠ÊãñÊîæÁªÑ‰ª∂Ôºå‰ª•ÂàõÂª∫‰∏Ä‰∏™ÂÆåÂÖ®ÂäüËÉΩÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇËøôÂèØ‰ª•Âú®Âá†‰πé‰∏çÁºñÂÜô‰ª£Á†ÅÁöÑÊÉÖÂÜµ‰∏ãÂÆåÊàê„ÄÇ\n\n### ‰ΩïÊó∂‰ΩøÁî® LangFlowÔºö\n\nLangFlow ÈùûÂ∏∏ÈÄÇÂêà **ÈùûÂºÄÂèë‰∫∫Âëò** Êàñ **Âø´ÈÄüÂéüÂûãËÆæËÆ°**„ÄÇÂ¶ÇÊûúÊÇ®ÊÉ≥Âø´ÈÄüÂÆûÈ™å **LLM Â∑•‰ΩúÊµÅ** ËÄå‰∏çÊ∑±ÂÖ•‰ª£Á†ÅÔºåËøô‰∏™Â∑•ÂÖ∑ÂèØ‰ª•ËÆ©ÊÇ®ËΩªÊùæÂÖ•Èó®„ÄÇ\n\n**ÂÖ≥ÈîÆÁÇπ**Ôºö\n\n* Â¶ÇÊûúÊÇ®ÊÉ≥Âø´ÈÄüÂéüÂûãËÆæËÆ° LLM Â∑•‰ΩúÊµÅËÄå‰∏çÁºñÂÜô‰ª£Á†Å„ÄÇ\n* Â¶ÇÊûúÊÇ®ÂØπËßÜËßâÁºñÁ®ãÊÑüÂà∞ËàíÈÄÇÔºå‰ΩÜÈúÄË¶Å LangChain ÁöÑÁÅµÊ¥ªÊÄß„ÄÇ\n* Áî®‰∫éÊïôËÇ≤ÁõÆÁöÑÔºåÂ∏ÆÂä©Áî®Êà∑‰∫ÜËß£Â¶Ç‰ΩïÊûÑÂª∫Â∑•‰ΩúÊµÅ„ÄÇ\n\n## 4. LangSmith: ÁõëÊéß‰∏éÂèØËßÇÂØüÊÄß\n\nËôΩÁÑ∂ÂÖ∂‰ªñÂ∑•ÂÖ∑‰∏ìÊ≥®‰∫é **ÊûÑÂª∫Â∑•‰ΩúÊµÅÁ®ã**Ôºå**LangSmith** ÁöÑËÆæËÆ°ÁõÆÊ†áÊòØ **ÁõëÊéß** Âíå **Ë∞ÉËØï** ËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®„ÄÇÂÆÉÊèê‰æõ‰∫ÜÂÖàËøõÁöÑÂèØËßÇÂØüÊÄßÂäüËÉΩÔºå‰ª•Ë∑üË∏™ÊÇ®ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÂíåÊ®°ÂûãÁöÑÊÄßËÉΩÔºå‰ΩøÂÖ∂Âú®Áîü‰∫ßÁéØÂ¢É‰∏≠‰∏çÂèØÊàñÁº∫„ÄÇ\n\n### ‰ºòÂäøÔºö\n\n* **Ê∑±Â∫¶ÂèØËßÇÂØüÊÄß**ÔºöLangSmith ÂÖÅËÆ∏ÂºÄÂèëËÄÖÁõëÊéßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÁ°Æ‰øùÂ∑•‰ΩúÊµÅÁ®ãÊåâÈ¢ÑÊúüËøêË°å„ÄÇ\n* **ÈîôËØØË∑üË∏™**ÔºöÂÆÉÂú®Â∏ÆÂä©ÂºÄÂèëËÄÖÂÆö‰ΩçÈóÆÈ¢òÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩøË∞ÉËØïÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇ\n* **ÊÄßËÉΩÊ¥ûÂØü**ÔºöLangSmith Êèê‰æõÊúâÂÖ≥ **Â∑•‰ΩúÊµÅÁ®ãÊÄßËÉΩ** ÁöÑÊ¥ûÂØüÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖ‰ºòÂåñ‰ªñ‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n### Á§∫‰æãÁî®‰æãÔºö\n\nÂÅáËÆæÊÇ®Â∑≤ÁªèÈÉ®ÁΩ≤‰∫Ü‰∏Ä‰∏™**ÂÆ¢Êà∑ÊúçÂä°ËÅäÂ§©Êú∫Âô®‰∫∫**ÔºåËØ•ËÅäÂ§©Êú∫Âô®‰∫∫‰ΩøÁî®ËØ≠Ë®ÄÊ®°ÂûãÊù•ÂõûÁ≠îÈóÆÈ¢ò„ÄÇÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÔºåÊÇ®‰ºöÂèëÁé∞Êüê‰∫õÂõûÁ≠îÁöÑÂáÜÁ°ÆÊÄß‰Ωé‰∫éÈ¢ÑÊúü„ÄÇLangSmith ÂèØ‰ª•Â∏ÆÂä©ÊÇ®ËøΩË∏™ÈóÆÈ¢òÔºåÈÄöËøáÊèê‰æõÂØπÂ∑•‰ΩúÊµÅÁ®ã‰∏≠ÊØè‰∏™ÂÜ≥Á≠ñÁÇπÁöÑÂèØËßÅÊÄß„ÄÇ\n\n### ‰ΩïÊó∂‰ΩøÁî® LangSmithÔºö\n\nÂ¶ÇÊûúÊÇ®Âú® **Áîü‰∫ßÁéØÂ¢É** ‰∏≠ÈÉ®ÁΩ≤Â∫îÁî®Á®ãÂ∫èÔºåÂπ∂‰∏îÈúÄË¶ÅÁ°Æ‰øù **ÂÅ•Â£ÆÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊÄßËÉΩ**ÔºåLangSmith ÊòØ‰∏Ä‰∏™‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑„ÄÇÂÆÉÂú®ÁÆ°ÁêÜ **ÈúÄË¶ÅÈöèÁùÄÊó∂Èó¥Ë∞ÉËØïÂíå‰ºòÂåñÁöÑÂ§çÊùÇÁ≥ªÁªü** Êó∂ÁâπÂà´ÊúâÁî®„ÄÇ\n\n**ÂÖ≥ÈîÆÁÇπ**Ôºö\n\n* Â¶ÇÊûúÊÇ®ÈúÄË¶Å LLM Â∑•‰ΩúÊµÅ‰∏≠ÁöÑÈ´òÁ∫ßÁõëÊéßÊàñË∞ÉËØïËÉΩÂäõ„ÄÇ\n* ÂØπ‰∫éËßÇÂØüÊÄßÂØπÁ°Æ‰øùÊúÄ‰Ω≥Ê®°ÂûãÊÄßËÉΩËá≥ÂÖ≥ÈáçË¶ÅÁöÑÂºÄÂèëÁéØÂ¢É„ÄÇ\n* Â¶ÇÊûúÊÇ®ÁöÑÈáçÁÇπÊòØÂü∫‰∫éÂÆûÊó∂Ê¥ûÂØüÊîπËøõÂíåËø≠‰ª£ LLM È©±Âä®ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n## Âì™‰∏™Êõ¥ÈÄÇÂêà‰Ω†Ôºü\n\n* **‰ΩøÁî® LangGraph** Â¶ÇÊûú‰Ω†Êõ¥ÂñúÊ¨¢Âü∫‰∫éÂõæÂΩ¢ÁöÑÂèØËßÜÂåñÂ∑•‰ΩúÊµÅÁ®ãÊù•ÊûÑÂª∫Â§çÊùÇÁöÑ LLM ‰ªªÂä°„ÄÇÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÊ∏ÖÊô∞ÂíåÁªìÊûÑÁöÑÁî®Êà∑„ÄÇ\n* **‰ΩøÁî® LangChain** Â¶ÇÊûú‰Ω†ÈúÄË¶Å‰∏Ä‰∏™Âº∫Â§ß„ÄÅÁÅµÊ¥ªÁöÑËß£ÂÜ≥ÊñπÊ°àÊù•‰ª•ÁºñÁ®ãÊñπÂºèÂàõÂª∫ËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®„ÄÇÂÆÉÂ§öÂäüËÉΩ‰∏îÈùûÂ∏∏ÈÄÇÂêàÊûÑÂª∫Áîü‰∫ßÁ∫ßÂ∫îÁî®ÁöÑÂºÄÂèëËÄÖ„ÄÇ\n* **‰ΩøÁî® LangFlow** Â¶ÇÊûú‰Ω†ÊÉ≥Ë¶Å LangChain ÁöÑÂº∫Â§ßÂäüËÉΩÔºåÂêåÊó∂ÂèàÂ∏åÊúõÊã•Êúâ‰∏Ä‰∏™ÂèØËßÜÂåñÁöÑÊó†‰ª£Á†Å/‰Ωé‰ª£Á†ÅÁïåÈù¢„ÄÇÊúÄÈÄÇÂêàÂø´ÈÄüÂéüÂûãÂºÄÂèëÂíåÊõ¥ÂñúÊ¨¢ÂèØËßÜÂåñÂ∑•ÂÖ∑ËÄåÈùûÁºñÁ†ÅÁöÑÁî®Êà∑„ÄÇ\n* **‰ΩøÁî® LangSmith** Â¶ÇÊûú‰Ω†ÁöÑÈáçÁÇπÊòØ LLM Â∫îÁî®ÁöÑÂèØËßÇÂØüÊÄßÂíåË∞ÉËØï„ÄÇÈùûÂ∏∏ÈÄÇÂêàÂú®ÂºÄÂèëÊàñÁîü‰∫ßÁéØÂ¢É‰∏≠ÁõëÊéßÂíå‰ºòÂåñÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\nÊúÄÁªàÔºå‰Ω†ÁöÑÈÄâÊã©ÂèñÂÜ≥‰∫é‰Ω†ÂØπ‰ª£Á†ÅÁöÑËàíÈÄÇÂ∫¶„ÄÅÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂ§çÊùÇÊÄßÔºå‰ª•Âèä‰Ω†ÊòØÂê¶‰ºòÂÖàËÄÉËôëÊòìÁî®ÊÄß„ÄÅÁÅµÊ¥ªÊÄßÊàñÂèØËßÇÂØüÊÄß„ÄÇ\n\n## ÁªìËÆ∫\n\nËøô‰∫õÂ∑•ÂÖ∑ ‚Äî **LangGraph**„ÄÅ**LangChain**„ÄÅ**LangFlow** Âíå **LangSmith** ‚Äî ÈíàÂØπÂºÄÂèëÂíåÁÆ°ÁêÜËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®ÁöÑ‰∏çÂêåÈò∂ÊÆµ„ÄÇ**LangGraph** Êèê‰æõ‰∫Ü‰∏ÄÁßçÂèØËßÜÂåñ„ÄÅÁõ¥ËßÇÁöÑÊñπÂºèÊù•ÊûÑÂª∫Â§çÊùÇÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåËÄå **LangChain** Âàô‰∏∫Â∏åÊúõÂàõÂª∫ÂèØÊâ©Â±ïÂ∫îÁî®ÁöÑÂºÄÂèëËÄÖÊèê‰æõ‰∫Ü‰∏ÄÁßçÂº∫Â§ßÁöÑ‰ª£Á†Å‰ºòÂÖàËß£ÂÜ≥ÊñπÊ°à„ÄÇÂØπ‰∫éÈÇ£‰∫õÊõ¥ÂñúÊ¨¢ **‰Ωé‰ª£Á†Å**„ÄÅÊãñÊîæÊñπÂºèÁöÑÁî®Êà∑Ôºå**LangFlow** Âú®‰∏çÁâ∫Áâ≤ÂäüËÉΩÁöÑÊÉÖÂÜµ‰∏ãÁÆÄÂåñ‰∫ÜÊµÅÁ®ã„ÄÇÊúÄÂêéÔºå**LangSmith** ‰∏ìÊ≥®‰∫éÂèØËßÇÂØüÊÄßÂíåË∞ÉËØïÔºåÁ°Æ‰øùÊÇ®ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÊòØ‰ºòÂåñÂíåÂèØÈù†ÁöÑ„ÄÇÈÄâÊã©ÂêàÈÄÇÁöÑÂ∑•ÂÖ∑ÂèñÂÜ≥‰∫éÊÇ®ÁöÑÈ°πÁõÆÈúÄÊ±ÇÔºåÊó†ËÆ∫ÊòØÂø´ÈÄüÂéüÂûãËÆæËÆ°„ÄÅÁîü‰∫ßÁ∫ßÊâ©Â±ïÔºåËøòÊòØÁõëÊéßÂíåÊÄßËÉΩË∑üË∏™„ÄÇ\n\nÂø´‰πêÁºñÁ†ÅÔºÅ üéâ\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è | üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) |üìù [Medium](https://medium.com/@monsuralirana)\n\nÊÑüË∞¢ÊÇ®Ëä±Êó∂Èó¥ÈòÖËØªËøôÁØáÊñáÁ´†ÔºÅ\n\nËØ∑Âä°ÂøÖÁïô‰∏ãÊÇ®ÁöÑÂèçÈ¶àÂíåËØÑËÆ∫„ÄÇ‰∏ãÊ¨°ÂçöÂÆ¢ËßÅÔºåÊï¨ËØ∑ÂÖ≥Ê≥® üì¢\n\n## ÂèÇËÄÉÊñáÁåÆÔºö\n\n1. ‚ÄúLangChain ÊñáÊ°£‚Äù ‚Äî <https://python.langchain.com/docs/introduction/>\n2. ‚ÄúLangGraph Ê¶ÇËø∞‚Äù ‚Äî <https://langchain-ai.github.io/langgraph/>\n3. ‚ÄúLangFlow GitHub ‰ªìÂ∫ì‚Äù ‚Äî [https://github.com/LangFlow/LangFlow](https://docs.langflow.org/)\n4. ‚ÄúLangSmith ‰ªãÁªç‚Äù ‚Äî <https://www.langchain.com/langsmith>\n5. ‚ÄúÂ¶Ç‰Ωï‰ΩøÁî® LangChain ÊûÑÂª∫ËÅäÂ§©Êú∫Âô®‰∫∫‚Äù by JetBrains ÂçöÂÆ¢ ‚Äî <https://blog.jetbrains.com/pycharm/2024/08/how-to-build-chatbots-with-langchain/>\n\n"},{"lang":"zh","group":"blog","slug":"blog/large-language-models-just-got-a-whole-lot-smaller-f93425ee59a2","frontmatter":{"title":"Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂèòÂæóÊõ¥Â∞è‰∫Ü","meta_title":"Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂèòÂæóÊõ¥Â∞è‰∫Ü","description":"ËøôÂèØËÉΩ‰ºöÊîπÂèòËΩØ‰ª∂ÂàùÂàõ‰ºÅ‰∏öÁöÑÊ∏∏ÊàèËßÑÂàô","date":"2024-11-04T12:29:02.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1PeFyz_Dlt6jEf27Q9Y33Q.png","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["compression","optimization","ternary","parallelism","hardware"],"draft":false,"slug":"blog/large-language-models-just-got-a-whole-lot-smaller-f93425ee59a2"},"content":"\n### ËøôÂ∞ÜÂ¶Ç‰ΩïÊîπÂèòËΩØ‰ª∂ÂàùÂàõ‰ºÅ‰∏öÁöÑÊ∏∏ÊàèËßÑÂàô\n\n\n\n**Êú¨Êñá‰∏é [David Meiborg](https://readmedium.com/undefined) ÂÖ±ÂêåÊí∞ÂÜô„ÄÇ**\n\n*TLDR: Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàÁÆÄÁß∞ LLMsÔºâÁõÆÂâç‰ΩìÁßØÂ∫ûÂ§ßÔºåËøêË°åÊàêÊú¨È´òÔºåÂπ∂‰∏îÂÖ∑Êúâ [ÊòæËëóÁöÑÁ¢≥Ë∂≥Ëøπ](https://arxiv.org/abs/2309.14393)„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÂú®Ê®°ÂûãÂéãÁº©ÂíåÁ≥ªÁªüÁ∫ß‰ºòÂåñÊñπÊ≥ï‰∏äÁöÑËøõÂ±ïÂèØËÉΩ‰ºöÂ¢ûÂº∫ LLM Êé®ÁêÜËÉΩÂäõ„ÄÇÁâπÂà´ÊòØ‰∏ÄÁßç‰ΩøÁî®‰∏âÂÖÉÁªìÊûÑÂèÇÊï∞ÁöÑÊñπÊ≥ïÔºåÊúâÊΩúÂäõÁªïËøáÂΩìÂâçÊ†áÂáÜÁöÑÊòÇË¥µÁü©Èòµ‰πòÊ≥ï„ÄÇËøôÂØπÂà∂ÈÄ†‰∏ìÁî®ËäØÁâáÁöÑÁ°¨‰ª∂ÂàùÂàõ‰ºÅ‰∏ö‰ª•Âèä‰ΩøÁî®ÊàñÂÆöÂà∂ÊûÑÂª∫Ëá™Â∑± LLM ÁöÑËΩØ‰ª∂ÂàùÂàõ‰ºÅ‰∏öÈÉΩÊúâ‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÂΩ±Âìç„ÄÇÂ∏ÆÂä©ÂÆ¢Êà∑ÈÉ®ÁΩ≤ LLM ÁöÑÂàùÂàõ‰ºÅ‰∏öÂèØËÉΩ‰πü‰ºöËøéÊù•Êõ¥Â§öÁöÑ‰∏öÂä°„ÄÇ*\n\nÂ¶Ç‰ªäÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈùûÂ∏∏Â∫ûÂ§ß„ÄÇÁúüÁöÑÂæàÂ§ß„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥Âä†ËΩΩ‰∏Ä‰∏™ LlaMa-2‚Äì70B Ê®°ÂûãÔºå‰Ω†ÈúÄË¶Å 140 GB ÁöÑÊòæÂ≠òÔºàËøôÂ∞±ÊòØ 70 ‰∫ø‰∏™ÂèÇÊï∞‰πò‰ª•ÊØè‰∏™ÂèÇÊï∞ 2 Â≠óËäÇÔºâ„ÄÇ‰Ωú‰∏∫ÂØπÊØîÔºåÂÉè NVIDIA RTX 3090 Êàñ 4090 ËøôÊ†∑ÁöÑ GPU Âè™Êúâ 24 GB ÁöÑÊòæÂ≠ò‚Äî‚ÄîËøôÂè™ÊòØÊâÄÈúÄÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜ„ÄÇ\n\nÊúâ‰∏Ä‰∫õÂÖ≥‰∫éÈáèÂåñÁöÑ [Ëß£ÂÜ≥ÊñπÊ≥ï](https://towardsdatascience.com/run-llama-2-70b-on-your-gpu-with-exllamav2-588141a88598)Ôºå‰ΩÜËøô‰∫õÂæÄÂæÄÊØîËæÉÁπÅÁêê„ÄÇ‰Ω†ÂèØËÉΩ‰ªçÁÑ∂ÈúÄË¶ÅËÆ©‰Ω†ÁöÑ GPU È´òÊ∏©ËøêË°åÈïøËææ 15 Â∞èÊó∂ÔºåÁõ¥Âà∞Ê®°ÂûãÂä†ËΩΩÂÆåÊàê„ÄÇÊõ¥‰∏çÁî®ËØ¥‰Ω†‰ªçÁÑ∂ÈúÄË¶Å‰∏Ä‰∫õÁ©∫‰ΩôÂÜÖÂ≠òÁî®‰∫éÊé®ÁêÜÔºåÊç¢Âè•ËØùËØ¥ÔºåÂ∞±ÊòØÁî®‰∫éÈÉ®ÁΩ≤Ê®°Âûã„ÄÇ\n\nÂõ†Ê≠§Ôºå‰ΩøÁî®ÂΩìÂâçÁöÑ LLMs ÊàêÊú¨È´òÊòÇÔºöÈÄöÂ∏∏ÈúÄË¶ÅÂ§ö‰∏™È´òÁ´Ø GPU Êù•‰øùÂ≠òÊ®°ÂûãÔºåÂπ∂‰∏îËøòÂøÖÈ°ªËÄÉËôëÊé®ÁêÜÊâÄ‰∫ßÁîüÁöÑËÉΩÊ∫êÊàêÊú¨„ÄÇ\n\nËøôÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÂæàÂ§öÁ†îÁ©∂ÈÉΩÂú®Ëá¥Âäõ‰∫éÂ∫îÁî®ÊäÄÊúØÔºå‰Ωø LLMs Êõ¥Â∞èÔºå‰ªéËÄåËÉΩÂ§üÂú®Êõ¥Â∞èÁöÑÁ°¨‰ª∂‰∏ä‰ª•Êõ¥‰ΩéÁöÑÊàêÊú¨ËøêË°å„ÄÇÂú®Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÔºåËøôÊòØ‰∏ÄÁßçËâ∞ÈöæÁöÑÊùÉË°°ÔºåÂõ†‰∏∫‰Ωø LLMs Êõ¥Â∞èÈÄöÂ∏∏‰ºöÂΩ±ÂìçÂÆÉ‰ª¨ÁöÑË¥®Èáè„ÄÇÊâæÂà∞ÊàêÊú¨‰∏éÊî∂ÁõäÁõ∏Á≠âÁöÑÁÇπÂèØËÉΩÊòØÊ£òÊâãÁöÑ„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Ê¶ÇËø∞‰∫Ü‰∏Ä‰∫õÊúâÂâçÊôØÁöÑ‰ºòÂåñÊñπÊ≥ïÔºåËß£Èáä‰∫ÜÂæÆËΩØÁ†îÁ©∂‰∫∫ÂëòÁöÑÊúÄÊñ∞Á™ÅÁ†¥ÔºåÁÆÄË¶ÅÊ¶ÇËø∞‰∫Ü‚ÄúÈ´òÊïà LLM‚ÄùÈ¢ÜÂüüÁöÑÂàõÊñ∞ÂàùÂàõ‰ºÅ‰∏öÔºåÂπ∂Êé®ÂØºÂá∫‰∏Ä‰∫õÂØπÂú® LLM ÁîüÊÄÅÁ≥ªÁªü‰∏≠ËøêËê•ÁöÑÂàùÂàõ‰ºÅ‰∏öÁöÑ‰∏ÄËà¨ÂΩ±Âìç„ÄÇ\n\n## LLMÂ¶Ç‰ΩïÂèòÂæóÊõ¥Âä†ËµÑÊ∫êÈ´òÊïà\n\nÂÉèÂæÆËΩØ„ÄÅOpenAI„ÄÅMetaÊàñË∞∑Ê≠åËøôÊ†∑ÁöÑÁßëÊäÄÂ∑®Â§¥Êã•ÊúâË∂≥Â§üÁöÑËµÑÊ∫êÊù•ËÆ≠ÁªÉÂ∞ñÁ´ØÊ®°ÂûãÔºåÂç≥‰ΩøÁõÆÂâçËÆ≠ÁªÉÊàêÊú¨ÂØπÂ§ßÂ§öÊï∞ÂÖ∂‰ªñÂÖ¨Âè∏Êù•ËØ¥ÊòØ‰∏çÂèØÊâøÂèóÁöÑ„ÄÇÂõ†Ê≠§ÔºåÂπøÊ≥õÈááÁî®ÁöÑÊúÄÂ§ßÁì∂È¢à‰∏çÊòØËÆ≠ÁªÉÔºåËÄåÊòØÊé®ÁêÜÊïàÁéá„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂ∞ΩÁÆ°MetaÂ∑≤ÁªèÂèëÂ∏É‰∫ÜLlaMaÔºå‰ΩÜÁî±‰∫éËøêË°åÊ®°Âûã‚Äî‚ÄîËÄå‰∏çÊòØÂàõÂª∫Ê®°Âûã‚Äî‚ÄîÂ∑≤ÁªèË∂≥Â§üÂÖ∑ÊúâÊåëÊàòÊÄßÔºåÂõ†Ê≠§ÂÆÉ‰ªçÊú™ÂæóÂà∞Ë∂≥Â§üÁöÑÈááÁî®„ÄÇ\n\nÁÑ∂ËÄåÔºåÁ†îÁ©∂‰∫∫ÂëòÂºÄÂßãÊèêÈ´òËøôÁßçÊé®ÁêÜÊïàÁéá„ÄÇÂπø‰πâËÄåË®ÄÔºåÊúâ‰∏§ÁßçÊñπÊ≥ïÂèØ‰ª•ÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºö**Á≥ªÁªüÁ∫ß‰ºòÂåñ**Âπ∂‰∏çÊîπÂèòÊ®°ÂûãÊú¨Ë∫´ÔºåËÄåÊòØÈÄöËøáÊîπÂèòÊ®°ÂûãÊâÄÂ§ÑÁéØÂ¢ÉÁöÑÂÖ≥ÈîÆÊñπÈù¢Êù•ÊèêÈ´òÂÖ∂ÊÄßËÉΩ„ÄÇ**Ê®°Âûã‰ºòÂåñ**ÂàôÂéãÁº©Ê®°ÂûãÔºå‰ΩøÂÖ∂Êõ¥Êòì‰∫éÈÉ®ÁΩ≤ÂíåËøêË°å„ÄÇ\n\nËøô‰∏§ÁßçÊñπÊ≥ïÈÉΩÊúâÂ§öÁßç‰∏çÂêåÁöÑÊäÄÊúØ„ÄÇ[‰∏ÄÁØáÊúÄËøëÁöÑËÆ∫Êñá](https://arxiv.org/pdf/2402.01799.pdf)Áî±Á†îÁ©∂‰∫∫ÂëòÂá∫Ëâ≤Âú∞ÊÄªÁªì‰∫ÜËøô‰∫õÊäÄÊúØ„ÄÇÁî±‰∫éËøô‰∫õÊäÄÊúØÂèØËÉΩÂæàÂø´Â∞±‰ºöÊàê‰∏∫‰ªª‰Ωï‰ªé‰∫ãLLMÁ≥ªÁªüÂ∑•‰ΩúËÄÖÁöÑÂü∫Êú¨Áü•ËØÜÔºåÊàë‰ª¨Âú®‰∏ãÈù¢ÂØπËøô‰∫õÊäÄÊúØËøõË°å‰∫ÜÂø´ÈÄüÊ¶ÇËø∞„ÄÇ\n\n### Á≥ªÁªüÁ∫ß‰ºòÂåñ\n\nÁ≥ªÁªüÁ∫ß‰ºòÂåñÊåáÁöÑÊòØÊîπÂèòÊ®°ÂûãÊú¨Ë∫´ÁöÑËøêË°åÊñπÂºèÔºåËÄå‰∏çÊòØÊ®°ÂûãÊú¨Ë∫´„ÄÇ‰∫ãÂÆûËØÅÊòéÔºåÊúâÂæàÂ§öÊâãÊÆµÂèØ‰ª•ÈÅøÂÖçËµÑÊ∫êÈó≤ÁΩÆÊàñÊ∂àÈô§ÂÖ∂‰ªñ‰ΩéÊïàÁé∞Ë±°„ÄÇ\n\n**ÂàÜÈ°µÊ≥®ÊÑèÂäõ**\n\nÂÉè GPT ËøôÊ†∑ÁöÑ LLM ÁöÑÊ†∏ÂøÉÊòØÊ≥®ÊÑèÂäõÊú∫Âà∂„ÄÇËøô‰∏™Êú∫Âà∂ÂÖÅËÆ∏Ê®°ÂûãÂú®ÁîüÊàêÊØè‰∏™ËæìÂá∫ÂçïËØçÊó∂ÂÖ≥Ê≥®ËæìÂÖ•ÊñáÊú¨ÁöÑ‰∏çÂêåÈÉ®ÂàÜ„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊÇ®Ê≠£Âú®ÈòÖËØª‰∏ÄÊú¨‰π¶ÔºåÂπ∂Ê†áËÆ∞ÈáçË¶ÅÁöÑÂè•Â≠ê‰ª•Êõ¥Â•ΩÂú∞ËÆ∞‰ΩèÊïÖ‰∫ã„ÄÇÁ±ª‰ººÂú∞ÔºåÊ≥®ÊÑèÂäõÊú∫Âà∂Âú®ÂÅöÂá∫È¢ÑÊµãÊó∂‚ÄúÁ™ÅÂá∫‚ÄùÊàñËµã‰∫àÊüê‰∫õÂçïËØçÊàñÁü≠ËØ≠Êõ¥Â§öÈáçË¶ÅÊÄß„ÄÇ\n\nËøô‰∏™Êú∫Âà∂ÈùûÂ∏∏ËÄóË¥πËµÑÊ∫ê„ÄÇÂÆÉË¶ÅÊ±ÇÊ®°ÂûãËÄÉËôëËæìÂÖ•ÊñáÊú¨‰∏≠ÊâÄÊúâÂçïËØçÂØπ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂØπ‰∫éÈïøÊñáÊú¨ÔºåËøôÂèØËÉΩÈúÄË¶ÅÂ§ßÈáèÁöÑÂÜÖÂ≠òÂíåËÆ°ÁÆóËÉΩÂäõ„ÄÇ\n\nÂàÜÈ°µÊ≥®ÊÑèÂäõ‰∏çÊòØ‰∏ÄÊ¨°Â§ÑÁêÜÊï¥‰∏™ÊñáÊú¨ÔºåËÄåÊòØÂ∞ÜÊñáÊú¨ÂàÜÊàêÊõ¥Â∞èÁöÑ‚ÄúÈ°µ‚ÄùÊàñÊÆµËêΩ„ÄÇÊ®°ÂûãÁÑ∂Âêé‰∏ÄÊ¨°Â§ÑÁêÜËøô‰∫õÈ°µÈù¢Êàñ‰ª•ËæÉÂ∞èÁöÑÁªÑÂ§ÑÁêÜ„ÄÇËøôÁßçÊñπÊ≥ïÊòæËëóÂáèÂ∞ë‰∫Ü‰ªª‰ΩïÁªôÂÆöÊó∂ÂàªÊâÄÈúÄÁöÑÂÜÖÂ≠òÈáèÔºåÂõ†‰∏∫Ê®°Âûã‰∏çÈúÄË¶ÅÂêåÊó∂Ë∑üË∏™Êï¥‰∏™ÊñáÊú¨ÁöÑÂÖ≥Á≥ª„ÄÇ\n\nËøôÊúâÁÇπÂÉè‰∏Ä‰∏™Â≠¶ÁîüÔºåÂ¶ÇÊûú‰∏ÄÊ¨°ÊÄßÈòÖËØªÊï¥Êï¥‰∏ÄÂπ¥ÁöÑÊïôÁßë‰π¶‰ºöÊÑüÂà∞‰∏çÁü•ÊâÄÊé™„ÄÇÈÄöËøáÂú®Êï¥‰∏™Â≠¶Âπ¥‰∏≠Â∞ÜÂÖ∂ÂàÜËß£‰∏∫ÂèØÁÆ°ÁêÜÁöÑÊÆµËêΩÔºåÂ≠¶ÁîüÂèØ‰ª•ËÆ∞‰ΩèÊïôÁßë‰π¶ÁöÑÂÜÖÂÆπ„ÄÇ\n\nÈÄöËøáÊØè‰∏ÄÊ≠•ÊâÄÈúÄÁöÑÂÜÖÂ≠òÂáèÂ∞ëÔºåÂàÜÈ°µÊ≥®ÊÑèÂäõÂÖÅËÆ∏Âú®Áõ∏ÂêåÁöÑÁ°¨‰ª∂Á∫¶Êùü‰∏ã‰ΩøÁî®Êõ¥Â§ßÁöÑÊ®°ÂûãÊàñÊõ¥ÈïøÁöÑÊñáÊú¨„ÄÇ\n\n**Âº†ÈáèÂπ∂Ë°å**\n\nÂπ∂Ë°åÊòØ‰∏ÄÁßçËÆ°ÁÆó‰∏≠ÁöÑ‰ºóÊâÄÂë®Áü•ÁöÑÊ¶ÇÂøµ„ÄÇÂÆÉÊÑèÂë≥ÁùÄÂ∞Ü‰∏Ä‰∏™Â§ßÂûãËÆ°ÁÆó‰ªªÂä°ÂàÜÊàêÂèØ‰ª•Áî±Â§ö‰∏™Â§ÑÁêÜÂô®ÊàñËÆ°ÁÆóÊú∫ÂêåÊó∂Â§ÑÁêÜÁöÑÂ∞èÈÉ®ÂàÜ„ÄÇËøôÊòæËëóÂä†Âø´‰∫ÜÁ®ãÂ∫èËøêË°åÊâÄÈúÄÁöÑÊó∂Èó¥„ÄÇ\n\nÂú® LLM ÁöÑ‰∏ä‰∏ãÊñá‰∏≠Ôºå[Âº†Èáè](https://towardsdatascience.com/what-is-a-tensor-in-deep-learning-6dedd95d6507) ÊòØÂ§öÁª¥Êï∞Â≠óÊï∞ÁªÑ„ÄÇËøô‰∫õÂº†ÈáèÁî®‰∫éË°®Á§∫Ê®°ÂûãÂ§ÑÁêÜÁöÑÊï∞ÊçÆ„ÄÇËøôÁ±ªÊï∞ÊçÆÂåÖÊã¨ËæìÂÖ•ÊñáÊú¨„ÄÅÊ®°ÂûãÊùÉÈáçÔºåÂç≥Ê®°ÂûãÂ≠¶‰π†ÁöÑÂèÇÊï∞Ôºå‰ª•ÂèäËæìÂá∫È¢ÑÊµã„ÄÇ\n\nÂ∞ÜËøô‰∏§‰∏™Ê¶ÇÂøµÁªìÂêàËµ∑Êù•ÔºåÂº†ÈáèÂπ∂Ë°åÊ∂âÂèäÂ∞ÜËøô‰∫õÂº†ÈáèÂàÜÂâ≤Âà∞Â§ö‰∏™ GPU ÊàñÂÖ∂‰ªñÂ§ÑÁêÜÂçïÂÖÉ‰∏ä„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊ®°ÂûãÁöÑÂèÇÊï∞ÔºàÊùÉÈáçÔºâÂ§™Â§ßËÄåÊó†Ê≥ïÈÄÇÂ∫îÂçï‰∏™ GPU ÁöÑÂÜÖÂ≠òÔºåÂàôÂèØ‰ª•Â∞ÜÂÖ∂ÂàÜÂ∏ÉÂà∞Â§ö‰∏™ GPU ‰∏ä„ÄÇÊØè‰∏™ GPU ÁÑ∂Âêé‰∏ÄÊ¨°Âè™Â§ÑÁêÜÂº†ÈáèÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ\n\nÂ∞±ÂÉè‰∏Ä‰∏™Âõ¢Èòü‰∏≠ÁöÑÂ§ö‰∏™ÊàêÂëò‰∏ÄËµ∑Â∑•‰ΩúÂú®‰∏Ä‰∏™Â§ßÂûãÈ°πÁõÆ‰∏äÔºåÂ§ÑÁêÜÂçïÂÖÉÂú®Â§ÑÁêÜÂêÑËá™ÈÉ®ÂàÜÁöÑÂº†ÈáèÊó∂ÈúÄË¶Å‰∫§Êç¢‰ø°ÊÅØ„ÄÇ‰æãÂ¶ÇÔºå‰∏Ä‰∏™ GPU ‰∏äÁöÑËÆ°ÁÆóÁªìÊûúÂèØËÉΩÈúÄË¶Å‰∏éÂè¶‰∏Ä‰∏™ GPU ÂÖ±‰∫´Ôºå‰ª•ÁªßÁª≠‰∏ã‰∏ÄÊ≠•ËÆ°ÁÆó„ÄÇÂõ†Ê≠§ÔºåÂçïÂÖÉ‰πãÈó¥ÁöÑÈ´òÊïàÈÄö‰ø°ÂØπ‰∫éÂº†ÈáèÂπ∂Ë°åÁöÑÊúâÊïàÊÄßËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nÁÆÄËÄåË®Ä‰πãÔºåÂº†ÈáèÂπ∂Ë°åÊòØ‰∏ÄÁßçÂ∞Ü LLM ÊâÄÈúÄÁöÑËÆ°ÁÆóÂàÜËß£‰∏∫Êõ¥Â∞èÁöÑÂπ∂Ë°å‰ªªÂä°ÁöÑÊñπÊ≥ïÔºåËøô‰∫õ‰ªªÂä°ÂèØ‰ª•Áî±Â§ö‰∏™ËÆ°ÁÆóÂçïÂÖÉÂêåÊó∂Â§ÑÁêÜÔºå‰ªéËÄåÂä†Âø´Ëøô‰∫õÂ§ßÂûãÂ§çÊùÇÊ®°ÂûãÁöÑËÆ≠ÁªÉÂíåÊé®ÁêÜÊó∂Èó¥„ÄÇ\n\n**ÊµÅÊ∞¥Á∫øÂπ∂Ë°å**\n\nËøôÁßçÊäÄÊúØ‰∏ìÊ≥®‰∫éÊîπÂñÑÊï∞ÊçÆÈÄöËøáÊ®°ÂûãÂ±ÇÁöÑÂ§ÑÁêÜÂ∑•‰ΩúÊµÅ„ÄÇËøôÂèØ‰ª•ÊòæËëóÂä†Âø´Êï¥‰ΩìËÆ°ÁÆóÈÄüÂ∫¶ÔºåÂπ∂Êõ¥Â•ΩÂú∞Âà©Áî®ÂèØÁî®Á°¨‰ª∂„ÄÇ\n\nËÆ°ÁÆó‰∏≠ÁöÑÊµÅÊ∞¥Á∫øÂ∑•‰ΩúÊñπÂºèÁ±ª‰ºº‰∫éÂ∑•ÂéÇÁöÑË£ÖÈÖçÁ∫øÔºå‰∏çÂêå‰ªªÂä°ÁöÑÈò∂ÊÆµÊåâÈ°∫Â∫èÂÆåÊàê„ÄÇËøôÂÖÅËÆ∏Â§ö‰∏™‰ªªÂä°Âú®‰∏çÂêåÈò∂ÊÆµÂêåÊó∂ËøõË°å„ÄÇ\n\nÂú® LLM ‰∏≠ÔºåËøô‰∫õ‰∏çÂêåÁöÑÈò∂ÊÆµÁî±Á•ûÁªèÁΩëÁªúÁöÑÂ±ÇË°®Á§∫„ÄÇÊØè‰∏ÄÂ±ÇÊåâÈ°∫Â∫èÂ§ÑÁêÜËæìÂÖ•Êï∞ÊçÆÔºåÈÄêÊ∏êÊèêÂèñÊõ¥Â§çÊùÇÁöÑÁâπÂæÅÊàñÊ®°ÂºèÔºåÁõ¥Âà∞‰∫ßÁîüÊúÄÁªàËæìÂá∫„ÄÇÂèØ‰ª•Â∞ÜÊØè‰∏ÄÂ±ÇËßÜ‰∏∫Â∑•ÂéÇË£ÖÈÖçÁ∫ø‰∏äÁöÑ‰∏Ä‰∏™Â∑•‰∫∫ÔºöÊØè‰∏™Â∑•‰∫∫Âú®Êï∞ÊçÆÈÄöËøáÊó∂ÈÉΩ‰ºöÂú®ÂÖ∂‰∏äÊ∑ªÂä†‰∏Ä‰∫õ‰∏úË•øÔºåÁõ¥Âà∞ÊúÄÁªàÂá∫Áé∞‰∏Ä‰∏™Â§çÊùÇÁöÑ‰∫ßÂìÅ„ÄÇ\n\nÂú®ÊµÅÊ∞¥Á∫øÂπ∂Ë°å‰∏≠ÔºåÊ®°ÂûãÁöÑÂ±ÇË¢´ÂàÜ‰∏∫Â§ö‰∏™ÊÆµÔºåÊØè‰∏™ÊÆµÂàÜÈÖçÁªô‰∏çÂêåÁöÑ GPU ÊàñÂ§ÑÁêÜÂçïÂÖÉ„ÄÇËøôÊ†∑ÔºåÊ®°ÂûãÂèØ‰ª•ÊåâÊâπÊ¨°ËæìÂÖ•Êï∞ÊçÆÔºö‰∏ÄÊó¶Á¨¨‰∏Ä‰∏™ÊÆµÂ§ÑÁêÜÂÆåÁ¨¨‰∏ÄÊâπÊï∞ÊçÆÔºåÁ¨¨‰∫å‰∏™ÊÆµÂ∞±Êé•ÊâãÈÇ£ÊâπÊï∞ÊçÆÔºåËÄåÁ¨¨‰∏Ä‰∏™ÊÆµÂàôÊé•Êâã‰∏ÄÊâπÊñ∞ÁöÑÊï∞ÊçÆ„ÄÇ\n\nËøôÂú®Ê®°Âûã‰∏≠ÂàõÂª∫‰∫ÜÊï∞ÊçÆÁöÑËøûÁª≠ÊµÅÂä®ÔºåÊØè‰∏™Ê®°ÂûãÊÆµÂú®‰ªª‰ΩïÁªôÂÆöÊó∂Èó¥ÈÉΩÂú®Â§ÑÁêÜ‰∏çÂêåÁöÑÊï∞ÊçÆ„ÄÇËøôÈÄöËøá‰øùÊåÅÊ®°ÂûãÁöÑÊâÄÊúâÈÉ®ÂàÜÂ§Ñ‰∫éÊ¥ªÂä®Áä∂ÊÄÅÊù•ÊúÄÂ§ßÂåñÂèØÁî®Á°¨‰ª∂ËµÑÊ∫êÁöÑ‰ΩøÁî®ÔºåÂπ∂ÂáèÂ∞ëÂçï‰∏™Â§ÑÁêÜÂô®Á≠âÂæÖ‰ªªÂä°ÂÆåÊàêÊó∂ÂèØËÉΩÂèëÁîüÁöÑÁ©∫Èó≤Êó∂Èó¥„ÄÇ\n\nÂâçÈù¢ËÆ®ËÆ∫ÁöÑÊµÅÊ∞¥Á∫øÂπ∂Ë°åÂú®Ê®°ÂûãÂ±ÇÁ∫ßÂà´‰∏äÊìç‰ΩúÔºåÂ∞ÜÈ°∫Â∫èÂ§ÑÁêÜÈò∂ÊÆµÂàÜÂ∏ÉÂà∞ËÆæÂ§á‰∏ä„ÄÇËÄåÂº†ÈáèÂπ∂Ë°åÂàôÂú®Êõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÂ±ÇÈù¢‰∏äÊìç‰ΩúÔºåÂ∞ÜÂ±ÇÂÜÖÂèëÁîüÁöÑÂÆûÈôÖËÆ°ÁÆóÔºà‰æãÂ¶ÇÔºåÂ§ßÂûãÁü©Èòµ‰πòÊ≥ïÁöÑÈÉ®ÂàÜÔºâÂàÜÂ∏ÉÂà∞ËÆæÂ§á‰∏ä„ÄÇ\n\n**CPU/GPU Âç∏ËΩΩ**\n\nÂú®ËøôÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂæàÂ§öÂÖ≥‰∫é GPU ÁöÑÂÜÖÂÆπ„ÄÇÁÑ∂ËÄåÔºåÂπ∂‰∏çÊòØÊâÄÊúâÂú®ËÆ≠ÁªÉÊàñËøêË°å LLM ‰∏≠ÁöÑ‰ªªÂä°ÈÉΩÂêåÊ†∑ÈÄÇÂêà GPU„ÄÇ‰∏Ä‰∫õ‰ªªÂä°ÔºåÂ¶ÇÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊàñÊüê‰∫õÊéßÂà∂ÈÄªËæëÔºåÂèØËÉΩÊõ¥ÊúâÊïàÂú∞Áî± CPU Â§ÑÁêÜ„ÄÇÂÖ∂‰ªñ‰ªªÂä°ÔºåÁâπÂà´ÊòØÂ§ÑÁêÜÁ•ûÁªèÁΩëÁªúÔºàÂ¶ÇÁü©Èòµ‰πòÊ≥ïÔºâÊâÄÊ∂âÂèäÁöÑÈáçÊï∞Â≠¶ËÆ°ÁÆóÔºåÁ°ÆÂÆûÊõ¥ÊúâÊïàÂú∞Âú® GPU ‰∏äÊâßË°å„ÄÇ\n\nÈÄöËøáÂ∞ÜÁâπÂÆö‰ªªÂä°Âç∏ËΩΩÂà∞ÊúÄÈÄÇÂêàÂÆÉ‰ª¨ÁöÑÂ§ÑÁêÜÂô®‰∏ä‚Äî‚ÄîÂ∞ÜÂπ∂Ë°åÂåñ„ÄÅËÆ°ÁÆóÂØÜÈõÜÂûã‰ªªÂä°ÂàÜÈÖçÁªô GPUÔºåËÄåÂ∞ÜÈ°∫Â∫èÊàñÈÄªËæëÂØÜÈõÜÂûã‰ªªÂä°ÂàÜÈÖçÁªô CPU‚Äî‚ÄîÁ≥ªÁªüÂèØ‰ª•Á°Æ‰øùÊØè‰∏™Â∑•‰ΩúË¥üËΩΩÈÉ®ÂàÜ‰ª•ÊúÄÊúâÊïàÁöÑÊñπÂºèËøõË°åÂ§ÑÁêÜ„ÄÇ\n\n**ËûçÂêàÊìç‰Ωú**\n\nËûçÂêàÊìç‰ΩúÂ∞ÜÈÄöÂ∏∏ÂçïÁã¨ÊâßË°åÁöÑÂ§ö‰∏™Â§ÑÁêÜÊ≠•È™§ÂêàÂπ∂‰∏∫‰∏Ä‰∏™ÁÆÄÂåñÁöÑÊìç‰Ωú„ÄÇ‰æãÂ¶ÇÔºåËÄå‰∏çÊòØÂÖàÊâßË°åÁü©Èòµ‰πòÊ≥ïÂÜçËøõË°åÂä†Ê≥ïÔºåËûçÂêàÊìç‰Ωú‰ºöÂêåÊó∂ÊâßË°å‰∏§ËÄÖ„ÄÇ\n\n**Êé®ÊµãËß£Á†Å**\n\nÂú®ÁîüÊàêÊñáÊú¨Êó∂ÔºåLLM Ê†πÊçÆ‰πãÂâçÁöÑÂçïËØçËÆ°ÁÆóÂè•Â≠ê‰∏≠‰∏ã‰∏Ä‰∏™ÂçïËØçÁöÑÊ¶ÇÁéá„ÄÇ‰º†Áªü‰∏äÔºåÂú®ÁîüÊàêÊØè‰∏™ÂçïËØçÂêéÔºåÊ®°Âûã‰ºöÈáçÊñ∞ËÆ°ÁÆó‰ª•Á°ÆÂÆö‰∏ã‰∏Ä‰∏™ÂçïËØçÔºåÂπ∂‰∏îËøô‰∏™ËøáÁ®ã‰ºöÈáçÂ§çÔºåÁõ¥Âà∞ÂÆåÊï¥ÁöÑÂè•Â≠êÊàñÊÆµËêΩÂÆåÊàê„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÈ°∫Â∫èËøáÁ®ãÂèØËÉΩÂæàÊÖ¢ÔºåÂ∞§ÂÖ∂ÊòØÂØπ‰∫éËæÉÈïøÁöÑÊñáÊú¨ÊàñÊõ¥Â§çÊùÇÁöÑÊ®°ÂûãÔºåÂõ†‰∏∫ÊØè‰∏ÄÊ≠•ÈÉΩ‰æùËµñ‰∫éÂâç‰∏ÄÊ≠•ÁöÑÂÆåÊàê„ÄÇ\n\nÂπ∂Ë°åÈ¢ÑÊµãÔºö‰∏éÂÖ∂Á≠âÂæÖÊØè‰∏™ÂçïËØçË¢´ÈÄâÊã©ÂêéÂÜçËÄÉËôë‰∏ã‰∏Ä‰∏™ÔºåÊé®ÊµãËß£Á†ÅÂÖÅËÆ∏Ê®°Âûã‚ÄúÊé®Êµã‚ÄùÊàñÂêåÊó∂ÂØπÊé•‰∏ãÊù•ÁöÑÂá†‰∏™ÂçïËØçÂÅöÂá∫Â§ö‰∏™È¢ÑÊµã„ÄÇËøôË¢´Áß∞‰∏∫ *Âπ∂Ë°åÈ¢ÑÊµã*„ÄÇËøôÂ∞±ÂÉèÂØπÂè•Â≠êÊé•‰∏ãÊù•ÂèØËÉΩÈááÂèñÁöÑÂá†Êù°Ë∑ØÂæÑËøõË°åÊúâÊ†πÊçÆÁöÑÁåúÊµã„ÄÇ\n\nÈÄöËøáÂπ∂Ë°åÊé¢Á¥¢Ëøô‰∫õÂèØËÉΩÊÄßÔºåÊ®°ÂûãÂèØ‰ª•ÊΩúÂú®Âú∞ÂáèÂ∞ëÁîüÊàêÊñáÊú¨ÊâÄÈúÄÁöÑÊï¥‰ΩìÊó∂Èó¥„ÄÇ‰∏ÄÊó¶ÂÆûÈôÖÁöÑ‰∏ã‰∏Ä‰∏™ÂçïËØçË¢´ÈÄâÂÆöÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Âø´Âú∞Ê≤øÁùÄÊúÄÂèØËÉΩÁöÑË∑ØÂæÑÁªßÁª≠ÔºåÂõ†‰∏∫ÂÆÉÂ∑≤ÁªèËÆ°ÁÆó‰∫ÜÂêéÁª≠ÁöÑÈÄâÈ°π„ÄÇ\n\n### LLMÊ®°ÂûãÁöÑÂéãÁº©\n\nÁ†îÁ©∂‰∫∫ÂëòËøáÂéªÊé¢Á¥¢ËøáÊ®°ÂûãÂéãÁº©„ÄÇÁÑ∂ËÄåÔºåÈöèÁùÄÂ§ßËßÑÊ®°LLMÁöÑÂá∫Áé∞ÔºåËøôÂ∑≤Êàê‰∏∫‰∏Ä‰∏™Êõ¥Â§ßÁöÑÊåëÊàò„ÄÇ\n\nËÆ∏Â§öÁé∞ÊúâÁöÑÂéãÁº©ÊñπÊ≥ï‰æùËµñ‰∫éÊâßË°åÂæÆË∞ÉÊ≠•È™§‰ª•Âú®ÂéãÁº©Èò∂ÊÆµÊÅ¢Â§ç‰∏¢Â§±ÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂΩìÂ∫îÁî®‰∫éLLMÊó∂ÔºåÁî±‰∫éÂÖ∂Â∫ûÂ§ßÁöÑËßÑÊ®°ÔºåËøôÁßçÊñπÊ≥ïÊúâÊòæËëóÁöÑÂ±ÄÈôêÊÄß„ÄÇÂõ†Ê≠§ÔºåLLMÂéãÁº©Â∑≤Êàê‰∏∫‰∏Ä‰∏™ÂÖ®Êñ∞ÁöÑÁ†îÁ©∂È¢ÜÂüü„ÄÇ\n\n**Êû∂ÊûÑÂâ™Êûù**\n\nÂΩì‰Ω†‰øÆÂâ™ËãπÊûúÊ†ëÊó∂Ôºå‰Ω†‰ºöÂú®ÂÜ¨Â≠£ÊàñÊó©Êò•Ââ™ÊéâÊüê‰∫õÊ†ëÊûù„ÄÇËøôÁ°Æ‰øùÊ†ëÊú®‰∏ç‰ºöÂú®Êó†ÊïàÁöÑÊ†ëÊûù‰∏äÊµ™Ë¥πËµÑÊ∫êÊàñÂõ†ÊûØÊú®ËÄåÊÑüÊüìÁñæÁóÖ„ÄÇËøôÊúâÂä©‰∫éÂÆÉÁªìÂá∫Êõ¥Â•ΩÁöÑÊûúÂÆû„ÄÇ\n\nÂΩìÁÑ∂ÔºåLLMÂπ∂‰∏çÁªìÂá∫ÊûúÂÆû„ÄÇÂú®Ëøô‰∏™ËÉåÊôØ‰∏ãÔºåÂâ™ÊûùÊòØ‰∏ÄÁßçÁî®‰∫éÂáèÂ∞ëÊ®°ÂûãÂ§ßÂ∞èÁöÑÊñπÊ≥ïÔºåÂêåÊó∂Â∞ΩÈáè‰øùÊåÅÊàñÊúÄÂ∞èÂåñÂØπÂÖ∂ÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇ\n\nLLMÊ®°ÂûãÊúâÊï∞Áôæ‰∏áÁîöËá≥Êï∞ÂçÅ‰∫ø‰∏™ÂèÇÊï∞„ÄÇËøô‰∫õÂèÇÊï∞Âπ∂‰∏çÊòØÊâÄÊúâÂØπÊ®°ÂûãËøõË°åÈ¢ÑÊµãÊàñÁêÜËß£ËØ≠Ë®ÄÈÉΩÂêåÁ≠âÈáçË¶Å„ÄÇÊúâ‰∫õÂèÇÊï∞ÂæàÂ∞ë‰ΩøÁî®ÊàñÂØπÊ®°ÂûãÁöÑÂÜ≥Á≠ñË¥°ÁåÆ‰∏çÂ§ßÔºöÂõ†Ê≠§ÔºåÊ∂àÈô§Ëøô‰∫õÂÜó‰ΩôÊàñÂΩ±ÂìçËæÉÂ∞èÁöÑËøûÊé•„ÄÅÁ•ûÁªèÂÖÉÊàñÊï¥‰∏™Â±ÇÔºå‰ΩøÊ®°ÂûãÁöÑ‰ΩøÁî®Êõ¥È´òÊïà„ÄÇ\n\nÈÄâÊã©Ââ™ÊûùÂì™‰∫õÂèÇÊï∞Âπ∂‰∏çÊòØ‰∏ÄÈ°πÁÆÄÂçïÁöÑ‰ªªÂä°„ÄÇÂú®Âü∫‰∫éÂπÖÂ∫¶ÁöÑÂâ™Êûù‰∏≠ÔºåÁßªÈô§Á•ûÁªèÁΩëÁªú‰∏≠ÁªùÂØπÂÄºÊúÄÂ∞èÁöÑÊùÉÈáç„ÄÇÂú®ËÆ≠ÁªÉ‰πãÂâçÔºåËøô‰∫õÊùÉÈáçÈÄöÂ∏∏‰∏∫Èõ∂ÔºõËÆ≠ÁªÉ‰πãÂêéÔºåÂÆÉ‰ª¨ÈÄöÂ∏∏‰ªã‰∫é-1Âíå1‰πãÈó¥„ÄÇÂ¶ÇÊûúËÆ≠ÁªÉÂØπÊüê‰∏™ÊùÉÈáçÁöÑÂΩ±Âìç‰∏çÂ§ßÔºåÈÇ£‰πàÂÆÉÂæàÂèØËÉΩÊé•ËøëÈõ∂ÔºåÂõ†Ê≠§ÂØπÊ®°ÂûãÁöÑÂÜ≥Á≠ñË¥°ÁåÆËæÉÂ∞ë„ÄÇ\n\n‰∏ÄÁßçËµÑÊ∫êÂØÜÈõÜ‰ΩÜ‰πüÊõ¥Á®≥ÂÅ•ÁöÑÂâ™ÊûùÊäÄÊúØÊòØÁÅµÊïèÂ∫¶ÂàÜÊûê„ÄÇËøôÊ∂âÂèäËØÑ‰º∞ÁßªÈô§ÊØè‰∏™ÂèÇÊï∞ÊàñÂèÇÊï∞ÁªÑÂØπÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇÁßªÈô§ÂêéÂØºËá¥ÊÄßËÉΩ‰∏ãÈôçÊúÄÂ∞èÁöÑÂèÇÊï∞‰ºöË¢´Ââ™Êûù„ÄÇ\n\nËøòÊúâÂÖ∂‰ªñÊäÄÊúØÔºå‰ΩÜÈÄöÂ∏∏ÂèØ‰ª•Â∞ÜÂÆÉ‰ª¨ÂàÜÁ±ª‰∏∫ÈùûÁªìÊûÑÂåñÂâ™ÊûùÊàñÁªìÊûÑÂåñÂâ™Êûù„ÄÇÈùûÁªìÊûÑÂåñÂâ™ÊûùÔºà‰æãÂ¶ÇÂü∫‰∫éÂπÖÂ∫¶ÁöÑÂâ™ÊûùÔºâÁßªÈô§Âçï‰∏™ÊùÉÈáçÔºåÂØºËá¥Á®ÄÁñèËøûÊé•ÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇÁªìÊûÑÂåñÂâ™ÊûùÔºà‰æãÂ¶ÇÁÅµÊïèÂ∫¶ÂàÜÊûêÔºâÁßªÈô§Êï¥‰∏™ÂçïÂÖÉÊàñÂ±ÇÔºà‰æãÂ¶ÇÔºåÊï¥‰∏™Á•ûÁªèÂÖÉÊàñÈÄöÈÅìÔºâÔºåËøôÂú®Êüê‰∫õÁ°¨‰ª∂‰∏äÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞ÊèêÈ´òËÆ°ÁÆóÊïàÁéá„ÄÇ\n\nÂâ™ÊûùÂêéÔºåÊ®°ÂûãÈÄöÂ∏∏‰ºöÁªèÂéÜÂæÆË∞ÉËøáÁ®ã„ÄÇËøôÊ∂âÂèäÂú®ËÆ≠ÁªÉÊï∞ÊçÆÈõÜÊàñÂÖ∂Â≠êÈõÜ‰∏äÂØπÂâ™ÊûùÂêéÁöÑÊ®°ÂûãËøõË°åÂÜçËÆ≠ÁªÉ„ÄÇÁõÆÊ†áÊòØËÆ©Ê®°ÂûãË∞ÉÊï¥Âíå‰ºòÂåñÂÖ∂Ââ©‰ΩôÂèÇÊï∞Ôºå‰ª•Ë°•ÂÅøÂâ™ÊûùÊâÄÈÄ†ÊàêÁöÑÊçüÂ§±„ÄÇËøôÊúâÂä©‰∫éÊÅ¢Â§çÂõ†Ââ™ÊûùËÄåÂ§±ÂéªÁöÑ‰ªª‰ΩïÊÄßËÉΩ„ÄÇ\n\nËøôÂèØ‰ª•ÈÄöËøáËø≠‰ª£ÊñπÂºèÊàñ‰∏ÄÊ¨°ÊÄßÊñπÂºèËøõË°å„ÄÇÂú®Ëø≠‰ª£Ââ™Êûù‰∏≠ÔºåÊ®°ÂûãÂú®Â§ö‰∏™ËΩÆÊ¨°‰∏≠ÈÄêÊ≠•Ââ™Êûù„ÄÇÂú®ÊØè‰∏ÄËΩÆ‰πãÂêéÔºåÂâ™ÊûùÂêéÁöÑÊ®°Âûã‰ºöÈáçÊñ∞ËÆ≠ÁªÉÔºå‰ª•ÊÅ¢Â§çÂõ†Ââ™ÊûùËÄåÂ§±ÂéªÁöÑÊÄßËÉΩ„ÄÇËøô‰∏™Âæ™ÁéØÂèØ‰ª•ÈáçÂ§çÂ§öÊ¨°ÔºåÊ®°ÂûãÂèØËÉΩ‰ºöÂèòÂæóÊõ¥Âä†Á®≥ÂÅ•ÔºåÂç≥‰ΩøÂú®ÊòæËëóÂáèÂ∞ëÂèÇÊï∞ÁöÑÊÉÖÂÜµ‰∏ã‰πüËÉΩ‰øùÊåÅÊÄßËÉΩ„ÄÇÂú®‰∏ÄÊ¨°ÊÄßÂâ™Êûù‰∏≠ÔºåÊâÄÊúâËØÜÂà´Âá∫ÁöÑÂèÇÊï∞‰∏ÄÊ¨°ÊÄßÁßªÈô§ÔºåÁÑ∂ÂêéÂØπÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ\n\n**Áü•ËØÜËí∏È¶è**\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊúâ‰∏Ä‰∏™Ë∂≥ÁêÉÂú∫‰∏äÊúâ‰∏§‰∏™ÁêÉÂëòÔºö‰∏Ä‰∏™ÈùûÂ∏∏ÊúâÁªèÈ™åÔºåÁü•ÈÅìÂæàÂ§öÊäÄÂ∑ßÔºåÂè¶‰∏Ä‰∏™ÊòØÂàùÂ≠¶ËÄÖ„ÄÇÁªèÈ™å‰∏∞ÂØåÁöÑÁêÉÂëòÁü•ÈÅìÁöÑÊØîÂàùÂ≠¶ËÄÖÂ§öÂæóÂ§öÔºå‰ΩÜÂàùÂ≠¶ËÄÖÂèØ‰ª•ÈÄöËøáÊ®°‰ªøÂÖ∂‰ªñÁêÉÂëòÂú®Âú∫‰∏äÁöÑË°å‰∏∫ËøÖÈÄüËææÂà∞ÂèØÊØîÁöÑË°®Áé∞„ÄÇ\n\nLLMÁöÑÁü•ËØÜËí∏È¶èÂ∑•‰ΩúÂéüÁêÜÁ±ª‰ººÔºöËøôÊòØËÆ≠ÁªÉ‰∏Ä‰∏™Êõ¥Â∞èÔºàÂ≠¶ÁîüÊ®°ÂûãÔºâ„ÄÅÊõ¥È´òÊïàÁöÑÊ®°ÂûãÔºå‰ª•ÈÄöËøáÂ≠¶‰π†Â§ßÊ®°ÂûãÔºàÊïôÂ∏àÊ®°ÂûãÔºâÁöÑËæìÂá∫ÂíåÂ§ÑÁêÜ‰ø°ÊÅØÁöÑÊñπÂºèÊù•Â§çÂà∂ÂÖ∂ÊÄßËÉΩÁöÑËøáÁ®ã„ÄÇ\n\nË¶ÅÂ∫îÁî®Ëøô‰∏ÄÊäÄÊúØÔºåÊòæÁÑ∂ÈúÄË¶Å‰∏Ä‰∏™Â§ßÂûãÊïôÂ∏àÊ®°ÂûãÔºå‰æãÂ¶ÇLlaMaÊàñMistralÁöÑÂºÄÊ∫êÂ§ßÂûãÊ®°Âûã‰πã‰∏Ä„ÄÇÁÑ∂ÂêéÈúÄË¶ÅËÆæËÆ°‰∏Ä‰∏™ÂèÇÊï∞Êï∞ÈáèÊòæËëóÂ∞ë‰∫éÊïôÂ∏àÊ®°ÂûãÁöÑËæÉÂ∞èÁ•ûÁªèÁΩëÁªú„ÄÇ\n\nÂ≠¶ÁîüÊ®°Âûã‰∏ç‰ªÖ‰ªÖÂú®ÂéüÂßãÁ°¨ÁõÆÊ†áÔºàÂç≥ÁúüÂÆûÊï∞ÊçÆÊ†áÁ≠æÔºâ‰∏äËøõË°åËÆ≠ÁªÉÔºåËøòÂú®ËΩØÁõÆÊ†á‰∏äËøõË°åËÆ≠ÁªÉ„ÄÇËøô‰∫õÊòØÊïôÂ∏àÊ®°ÂûãÂØπÁõ∏ÂêåËæìÂÖ•ÁîüÊàêÁöÑÊ¶ÇÁéá„ÄÇ‰æãÂ¶ÇÔºåÂØπ‰∫é‰∏ÄÁªÑÁâπÂÆöÁöÑÊü•ËØ¢ÔºåÂÅáËÆæÊïôÂ∏àÊ®°Âûã70%ÁöÑÊó∂Èó¥ÂõûÁ≠î‰∏∫‚ÄúA‚ÄùÔºå20%ÁöÑÊó∂Èó¥ÂõûÁ≠î‰∏∫‚ÄúB‚ÄùÔºå10%ÁöÑÊó∂Èó¥ÂõûÁ≠î‰∏∫‚ÄúC‚Äù„ÄÅ‚ÄúD‚ÄùÊàñ‚ÄúE‚Äù„ÄÇÂ≠¶ÁîüÊ®°Âûã‰∏ç‰ªÖ‰ºöÂ∞ùËØïÊ≠£Á°ÆÂõûÁ≠îÊØè‰∏™ÈóÆÈ¢òÔºõÂÆÉËøò‰ºöÂ∞ùËØïÂú®‰∏ÄÁªÑÊü•ËØ¢‰∏≠ÈÅµÂæ™Áõ∏ÂêåÁöÑÊ¶ÇÁéáÂàÜÂ∏É„ÄÇ\n\nËøôÊ†∑ÁöÑËΩØÁõÆÊ†áÊØè‰∏™Á§∫‰æãÊê∫Â∏¶ÁöÑ‰ø°ÊÅØÊØîÁ°¨Ê†áÁ≠æÊõ¥Â§öÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂåÖÂê´ÊïôÂ∏àÊ®°ÂûãÂØπÊâÄÊúâÂèØËÉΩÁªìÊûúÁöÑÁΩÆ‰ø°Ê∞¥Âπ≥„ÄÇËøôÂ∞±ÊòØÂ≠¶ÁîüÊ®°ÂûãËÉΩÂ§ü‰ª•ËæÉ‰ΩéÁöÑËÆ°ÁÆóÂºÄÈîÄË°®Áé∞Âæó‰∏éÊïôÂ∏àÁõ∏‰ººÁöÑÂéüÂõ†„ÄÇ\n\nÂú®ÂàùÂßãÁü•ËØÜËí∏È¶è‰πãÂêéÔºåÂ≠¶ÁîüÊ®°ÂûãÂèØËÉΩ‰ºöÂú®ÁâπÂÆö‰ªªÂä°ÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åËøõ‰∏ÄÊ≠•ÁöÑÂæÆË∞ÉÔºå‰ª•ÊúÄÂ§ßÂåñÂÖ∂ÊÄßËÉΩ„ÄÇ\n\n**‰ΩéÁß©Ëøë‰ºº**\n\nLLMÈÄöËøáÂ§ÑÁêÜÂíåÁîüÊàêÂü∫‰∫éÂ∑®Â§ßÁöÑÁü©ÈòµÔºàÂç≥ÈùûÂ∏∏Â§ßÁöÑÊï∞Â≠óË°®ÔºâÊù•Â∑•‰ΩúÔºåËøô‰∫õÁü©ÈòµË°®Á§∫ÂçïËØç‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÅÂÆÉ‰ª¨ÁöÑÂê´‰πâ‰ª•ÂèäÂÆÉ‰ª¨Âú®ËØ≠Ë®Ä‰∏≠ÁöÑ‰ΩøÁî®„ÄÇËøô‰∫õÁü©ÈòµÂèØËÉΩÂ§ßÂà∞Èöæ‰ª•Â§ÑÁêÜÔºåÁâπÂà´ÊòØÂú®Â≠òÂÇ®ÂíåËÆ°ÁÆóÊñπÈù¢„ÄÇ\n\n‰ΩéÁß©Ëøë‰ººÊ∂âÂèäÊâæÂà∞‰∏Ä‰∏™Êõ¥ÁÆÄÂçïÁöÑÁü©ÈòµÔºåÂÖ∂Â§ßÂ∞èË¶ÅÂ∞èÂæóÂ§öÔºå‰ΩÜ‰ªçËÉΩÊçïÊçâÂà∞ÂéüÂßãÂ§ßÁü©Èòµ‰∏≠ÊúÄÈáçË¶ÅÁöÑ‰ø°ÊÅØ„ÄÇËøôÊúâÁÇπÂÉèÂ∞ÜËØ¶ÁªÜÁöÑÁîª‰ΩúÁÆÄÂåñ‰∏∫ËçâÂõæ„ÄÇ\n\nËøôÈÄöËøáÊï∞Â≠¶ÊäÄÊúØÊù•ÂÆåÊàêÔºåËøô‰∫õÊäÄÊúØËØÜÂà´Áü©ÈòµÔºàÊàñÂú®Êàë‰ª¨ÁöÑÁ±ªÊØî‰∏≠ÔºåÁîª‰ΩúÔºâ‰∏≠Âì™‰∫õÈÉ®ÂàÜÂåÖÂê´ÊúÄÂ§öÁöÑ‰ø°ÊÅØÔºåÂπ∂Â∞ÜÁü©ÈòµÁº©ÂáèÂà∞‰ªÖËøô‰∫õÈÉ®ÂàÜ„ÄÇÊúâ‰∏Ä‰∫õÊï∞Â≠¶ÊäÄÊúØÔºåÂ∞§ÂÖ∂ÊòØ[Â•áÂºÇÂÄºÂàÜËß£](https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/book-chapter-4.pdf)ÔºåÊúâÂä©‰∫éÂÆûÁé∞Ëøô‰∏ÄÁÇπ„ÄÇ\n\n‰∏éÂâ™Êûù‰∏çÂêåÔºå‰ΩéÁß©Ëøë‰ººÊâßË°åÁü©ÈòµÁª¥Â∫¶ÂáèÂ∞ëÔºå‰øùÊåÅÊ®°ÂûãÁöÑÁªìÊûÑÔºå‰ΩÜ‰ª•Êõ¥Á¥ßÂáëÁöÑÂΩ¢ÂºèË°®Á§∫ÔºåËÄåÂâ™ÊûùÂàôÁõ¥Êé•ÁßªÈô§Á•ûÁªèÁΩëÁªúÁöÑÈÉ®ÂàÜ„ÄÇ\n\n**ÈáèÂåñ**\n\nLLM‰ΩøÁî®Â§ßÈáèÊï∞Â≠¶ËÆ°ÁÆóÊù•Â§ÑÁêÜÊñáÊú¨„ÄÇËøô‰∫õËÆ°ÁÆó‰ΩøÁî®ÂèØ‰ª•ÂÖ∑ÊúâÂπøÊ≥õÂÄºËåÉÂõ¥ÁöÑÊï∞Â≠ó„ÄÇÈÄöÂ∏∏ÔºåËøô‰∫õÊï∞Â≠ó‰ª•ÂèØ‰ª•Ë°®Á§∫ÈùûÂ∏∏ÂπøÊ≥õÂÄºËåÉÂõ¥ÁöÑÊ†ºÂºèÂ≠òÂÇ®Ôºà[ÊµÆÁÇπÊ†ºÂºè](https://de.wikipedia.org/wiki/Einfache_Genauigkeit)ÔºâÔºåÂú®ÂÜÖÂ≠ò‰∏≠Âç†Áî®32‰Ωç„ÄÇ\n\nÈáèÂåñÂáèÂ∞ë‰∫ÜËøô‰∫õÊï∞Â≠óÁöÑÁ≤æÂ∫¶ÔºåÈÄöÂ∏∏Â∞Ü32‰ΩçÊµÆÁÇπÊï∞Â≠óËΩ¨Êç¢‰∏∫Êõ¥‰Ωé‰ΩçÂÆΩÁöÑË°®Á§∫Ôºå‰æãÂ¶Ç8‰ΩçÊï¥Êï∞„ÄÇËøôÊÑèÂë≥ÁùÄÊ®°Âûã‰∏çÂÜç‰ΩøÁî®ÂÖ∑ÊúâËÆ∏Â§öÂ∞èÊï∞‰ΩçÁöÑÊï∞Â≠óÔºåËÄåÊòØ‰ΩøÁî®‚ÄúÊõ¥ÁÆÄÂçï‚ÄùÁöÑÊï∞Â≠óÔºå‰ªéËÄå‰ΩøËÆ°ÁÆóÊõ¥Âø´Âπ∂ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®„ÄÇ\n\nÈáèÂåñÊÑüÁü•ËÆ≠ÁªÉÔºàQATÔºâÊ∂âÂèäÂú®ËÆ≠ÁªÉÊ®°ÂûãÊó∂ËÄÉËôëÈáèÂåñÔºå‰ΩøÂÖ∂ËÉΩÂ§üÈÄÇÂ∫îÁ≤æÂ∫¶ÊçüÂ§±ÔºåÈÄöÂ∏∏ÂØºËá¥Êõ¥Â•ΩÁöÑÊÄßËÉΩÔºå‰ΩÜ‰ª£‰ª∑ÊòØÊõ¥Â§çÊùÇÂíåËµÑÊ∫êÂØÜÈõÜÁöÑËÆ≠ÁªÉËøáÁ®ã„ÄÇ\n\nÂêéËÆ≠ÁªÉÈáèÂåñÔºàPTQÔºâÂú®Ê®°ÂûãÂÆåÂÖ®ËÆ≠ÁªÉÂêéÂ∫îÁî®ÈáèÂåñÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßçÊõ¥ÁÆÄÂçïÂíåÊõ¥Âø´ÈÄüÁöÑÊñπÊ≥ïÊù•ÂáèÂ∞ëËÆ°ÁÆóÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÊ®°ÂûãÂπ∂Êú™ÁâπÂà´ÈíàÂØπ‰ΩéÁ≤æÂ∫¶Êìç‰ΩúËøõË°å‰ºòÂåñÔºåÂõ†Ê≠§ÂèØËÉΩÊó†Ê≥ïËææÂà∞‰∏éQATÁõ∏ÂêåÁöÑÂáÜÁ°ÆÊÄßÊàñÊÄßËÉΩÊ∞¥Âπ≥„ÄÇ\n\n### 1‰Ωç LLM Êó∂‰ª£Ôºü\n\nÂæÆËΩØÁ†îÁ©∂‰∫∫ÂëòÊúÄËøëÂèëË°®‰∫Ü‰∏ÄÁØá[ÂºïËµ∑ËΩ∞Âä®ÁöÑËÆ∫Êñá](https://arxiv.org/pdf/2402.17764.pdf)ÔºåÂ∞ÜÊØè‰∏™ÂèÇÊï∞ÁöÑÂ≠òÂÇ®‰ΩçÊï∞‰ªéÂΩìÂâç LLM ‰∏≠ÁöÑ 16 ‰ΩçÊ†áÂáÜÔºåÈôç‰ΩéÂà∞‰∫Ü‰ªÖ‰ªÖ 1.58 ‰Ωç„ÄÇËøôÊòØ‰∏™ÈáçÂ§ßÊñ∞ÈóªÔºöÈÄöËøáËøôÁßçÊäÄÊúØÔºå‰ªñ‰ª¨ÂÆûÁé∞‰∫ÜËøë 10 ÂÄçÁöÑ‰ª§ÁâåÂêûÂêêÈáèÔºåÂç≥Â§ÑÁêÜÊñáÊú¨ÁöÑÈÄüÂ∫¶Âá†‰πéÂø´‰∫Ü 10 ÂÄç„ÄÇ‰ªñ‰ª¨ËøòÂ∞ÜÂÜÖÂ≠òÂç†Áî®ÂáèÂ∞ë‰∫Ü 3.5 ÂÄçÔºåËøôÊÑèÂë≥ÁùÄËøêË°åËøô‰∫õÊ®°ÂûãÊâÄÈúÄÁöÑÁ°¨‰ª∂Â§ßÂ§ßÂáèÂ∞ë„ÄÇ\n\nËøôÊòØÈÄöËøá‰ΩøÁî®‰∏âÂÖÉ‰ΩçÂÆûÁé∞ÁöÑ„ÄÇ‰∏éÈÄöÂ∏∏‰ΩøÁî®ÁöÑ‰ªã‰∫é -1 Âíå 1 ‰πãÈó¥ÁöÑÊµÆÁÇπÊï∞ÔºàÈÄöÂ∏∏‰ΩøÁî® 16 ‰ΩçÔºâ‰∏çÂêåÔºåÊØè‰∏™ÊùÉÈáçË¢´Ë°®Á§∫‰∏∫ -1„ÄÅ0 Êàñ 1„ÄÇËøô‰∫õÊï∞Â≠óÂèØ‰ª•Â≠òÂÇ®Âú® 1.58 ‰ΩçÔºåÂõ†‰∏∫ÂØπ‰∫é 3 ‰∏™ÂèØËÉΩÂÄºÁöÑ‰∫åËøõÂà∂Êô∂‰ΩìÁÆ°ÔºåÂèØ‰ª•ÂæóÂà∞ 2¬π.58 = 3„ÄÇ‰ªÖ‰ΩøÁî®Â¶ÇÊ≠§ÁÆÄÂçïÁöÑÊï∞Â≠ó‰πüÊÑèÂë≥ÁùÄ‰∏çÂÜçÈúÄË¶ÅÂ§çÊùÇÁöÑÁü©Èòµ‰πòÊ≥ïÔºåËøô‰ΩøÂæóËµÑÊ∫ê‰ΩøÁî®ÊïàÁéáÂ§ßÂ§ßÊèêÈ´ò„ÄÇ\n\nËøôÁßçÊäÄÊúØ‰ª§‰∫∫Âõ∞ÊÉëÁöÑÊòØÔºåÂÆÉÂú® 30 ‰∫øÂèÇÊï∞ÁöÑÂ§ßÂ∞è‰∏ãÔºåËÉΩÂ§üÂÆûÁé∞‰∏é‰º†Áªü 16 ‰ΩçÊ®°ÂûãÁõ∏‰ººÁöÑËæìÂá∫ÊÄßËÉΩ„ÄÇÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öËøôÁßçÊ®°ÂûãÂú®Ë∂ÖËøá 130 ‰∫øÂèÇÊï∞ÁöÑÈòàÂÄºÊó∂ÔºåÊòØÂê¶ËÉΩÂÉè‰º†ÁªüÊ®°Âûã‰∏ÄÊ†∑Êâ©Â±ï„ÄÇÊòéÁ°ÆÁöÑÊòØÔºåÂç≥‰ΩøÂú® 700 ‰∫øÂèÇÊï∞‰∏ãÔºåÂÆÉÂú®Âª∂Ëøü„ÄÅÂÜÖÂ≠ò‰ΩøÁî®ÂíåËÉΩËÄóÊñπÈù¢ÊØî‰ªÖÊúâ 130 ‰∫øÂèÇÊï∞ÁöÑ‰º†ÁªüÊ®°ÂûãÊõ¥È´òÊïà„ÄÇËæìÂá∫Ë¥®Èáè‰ªçÈúÄËØ¶ÁªÜÊµãËØï„ÄÇ\n\nÂè¶‰∏Ä‰∏™Áº∫ÁÇπÊòØÔºåÁé∞Êúâ LLM ÁöÑÊúÄÂÖàËøõÈáèÂåñÊäÄÊúØÊó†Ê≥ïÁî®‰∫éÁîüÊàê 1.58 ‰ΩçÊ®°Âûã„ÄÇËøôÁ±ªÊ®°ÂûãÈúÄË¶Å‰ªéÂ§¥ÂºÄÂßãÂàõÂª∫ÔºåÂ∞ΩÁÆ°ÊàêÊú¨Â§ßÂπÖÈôç‰ΩéÔºå‰ΩÜÁõÆÂâç‰ªçË∂ÖÂá∫ÊôÆÈÄöÂ∏ÇÊ∞ëÁöÑÊâøÂèóËåÉÂõ¥„ÄÇ\n\nÁÑ∂ËÄåÔºåÂ¶ÇÊûúËøôÊ†∑ÁöÑÊ®°ÂûãË¢´ÂàõÂª∫Âπ∂ËøêË°åËâØÂ•ΩÔºåÊé®ÁêÜÂ∞ÜÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇ1.58 ‰Ωç LLM ÁîöËá≥ÂèØËÉΩÂú®ËæπÁºòÂíåÁßªÂä®ËÆæÂ§á‰∏äÈÉ®ÁΩ≤„ÄÇÂÆÉ‰ª¨ÂØπ CPU ËÆæÂ§áÔºàÂ§ßÂ§öÊï∞ÁßªÂä®ËÆæÂ§áËøêË°åÁöÑËÆæÂ§áÔºâ‰πüÊõ¥Âä†ÂèãÂ•ΩÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨Êõ¥ÂÆπÊòìÂú®Êõ¥‰æøÂÆúÁöÑËäØÁâá‰∏äÈÉ®ÁΩ≤„ÄÇÊâÄÊúâËøô‰∫õÈÉΩÊúâËÆ∏Â§ö‰ºòÂäøÔºå‰æãÂ¶ÇÈöêÁßÅÊñπÈù¢Ôºå‰ΩÜ‰πüÂÖÅËÆ∏Âá∫Áé∞‰∫∫Á±ªÂ∞öÊú™Ê¢¶ÊÉ≥ÁöÑÊñ∞ÁöÑÂ∫îÁî®„ÄÇ\n\nÊ≠§Â§ñÔºåÂÉè [Groq](https://groq.com/) ËøôÊ†∑ÁöÑÂàùÂàõÂÖ¨Âè∏Â∑≤ÁªèÂ±ïÁ§∫‰∫ÜÂú®‰∏∫ LLM ÊûÑÂª∫ÁâπÂÆöÁ°¨‰ª∂ [Â¶Ç LPU](https://wow.groq.com/why-groq/) ÁöÑ promising results ÂíåÂ∑®Â§ßÊΩúÂäõ„ÄÇLLM ‰∏ìÁî®Á°¨‰ª∂Â∑≤ÁªèÊòØ‰∏Ä‰∏™[Â∑®Â§ßÂ∏ÇÂú∫](https://finance.yahoo.com/news/generative-ai-market-size-expected-163500846.html#:~:text=%2D%20Large%20Language%20Model%20(LLM),the%20forecast%20period%202023%2D2029.)„ÄÇËøôÊ†∑ÁöÑÂèëÁé∞ÂèØËÉΩ‰ΩøËøô‰∏™Â∏ÇÂú∫ÁöÑÂ¢ûÈïøÈÄüÂ∫¶ÊØîÂàÜÊûêÂ∏àËøÑ‰ªäÈ¢ÑËßÅÁöÑÊõ¥‰∏∫ÊøÄËøõ„ÄÇ\n\nÂ¶ÇÊûúÊ≤°ÊúâÂÖ∂‰ªñÔºåÊé®ÁêÜÂ∞ÜÁî±‰∫éÈáèÂåñÊäÄÊúØÂíå‰∏ìÁî®Á°¨‰ª∂ÁöÑÁªìÂêàËÄåÂèòÂæóÊûÅ‰∏∫‰æøÂÆú„ÄÇËøôÂØπËÆ∏Â§öÂÖ¨Âè∏ÔºåÂåÖÊã¨ÂàùÂàõÂÖ¨Âè∏ÔºåÈÉΩ‰ºö‰∫ßÁîüÂΩ±Âìç„ÄÇ\n\n## ËæÉËΩªÈáèÁöÑ LLM ÂØπÂàùÂàõ‰ºÅ‰∏öÊÑèÂë≥ÁùÄ‰ªÄ‰πàÔºü\n\n### AIÁ°¨‰ª∂ÁöÑÁπÅËç£ÂàöÂàöÂºÄÂßã\n\nÂú®1971Âπ¥Ëá≥1999Âπ¥Èó¥ÔºåCPUÂá†‰πéÊòØÂ∏ÇÂú∫‰∏ä[ÂîØ‰∏ÄÁöÑÂæÆÂ§ÑÁêÜÂô®](https://cs.stanford.edu/people/eroberts/courses/soco/projects/2005-06/64-bit-processors/history1.html)„ÄÇÈöèÂêéÔºå[NVIDIAÊé®Âá∫](https://readmedium.com/a-brief-history-of-gpu-47d98d6a0f8a)‰∫ÜÂÖ∂GPU„ÄÇËôΩÁÑ∂‰ªéÊäÄÊúØ‰∏äËÆ≤ÔºåÂÆÉÂπ∂‰∏çÊòØ‰∏ñÁïå‰∏äÁ¨¨‰∏Ä‰∏™GPUÔºå‰ΩÜÂÆÉÊòØ‰ΩøÊ∏∏ÊàèÊàê‰∏∫‰∏ÄÁßçÂèØÊé•Ëß¶ÂíåÊ≤âÊµ∏Âºè‰ΩìÈ™åÁöÑÈ¶ñÊâπÂæÆÂ§ÑÁêÜÂô®‰πã‰∏Ä„ÄÇÔºàÊ∏∏ÊàèÊ∂àËÄóÂ§ßÈáèËÆ°ÁÆóËÉΩÂäõ‚Äî‚ÄîÂ¶ÇÊûú‰Ω†‰∏çÁü•ÈÅìÔºåÁé∞Âú®‰Ω†Áü•ÈÅì‰∫ÜÔºÅÔºâ\n\n‰ªéÊ∏∏ÊàèÂºÄÂßãÔºåGPUËøÖÈÄüÊâ©Â±ïÂà∞ËÆ∏Â§ö‰∏çÂêåÁöÑ‰ªªÂä°ÔºåÂåÖÊã¨ÁßëÂ≠¶ÂõæÂÉèÂ§ÑÁêÜ„ÄÅÁ∫øÊÄß‰ª£Êï∞„ÄÅ3DÈáçÂª∫Á≠â„ÄÇGPUÁâπÂà´ÊìÖÈïøÁöÑ‰∏Ä‰ª∂‰∫ãÊòØ‰ªÄ‰πàÔºüÊú∫Âô®Â≠¶‰π†ÂíåLLM„ÄÇÂ¶Ç‰ªäÔºåËÆ∏Â§öNVIDIAÁöÑËäØÁâáÊ≠£Âú®Áî®‰∫éËÆ≠ÁªÉLLM„ÄÇ\n\n‰ªéÈÇ£Êó∂Ëµ∑ÔºåÂÖ∂‰ªñÂæÆÂ§ÑÁêÜÂô®‰πüÂºÄÂßãÊ∂åÁé∞„ÄÇ[Ë∞∑Ê≠åÁöÑTPU](https://cloud.google.com/tpu?hl=en)‰∫é2016Âπ¥Êé®Âá∫ÔºåÁâπÂà´ÈÄÇÂêàAIËÆ≠ÁªÉÂíåÊé®ÁêÜ„ÄÇËôΩÁÑ∂GPUË¢´ËØÅÊòéÈùûÂ∏∏ÈÄÇÂêàLLMÔºå‰ΩÜTPUÊòØ‰∏ìÈó®‰∏∫Ê≠§ÁõÆÁöÑËÆæËÆ°ÁöÑ„ÄÇÂÆÉ‰ª¨Âú®ËÆ≠ÁªÉÂíåÊé®ÁêÜÊñπÈù¢ÈÉΩÈùûÂ∏∏ÂêàÈÄÇ„ÄÇ\n\nÁÑ∂ËÄåÔºåË°å‰∏öÊ≠£Â§Ñ‰∫é[ËΩ¨ÊäòÁÇπ](https://www.wsj.com/tech/ai/how-a-shifting-ai-chip-market-will-shape-nvidias-future-f0c256b1)Ôºö‰∏ç‰πÖ‰πãÂêéÔºåÂ§ßÂ§öÊï∞‰∏éLLMÁõ∏ÂÖ≥ÁöÑÂ∑•‰ΩúÂ∞ÜÊòØÊé®ÁêÜÔºåËÄå‰∏çÂÜçÊòØËÆ≠ÁªÉÔºåÂõ†‰∏∫Áî®Êà∑ÂºÄÂßãÈÉ®ÁΩ≤ÂÉèLlaMaËøôÊ†∑ÁöÑÊ®°Âûã„ÄÇÊñ∞ÁöÑÂàõÊñ∞AIÂçäÂØº‰ΩìÂÖ¨Âè∏Áé∞Âú®ÊúâÊú∫‰ºöËøõÂÖ•Ëøô‰∏™È¢ÜÂüü„ÄÇ\n\nËøôÂåÖÊã¨‰∏ìÊ≥®‰∫éÁâπÂà´Âø´ÈÄüÊé®ÁêÜÂ§ÑÁêÜÂô®ÁöÑËäØÁâáÂà∂ÈÄ†ÂïÜ[Groq](https://wow.groq.com/press/)„ÄÇÂÖ∂‰ªñÂàùÂàõÂÖ¨Âè∏ÂåÖÊã¨[ËµõÊãâÂ∏ÉÊãâÊñØ](https://www.cerebras.net/)Ôºà‰∏ìÊ≥®‰∫éËÆ≠ÁªÉÔºâ„ÄÅ[Graphcore](https://www.graphcore.ai/about)ÔºàÊ∂µÁõñËÆ≠ÁªÉÂíåÊé®ÁêÜÔºâÂíå[SambaNova](https://sambanova.ai/)Ôºà‰πüÂåÖÊã¨ËÆ≠ÁªÉÂíåÊé®ÁêÜÔºâ„ÄÇÂÉèËã±ÁâπÂ∞îÂíåAMDËøôÊ†∑Êõ¥ÊàêÁÜüÁöÑÁ´û‰∫âÂØπÊâã‰πüÂú®ÂÖ≥Ê≥®ËÆ≠ÁªÉÂíåÊé®ÁêÜÔºåÂ∞ΩÁÆ°È¢ÑËÆ°Êú™Êù•Âá†Âπ¥ÁöÑÂ§ßÂ§öÊï∞Â¢ûÈïøÂ∞ÜÊù•Ëá™ÂêéËÄÖ„ÄÇÂ§ßÂûãÁßëÊäÄÂ∑®Â§¥‚Äî‚ÄîË∞∑Ê≠å„ÄÅ‰∫öÈ©¨ÈÄäÊàñÂæÆËΩØ‚Äî‚Äî‰πüÂú®ÂºÄÂèëAI‰∏ìÁî®ËäØÁâáÔºå‰ΩÜ‰∏ªË¶ÅÁî®‰∫éÂÜÖÈÉ®‰ΩøÁî®„ÄÇ\n\nÊÄª‰ΩìËÄåË®ÄÔºåLLMÁöÑÁ°¨‰ª∂Â∏ÇÂú∫‰ªçÁÑ∂Áî±Êï∞ÊçÆ‰∏≠ÂøÉÂ∫îÁî®‰∏ªÂØº„ÄÇËæπÁºòÂíåÁßªÂä®Â∫îÁî®ÊòØ‰∏ã‰∏Ä‰∏™Âêà‰πéÈÄªËæëÁöÑÊ≠•È™§Ôºå‰ΩÜÂ∞ÜÈúÄË¶ÅÊõ¥Â§öÁ™ÅÁ†¥Ôºå‰æãÂ¶ÇÂæÆËΩØÁ†îÁ©∂‰∫∫ÂëòÊúÄËøëÂèëÂ∏ÉÁöÑ1.58‰ΩçÊñπÊ≥ïÔºàËßÅ‰∏äÊñáÔºâ„ÄÇ\n\n## LLMËΩØ‰ª∂ÂÖ¨Âè∏ÁöÑÂΩ±Âìç\n\nÂú®Êñ∞ÂÖ¥AIÈ¢ÜÂüüÁöÑÊï¥‰∏™‰ª∑ÂÄºÈìæ‰∏≠ÔºåÊàë‰ª¨Ê¶ÇËø∞ÁöÑËøô‰∫õÂèëÂ±ïÂèØËÉΩ‰ºöÂØºËá¥**ËøêË°å/‰ΩøÁî®LLMÁöÑÊàêÊú¨ÊòæËëóÈôç‰Ωé**„ÄÇ\n\n‰ª•‰∏ãÊòØÊàë‰ª¨ÂØπËøô‰∏ÄË∂ãÂäøÁöÑÂá†ÁÇπÊÄùËÄÉÔºö\n\n* **‰ºòÁßÄÁöÑB2C‰∫ßÂìÅ**ÔºåÂõ†‰∏∫LLMÊàêÊú¨Èôç‰ΩéÊÑèÂë≥ÁùÄÂèØ‰ª•ÊûÑÂª∫ÂÖ∑ÊúâÈ´òLLM‰ΩøÁî®È¢ëÁéáÂíåËßÑÊ®°Ôºà‰æãÂ¶ÇÔºåÈïø‰∏ä‰∏ãÊñáÁ™óÂè£ÔºâÁöÑÂÖçË¥πÂ¢ûÂÄºB2C‰ΩìÈ™åÔºåËÄå‰∏ç‰ºöÁ†¥ÂùèÂÖ¨Âè∏ÁöÑÂçï‰ΩçÁªèÊµé„ÄÇ\n* ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÁöÑËÆøÈóÆÊ∞ë‰∏ªÂåñÔºå‰ΩøÂæó**‰ΩéÊî∂ÂÖ•ÂõΩÂÆ∂ÁöÑÁî®Êà∑**ËÉΩÂ§üÂà©Áî®ÂÖàËøõÁöÑAIÊäÄÊúØ„ÄÇ\n* ÂÖ¨Âè∏ÂèØ‰ª•Ëá™Âä®ÂåñÊõ¥ÂπøÊ≥õÁöÑ‰ªªÂä°Ôºå‰ªéËÄåÂÆûÁé∞**ÊïàÁéáÂíåÁîü‰∫ßÂäõÁöÑÊèêÂçá**Ôºà‚ÄúÊàë‰∏çÂÜçÂÖ≥ÂøÉÊØèÂ∞èÊó∂Êúâ1‰∏áÊ¨°APIË∞ÉÁî®‚ÄùÔºâ„ÄÇ\n* Êñ∞ÁöÑËæπÁºòAIÁ°¨‰ª∂ÁªìÂêàÊõ¥Â∞èÁöÑÊ®°ÂûãÂ∞ÜÂØºËá¥**Êñ∞ÁöÑËæπÁºòAIÁî®‰æã**ÂèòÂæóÂèØË°åÔºåËøô‰∫õÁî®‰æã‰πãÂâç‰ªÖÈôê‰∫é‚ÄúÊï∞ÊçÆ‰∏≠ÂøÉ‚Äù„ÄÇ\n* ÈöèÁùÄËæπÁºòÁ°¨‰ª∂ÁöÑÂø´ÈÄüÂèëÂ±ïÔºåÊàë‰ª¨Áõ∏‰ø°ÊúâÊú∫‰ºöÂª∫Á´ãËΩØ‰ª∂ÂÖ¨Âè∏ÔºåÂ∏ÆÂä©ÂÆ¢Êà∑Â∞ÜAIÊ®°ÂûãÂ∏¶ÂÖ•ÂÆöÂà∂ËæπÁºòËÆæÂ§áÁöÑÁ¢éÁâáÂåñÁ©∫Èó¥Ôºà‚ÄúÊää‰Ω†ÁöÑÊ®°ÂûãÁªôÊàëÔºåÊàëÁî®ÂêÑÁßçÊäÄÊúØËøõË°åÂéãÁº©ÔºåÂú®10Áßç‰∏çÂêåÁöÑËæπÁºòËÆæÂ§á‰∏äÊµãËØïÔºåÂëäËØâ‰Ω†Âì™‰∏™ÊïàÊûúÊúÄÂ•ΩÔºåÁÑ∂ÂêéÂ∏ÆÂä©‰Ω†ÈÉ®ÁΩ≤‚ÄùÔºâ„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/leveraging-gemini-1-5-api-for-automated-test-case-generation-reverse-engineering-2ee8789f01db","frontmatter":{"title":"Âà©Áî® Gemini 1.5 API ËøõË°åËá™Âä®ÊµãËØïÁî®‰æãÁîüÊàêÈÄÜÂêëÂ∑•Á®ã","meta_title":"Âà©Áî® Gemini 1.5 API ËøõË°åËá™Âä®ÊµãËØïÁî®‰æãÁîüÊàêÈÄÜÂêëÂ∑•Á®ã","description":"ËØ•ÊµãËØïÊé¢Á¥¢‰ΩøÁî® Gemini API Âíå Google Apps Script Ëá™Âä®ÂàõÂª∫Á§∫‰æãËæìÂÖ•Ôºå‰ª•‰æøÊõ¥Âø´Âú∞ËøõË°åËÑöÊú¨ÈÄÜÂêëÂ∑•Á®ã„ÄÇ","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fTtML3Sm1TuQNhQP.jpg","categories":["Programming","Programming/Scripting","Technology/WebAPI"],"author":"Rifx.Online","tags":["Gemini","API","automation","reverse-engineering","scripts"],"draft":false,"slug":"blog/leveraging-gemini-1-5-api-for-automated-test-case-generation-reverse-engineering-2ee8789f01db"},"content":"\n\n\n\n\n## ÊëòË¶Å\n\nÊú¨Êä•ÂëäÊé¢ËÆ®‰∫ÜÂà©Áî® Gemini 1.5 API ‰∏é Google Apps Script ÁªìÂêàÔºåËá™Âä®ÂåñËÑöÊú¨ÈÄÜÂêëÂ∑•Á®ã‰∏≠ÁöÑÁ§∫‰æãËæìÂÖ•ÂàõÂª∫„ÄÇ‰º†Áªü‰∏äÔºåËøô‰∏ÄËøáÁ®ãÊòØÊâãÂä®‰∏îËÄóÊó∂ÁöÑÔºåÁâπÂà´ÊòØÂØπ‰∫éÂÖ∑ÊúâÂ§ßÈáèÊµãËØïÁî®‰æãÁöÑÂáΩÊï∞„ÄÇÈÄöËøáÂ∞ÜÈÄÜÂêëÂ∑•Á®ãÊäÄÊúØÂ∫îÁî®‰∫é Google Apps Script Á§∫‰æãÔºåÊé¢ËÆ®‰∫Ü Gemini 1.5 API Âú®Ëá™Âä®ÂåñËæìÂÖ•ÁîüÊàêÊñπÈù¢ÁÆÄÂåñÂºÄÂèëÁöÑÊΩúÂäõ„ÄÇ\n\n## ‰ªãÁªç\n\nÈöèÁùÄ Gemini 1\\.5 API ÁöÑÂèëÂ∏ÉÔºåÁî®Êà∑Ëé∑Âæó‰∫ÜÂ§ÑÁêÜÊõ¥Â§çÊùÇÊï∞ÊçÆÁöÑËÉΩÂäõÔºå‰∏∫ÂêÑÁßçÂ∫îÁî®ÂºÄÂèëÊâìÂºÄ‰∫ÜÂ§ßÈó®„ÄÇÊú¨Êä•ÂëäÊé¢ËÆ®‰∫ÜÂ∞Ü Gemini 1\\.5 API ‰∏é Google Apps Script ÁªìÂêà‰ΩøÁî®ÁöÑÊΩúÂäõÔºå‰ª•ÂÆûÁé∞ËÑöÊú¨ÂºÄÂèëÂíåÊîπËøõÁöÑÈÄÜÂêëÂ∑•Á®ã„ÄÇ\n\n‰º†Áªü‰∏äÔºåËÑöÊú¨ÂºÄÂèëÊ∂âÂèäÊâãÂä®ÊûÑÂª∫Á§∫‰æãËæìÂÖ•ÂÄº„ÄÇËøô‰∏™ËøáÁ®ãÂèØËÉΩËÄóÊó∂ÔºåÁâπÂà´ÊòØÂú®ÂàõÂª∫ÂáΩÊï∞ÊàñÊµãËØï‰ªéÂú®Á∫øËµÑÊ∫êÔºàÂ¶Ç Stack OverflowÔºâËé∑ÂèñÁöÑ‰ª£Á†ÅÊó∂„ÄÇÊØè‰∏™ÂáΩÊï∞ÂèØËÉΩÈúÄË¶ÅÂ§ßÈáèÁöÑÊµãËØïÁî®‰æãÔºåÊâãÂä®ÁîüÊàêËøô‰∫õËæìÂÖ•ÂèØËÉΩÊàê‰∏∫Áì∂È¢à„ÄÇ\n\nGemini 1\\.5 API Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÊΩúÂú®ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÈÄöËøáËá™Âä®ÂåñÁ§∫‰æãËæìÂÖ•ÂÄºÁöÑÂàõÂª∫„ÄÇËøôÂèØ‰ª•ÊòæËëóÂáèÂ∞ëÂºÄÂèëÊó∂Èó¥ÂíåÁ≤æÂäõ„ÄÇÊú¨Êä•ÂëäÈÄöËøáÂ∞ÜÈÄÜÂêëÂ∑•Á®ãÊäÄÊúØÂ∫îÁî®‰∫éÂêÑÁßç‰ΩøÁî® Gemini 1\\.5 API ÁöÑ Google Apps Script Á§∫‰æãÔºåÊù•Ë∞ÉÊü•Ëøô‰∏ÄÂèØËÉΩÊÄß„ÄÇ\n\nÂú®ËøôÈáåÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Â¶Ç‰Ωï‰ΩøÁî® Gemini 1\\.5 API Ëá™Âä®ÂåñÁîüÊàêÁ§∫‰æãËæìÂÖ•ÂÄºÔºå‰ª•ËøõË°åÁºñÂÜôÂú® Google Apps Script ‰∏≠ÁöÑËÑöÊú¨ÁöÑÈÄÜÂêëÂ∑•Á®ã„ÄÇ\n\n## ‰ΩøÁî®\n\n‰∏∫‰∫ÜÊµãËØïÊ≠§ËÑöÊú¨ÔºåËØ∑ÊåâÁÖß‰ª•‰∏ãÊµÅÁ®ãËøõË°å„ÄÇ\n\n## 1\\. ÂàõÂª∫ API ÂØÜÈí•\n\nËØ∑ËÆøÈóÆ [https://ai.google.dev/gemini\\-api/docs/api\\-key](https://ai.google.dev/gemini-api/docs/api-key) Âπ∂ÂàõÂª∫ÊÇ®ÁöÑ API ÂØÜÈí•„ÄÇÂ±äÊó∂ÔºåËØ∑Âú® API ÊéßÂà∂Âè∞ÂêØÁî®ÁîüÊàêËØ≠Ë®Ä API„ÄÇÊ≠§ API ÂØÜÈí•Áî®‰∫éÊ≠§Á§∫‰æãËÑöÊú¨„ÄÇ\n\nËØ•ÂÆòÊñπÊñáÊ°£‰πüÂèØ‰ª•Êü•Áúã„ÄÇ [ÂèÇËÄÉ](https://ai.google.dev/)„ÄÇ\n\n## 2\\. ÂàõÂª∫ Google Apps Script È°πÁõÆ\n\nÂú®Êú¨Êä•Âëä‰∏≠Ôºå‰ΩøÁî®‰∫Ü Google Apps Script„ÄÇÂΩìÁÑ∂ÔºåÊú¨Êä•Âëä‰∏≠‰ªãÁªçÁöÑÊñπÊ≥ï‰πüÂèØ‰ª•Áî®‰∫éÂÖ∂‰ªñËØ≠Ë®Ä„ÄÇ\n\nÂú®ËøôÈáåÔºå‰∏∫‰∫ÜÊµãËØï‰ª•‰∏ãÁ§∫‰æãËÑöÊú¨ÔºåËØ∑ÂàõÂª∫‰∏Ä‰∏™Áã¨Á´ãÁöÑ Google Apps Script È°πÁõÆ„ÄÇÂΩìÁÑ∂ÔºåÊ≠§ËÑöÊú¨‰πüÂèØ‰ª•‰∏éÂÆπÂô®ÁªëÂÆöËÑöÊú¨‰∏ÄËµ∑‰ΩøÁî®„ÄÇ\n\nËØ∑ÊâìÂºÄ Google Apps Script È°πÁõÆÁöÑËÑöÊú¨ÁºñËæëÂô®„ÄÇ\n\n## 3\\. ÂÆâË£Ö Google Apps Script Â∫ì\n\n‰∏∫‰∫ÜÊñπ‰æøËÆøÈóÆ Gemini APIÔºåÊàëÂàõÂª∫‰∫Ü‰∏Ä‰∏™ Google Apps Script Â∫ì [GeminiWithFiles](https://github.com/tanaikech/GeminiWithFiles)„ÄÇÂú®‰ª•‰∏ãÁ§∫‰æãËÑöÊú¨‰∏≠ÔºåÂ∞Ü‰ΩøÁî®ËØ•Â∫ì„ÄÇÂõ†Ê≠§ÔºåËØ∑ÂÆâË£ÖÂÆÉ„ÄÇÊÇ®ÂèØ‰ª•Âú® [ËøôÈáå](https://github.com/tanaikech/GeminiWithFiles?tab=readme-ov-file#1-use-geminiwithfiles-as-a-google-apps-script-library) Êü•ÁúãÂÆâË£ÖÊñπÊ≥ï„ÄÇ\n\n## 4\\. Á§∫‰æãËÑöÊú¨ 1\n\nÁ§∫‰æãÂáΩÊï∞ÈÄâËá™ [ÊàëÁöÑ‰ª£Á†ÅÂ∫ì](https://github.com/tanaikech/UtlApp)„ÄÇ\n\n* [transpose](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#transpose): ËΩ¨ÁΩÆ‰∫åÁª¥Êï∞ÁªÑ„ÄÇ\n* [removeDuplicatedValues](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#removeduplicatedvalues): ‰ªé‰∏ÄÁª¥Êï∞ÁªÑ‰∏≠ÁßªÈô§ÈáçÂ§çÂÄº„ÄÇ\n* [compilingNumbers](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#compilingnumbers): ‰ΩøÁî® Google Apps Script ÁºñËØëËøûÁª≠Êï∞Â≠ó„ÄÇ\n* [unpivot](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#unpivot): Â∞Ü‰∫åÁª¥Êï∞ÁªÑËΩ¨Êç¢‰∏∫ÈùûÈÄèËßÜÔºàÂèçÈÄèËßÜÔºâ„ÄÇ\n* [expandA1Notations](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#expanda1notations): Ê≠§ÊñπÊ≥ïÁî®‰∫éÊâ©Â±ï A1 Ë°®Á§∫Ê≥ï„ÄÇ\n\n‰∏ãÈù¢Êèê‰æõ‰∫ÜÊºîÁ§∫Ëøô‰∫õÂáΩÊï∞ÁöÑÁ§∫‰æãËÑöÊú¨„ÄÇÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊâÄÊúâÂáΩÊï∞ÂèØ‰ª•Âú®‰∏ÄÊ¨° API Ë∞ÉÁî®‰∏≠ÊâßË°å„ÄÇÂΩìÊàëËøêË°åËøô‰∏™ËÑöÊú¨Êó∂ÔºåÂÆÉËøîÂõû‰∫ÜÊÄªÂÖ± 2,880 ‰∏™‰ª§Áâå„ÄÇ\n\nÁ§∫‰æãÈ¶ñÂÖà‰ΩøÁî® Gemini ÂàõÂª∫ËæìÂÖ•ÂÄº„ÄÇ‰∏∫‰∫ÜÊµãËØïËøô‰∫õÂÄºÔºåËÑöÊú¨ÈöèÂêéÂ∞ÜÂÆÉ‰ª¨‰∏éÂú® Google Apps Script ‰∏≠ÂÆûÁé∞ÁöÑÂáΩÊï∞‰∏ÄËµ∑‰ΩøÁî®„ÄÇÊúÄÂêéÔºåËæìÂÖ•ÂíåËæìÂá∫ÂÄºÈÉΩË¢´ÊâìÂç∞Âá∫Êù•„ÄÇ\n\nËøôÈáå‰ΩøÁî® JSON Ê®°ÂºèÁîüÊàêÂÜÖÂÆπ„ÄÇËøôÁ°Æ‰øù‰∫Ü Gemini Á®≥ÂÆöÁîüÊàêÂ§çÊùÇÁöÑ JSON ÂØπË±°„ÄÇ[ÂèÇËÄÉ](https://readmedium.com/taming-the-wild-output-effective-control-of-gemini-api-response-formats-with-response-mime-type-da273c08be85)Âõ†Ê≠§ÔºåÊàëÈÄâÊã©Âú®Ëøô‰∏™ÂÆû‰æã‰∏≠‰ΩøÁî®ÂÆÉ„ÄÇ\n\n```python\nfunction myFunction() {\n\n  const apiKey = \"###\"; // Please set your API key.\n\n  const functionObj = {\n    transpose: function transpose(array) {\n      /**\n       * ### Description\n       * When the inputted array is 2 dimensional array, true is returned.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @return {Boolean} When the inputted array is 2 dimensional array, true is returned.\n       */\n      function is2DimensionalArray(array) {\n        return array.every((r) => Array.isArray(r));\n      }\n\n      /**\n       * ### Description\n       * Transpose 2 dimensional array.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @param {Boolean} check Check whether the inputted array is 2 dimensional array. Default is true.\n       * @return {Array} Transposed array.\n       */\n      function transpose(array, check = true) {\n        if (check && !is2DimensionalArray(array)) {\n          throw new Error(\"Please use 2 dimensional array.\");\n        }\n        return array[0].map((_, col) => array.map((row) => row[col] || null));\n      }\n      return transpose(array);\n    },\n    removeDuplicatedValues: function removeDuplicatedValues(array) {\n      /**\n       * ### Description\n       * Remove duplicated values from 1 dimensional array.\n       *\n       * @param {Array} array 1 dimensional array.\n       * @return {Object} Object including removeDuplicatedValues, duplicatedValues and numberOfDuplicate.\n       */\n      function removeDuplicatedValues(array) {\n        if (!Array.isArray(array)) {\n          throw new Error(\"Please use 1 dimensional array.\");\n        }\n        const obj = array.reduce(\n          (m, e) => m.set(e, m.has(e) ? m.get(e) + 1 : 1),\n          new Map()\n        );\n        const e = [...obj.entries()];\n        return {\n          removeDuplicatedValues: [...obj.keys()],\n          duplicatedValues: e.reduce((ar, [k, v]) => {\n            if (v != 1) ar.push(k);\n            return ar;\n          }, []),\n          numberOfDuplicate: Object.fromEntries(e),\n        };\n      }\n      return removeDuplicatedValues(array);\n    },\n    compilingNumbers: function compilingNumbers(array) {\n      /**\n       * ### Description\n       * Compiling Continuous Numbers using Google Apps Script.\n       *\n       * @param {Array} array Input array.\n       * @return {Array} Array including object like [{\"start\":1,\"end\":1},{\"start\":3,\"end\":5},{\"start\":7,\"end\":7},{\"start\":9,\"end\":11},{\"start\":13,\"end\":13}].\n       */\n      function compilingNumbers(array) {\n        if (!(Array.isArray(array) && array.every((e) => !isNaN(e)))) {\n          throw new Error(\"Please give an array including numbers.\");\n        }\n        const { values } = [...new Set(array.sort((a, b) => a - b))].reduce(\n          (o, e, i, a) => {\n            if (\n              o.temp.length == 0 ||\n              (o.temp.length > 0 && e == o.temp[o.temp.length - 1] + 1)\n            ) {\n              o.temp.push(e);\n            } else {\n              if (o.temp.length > 0) {\n                o.values.push({\n                  start: o.temp[0],\n                  end: o.temp[o.temp.length - 1],\n                });\n              }\n              o.temp = [e];\n            }\n            if (i == a.length - 1) {\n              o.values.push(\n                o.temp.length > 1\n                  ? { start: o.temp[0], end: o.temp[o.temp.length - 1] }\n                  : { start: e, end: e }\n              );\n            }\n            return o;\n          },\n          { temp: [], values: [] }\n        );\n        return values;\n      }\n      return compilingNumbers(array);\n    },\n    unpivot: function unpivot(values) {\n      /**\n       * ### Description\n       * When the inputted array is 2 dimensional array, true is returned.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @return {Boolean} When the inputted array is 2 dimensional array, true is returned.\n       */\n      function is2DimensionalArray(array) {\n        return array.every((r) => Array.isArray(r));\n      }\n\n      /**\n       * ### Description\n       * Converting 2-dimensional array as unpivot (reverse pivot).\n       *\n       * @param {Array} values 2 dimensional array.\n       * @return {Array} 2 dimensional array converted as unpivot (reverse pivot).\n       */\n      function unpivot(values) {\n        if (!Array.isArray(values) || !is2DimensionalArray(values)) {\n          throw new Error(\"Please give an array of values.\");\n        }\n        const [[, ...h], ...v] = values;\n        return h.flatMap((hh, i) => v.map((t) => [hh, t[0], t[i + 1]]));\n      }\n      return unpivot(values);\n    },\n    expandA1Notations: function expandA1Notations(a1Notations) {\n      /**\n       * ### Description\n       * Converting colum letter to column index. Start of column index is 0.\n       * @param {String} letter Column letter.\n       * @return {Number} Column index.\n       */\n      function columnLetterToIndex(letter = null) {\n        if (letter === null || typeof letter != \"string\") {\n          throw new Error(\"Please give the column letter as a string.\");\n        }\n        letter = letter.toUpperCase();\n        return [...letter].reduce(\n          (c, e, i, a) =>\n            (c += (e.charCodeAt(0) - 64) * Math.pow(26, a.length - i - 1)),\n          -1\n        );\n      }\n\n      /**\n       * ### Description\n       * Converting colum index to column letter. Start of column index is 0.\n       * Ref: https://stackoverflow.com/a/53678158/7108653\n       * @param {Number} index Column index.\n       * @return {String} Column letter.\n       */\n      function columnIndexToLetter(index = null) {\n        if (index === null || isNaN(index)) {\n          throw new Error(\n            \"Please give the column indexr as a number. In this case, 1st number is 0.\"\n          );\n        }\n        return (a = Math.floor(index / 26)) >= 0\n          ? columnIndexToLetter(a - 1) + String.fromCharCode(65 + (index % 26))\n          : \"\";\n      }\n\n      /**\n       * ### Description\n       * This method is used for expanding A1Notations.\n       * @param {Array} a1Notations Array including A1Notations.\n       * @return {Array} Array including the expanded A1Notations.\n       */\n      function expandA1Notations(a1Notations, maxRow = \"10\", maxColumn = \"Z\") {\n        if (!Array.isArray(a1Notations) || a1Notations.length == 0) {\n          throw new Error(\"Please give a1Notations (Array).\");\n        }\n        const reg1 = new RegExp(\"^([A-Z]+)([0-9]+)$\");\n        const reg2 = new RegExp(\"^([A-Z]+)$\");\n        const reg3 = new RegExp(\"^([0-9]+)$\");\n        return a1Notations.map((e) => {\n          const a1 = e.split(\"!\");\n          const r = a1.length > 1 ? a1[1] : a1[0];\n          const [r1, r2] = r.split(\":\");\n          if (!r2) return [r1];\n          let rr;\n          if (reg1.test(r1) && reg1.test(r2)) {\n            rr = [r1.toUpperCase().match(reg1), r2.toUpperCase().match(reg1)];\n          } else if (reg2.test(r1) && reg2.test(r2)) {\n            rr = [\n              [null, r1, 1],\n              [null, r2, maxRow],\n            ];\n          } else if (reg1.test(r1) && reg2.test(r2)) {\n            rr = [r1.toUpperCase().match(reg1), [null, r2, maxRow]];\n          } else if (reg2.test(r1) && reg1.test(r2)) {\n            rr = [[null, r1, maxRow], r2.toUpperCase().match(reg1)];\n          } else if (reg3.test(r1) && reg3.test(r2)) {\n            rr =\n              Number(r1) > Number(r2)\n                ? [\n                    [null, \"A\", r2],\n                    [null, maxColumn, r1],\n                  ]\n                : [\n                    [null, \"A\", r1],\n                    [null, maxColumn, r2],\n                  ];\n          } else if (reg1.test(r1) && reg3.test(r2)) {\n            rr = [r1.toUpperCase().match(reg1), [null, maxColumn, r2]];\n          } else if (reg3.test(r1) && reg1.test(r2)) {\n            let temp = r2.toUpperCase().match(reg1);\n            rr =\n              Number(temp[2]) > Number(r1)\n                ? [\n                    [null, temp[1], r1],\n                    [null, maxColumn, temp[2]],\n                  ]\n                : [temp, [null, maxColumn, r1]];\n          } else {\n            throw new Error(\"Wrong a1Notation: \" + r);\n          }\n          const obj = {\n            startRowIndex: Number(rr[0][2]),\n            endRowIndex:\n              rr.length == 1 ? Number(rr[0][2]) + 1 : Number(rr[1][2]) + 1,\n            startColumnIndex: columnLetterToIndex(rr[0][1]),\n            endColumnIndex:\n              rr.length == 1\n                ? columnLetterToIndex(rr[0][1]) + 1\n                : columnLetterToIndex(rr[1][1]) + 1,\n          };\n          let temp = [];\n          for (let i = obj.startRowIndex; i < obj.endRowIndex; i++) {\n            for (let j = obj.startColumnIndex; j < obj.endColumnIndex; j++) {\n              temp.push(columnIndexToLetter(j) + i);\n            }\n          }\n          return temp;\n        });\n      }\n      return expandA1Notations(a1Notations);\n    },\n  };\n\n  const g = GeminiWithFiles.geminiWithFiles({\n    apiKey,\n    response_mime_type: \"application/json\",\n    doCountToken: true,\n  });\n\n  const functions = Object.entries(functionObj)\n    .map(\n      ([k, v]) =>\n        `<FunctionName>${k}</FunctionName><Function>${v.toString()}</Function>`\n    )\n    .join(\"\");\n  const jsonSchema = {\n    title: \"5 input values for giving each function\",\n    description: `Proposal 5 input values for giving each function. ${functions} Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n    type: \"array\",\n    items: {\n      type: \"object\",\n      properties: {\n        functionName: { description: \"Function name\", type: \"string\" },\n        inputValues: {\n          description: `Proposed 5 input values. Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n          type: \"array\",\n          items: {\n            description: \"Proposed input value\",\n            type: \"array|object|string|number\",\n          },\n        },\n      },\n      additionalProperties: false,\n    },\n  };\n  let res = g.generateContent({ jsonSchema });\n  if (typeof res == \"string\") {\n    try {\n      res = JSON.parse(res);\n    } catch ({ stack }) {\n      console.error(stack);\n      return;\n    }\n  }\n  const result = res.reduce((o, { functionName, inputValues }) => {\n    try {\n      o[functionName] = [];\n      inputValues.forEach((input) => {\n        const output = functionObj[functionName](input);\n        o[functionName].push({ input, output });\n      });\n    } catch ({ stack }) {\n      console.log(stack);\n    }\n    return o;\n  }, {});\n  console.log(JSON.stringify(result));\n}\n```\nËøêË°åÊ≠§ËÑöÊú¨ÂêéÔºåËé∑Âæó‰ª•‰∏ãÁªìÊûú„ÄÇÂèØ‰ª•ÁúãÂà∞ÊúâÊïàÁöÑËæìÂÖ•ÂíåËæìÂá∫ÂÄºÂ∑≤Ë¢´ÂàõÂª∫„ÄÇ\n\n```python\n{\n  \"transpose\": [\n    { \"input\": [[1, 2], [3, 4]], \"output\": [[1, 3], [2, 4]] },\n    { \"input\": [[\"a\", \"b\"], [\"c\", \"d\"]], \"output\": [[\"a\", \"c\"], [\"b\", \"d\"]] },\n    { \"input\": [[\"a1\", \"b1\"], [\"c1\", \"d1\"], [\"e1\", \"f1\"]], \"output\": [[\"a1\", \"c1\", \"e1\"], [\"b1\", \"d1\", \"f1\"]] },\n    { \"input\": [[true, false], [false, true]], \"output\": [[true, null], [null, true]] },\n    { \"input\": [[1, \"a\"], [\"c\", true]], \"output\": [[1, \"c\"], [\"a\", true]] }\n  ],\n\n  \"removeDuplicatedValues\": [\n    { \"input\": [1, 2, 3, 4, 5], \"output\": { \"removeDuplicatedValues\": [1, 2, 3, 4, 5], \"duplicatedValues\": [], \"numberOfDuplicate\": { \"1\": 1, \"2\": 1, \"3\": 1, \"4\": 1, \"5\": 1 } } },\n    { \"input\": [\"a\", \"b\", \"c\", \"d\", \"e\"], \"output\": { \"removeDuplicatedValues\": [\"a\", \"b\", \"c\", \"d\", \"e\"], \"duplicatedValues\": [], \"numberOfDuplicate\": { \"a\": 1, \"b\": 1, \"c\": 1, \"d\": 1, \"e\": 1 } } },\n    { \"input\": [1, 2, 1, 3, 2, 4, 3, 5, 4], \"output\": { \"removeDuplicatedValues\": [1, 2, 3, 4, 5], \"duplicatedValues\": [1, 2, 3, 4], \"numberOfDuplicate\": { \"1\": 2, \"2\": 2, \"3\": 2, \"4\": 2, \"5\": 1 } } },\n    { \"input\": [\"a\", \"b\", \"a\", \"c\", \"b\", \"d\", \"c\", \"e\", \"d\"], \"output\": { \"removeDuplicatedValues\": [\"a\", \"b\", \"c\", \"d\", \"e\"], \"duplicatedValues\": [\"a\", \"b\", \"c\", \"d\"], \"numberOfDuplicate\": { \"a\": 2, \"b\": 2, \"c\": 2, \"d\": 2, \"e\": 1 } } },\n    { \"input\": [1, \"a\", 2, \"b\", 1, \"c\", 2, \"d\", 1, \"e\"], \"output\": { \"removeDuplicatedValues\": [1, \"a\", 2, \"b\", \"c\", \"d\", \"e\"], \"duplicatedValues\": [1, 2], \"numberOfDuplicate\": { \"1\": 3, \"2\": 2, \"a\": 1, \"b\": 1, \"c\": 1, \"d\": 1, \"e\": 1 } } }\n  ],\n\n  \"compilingNumbers\": [\n    { \"input\": [1, 2, 3, 4, 5], \"output\": [{ \"start\": 1, \"end\": 5 }] },\n    { \"input\": [1, 3, 5, 7, 9, 11, 13], \"output\": [{ \"start\": 1, \"end\": 1 }, { \"start\": 3, \"end\": 3 }, { \"start\": 5, \"end\": 5 }, { \"start\": 7, \"end\": 7 }, { \"start\": 9, \"end\": 9 }, { \"start\": 11, \"end\": 11 }, { \"start\": 13, \"end\": 13 }] },\n    { \"input\": [1, 3, 5, 7, 8, 10, 12, 13], \"output\": [{ \"start\": 1, \"end\": 1 }, { \"start\": 3, \"end\": 3 }, { \"start\": 5, \"end\": 5 }, { \"start\": 7, \"end\": 8 }, { \"start\": 10, \"end\": 10 }, { \"start\": 12, \"end\": 13 }] },\n    { \"input\": [1, 2, 4, 5, 7, 8, 10, 11, 13, 14], \"output\": [{ \"start\": 1, \"end\": 2 }, { \"start\": 4, \"end\": 5 }, { \"start\": 7, \"end\": 8 }, { \"start\": 10, \"end\": 11 }, { \"start\": 13, \"end\": 14 }] },\n    { \"input\": [1, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15], \"output\": [{ \"start\": 1, \"end\": 3 }, { \"start\": 5, \"end\": 6 }, { \"start\": 8, \"end\": 9 }, { \"start\": 11, \"end\": 12 }, { \"start\": 14, \"end\": 15 }] }\n  ],\n\n  \"unpivot\": [\n    { \"input\": [[\"name\", \"score1\", \"score2\"], [\"sample1\", 100, 80], [\"sample2\", 90, 70]], \"output\": [[\"score1\", \"sample1\", 100], [\"score1\", \"sample2\", 90], [\"score2\", \"sample1\", 80], [\"score2\", \"sample2\", 70]] },\n    { \"input\": [[\"name\", \"score1\", \"score2\", \"score3\"], [\"sample1\", 100, 80, 70], [\"sample2\", 90, 70, 80]], \"output\": [[\"score1\", \"sample1\", 100], [\"score1\", \"sample2\", 90], [\"score2\", \"sample1\", 80], [\"score2\", \"sample2\", 70], [\"score3\", \"sample1\", 70], [\"score3\", \"sample2\", 80]] },\n    { \"input\": [[\"id\", \"x\", \"y\", \"z\"], [\"a\", 1, 2, 3], [\"b\", 4, 5, 6]], \"output\": [[\"x\", \"a\", 1], [\"x\", \"b\", 4], [\"y\", \"a\", 2], [\"y\", \"b\", 5], [\"z\", \"a\", 3], [\"z\", \"b\", 6]] },\n    { \"input\": [[\"id\", \"x\", \"y\", \"z\", \"xx\", \"yy\", \"zz\"], [\"a\", 1, 2, 3, 10, 20, 30], [\"b\", 4, 5, 6, 40, 50, 60]], \"output\": [[\"x\", \"a\", 1], [\"x\", \"b\", 4], [\"y\", \"a\", 2], [\"y\", \"b\", 5], [\"z\", \"a\", 3], [\"z\", \"b\", 6], [\"xx\", \"a\", 10], [\"xx\", \"b\", 40], [\"yy\", \"a\", 20], [\"yy\", \"b\", 50], [\"zz\", \"a\", 30], [\"zz\", \"b\", 60]] },\n    { \"input\": [[\"Fruit\", \"2021\", \"2022\", \"2023\"], [\"apple\", 100, 120, 150], [\"orange\", 80, 90, 100]], \"output\": [[\"2021\", \"apple\", 100], [\"2021\", \"orange\", 80], [\"2022\", \"apple\", 120], [\"2022\", \"orange\", 90], [\"2023\", \"apple\", 150], [\"2023\", \"orange\", 100]] }\n  ],\n\n  \"expandA1Notations\": [\n    { \"input\": [\"A1:B5\", \"C3:D7\", \"E2:F10\"], \"output\": [[\"A1\", \"B1\", \"A2\", \"B2\", \"A3\", \"B3\", \"A4\", \"B4\", \"A5\", \"B5\"], [\"C3\", \"D3\", \"C4\", \"D4\", \"C5\", \"D5\", \"C6\", \"D6\", \"C7\", \"D7\"], [\"E2\", \"F2\", \"E3\", \"F3\", \"E4\", \"F4\", \"E5\", \"F5\", \"E6\", \"F6\", \"E7\", \"F7\", \"E8\", \"F8\", \"E9\", \"F9\", \"E10\", \"F10\"]] },\n    { \"input\": [\"A:B\", \"C:D\", \"E:F\"], \"output\": [[\"A1\", \"B1\", \"A2\", \"B2\", \"A3\", \"B3\", \"A4\", \"B4\", \"A5\", \"B5\", \"A6\", \"B6\", \"A7\", \"B7\", \"A8\", \"B8\", \"A9\", \"B9\", \"A10\", \"B10\"], [\"C1\", \"D1\", \"C2\", \"D2\", \"C3\", \"D3\", \"C4\", \"D4\", \"C5\", \"D5\", \"C6\", \"D6\", \"C7\", \"D7\", \"C8\", \"D8\", \"C9\", \"D9\", \"C10\", \"D10\"], [\"E1\", \"F1\", \"E2\", \"F2\", \"E3\", \"F3\", \"E4\", \"F4\", \"E5\", \"F5\", \"E6\", \"F6\", \"E7\", \"F7\", \"E8\", \"F8\", \"E9\", \"F9\", \"E10\", \"F10\"]] },\n    { \"input\": [\"A1:C5\"], \"output\": [[\"A1\", \"B1\", \"C1\", \"A2\", \"B2\", \"C2\", \"A3\", \"B3\", \"C3\", \"A4\", \"B4\", \"C4\", \"A5\", \"B5\", \"C5\"]] },\n    { \"input\": [\"A:C\"], \"output\": [[\"A1\", \"B1\", \"C1\", \"A2\", \"B2\", \"C2\", \"A3\", \"B3\", \"C3\", \"A4\", \"B4\", \"C4\", \"A5\", \"B5\", \"C5\", \"A6\", \"B6\", \"C6\", \"A7\", \"B7\", \"C7\", \"A8\", \"B8\", \"C8\", \"A9\", \"B9\", \"C9\", \"A10\", \"B10\", \"C10\"]] },\n    { \"input\": [\"1:5\", \"3:7\", \"2:10\"], \"output\": [[\"A1\", \"B1\", \"C1\", \"D1\", \"E1\", \"F1\", \"G1\", \"H1\", \"I1\", \"J1\", \"K1\", \"L1\", \"M1\", \"N1\", \"O1\", \"P1\", \"Q1\", \"R1\", \"S1\", \"T1\", \"U1\", \"V1\", \"W1\", \"X1\", \"Y1\", \"Z1\", \"A2\", \"B2\", \"C2\", \"D2\", \"E2\", \"F2\", \"G2\", \"H2\", \"I2\", \"J2\", \"K2\", \"L2\", \"M2\", \"N2\", \"O2\", \"P2\", \"Q2\", \"R2\", \"S2\", \"T2\", \"U2\", \"V2\", \"W2\", \"X2\", \"Y2\", \"Z2\", \"A3\", \"B3\", \"C3\", \"D3\", \"E3\", \"F3\", \"G3\", \"H3\", \"I3\", \"J3\", \"K3\", \"L3\", \"M3\", \"N3\", \"O3\", \"P3\", \"Q3\", \"R3\", \"S3\", \"T3\", \"U3\", \"V3\", \"W3\", \"X3\", \"Y3\", \"Z3\", \"A4\", \"B4\", \"C4\", \"D4\", \"E4\", \"F4\", \"G4\", \"H4\", \"I4\", \"J4\", \"K4\", \"L4\", \"M4\", \"N4\", \"O4\", \"P4\", \"Q4\", \"R4\", \"S4\", \"T4\", \"U4\", \"V4\", \"W4\", \"X4\", \"Y4\", \"Z4\", \"A5\", \"B5\", \"C5\", \"D5\", \"E5\", \"F5\", \"G5\", \"H5\", \"I5\", \"J5\", \"K5\", \"L5\", \"M5\", \"N5\", \"O5\", \"P5\", \"Q5\", \"R5\", \"S5\", \"T5\", \"U5\", \"V5\", \"W5\", \"X5\", \"Y5\", \"Z5\"], [\"A3\", \"B3\", \"C3\", \"D3\", \"E3\", \"F3\", \"G3\", \"H3\", \"I3\", \"J3\", \"K3\", \"L3\", \"M3\", \"N3\", \"O3\", \"P3\", \"Q3\", \"R3\", \"S3\", \"T3\", \"U3\", \"V3\", \"W3\", \"X3\", \"Y3\", \"Z3\", \"A4\", \"B4\", \"C4\", \"D4\", \"E4\", \"F4\", \"G4\", \"H4\", \"I4\", \"J4\", \"K4\", \"L4\", \"M4\", \"N4\", \"O4\", \"P4\", \"Q4\", \"R4\", \"S4\", \"T4\", \"U4\", \"V4\", \"W4\", \"X4\", \"Y4\", \"Z4\", \"A5\", \"B5\", \"C5\", \"D5\", \"E5\", \"F5\", \"G5\", \"H5\", \"I5\", \"J5\", \"K5\", \"L5\", \"M5\", \"N5\", \"O5\", \"P5\", \"Q5\", \"R5\", \"S5\", \"T5\", \"U5\", \"V5\", \"W5\", \"X5\", \"Y5\", \"Z5\", \"A6\", \"B6\", \"C6\", \"D6\", \"E6\", \"F6\", \"G6\", \"H6\", \"I6\", \"J6\", \"K6\", \"L6\", \"M6\", \"N6\", \"O6\", \"P6\", \"Q6\", \"R6\", \"S6\", \"T6\", \"U6\", \"V6\", \"W6\", \"X6\", \"Y6\", \"Z6\", \"A7\", \"B7\", \"C7\", \"D7\", \"E7\", \"F7\", \"G7\", \"H7\", \"I7\", \"J7\", \"K7\", \"L7\", \"M7\", \"N7\", \"O7\", \"P7\", \"Q7\", \"R7\", \"S7\", \"T7\", \"U7\", \"V7\", \"W7\", \"X7\", \"Y7\", \"Z7\"], [\"A2\", \"B2\", \"C2\", \"D2\", \"E2\", \"F2\", \"G2\", \"H2\", \"I2\", \"J2\", \"K2\", \"L2\", \"M2\", \"N2\", \"O2\", \"P2\", \"Q2\", \"R2\", \"S2\", \"T2\", \"U2\", \"V2\", \"W2\", \"X2\", \"Y2\", \"Z2\", \"A3\", \"B3\", \"C3\", \"D3\", \"E3\", \"F3\", \"G3\", \"H3\", \"I3\", \"J3\", \"K3\", \"L3\", \"M3\", \"N3\", \"O3\", \"P3\", \"Q3\", \"R3\", \"S3\", \"T3\", \"U3\", \"V3\", \"W3\", \"X3\", \"Y3\", \"Z3\", \"A4\", \"B4\", \"C4\", \"D4\", \"E4\", \"F4\", \"G4\", \"H4\", \"I4\", \"J4\", \"K4\", \"L4\", \"M4\", \"N4\", \"O4\", \"P4\", \"Q4\", \"R4\", \"S4\", \"T4\", \"U4\", \"V4\", \"W4\", \"X4\", \"Y4\", \"Z4\", \"A5\", \"B5\", \"C5\", \"D5\", \"E5\", \"F5\", \"G5\", \"H5\", \"I5\", \"J5\", \"K5\", \"L5\", \"M5\", \"N5\", \"O5\", \"P5\", \"Q5\", \"R5\", \"S5\", \"T5\", \"U5\", \"V5\", \"W5\", \"X5\", \"Y5\", \"Z5\", \"A6\", \"B6\", \"C6\", \"D6\", \"E6\", \"F6\", \"G6\", \"H6\", \"I6\", \"J6\", \"K6\", \"L6\", \"M6\", \"N6\", \"O6\", \"P6\", \"Q6\", \"R6\", \"S6\", \"T6\", \"U6\", \"V6\", \"W6\", \"X6\", \"Y6\", \"Z6\", \"A7\", \"B7\", \"C7\", \"D7\", \"E7\", \"F7\", \"G7\", \"H7\", \"I7\", \"J7\", \"K7\", \"L7\", \"M7\", \"N7\", \"O7\", \"P7\", \"Q7\", \"R7\", \"S7\", \"T7\", \"U7\", \"V7\", \"W7\", \"X7\", \"Y7\", \"Z7\", \"A8\", \"B8\", \"C8\", \"D8\", \"E8\", \"F8\", \"G8\", \"H8\", \"I8\", \"J8\", \"K8\", \"L8\", \"M8\", \"N8\", \"O8\", \"P8\", \"Q8\", \"R8\", \"S8\", \"T8\", \"U8\", \"V8\", \"W8\", \"X8\", \"Y8\", \"Z8\", \"A9\", \"B9\", \"C9\", \"D9\", \"E9\", \"F9\", \"G9\", \"H9\", \"I9\", \"J9\", \"K9\", \"L9\", \"M9\", \"N9\", \"O9\", \"P9\", \"Q9\", \"R9\", \"S9\", \"T9\", \"U9\", \"V9\", \"W9\", \"X9\", \"Y9\", \"Z9\", \"A10\", \"B10\", \"C10\", \"D10\", \"E10\", \"F10\", \"G10\", \"H10\", \"I10\", \"J10\", \"K10\", \"L10\", \"M10\", \"N10\", \"O10\", \"P10\", \"Q10\", \"R10\", \"S10\", \"T10\", \"U10\", \"V10\", \"W10\", \"X10\", \"Y10\", \"Z10\"]] }\n  ]\n}\n```\n\n## 5\\. Á§∫‰æãËÑöÊú¨ 2\n\n‰∏äËø∞Á§∫‰æãËÑöÊú¨ÁöÑÊØè‰∏™ÂáΩÊï∞‰ªÖ‰ΩøÁî®‰∏Ä‰∏™ÂèÇÊï∞„ÄÇÂΩì‰ΩøÁî®Â§ö‰∏™ÂèÇÊï∞Êó∂ÔºåËÑöÊú¨Â¶Ç‰∏ã„ÄÇÁ§∫‰æãÂáΩÊï∞Â¶Ç‰∏ã„ÄÇ\n\n* [splitArray](https://github.com/tanaikech/UtlApp?tab=readme-ov-file#splitarray): ÊØè n ÈïøÂ∫¶ÊãÜÂàÜÊï∞ÁªÑ„ÄÇ\n\n\n```python\nfunction myFunction() {\n\n  const apiKey = \"###\"; // Please set your API key.\n\n  const functionObj = {\n    splitArray: function splitArray(array, size) {\n      /**\n       * ### Description\n       * Split array every n length.\n       *\n       * @param {Array} array 2 dimensional array.\n       * @param {Boolean} check Check whether the inputted array is 2 dimensional array. Default is true.\n       * @return {Array} Transposed array.\n       */\n      function splitArray(array, size) {\n        if (!array || !size || !Array.isArray(array)) {\n          throw new Error(\"Please give an array and split size.\");\n        }\n        return [...Array(Math.ceil(array.length / size))].map((_) =>\n          array.splice(0, size)\n        );\n      }\n      return splitArray(array, size);\n    },\n  };\n\n  const g = GeminiWithFiles.geminiWithFiles({\n    apiKey,\n    response_mime_type: \"application/json\",\n    doCountToken: true,\n  });\n\n  const functions = Object.entries(functionObj)\n    .map(\n      ([k, v]) =>\n        `<FunctionName>${k}</FunctionName><Function>${v.toString()}</Function>`\n    )\n    .join(\"\");\n  const jsonSchema = {\n    title: \"5 input values for giving each function\",\n    description: `Proposal 5 input values for giving each function. ${functions} Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n    type: \"array\",\n    items: {\n      type: \"object\",\n      properties: {\n        functionName: { description: \"Function name\", type: \"string\" },\n        inputValues: {\n          description: `Proposed 5 input values. Don't propose \"empty\", \"null\", \"undefined\" as values.`,\n          type: \"array\",\n          items: {\n            description: \"Proposed input value\",\n            type: \"array|object|string|number\",\n          },\n        },\n      },\n      additionalProperties: false,\n    },\n  };\n  let res = g.generateContent({ jsonSchema });\n  if (typeof res == \"string\") {\n    try {\n      res = JSON.parse(res);\n    } catch ({ stack }) {\n      console.error(stack);\n      return;\n    }\n  }\n  const result = res.reduce((o, { functionName, inputValues }) => {\n    try {\n      o[functionName] = [];\n      inputValues.forEach((input) => {\n        const temp = JSON.parse(JSON.stringify(input));\n        const output = functionObj[functionName](...temp);\n        o[functionName].push({ input, output });\n      });\n    } catch ({ stack }) {\n      console.log(stack);\n    }\n    return o;\n  }, {});\n  console.log(JSON.stringify(result));\n}\n```\nËøêË°åÊ≠§ËÑöÊú¨Êó∂ÔºåÂ∞ÜËé∑Âæó‰ª•‰∏ãÁªìÊûú„ÄÇ\n\n\n```python\n{\n  \"splitArray\": [\n    { \"input\": [[1, 2, 3, 4, 5, 6], 2], \"output\": [[1, 2], [3, 4], [5, 6]] },\n    { \"input\": [[\"a\", \"b\", \"c\", \"d\", \"e\"], 2], \"output\": [[\"a\", \"b\"], [\"c\", \"d\"], [\"e\"]] },\n    { \"input\": [[\"apple\", \"orange\", \"grape\", \"banana\", \"kiwi\"], 3], \"output\": [[\"apple\", \"orange\", \"grape\"], [\"banana\", \"kiwi\"]] },\n    { \"input\": [[true, false, true, false, true], 1], \"output\": [[true], [false], [true], [false], [true]] },\n    { \"input\": [[1.2, 3.14, 2.71, 0.577], 2], \"output\": [[1.2, 3.14], [2.71, 0.577]] }\n  ]\n}\n```\n\n## ÊëòË¶Å\n\n‰ªé‰∏äËø∞ÁªìÊûúÊù•ÁúãÔºåÊàë‰ª¨ÂèØ‰ª•Á°ÆËÆ§‰ΩøÁî® Gemini API ËøõË°åÈÄÜÂêëÂ∑•Á®ãÁöÑÂèØËÉΩÊÄß„ÄÇËøô‰πüË°®Êòé Gemini API ÂèØ‰ª•Áî®‰∫éÂºÄÂèëÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n## Ê≥®ÊÑè\n\n* Â¶ÇÊûúÂèëÁîüÈîôËØØÔºåËØ∑ÂÜçÊ¨°ËøêË°åËÑöÊú¨„ÄÇÊàñËÄÖÔºåËØ∑Ë∞ÉÊï¥ JSON Êû∂ÊûÑ‰∏≠ÁöÑÊèèËø∞„ÄÇ\n* ÊàëÁõ∏‰ø°ËøôÁßçÊñπÊ≥ï‰πüÂèØ‰ª•Áî®‰∫éÈô§ Google Apps Script ‰πãÂ§ñÁöÑÂÖ∂‰ªñËØ≠Ë®Ä„ÄÇ\n* Âú®ÂΩìÂâçÈò∂ÊÆµÔºå‰ºº‰πé‰æùËµñ‰∫é Google Apps Script ÁöÑÁ±ªÂØπË±°ÔºåÂ¶Ç SpreadsheetApp„ÄÅDriveApp Á≠âÔºåÊó†Ê≥ïÁî®‰ΩúËæìÂÖ•ÂÄº„ÄÇ\n* È°∂ÈÉ®ÁöÑÊäΩË±°ÂõæÂÉèÊòØÁî± [Gemini](https://gemini.google.com/app) ÂàõÂª∫ÁöÑ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/leveraging-large-language-models-llms-in-b2c-industries-transforming-customer-experience-with-4073990a6200","frontmatter":{"title":"Âú® B2C Ë°å‰∏ö‰∏≠Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)ÔºöÂú® B2C Ë°å‰∏ö‰∏≠Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)Ôºö...","meta_title":"Âú® B2C Ë°å‰∏ö‰∏≠Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)ÔºöÂú® B2C Ë°å‰∏ö‰∏≠Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)Ôºö...","description":"Âú®B2CË°å‰∏ö‰∏≠Ôºå‰ºÅ‰∏öÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂíåËá™‰∏ª‰ª£ÁêÜÊòæËëóÊèêÂçáÂÆ¢Êà∑‰ΩìÈ™åÔºåÂ∞§ÂÖ∂Âú®ÈáëËûçÊúçÂä°„ÄÅÈõ∂ÂîÆÂíåÁîµÂ≠êÂïÜÂä°È¢ÜÂüü„ÄÇÈÄöËøáÂü∫‰∫éÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÁöÑÊñπÊ≥ïÔºåËøô‰∫õ‰ª£ÁêÜËÉΩÂ§üÊèê‰æõÂÆûÊó∂„ÄÅÊô∫ËÉΩÁöÑÂìçÂ∫îÔºåÂ¢ûÂº∫ÂÆ¢Êà∑Êª°ÊÑèÂ∫¶Âπ∂Èôç‰ΩéÂØπ‰∫∫Â∑•ÊîØÊåÅÁöÑ‰æùËµñ„ÄÇÊñáÁ´†ËØ¶ÁªÜ‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÂàõÂª∫‰∏Ä‰∏™Â§ÑÁêÜ‰ø°Áî®Âç°Êü•ËØ¢ÁöÑËá™‰∏ª‰ª£ÁêÜÔºåÂåÖÊã¨Êï∞ÊçÆÊ∫êÁöÑ‰ΩøÁî®„ÄÅÂµåÂÖ•‰∏éÂêëÈáèÊï∞ÊçÆÂ∫ìÁöÑÂàõÂª∫„ÄÅÊèêÁ§∫Â∑•Á®ãÁöÑÂ∫îÁî®Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöËøáFlaskÊàñStreamlitËøõË°åÈÉ®ÁΩ≤ÔºåÂ±ïÁé∞‰∫ÜLLMsÂú®Êèê‰æõ‰∏™ÊÄßÂåñÂÆ¢Êà∑ÊúçÂä°ÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Zf15fyqPpBcoEHf6G5rgbw.jpeg","categories":["Programming","Machine Learning","Chatbots"],"author":"Rifx.Online","tags":["LLMs","RAG","embeddings","vector","Flask"],"draft":false,"slug":"blog/leveraging-large-language-models-llms-in-b2c-industries-transforming-customer-experience-with-4073990a6200"},"content":"\n\n\n\n\nÂú®ÈáëËûçÊúçÂä°„ÄÅÈõ∂ÂîÆÂíåÁîµÂ≠êÂïÜÂä°Á≠âB2CË°å‰∏öÂø´ÈÄüÂèëÂ±ïÁöÑÁéØÂ¢É‰∏≠ÔºåÂÆ¢Êà∑ÂØπ‰∏™ÊÄßÂåñÂíåÂç≥Êó∂ÂìçÂ∫îÁöÑÊúüÊúõËææÂà∞‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÈ´òÂ∫¶„ÄÇÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑËøõÊ≠•ÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÂèëÂ±ïÔºå‰ºÅ‰∏öÂú®Â§ÑÁêÜÂÆ¢Êà∑‰∫íÂä®ÊñπÈù¢ÂèëÁîü‰∫ÜÂâßÁÉàÂèòÂåñ„ÄÇÂú®Èì∂Ë°åÂíå‰ø°Áî®Âç°ÊúçÂä°Á≠âË°å‰∏öÔºåÂÆ¢Êà∑ÁªèÂ∏∏ÂØªÊ±ÇÊúâÂÖ≥‰∫ßÂìÅ„ÄÅÁ¶èÂà©Êàñ‰∫§ÊòìÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåÂõ†Ê≠§ÈááÁî®Âü∫‰∫éLLMÁöÑËá™‰∏ª‰ª£ÁêÜÊèê‰æõ‰∫ÜÊòæËëóÁöÑ‰ºòÂäø„ÄÇËøô‰∫õ‰ª£ÁêÜËÉΩÂ§üÊèê‰æõÂÆûÊó∂„ÄÅÊô∫ËÉΩÁöÑÂìçÂ∫îÔºåËΩ¨ÂèòÂÆ¢Êà∑ÂèÇ‰∏éÊñπÂºèÔºåÂêåÊó∂ÊèêÈ´òËøêËê•ÊïàÁéá„ÄÇ\n\nÊ†πÊçÆÊàëÂú®ÈáëËûçÊúçÂä°Ë°å‰∏öAI‰∫ßÂìÅÂºÄÂèëÁöÑÁªèÈ™åÔºåËøô‰∫õÂü∫‰∫éLLMÁöÑ‰ª£ÁêÜÂú®Ê≠£Á°ÆÂÆûÊñΩÊó∂ÔºåÂèØ‰ª•Êàê‰∏∫Ê∏∏ÊàèËßÑÂàôÁöÑÊîπÂèòËÄÖ„ÄÇÂÆÉ‰ª¨Êèê‰æõÂèØÊâ©Â±ïÁöÑ„ÄÅ‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÂÆ¢Êà∑ÊîØÊåÅÔºå‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ÔºåËøòÂáèÂ∞ë‰∫ÜÂØπ‰∫∫Â∑•‰ª£ÁêÜÁöÑ‰æùËµñ„ÄÇ‰ΩÜÊàë‰ª¨Â¶Ç‰ΩïÂºÄÂèëËøô‰∫õÊô∫ËÉΩÁ≥ªÁªüÂë¢Ôºü‰∏ãÈù¢ÔºåÊàëÂ∞ÜÂ∏¶ÊÇ®‰∫ÜËß£ÂàõÂª∫‰∏Ä‰∏™Áî®‰∫éÂ§ÑÁêÜ‰∏é‰ø°Áî®Âç°‰∫ßÂìÅÁõ∏ÂÖ≥ÁöÑÂÆ¢Êà∑Êü•ËØ¢ÁöÑ‰ª£ÁêÜÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÁ≥ªÁªüÁöÑ‰∏öÂä°ÈóÆÈ¢òÔºåÂπ∂Ëß£ÈáäLLMs„ÄÅÂµåÂÖ•„ÄÅÂêëÈáèÊï∞ÊçÆÂ∫ìÂíåÊèêÁ§∫Â∑•Á®ãÂ¶Ç‰ΩïÂú®Ëøô‰∏™Ëß£ÂÜ≥ÊñπÊ°à‰∏≠ÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇ\n\n## ÂïÜ‰∏öÈóÆÈ¢òÔºöÂàõÂª∫‰∏Ä‰∏™Áî®‰∫é‰ø°Áî®Âç°Êü•ËØ¢ÁöÑËá™‰∏ª‰ª£ÁêÜ\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰∏ÄÂÆ∂‰∏ªË¶ÅÁöÑÈáëËûçÊúçÂä°ÂÖ¨Âè∏ÂêëÂÖ∂ÂÆ¢Êà∑Êèê‰æõÂ§öÁßç‰ø°Áî®Âç°‰∫ßÂìÅ„ÄÇÂ§ÑÁêÜÂÆ¢Êà∑ÂÖ≥‰∫é‰∏çÂêå‰ø°Áî®Âç°‰∫ßÂìÅÁöÑÁâπÊÄß„ÄÅÁ¶èÂà©„ÄÅÂà©ÁéáÂíåÂ•ñÂä±ËÆ°ÂàíÁöÑÊü•ËØ¢ÊòØ‰∏Ä‰∏™Âä≥Âä®ÂØÜÈõÜÂûãÁöÑËøáÁ®ã„ÄÇÁõÆÊ†áÊòØÂºÄÂèë‰∏Ä‰∏™ËÉΩÂ§üËá™‰∏ª„ÄÅÂáÜÁ°ÆÂπ∂ÂÖ∑Â§áÊ∑±Âàª‰∏ä‰∏ãÊñáÁêÜËß£ËÉΩÂäõÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÔºå‰ª•Â§ÑÁêÜÂ§ßÈáèÈóÆÈ¢ò„ÄÇ\n\n### Áî®‰∫é‰ª£ÁêÜRAGÂºÄÂèëÁöÑÊï∞ÊçÆÊ∫ê\n\nÂØπ‰∫éËøô‰∏™Áî®‰æãÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®Êù•Ëá™Ëä±ÊóóÈì∂Ë°åÁöÑÂÖ¨ÂÖ±Êï∞ÊçÆÊ∫êÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏ÄÁ≥ªÂàó‰ø°Áî®Âç°‰∫ßÂìÅÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåÂèØ‰ª•‰øùÂ≠ò‰∏∫PDFÊ†ºÂºè„ÄÇËøô‰∫õÊñáÊ°£ÂåÖÂê´ÂõûÁ≠îÂÆ¢Êà∑ÂÖ≥‰∫éËä±ÊóóÈì∂Ë°å‰ø°Áî®Âç°‰∫ßÂìÅÊü•ËØ¢ÊâÄÈúÄÁöÑ‰ø°ÊÅØÔºö[Ëä±Êóó‰ø°Áî®Âç°Ê¶ÇËø∞](https://www.citi.com/credit-cards/compare/view-all-credit-cards?intc=citicard_vac_202405_AB)„ÄÇÂÆåÊï¥ÁöÑ‰ª£Á†ÅÂ∫ìÂíåÈÄêÊ≠•ÁöÑÁ¨îËÆ∞Êú¨ÂèØ‰ª•Âú®Ëøô‰∏™[git‰ªìÂ∫ì](https://github.com/nitsourish/Conversational_AIchatbot)‰∏≠ÊâæÂà∞„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rNgsnBXq0R-RnKfSVCQ26Q.png)\n\n## ÂµåÂÖ•‰∏éÂêëÈáèÊï∞ÊçÆÂ∫ìÂàõÂª∫\n\n‰∏∫‰∫Ü‰ΩøAI‰ª£ÁêÜËÉΩÂ§ü‰ªéÂèØÁî®ÁöÑ‰∫ßÂìÅPDF‰∏≠Ê£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØÔºåÁ¨¨‰∏ÄÊ≠•ÊòØÂàõÂª∫ÂµåÂÖ•„ÄÇÂµåÂÖ•ÊòØÊñáÊú¨ÁöÑÂêëÈáèË°®Á§∫ÔºåÂÖÅËÆ∏Ê®°ÂûãÂú®ËøûÁª≠ÁöÑÂêëÈáèÁ©∫Èó¥‰∏≠ÊçïÊçâÂçïËØç„ÄÅÁü≠ËØ≠ÁîöËá≥ÂÆåÊï¥ÊñáÊ°£ÁöÑËØ≠‰πâÊÑè‰πâ„ÄÇ\n\nÂú®Ëøô‰∏™Áî®‰æã‰∏≠Ôºå‰∏ãËΩΩÂπ∂Â§ÑÁêÜÂåÖÂê´‰∏çÂêå‰ø°Áî®Âç°ËØ¶ÁªÜ‰ø°ÊÅØÁöÑPDFÊñá‰ª∂„ÄÇ‰ΩøÁî®È¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã **text-embedding-3-small**ÔºåÊàë‰ª¨Â∞ÜÊñáÊú¨Êï∞ÊçÆËΩ¨Êç¢‰∏∫Á®†ÂØÜÁöÑÂêëÈáèË°®Á§∫„ÄÇËøô‰∫õÂêëÈáèÂ≠òÂÇ®Âú®ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠Ôºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÁõ∏‰ººÊÄßÊêúÁ¥¢„ÄÇ\n\n**ÂÖ≥ÈîÆÊ≠•È™§Ôºö**\n\n1. **Êï∞ÊçÆÊëÑÂèñ**ÔºöËß£ÊûêÂπ∂Â∞ÜËä±ÊóóÈì∂Ë°å‰ø°Áî®Âç°‰∫ßÂìÅÁöÑPDFËΩ¨Êç¢‰∏∫ÊñáÊú¨Ê†ºÂºè„ÄÇ\n\n```python\nfor file in os.listdir(\"../credit_card_products\"):\n    if file.endswith(\".pdf\"):\n        loaders.append(file)     \npdf_loaders = [PyPDFLoader(f\"../credit_card_products/{file}\") for file in loaders]\n\npages = []\n\nfor loader in pdf_loaders:\n    pages.extend(loader.load())\n```\n**2\\. ÂàáÂàÜ**ÔºöÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫ÂùóÔºå‰ΩøÁî®Êç¢Ë°åÁ¨¶ (`\"\\n\"`) ‰Ωú‰∏∫ÂàÜÈöîÁ¨¶„ÄÇÊØè‰∏™ÂùóÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÂ≠óÁ¨¶ÈáçÂè†„ÄÇËøôÊúâÂä©‰∫éÁ°Æ‰øùÂú®ÂµåÂÖ•ÊàñÊ£ÄÁ¥¢Á≠â‰∏ãÊ∏∏Â§ÑÁêÜËøáÁ®ã‰∏≠ÁöÑÊñáÊú¨ÂàÜÂâ≤Êõ¥‰∏∫È°∫ÁïÖ„ÄÇ\n\n```python\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=1500,\n    chunk_overlap=100,\n    length_function=len\n)\ndocs = text_splitter.split_documents(pages)\n```\n**3\\. ÂµåÂÖ•ÂàõÂª∫‰∏éÂêëÈáèÊï∞ÊçÆÂ∫ì**Ôºö‰ΩøÁî®Âü∫‰∫éLLMÁöÑÂµåÂÖ•Ê®°ÂûãÂ∞ÜÈ¢ÑÂ§ÑÁêÜÁöÑÊñáÊú¨ËΩ¨Êç¢‰∏∫ÂêëÈáèË°®Á§∫ÔºåÂπ∂Â∞ÜÂµåÂÖ•Â≠òÂÇ®Âú®Â¶ÇPinecone„ÄÅFAISSÊàñÂü∫‰∫éMongoDBÁöÑËá™ÂÆö‰πâËß£ÂÜ≥ÊñπÊ°àÁ≠âÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇÊàë‰ª¨Âú®ËøôÈáå‰ΩøÁî®FAISSÔºàFacebook AIÁõ∏‰ººÊÄßÊêúÁ¥¢Ôºâ„ÄÇËøôÂ∞ÜÂÖÅËÆ∏ÂØπÂ§ßÈáèÊñáÊ°£ÈõÜËøõË°åÂø´ÈÄü„ÄÅÂèØÊâ©Â±ïÁöÑÊêúÁ¥¢„ÄÇ\n\n```python\nembeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n## Load it into the vector store and embed\nvectordb = FAISS.from_documents(docs, embeddings_model)\n```\n\n## Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂíåÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG)\n\nLLMÔºå‰æãÂ¶Ç GPT Ê®°ÂûãÔºåÂú®ÁîüÊàêÁ±ª‰∫∫ÊñáÊú¨ÊñπÈù¢ÈùûÂ∏∏Âº∫Â§ßÔºå‰ΩÜÂΩì‰∏é RAG Á≥ªÁªüÈÖçÂØπÊó∂ÔºåÂÆÉ‰ª¨ÁöÑËÉΩÂäõÂæóÂà∞‰∫ÜÂ¢ûÂº∫ÔºåÊòæËëóÂáèÂ∞ë‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÂπªËßâÔºåÂπ∂‰ΩøËá™‰∏ª‰ª£ÁêÜËÉΩÂ§üÊèê‰æõÂèØÈù†‰∏îÂÖ∑Êúâ‰∏ä‰∏ãÊñáÊÑèËØÜÁöÑ‰ø°ÊÅØ„ÄÇÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) ÈÄöËøáÂ∞ÜÂÖ∂ÂìçÂ∫îÁîüÊàê‰∏é‰ªéÂêëÈáèÊï∞ÊçÆÂ∫ìÊ£ÄÁ¥¢ÁöÑÁõ∏ÂÖ≥Â§ñÈÉ®Áü•ËØÜÁõ∏ÁªìÂêàÔºåÊù•ÊèêÈ´ò LLM ÁöÑÊÄßËÉΩ„ÄÇÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÔºåÊ£ÄÁ¥¢Êù•Ê∫êÂèØ‰ª•ÊòØ‰ªª‰Ωï‰∏úË•øÔºå‰ªé‰ºÅ‰∏öÂêëÈáèÊï∞ÊçÆÂ∫ìÂà∞ÁßÅÊúâÊàñÂÖ¨ÂÖ±ÁΩëÂùÄÔºàÁª¥Âü∫ÁôæÁßë„ÄÅË∞∑Ê≠åÊñáÊ°£Á≠âÔºâ„ÄÇ\n\nÂú®Êàë‰ª¨ÁöÑ‰ø°Áî®Âç°‰ª£ÁêÜÁöÑ‰∏ä‰∏ãÊñá‰∏≠ÔºåÂÆ¢Êà∑Êü•ËØ¢ÂèØËÉΩÂåÖÊã¨Ôºö‚ÄúCiti ÁöÑ Costco Anywhere Visa¬Æ Card ÁöÑÂà©Áéá (APR) ÊòØÂ§öÂ∞ëÔºü‚ÄùÂü∫‰∫é RAG ÁöÑÁ≥ªÁªüÂ∞ÜÂàÜ‰∏§Ê≠•Â∑•‰ΩúÔºö\n\n**1\\. Ê£ÄÁ¥¢**Ôºö‰ΩøÁî®ÂêëÈáèÊï∞ÊçÆÂ∫ìÊ†πÊçÆ‰∏éÊü•ËØ¢ÁöÑÂµåÂÖ•Áõ∏‰ººÊÄßËé∑ÂèñÁõ∏ÂÖ≥ÁöÑËä±Êóó‰ø°Áî®Âç° PDF ÁöÑÈÉ®ÂàÜÂÜÖÂÆπ„ÄÇ\n\n```python\nretriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n```\n**2\\. ÁîüÊàê**ÔºöLLM Ëé∑ÂèñÊ£ÄÁ¥¢Âà∞ÁöÑ‰∏ä‰∏ãÊñáÔºåÂπ∂ÁîüÊàêÁõ¥Êé•ÂõûÁ≠îÂÆ¢Êà∑ÈóÆÈ¢òÁöÑËØ¶ÁªÜ‰∏îÂáÜÁ°ÆÁöÑÂìçÂ∫î„ÄÇ\n\n```python\nquestion = \"\"\" \"\"\"\n\nai_msg = rag.invoke({\"input\": question, \"chat_history\": retriever})\n\n```\nËøôÁßçÊñπÊ≥ïÁ°Æ‰øù‰ª£ÁêÜÁöÑÂìçÂ∫îÊó¢Âü∫‰∫éÁúüÂÆûÊï∞ÊçÆÔºà‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢ÔºâÂèàÂÖ∑Êúâ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄß„ÄÇ\n\n## ÊèêÂçá‰∫§‰∫íÁöÑÊèêÁ§∫Â∑•Á®ã\n\nÈÉ®ÁΩ≤Âü∫‰∫éLLMÁöÑ‰ª£ÁêÜÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊñπÈù¢ÊòØÊèêÁ§∫Â∑•Á®ã„ÄÇÂú®Ëøô‰∏™ËøáÁ®ã‰∏≠ÔºåÁ≤æÂøÉËÆæËÆ°ÁöÑÊèêÁ§∫ÂºïÂØºLLMÁîüÊàêÂáÜÁ°Æ‰∏îÂÖ∑Êúâ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄßÁöÑËæìÂá∫„ÄÇÂΩìÂõûÁ≠î‰∏é‰ø°Áî®Âç°‰∫ßÂìÅÁõ∏ÂÖ≥ÁöÑÊü•ËØ¢Êó∂Ôºå‰ª£ÁêÜÈúÄË¶ÅËÉΩÂ§üÁêÜËß£Áî®Êà∑ÊÑèÂõæÔºå‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢Ê≠£Á°ÆÁöÑ‰ø°ÊÅØÔºåÂπ∂‰ª•ÂØπËØùÁöÑÊñπÂºèËøõË°åÂõûÂ∫î„ÄÇ\n\nÊúâÊïàÊèêÁ§∫Â∑•Á®ãÁöÑÁ§∫‰æãÂåÖÊã¨Ôºö\n\n* **‰∏ä‰∏ãÊñáË∑üËøõ**ÔºöÊ∏ÖÊô∞Âú∞Ëß£ÈáäËßíËâ≤Âíå‰ø°ÊÅØÈ¢ÜÂüü„ÄÇÊàë‰ª¨Âú®ËøôÈáå‰ΩøÁî®Êù•Ëá™*langchain_core*ÁöÑ*ChatPromptTemplate*„ÄÇ\n\n\n```python\nqa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\nUse the following pieces of retrieved context to answer the question. \\\nIf you don't know the answer, just say that you don't know. \\\nUse three sentences maximum and keep the answer concise.\\\n\n{context}\"\"\"\n\nqa_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", qa_system_prompt),\n        (\"human\", \"{input}\"),\n    ]\n)\n```\nÈÄöËøáÂæÆË∞ÉÊèêÁ§∫Âπ∂Á°Æ‰øùÂÖ∂Ê∂µÁõñÊü•ËØ¢ÁöÑÂêÑ‰∏™ËßíÂ∫¶ÔºåAI‰ª£ÁêÜËÉΩÂ§üÂà©Áî®ÊúÄ‰Ω≥ÁöÑ‰∏ä‰∏ãÊñáÂíåÊåá‰ª§Êèê‰æõÊõ¥Â•ΩÁöÑÂÆ¢Êà∑‰ΩìÈ™å„ÄÇ\n\n## Ê£ÄÁ¥¢ËÅäÂ§©ÂéÜÂè≤‰ª•Â¢ûÂº∫‰∏ä‰∏ãÊñáÊÑèËØÜ\n\nAIÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊúçÂä°Èù¢‰∏¥ÁöÑÊåëÊàò‰πã‰∏ÄÊòØÔºåÂú®‰∏ÄÁ≥ªÂàó‰∫íÂä®‰∏≠Êèê‰æõËøûË¥Ø‰∏îÂÖ∑Êúâ‰∏ä‰∏ãÊñáÊÑèËØÜÁöÑÂõûÂ∫î„ÄÇ‰æãÂ¶ÇÔºåÂÆ¢Êà∑ÂèØËÉΩÂú®‰∏ÄÊ¨°‰ºöËØù‰∏≠ÂØπ‰ø°Áî®Âç°‰∫ßÂìÅÊèêÂá∫Â§ö‰∏™ÈóÆÈ¢ò„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÂØπËØùÁöÑÊµÅÁïÖÊÄßÔºåÁ≥ªÁªüÂøÖÈ°ªË∑üË∏™ÂÖàÂâçÁöÑ‰∫íÂä®„ÄÇ\n\n```python\nsystem_prompt = \"\"\"Given the chat history and a recent user question \\\ngenerate a new standalone question \\\nthat can be understood without the chat history. Do NOT answer the question, \\\njust reformulate it if needed or otherwise return it as is.\"\"\"\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n\nretriever_with_history = create_history_aware_retriever(\n    llm, retriever, prompt\n)\n```\nÊ£ÄÁ¥¢ËÅäÂ§©ÂéÜÂè≤Â∏ÆÂä©‰ª£ÁêÜ‰øùÊåÅ‰∏ä‰∏ãÊñáÂπ∂Êèê‰æõÊõ¥‰∏™ÊÄßÂåñÁöÑÂõûÂ∫î„ÄÇËøôÂú®ÂÆ¢Êà∑ÊèêÂá∫ÂêéÁª≠ÈóÆÈ¢òÊàñÂú®Â§ö‰∏™‰∫ßÂìÅ‰πãÈó¥ÂàáÊç¢ÁöÑÊÉÖÂÜµ‰∏ãÂ∞§ÂÖ∂ÈáçË¶Å„ÄÇÁ≥ªÁªüÁ°Æ‰øùÊó©ÊúüÁöÑÊï∞ÊçÆÁÇπÔºà‰æãÂ¶ÇÔºåÂÆ¢Êà∑Ê≠£Âú®ËÆ®ËÆ∫ÁöÑ‰∫ßÂìÅÔºâ‰ªçÁÑ∂ÊòØÂΩìÂâçÂØπËØùÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ\n\n## LangchainÔºöÂçèË∞É‰ª£ÁêÜ\n\nLangchain ÊòØËøûÊé•ÊâÄÊúâËøô‰∫õÁªÑ‰ª∂ÁöÑÂÖ≥ÈîÆÂ∑•ÂÖ∑ÔºöLLMs„ÄÅÂêëÈáèÊï∞ÊçÆÂ∫ì„ÄÅRAG Á≥ªÁªüÂíåÂ§ñÈÉ® API„ÄÇÂÆÉÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÈõÜÊàêÊ°ÜÊû∂ÔºåÁî®‰∫éÊûÑÂª∫Ëøô‰∫õËá™‰∏ª‰ª£ÁêÜÔºåÁÆÄÂåñÂºÄÂèëËøáÁ®ãÔºåÂπ∂Á°Æ‰øù‰ª£ÁêÜÂú®‰∏çÂêå‰ªªÂä°‰πãÈó¥Êó†ÁºùÂ∑•‰ΩúÔºåÂåÖÊã¨Ê£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÁîüÊàêÂíåÂìçÂ∫îÂà∂ÂÆö„ÄÇ\n\n```python\nllm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")\nquestion_answer_chain = create_stuff_documents_chain(llm, qa_system_prompt)\n\nretriever_with_history = create_history_aware_retriever(\n    llm, retriever, prompt\n)\n\nchat_history = [\"\"\" \"\"\"]\nrag_chain = create_retrieval_chain(retriever_with_history, question_answer_chain)\nai_msg = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history}\nchat_history.append([HumanMessage(content=question),ai_msg[\"answer\"]])\n```\nLangchain ÁöÑÊ®°ÂùóÂåñÊû∂ÊûÑÂÖÅËÆ∏ËΩªÊùæÈõÜÊàê‰∏çÂêåÁöÑÊï∞ÊçÆÊ∫êÔºåÊó†ËÆ∫ÂÆÉ‰ª¨ÊòØÂ≠òÂÇ®Âú®ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠ËøòÊòØÈÄöËøá API ËÆøÈóÆ„ÄÇÂÆÉËøò‰øÉËøõ‰∫ÜÁî®Êà∑Êü•ËØ¢ÁöÑÂÆûÊó∂ÂçèË∞ÉÔºåÁªìÂêàÈÄÇÂΩìÁöÑÊ£ÄÁ¥¢„ÄÅÁîüÊàêÂíå‰∏ä‰∏ãÊñáÊÑüÁü•Êú∫Âà∂„ÄÇ\n\n## ‰ΩøÁî® Flask Âíå Streamlit ÈÉ®ÁΩ≤\n\n‰∏ÄÊó¶ RAG Ê®°ÂûãÁªèËøáËÆ≠ÁªÉÂíå‰ºòÂåñÔºåÂ∞±ÂèØ‰ª•‰ΩøÁî®ËΩªÈáèÁ∫ßÁöÑ Web Ê°ÜÊû∂Â¶Ç Flask Êàñ Streamlit ËøõË°åÈÉ®ÁΩ≤„ÄÇFlask ÂÖÅËÆ∏ÂØπÈÉ®ÁΩ≤ËøõË°åÊõ¥Â§öÁöÑËá™ÂÆö‰πâÂíåÊéßÂà∂ÔºåËÄå Streamlit Âàô‰∏ìÊ≥®‰∫éÁÆÄÂçïÊÄßÔºåÊèê‰æõÂø´ÈÄüÂéüÂûãÂºÄÂèë„ÄÇÂÆåÊï¥ÂÆûÁé∞ÂèØ‰ª•Âú® [git repo](https://github.com/nitsourish/Conversational_AIchatbot) ‰∏≠ÊâæÂà∞„ÄÇ\n\n**Flask Á§∫‰æãÔºö**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1BZhU0OMY10wCQPRYliEQw.png)\n\n\n```python\napp = Flask(__name__)\n\n@app.route('/query', methods=['POST'])\ndef query_model():\n    input_data = request.json['query']\n    response = rag_chain.invoke({\"input\": input_data})\n    return jsonify({\"response\": response})\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n**Streamlit Á§∫‰æãÔºö**\n\n\n```python\nst.title(\"‰ø°Áî®Âç°‰∫ßÂìÅÊü•ËØ¢‰ª£ÁêÜ\")\nuser_query = st.text_input(\"ËØ¢ÈóÆÊúâÂÖ≥Ëä±Êóó‰ø°Áî®Âç°ÁöÑÈóÆÈ¢òÔºö\")\nif user_query:\n    response = rag_chain.invoke({\"input\": user_query})\n    st.write(f\"ÂìçÂ∫î: {response}\")\n```\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uOXAnRB0yln6U21aCUMy9Q.png)\n\n## ÂÖ≥ÈîÆË¶ÅÁÇπ‰∏éÊú™Êù•Â±ïÊúõ\n\nÂú®ËøôÁØáÂçöÂÆ¢‰∏≠ÔºåÊàëËÆ®ËÆ∫‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®B2CË°å‰∏ö‰∏≠ÁöÑÁõ∏ÂÖ≥ÊÄßÔºåÁâπÂà´ÊòØÂú®ÂÆ¢Êà∑Êé•Ëß¶ÁÇπËæÉÂ§öÁöÑÈ¢ÜÂüüÔºåÈáçÁÇπÂ∫îÁî®‰∫éÈì∂Ë°å‰∫ßÂìÅÁöÑÂØπËØùÂºèAI‰ª£ÁêÜÔºåÂåÖÊã¨Âü∫‰∫éRAGÁöÑÁÆ°ÈÅìÁöÑÈÄêÊ≠•ÂºÄÂèëÂíåÈÉ®ÁΩ≤ÔºåÂà©Áî®ÊµÅË°åÁöÑlang-chainÊ°ÜÊû∂„ÄÇÊµÅÁ®ãÂåÖÊã¨ÂÆöÂà∂ÁöÑÂ∑•Á®ãÁÆ°ÈÅìÔºåÊï∞ÊçÆÊëÑÂèñÔºåÂêëÈáèÊï∞ÊçÆÂ∫ìÔºàÊ£ÄÁ¥¢Âô®ÔºâÁöÑÈÖçÁΩÆ„ÄÇÊúÄÂêéÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ÂæÆÂûãWebÊ°ÜÊû∂Â¶ÇFlaskËøõË°åÂÖ®Èù¢ÊéßÂà∂Êàñ‰ΩøÁî®StreamlitËøõË°åÂø´ÈÄüÂéüÂûãÂºÄÂèëÁöÑÈÉ®ÁΩ≤„ÄÇ\n\nÂú®ÂΩì‰ªäÂø´ÈÄüÂèëÂ±ïÁöÑB2CÁéØÂ¢É‰∏≠ÔºåÊèê‰æõÂø´ÈÄü„ÄÅÂáÜÁ°ÆÂíå‰∏™ÊÄßÂåñÁöÑÂÆ¢Êà∑ÊúçÂä°ÊòØËé∑ÂæóÁ´û‰∫â‰ºòÂäøÁöÑÂÖ≥ÈîÆ„ÄÇÈÄöËøáÂ∞ÜLLMs‰∏éÂêëÈáèÊï∞ÊçÆÂ∫ì„ÄÅÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÂíåÊèêÁ§∫Â∑•Á®ãÁõ∏ÁªìÂêàÔºåÂÖ¨Âè∏ÂèØ‰ª•ÈÉ®ÁΩ≤‰∏ç‰ªÖËÉΩÂõûÁ≠îÂÆ¢Êà∑Êü•ËØ¢ÁöÑAI‰ª£ÁêÜÔºåËÄå‰∏îËÉΩÂ§ü‰ª•È´ò‰∏ä‰∏ãÊñáÂáÜÁ°ÆÊÄßËøõË°åÂõûÁ≠î„ÄÇ\n\nÊÑüË∞¢ÈòÖËØªÊú¨Êñá„ÄÇË¶ÅÈòÖËØªÊõ¥Â§öÁ≤æÂΩ©ÁöÑAIÊïÖ‰∫ãÔºåËØ∑ÂÖ≥Ê≥®ÊàëÁöÑ[medium stories](https://medium.com/@sourish.syntel)„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/lightrag-simple-and-efficient-rival-to-graphrag-fe49e12e9ece","frontmatter":{"title":"LightRAG - GraphRAG ÁÆÄÂçïÈ´òÊïàÁöÑÁ´û‰∫âÂØπÊâãÔºü","meta_title":"LightRAG - GraphRAG ÁÆÄÂçïÈ´òÊïàÁöÑÁ´û‰∫âÂØπÊâãÔºü","description":"‰º†ÁªüÁöÑ RAG Á≥ªÁªüÈÄöËøáÁ¥¢ÂºïÂéüÂßãÊï∞ÊçÆÊù•Â∑•‰Ωú„ÄÇËøô‰∫õÊï∞ÊçÆË¢´ÁÆÄÂçïÂú∞ÂàÜÂùóÂπ∂Â≠òÂÇ®Âú®ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇÊØèÂΩìÊúâÊü•ËØ¢‰ªé...","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7_2PyaNMVdYDWTCrb_cMCg.png","categories":["Generative AI","Data Science","Technology/Web"],"author":"Rifx.Online","tags":["LightRAG","retrieval","GraphRAG","indexing","dual-level"],"draft":false,"slug":"blog/lightrag-simple-and-efficient-rival-to-graphrag-fe49e12e9ece"},"content":"\n\n\n\n\n‰º†ÁªüÁöÑ RAG Á≥ªÁªüÈÄöËøáÁ¥¢ÂºïÂéüÂßãÊï∞ÊçÆÊù•Â∑•‰Ωú„ÄÇËøô‰∫õÊï∞ÊçÆË¢´ÁÆÄÂçïÂú∞ÂàáÂàÜÂπ∂Â≠òÂÇ®Âú®ÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇÊØèÂΩìÁî®Êà∑ÂèëÂá∫Êü•ËØ¢Êó∂ÔºåÂÆÉ‰ºöÊü•ËØ¢Â≠òÂÇ®ÁöÑÁâáÊÆµÂπ∂ *Ê£ÄÁ¥¢* Áõ∏ÂÖ≥ÁâáÊÆµ„ÄÇÂ¶ÇÊûúÊÇ®Â∏åÊúõ‰∫ÜËß£ RAG ÁöÑÂü∫Êú¨ÂéüÁêÜÔºåÊàëÂ∑≤ÁªèÂú® [ËøôÈáå](https://proxy.rifx.online/https://readmedium.com/retrieval-augmented-generation-rag-a-quick-and-comprehensive-introduction-6cd5217a4ebb) ÂÜô‰∫Ü‰∏ÄÁØáÂÖ®Èù¢ÁöÑ‰ªãÁªç„ÄÇ\n\nÁî±‰∫éÊ£ÄÁ¥¢Ê≠•È™§ÈíàÂØπÁî®Êà∑ÁöÑÊØè‰∏Ä‰∏™Êü•ËØ¢ÈÉΩ‰ºöÂèëÁîüÔºåÂõ†Ê≠§ËøôÊòØÂä†ÈÄüÁÆÄÂçï RAG Á≥ªÁªüÁöÑÊúÄÂÖ≥ÈîÆÁì∂È¢à„ÄÇËÆ©Ê£ÄÁ¥¢ËøáÁ®ãÂèòÂæóË∂ÖÁ∫ßÈ´òÊïàÈöæÈÅì‰∏çÊòØÂêà‰πéÈÄªËæëÁöÑÂêóÔºüËøôÂ∞±ÊòØ **LightRAG** ÁöÑÊâøËØ∫„ÄÇ\n\n\n> **Â¶ÇÊûúÊÇ®‰∏çÊòØ‰ºöÂëòÔºåÊÇ®ÂèØ‰ª•Âú® [ËøôÈáå](https://proxy.rifx.online/https://www.ai-bites.net/lightrag-simple-and-efficient-rival-to-graphrag/) ÂÖçË¥πÈòÖËØªÊ≠§ÂÜÖÂÆπ„ÄÇ‰∏∫‰ªÄ‰πà‰∏çÂú®ÈÇ£ÈáåËÆ¢ÈòÖÂπ∂Â∞ÜËøô‰∫õÂÜÖÂÆπÁõ¥Êé•ÂèëÈÄÅÂà∞ÊÇ®ÁöÑÊî∂‰ª∂ÁÆ±Âë¢Ôºü**\n\n## ‰∏∫‰ªÄ‰πà‰∏ç‰ΩøÁî® GraphRAG\n\nÂú®Êàë‰ª¨Êü•ÁúãÂÆÉ‰ª¨‰πãÂâçÔºå‰Ω†ÂèØËÉΩ‰ºöÈóÆÔºö‚ÄúÁ≠â‰∏Ä‰∏ã„ÄÇÊàë‰ª¨‰∏çÊòØÊúâÂæÆËΩØÁöÑ GraphRAG ÂêóÔºü‚ÄùÊòØÁöÑÔºå‰ΩÜ GraphRAG ‰ºº‰πéÊúâÂá†‰∏™Áº∫ÁÇπ„ÄÇ\n\n* **Â¢ûÈáèÁü•ËØÜÊõ¥Êñ∞„ÄÇ** (sec 3\\.1\\) GraphRAG È¶ñÂÖàÂú®Êï¥‰∏™ÁßÅÊúâÊï∞ÊçÆÈõÜ‰∏≠ÂàõÂª∫ÂØπÂÆû‰ΩìÂíåÂÖ≥Á≥ªÁöÑÂºïÁî®„ÄÇÁÑ∂ÂêéÔºåÂÆÉÈÄöËøáËá™‰∏ãËÄå‰∏äÁöÑËÅöÁ±ªÂ∞ÜÊï∞ÊçÆÂ±ÇÊ¨°ÂåñÁªÑÁªáÊàêËØ≠‰πâÈõÜÁæ§„ÄÇÂØπÊï∞ÊçÆÈõÜËøõË°åÊñ∞Áü•ËØÜÁöÑÊõ¥Êñ∞ÊÑèÂë≥ÁùÄÊàë‰ª¨ÂøÖÈ°ªÈáçÊñ∞ÁªèÂéÜÊûÑÂª∫ÂõæÁöÑÊï¥‰∏™ËøáÁ®ãÔºÅËÄå LightRAG ÂàôÈÄöËøáÁÆÄÂçïÂú∞Â∞ÜÊñ∞Áü•ËØÜÈôÑÂä†Âà∞Áé∞ÊúâÁü•ËØÜ‰∏äÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÊõ¥ÂÖ∑‰ΩìÂú∞ËØ¥ÔºåÂÆÉÈÄöËøáÁÆÄÂçïÁöÑÂπ∂ÈõÜÊìç‰ΩúÂ∞ÜÊñ∞ÁöÑÂõæËäÇÁÇπÂíåËæπ‰∏éÁé∞ÊúâÁöÑÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇ\n* **ËÆ°ÁÆóÂº∫Â∫¶„ÄÇ** ‰ªé‰ªñ‰ª¨ÁöÑÁ†îÁ©∂‰∏≠ÂèØ‰ª•ÁúãÂá∫ÔºåLightRAG ÊòæËëóÈôç‰Ωé‰∫ÜÊ£ÄÁ¥¢Èò∂ÊÆµÁöÑÊàêÊú¨„ÄÇGraphRAG ÈúÄË¶Å 610,000 ‰∏™Ê†áËÆ∞ÔºåËÄå LightRAG ÂàôÂ∞ë‰∫é 100 ‰∏™Ê†áËÆ∞„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0TwUDr1BCNr_nSfTPwxenw.png)\n\nÊâÄ‰ª•‰∏çÂÜçËµòËø∞ÔºåËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£ LightRAG„ÄÇ\n\n## LightRAG\n\nLightRAGÁöÑ‰∏§‰∏™‰∏ªË¶ÅÂçñÁÇπÊòØÂü∫‰∫éÂõæÁöÑÁ¥¢ÂºïÂíåÂèåÂ±ÇÊ£ÄÁ¥¢Ê°ÜÊû∂„ÄÇËÆ©Êàë‰ª¨ÈÄê‰∏Ä‰∫ÜËß£ÂÆÉ‰ª¨„ÄÇ\n\n## Âü∫‰∫éÂõæÁöÑÁ¥¢Âºï\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*U7sYYNA9teKEVig1dzfi2g.png)\n\n‰ª•‰∏ãÊòØLightRAGÈÅµÂæ™ÁöÑÊ≠•È™§Ôºå‰ª•ÂÆûÁé∞Âü∫‰∫éÂõæÁöÑÁ¥¢Âºï„ÄÇ\n\n* **ÂÆû‰ΩìÂíåÂÖ≥Á≥ªÔºàERÔºâÊèêÂèñ„ÄÇ** ERÊèêÂèñÂú®‰∏äÂõæ‰∏≠Áî®R(.)Ë°®Á§∫„ÄÇÊ≠§Ê≠•È™§Á°Æ‰øùÈ¶ñÂÖà‰ªéÁªôÂÆöÊñáÊ°£‰∏≠ÊèêÂèñÁÆÄÂçïÂÆû‰Ωì„ÄÇ‰æãÂ¶ÇÔºåÂú®‰∏äËø∞Á§∫‰æã‰∏≠Ôºå‚ÄúËúúËúÇ‚ÄùÂíå‚ÄúÂÖªËúÇ‰∫∫‚ÄùÊòØ‰∏§‰∏™ÂÆû‰Ωì„ÄÇÂÆÉ‰ª¨ÈÄöËøá‚ÄúËßÇÂØü‚ÄùÂÖ≥Á≥ªÁõ∏ÂÖ≥ËÅî„ÄÇÂç≥ÔºåÂÖªËúÇ‰∫∫ËßÇÂØüËúúËúÇ„ÄÇ\n* **‰ΩøÁî®LLMÁîüÊàêÈîÆÂÄºÔºàKVÔºâÂØπ„ÄÇ** ÁÑ∂Âêé‰ΩøÁî®ÁÆÄÂçïÁöÑLLMÁîüÊàêKVÂØπ„ÄÇLLMÂàÜÊûêÊ≠•È™§Êèê‰æõ‰∫ÜÂÖ≥‰∫éÂÆû‰ΩìÊàñÂÖ≥Á≥ªÁöÑÁÆÄË¶ÅËØ¥ÊòéÊàñËß£Èáä„ÄÇ‰æãÂ¶ÇÔºåLLMËß£Èáä‰∫ÜÂú®Êàë‰ª¨ÈÄâÊã©ÁöÑÁ§∫‰æã‰∏≠‚ÄúÂÖªËúÇ‰∫∫‚ÄùÊòØË∞Å„ÄÇÊ≠§Ê≠•È™§Âú®‰∏äÂõæ‰∏≠Áî®P(.)Ë°®Á§∫„ÄÇËØ∑Ê≥®ÊÑèÔºåËøô‰∏™LLM‰∏é‰∏ªRAGÁÆ°ÈÅì‰∏≠‰ΩøÁî®ÁöÑÈÄöÁî®LLM‰∏çÂêå„ÄÇ\n* **ÂéªÈáç„ÄÇ** Èâ¥‰∫éËøô‰∫õÊñáÊ°£‰∏éËúúËúÇÊúâÂÖ≥ÔºåÂÆû‰Ωì‚ÄúÂÖªËúÇ‰∫∫‚ÄùÂèØËÉΩÊòØ‰ªéÂ§ö‰∏™ÊñáÊ°£ÊàñÁâáÊÆµ‰∏≠Ê£ÄÁ¥¢Âà∞ÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™ÂéªÈáçÊ≠•È™§Ôºå‰ªÖ‰øùÁïô‰∏Ä‰∏™Âπ∂‰∏¢ÂºÉÂÖ∂‰ΩôÂÖ∑ÊúâÁõ∏ÂêåÂê´‰πâÁöÑÂÜÖÂÆπ„ÄÇËøôÂú®‰∏äÂõæ‰∏≠Áî®D(.)Ë°®Á§∫„ÄÇ\n\n## ÂèåÂ±ÇÊ£ÄÁ¥¢\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t9W1UBbjFa5cnAe-_tqz-Q.png)\n\nÂØπRAGÁ≥ªÁªüÁöÑÊü•ËØ¢ÂèØ‰ª•ÂàÜ‰∏∫‰∏§ÁßçÁ±ªÂûã‚Äî‚ÄîÂÖ∑‰ΩìÊü•ËØ¢ÊàñÊäΩË±°Êü•ËØ¢„ÄÇÂú®Âêå‰∏Ä‰∏™ËúúËúÇÁöÑ‰æãÂ≠ê‰∏≠ÔºåÂÖ∑‰ΩìÊü•ËØ¢ÂèØ‰ª•ÊòØ‚ÄúËúÇÂ∑¢‰∏≠ÂèØ‰ª•ÊúâÂ§öÂ∞ëÂè™ËúÇÂêéÔºü‚ÄùÊäΩË±°Êü•ËØ¢ÂèØ‰ª•ÊòØ‚ÄúÊ∞îÂÄôÂèòÂåñÂØπËúúËúÇÁöÑÂΩ±ÂìçÊòØ‰ªÄ‰πàÔºü‚Äù‰∏∫‰∫ÜÂ∫îÂØπËøôÁßçÂ§öÊ†∑ÊÄßÔºåLightRAGÈááÁî®‰∫Ü‰∏§ÁßçÊ£ÄÁ¥¢Á±ªÂûãÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DuVxwxwl_2-gej_DwGzoeg.png)\n\n* **‰ΩéÂ±ÇÊ£ÄÁ¥¢„ÄÇ** ÂÆÉÁÆÄÂçïÂú∞ÊèêÂèñÁ≤æÁ°ÆÁöÑÂÆû‰ΩìÂèäÂÖ∂ÂÖ≥Á≥ªÔºåÂ¶ÇËúúËúÇ„ÄÅËßÇÂØüÂíåÂÖªËúÇ‰∫∫„ÄÇ\n* **È´òÂ±ÇÊ£ÄÁ¥¢„ÄÇ** ÈÄöËøá‰ΩøÁî®LLMÔºåLightRAGÊ±áÊÄª‰ø°ÊÅØÂπ∂ÊÄªÁªìÂ§ö‰∏™‰ø°ÊÅØÊù•Ê∫ê„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàË¶ÅÂÅöËøô‰∫õÔºü\n\nËøõË°åÊâÄÊúâËøô‰∫õÁªÉ‰π†Âπ∂ÂàáÊç¢Âà∞ LightRAG Á°ÆÂÆûÊèêÈ´ò‰∫ÜÊâßË°åÊó∂Èó¥„ÄÇÂú®Á¥¢ÂºïËøáÁ®ã‰∏≠ÔºåLLM ÊØè‰∏™ÂùóÂè™ÈúÄË∞ÉÁî®‰∏ÄÊ¨°‰ª•ÊèêÂèñÂÆû‰ΩìÂèäÂÖ∂ÂÖ≥Á≥ª„ÄÇ\n\nÂêåÊ†∑ÔºåÂú®Áî®Êà∑Êü•ËØ¢ÊúüÈó¥ÔºåÊàë‰ª¨Âè™ÈúÄ‰ΩøÁî®Áî®‰∫éÁ¥¢ÂºïÁöÑÁõ∏Âêå LLM ‰ªéÂùó‰∏≠Ê£ÄÁ¥¢ÂÆû‰ΩìÂíåÂÖ≥Á≥ª„ÄÇËøôÂú®Ê£ÄÁ¥¢ÂºÄÈîÄÂíåËÆ°ÁÆó‰∏äËäÇÁúÅ‰∫ÜÂ§ßÈáèÊàêÊú¨„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Áªà‰∫éÊúâ‰∫Ü‰∏Ä‰∏™‚ÄúËΩªÈáèÁ∫ß‚ÄùÁöÑ RAGÔºÅ\n\nÂ∞ÜÊñ∞Áü•ËØÜÊï¥ÂêàÂà∞Áé∞ÊúâÂõæ‰∏≠‰ºº‰πéÊòØ‰∏Ä‰∏™Êó†ÁºùÁöÑËøáÁ®ã„ÄÇÊØèÂΩìÊàë‰ª¨ÊúâÊñ∞‰ø°ÊÅØÊó∂Ôºå‰∏çÂøÖÈáçÊñ∞Á¥¢ÂºïÊï¥‰∏™Êï∞ÊçÆÔºåÊàë‰ª¨ÂèØ‰ª•ÁÆÄÂçïÂú∞Â∞ÜÊñ∞Áü•ËØÜÈôÑÂä†Âà∞Áé∞ÊúâÂõæ‰∏≠„ÄÇ\n\n## ËØÑ‰º∞\n\nÂú®‰ªñ‰ª¨ÁöÑËØÑ‰º∞‰∏≠Ôºå‰ªñ‰ª¨‰∏é Naive RAG„ÄÅRQ\\-RAG„ÄÅHyDE Âíå GraphRAG ËøõË°å‰∫ÜÊØîËæÉ„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÊØîËæÉÁöÑÂÖ¨Âπ≥ÊÄßÔºå‰ªñ‰ª¨Âú®ÊâÄÊúâÊï∞ÊçÆÈõÜ‰∏ä‰ΩøÁî®‰∫ÜÂõ∫ÂÆöÁöÑ 1200 ÁöÑÂùóÂ§ßÂ∞èÂπ∂‰∏î‰ΩøÁî®‰∫Ü GPT\\-4o\\-mini ‰Ωú‰∏∫ LLM„ÄÇÁ≠îÊ°àÁöÑËØÑ‰º∞Ê†áÂáÜÂåÖÊã¨ÂÖ®Èù¢ÊÄß„ÄÅÂ§öÊ†∑ÊÄßÂíåÂú®ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢òÔºàÂç≥ËÆ∫Êñá‰∏≠ÁöÑ *ËµãËÉΩ*ÔºâÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DNdNHW7NRcOXpvEWjT5BKQ.png)\n\n‰ªé‰∏ãÂàíÁ∫øÁöÑÁªìÊûú‰∏≠ÂèØ‰ª•ÁúãÂá∫ÔºåLightRAG Ë∂ÖË∂ä‰∫ÜÂΩìÂâçÊâÄÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇ\n\nÊÄª‰ΩìËÄåË®ÄÔºå‰ªñ‰ª¨ÂæóÂá∫‰∫Ü‰ª•‰∏ãÁªìËÆ∫Ôºö\n\n* ‰ΩøÁî®Âü∫‰∫éÂõæÁöÑÊñπÊ≥ïÔºàGraphRAG Êàñ LightRAGÔºâÊòæËëóÊîπÂñÑ‰∫ÜÂü∫Á∫ø Naive RAG\n* LightRAG ÈÄöËøáÂèåÂ±ÇÊ£ÄÁ¥¢ËåÉÂºè‰∫ßÁîü‰∫ÜÁõ∏ÂΩìÂ§öÊ†∑ÁöÑÁ≠îÊ°à\n* LightRAG ËÉΩÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂ§çÊùÇÊü•ËØ¢\n\n## ÁªìËÆ∫\n\nÂ∞ΩÁÆ° RAG ÊòØ‰∏ÄÁßçÁõ∏ÂØπËæÉÊñ∞ÁöÑÊäÄÊúØÔºå‰ΩÜÊàë‰ª¨Âú®Ëøô‰∏ÄÈ¢ÜÂüüÁúãÂà∞‰∫ÜÂø´ÈÄüËøõÂ±ï„ÄÇÂÉè LightRAG ËøôÊ†∑ÁöÑÊäÄÊúØËÉΩÂ§üÂ∞Ü RAG ÊµÅÊ∞¥Á∫øËøêË°åÂú®Âªâ‰ª∑ÁöÑÂïÜÂìÅÁ°¨‰ª∂‰∏äÔºåÂèóÂà∞‰∫ÜÂπøÊ≥õÊ¨¢Ëøé„ÄÇÈöèÁùÄÁ°¨‰ª∂ÁéØÂ¢ÉÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåÂÆûÊó∂Âú®ËÆ°ÁÆóÂèóÈôêÁöÑÁ°¨‰ª∂‰∏äËøêË°å LLM Âíå RAG ÊµÅÊ∞¥Á∫øÁöÑÈúÄÊ±Ç‰πüÂú®‰∏çÊñ≠Â¢ûÂä†„ÄÇ\n\nÊÇ®ÊÉ≥ÁúãÁúãÂÖ≥‰∫é LightRAG ÁöÑ‰∏Ä‰∫õÂÆûË∑µÁ†îÁ©∂ÂêóÔºüËØ∑ÁªßÁª≠ÂÖ≥Ê≥®‚Ä¶‚Ä¶\n\n## ÂêëÂ§ßÂÆ∂Ëá¥Êï¨\n\nÂ∏åÊúõËøôÂØπ‰Ω†ÊúâÂ∏ÆÂä©„ÄÇ\n\n**Â¶ÇÊûú‰Ω†ÂñúÊ¨¢ËøôÁØáÊñáÁ´†Ôºå‰∏∫‰ªÄ‰πà‰∏çÂú® [Twitter](https://proxy.rifx.online/https://twitter.com/ai_bites) ‰∏äÂÖ≥Ê≥®ÊàëÂë¢ÔºüÊàëÊØèÂ§©ÈÉΩ‰ºöÂàÜ‰∫´È°∂Á∫ßAIÂÆûÈ™åÂÆ§ÁöÑÁ†îÁ©∂Êõ¥Êñ∞„ÄÇ**\n\n**ÂêåÊó∂ÔºåËØ∑ËÆ¢ÈòÖÊàëÁöÑ [YouTube È¢ëÈÅì](https://proxy.rifx.online/https://www.youtube.com/c/aibites)ÔºåÊàë‰ºö‰ª•ËßÜËßâÊñπÂºèËß£ÈáäAIÊ¶ÇÂøµÂíåËÆ∫Êñá„ÄÇ**\n\n**ÊúÄÂêéÔºåËØ∑ÁªôÊàëÁÇπËµûÔºåËÆ©Êàë‰ª¨‰∏ÄËµ∑Â∫ÜÁ•ù‰Ω†ÈòÖËØªÂÆåËøô‰∏™ÊïÖ‰∫ã„ÄÇ**\n\n"},{"lang":"zh","group":"blog","slug":"blog/llama-3-1-405b-how-to-use-for-free-9aaf3561932d","frontmatter":{"title":"Llama 3.1 405B‚Äî‚ÄîÂ¶Ç‰ΩïÂÖçË¥π‰ΩøÁî®","meta_title":"Llama 3.1 405B‚Äî‚ÄîÂ¶Ç‰ΩïÂÖçË¥π‰ΩøÁî®","description":"Êó†ÈúÄÊú¨Âú∞ÂÆâË£Ö","date":"2024-10-29T05:09:24.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*db_ND6LyQ5_p5jFJCTo5GQ.jpeg","categories":["Programming","Technology","Generative AI"],"author":"Rifx.Online","tags":["Llama","Meta","HuggingChat","Groq","API"],"draft":false,"slug":"blog/llama-3-1-405b-how-to-use-for-free-9aaf3561932d"},"content":"\n\n\n### Êó†ÈúÄÊú¨Âú∞ÂÆâË£Ö\n\n**Llama 3\\.1 405B** ÊòØMeta‰∫é2024Âπ¥7ÊúàÂèëÂ∏ÉÁöÑÊúÄÂÖàËøõÁöÑAIÊ®°Âûã‚Äî‚Äî**‰ΩÜ‰Ω†ÂèØ‰ª•Âú®Âì™ÈáåËØïÁî®ÂÆÉ*Ôºü***\n\n\n\n**LLama 3\\.1** Êúâ‰∏çÂêåÁöÑÁâàÊú¨ÔºåÂåÖÊã¨ÂèÇÊï∞ÊúÄÂ§öÁöÑ4050‰∫øÊ®°Âûã‰ª•ÂèäËæÉÂ∞èÁöÑ70BÂíå8BÊ®°Âûã„ÄÇ\n\nËØïÁî®70BÂíå8BÊ®°ÂûãÁöÑÊúÄÁÆÄÂçïÊñπÊ≥ïÊòØÂú®[Groq](https://console.groq.com/playground)‰∏ä‚Äî‚Äî‰Ω†ÂèØ‰ª•Áõ¥Êé•Âú®‰ªñ‰ª¨ÁöÑÊ∏∏‰πêÂú∫‰∏≠ËØïÁî®ÂÆÉ‰ª¨„ÄÇ\n\nÁî±‰∫éÈúÄÊ±ÇÈáèÂ∑®Â§ßÔºåÊúÄÂº∫Â§ßÁöÑ405BÊ®°ÂûãÈÄöÂ∏∏‰∏çÂèØÁî®„ÄÇ\n\nÊú¨ÊåáÂçóÈÄÇÁî®‰∫é‰ªª‰ΩïÊÉ≥Ë¶ÅÂÖçË¥πËØïÁî®Llama 3\\.1 405BÁöÑÁî®Êà∑ÔºåÂåÖÊã¨ÂºÄÂèëËÄÖ‚Äî‚ÄîÊó†ÈúÄ‰∏ãËΩΩÂíåÂÆâË£Ö„ÄÇ\n\nÂ¶ÇÊûú‰Ω†Ê≤°Êúâ‰ªòË¥πÁöÑMediumË¥¶Êà∑ÔºåÂèØ‰ª•Âú®[ËøôÈáå](https://addison-best.medium.com/9aaf3561932d?source=friends_link&sk=5fa532d1caaec229a0b9a445d8749449)ÂÖçË¥πÈòÖËØª„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ÊòØÂºÄÂèëËÄÖÔºåÂπ∂‰∏îÊÉ≥Ë¶ÅÈÄöËøáAPIÂÖçË¥πËØïÁî®**LLama 3\\.1 405B‚Äî‚Äî**‰Ω†ÂèØ‰ª•Ë∑≥Âà∞ÊñáÁ´†ÁöÑÊú´Â∞æ„ÄÇ\n\n## ÊàëÂú®Âì™ÈáåÂèØ‰ª•ÂÖçË¥π‰ΩøÁî® Llama 3\\.1 405BÔºü\n\nÊÇ®ÂèØ‰ª•Áõ¥Êé•‰ªé [Meta](https://llama.meta.com/) ‰∏ãËΩΩÂπ∂ÂÆâË£ÖÂÆÉ‚Äî‚Äî‰ΩÜÂÆÉÈùûÂ∏∏Â∫ûÂ§ßÔºåÊÇ®ÈúÄË¶ÅÊï∞Áôæ‰∏™ÂçÉÂÖÜÂ≠óËäÇÁöÑÁ©∫Èó¥Âíå‰∏ÄÂè∞Âº∫Â§ßÁöÑËÆ°ÁÆóÊú∫ÊâçËÉΩÊ≠£Á°ÆÂ∞ùËØï„ÄÇ\n\n‰ΩÜÊÇ®Áé∞Âú®‰πüÂèØ‰ª•Âú®‰∏ç‰∏ãËΩΩÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÂ∞ùËØï„ÄÇ\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∫õÊÇ®ÂèØ‰ª•Â∞ùËØïÁöÑÈÄâÈ°πÔºö\n\n**Â¶ÇÊûúÊÇ®ÊÉ≥‰∫ÜËß£Êõ¥Â§ö AI Â∞èÊäÄÂ∑ßÔºå‰ª•Â∏ÆÂä©ÊÇ®ÁöÑ‰∏öÂä°Â¢ûÈïøÂπ∂Âú®Á∫øËµöÂèñÊõ¥Â§öÊî∂ÂÖ•Ôºö**\n\n***üëâ*** *Ê≥®ÂÜåÊàë‰ª¨ÁöÑ **[ÂÖçË¥π 5 Â§©ÁîµÂ≠êÈÇÆ‰ª∂ËØæÁ®ã](https://aigrowthguys.com/5-day-free-course-how-to-grow-your-business-like-a-weed)**ÔºåÂÆûÁé∞Â¢ûÈïø üöÄ Âπ∂ËµöÂèñ**üí≤üëà***\n\n## 1\\. Âú®Meta AI‰∏ä‰ΩøÁî®Llama 3\\.1 405B\n\nÂ¶ÇÊûú‰Ω†Âú®ÁæéÂõΩÔºåËá≥Â∞ëÂú®Âä†ÊãøÂ§ßÔºàÊàëÊâÄÂú®ÁöÑÂú∞ÊñπÔºâÔºå‰Ω†ÂèØ‰ª•ÈÄöËøáMeta AI‰∏éLlama 3\\.1 405BÊ®°ÂûãËÅäÂ§©„ÄÇËÆøÈóÆ[Meta AIÁΩëÁ´ô](https://www.meta.ai)ÔºåÂπ∂‰ΩøÁî®‰Ω†ÁöÑFacebookÊàñInstagramË¥¶Êà∑ÁôªÂΩï„ÄÇ\n\nÂÆÉÁé∞Âú®‰πüÂèØËÉΩÂú®ÂÖ∂‰ªñÂõΩÂÆ∂ÂèØÁî®ÔºåÊâÄ‰ª•ÂèØ‰ª•ÁúãÁúã„ÄÇ\n\nÂΩì‰Ω†ÁôªÂΩïÊó∂‚Äî‚ÄîÂ∏åÊúõ‰Ω†ËÉΩÁúãÂà∞Â∞ùËØï**Llama 3\\.1 405B**ÁöÑÈÄâÈ°π„ÄÇ\n\nÂ¶ÇÊûúÂèØ‰ª•Ôºå‰Ω†‰ºöÁúãÂà∞Â¶Ç‰∏ãÊà™Âõæ‰∏≠ÁöÑÊ∂àÊÅØ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cw1WMKhdZhzUp0L3Kn7Qng.png)\n\n‰Ω†‰πüÂèØ‰ª•ÈÄöËøáÈìæÊé•‰Ω†ÁöÑMetaË¥¶Êà∑Êù•ÈÄöËøáWhatsAppËÆøÈóÆÂÆÉ„ÄÇ[**Âú®Meta AI‰∏äÂ∞ùËØï**](https://www.meta.ai)\n\n‰Ω†ËøòÂèØ‰ª•Â∞ùËØï‰ªñ‰ª¨ÁöÑ**Imagine**ÁÖßÁâáÂàõ‰ΩúÂ∑•ÂÖ∑ÂíåAIÂõæÂÉèÁºñËæëÂô®**„ÄÇ**\n\nÊñáÁ´†ÂºÄÂ§¥ÁöÑÈÇ£ÂπÖÂ∏¶ÊúâÊãâÈ©¨ÂíåÁîµËÑëÁöÑÂç°ÈÄöÂõæÂÉèÂ∞±ÊòØÁî®Ëøô‰∏™Â∑•ÂÖ∑ÂàõÂª∫ÁöÑ„ÄÇ\n\n**ÊàëÊèêÁ§∫‰∫Ü**\n\n> **Imagine: ÊàëÊÉ≥Ë¶Å‰∏ÄÂπÖÊúâË∂£ÁöÑÂç°ÈÄöÂõæÂÉèÔºåÁî®‰∫é‰∏≠Á≠âÊñáÁ´†ÔºåÂ±ïÁ§∫Â∞ùËØï‰ΩøÁî®Llama 3\\.1 405B**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8MeC_M2O7UX7ulPOfUCuHA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dIG62eA7YAT3mpLA0etz9Q.png)\n\nÂÄºÂæó‰∏ÄËØï„ÄÇÊàëËÆ§‰∏∫ÂÆÉÊó†Ê≥ï‰∏éFlux.1ÊàñMidjourneyÁõ∏ÊèêÂπ∂ËÆ∫‚Äî‚Äî‰ΩÜÂÆÉÊòì‰∫é‰ΩøÁî®‰∏îÂÖçË¥π„ÄÇ\n\n## 2\\. Âú® HuggingChat ‰∏ä‰ΩøÁî® Llama 3\\.1 405B\n\nHuggingChat ÂØπÁæéÂõΩ‰ª•Â§ñÁöÑÁî®Êà∑ÂºÄÊîæÔºåÂπ∂Êèê‰æõÂØπ Llama 3\\.1 405B Ê®°ÂûãÁöÑËÆøÈóÆ„ÄÇÊÇ®ÂèØ‰ª•Á´ãÂç≥ÂºÄÂßãËÅäÂ§©ÔºåÊó†ÈúÄÊ≥®ÂÜåÔºåËøô‰ΩøÂæóÊé¢Á¥¢Ê®°ÂûãÁöÑËÉΩÂäõÂèòÂæóÁÆÄÂçï„ÄÇËÆøÈóÆ [HuggingChat È°µÈù¢](https://huggingface.co) ÂºÄÂßã„ÄÇ[Âú® HuggingChat ‰∏äËØïÁî®](https://huggingface.co)\n\n## 3\\. Âú® Groq ‰∏ä‰ΩøÁî® Llama 3\\.1 405B\n\n**Â¶Ç‰ΩïÔºö** Groq ÊúÄÂàùÊâòÁÆ°‰∫Ü Llama 3\\.1 405B Ê®°ÂûãÔºå‰ΩÜÁé∞Âú®Áî±‰∫éÈúÄÊ±ÇÈáèÂ§ßÔºåÊèê‰æõ‰∫ÜÊõ¥Â∞èÁöÑ 70B Âíå 8B ÁâàÊú¨„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøáÂú® [Groq ÁöÑÁΩëÁ´ô](https://groq.com) ‰∏äÂàõÂª∫‰∏Ä‰∏™ÂÖçË¥πË¥¶Êà∑Êù•Êé¢Á¥¢Ëøô‰∫õÊ®°Âûã„ÄÇ[Âú® Groq ‰∏äËØïÁî®](https://groq.com)\n\n## 4\\. Âú® Perplexity ‰∏ä‰ΩøÁî® Llama 3\\.1 405B\n\nPerplexity Êèê‰æõ‰∫Ü‰∏ÄÁßçÁÆÄÂçïÁöÑÊñπÂºè‰∏é Llama 3\\.1 ËøõË°å‰∫§‰∫íÔºåÊó®Âú®Âø´ÈÄü‰æøÊç∑Âú∞ËÆøÈóÆËØ•Ê®°Âûã„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøáËÆøÈóÆ Perplexity AI Âπ≥Âè∞ÂºÄÂßã‰ΩøÁî®ÂÆÉ„ÄÇ‰ΩÜËøô‰ªÖÂú® Pro ËÆ°Âàí‰∏≠ÂèØÁî®„ÄÇ[Âú® Perplexity ‰∏äÂ∞ùËØï](https://www.perplexity.ai)\n\n## 5\\. Âú® Poe ‰∏ä‰ΩøÁî® Llama 3\\.1 405B\n\nPoe ÊòØ Quora Êèê‰æõÁöÑÂè¶‰∏Ä‰∏™Âπ≥Âè∞ÔºåÊÇ®ÂèØ‰ª•Âú®ËøôÈáåÂ∞ùËØï Llama 3\\.1„ÄÇPoe ÂÖÅËÆ∏Áî®Êà∑ÈÄöËøáËÅäÂ§©ÁïåÈù¢Êé¢Á¥¢‰∏çÂêåÁöÑ AI Ê®°ÂûãÔºåÂåÖÊã¨ Llama 3\\.1„ÄÇÂ¶ÇÊûúÊÇ®ÊÉ≥Âú®‰∏Ä‰∏™Âú∞ÊñπÊØîËæÉ Llama 3\\.1 ÂíåÂÖ∂‰ªñ AI Ê®°ÂûãÔºåËøôÊòØ‰∏Ä‰∏™Â§öÂäüËÉΩÁöÑÈÄâÊã©„ÄÇÊÇ®ÂèØ‰ª•ÂÖçË¥πÂ∞ùËØï 3\\.1 405B ‚Äî ÊØèÂ§©ÊúâÊúâÈôêÁöÑÂÖçË¥πÁßØÂàÜ„ÄÇ[Âú® Poe ‰∏äÂ∞ùËØï](https://poe.com)\n\n## ÊàëÂú®Âì™ÈáåÂèØ‰ª•ÂÖçË¥π‰ΩøÁî® Llama 3\\.1 405B APIÔºü\n\nÂ¶ÇÊûú‰Ω†ÊòØÂºÄÂèëËÄÖÂπ∂ÊÉ≥ÂÆåÂÖ®ÂÖçË¥πÂ∞ùËØï Llama 3\\.1 405B ÁâàÊú¨‚Äî‚ÄîÁõÆÂâç‰Ω†ÁöÑÈÄâÊã©ÊúâÈôê„ÄÇ\n\n‰ΩÜÊàëÊÉ≥Áªô‰Ω†‰∏Ä‰∏™ÁÆÄÂçï‰∏îÂÖçË¥πÁöÑÈÄâÈ°πÔºåËÆ©‰Ω†ÂèØ‰ª•ÂºÄÂßã‰ΩøÁî®„ÄÇ\n\n‰Ω†Áé∞Âú®ÂèØ‰ª•Âú® [together.ai](https://together.ai) ‰∏äÂÖçË¥πÂ∞ùËØï„ÄÇ\n\n‰Ω†ÂèØ‰ª•Ëé∑Âæó $5 ÁöÑÂÖçË¥πÈ¢ùÂ∫¶Âíå‰∏Ä‰∏™ API ÂØÜÈí•Êù•ËøõË°åÂ∞ùËØï„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*w8LOXw-Wm0QTz5YgvZ27ug.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YpKURkmy--xstoJpZ4fmbw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*g0FxHkg6gq5OMXXo1Yzr0A.png)\n\nËøôÊòØÊàëÊâæÂà∞ÁöÑÂø´ÈÄü‰∏îÂÖçË¥πÁöÑÊµãËØï Llama 3\\.1 405B ÁâàÊú¨ÁöÑÊúÄÁÆÄÂçïÊñπÊ≥ï„ÄÇ\n\nËøôÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÈÄâÈ°πÔºåÈÄÇÂêàÂ∏åÊúõÂÖçË¥πÂ∞ùËØï‰ΩøÁî® API ÁöÑÂºÄÂèëËÄÖ„ÄÇ\n\n## Ê≥®ÊÑèÔºö\n\nÂ¶ÇÊûúÊÇ®Â∏åÊúõÊàë‰ª¨ÁöÑÂõ¢Èòü‰ΩøÁî®LLMsÂàõÂª∫ÂÆöÂà∂ÁöÑAIËΩØ‰ª∂ÔºåÊàñ‰∏∫ÊÇ®ÁöÑ‰∏öÂä°ÂàõÂª∫ÂÆöÂà∂ÁöÑAIËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÊÇ®ÂèØ‰ª•Âú®ËøôÈáå[**ËÅîÁ≥ªÊàë**](https://aigrowthguys.com/contact/) ‚úâÔ∏èÔºåÊàë‰ºöÂ∞ΩÂø´ÂõûÂ§çÊÇ®Ôºö\n\n[**AI Growth Guys ËÅîÁ≥ª**](https://aigrowthguys.com/contact/)‚úâÔ∏è\n\nüëâ Ê≥®ÂÜåÊàë‰ª¨ÁöÑ[**ÂÖçË¥π5Â§©ÁîµÂ≠êÈÇÆ‰ª∂ËØæÁ®ã**](https://aigrowthguys.com/5-day-free-course-how-to-grow-your-business-like-a-weed/)ÔºåÂú®AIÊó∂‰ª£Ëì¨ÂãÉÂèëÂ±ïüöÄÂπ∂ËµöÂèñüí≤\n\nÊÇ®ËøòÂèØ‰ª•[**Ê≥®ÂÜåÊàëÁöÑÊñ∞ÈóªÈÄöËÆØ**](https://ai-growth-guys.beehiiv.com/subscribe/?via=andrew-best)Ôºå‰∫ÜËß£Â¶Ç‰ΩïÂà©Áî®AIËµöÂèñÊõ¥Â§öÊî∂ÂÖ•„ÄÇ\n\nÊü•ÁúãÊàë‰ª¨ÁöÑ[**YouTubeÈ¢ëÈÅì**](https://www.youtube.com/@aigrowthguys)\n\nÂú®Êàë‰ª¨ÁöÑÁΩëÁ´ô‰∏äÂÖ≥Ê≥®Êàë‰ª¨Ôºö[**AI Growth Guys**](https://aigrowthguys.com/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/llama-3-2-the-next-generation-of-lightweight-instruction-tuned-language-models-a-hands-on-9bca07c8af1d","frontmatter":{"title":"Llama 3.2Ôºö‰∏ã‰∏Ä‰ª£ËΩªÈáèÁ∫ß„ÄÅÊåá‰ª§Ë∞ÉÊï¥ËØ≠Ë®ÄÊ®°ÂûãÔºöÂÆûË∑µ‚Ä¶‚Ä¶","meta_title":"Llama 3.2Ôºö‰∏ã‰∏Ä‰ª£ËΩªÈáèÁ∫ß„ÄÅÊåá‰ª§Ë∞ÉÊï¥ËØ≠Ë®ÄÊ®°ÂûãÔºöÂÆûË∑µ‚Ä¶‚Ä¶","description":"Êé¢Á¥¢ LLaMA 3.2 Âú®‰øÆÂâ™„ÄÅÁü•ËØÜÊèêÁÇºÂíåÂ§öËØ≠Ë®ÄÊÄßËÉΩÊñπÈù¢ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Ôºå‰ª•ÂèäËøêË°åÁöÑÂÆûË∑µÊïôÁ®ã‚Ä¶‚Ä¶","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BMalqlcJIFe50hidF4FnqQ.png","categories":["Natural Language Processing","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["LLaMA","tuning","pruning","distillation","multilingual"],"draft":false,"slug":"blog/llama-3-2-the-next-generation-of-lightweight-instruction-tuned-language-models-a-hands-on-9bca07c8af1d"},"content":"\n### Êé¢Á¥¢ LLaMA 3\\.2 Âú®Ââ™Êûù„ÄÅÁü•ËØÜËí∏È¶èÂíåÂ§öËØ≠Ë®ÄÊÄßËÉΩÊñπÈù¢ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Ôºå‰ª•ÂèäÊú¨Âú∞ËøêË°åÊàñÈÄöËøá Google Colab ÁöÑÂÆûÁî®ÊïôÁ®ã\n\nüë®üèæ‚Äçüíª [GitHub](https://github.com/mdmonsurali) ‚≠êÔ∏è \\| üëî[LinkedIn](https://www.linkedin.com/in/mdmonsurali/) \\|üìù [Medium](https://medium.com/@monsuralirana)\n\n\n\n## ‰ªãÁªç\n\nËØ≠Ë®ÄÊ®°ÂûãÊåÅÁª≠ÂèëÂ±ïÔºåÊé®Âä®ÁùÄÊïàÁéá„ÄÅÈÄüÂ∫¶ÂíåÂ§öËØ≠Ë®ÄËÉΩÂäõÁöÑËæπÁïå„ÄÇLLaMA 3\\.2ÔºàËΩªÈáèÁ∫ßLLaMAÔºâ‰ª£Ë°®‰∫ÜËøô‰∏ÄËΩ®Ëøπ‰∏äÁöÑ‰∏ã‰∏Ä‰∏™Á™ÅÁ†¥ÔºåÁªìÂêà‰∫ÜÂâ™Êûù„ÄÅÁü•ËØÜËí∏È¶èÂíåÂêàÊàêÊï∞ÊçÆÁîüÊàêÁ≠âÂàõÊñ∞„ÄÇÂú®Meta‰πãÂâçÁöÑÂàõÊñ∞Âü∫Á°Ä‰∏äÔºåLLaMA 3\\.2Âú®‰∏çÁâ∫Áâ≤ÈÄüÂ∫¶„ÄÅÂáÜÁ°ÆÊÄßÊàñÈöêÁßÅÁöÑÊÉÖÂÜµ‰∏ãÔºåÊèêÈ´ò‰∫ÜËæÉÂ∞èÊ®°ÂûãÔºà1BÂíå3BÂèÇÊï∞ÔºâÁöÑÊÄßËÉΩ„ÄÇÂú®ËøôÁØáÂçöÂÆ¢‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®LLaMA 3\\.2ÁöÑÂÖ≥ÈîÆÊäÄÊúØËøõÂ±ïÔºåËÆ®ËÆ∫ÂÖ∂Âü∫ÂáÜÊµãËØïÁªìÊûúÔºåÂπ∂Êèê‰æõÂü∫‰∫éÁ†îÁ©∂ÁöÑËßÜËßíÔºåËØ¥ÊòéËøô‰∫õÂàõÊñ∞ÁöÑÈáçË¶ÅÊÄß„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Â∞ÜÈÄöËøá‰∏Ä‰∏™ÂÆûË∑µÊïôÁ®ãÔºåÂ∏ÆÂä©ÊÇ®ÂºÄÂßã‰ΩøÁî®LangChainÂíåOllamaÈÉ®ÁΩ≤LLaMA 3\\.2„ÄÇ\n\n## 1\\. LLaMAÊ®°ÂûãÁöÑÊºîÂèòÔºö‰ªé1\\.0Âà∞3\\.2\n\n### LLaMA Ê®°ÂûãÁöÑÁÆÄÂè≤\n\n**Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã Meta AI (LLaMA)** Á≥ªÂàóËá™È¶ñÊ¨°ÂèëÂ∏É‰ª•Êù•ÁªèÂéÜ‰∫ÜÊòæËëóÁöÑÂèëÂ±ï„ÄÇMeta ÁöÑ **LLaMA 1\\.0** Êó®Âú®‰Ωø LLM ÁöÑËé∑ÂèñÊõ¥Âä†Ê∞ë‰∏ªÂåñÔºåÊèê‰æõ‰∫ÜÊØî GPT\\-3 Á≠âÊ®°ÂûãÊõ¥Â∞ëÂèÇÊï∞ÁöÑÈ´òÊÄßËÉΩÊ®°ÂûãÔºåÂêåÊó∂Âú®ÂêÑÁßç‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÁ±ª‰ººÁöÑÂáÜÁ°ÆÊÄß„ÄÇLLaMA 2\\.0 ÂºïÂÖ•‰∫ÜÊåá‰ª§Ë∞É‰ºòÂíåÂ§öËØ≠Ë®ÄÊÄßËÉΩÁöÑÊîπËøõ„ÄÇ\n\n**LLaMA 3\\.2** ‰ª£Ë°®‰∫Ü‰∏ã‰∏Ä‰∏™È£ûË∑ÉÔºåÈáçÁÇπÂÖ≥Ê≥®‰ª•‰∏ãÊ†∏ÂøÉÈ¢ÜÂüüÔºö\n\n* **Êåá‰ª§Ë∞É‰ºòÂíåÂæÆË∞É**ÔºöÊåá‰ª§Ë∑üÈöèËÉΩÂäõÁöÑÂ¢ûÂº∫‰ΩøÊ®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÁöÑË°®Áé∞Êõ¥‰Ω≥„ÄÇ\n* **ËæπÁºòËÆæÂ§áÁöÑÊïàÁéá**Ôºö‰øÆÂâ™ÂíåËí∏È¶èÊäÄÊúØ‰ΩøÊ®°ÂûãËÉΩÂ§üÂú®ËÆ°ÁÆóËµÑÊ∫êÊúâÈôêÁöÑËÆæÂ§á‰∏äÈÉ®ÁΩ≤Ôºå‰æãÂ¶ÇÊô∫ËÉΩÊâãÊú∫ÔºåËÄå‰∏çÊçüÂ§±ÊÄßËÉΩ„ÄÇ\n* **ËßÜËßâÂíåËØ≠Ë®ÄÁêÜËß£**ÔºöÂ∞ÜËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÈõÜÊàêÂà∞ LLaMA 3\\.2 ‰∏≠ÔºåËÉΩÂ§üÂ§ÑÁêÜÂ§öÊ®°ÊÄÅ‰ªªÂä°Ôºå‰æãÂ¶ÇÂü∫‰∫éÂõæÂÉèÁöÑÈóÆÁ≠î„ÄÇ\n\n## 2\\. LLaMA 3\\.2 ÁöÑÂÖ≥ÈîÆÂàõÊñ∞\n\n### A. Êåá‰ª§Ë∞É‰ºò‰∏éÂØπÈΩê\n\nÊåá‰ª§Ë∞É‰ºòÂ∑≤Ë¢´ËØÅÊòéÊòØÊèêÈ´òÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÈÅµÂæ™Ëá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§ËÉΩÂäõÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇÂú® LLaMA 3.2 ‰∏≠ÔºåMeta ‰ΩøÁî®‰∫Ü **ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâ**„ÄÅ**ÊãíÁªùÈááÊ†∑ÔºàRSÔºâ** Âíå **Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâ** ÊäÄÊúØ„ÄÇËøô‰∫õÊäÄÊúØË¢´Ëø≠‰ª£Â∫îÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãÔºå‰ª•Êõ¥È´òÁöÑÂáÜÁ°ÆÊÄßÂ§ÑÁêÜÂêÑÁßç‰ªªÂä°ÔºåÂ¶ÇÊé®ÁêÜ„ÄÅÊëòË¶ÅÂíåÂ∑•ÂÖ∑‰ΩøÁî®„ÄÇ\n\n* **ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâ**ÔºöÊ®°ÂûãÂú®‰∫∫Â∑•Ê†áÊ≥®ÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞ÉÔºå‰ªé‰∏≠Â≠¶‰π†ÁîüÊàêÊõ¥ÂèóÊ¨¢ËøéÁöÑËæìÂá∫„ÄÇ\n* **Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâ**Ôºö‰∏ÄÁßçËÆ≠ÁªÉÊ®°ÂûãÁõ¥Êé•‰ºòÂåñÁî®Êà∑ÂÅèÂ•ΩÁöÑÊäÄÊúØÔºå‰ΩøËæìÂá∫‰∏é‰∫∫Á±ªÊúüÊúõÊõ¥Á¥ßÂØÜÂØπÈΩê„ÄÇ\n\n### B. È´òÊïàÂâ™Êûù‰∏éÁü•ËØÜËí∏È¶è\n\nLLaMA 3\\.2 ÁöÑËΩªÈáèÁ∫ßÊ®°ÂûãÔºåÂ¶Ç 1B Âíå 3B ÂèÇÊï∞Ê®°ÂûãÔºåÂà©Áî® **ÁªìÊûÑÂåñÂâ™Êûù** Âíå **Áü•ËØÜËí∏È¶è**„ÄÇËøô‰∫õÊäÄÊúØÂú®ÂáèÂ∞èÊ®°Âûã‰ΩìÁßØÁöÑÂêåÊó∂Ôºå‰øùÁïô‰∫ÜÊù•Ëá™Êõ¥Â§ßÊ®°ÂûãÔºà‰æãÂ¶Ç LLaMA 3\\.1 8B Âíå 70BÔºâÁöÑÂ§ßÈáèÁü•ËØÜÔºö\n\n* **ÁªìÊûÑÂåñÂâ™Êûù**ÔºöÂú®ËøôÁßçÊñπÊ≥ï‰∏≠ÔºåÁ≥ªÁªüÊÄßÂú∞ÁßªÈô§ÁΩëÁªú‰∏≠ÈáçË¶ÅÊÄßËæÉ‰ΩéÁöÑÈÉ®ÂàÜÔºå‰ª•ÂàõÂª∫Êõ¥Â∞èÁöÑÊ®°ÂûãÔºåÂêåÊó∂‰øùÊåÅÂáÜÁ°ÆÊÄß„ÄÇ\n* **Áü•ËØÜËí∏È¶è**Ôºö‰∏Ä‰∏™Â§ßÂûãÊ®°ÂûãÔºàÊïôÂ∏àÔºâÂ∞ÜÁü•ËØÜËΩ¨ÁßªÂà∞‰∏Ä‰∏™ËæÉÂ∞èÁöÑÊ®°ÂûãÔºàÂ≠¶ÁîüÔºâÔºå‰ΩøÂæóËæÉÂ∞èÁöÑÊ®°ÂûãÂú®ËÆ≠ÁªÉÊúüÈó¥ËÉΩÂ§üÊ®°‰ªøËæÉÂ§ßÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ\n\n### C. Êâ©Â±ï‰∏ä‰∏ãÊñáÈïøÂ∫¶\n\nLLaMA 3\\.2 ÁöÑ‰∏Ä‰∏™‰∏ªË¶ÅÊõ¥Êñ∞ÊòØÂÖ∂Â§ÑÁêÜÊõ¥Èïø‰∏ä‰∏ãÊñáÈïøÂ∫¶ÁöÑËÉΩÂäõ‚Äî‚ÄîÊúÄÂ§öÂèØËææ **128K tokens**„ÄÇËøô‰ΩøÂÖ∂Âú®Â§ÑÁêÜÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáèÊñáÊú¨ÁöÑ‰ªªÂä°Êó∂ÈùûÂ∏∏È´òÊïàÔºå‰æãÂ¶ÇÊëòË¶Å„ÄÅÈïøÊñáÊ°£ÂàÜÊûêÂíåÂ§öËΩÆÂØπËØù„ÄÇ\n\n### D. ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã\n\nMeta Âú® LLaMA 3.2 ‰∏≠ÂºïÂÖ•ÁöÑ **ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã (VLMs)** ÂºÄËæü‰∫ÜÂ§öÊ®°ÊÄÅ‰ªªÂä°ÁöÑÊñ∞È¢ÜÂüü„ÄÇËøô‰∫õÊ®°ÂûãÊó®Âú®Â§ÑÁêÜÊñáÊú¨ÂíåÂõæÂÉèÔºå‰ΩøÂÖ∂Âú®ÊñáÊ°£ÈóÆÁ≠î„ÄÅÁßëÂ≠¶ÂõæË°®Ëß£ÈáäÂíåÂõæÂÉèÊèèËø∞Á≠âÂ∫îÁî®‰∏≠ÈùûÂ∏∏ÊúâÊïà„ÄÇ\n\n## 3\\. Âü∫ÂáÜÊÄßËÉΩÔºöLLaMA 3\\.2 Â¶Ç‰ΩïÊØîËæÉÔºü\n\nLLaMA 3\\.2 Âú®ÂπøÊ≥õÁöÑÂü∫ÂáÜÊµãËØï‰∏≠ËøõË°å‰∫Ü‰∏•Ê†ºËØÑ‰º∞ÔºåÂ¶ÇÊÇ®ÊâÄÂàÜ‰∫´ÁöÑË°®Ê†ºÊâÄÁ§∫„ÄÇ‰∏ªË¶Å‰∫ÆÁÇπÂåÖÊã¨Ôºö\n\n* **‰∏ÄËà¨‰ªªÂä°**Ôºö3B Ê®°ÂûãÂú® **MMLU** (63\\.4) Âíå **IFEval** (77\\.4) Á≠âÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÊòæÁ§∫Âá∫ÂçìË∂äÁöÑÊåá‰ª§ÈÅµÂæ™ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ\n* **Â∑•ÂÖ∑‰ΩøÁî®**ÔºöÂú® **BFCL V2** Á≠â‰ªªÂä°‰∏≠ÔºåLLaMA 3\\.2 (3B) ÂæóÂàÜ 67\\.0ÔºåË∂ÖË∂ä‰∫Ü **Gemma 2** Âíå **Phi\\-3\\.5\\-mini** Á≠âÁ´û‰∫âÂØπÊâãÔºåÂú®ÈÅµÂæ™‰∏éÂ∑•ÂÖ∑‰ΩøÁî®Áõ∏ÂÖ≥ÁöÑÂ§çÊùÇÊåá‰ª§ÊñπÈù¢Ë°®Áé∞Êõ¥‰Ω≥„ÄÇ\n* **Êï∞Â≠¶ÂíåÊé®ÁêÜ**Ôºö3B Ê®°ÂûãÂú®‰∏éÊï∞Â≠¶Áõ∏ÂÖ≥ÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞Âº∫Âä≤ÔºåÂú® **GSM8K** (Â∞èÂ≠¶Êï∞Â≠¶) ‰∏≠ÂæóÂàÜ **77\\.7**ÔºåÂú® **ARC Challenge** ‰∏≠ÂæóÂàÜ **78\\.6**ÔºåËØ•Âü∫ÂáÜ‰∏ìÊ≥®‰∫éÊé®ÁêÜ„ÄÇ\n* **Â§öËØ≠Ë®ÄÁîüÊàê**Ôºö3B Ê®°ÂûãÂú®Â§öËØ≠Ë®Ä MGSM Âü∫ÂáÜ‰∏≠‰πüË°®Áé∞‰ºòÂºÇÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§öÁßçËØ≠Ë®Ä‰∏≠ÁîüÊàêËøûË¥ØÊñáÊú¨ÁöÑËÉΩÂäõ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lpjDJ6AaRnljLwAxtAf-Ag.png)\n\nLLaMA 3\\.2 Âú®Ëøô‰∫õ‰ªªÂä°‰∏≠ÁöÑ‰ºòÂäøË°®ÊòéÔºåÂÆÉ‰∏∫Ê∂âÂèäËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£„ÄÅÊåá‰ª§ÈÅµÂæ™ÂíåÊé®ÁêÜÁöÑ‰ªªÂä°Êèê‰æõ‰∫ÜÂº∫ÊúâÂäõÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÈÄÇÁî®‰∫é‰∏ÄËà¨ÂíåÂ§öËØ≠Ë®ÄÁéØÂ¢É„ÄÇ\n\n## 4\\. ÂÆûË∑µÊïôÁ®ãÔºö‰ΩøÁî® LangChain Âíå Ollama Âú®Êú¨Âú∞ËøêË°å LLaMA 3\\.2\n\nÁé∞Âú®Êàë‰ª¨Â∑≤ÁªèÊé¢ËÆ®‰∫Ü LLaMA 3\\.2 ÁöÑÊäÄÊúØËøõÂ±ïÔºåËÆ©Êàë‰ª¨ÈÄöËøáÈÄêÊ≠•ÊåáÂçóÂú®Êú¨Âú∞‰ΩøÁî® **LangChain** Âíå **Ollama** ËøõË°åÂÆûË∑µ„ÄÇÊàë‰ª¨ÂèØ‰ª•Âú®Êú¨Âú∞Êú∫Âô®Êàñ Google Colab ÁªàÁ´Ø‰∏äÂÆâË£ÖÂÆÉ„ÄÇÂè™ÈúÄÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Êìç‰ΩúÔºö\n\n### Ê≠•È™§ 1ÔºöÂÆâË£ÖÊâÄÈúÄÁöÑÂ∫ì\n\nÈ¶ñÂÖàÔºåÂú®ÊÇ®ÁöÑ Python ÁéØÂ¢É‰∏≠ÂÆâË£ÖÊâÄÈúÄÁöÑÂ∫ì„ÄÇËøêË°å‰ª•‰∏ãÂëΩ‰ª§‰ª•ËÆæÁΩÆ LangChain Âíå OllamaÔºö\n\n```python\n!pip install langchain\n!pip install -U langchain-community\n!pip install langchain_ollama\n```\n\n### Á¨¨2Ê≠•ÔºöÂÆâË£ÖÂπ∂Âä†ËΩΩ Colab\\-XTerm\n\nColab\\-XTerm ÊòØ‰∏Ä‰∏™Êñπ‰æøÁöÑÂåÖÔºåÂèØ‰ª•Âú® Colab Á¨îËÆ∞Êú¨‰∏≠ÂêØÁî®ÁªàÁ´ØËÆøÈóÆ„ÄÇËøôÂØπ‰∫éÁõ¥Êé•Âú®Á¨îËÆ∞Êú¨ÁéØÂ¢É‰∏≠ËøêË°å shell ÂëΩ‰ª§ÈùûÂ∏∏ÊúâÁî®„ÄÇË¶ÅÂÆâË£ÖÂÆÉÔºåËØ∑ËøêË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö\n\n```python\n!pip install colab-xterm\n%load_ext colabxterm\n```\n\n### Á¨¨ 3 Ê≠•ÔºöÂÆâË£Ö Ollama\n\nÊÇ®ÂèØ‰ª•ÈÄöËøáËøêË°å‰ª•‰∏ãÂëΩ‰ª§ÊâìÂºÄÁªàÁ´Ø‰ºöËØùÔºö\n\n```python\n%xterm\n```\n\nÂú®ÁªàÁ´Ø‰∏≠ÔºåËøêË°å‰ª•‰∏ãÂëΩ‰ª§‰ª•ÂÆâË£Ö OllamaÔºö\n\n```python\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n```python\nollama serve\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*itAzyQHMHhin8b7bRLc09w.png)\n\n### Á¨¨4Ê≠•ÔºöÊãâÂèñÊ®°Âûã\n\nÂÆâË£ÖÂÆåOllamaÂêéÔºåÊÇ®ÂèØ‰ª•ÊãâÂèñÊâÄÈúÄÁöÑÊ®°Âûã„ÄÇOllamaÊèê‰æõ‰∫ÜÂ§ö‰∏™LLMÔºåÂåÖÊã¨Llama 3\\.2\\. ‰ª•‰∏ãÊòØÊãâÂèñÂÆÉ‰ª¨ÁöÑÊñπÊ≥ïÔºö\n\n```python\nollama pull llama3.2\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S3R4gByToCZXKEWBh4GWaQ.png)\n\n‰∏äËø∞ÂëΩ‰ª§Â∞Ü‰∏ãËΩΩÂπ∂ÂáÜÂ§áÊ®°Âûã‰ª•‰æõÂú®ÊÇ®ÁöÑColabÁéØÂ¢É‰∏≠‰ΩøÁî®„ÄÇ\n\nÊàñËÄÖÔºåÊãâÂèñOllama‰∏≠ÂèØÁî®ÁöÑ‰ªª‰ΩïLLMÊ®°Âûã„ÄÇÊâÄÊúâLLMÊ®°ÂûãÂàóË°®ÂíåËØ¶ÁªÜ‰ø°ÊÅØÂèØÂú®Ê≠§Êü•ÁúãÔºö[https://ollama.com/library](https://ollama.com/library)\n\n### Á¨¨5Ê≠•ÔºöÂ∞ÜLLaMA 3\\.2‰∏éLangChainÈõÜÊàê\n\nLangChain‰ΩøÂæóË∞ÉÁî®LLaMA 3\\.2ËøõË°åÂêÑÁßçNLP‰ªªÂä°ÂèòÂæóÁÆÄÂçï„ÄÇ‰ª•‰∏ãÊòØÊµãËØïÊ®°ÂûãÁöÑÁÆÄÂçïËÑöÊú¨Ôºö\n\n```python\nfrom langchain_community.llms import Ollama\n\n## Initialize an instance of the Llama 3.1 model\nllm_llama = Ollama(model=\"llama3.2\")\n\n## Invoke the model to generate a response\nresponse = llm_llama.invoke(\"Tell me a joke\")\nprint(response)\n```\n\nËæìÂá∫Ôºö\n\n```python\nHere's one:\n\nWhat do you call a fake noodle?\n\nAn impasta.\n```\n\n### Á¨¨6Ê≠•ÔºöÂ∞ùËØï‰∏çÂêåÁöÑ‰ªªÂä°\n\nÊÇ®ÂèØ‰ª•Â∞ÜÂÖ∂Êâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°ÔºåÂ¶ÇÊëòË¶Å„ÄÅ multilingual translation ÂíåÊé®ÁêÜÔºö\n\n```python\n## Summarization\nresponse = llm_llama.invoke(\"Summarize the following text: 'LLaMA 3.2 represents a major step forward in AI development...'\")\nprint(response)\n\n## Multilingual Generation\nresponse = llm_llama.invoke(\"Translate the following into French: 'What are the major improvements in LLaMA 3.2?'\")\nprint(response)\n```\n\nËæìÂá∫Ôºö\n\n```python\nQuantum Mechanics is a complex and fascinating subject, but I'll try to break it down in simple terms.\n\n**The Basics**\n\nImagine you have a coin. Heads or tails, right? In classical physics (the way things work today), the coin is either one or the other - heads or tails. It's like a definite choice.\n\nIn Quantum Mechanics, however, the coin isn't quite so simple. When you flip it, it doesn't just land on heads or tails; it exists in both states at the same time! This idea might sound crazy, but that's basically what happens with tiny particles like atoms and electrons.\n\n**Wave-Particle Duality**\n\nHere's a key concept: tiny particles can behave like both waves and particles. It sounds weird, but think of it like this:\n\n* Imagine a wave in the ocean. The water molecules are moving up and down, creating ripples.\n* Now imagine a single water molecule as a particle (a tiny ball). That's what quantum mechanics says these particles can be!\n\n**Superposition**\n\nAnother mind-bending idea is superposition. It means that tiny particles can exist in multiple states at the same time. Think of it like this:\n\n* Imagine a coin that's both heads AND tails simultaneously!\n* This happens with electrons, which can spin both clockwise and counterclockwise at the same time.\n\n**Entanglement**\n\nQuantum Mechanics also introduces entanglement. When two particles interact, they become \"connected\" in such a way that what happens to one particle instantly affects the other, no matter how far apart they are!\n\n* Imagine two dancers who are perfectly synchronized, even if they're on opposite sides of the stage.\n* This is basically entanglement: two particles can be connected in a similar way.\n\n**The Weird Stuff**\n\nNow we get to some really weird and interesting aspects of quantum mechanics:\n\n* **Uncertainty Principle**: You can't know both the position AND momentum of a particle at the same time!\n* **Quantum Tunneling**: Particles can pass through solid objects, which is weird because they shouldn't be able to fit through.\n* **Schr√∂dinger's Cat**: Imagine a cat in a box with a radioactive atom. If the atom decays, the cat dies. But according to quantum mechanics, the cat is BOTH alive AND dead until someone opens the box and observes it!\n\n**In a Nutshell**\n\nQuantum Mechanics is all about tiny particles behaving in strange and fascinating ways. It's like they're playing by their own rules, which can lead to some pretty wild and unpredictable outcomes.\n\nWhile this explanation is simplified, it should give you an idea of how quantum mechanics works and its weird and wonderful principles!\n```\n\nËæìÂá∫Ôºö\n\n```python\nThe translation of \"What are the major improvements in LLaMA 3.2?\" into French is:\n\n\"Quels sont les am√©liorations majeures de LLaMA 3.2?\"\n\nHere's a breakdown of the translation:\n\n- \"What\" becomes \"Quels\"\n- \"are\" becomes \"sont\"\n- \"the\" becomes \"les\"\n- \"major improvements\" become \"am√©liorations majeures\"\n- \"in\" becomes \"sont\"\n- \"LLaMA 3.2\" remains the same, as it's a proper noun.\n\nNote: The phrase \"majeures\" is used to describe significant or substantial improvements.\n```\n\n> **Ëé∑Âèñ GitHub ‰ª£Á†ÅÔºö**\n\n## ÁªìËÆ∫\n\nLLaMA 3\\.2 ÊòØ‰∏Ä‰∏™Â§öÂäüËÉΩ‰∏îÈ´òÊïàÁöÑÊ®°ÂûãÔºåÂú®Â§öÁßçËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ªéÂ§öËØ≠Ë®ÄÊñáÊú¨ÁîüÊàêÂà∞ÂÆûÁî®Â∑•ÂÖ∑‰ΩøÁî®„ÄÇÂÆÉÂú®Ââ™ÊûùÂíåÁü•ËØÜËí∏È¶èÊñπÈù¢ÁöÑÂàõÊñ∞Á°Æ‰øù‰∫ÜÂÆÉÂú®ËΩªÈáèÁ∫ß„ÄÅËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏≠‰ªçËÉΩ‰øùÊåÅÈ°∂Á∫ßÊÄßËÉΩ„ÄÇÈÄöËøáÊú¨ÊïôÁ®ãÔºåÊÇ®ÂèØ‰ª•Âø´ÈÄüÂ∞Ü LLaMA 3\\.2 ÈõÜÊàêÂà∞Êú¨Âú∞Â∫îÁî®Á®ãÂ∫èÊàñÈÄöËøá Google Colab Á≠â‰∫ëÊúçÂä°‰∏≠„ÄÇ\n\nÈÄöËøáËß£ÈîÅ LLaMA 3\\.2 ÁöÑËÉΩÂäõÔºåÂºÄÂèëËÄÖÂèØ‰ª•ÂàõÂª∫ÂâçÊ≤øÁöÑÂ∫îÁî®Á®ãÂ∫èÔºåËøô‰∫õÂ∫îÁî®‰∏ç‰ªÖÂø´ÈÄü„ÄÅÂìçÂ∫îÁÅµÊïèÔºåËÄå‰∏îÊ≥®ÈáçÈöêÁßÅÔºåÁ°Æ‰øùÁî®Êà∑Êï∞ÊçÆ‰øùÁïôÂú®ËÆæÂ§á‰∏ä„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÂú®Êé¢Á¥¢Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËøòÊòØÊûÑÂª∫ÂÆûÈôÖÂ∫îÁî®ÔºåLLaMA 3\\.2 ÈÉΩ‰∏∫ËΩªÈáèÁ∫ß„ÄÅÊåá‰ª§Ë∞É‰ºòÁöÑËØ≠Ë®ÄÊ®°ÂûãËÆæÂÆö‰∫ÜÊñ∞ÁöÑÂü∫ÂáÜ„ÄÇ\n\nÊ¨¢ËøéÊÇ®Êé¢Á¥¢ Ollama Â∫ì‰∏≠ÁöÑÂÖ∂‰ªñÊ®°ÂûãÔºåÂπ∂Â∞ùËØï‰∏çÂêåÁöÑ‰ªªÂä°„ÄÇÂèØËÉΩÊÄßÊòØÊó†Á©∑Êó†Â∞ΩÁöÑÔºÅ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/longrag-giving-ai-a-bigger-net-to-catch-more-fish-in-the-sea-of-information-7ecdd63f330d","frontmatter":{"title":"LongRAGÔºöËÆ©‰∫∫Â∑•Êô∫ËÉΩÂú®‰ø°ÊÅØÊµ∑Ê¥ã‰∏≠ÊçïÊçûÊõ¥Â§öÈ±º","meta_title":"LongRAGÔºöËÆ©‰∫∫Â∑•Êô∫ËÉΩÂú®‰ø°ÊÅØÊµ∑Ê¥ã‰∏≠ÊçïÊçûÊõ¥Â§öÈ±º","description":"Âú®Êàë‰πãÂâçÁöÑÊñáÁ´†‰∏≠ÔºåÊàë‰ªãÁªç‰∫Ü RAG ÊòØÂê¶‰ºöÂõ†ÈïøËØ≠Â¢É LLM ËÄåËøáÊó∂„ÄÇ‰ªäÂ§©ÔºåÊàë‰ª¨Êù•ÁúãÁúãÂ¶Ç‰ΩïÁî≥ËØ∑‚Ä¶‚Ä¶","date":"2024-11-08T00:17:39.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Nt5TRh0ooDkgmibMlA1Srg.png","categories":["Generative AI","Natural Language Processing","Data Science"],"author":"Rifx.Online","tags":["long-context","LLMs","RAG","retrieval","generation"],"draft":false,"slug":"blog/longrag-giving-ai-a-bigger-net-to-catch-more-fish-in-the-sea-of-information-7ecdd63f330d"},"content":"\nÂú® [Êàë‰πãÂâçÁöÑÊñáÁ´†](https://readmedium.com/will-long-context-llms-cause-the-extinction-of-rag-de41ca5ddfc6) ‰∏≠ÔºåÊàë‰ªãÁªç‰∫ÜRAGÊòØÂê¶‰ºöÂõ†Èïø‰∏ä‰∏ãÊñáLLMsËÄåÂèòÂæóËøáÊó∂„ÄÇ‰ªäÂ§©ÔºåËÆ©Êàë‰ª¨ÁúãÁúãÂ¶Ç‰ΩïÂ∞ÜÈïø‰∏ä‰∏ãÊñáLLMsÂ∫îÁî®‰∫éRAGÂú∫ÊôØ„ÄÇ\n\nÂú®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÈ¢ÜÂüüÔºå‰º†ÁªüÊñπÊ≥ï‰∏ÄÁõ¥‰æùËµñ‰∫éÁü≠Ê£ÄÁ¥¢ÂçïÂÖÉÔºåÈÄöÂ∏∏Á∫¶‰∏∫100‰∏™ÂçïËØçÔºåËøôËø´‰ΩøÊ£ÄÁ¥¢Âô®Âú®Â∫ûÂ§ßÁöÑËØ≠ÊñôÂ∫ì‰∏≠Á≠õÈÄâ‰ª•ÊèêÂèñÂøÖË¶Å‰ø°ÊÅØ„ÄÇËøôÁßçËÆæËÆ°ËôΩÁÑ∂ÂèØË°åÔºå‰ΩÜÂØπÊ£ÄÁ¥¢Âô®ÊñΩÂä†‰∫Ü‰∏çÂπ≥Ë°°ÁöÑË¥üÊãÖÔºåÂæÄÂæÄÂõ†ÂÖ∂ÂøÖÈ°ªÂ§ÑÁêÜÁöÑÂçïÂÖÉÊï∞ÈáèÂ∫ûÂ§ßËÄåÂØºËá¥Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ\n\nÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÈ°πÊñ∞Á†îÁ©∂ÔºåÊ†áÈ¢ò‰∏∫‚Äú[LongRAG: ‰ΩøÁî®Èïø‰∏ä‰∏ãÊñáLLMsÂ¢ûÂº∫Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê](https://arxiv.org/pdf/2406.15319v3)‚Äù„ÄÇÂÆÉÊó®Âú®ÈÄöËøáÊèêÂá∫‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ°ÜÊû∂Êù•Ëß£ÂÜ≥ËøôÁßç‰∏çÂπ≥Ë°°Ôºå‰ªéËÄåÂ∞ÜÊ£ÄÁ¥¢ÂçïÂÖÉÁöÑÈïøÂ∫¶Êâ©Â±ïÂà∞4,000‰∏™Ê†áËÆ∞ÔºåÊòæËëóÊèêÈ´òÊ£ÄÁ¥¢Âô®ÁöÑÊïàÁéáÂíåËØªËÄÖÁöÑË°®Áé∞„ÄÇ\n\n## ‰º†Áªü RAG ‰∏é LongRAG\n\n\n\nÂ¶ÇÂõæ 1 ÊâÄÁ§∫ÔºåLongRAG ÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂÖ∂ÂØπ‰º†Áªü RAG Ê°ÜÊû∂ÁöÑÈáçÊûÑ„ÄÇÈÄöËøáÂ∞ÜÊ£ÄÁ¥¢ÂçïÂÖÉÁöÑÂ§ßÂ∞èÊâ©Â±ïÂà∞ 4K tokens‚Äî‚ÄîÊòØÂÖ∏ÂûãÂçïÂÖÉÁöÑ 30 ÂÄç‚Äî‚ÄîLongRAG Â∞ÜÂçïÂÖÉÊï∞Èáè‰ªéÊï∞Áôæ‰∏áÂáèÂ∞ëÂà∞ÂèØÁÆ°ÁêÜÁöÑÂá†ÂçÅ‰∏á‰∏™„ÄÇ\n\nËøôÁßçÊñπÊ≥ï‰∏ç‰ªÖÂáèËΩª‰∫ÜÊ£ÄÁ¥¢Âô®ÁöÑË¥üÊãÖÔºåËøòÂ¢ûÂº∫‰∫ÜÊâÄÊ£ÄÁ¥¢‰ø°ÊÅØÁöÑËØ≠‰πâÂÆåÊï¥ÊÄßÔºå‰ªéËÄåÊèêÈ´ò‰∫Ü‰∏ãÊ∏∏ÊÄßËÉΩ„ÄÇ\n\n## LongRAG\n\nLongRAGÊ°ÜÊû∂Áî±‰∏§‰∏™‰∏ªË¶ÅÁªÑ‰ª∂ÁªÑÊàêÔºö**Long Retriever**Âíå**Long Reader**„ÄÇËøô‰∏§‰∏™ÁªÑ‰ª∂ÁöÑÁ§∫‰æãÂ¶ÇÂõæ2ÊâÄÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fs37A8QUj-y2rW9_iAqS3Q.png)\n\nLong RetrieverÈÄöËøáÂ∞ÜÁõ∏ÂÖ≥ÊñáÊ°£ÂàÜÁªÑ‰∏∫‰øùÊåÅËØ≠‰πâÂÆåÊï¥ÊÄßÁöÑÁªü‰∏Ä‰ΩìÊù•ÁªÑÁªáÊ£ÄÁ¥¢ËøáÁ®ã„ÄÇ‰∏ÄÊó¶ËØÜÂà´Âá∫Áõ∏ÂÖ≥ÁöÑÈïøÊ£ÄÁ¥¢ÂçïÂÖÉÔºåÂÆÉ‰ª¨Â∞ÜË¢´‰º†ÈÄíÁªôLong ReaderÔºåËØ•ÁªÑ‰ª∂ËÉΩÂ§üÂ§ÑÁêÜÂπøÊ≥õÁöÑ‰∏ä‰∏ãÊñáÔºàÂ§ßÁ∫¶30K‰∏™Ê†áËÆ∞Ôºâ„ÄÇ\n\n‰ª•‰∏ãÊòØÂ∑•‰ΩúÊµÅÁ®ãÁöÑÈÄêÊ≠•ÂàÜËß£Ôºö\n\n### 1\\. Âà∂ÂÆöÈïøÊ£ÄÁ¥¢ÂçïÂÖÉ\n\nLongRAGÁöÑÁ¨¨‰∏ÄÊ≠•ÊòØÂàõÂª∫ÈïøÊ£ÄÁ¥¢ÂçïÂÖÉ„ÄÇ\n\n**Âú®‰º†ÁªüÁöÑRAG**Ê°ÜÊû∂‰∏≠ÔºåÊ£ÄÁ¥¢ÂçïÂÖÉËæÉÁü≠ÔºåÈÄöÂ∏∏Âè™ÊúâÂá†Áôæ‰∏™Ê†áËÆ∞ÔºåËøôÂèØËÉΩÂØºËá¥‰ø°ÊÅØÁ¢éÁâáÂåñÔºåÂπ∂‰∏îÁªôÊ£ÄÁ¥¢Âô®Â∏¶Êù•ÈáçÂ§ßÁöÑË¥üÊãÖÔºåÈúÄË¶ÅÂ∞ÜÁõ∏ÂÖ≥‰∏ä‰∏ãÊñáÊãºÂáëÂú®‰∏ÄËµ∑„ÄÇ\n\n**LongRAGËß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢ò**ÔºåÈÄöËøáÂ∞ÜÁõ∏ÂÖ≥ÊñáÊ°£ÂàÜÁªÑ‰∏∫ËøûË¥ØÁöÑÈïøÊ£ÄÁ¥¢ÂçïÂÖÉÔºåËøô‰∫õÂçïÂÖÉÊòæËëóÊõ¥Â§ß ‚Äî ÊØè‰∏™ÂçïÂÖÉÂèØËææ4,000‰∏™Ê†áËÆ∞„ÄÇ\n\n‰∏∫‰∫ÜÂΩ¢ÊàêËøô‰∫õÈïøÂçïÂÖÉÔºåLongRAGÈááÁî®‰∫Ü‰∏ÄÁßçÂàÜÁªÑÁÆóÊ≥ïÔºåÊ†πÊçÆÊñáÊ°£‰πãÈó¥ÁöÑÂÖ≥Á≥ªÁªÑÁªáÊñáÊ°£Ôºå‰æãÂ¶ÇÁª¥Âü∫ÁôæÁßëÊñáÁ´†‰∏≠ÂµåÂÖ•ÁöÑË∂ÖÈìæÊé•„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*zPEDmLo7rcdCQ06e.png)\n\n‰æãÂ¶ÇÔºåÂÖ≥‰∫éÁâπÂÆö‰∏ªÈ¢òÊàñÂÆû‰ΩìÁöÑÊñáÊ°£Ë¢´ÂàÜÁªÑÂú®‰∏ÄËµ∑Ôºå‰ª•ÂàõÂª∫‰∏Ä‰∏™ÁªºÂêàÁöÑÊ£ÄÁ¥¢ÂçïÂÖÉÔºàÂõæ2Ôºâ„ÄÇËøôÁ°Æ‰øù‰∫ÜÊØè‰∏™ÂçïÂÖÉ‰øùÊåÅËØ≠‰πâÂÆåÊï¥ÊÄßÔºåÂπ∂‰∏∫ËØªËÄÖÊèê‰æõ‰∫ÜÊõ¥‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñáÔºå‰ª•‰æø‰ªé‰∏≠ÊèêÂèñÁ≠îÊ°à„ÄÇ\n\n### 2\\. Áõ∏‰ººÊÄßÊêúÁ¥¢‰∏éÊéíÂêç\n\n‰∏ÄÊó¶ÂΩ¢Êàê‰∫ÜÈïøÊ£ÄÁ¥¢ÂçïÂÖÉÔºå‰∏ã‰∏ÄÊ≠•Â∞±ÊòØÊâßË°åÁõ∏‰ººÊÄßÊêúÁ¥¢Ôºå‰ª•ËØÜÂà´Âì™‰∫õÂçïÂÖÉ‰∏éÊü•ËØ¢ÊúÄÁõ∏ÂÖ≥„ÄÇ\n\nÊü•ËØ¢ÈÄöËøáÁºñÁ†ÅÂô®ÂáΩÊï∞ E\\_Q ÁºñÁ†Å‰∏∫‰∏Ä‰∏™ÂêëÈáèÔºåÊØè‰∏™Ê£ÄÁ¥¢ÂçïÂÖÉ‰πüÈÄöËøáÂè¶‰∏Ä‰∏™ÁºñÁ†ÅÂô®ÂáΩÊï∞ E\\_C ËøõË°åÁ±ª‰ººÁöÑÁºñÁ†Å„ÄÇÊü•ËØ¢ `q` ‰∏éÊØè‰∏™Ê£ÄÁ¥¢ÂçïÂÖÉ `g` ‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÈÄöËøáÂÆÉ‰ª¨ÂêÑËá™ÂêëÈáèÁöÑÁÇπÁßØÊù•ËÆ°ÁÆó„ÄÇ\n\nÁÑ∂ËÄåÔºåËÄÉËôëÂà∞Ê£ÄÁ¥¢ÂçïÂÖÉÁöÑÈïøÂ∫¶Ôºå**Áõ¥Êé•ÁºñÁ†ÅÊï¥‰∏™ÂçïÂÖÉÂèØËÉΩËÆ°ÁÆóÂºÄÈîÄÂ§ß‰∏îÊïàÊûúËæÉÂ∑Æ**„ÄÇ**‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåLongRAG ÈÄöËøáÂ∞ÜÈïøÂçïÂÖÉÂàÜËß£‰∏∫Êõ¥Â∞èÁöÑÂùóÊù•Ëøë‰ººÁõ∏‰ººÊÄß**ÔºåÂπ∂ËÆ°ÁÆóËøô‰∫õÂùó‰πãÈó¥ÁöÑÊúÄÂ§ßÁõ∏‰ººÊÄßÂæóÂàÜ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*U1BsMZuyXqO1oqsl.png)\n\nËøôÁßçÊñπÊ≥ïÁ±ª‰ºº‰∫é[‰ª•ÂæÄÂ∑•‰ΩúÁöÑ MaxP ËÆæËÆ°](https://arxiv.org/pdf/1905.09217)Ôºå‰Ωø LongRAG ËÉΩÂ§üÈ´òÊïàÂú∞ËØÜÂà´ÊØè‰∏™ÈïøÊ£ÄÁ¥¢ÂçïÂÖÉ‰∏≠ÊúÄÁõ∏ÂÖ≥ÁöÑÈÉ®ÂàÜÔºåËÄå‰∏ç‰ºöÁâ∫Áâ≤ÊÄßËÉΩ„ÄÇ\n\n### 3\\. ËÅöÂêàÊ£ÄÁ¥¢ÁªìÊûú\n\nÂú®ËÆ°ÁÆóÁõ∏‰ººÂ∫¶ÂàÜÊï∞ÂêéÔºåÂü∫‰∫é‰∏éÊü•ËØ¢ÁöÑÁõ∏ÂÖ≥ÊÄßÈÄâÊã©Ââç k ‰∏™Ê£ÄÁ¥¢ÂçïÂÖÉ„ÄÇ**Ëøô‰∫õÈÄâÂÆöÁöÑÂçïÂÖÉÈöèÂêéË¢´ËøûÊé•Ëµ∑Êù•ÂΩ¢Êàê‰∏Ä‰∏™Âçï‰∏ÄÁöÑÈïø‰∏ä‰∏ãÊñáÔºåÈÄöÂ∏∏ÂåÖÂê´Á∫¶ 30,000 ‰∏™Ê†áËÆ∞„ÄÇ** Ëøô‰∏™ËÅöÂêàÁöÑ‰∏ä‰∏ãÊñáÂ∞ÜË¢´‰º†ÈÄíÁªô Long Reader„ÄÇ\n\nk ÁöÑÂ§ßÂ∞èÊàñÊ£ÄÁ¥¢ÂçïÂÖÉÁöÑÊï∞ÈáèÂØπ‰∫éÂπ≥Ë°°Â∑•‰ΩúË¥üËΩΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂ¶ÇÊûúÊ£ÄÁ¥¢ÂçïÂÖÉÂ§™Áü≠ÔºåÂàôÈúÄË¶ÅÊõ¥Â§öÂçïÂÖÉÔºåËøôÂèØËÉΩ‰ºö‰ΩøÈòÖËØªÂô®‰∏çÂ†™ÈáçË¥ü„ÄÇÁõ∏ÂèçÔºåÂ¶ÇÊûúÂçïÂÖÉÂ§™ÈïøÔºåÂàôÈúÄË¶ÅÁöÑÊï∞ÈáèËæÉÂ∞ëÔºå‰ΩÜÂøÖÈ°ªÈ´òÂ∫¶Áõ∏ÂÖ≥Ôºå‰ª•ÈÅøÂÖçÂåÖÂê´Â§ö‰ΩôÁöÑ‰ø°ÊÅØ„ÄÇ\n\nLongRAG ÈÄöËøá‰ΩøÁî®ÈÄÇÈáèÁöÑÁªìÊûÑËâØÂ•ΩÁöÑÈïøÊ£ÄÁ¥¢ÂçïÂÖÉÊù•‰ºòÂåñËøôÁßçÂπ≥Ë°°ÔºåÈÄöÂ∏∏Âú® 4 Âà∞ 8 ‰πãÈó¥ÔºåÂÖ∑‰ΩìÂèñÂÜ≥‰∫é‰ªªÂä°„ÄÇ\n\n### 4\\. ÈÄöËøáÈïøÈòÖËØªÂô®Â§ÑÁêÜ\n\nÈïøÈòÖËØªÂô®ÊòØË¥üË¥£‰ªéÈïø‰∏ä‰∏ãÊñá‰∏≠ÊèêÂèñÊúÄÁªàÁ≠îÊ°àÁöÑÁªÑ‰ª∂„ÄÇÊ≠§Ê≠•È™§Âà©Áî®ÂÖàËøõÁöÑÈïø‰∏ä‰∏ãÊñáËØ≠Ë®ÄÊ®°ÂûãÔºåÂ¶ÇGPT-4oÊàñGemini-1.5-ProÔºåËÉΩÂ§üÂ§ÑÁêÜÂ§ßÈáèÊñáÊú¨Â∫èÂàóËÄå‰∏ç‰∏¢Â§±ÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇ\n\nÂØπ‰∫éËæÉÁü≠ÁöÑ‰∏ä‰∏ãÊñáÔºàÂ∞ë‰∫é1,000‰∏™tokensÔºâÔºåÈïøÈòÖËØªÂô®Áõ¥Êé•ÊèêÂèñÁ≠îÊ°à„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÂÖ∏ÂûãÁöÑÈïøRAGÁöÑËæÉÈïø‰∏ä‰∏ãÊñáÔºåËØ•ËøáÁ®ãÊõ¥Âä†ÁªÜËá¥„ÄÇÊúÄÂàùÔºåÊ®°ÂûãÁîüÊàê‰∏Ä‰∏™Ê∂µÁõñÂá†Âè•ËØùÁöÑËØ¶ÁªÜÂìçÂ∫îÔºåÁ°Æ‰øùÊçïÊçâÂà∞ÊâÄÊúâÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáÁ¨¨‰∫åËΩÆÂ§ÑÁêÜÔºåÈïøÈòÖËØªÂô®ÂØπÂàùÂßãËæìÂá∫ËøõË°åÁ≤æÁÇºÔºåÂ∞ÜÂìçÂ∫îÊµìÁº©‰∏∫‰∏Ä‰∏™Á≤æÁ°Æ„ÄÅÁÆÄÊ¥ÅÁöÑÁ≠îÊ°à„ÄÇ\n\nËøôÁßç‰∏§Ê≠•Ê≥ïÁ°Æ‰øùÈïøÈòÖËØªÂô®ËÉΩÂ§üÊúâÊïàÂ§ÑÁêÜÈïøÊ£ÄÁ¥¢ÂçïÂÖÉÊèê‰æõÁöÑÂ§ßÈáè‰ø°ÊÅØÔºåÂêåÊó∂‰ªçÁÑ∂Êèê‰æõÂáÜÁ°Æ‰∏îÈõÜ‰∏≠ÁöÑÁ≠îÊ°à„ÄÇ\n\n## ËØÑ‰º∞\n\nÊú¨ÊñáÂØπ LongRAG Âú®Áü•ÂêçÊï∞ÊçÆÈõÜ‰∏äÁöÑË°®Áé∞ËøõË°å‰∫ÜÂÖ®Èù¢ËØÑ‰º∞ÔºåÂ¶Ç Natural Questions (NQ) Âíå HotpotQA„ÄÇÁªìÊûú‰ª§‰∫∫‰ø°ÊúçÔºåÊ£ÄÁ¥¢ÊÄßËÉΩÊúâÊâÄÊèêÂçáÔºåNQ ÁöÑÁ≠îÊ°àÂè¨ÂõûÁéá‰ªé 52% ÊèêÂçáËá≥ 71%ÔºàÂõæ 4ÔºâÔºåHotpotQA ÁöÑÁ≠îÊ°àÂè¨ÂõûÁéá‰ªé 47% ÊèêÂçáËá≥ 72%ÔºàÂõæ 5Ôºâ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wLUdp-4OihjAz8Fu.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*vmTsnuIsV6LxJFtj.png)\n\n## ÁªìËÆ∫\n\nÊú¨ÊñáÊé¢ËÆ®‰∫ÜÂàõÊñ∞ÁöÑ LongRAG Ê°ÜÊû∂ÔºåËøôÊòØ‰∏ÄÁßçÈÄöËøáÊâ©Â±ï RAG Ê°ÜÊû∂‰ª•Â§ÑÁêÜÈïøÊñáÊ°£ÁöÑÂàõÊñ∞ÊñπÊ≥ïÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÂíåÁîüÊàêÊù•Ëá™Êâ©Â±ï‰∏ä‰∏ãÊñáÁöÑÁ≠îÊ°à„ÄÇÂÆÉÁªìÂêà‰∫Ü‰∏Ä‰∏™Â§öÊ≠•È™§Ê£ÄÁ¥¢ËøáÁ®ãÔºåÂä®ÊÄÅÊ£ÄÁ¥¢ÈïøÊñáÊú¨ÁöÑÁõ∏ÂÖ≥ÈÉ®ÂàÜÔºåÁ°Æ‰øùÂú®ÁîüÊàêÈò∂ÊÆµ‰ΩøÁî®ÊúÄÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇËøô‰ΩøÂæó LongRAG Âú®ÈúÄË¶ÅÁêÜËß£ÂíåÁªºÂêàÊù•Ëá™ÂÜóÈïøÂ§çÊùÇÊñáÊ°£ÁöÑ‰ø°ÊÅØÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ã‰ºò‰∫é‰º†ÁªüÁöÑ RAG Ê®°Âûã„ÄÇ\n\nÁÑ∂ËÄåÔºåËøôÁßçÊñπÊ≥ïÂπ∂ÈùûÊ≤°ÊúâÊåëÊàò„ÄÇÂØπÂº∫Â§ßÁöÑÈïø‰∏ä‰∏ãÊñáÊ®°ÂûãÁöÑ‰æùËµñÊÑèÂë≥ÁùÄËØ•Ê°ÜÊû∂ÁöÑÊÄßËÉΩ‰∏éËøô‰∫õÊ®°ÂûãÁöÑËÉΩÂäõÁ¥ßÂØÜÁõ∏ÂÖ≥„ÄÇÊ≠§Â§ñÔºåÁî®‰∫éÂàõÂª∫ÈïøÊ£ÄÁ¥¢ÂçïÂÖÉÁöÑÂàÜÁªÑÁÆóÊ≥ïÂèØËÉΩÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÊîπËøõÔºå‰ª•‰æøÂú®Ë∂ÖË∂äÂü∫‰∫éÁª¥Âü∫ÁôæÁßëÁöÑËØ≠ÊñôÂ∫ìÊó∂ËøõË°åÊ≥õÂåñ„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/meet-ministral-3b-and-8b-edge-ai-game-changers-3f7532da8f90","frontmatter":{"title":"ËÆ§ËØÜ Ministral 3B Âíå 8BÔºöËæπÁºò AI Ê∏∏ÊàèËßÑÂàôÊîπÂèòËÄÖ","meta_title":"ËÆ§ËØÜ Ministral 3B Âíå 8BÔºöËæπÁºò AI Ê∏∏ÊàèËßÑÂàôÊîπÂèòËÄÖ","description":"Mistral AI Âú®ËæπÁºò AI ÂíåËÆæÂ§áËÆ°ÁÆóÈ¢ÜÂüüÁöÑÊñ∞ÂâçÊ≤ø","date":"2024-11-01T03:55:06.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3CmWlEiW7ea8gtqxpI83_w.png","categories":["Technology","Autonomous Systems","Data Science"],"author":"Rifx.Online","tags":["Mistral","edge","computing","translation","robotics"],"draft":false,"slug":"blog/meet-ministral-3b-and-8b-edge-ai-game-changers-3f7532da8f90"},"content":"\n\n\n### Mistral AIÂú®ËæπÁºòAIÂíåËÆæÂ§áËÆ°ÁÆóÁöÑÊñ∞ÂâçÊ≤ø\n\nÂú®Âø´ÈÄüÂèëÂ±ïÁöÑAIÈ¢ÜÂüüÔºåËæπÁºòËÆ°ÁÆóÂèòÂæóË∂äÊù•Ë∂äÈáçË¶ÅÔºåÈÄÇÁî®‰∫éÈÇ£‰∫õÈúÄË¶Å‰ΩéÂª∂Ëøü„ÄÅ‰ª•ÈöêÁßÅ‰∏∫È¶ñÁöÑÈ´òÊïàÊé®ÁêÜÁöÑÂ∫îÁî®ÔºåËÄå‰∏ç‰æùËµñ‰∫éÂü∫‰∫é‰∫ëÁöÑÂü∫Á°ÄËÆæÊñΩ„ÄÇ\n\n**Mistral AI**ÊúÄÊñ∞Êé®Âá∫ÁöÑ[**Ministral**](https://mistral.ai/news/ministraux/)Ê®°ÂûãÂÆ∂ÊóèÔºåÊ†áÂøóÁùÄAIÈ¢ÜÂüüÁöÑ‰∏ÄÊ¨°Á™ÅÁ†¥ÊÄßËøõÂ±ï„ÄÇ\n\n‰∏∫Â∫ÜÁ•ùÂÖ∂ÂºÄÂàõÊÄßÁöÑ**Mistral 7B**Ê®°ÂûãÂèëÂ∏É‰∏ÄÂë®Âπ¥ÔºåMistral AIÊé®Âá∫‰∫Ü‰∏ã‰∏Ä‰ª£ËØ≠Ë®ÄÊ®°ÂûãÔºö**Ministral 3B**Âíå**Ministral 8B**ÔºåÁªüÁß∞‰∏∫‚Äú[**les Ministraux**](https://mistral.ai/news/ministraux/)‚Äù„ÄÇËøô‰∫õÊ®°Âûã‰∏ç‰ªÖ‰ªÖÊòØÊ∏êËøõÂºèÁöÑÊîπËøõÔºõÂÆÉ‰ª¨‰ª£Ë°®‰∫ÜËæπÁºòAIÂèØËÉΩÊÄßÁöÑÈáçÂ§ßÈ£ûË∑É„ÄÇ\n\n\n\n## ‰∏∫‰ªÄ‰πàËøô‰∫õÊ®°ÂûãÂæàÈáçË¶ÅÔºü\n\nËæπÁºò‰∫∫Â∑•Êô∫ËÉΩÁöÑÊ†∏ÂøÉÂú®‰∫éÂú®Êú¨Âú∞ÊâßË°åÂ§çÊùÇËÆ°ÁÆóÔºåÁ°Æ‰øùÊï∞ÊçÆÈöêÁßÅÂπ∂ÂáèÂ∞ëÂìçÂ∫îÊó∂Èó¥„ÄÇÈÄöËøá **Ministral 3B** Âíå **Ministral 8B**ÔºåMistral AI Êèê‰æõ‰∫ÜÂ∞ÜÈ´òËÆ°ÁÆóËÉΩÂäõ‰∏éÂÜÖÂ≠òÊïàÁéáÁõ∏ÁªìÂêàÁöÑÊ®°ÂûãÔºåÊâÄÊúâËøô‰∫õÈÉΩÂèØ‰ª•Áõ¥Êé•Âú®ËÆæÂ§á‰∏äËøêË°å„ÄÇËøô‰∫õÊ®°ÂûãÊó®Âú®‰∏∫Êó†Ê≥ïÊâøÂèóÂª∂ËøüÊàñ‰æùËµñ‰∫ëËøûÊé•ÁöÑÂ∫îÁî®Á®ãÂ∫èÊèê‰æõÂÆûÊó∂Ê¥ûÂØü„ÄÇ\n\n## ‰∏ªË¶ÅÁâπÁÇπÔºö\n\n1. **ÊúÄÂÖàËøõÁöÑÊÄßËÉΩ**ÔºöÂú®Áü•ËØÜ„ÄÅÂ∏∏ËØÜ„ÄÅÊé®ÁêÜ„ÄÅÂéüÁîüÂáΩÊï∞Ë∞ÉÁî®ÂíåÂ∞è‰∫é10BÁ±ªÂà´ÁöÑÊïàÁéáÁ≠â‰∏çÂêå‰ªªÂä°‰∏≠Ë∂ÖË∂äÁé∞ÊúâÊ®°Âûã„ÄÇ\n2. **Â§ß‰∏ä‰∏ãÊñáÁ™óÂè£**ÔºöÊîØÊåÅÊúÄÂ§ö128kÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåÂÆûÁé∞Êõ¥ÂÖ®Èù¢ÁöÑÁêÜËß£ÂíåÁîüÊàê„ÄÇ\n3. **È´òÊïàÊû∂ÊûÑ**ÔºöMinistral 8BÈááÁî®ÁâπÊÆäÁöÑ‰∫§ÈîôÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÊ®°ÂºèÔºåÂÆûÁé∞Êõ¥Âø´ÂíåÊõ¥ËäÇÁúÅÂÜÖÂ≠òÁöÑÊé®ÁêÜ„ÄÇ\n4. **Â§öÂäüËÉΩÊÄß**ÔºöÈÄÇÁî®‰∫éÂπøÊ≥õÁöÑÂ∫îÁî®Ôºå‰ªéËÆæÂ§áÂÜÖÁøªËØëÂà∞Ëá™‰∏ªÊú∫Âô®‰∫∫„ÄÇ\n5. **ÈöêÁßÅ‰ºòÂÖàËÆæËÆ°**Ôºö‰∏∫Êú¨Âú∞Êé®ÁêÜËÄåÊûÑÂª∫ÔºåËøô‰∫õÊ®°ÂûãÈùûÂ∏∏ÈÄÇÂêà‰ºòÂÖàËÄÉËôëÊï∞ÊçÆÈöêÁßÅÁöÑÂ∫îÁî®ÔºåÊ∂àÈô§‰∫ÜÂØπÊåÅÁª≠‰∫ëËÆøÈóÆÁöÑÈúÄÊ±Ç„ÄÇ\n6. **ÂèØÊâ©Â±ïÊÄß**ÔºöÊó†ËÆ∫ÊòØÈúÄË¶ÅMinistral 3BÁöÑ‰ΩéÂäüËÄóÊ∂àËÄóÁöÑÂ∞èÂûãËÆæÂ§áÔºåËøòÊòØÈúÄË¶Å8BÂèò‰ΩìÁöÑÊõ¥Â§ßËÉΩÂäõÔºåËøô‰∏§ÁßçÊ®°ÂûãÈÉΩË∂≥Â§üÁÅµÊ¥ªÔºåÂèØ‰ª•ÈÄÇÂ∫îÂêÑÁßçÁî®‰æã„ÄÇ\n\n> ÊúâÂÖ≥Âü∫ÂáÜÊµãËØïÁªìÊûúÔºåËØ∑ÂèÇÈòÖ [ËøôÈáå](https://mistral.ai/news/ministraux/)\n\n## ÂàÜÊûêÊ®°ÂûãÔºö\n\n### Ministral 3B:\n\n* ‰ªÖÂá≠ **30‰∫ø‰∏™ÂèÇÊï∞**Ôºå‰∏∫ËµÑÊ∫êÂèóÈôêÁöÑÁéØÂ¢ÉÊèê‰æõ‰∫ÜÂπ≥Ë°°ÁöÑËß£ÂÜ≥ÊñπÊ°à\n* ÊîØÊåÅÊúÄÈ´ò **128k ‰∏ä‰∏ãÊñáÈïøÂ∫¶**ÔºåÂèØ‰ª•ÂÖ®Èù¢Â§ÑÁêÜÂ§çÊùÇÊü•ËØ¢\n* ÈÄÇÁî®‰∫éË∂Ö‰ΩéÂª∂ËøüÂ∫îÁî®\n* Âú®ÂêåÁ±ªÊ®°Âûã‰∏≠Ë°®Áé∞‰ºò‰∫éËÆ∏Â§öÂÖ∂‰ªñÊ®°Âûã\n\n### Ministral 8B:\n\n* ÂÖ∑Êúâ **80‰∫øÂèÇÊï∞** Âíå **128k‰∏ä‰∏ãÊñáÈïøÂ∫¶**ÔºåÂú®Â§ÑÁêÜÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°Êó∂ËÉΩÂ§üÊèê‰æõÂ¢ûÂº∫ÁöÑËÆ°ÁÆóËÉΩÂäõ\n* ÈááÁî® **ÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõ** Ê®°ÂºèÔºåÊèêÈ´òÈÄüÂ∫¶ÂíåÂÜÖÂ≠òÊïàÁéá\n* Âü∫‰∫éÂπøÊ≥õÁöÑ **Â§öËØ≠Ë®Ä** Âíå **‰ª£Á†Å** Êï∞ÊçÆÔºå‰ΩøÂÖ∂ÈÄÇÁî®‰∫éÂ§öÁßçÂ∫îÁî®\n* ÊîØÊåÅ **ÂáΩÊï∞Ë∞ÉÁî®**\n* Âú®È´òË¶ÅÊ±ÇÁöÑÂ∫îÁî®‰∏≠Âπ≥Ë°°ÊÄßËÉΩÂíåÊïàÁéá\n* ËØçÊ±áÈáè‰∏∫ **131k**Ôºå‰ΩøÁî® **V3-Tekken** ÂàÜËØçÂô®\n* ÊèêÁ§∫Ê®°ÊùøÔºö\n\n\n```python\n<s>[INST]user message[/INST]assistant response</s>[INST]new user message[/INST]\n```\n\n## Áî®‰æãÔºö\n\nËøô‰∫õÊ®°ÂûãÊèê‰æõ‰∫ÜËÆ°ÁÆóÈ´òÊïàÂíå‰ΩéÂª∂ËøüÁöÑÊÄßËÉΩÔºå‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêà‰ª•‰∏ãÂú∫ÊôØÔºö\n\n* **ËÆæÂ§áÁ´ØÁøªËØë**Ôºö‰ΩøÁî®Êà∑ËÉΩÂ§üÂú®ÂÆûÊó∂‰∏≠Êó†ÁºùÊ≤üÈÄöË∑®ËØ≠Ë®ÄÔºåÂç≥‰ΩøÂú®ÁΩëÁªúËøûÊé•ËæÉÂ∑ÆÁöÑÂú∞Âå∫„ÄÇ\n* **Êó†ÁΩëÁªúÊô∫ËÉΩÂä©Êâã**ÔºöÊîØÊåÅÁã¨Á´ã‰∫é‰∫ëËøûÊé•ËøêË°åÁöÑÊô∫ËÉΩËôöÊãüÂä©ÊâãÔºåÂ¢ûÂº∫ÈöêÁßÅÊïèÊÑüÁéØÂ¢É‰∏≠ÁöÑÁî®Êà∑‰ΩìÈ™å„ÄÇ\n* **Êú¨Âú∞ÂàÜÊûê**Ôºö‰ΩøÁªÑÁªáËÉΩÂ§üÂÆûÊó∂ÂàÜÊûêÊï∞ÊçÆÔºåÂêåÊó∂‰øùÊåÅ‰∏•Ê†ºÁöÑÈöêÁßÅÊ†áÂáÜÔºåËøôÂú®ÂåªÁñóÂíåÈáëËûçÁ≠âË°å‰∏öËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n* **Ëá™‰∏ªÊú∫Âô®‰∫∫**Ôºö‰∏∫Êú∫Âô®‰∫∫ÈÖçÂ§áÂÖàËøõÁöÑËØ≠Ë®ÄËÉΩÂäõÔºå‰ª•ÂÆûÁé∞Ëá™‰∏ªÂÜ≥Á≠ñÂíåÊ≤üÈÄöÔºåÊèêÈ´òÂÆÉ‰ª¨Âú®ÂêÑ‰∏™Ë°å‰∏öÁöÑËøêËê•ÊïàÁéá„ÄÇ\n\nÈô§‰∫ÜÂÖ∂Áã¨Á´ãÁöÑËÉΩÂäõÂ§ñÔºåles Ministraux ËøòÂèØ‰ª•‰∏éÊõ¥Â§ßÁöÑÊ®°ÂûãÂ¶Ç Mistral Large ÂçèÂêåÂ∑•‰Ωú„ÄÇËøôÁßçÂçèÂêå‰ΩøÂÆÉ‰ª¨ËÉΩÂ§ü‰Ωú‰∏∫ **Âú®‰ª£ÁêÜÂ∑•‰ΩúÊµÅ‰∏≠ËøõË°åÂáΩÊï∞Ë∞ÉÁî®ÁöÑÈ´òÊïà‰∏≠‰ªã**ÔºåÂ§ÑÁêÜÔºö\n\n* **ËæìÂÖ•Ëß£Êûê**ÔºöÂø´ÈÄüËß£ÈáäÁî®Êà∑ËæìÂÖ•Ôºå‰ª•Á°Æ‰øùÂáÜÁ°ÆÂìçÂ∫î„ÄÇ\n* **‰ªªÂä°Ë∑ØÁî±**ÔºöÊ†πÊçÆÁî®Êà∑ÊÑèÂõæÂ∞ÜËØ∑Ê±ÇÊåáÂêëÈÄÇÂΩìÁöÑËµÑÊ∫ê„ÄÇ\n* **API Ë∞ÉÁî®**ÔºöÂÆûÊó∂ÊâßË°å API ÂäüËÉΩÔºåÁ°Æ‰øùÂú®ÂêÑÁßç‰∏ä‰∏ãÊñá‰∏≠È°∫ÁïÖ‰∫íÂä®„ÄÇ\n\n## ‰ª£Á†Å‰ΩøÁî®Ôºà‰∏é vLLM ‰∏ÄËµ∑ÔºâÔºö\n\n[Ministral\\-8B\\-Instruct\\-2410](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) ËØ≠Ë®ÄÊ®°ÂûãÊòØ‰∏Ä‰∏™ÁªèËøáÊåá‰ª§ÂæÆË∞ÉÁöÑÊ®°ÂûãÔºåÂèØ‰ª•‰ΩøÁî® vLLM È´òÊïàÈÉ®ÁΩ≤„ÄÇÊÇ®ÂèØ‰ª•Âú® Hugging Face ‰∏ä [ËøôÈáå](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) ÊâæÂà∞ÂÆÉ„ÄÇ‰ª•‰∏ãÊòØÊÇ®ÂèØ‰ª•ÂºÄÂßãÁöÑÊñπÂºèÔºö\n\n### ÂÆâË£Ö\n\nÈ¶ñÂÖàÔºåÁ°Æ‰øùÊÇ®Â∑≤ÂÆâË£ÖÊúÄÊñ∞ÁâàÊú¨ÁöÑ vLLM Âíå mistral\\_commonÔºö\n\n\n```python\npip install --upgrade vllm\npip install --upgrade mistral_common\n```\n\n> ***Ê≥®ÊÑè****ÔºöÈúÄË¶Å vLLM ÁâàÊú¨ 0\\.6\\.2 ÊàñÊõ¥È´òÁâàÊú¨„ÄÇ*\n\n### Á¶ªÁ∫ø‰ΩøÁî® vLLM\n\n‰ª•‰∏ãÊòØÂ¶Ç‰ΩïÂú®Á¶ªÁ∫øÊ®°Âºè‰∏ã‰ΩøÁî® Ministral\\-8B Âíå vLLM ÁöÑÁ§∫‰æãÔºö\n\n\n```python\nfrom vllm import LLM\nfrom vllm.sampling_params import SamplingParams\n\nmodel_name = \"mistralai/Ministral-8B-Instruct-2410\"\nsampling_params = SamplingParams(max_tokens=8192)\n\nllm = LLM(model=model_name, tokenizer_mode=\"mistral\", config_format=\"mistral\", load_format=\"mistral\")\n\nprompt = \"What are the potential implications of artificial intelligence on the job market in the next decade?\"\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": prompt\n    },\n]\n\noutputs = llm.chat(messages, sampling_params=sampling_params)\nprint(outputs[0].outputs[0].text)\n```\n\n### ÊúçÂä°Âô®Ê®°ÂºèÊé®ÁêÜ‰∏é vLLM\n\nÂú®ÊúçÂä°Âô®Êé®ÁêÜÊ®°Âºè‰∏ãÔºåvLLM ËøêË°å‰∏Ä‰∏™ HTTP ÊúçÂä°Âô®ÔºåËÉΩÂ§üÈÄöËøá‰∏é OpenAI ÂçèËÆÆÂÖºÂÆπÁöÑ REST API ÂêåÊó∂Â§ÑÁêÜÂÆ¢Êà∑Á´ØËøûÊé•ÂíåËØ∑Ê±Ç„ÄÇ‰ª•‰∏ãÊòØËÆæÁΩÆÊñπÊ≥ïÔºö\n\n* ÂêØÂä®ÊúçÂä°Âô®Ôºö\n\n```python\nvllm serve mistralai/Ministral-8B-Instruct-2410 --tokenizer_mode mistral --config_format mistral --load_format mistral\n```\n* ÂêëÊúçÂä°Âô®ÂèëÈÄÅËØ∑Ê±ÇÔºö\n\n```python\ncurl --location 'http://localhost:8000/v1/chat/completions' \\\n    --header 'Content-Type: application/json' \\\n    --header 'Authorization: Bearer token' \\\n    --data '{\n        \"model\": \"mistralai/Ministral-8B-Instruct-2410\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"What are the potential implications of artificial intelligence on the job market in the next decade?\"\n          }\n        ]\n      }'\n```\n\n> ÂÖ≥‰∫é vLLM ‰ΩøÁî®ÁöÑÈáçË¶ÅËØ¥ÊòéÔºö\n\n* ÁõÆÂâçÔºåÁî±‰∫éÂú®ÂÆûÁé∞ÂàÜÈ°µÊ≥®ÊÑèÂäõÁöÑ‰∫§ÈîôÊ≥®ÊÑèÂäõÂÜÖÊ†∏ÊñπÈù¢ÁöÑÈôêÂà∂ÔºåvLLM ÁöÑ‰∏ä‰∏ãÊñáÂ§ßÂ∞èÈôêÂà∂‰∏∫ 32k„ÄÇ\n* ‰∏∫‰∫ÜÂà©Áî®ÂÆåÊï¥ÁöÑ 128k ‰∏ä‰∏ãÊñáÂ§ßÂ∞èÔºåÂª∫ËÆÆ‰ΩøÁî® [Mistral Inference](https://github.com/mistralai/mistral-inference)„ÄÇ\n* Â¶ÇÊûúÊÇ®ÈúÄË¶ÅÂáèÂ∞ë GPU ÂÜÖÂ≠òÈúÄÊ±ÇÔºåÂèØ‰ª•ÈÄöËøáÂú® LLM ÂàùÂßãÂåñÊó∂Ê∑ªÂä† `tensor_parallel=2` Êù•‰ΩøÁî®Âº†ÈáèÂπ∂Ë°å„ÄÇ\n\nÈÄöËøáÈÅµÂæ™Ëøô‰∫õÁ§∫‰æãÔºåÊÇ®ÂèØ‰ª•ËΩªÊùæÂú∞Â∞Ü Ministral\\-8B ÈõÜÊàêÂà∞ÊÇ®ÁöÑÈ°πÁõÆ‰∏≠ÔºåÊó†ËÆ∫ÊÇ®ÊòØÂú®Á¶ªÁ∫øÊé®ÁêÜËøòÊòØ‰∏∫Â§ö‰∏™ÂÆ¢Êà∑Á´ØËÆæÁΩÆÊúçÂä°Âô®„ÄÇËØ•Ê®°ÂûãÁöÑÈ´òÊïàÊÄßÂíåÂº∫Â§ßÂäüËÉΩÔºåÂä†‰∏ä vLLM ÁöÑ‰ºòÂåñÊé®ÁêÜÔºå‰ΩøÂÖ∂Êàê‰∏∫ÂêÑÁßç AI Â∫îÁî®ÁöÑ‰ºòÁßÄÈÄâÊã©„ÄÇ\n\n## ÁªìËÆ∫Ôºö\n\nMinistralÁöÑÂèëÂ∏ÉÊ†áÂøóÁùÄ‰∫∫Â∑•Êô∫ËÉΩÂèëÂ±ï‰∏≠ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÈáåÁ®ãÁ¢ë„ÄÇÈÄöËøáÂ∞ÜGPTÁ∫ßÂà´ÁöÑÊÄßËÉΩÂ∏¶Âà∞ËæπÁºòËÆæÂ§áÔºåMistral AI‰∏ç‰ªÖÂú®Êé®Âä®ÊäÄÊúØËæπÁïå‚Äî‚Äî‰ªñ‰ª¨ËøòÂú®ÈáçÊñ∞ÊûÑÊÉ≥‰ª•Êú¨Âú∞„ÄÅÈöêÁßÅ‰ºòÂÖàÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∏∫Âü∫Á°ÄÁöÑÂèØËÉΩÊÄß„ÄÇ\n\nÈöèÁùÄÂºÄÂèëËÄÖ„ÄÅÁ†îÁ©∂‰∫∫ÂëòÂíå‰ºÅ‰∏öÂºÄÂßãÊé¢Á¥¢MinistralÁöÑËÉΩÂäõÔºåÊàë‰ª¨ÂèØ‰ª•ÊúüÂæÖÁúãÂà∞‰∏ÄÊ≥¢Êñ∞ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂ∫îÁî®Á®ãÂ∫èÔºåËøô‰∫õÂ∫îÁî®Á®ãÂ∫èÊØî‰ª•ÂæÄÊõ¥Âä†Âø´ÈÄü„ÄÅÊõ¥ÂÖ∑ÈöêÁßÅÊÄßÂíåÊõ¥Êòì‰∫éËé∑Âèñ„ÄÇËæπÁºò‰∫∫Â∑•Êô∫ËÉΩÁöÑÊó∂‰ª£Â∑≤ÁªèÂà∞Êù•ÔºåËÄåMinistralÊ≠£Âú®ÂºïÈ¢ÜËøô‰∏ÄÊΩÆÊµÅ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/meet-qwen2-5-coder-32b-instruct-coder-open-source-better-than-gpt4o-5dc8343f8157","frontmatter":{"title":"Êª°Ë∂≥ Qwen2.5-Coder-32B-Instruct -Coder - ÂºÄÊ∫êÊØî gpt4o Êõ¥Â•Ω","meta_title":"Êª°Ë∂≥ Qwen2.5-Coder-32B-Instruct -Coder - ÂºÄÊ∫êÊØî gpt4o Êõ¥Â•Ω","description":"Qwen2.5-Coder-32BÊòØ‰∏ÄÊ¨æÂºÄÊ∫êÁöÑAIÁºñÁ†ÅÂä©ÊâãÔºåÂÖ∑Êúâ320‰∫øÂèÇÊï∞ÂíåÈïøËææ128KÁöÑ‰∏ä‰∏ãÊñáÂ§ÑÁêÜËÉΩÂäõÔºåÊîØÊåÅ29ÁßçËØ≠Ë®Ä„ÄÇÂÖ∂ÊÄßËÉΩÂú®ÁºñÁ†ÅËÉΩÂäõ‰∏ä‰∏éGPT-4oÁõ∏Â™≤ÁæéÔºå‰∏îÁîüÊàêÁöÑ‰ª£Á†ÅËØ≠Ê≥ïÂáÜÁ°Æ„ÄÅÈ´òÊïà„ÄÇÂ∞ΩÁÆ°ÂÖ∂ËÆ°ÁÆóÈúÄÊ±ÇËæÉÈ´òÔºå‰ΩÜÂÖ∂Âø´ÈÄü„ÄÅÂáÜÁ°ÆÁöÑÁâπÊÄß‰ΩøÂÖ∂Êàê‰∏∫ÂºÄÂèëËÄÖÁöÑÊúâÂäõÂ∑•ÂÖ∑ÔºåËÉΩÂ§üÊèêÈ´òÁîü‰∫ßÂäõÂíåÂ≠¶‰π†ÊïàÁéá„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VENiO-pvY-FzxBLUqodjRQ.jpeg","categories":["Programming","Generative AI","Data Science"],"author":"Rifx.Online","tags":["parameters","coding","benchmarks","languages","efficiency"],"draft":false,"slug":"blog/meet-qwen2-5-coder-32b-instruct-coder-open-source-better-than-gpt4o-5dc8343f8157"},"content":"\n**ËÆ§ËØÜ** Qwen2\\.5\\-Coder\\-32B-CoderÔºåÊÇ®Êñ∞ÁöÑ AI ÁºñÁ†Å‰ºô‰º¥\n\nÊÇ®ÊòØÂê¶ÊõæÂ∏åÊúõÁºñÁ†ÅÂèòÂæóÊõ¥ÁÆÄÂçï„ÄÅÊõ¥Âø´ÈÄüÔºåÁîöËá≥Êõ¥ÊúâË∂£ÔºüÈÇ£‰πàÔºåÂáÜÂ§áÂ•ΩËøéÊé•ÊÇ®ÁöÑÊñ∞ AI ÁºñÁ†ÅÊúãÂèã Qwen2\\.5\\-Coder„ÄÇQwen2\\.5\\-Code ‰∏ìÈó®ÂºÄÂèë‰∫ÜËøô‰∏™Ê®°ÂûãÔºå‰Ωú‰∏∫‰∏Ä‰∏™Â∞ñÁ´ØËØ≠Ë®ÄÊ®°ÂûãÔºå‰ª•ÁÆÄÂåñÊÇ®ÁöÑÁºñÁ†Å‰ΩìÈ™å„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊã•Êúâ‰∏Ä‰∏™Áü•ËØÜÊ∏äÂçöÁöÑÂä©ÊâãÔºåÂèØ‰ª•‰∏∫ÊÇ®ÁºñÂÜô‰ª£Á†Å„ÄÅË∞ÉËØï„ÄÅËß£ÈáäÂ§çÊùÇÊ¶ÇÂøµÔºåÂπ∂Â§ÑÁêÜÂ§öÁßçËØ≠Ë®Ä„ÄÇÊÑüÂÖ¥Ë∂£ÂêóÔºüËÆ©Êàë‰ª¨Êù•ÁúãÁúã Qwen2\\.5\\-Coder Êúâ‰ΩïÁã¨Áâπ‰πãÂ§Ñ„ÄÇ\n\n\n\nüß† **Âº∫Â§ßÁöÑÊÄßËÉΩÔºöÂåπÊïå GPT\\-4o ÁöÑÁºñÁ†ÅËÉΩÂäõ**\n\n> **Qwen2\\.5\\-Coder**ÔºåÁâπÂà´ÊòØ 32B\\-Instruct ÁâàÊú¨Ôºå‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™‰ª£Á†ÅÂä©ÊâãÔºõÂÆÉÊòØ‰∏ÄÊ¨æÈ°∂Á∫ßË°®Áé∞ËÄÖÔºåÂåπÊïåÁîöËá≥Ë∂ÖË∂ä GPT\\-4o Âíå Sonnet 3\\.5ÔºåË¢´ËÆ§‰∏∫ÊòØÊúÄÂº∫Â§ßÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊ®°Âûã‰πã‰∏Ä„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊÇ®‰πüÂèØ‰ª•Êã•ÊúâËøôÁßçÊ∞¥Âπ≥ÁöÑÁºñÁ†ÅËÉΩÂäõ„ÄÇ\n\n## ÂºÄÊ∫ê\n\n‰ΩÜËøôÂπ∂‰∏çÂè™ÊòØÂÖ≥‰∫éÂéüÂßãËÉΩÂäõÔºõËØ•Ê®°ÂûãÂ±ïÁé∞‰∫ÜÂá∫Ëâ≤ÁöÑÊ≠£Á°ÆÊÄßÔºåÁîüÊàê‰∫ÜËØ≠Ê≥ï‰∏äÁ≤æÁ°Æ‰∏îÈ´òÊïàÁöÑ‰ª£Á†Å„ÄÇÊúÄÊ£íÁöÑÊòØ‰ªÄ‰πàÔºüÂÆÉÊØîÂÖ∂ÂâçË∫´Âø´ÂæóÂ§öÔºå‰ΩøÊÇ®ËÉΩÂ§üÂø´ÈÄüÂÆåÊàê‰ªªÂä°„ÄÇ\n\n**‰∏ªË¶ÅÁâπÁÇπ**\n\n* **Ê®°ÂûãÂ§ßÂ∞è**Ôºö320‰∫øÂèÇÊï∞„ÄÇ\n* **‰∏ä‰∏ãÊñáÈïøÂ∫¶**ÔºöÊîØÊåÅÊúÄÂ§ö128K‰∏™tokenÔºåÂÖÅËÆ∏ÂπøÊ≥õÁöÑËæìÂÖ•ÂíåËæìÂá∫ËÉΩÂäõ„ÄÇ\n* **Â§öËØ≠Ë®ÄÊîØÊåÅ**ÔºöËØ•Á≥ªÁªüÂèØ‰ª•Â§ÑÁêÜË∂ÖËøá29ÁßçËØ≠Ë®ÄÔºåÂåÖÊã¨Ëã±ËØ≠„ÄÅ‰∏≠Êñá„ÄÅÊ≥ïËØ≠ÂíåË•øÁè≠ÁâôËØ≠„ÄÇ\n* **Êåá‰ª§ÈÅµÂæ™**ÔºöÊ≠§ÂäüËÉΩÂ¢ûÂº∫‰∫ÜÈÅµÂæ™Â§çÊùÇÊåá‰ª§ÁöÑËÉΩÂäõÔºåÂπ∂ÁîüÊàêÁªìÊûÑÂåñËæìÂá∫ÔºåÂ¶ÇJSON„ÄÇ\n* **ÊÄßËÉΩÂü∫ÂáÜ**ÔºöÂõ¢ÈòüÂú®ÂêÑÁßçÁºñÁ†ÅÂü∫ÂáÜÔºàÂ¶ÇHumanEvalÂíåMATHÔºâ‰∏äÂæóÂàÜÂæàÈ´ò„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zyjKE3ZHtax3uX9GnbKUfA.png)\n\nÊúâÈÄÇÂêàÊâÄÊúâÈúÄÊ±ÇÁöÑÊ®°ÂûãÔºå‰ªéÂ∞èÂûãÂà∞Â§ßÂûã„ÄÇ\n\nÊó†ËÆ∫ÊÇ®ÁöÑÁªèÈ™åÊ∞¥Âπ≥Â¶Ç‰ΩïÔºåQwen2.5-CoderÈÉΩÊèê‰æõÂÖ®Èù¢ÁöÑË¶ÜÁõñ„ÄÇQwen2.5-CoderÊúâÂ§öÁßçÂ§ßÂ∞èÔºå‰ªé0.5BÂà∞‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ32B„ÄÇËøôÊÑèÂë≥ÁùÄÊÇ®ÂèØ‰ª•ÈÄâÊã©ÊúÄÁ¨¶ÂêàÊÇ®ÁöÑÈúÄÊ±ÇÂíåËµÑÊ∫êÁöÑÊ®°Âûã„ÄÇÂ∞±ÂÉèÊã•Êúâ‰∏Ä‰∏™Â∑•ÂÖ∑ÁÆ±ÔºåÈáåÈù¢Êúâ‰∏çÂêåÂ§ßÂ∞èÁöÑÊâ≥ÊâãÔºåÊØè‰∏™ÈÉΩÈÄÇÂêàÁã¨ÁâπÁöÑ‰ªªÂä°„ÄÇ\n\nüåé Á≤æÈÄöÂ§öÁßçËØ≠Ë®Ä\n\n‰ΩøÁî®Â§öÁßçËØ≠Ë®ÄËøõË°åÁºñÁ†ÅÔºüÊ≤°ÈóÆÈ¢òÔºÅQwen2.5-CoderÊîØÊåÅË∂ÖËøá29ÁßçËØ≠Ë®ÄÔºåÂåÖÊã¨Ëã±ËØ≠„ÄÅ‰∏≠Êñá„ÄÅÊ≥ïËØ≠ÂíåË•øÁè≠ÁâôËØ≠Á≠âÊµÅË°åËØ≠Ë®Ä„ÄÇËøôÁßçÂèåËØ≠ËÉΩÂäõ‰ΩøÂÖ∂Êàê‰∏∫ÂÖ®ÁêÉÂºÄÂèë‰∫∫ÂëòÈùûÂ∏∏ÈÄÇÂ∫îÁöÑÂ∑•ÂÖ∑„ÄÇÂ∞±ÂÉèÊã•Êúâ‰∏Ä‰∏™ÈÄöÁî®ÁöÑ‰ª£Á†ÅÁøªËØëÂô®ÔºåÊ∂àÈô§‰∫ÜËØ≠Ë®ÄÈöúÁ¢çÔºåÂºÄÂêØ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇ\n\nüëç ‰ºòÂäøÔºöÊèêÈ´òÁîü‰∫ßÂäõÂíåÊîπÂñÑÂ≠¶‰π†\n\nËÆ©Êàë‰ª¨ËÆ®ËÆ∫‰∏Ä‰∏ã‰ºòÁÇπ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MAhK8R45yNzB8A7mZZITBg.png)\n\n**Èïø‰∏ä‰∏ãÊñáÂ§ÑÁêÜ**ÔºöËØ•Ê®°ÂûãÂèØ‰ª•Â§ÑÁêÜÈïøËææ128K‰∏™tokenÁöÑËæìÂÖ•„ÄÇËøôÂØπ‰∫éÈúÄË¶ÅÂπøÊ≥õËÉåÊôØÁöÑÂ§çÊùÇÁºñÁ†Å‰ªªÂä°Â∞§ÂÖ∂ÊúâÁî®„ÄÇ**Â§öËØ≠Ë®ÄÊäÄËÉΩ**ÔºöQwen2.5-Coder-32B-InstructÊîØÊåÅË∂ÖËøá29ÁßçËØ≠Ë®ÄÔºåÂåÖÊã¨Ëã±ËØ≠„ÄÅ‰∏≠Êñá„ÄÅÊ≥ïËØ≠ÂíåË•øÁè≠ÁâôËØ≠„ÄÇËøô‰ΩøÂÖ∂Êàê‰∏∫Âú®Â§öËØ≠Ë®ÄÈ°πÁõÆ‰∏≠Â∑•‰ΩúÁöÑÂºÄÂèë‰∫∫ÂëòÁöÑÂÆùË¥µÂ∑•ÂÖ∑„ÄÇ\n\nüëé **Áº∫ÁÇπ**ÔºöËµÑÊ∫êÂØÜÈõÜÂûãÂíåËøáÂ∫¶‰æùËµñÁöÑÈ£éÈô©„ÄÇ\n\nÂΩìÁÑ∂ÔºåÊØèÈ°πÊäÄÊúØÈÉΩÊúâÂÖ∂Áº∫ÁÇπ„ÄÇQwen2.5-CoderÂØπÂ§ÑÁêÜËÉΩÂäõÁöÑË¶ÅÊ±ÇÂæàÈ´òÔºåÁâπÂà´ÊòØÂú®ÂÖ∂ËæÉÂ§ßÂèò‰Ωì‰∏≠„ÄÇÂÖÖÂàÜÂà©Áî®ÂÆÉÈúÄË¶ÅÂº∫Â§ßÁöÑÁ°¨‰ª∂„ÄÇ\n\nüéâ **ÁºñÁ†ÅÁöÑÊú™Êù•**Ôºü\n\nQwen2.5-CoderÊ†áÂøóÁùÄAIÈ©±Âä®ÁºñÁ†ÅÁöÑÈáçÂ§ßËøõÂ±ï„ÄÇÂÖ∂Á≤æÁ°ÆÊÄß„ÄÅÈÄüÂ∫¶„ÄÅÈÄÇÂ∫îÊÄßÂíåÂºÄÊ∫êÁâπÊÄß‰ΩøÂÖ∂Êàê‰∏∫‰∏Ä‰∏™Âºï‰∫∫Ê≥®ÁõÆÁöÑÁ™ÅÁ†¥„ÄÇÂØπ‰∫éÂºÄÊ∫êÁ§æÂå∫ÁöÑÁúüÊ≠£Â•ΩÂ§ÑÂ∞ÜÊòØÂ¶ÇÊûúÊâÄÈúÄÁöÑËÆ°ÁÆóËÉΩÂäõÂáèÂ∞ëÔºåÂºÄÂèëÁöÑAPIÊàêÊú¨‰πüÊõ¥‰Ωé„ÄÇ\n\nÈô§Ê≠§‰πãÂ§ñÔºåÂÆÉÈùûÂ∏∏ÊúâÂâçÊôØÔºå‰πüÂ∞Ü‰ΩøÂ§ßÂûãÂèÇ‰∏éËÄÖÂú®‰ªòË¥πÂ¢ô‰∏ãÂèóÂà∞ÊéßÂà∂„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aHeNvfOvcpME0qzy6EQexQ.jpeg)\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PI0ioI2MtxQgtNZ0Tq1jwQ.jpeg)\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/metas-llama-4-is-coming-soon-plus-parallels-brings-apple-intelligence-to-windows-c1c2722dcf03","frontmatter":{"title":"Meta's Llama 4 Âç≥Â∞ÜÊé®Âá∫ Âè¶Â§ñParallels ‰∏∫ Windows Â∏¶Êù• Apple Êô∫ËÉΩ","meta_title":"Meta's Llama 4 Âç≥Â∞ÜÊé®Âá∫ Âè¶Â§ñParallels ‰∏∫ Windows Â∏¶Êù• Apple Êô∫ËÉΩ","description":"Êú™Êèê‰æõÂ≠óÂπï","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*sYakQyN_2Lupo_By","categories":["Technology","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["Llama","GPUs","Parallels","Recraft","Midjourney"],"draft":false,"slug":"blog/metas-llama-4-is-coming-soon-plus-parallels-brings-apple-intelligence-to-windows-c1c2722dcf03"},"content":"\n\n\n### Plus: Parallels Â∞ÜËãπÊûúÊô∫ËÉΩÂ∏¶ÂÖ• Windows\n\n\n\n**Ê¨¢ËøéÊù•Âà∞ Get The Gist**ÔºåÂú®ËøôÈáåÔºåÊàë‰ª¨ÊØè‰∏™Â∑•‰ΩúÊó•ÂàÜ‰∫´ÊúÄÊñ∞ÂíåÊúÄ‰ºüÂ§ßÁöÑ AI ÂèëÂ±ïÁÆÄÊòéÊòìÊáÇÁöÑÊÄªÁªì‚Äî‚ÄîÊñ∞Èóª„ÄÅÂàõÊñ∞ÂíåË∂ãÂäø‚Äî‚ÄîÊâÄÊúâÂÜÖÂÆπÈÉΩÂú® 5 ÂàÜÈíüÂÜÖÈÄÅËææÔºÅ‚è±\n\n**Âú®‰ªäÂ§©ÁöÑÁâàÂùó‰∏≠Ôºö**\n\n* È©¨ÂÖã¬∑ÊâéÂÖã‰ºØÊ†ºÂÆ£Â∏É Meta ÁöÑ Llama 4\n* Parallels Â∞ÜËãπÊûúÊô∫ËÉΩÂ∏¶ÂÖ• Windows\n* Recraft V3 ÊåëÊàò Midjourney\n* Meta AI Áî®Êà∑Ë∂ÖËøá 5 ‰∫ø\n* ËøòÊúâÊõ¥Â§ö AI Êñ∞Èóª‚Ä¶.\n\n## 1\\. MetaÁöÑLlama 4Âç≥Â∞ÜÂèëÂ∏ÉÔºåÂ∏¶Êù•ÈáçÂ§ßAIËøõÂ±ï\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*E_j8uSNV6s3lg2vm)\n\n**Ë¶ÅÁÇπÔºö** È©¨ÂÖã¬∑ÊâéÂÖã‰ºØÊ†º[**Á°ÆËÆ§**](https://analyticsindiamag.com/ai-news-updates/mark-zuckerberg-confirms-llama-4-release-early-next-year/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon) MetaÂ∞ÜÂú®ÊòéÂπ¥ÂàùÊé®Âá∫ÂÖ∂Llama 4Ê®°ÂûãÔºåÊâøËØ∫Âú®ÈÄüÂ∫¶„ÄÅÊé®ÁêÜÂíåË∑®Ê®°ÊÄÅÊñπÈù¢Êèê‰æõÊñ∞ËÉΩÂäõÔºåËøôÂæóÁõä‰∫éÂàõÁ∫™ÂΩïÁöÑËÆ≠ÁªÉÈÖçÁΩÆ„ÄÇ\n\n**ÂÖ≥ÈîÆÁªÜËäÇÔºö**\n\n* MetaÊ≠£Âú®‰ΩøÁî®Ë∂ÖËøá100,000‰∏™H100 GPUÁöÑÂ§ßÂûãÈÖçÁΩÆËÆ≠ÁªÉLlama 4ÔºåËøôÊòØÊä•Âëä‰∏≠ÊúÄÂ§ßÁöÑAIÈõÜÁæ§‰πã‰∏ÄÔºåÁõÆÊ†áÊòØÊØî‰ª•ÂæÄÊõ¥Âø´„ÄÅÊõ¥Âº∫Â§ßÁöÑÊ®°Âûã„ÄÇ\n* Êñ∞ÁöÑLlama 4Â∞ÜÂºïÂÖ•ÂÖàËøõÁöÑÂäüËÉΩÔºåÂ¶ÇÊâ©Â±ïÂÜÖÂ≠ò„ÄÅÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÁ±ªÂûãÂíåÊó†ÁºùÁöÑÁ¨¨‰∏âÊñπÈõÜÊàê„ÄÇ\n* AIÁªßÁª≠Êé®Âä®MetaÁöÑÂ¢ûÈïøÔºåÂõ†‰∏∫ÁîüÊàêÂ∑•ÂÖ∑Â∏ÆÂä©Ë∂ÖËøá‰∏ÄÁôæ‰∏áÂπøÂëäÂÆ¢Êà∑Â∞ÜËΩ¨ÂåñÁéáÊèêÈ´ò7%ÔºåÂπ∂ÊèêÂçáFacebookÂíåInstagram‰∏äÁöÑÁî®Êà∑ÂèÇ‰∏éÂ∫¶„ÄÇ\n* ÊâéÂÖã‰ºØÊ†ºÂº∫Ë∞ÉÔºåAIÂàõÊñ∞Ê≠£Âú®ÂàõÈÄ†Êñ∞ÁöÑÂïÜ‰∏öÊú∫‰ºöÔºåÂº∫Ë∞ÉMetaÂØπ‰∫ßÂìÅÂíåÂπ≥Âè∞ÈïøÊúüAIÈ©±Âä®Â¢ûÈïøÁöÑÊâøËØ∫„ÄÇ\n\n## 2\\. Parallels Â∞Ü Apple Êô∫ËÉΩÂ∏¶ÂÖ• Windows\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*36yykSGFUbML6zR4)\n\n**Ë¶ÅÁÇπÔºö** Parallels Desktop [**Áé∞Âú®ÊîØÊåÅ**](https://www.neowin.net/news/parallels-brings-apple-intelligence-features-to-windows/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon) Âú® Windows ËôöÊãüÊú∫‰∏ä‰ΩøÁî® Apple ÁöÑ AI È©±Âä®ÂÜô‰ΩúÂ∑•ÂÖ∑Ôºå‰ΩøÁî®Êà∑ËÉΩÂ§üÂú® Windows Â∫îÁî®‰∏≠Âà©Áî® Apple Êô∫ËÉΩÂ¢ûÂº∫ÊñáÊú¨„ÄÇ\n\n**‰∏ªË¶ÅÁªÜËäÇÔºö**\n\n* Parallels Desktop 20\\.1 Áé∞Âú®ÊîØÊåÅÂú® macOS Sequoia 15\\.1 ‰∏≠ÁöÑ Windows Â∫îÁî®‰∏ä‰ΩøÁî® Apple ÂÜô‰ΩúÂ∑•ÂÖ∑ÔºåËÆ©Áî®Êà∑ÂèØ‰ª•Âú® Word ÂíåËÆ∞‰∫ãÊú¨Á≠âÂ∫îÁî®‰∏≠ËÆøÈóÆÊñáÊú¨ÊîπËøõÂäüËÉΩÔºåÂ¶ÇÊëòË¶Å„ÄÅÈáçÂÜôÂíåËØ≠Ê∞îË∞ÉÊï¥„ÄÇ\n* Ë¶ÅÊøÄÊ¥ªÊ≠§ÂäüËÉΩÔºå‰ΩøÁî® macOS 15\\.1 ÂíåÂÖºÂÆπÁöÑ MacÔºàM1 ÊàñÊõ¥Êñ∞ÁâàÊú¨ÔºâÁöÑÁî®Êà∑ÂèØ‰ª•Êõ¥Êñ∞ ParallelsÔºåÂπ∂‰ΩøÁî®Âø´Êç∑ÈîÆÂú® Windows Â∫îÁî®‰∏≠Â∫îÁî®Ëøô‰∫õÂ∑•ÂÖ∑„ÄÇ\n* Apple ÂÜô‰ΩúÂ∑•ÂÖ∑ÊòØ Apple Êô∫ËÉΩÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰πüÊ≠£Âú® iPadOS Âíå iOS ‰∏äÊé®Âá∫Ôºå‰ΩÜ‰ªÖÈôê‰∫éÈÖçÂ§áÂÖàËøõÂ§ÑÁêÜÂô®ÁöÑËÆæÂ§áÔºåÂ¶Ç M1„ÄÅM2 Êàñ A17 Pro ËäØÁâá„ÄÇ\n* Ê≠§Êõ¥Êñ∞‰∏∫ Mac Áî®Êà∑Êèê‰æõ‰∫Ü‰∏ÄÁßçÊó†ÁºùÁöÑÊñπÂºèÔºåÂú® Mac Âíå Windows ÁéØÂ¢É‰∏≠Â¢ûÂº∫‰ªñ‰ª¨ÁöÑÂÜô‰ΩúÔºåÂ∞Ü Apple ÁöÑ AI ‰∏é Windows ÁöÑÂèØÁî®ÊÄßÁõ∏ÁªìÂêà„ÄÇ\n\n## 3\\. Recraft V3 ÊåëÊàò MidjourneyÔºåËÅöÁÑ¶ËÆæËÆ°Â∏àÁöÑ AI ÂõæÂÉèÁîüÊàê\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*lYoMCLyX61RKwMiF)\n\n**Ë¶ÅÁÇπÔºö** Recraft [**Â∑≤Êé®Âá∫**](https://www.tomsguide.com/ai/ai-image-video/watch-out-midjourney-recraft-just-announced-new-ai-image-generator-model?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon) Recraft V3ÔºåËøôÊòØ‰∏ÄÊ¨æÊñ∞ÁöÑÂõæÂÉèÁîüÊàê AI Ê®°ÂûãÔºåÊó®Âú®ÈÄöËøáÂº∫Â§ßÁöÑËÆæËÆ°ËÅöÁÑ¶ÂäüËÉΩÂíåÊó†ÁºùÁöÑÊñáÊú¨ÈõÜÊàêË∂ÖË∂ä Midjourney Á≠âÁ´û‰∫âÂØπÊâã„ÄÇ\n\n**ÂÖ≥ÈîÆÁªÜËäÇÔºö**\n\n* Recraft V3 ÂºïÂÖ•‰∫ÜÂõæÂÉè‰∏≠Á≤æÁ°ÆÁöÑÊñáÊú¨Â§ÑÁêÜÂäüËÉΩÔºåÂÖÅËÆ∏Áî®Êà∑ËΩªÊùæÊ∑ªÂä†ÂíåÊ†∑ÂºèÂåñÊñáÊú¨ÔºåËøôÊòØ AI Ê®°Âûã‰∏≠ÁΩïËßÅÁöÑÂäüËÉΩÔºõÁõÆÂâçÂú® Hugging Face ÁöÑÊéíË°åÊ¶ú‰∏äÊéíÂêçÁ¨¨‰∏Ä„ÄÇ\n* ËÆæËÆ°Â∏àÁé∞Âú®ÂèØ‰ª•ÊéßÂà∂ÊñáÊú¨‰ΩçÁΩÆ„ÄÅÂìÅÁâåÈ¢úËâ≤ÂíåÁã¨ÁâπÈ£éÊ†ºÔºåÊèê‰æõÊõ¥Â•ΩÁöÑÂÆöÂà∂ÂåñÔºåÊª°Ë∂≥ÂàõÊÑè‰∏ì‰∏ö‰∫∫Â£´ÁöÑÂÖ≥ÈîÆÈúÄÊ±Ç„ÄÇ\n* ÂÄüÂä©Êó†ÈôêÁîªÂ∏É„ÄÅÂÆûÊó∂Âçè‰ΩúÂíåÁî®‰∫éÈ´òÁ∫ßÂ∑•‰ΩúÊµÅÁ®ãÁöÑ APIÔºåRecraft V3 ÊîØÊåÅ‰∏™‰∫∫ÂíåÂõ¢ÈòüËÆæËÆ°È°πÁõÆ„ÄÇ\n* Recraft Êã•ÊúâË∂ÖËøá 150 ‰∏áÁî®Êà∑ÔºåÁîüÊàê‰∫ÜË∂ÖËøá 2 ‰∫øÂº†ÂõæÂÉèÔºåËØ•Â∑•ÂÖ∑ÂèØÂú®ÁΩëÈ°µ„ÄÅiOS Âíå Android Âπ≥Âè∞‰∏ä‰ΩøÁî®„ÄÇ\n\n## Âø´ÈÄüÊëòË¶Å\n\n* **Zenity** ÂÆåÊàê‰∫Ü 3800 ‰∏áÁæéÂÖÉÁöÑ B ËΩÆËûçËµÑÔºå‰ª•Êé®Ëøõ‰ºÅ‰∏ö‰ΩøÁî®‰ª£ÁêÜ AI Âíå‰Ωé‰ª£Á†ÅÂ∑•ÂÖ∑ÁöÑÂÆâÂÖ®Ëß£ÂÜ≥ÊñπÊ°àÔºåËß£ÂÜ≥ÊµÅÁ®ãËá™Âä®Âåñ‰∏≠ÁöÑÂÖ≥ÈîÆÂÆâÂÖ®ÈóÆÈ¢ò [(ÈòÖËØªÊõ¥Â§ö)](https://www.darkreading.com/application-security/zenity-raises-38m-series-b-funding-round-to-secure-agentic-ai?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon).\n* **OpenAI** Êõ¥Êñ∞‰∫ÜÂÖ∂ÂÆûÊó∂ APIÔºåÊñ∞Â¢û‰∫îÁßçÂØåÊúâË°®Áé∞ÂäõÁöÑËØ≠Èü≥Áî®‰∫éËØ≠Èü≥ÂØπËØ≠Èü≥Â∫îÁî®ÔºåÂπ∂ÈÄöËøáÊèêÁ§∫ÁºìÂ≠òÊòæËëóÈôç‰Ωé‰∫ÜÊàêÊú¨ÔºåÁõÆÂâçÂ§Ñ‰∫éÊµãËØïÈò∂ÊÆµ ([ÈòÖËØªÊõ¥Â§ö](https://venturebeat.com/ai/openai-expands-realtime-api-with-new-voices-and-cuts-prices-for-developers/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **OpenAI** Âú®Ê¨ßÊ¥≤‰∏∫ÂÖçË¥πÁî®Êà∑Êé®Âá∫‰∫ÜÈ´òÁ∫ßËØ≠Èü≥Ê®°ÂºèÔºåÂÖÅËÆ∏‰∏é ChatGPT ËøõË°åÂºï‰∫∫ÂÖ•ËÉúÁöÑ‰∫∫Á±ªËà¨ÁöÑ‰∫íÂä® ([ÈòÖËØªÊõ¥Â§ö](https://www.tomsguide.com/ai/openai-advanced-voice-is-now-free-for-10-minutes-a-month-3-tips-for-getting-the-most-out-of-that-time?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **OpenAI** Ê≠£Âú®‰∏∫ ChatGPT Êé®Âá∫‰∏ÄÈ°πÊñ∞ÂäüËÉΩÔºåÂÖÅËÆ∏Áî®Êà∑ÊêúÁ¥¢‰ªñ‰ª¨ÁöÑËÅäÂ§©ËÆ∞ÂΩïÔºåËÆ°Âàí‰∏ã‰∏™ÊúàÂêëÂÖçË¥πÁî®Êà∑ÂºÄÊîæ ([ÈòÖËØªÊõ¥Â§ö](https://indianexpress.com/article/technology/artificial-intelligence/chatgpt-now-allow-users-to-search-through-their-history-heres-how-to-use-it-9647233/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Meta** Ê≠£Âú®‰∏éÁæéÂõΩÊîøÂ∫úÂêà‰ΩúÔºåÂ∞ÜÂÖ∂ AI Ê®°Âûã Llama Â∫îÁî®‰∫éÂ§ö‰∏™ÂÖ¨ÂÖ±ÈÉ®Èó®È°πÁõÆÔºåÂåÖÊã¨ÊîπÂñÑËµÑÊ∫êËé∑ÂèñÂíåÁÆÄÂåñË¥¢Âä°Êè¥Âä©ÔºåËÄåÊó†ÈúÄÊ∂âÂèä‰ªª‰ΩïË¥¢Âä°‰∫§Êòì ([ÈòÖËØªÊõ¥Â§ö](https://www.newsbytesapp.com/news/science/meta-working-to-get-llama-used-in-us-government-sectors/story?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Meta** ËÆ°ÂàíÂú®ÊòéÂπ¥ÂàùÊé®Âá∫ÂÖ∂ Llama 4 AI Ê®°ÂûãÔºåËÆ≠ÁªÉÂÖ∂Âú®Ë∂ÖËøá 100,000 ‰∏™ H100 GPU ÁöÑÂâçÊâÄÊú™ÊúâÁöÑÈõÜÁæ§‰∏äÔºåÂêåÊó∂Â∞ΩÁÆ°Â≠òÂú®ÊΩúÂú®Êª•Áî®ÁöÑÊãÖÂøßÔºå‰ªçÂÄ°ÂØºÂºÄÊ∫êÊñπÊ≥ï ([ÈòÖËØªÊõ¥Â§ö](https://www.newsbytesapp.com/news/science/meta-trains-llama-4-models-on-largest-nvidia-gpu-cluster/story?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **OpenAI** Â∑≤‰∏∫ ChatGPT Êé®Âá∫‰∫ÜÈ´òÁ∫ßËØ≠Èü≥Ê®°ÂºèÔºåÂÖÅËÆ∏Áî®Êà∑Âú®Ê°åÈù¢Â∫îÁî®‰∏≠ËøõË°åËá™ÁÑ∂ÁöÑËØ≠Èü≥ÂØπËØùÔºåËØ•ÂäüËÉΩÂ∑≤Âú®ËÆ¢ÈòÖÁî®Êà∑‰∏≠Ëé∑Âæó‰∫Ü‰∫∫Ê∞î ([ÈòÖËØªÊõ¥Â§ö](https://www.digitaltrends.com/computing/chatgpt-advanced-voice-mode-macos-windows-desktops/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Waymo** Ê≠£Âú®ÈÄöËøáÂºÄÂèëÊñ∞ÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã EMMA Êù•ÊèêÂçáÂÖ∂Ëá™Âä®È©æÈ©∂ÊäÄÊúØÔºå‰ª•ÊîπÂñÑÂÖ∂Êú∫Âô®‰∫∫Âá∫ÁßüËΩ¶Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂÜ≥Á≠ñËÉΩÂäõÂíåÈÄÇÂ∫îÊÄß ([ÈòÖËØªÊõ¥Â§ö](https://www.theverge.com/2024/10/30/24283516/waymo-google-gemini-llm-ai-robotaxi?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Gemini** Áé∞Âú®‰∏∫Â§ßÂ±è Android ËÆæÂ§áÔºàÂ¶Ç Pixel Tablet Âíå FoldÔºâÊèê‰æõ‰∫ÜÂàÜÂ±èÂø´Êç∑ÊñπÂºèÔºåÂ¢ûÂº∫‰∫ÜÁî®Êà∑‰ΩìÈ™å ([ÈòÖËØªÊõ¥Â§ö](https://www.androidauthority.com/gemini-split-screen-shortcut-3495573/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Meta AI** Âú®Êé®Âá∫‰ªÖ‰∏ÄÂπ¥ÂÜÖÁî®Êà∑Â∑≤Ë∂ÖËøá‰∫î‰∫øÔºåÈ¢ÑËÆ°Âà∞ 2024 Âπ¥Â∫ïÊúâÂèØËÉΩÊàê‰∏∫‰ΩøÁî®ÊúÄÂπøÊ≥õÁöÑ AI Âä©ÊâãÔºåÂ∞ΩÁÆ°Âú®Ê¨ßÁõüÈù¢‰∏¥ÈöêÁßÅÊåëÊàò ([ÈòÖËØªÊõ¥Â§ö](https://www.phonearena.com/news/meta-ai-reaches-500-million-users-in-one-year_id164309?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Adobe** Êõ¥Êñ∞‰∫Ü Illustrator Âíå PhotoshopÔºåÂ¢ûÂä†‰∫Ü AI È©±Âä®ÁöÑÂäüËÉΩÔºå‰ª•ÁÆÄÂåñÂàõ‰ΩúÊµÅÁ®ãÂπ∂Â¢ûÂº∫Áî®Êà∑ÁÅµÊ¥ªÊÄßÔºåÂº∫Ë∞ÉÂ¢ûÂº∫‰∫∫Á±ªÂàõÈÄ†ÂäõËÄåÈùûÂèñ‰ª£ ([ÈòÖËØªÊõ¥Â§ö](https://www.gearpatrol.com/tech/six-new-powerful-ai-features-every-adobe-photoshop-illustrator-must-try/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **NVIDIA** Á†îÁ©∂‰∫∫ÂëòÊé®Âá∫‰∫Ü HOVERÔºåËøôÊòØ‰∏ÄÁßç 150 ‰∏áÂèÇÊï∞ÁöÑÁ•ûÁªèÁΩëÁªúÔºå‰ΩøÁ±ª‰∫∫Êú∫Âô®‰∫∫ËÉΩÂ§üÈÄöËøáÈ´òÊïàÁöÑËøêÂä®ÂçèË∞ÉÂíåÂÆûÊó∂ÈÄÇÂ∫îÊÄßÊâßË°åÂ§çÊùÇ‰ªªÂä° ([ÈòÖËØªÊõ¥Â§ö](https://analyticsindiamag.com/ai-news-updates/nvidia-introduces-hover-a-1-5-m-parameter-neural-network-for-humanoid-robotics/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n* **Google** ‰∏∫ Pixel ËÆæÂ§áÊé®Âá∫‰∫Ü‰∏ÄÊ¨æÊñ∞ÁöÑÁã¨Á´ãÂ§©Ê∞îÂ∫îÁî®ÔºåÂà©Áî® AI ÊÄªÁªìÊà∑Â§ñÊÉÖÂÜµÂπ∂Êèê‰æõÂ§öÂú∞ÁÇπË∑üË∏™ ([ÈòÖËØªÊõ¥Â§ö](https://www.theverge.com/2024/10/30/24283998/google-weather-app-pixel-8-7-6-ai-summaries?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=meta-s-llama-4-is-coming-soon)).\n\n‰ªäÂ§©Â∞±Âà∞ËøôÈáåÔºåÊòéÂ§©ËßÅÔºÅ üëã\n\nÂ¶ÇÊûúÊÇ®ÂñúÊ¨¢Ëøô‰∏™Êõ¥Êñ∞Âπ∂ÊÉ≥‰∫ÜËß£ AI ÁöÑÊúÄÊñ∞ÂèëÂ±ïÔºåËØ∑ËÄÉËôëÂú® Medium ‰∏äËÆ¢ÈòÖ ***Get The Gist*** ‰ª•Ëé∑ÂèñÊõ¥Â§öËßÅËß£ÂíåÂàÜÊûê„ÄÇ\n\n**ÊÉ≥Ë¶ÅÊ∑±ÂÖ•‰∫ÜËß£ÂêóÔºü** ËÆ¢ÈòÖÊàë‰ª¨ÁöÑÂÖçË¥πÊØèÊó•ÁîµÂ≠êÈÇÆ‰ª∂ÈÄöËÆØÔºåÂø´ÈÄü„ÄÅÁÆÄÊ¥ÅÁöÑÊõ¥Êñ∞Áõ¥Êé•ÂèëÈÄÅÂà∞ÊÇ®ÁöÑÊî∂‰ª∂ÁÆ±Ôºå‰ª•‰æøÊÇ®‰∏ç‰ºöÈîôËøá‰ªª‰ΩïÈáçË¶ÅÂèëÂ±ï„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøáÁÇπÂáª [ËøôÈáå](https://getthegist.beehiiv.com/) Ê≥®ÂÜå„ÄÇ\n\nËÆ©Êàë‰ª¨‰∏ÄËµ∑Êé¢Á¥¢ AI ÁöÑ‰∏ñÁïå‚Äî‚ÄîÊØèÊ¨°ÊëòË¶ÅÈÉΩÊòØ‰∏ÄÊ¨°Êñ∞ÁöÑÊóÖÁ®ãÔºÅ üí°ü§ñ\n\n"},{"lang":"zh","group":"blog","slug":"blog/microsoft-graphrag-v0-4-0-ec98f1f6ed7a","frontmatter":{"title":"Microsoft GraphRAG v0.4.0","meta_title":"Microsoft GraphRAG v0.4.0","description":"ÂæÆËΩØÊúÄËøëÂèëÂ∏É‰∫Ü GraphRAG È°πÁõÆÁöÑ v0.4.0 ÁâàÊú¨ÔºåÂÖ∂‰∏≠ÊúâÂá†È°πÈáçÂ§ßÊõ¥Êñ∞„ÄÇÂÖ∂‰∏≠ÊúÄÂºï‰∫∫Ê≥®ÁõÆÁöÑÊõ¥Êñ∞ÊòØ...","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*89qTckZYLUBF1Jtv","categories":["Programming","Data Science","Machine Learning"],"author":"Rifx.Online","tags":["GraphRAG","Incremental","Indexing","DRIFT","Embedding"],"draft":false,"slug":"blog/microsoft-graphrag-v0-4-0-ec98f1f6ed7a"},"content":"\n\n\nÂæÆËΩØÊúÄËøëÂèëÂ∏É‰∫Ü GraphRAG È°πÁõÆÁöÑ v0\\.4\\.0 ÁâàÊú¨ÔºåÂ∏¶Êù•‰∫ÜÂá†È°πÈáçË¶ÅÊõ¥Êñ∞„ÄÇÊúÄÊòæËëóÁöÑÊñ∞Â¢ûÂäüËÉΩÊòØÂ¢ûÈáèÁ¥¢ÂºïÁâπÊÄßÂíå DRIFT ÂõæÊé®ÁêÜÊü•ËØ¢Ê®°ÂùóÔºåËøôÂ§ßÂ§ßÂ¢ûÂº∫‰∫ÜÁ≥ªÁªüÁöÑÊïàÁéáÂíåÂäüËÉΩ„ÄÇ\n\n\n\nÊ≠§Ê¨°Êõ¥Êñ∞ÁöÑÊ†∏ÂøÉ‰∫ÆÁÇπÂåÖÊã¨Ôºö\n\n1\\. Â¢ûÈáèÁ¥¢ÂºïÔºöÊòæËëóÊèêÈ´òÂ§ßËßÑÊ®°Êï∞ÊçÆÂ§ÑÁêÜÁöÑÊïàÁéáÔºåÂÆûÁé∞Êõ¥Âø´ÁöÑ‰ø°ÊÅØÊõ¥Êñ∞„ÄÇ\n\n2\\. DRIFT ÂõæÊé®ÁêÜÊü•ËØ¢Ê®°ÂùóÔºöÂºïÂÖ•ÂÖàËøõÁöÑÂõæÊé®ÁêÜÊäÄÊúØÔºåÂ¢ûÂº∫Â§çÊùÇÊü•ËØ¢Â§ÑÁêÜËÉΩÂäõ„ÄÇ\n\nÊ≠§Â§ñÔºåÁâàÊú¨ 0\\.4\\.0 ‰ºòÂåñ‰∫ÜÂµåÂÖ•Â∑•‰ΩúÊµÅÁ®ãÔºåÈáçÊûÑ‰∫ÜÂ§ÑÁêÜÊµÅÁ®ãÔºåÊèêÈ´ò‰∫ÜÊï¥‰ΩìÁ≥ªÁªüÊÄßËÉΩÂíåÂèØÊìç‰ΩúÊÄß„ÄÇÂÆÉËøòÂ¢ûÂä†‰∫Ü DRIFT ÊêúÁ¥¢ CLI ÂíåÁ§∫‰æãÁ¨îËÆ∞Êú¨Ôºå‰ª•Â∏ÆÂä©ÂºÄÂèë‰∫∫ÂëòÊõ¥Â•ΩÂú∞ÁêÜËß£Êñ∞ÂäüËÉΩ„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•ÂÖ≥Á≥ªÂêàÂπ∂ÂíåÂ¢ûÈáèÊõ¥Êñ∞ÈÖçÁΩÆÈÄâÈ°πËøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫Ü GraphRAG ÁöÑÁÅµÊ¥ªÊÄßÂíåÊô∫ËÉΩÊ∞¥Âπ≥„ÄÇ\n\nËøô‰∫õÊõ¥Êñ∞‰∏ç‰ªÖÊèêÈ´ò‰∫Ü GraphRAG ÁöÑÂ§ÑÁêÜÈÄüÂ∫¶Ôºå‰æãÂ¶ÇÂú®Â§ßËßÑÊ®°ÈáëËûçÊï∞ÊçÆÂàÜÊûê‰∏≠ÔºåÂ¢ûÈáèÁ¥¢ÂºïÁâπÊÄßÂèØ‰ª•Â∞ÜÊï∞ÊçÆÊõ¥Êñ∞Êó∂Èó¥‰ªéÊï∞Â∞èÊó∂ÂáèÂ∞ëÂà∞Êï∞ÂàÜÈíü„ÄÇÂêåÊó∂ÔºåÂÆÉ‰ª¨‰πüÂ¢ûÂº∫‰∫ÜÂÖ∂Âú®Â§çÊùÇÁü•ËØÜÂõæË∞±Â∫îÁî®‰∏≠ÁöÑÈÄÇÁî®ÊÄßÔºåÊòæËëóÊãìÂÆΩ‰∫Ü‰ΩøÁî®Âú∫ÊôØ„ÄÇË°å‰∏ö‰∏ìÂÆ∂È¢ÑÊµãÔºåËøô‰∫õÊîπËøõÂ∞ÜÂú®ÈáëËûçÂàÜÊûêÂíåÂåªÁñóËØäÊñ≠Á≠âÈ¢ÜÂüüÂèëÊå•ÂÖ≥ÈîÆ‰ΩúÁî®ÔºåÊé®Âä® AI Â∫îÁî®ÂêëÊõ¥Á≤æÁ°ÆÂíåÈ´òÊïàÁöÑÊñπÂêëÂèëÂ±ï„ÄÇ\n\nÊõ¥Â§öÊõ¥Êñ∞ÂÜÖÂÆπÔºö [https://proxy.rifx.online/https://github.com/microsoft/graphrag/releases/tag/v0\\.4\\.0](https://proxy.rifx.online/https://github.com/microsoft/graphrag/releases/tag/v0.4.0)\n\n"},{"lang":"zh","group":"blog","slug":"blog/mistral-ai-releases-revolutionary-edge-models-ministral-3b-and-8b-superior-performance-and-privacy-5b24f0189493","frontmatter":{"title":"Mistral AI ÂèëÂ∏ÉÈù©ÂëΩÊÄßËæπÁºòÊ®°Âûã Ministral 3B Âíå 8BÔºöÂçìË∂äÊÄßËÉΩÂíåÈöêÁßÅ","meta_title":"Mistral AI ÂèëÂ∏ÉÈù©ÂëΩÊÄßËæπÁºòÊ®°Âûã Ministral 3B Âíå 8BÔºöÂçìË∂äÊÄßËÉΩÂíåÈöêÁßÅ","description":"Ê≤°ÊúâÊèê‰æõÂ≠óÂπï","date":"2024-10-31T08:32:15.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zFNeFlbfEnbjV5M65sH5ig@2x.jpeg","categories":["Technology","Machine Learning","Autonomous Systems"],"author":"Rifx.Online","tags":["edge","models","privacy","tokens","attention"],"draft":false,"slug":"blog/mistral-ai-releases-revolutionary-edge-models-ministral-3b-and-8b-superior-performance-and-privacy-5b24f0189493"},"content":"\n\n\nÊúÄËøëÔºåMistral AI Êé®Âá∫‰∫Ü‰∏§‰∏™Êñ∞ÁöÑËæπÁºòÊ®°Âûã‚Äî‚ÄîMinistral 3B Âíå Ministral 8BÔºåËøôÂºïËµ∑‰∫ÜÁßëÊäÄÁïåÁöÑÂπøÊ≥õÂÖ≥Ê≥®„ÄÇËøô‰∫õÊ®°Âûã‰∏ç‰ªÖÂú®ÊÄßËÉΩ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåËøòÂú®ÈöêÁßÅ‰øùÊä§ÊñπÈù¢Êèê‰æõ‰∫ÜÁã¨ÁâπÁöÑ‰ºòÂäø„ÄÇ\n\n\n\n## ÂçìË∂äÊÄßËÉΩÔºåÈöêÁßÅ‰ºòÂÖà\n\nMinistral 3B Âíå 8B ‰∏ì‰∏∫ËÆæÂ§áÂÜÖËÆ°ÁÆóËÄåËÆæËÆ°ÔºåËÉΩÂ§üÂ§ÑÁêÜÈïøÂ∫¶Ëææ 128k ÁöÑÊñáÊú¨‰ø°ÊÅØ„ÄÇÁâπÂà´ÊòØÔºåMinistral 8B ÈááÁî®‰∫ÜÂàõÊñ∞ÁöÑÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊòæËëóÊèêÈ´ò‰∫ÜËÆ°ÁÆóÈÄüÂ∫¶ÂíåÂÜÖÂ≠òÊïàÁéá„ÄÇÊ≠§Â§ñÔºåËøô‰∏§‰∏™Ê®°ÂûãÂú®ËÆæËÆ°‰∏ä‰ºòÂÖàËÄÉËôëÈöêÁßÅ‰øùÊä§ÔºåÁ°Æ‰øùÊï∞ÊçÆÂú®Êú¨Âú∞Â§ÑÁêÜÔºå‰ª•Èôç‰ΩéÊï∞ÊçÆÊ≥ÑÈú≤ÁöÑÈ£éÈô©„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GMgT6erSorAGUp-pqbXWhA@2x.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zRGh7rw7oVXYd5mOhXoc3g@2x.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IIYgXVtbHvWqn6QLSZ-0Ow@2x.jpeg)\n\n## Â§öÂäüËÉΩÂ∫îÁî®ÔºåÊó†ÈôêÊΩúÂäõ\n\nMinistralÁ≥ªÂàóÊ®°ÂûãÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇÂú®Êô∫ËÉΩÂä©ÊâãÈ¢ÜÂüüÔºåÂÆÉ‰ª¨ÂèØ‰ª•Âø´ÈÄüÂìçÂ∫îÁî®Êà∑ÂëΩ‰ª§ÔºåÂêåÊó∂Á°Æ‰øùÊï∞ÊçÆÂÆâÂÖ®ÔºõÂú®Ëá™‰∏ªÊú∫Âô®‰∫∫È¢ÜÂüüÔºåÂÆÉ‰ª¨Âº∫Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÊîØÊåÅÂ§çÊùÇÁöÑÂÜ≥Á≠ñÂíåÊìç‰Ωú„ÄÇ\n\n## ÊàêÊú¨ÊïàÁõäÈ´òÔºåÂπøÈòîÁöÑÂ∏ÇÂú∫ÂâçÊôØ\n\nÂ∞ΩÁÆ°Ë°®Áé∞Âá∫Ëâ≤ÔºåMinistral 3B Âíå 8B ÁöÑ‰ª∑Ê†ºÁ´û‰∫âÂäõ‰æùÁÑ∂ÂæàÂº∫„ÄÇ3B ÁöÑ‰ª∑Ê†º‰∏∫ÊØèÁôæ‰∏á‰∏™‰ª§Áâå $0.04ÔºåËÄå 8B ÁöÑ‰ª∑Ê†º‰∏∫ $0.10„ÄÇËøô‰∏ÄÂÆö‰ª∑Á≠ñÁï•‰∏∫‰ºÅ‰∏öÂíåÂºÄÂèëËÄÖÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊàêÊú¨ÊïàÁõäÈ´òÁöÑÈÄâÊã©„ÄÇÁõÆÂâçÔºåËøô‰∏§‰∏™Ê®°ÂûãÂùáÂèØ‰æõ‰ΩøÁî®„ÄÇ\n\n## ÂâçÊôØÂÖâÊòéÔºåÂºïÈ¢ÜËæπÁºòËÆ°ÁÆóÊñ∞Ë∂ãÂäø\n\nMistral AI ÂèëÂ∏ÉÁöÑ Ministral Á≥ªÂàóÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËæπÁºòËÆ°ÁÆóÊñπÈù¢ÁöÑÊ∑±ÂéöÊäÄÊúØÂÆûÂäõÔºå‰∏∫Êú™Êù•ÁöÑËÆæÂ§áÁ´Ø AI Â∫îÁî®Â•†ÂÆö‰∫ÜÂùöÂÆûÂü∫Á°Ä„ÄÇÈöèÁùÄÊäÄÊúØÁöÑËøõÊ≠•ÂíåÂ∫îÁî®ÁöÑÊ∑±ÂÖ•Êé¢Á¥¢ÔºåMinistral Ê®°ÂûãÈ¢ÑËÆ°Â∞ÜÂú®Êô∫ËÉΩËÆæÂ§áÂíåÁâ©ËÅîÁΩë‰∏≠ÂèëÊå•Êõ¥Â§ß‰ΩúÁî®„ÄÇ\n\nÊÄª‰πãÔºåMinistral 3B Âíå 8B ÁöÑÊé®Âá∫‰∏ç‰ªÖÊòØ Mistral AI ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÈáåÁ®ãÁ¢ëÔºå‰πüÊòØ AI Ë°å‰∏öÁöÑ‰∏ÄÊ¨°ÈáçÂ§ßËøõÊ≠•Ôºå‰∏∫ËÆæÂ§áÁ´ØËÆ°ÁÆóÂ∏¶Êù•‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*A6SToo3fO3DqnlWX)\n\n"},{"lang":"zh","group":"blog","slug":"blog/mistral-ai-unveils-ministral-3b-and-8b-models-plus-nvidia-launches-ai-model-that-outperforms-gpt-4-941712f5d22d","frontmatter":{"title":"Mistral AI Êé®Âá∫ Ministral 3B Âíå 8B Ê®°Âûã Âè¶Â§ñÔºöNvidia Êé®Âá∫‰ºò‰∫é GPT-4 ÁöÑ AI Ê®°Âûã","meta_title":"Mistral AI Êé®Âá∫ Ministral 3B Âíå 8B Ê®°Âûã Âè¶Â§ñÔºöNvidia Êé®Âá∫‰ºò‰∫é GPT-4 ÁöÑ AI Ê®°Âûã","description":"Ê≤°ÊúâÊèê‰æõÂ≠óÂπï","date":"2024-10-31T08:29:07.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*PtPEkgjabwBUu73Y","categories":["Technology","Generative AI","Machine Learning"],"author":"Rifx.Online","tags":["Mistral","edge","Llama","YouTube","DreamTracks"],"draft":false,"slug":"blog/mistral-ai-unveils-ministral-3b-and-8b-models-plus-nvidia-launches-ai-model-that-outperforms-gpt-4-941712f5d22d"},"content":"\n\n\n### Plus: NvidiaÊé®Âá∫ÁöÑAIÊ®°ÂûãË∂ÖË∂äGPT\\-4\n\n\n\n**Ê¨¢ËøéÊù•Âà∞Get The Gist**ÔºåÂú®ËøôÈáåÊàë‰ª¨ÊØè‰∏™Â∑•‰ΩúÊó•ÂàÜ‰∫´ÊúÄÊñ∞ÁöÑAIÂèëÂ±ïÂä®ÊÄÅ‚Äî‚ÄîÊñ∞Èóª„ÄÅÂàõÊñ∞ÂíåË∂ãÂäø‚Äî‚ÄîÊâÄÊúâÂÜÖÂÆπÈÉΩÂú®5ÂàÜÈíüÂÜÖËΩªÊùæÈòÖËØªÔºÅ‚è±\n\n**Âú®‰ªäÂ§©ÁöÑÁâàÊú¨‰∏≠Ôºö**\n\n* Mistral AIÊé®Âá∫‰∫ÜÁî®‰∫éËæπÁºòËÆ°ÁÆóÁöÑMinistral 3BÂíå8BÊ®°Âûã\n* NvidiaÊÇÑÁÑ∂Êé®Âá∫ÁöÑAIÊ®°ÂûãË∂ÖË∂äGPT\\-4\n* YouTubeÂêëÁæéÂõΩÂàõ‰ΩúËÄÖÊé®Âá∫AIÈü≥‰πêÂ∑•ÂÖ∑‚ÄúÊ¢¶ÂπªÊõ≤ÁõÆ‚Äù\n* Google GeminiÁé∞Âú®ÂèØ‰ª•ÁîüÊàêÂèØËá™ÂÆö‰πâÂÆΩÈ´òÊØîÁöÑÂõæÂÉè\n* ËøòÊúâÊõ¥Â§öAIÊñ∞Èóª‚Ä¶‚Ä¶\n\n## 1\\. Mistral AI ÂèëÂ∏É Ministral 3B Âíå 8B Ê®°Âûã‰ª•ÊîØÊåÅËæπÁºòËÆ°ÁÆó\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*qAjoYMHGI1TkNy_A)\n\n**Ë¶ÅÁÇπ:** Mistral AI Â∑≤Áªè[**Êé®Âá∫‰∫Ü‰∏§‰∏™Êñ∞ÁöÑ AI Ê®°Âûã**](https://analyticsindiamag.com/ai-news-updates/mistral-ai-launches-ministral-3b-and-8b-models-for-edge-computing/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)ÔºåMinistral 3B Âíå 8BÔºåÊó®Âú®ÂÆûÁé∞È´òÊïàÁöÑËÆæÂ§áÂÜÖÂíåËæπÁºòËÆ°ÁÆó„ÄÇËøô‰∫õÊ®°ÂûãÂú®ÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫ÜÁ´û‰∫âÂØπÊâãÔºåÂπ∂‰∏î‰∏ì‰∏∫ÈúÄË¶ÅÈöêÁßÅ‰ºòÂÖà„ÄÅÊú¨Âú∞Êé®ÁêÜÁöÑ‰ªªÂä°ËÄåËÆæËÆ°„ÄÇ\n\n**ÂÖ≥ÈîÆÁªÜËäÇ:**\n\n* Ê®°ÂûãÂ§ÑÁêÜÂ§ß‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºàÊúÄÈïøÂèØËææ 128kÔºâÔºåÂú®ËµÑÊ∫êÊúâÈôêÁöÑÁéØÂ¢É‰∏≠ÂÆûÁé∞ÊµÅÁïÖÊÄßËÉΩ„ÄÇ\n* ÈÄÇÁî®‰∫éÊô∫ËÉΩÂä©Êâã„ÄÅÊú¨Âú∞ÂàÜÊûêÂíåÊú∫Âô®‰∫∫Á≠âÂ∫îÁî®ÔºåÊèêÂçá‰ªªÂä°ÊïàÁéá„ÄÇ\n* ‰ª•ÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÂÆö‰ª∑Êèê‰æõÂïÜ‰∏ö‰ΩøÁî®ÔºåÂπ∂‰∏∫ 8B Instruct Ê®°ÂûãÊèê‰æõÁ†îÁ©∂ËÆøÈóÆ„ÄÇ\n* Âú®Âü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫Ü Gemma 2 Âíå Llama 3 Á≠â AI Ê®°Âûã„ÄÇ\n\n## 2\\. Nvidia ÂÆâÈùôÊé®Âá∫Ë∂ÖË∂ä GPT\\-4 ÁöÑ AI Ê®°Âûã\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Mza84SHereM3w5rN)\n\n**Ë¶ÅÁÇπ:** Nvidia [**ÂèëÂ∏É‰∫Ü‰∏ÄÊ¨æÊñ∞ AI Ê®°Âûã**](https://venturebeat.com/ai/nvidia-just-dropped-a-new-ai-model-that-crushes-openais-gpt-4-no-big-launch-just-big-results/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)ÔºåLlama\\-3.1\\-Nemotron\\-70B\\-InstructÔºåÂÖ∂ÊÄßËÉΩÂü∫ÂáÜË∂ÖË∂ä‰∫ÜË°å‰∏öÂ∑®Â§¥Â¶Ç OpenAI ÁöÑ GPT\\-4„ÄÇËøôÊ¨°ÂèëÂ∏ÉÊ†áÂøóÁùÄ Nvidia AI ÊàòÁï•ÁöÑÈáçÂ§ßÊâ©Â±ïÔºå‰ªéÁ°¨‰ª∂ËΩ¨ÂêëÈ´òÊÄßËÉΩ AI ËΩØ‰ª∂„ÄÇ\n\n**ÂÖ≥ÈîÆÁªÜËäÇ:**\n\n* Nvidia ÁöÑÊñ∞Ê®°ÂûãÂú®ÂÖ≥ÈîÆÂü∫ÂáÜÊµãËØï‰∏≠ÂæóÂàÜÈ´ò‰∫é GPT\\-4ÔºåÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑËØ≠Ë®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ„ÄÇ\n* ËØ•Ê®°ÂûãÈááÁî®‰∫ÜÂÖàËøõÊäÄÊúØÔºåÂ¶Ç‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π† (RLHF)ÔºåÂú®Â§ÑÁêÜÂ§çÊùÇÊü•ËØ¢ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n* Nvidia ÈÄöËøáÂÖ∂Âπ≥Âè∞Êèê‰æõÂÖçË¥πËÆøÈóÆÔºåÂÖÅËÆ∏‰ºÅ‰∏öËØïÁî®Ëøô‰∏ÄÂº∫Â§ßÁöÑ AI Â∑•ÂÖ∑„ÄÇ\n* ËØ•Ê®°ÂûãÂèØÊ†πÊçÆ‰∏öÂä°ÈúÄÊ±ÇËøõË°åÂÆöÂà∂Ôºå‰ΩÜÂú®Ê≥ïÂæãÊé®ÁêÜÊàñÊï∞Â≠¶Á≠â‰∏ì‰∏öÈ¢ÜÂüüÁöÑ‰ΩøÁî®ÈúÄË¶ÅË∞®ÊÖé„ÄÇ\n\n## 3\\. YouTube Âú®ÁæéÂõΩÊé®Âá∫ AI Èü≥‰πêÂ∑•ÂÖ∑ ‚ÄúDream Tracks‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5nUNrJmdCBBy4JdQ)\n\n**Ë¶ÅÁÇπ:** YouTube Âú®ÁæéÂõΩÊé®Âá∫‰∫ÜÂÖ∂ [**AI È©±Âä®ÁöÑÈü≥‰πêÁîüÊàêÂô®**](https://www.mediapost.com/publications/article/400280/youtube-brings-ai-audio-generator-to-us-creators.html?edition=136037&utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models) ‚ÄúDream Tracks‚ÄùÔºåÂÖÅËÆ∏Âàõ‰ΩúËÄÖ‰ΩøÁî®ÊñáÊú¨ÊèêÁ§∫‰∏∫‰ªñ‰ª¨ÁöÑÁü≠ËßÜÈ¢ëÂàõÂª∫Ëá™ÂÆö‰πâÈü≥È¢ë„ÄÇËØ•Â∑•ÂÖ∑Êó®Âú®ÈÄöËøáÈü≥‰πêÂàõ‰ΩúÂä†Ê∑±Ëâ∫ÊúØÂÆ∂‰∏éÁ≤â‰∏ù‰πãÈó¥ÁöÑËÅîÁ≥ª„ÄÇ\n\n**‰∏ªË¶ÅÁªÜËäÇ:**\n\n* Áî± Google DeepMind ÁöÑ Lyria Êèê‰æõÊîØÊåÅÔºåDream Tracks ‰∏∫ YouTube Shorts ÁîüÊàêÂÆöÂà∂ÁöÑ‰πêÂô®ÈÖç‰πê„ÄÇ\n* ÁæéÂõΩÂàõ‰ΩúËÄÖÁé∞Âú®ÂèØ‰ª•‰ΩøÁî®Ê≠§Â∑•ÂÖ∑ÂàõÂª∫ÊúÄÈïø 30 ÁßíÁöÑÂÖçÁâàÁ®éÈÖç‰πê„ÄÇ\n* Áî®Êà∑ÂèØ‰ª•ÂØπ AI ÁîüÊàêÁöÑÈü≥È¢ëÁâáÊÆµËøõË°åÊ∑∑Èü≥ÔºåÂ¢ûÂº∫Âàõ‰ΩúÂèØËÉΩÊÄß„ÄÇ\n* YouTube ÂØπÊâÄÊúâ AI ÁîüÊàêÁöÑÊõ≤ÁõÆÂ∫îÁî®ÈöêËóèÁöÑ SynthID Ê∞¥Âç∞Ôºå‰ª•Á°Æ‰øùÈÄèÊòéÂ∫¶„ÄÇ\n\n## Âø´ÈÄüÊëòË¶Å\n\n* **Clerk Chat** Ëé∑Âæó‰∫ÜÁî± Race Capital È¢ÜÊäïÁöÑ 700 ‰∏áÁæéÂÖÉËûçËµÑÔºå‰ª•Â¢ûÂº∫ÂÖ∂ AI È©±Âä®ÁöÑÂïÜ‰∏öÊ≤üÈÄöÂπ≥Âè∞ [(ÈòÖËØªÊõ¥Â§ö)](https://www.businesswire.com/news/home/20241017292794/en/World%E2%80%99s-First-AI-Telecom-Clerk-Chat-Raises-7.0-Million-in-Seed-Funding?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)„ÄÇ\n* **Anthropic** È¶ñÂ∏≠ÊâßË°åÂÆò Dario Amodei ÂèëÂ∏É‰∫Ü‰∏ÄÁØáÈïøÁØáÂçöÊñáÔºåÈòêËø∞‰∫ÜÂØπ‰∫∫Â∑•ÈÄöÁî®Êô∫ËÉΩÂèòÈù©ÊΩúÂäõÁöÑ‰πåÊâòÈÇ¶ÊÑøÊôØÔºåÂêåÊó∂ÂØªÊ±Ç‰∏∫ÂÖ¨Âè∏‰∫âÂèñ 400 ‰∫øÁæéÂÖÉÁöÑ‰º∞ÂÄº [(ÈòÖËØªÊõ¥Â§ö)](https://www.theverge.com/2024/10/16/24268209/anthropic-ai-dario-amodei-agi-funding-blog?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)„ÄÇ\n* **Google Cloud** ÂÆ£Â∏ÉÂÖ∂ÂçáÁ∫ßÁâà Vertex AI Âπ≥Âè∞ÂíåÂåªÁñóÊï∞ÊçÆÂºïÊìéÁöÑÊ≠£Âºè‰∏äÁ∫øÔºå‰ª•Â¢ûÂº∫ÂåªÁñóÈ¢ÜÂüüÁöÑ AI Â∫îÁî® [(ÈòÖËØªÊõ¥Â§ö)](https://www.forbes.com/sites/saibala/2024/10/17/google-cloud-announces-general-availability-of-vertex-ai-for-healthcare/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)„ÄÇ\n* **Amazon** È¢ÜÊäï‰∫Ü 5 ‰∫øÁæéÂÖÉÁöÑËûçËµÑËΩÆÔºå‰∏∫ X-energy Êé®Âá∫Âà∞ 2039 Âπ¥ÁöÑ 5GW Â∞èÂûãÊ†∏ÂèçÂ∫îÂ†ÜÔºåËÄå **Google** ‰∏é Kairos Power Âêà‰ΩúÔºåËÆ°ÂàíÂà∞ 2035 Âπ¥ÂÆâË£Ö 500MW ÁöÑÂ∞èÂûãÊ®°ÂùóÂåñÂèçÂ∫îÂ†ÜÔºå‰∫åËÄÖÈÉΩÊó®Âú®Âà©Áî®Ê∏ÖÊ¥ÅËÉΩÊ∫êÊª°Ë∂≥Êï∞ÊçÆ‰∏≠ÂøÉÊó•ÁõäÂ¢ûÈïøÁöÑËÉΩÊ∫êÈúÄÊ±Ç [(ÈòÖËØªÊõ¥Â§ö)](https://www.theengineer.co.uk/content/news/amazon-and-google-bet-big-on-smrs-to-power-ai?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)„ÄÇ\n* **Google** Â∞Ü‰∫é 2025 Âπ¥ÂàùÂú® Google Distributed Cloud ‰∏≠‰∏∫ÂÖ¨ÂÖ±ÈÉ®Èó®Êú∫ÊûÑÊé®Âá∫ÂÖ∂ Gemini AI Ê®°ÂûãÔºåÂπ∂Êèê‰æõËµÑÈáë‰ª•ÊèêÂçáÊîøÂ∫úÂëòÂ∑•Âú®Ë¥üË¥£‰ªªÁöÑ AI ÂÆûË∑µÊñπÈù¢ÁöÑÊäÄËÉΩ [(ÈòÖËØªÊõ¥Â§ö)](https://siliconangle.com/2024/10/16/google-looks-spearhead-ai-adoption-public-sector/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)„ÄÇ\n* **Google** ÁöÑ Gemini AI ËÅäÂ§©Êú∫Âô®‰∫∫Â∞ÜÊé®Âá∫‰∏ÄÈ°πÂäüËÉΩÔºåÂÖÅËÆ∏Áî®Êà∑‰ª•ÂèØËá™ÂÆö‰πâÁöÑÂÆΩÈ´òÊØîÁîüÊàêÂõæÂÉèÔºåÂ¢ûÂº∫ÂÖ∂ÂõæÂÉèÁºñËæëËÉΩÂäõ [(ÈòÖËØªÊõ¥Â§ö)](https://indianexpress.com/article/technology/artificial-intelligence/google-gemini-may-soon-get-new-image-resizing-feature-9623756/?utm_source=getthegist.beehiiv.com&utm_medium=referral&utm_campaign=mistral-ai-unveils-ministral-3b-and-8b-models)„ÄÇ\n\n‰ªäÂ§©Â∞±Âà∞ËøôÈáåÔºåÊòéÂ§©ËßÅÔºÅüëã\n\nÂ¶ÇÊûúÊÇ®ÂñúÊ¨¢Ëøô‰∏™Êõ¥Êñ∞Âπ∂Â∏åÊúõ‰∫ÜËß£ AI ÁöÑÊúÄÊñ∞Âä®ÊÄÅÔºåËØ∑ËÄÉËôëÂú® Medium ‰∏äËÆ¢ÈòÖ ***Get The Gist***ÔºåËé∑ÂèñÊõ¥Â§öËßÅËß£ÂíåÂàÜÊûê„ÄÇ\n\n**ÊÉ≥Ë¶ÅÊõ¥Ê∑±ÂÖ•‰∫ÜËß£ÂêóÔºü** ËÆ¢ÈòÖÊàë‰ª¨ÁöÑÂÖçË¥πÊØèÊó•ÁîµÂ≠êÈÇÆ‰ª∂ÈÄöËÆØÔºåÂø´ÈÄüËé∑ÂèñÁÆÄÊ¥ÅÁöÑÊõ¥Êñ∞ÔºåÁ°Æ‰øùÊÇ®‰∏ç‰ºöÈîôËøá‰ªª‰ΩïÈáçË¶ÅËøõÂ±ï„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøáÁÇπÂáª [ËøôÈáå](https://getthegist.beehiiv.com/) Ê≥®ÂÜå„ÄÇ\n\nËÆ©Êàë‰ª¨‰∏ÄËµ∑Êé¢Á¥¢ AI ÁöÑ‰∏ñÁïå‚Äî‚ÄîÊØèÊ¨°ÊëòË¶ÅÈÉΩÊòØ‰∏ÄÊ¨°Êñ∞ÂèëÁé∞ÔºÅüí°ü§ñ\n\n"},{"lang":"zh","group":"blog","slug":"blog/mojo-90-000-times-faster-than-python-finally-open-sourced-777bdd9a1896","frontmatter":{"title":"MojoÔºåÊØî Python Âø´ 90,000 ÂÄçÔºåÁªà‰∫éÂºÄÊ∫ê‰∫ÜÔºÅ","meta_title":"MojoÔºåÊØî Python Âø´ 90,000 ÂÄçÔºåÁªà‰∫éÂºÄÊ∫ê‰∫ÜÔºÅ","description":"2024Âπ¥3Êúà29Êó•ÔºåModular Inc.ÂÆ£Â∏ÉMojoÊ†∏ÂøÉÁªÑ‰ª∂ÂºÄÊ∫ê„ÄÇ","date":"2024-11-10T22:36:54.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*jcayumihC6jn5q_0","categories":["Programming","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Mojo","Python","MLIR","SIMD","open-source"],"draft":false,"slug":"blog/mojo-90-000-times-faster-than-python-finally-open-sourced-777bdd9a1896"},"content":"\n2024Âπ¥3Êúà29Êó•ÔºåModular Inc.ÂÆ£Â∏ÉÂºÄÊ∫êMojoÁöÑÊ†∏ÂøÉÁªÑ‰ª∂„ÄÇ\n\nMojoÊòØ‰∏ÄÁßç‰∏ìÈó®‰∏∫ÁºñÂÜô‰∫∫Â∑•Êô∫ËÉΩËΩØ‰ª∂ËÄåËÆæËÆ°ÁöÑÁºñÁ®ãËØ≠Ë®ÄÔºåÂéªÂπ¥ÂÖ´ÊúàÊ≠£ÂºèÂèëÂ∏É„ÄÇËá™ÈÇ£Êó∂‰ª•Êù•ÔºåÂÆÉÂ∑≤ÁªèÂê∏Âºï‰∫ÜË∂ÖËøá175,000ÂêçÂºÄÂèëËÄÖÂíå50,000‰∏™ÁªÑÁªá„ÄÇ\n\n‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈÄöÂ∏∏‰ΩøÁî®Â§öÁßçÁºñÁ®ãËØ≠Ë®ÄÁºñÂÜô„ÄÇÂºÄÂèëËÄÖÈÄöÂ∏∏‰ΩøÁî®PythonÂÆûÁé∞Á•ûÁªèÁΩëÁªúÁöÑÊúÄÁÆÄÂçïÈÉ®ÂàÜÔºåÂõ†‰∏∫ÂÆÉÊòì‰∫éÂ≠¶‰π†Ôºå‰ΩÜÁõ∏ÂØπËæÉÊÖ¢„ÄÇÂÖ∂‰Ωô‰ª£Á†ÅÈÄöÂ∏∏Áî®C++ÁºñÂÜôÔºåËôΩÁÑ∂ÈÄüÂ∫¶Êõ¥Âø´Ôºå‰ΩÜÂ≠¶‰π†Ëµ∑Êù•Êõ¥Â§çÊùÇ„ÄÇ\n\nModularÂ∞ÜMojoÂÆö‰Ωç‰∏∫‰∏ÄÁßçÊõ¥Êñπ‰æøÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÂÆÉÊèê‰æõ‰∫ÜÁ±ª‰ººPythonÁöÑÊòìÁî®ËØ≠Ê≥ïÔºå‰ΩÜÊâßË°åÈÄüÂ∫¶ÊúâÂèØËÉΩÂø´‰∏äÂçÉÂÄç„ÄÇÂõ†Ê≠§ÔºåÂºÄÂèëËÄÖÂèØ‰ª•ÁºñÂÜôÂø´ÈÄüÁöÑAIÊ®°ÂûãÔºåËÄåÊó†ÈúÄÂ≠¶‰π†ÂÉèC++ËøôÊ†∑Â§çÊùÇÁöÑËØ≠Ë®Ä„ÄÇ\n\n\n\nÂéªÂπ¥ÔºåÂΩìMojoÊé®Âá∫Êó∂Ôºå‰∏Ä‰∫õÂºÄÂèëËÄÖÂØπÂÆÉÁöÑÂá∫Áé∞Ë°®Á§∫ÂÖ¥Â•ã„ÄÇÁÑ∂ËÄåÔºåÂΩìË¢´ÈóÆÂèäÂºÄÊ∫êÊó•ÊúüÊó∂ÔºåChris LattnerÂú®Discord‰∏äË°®Á§∫Ôºö‚ÄúÂ¶ÇÊûúÊàëÁü•ÈÅìÔºåÊàë‰ºöÂëäËØâ‰Ω†„ÄÇ‚ÄùÂ§ßÁ∫¶‰∏ÄÂπ¥‰ª•Êù•ÔºåËÆ∏Â§öÂºÄÂèëËÄÖÂ§Ñ‰∫éËßÇÂØüÂíåË¥®ÁñëÁöÑÁä∂ÊÄÅÔºö\n\n> ‚ÄúÂÆ£‰º†ÂæàÂ•ΩÔºå‰ΩÜÂ¶ÇÊûú‰∏çÊòØÂºÄÊ∫êÁöÑÔºåÊàë‰∏ç‰ºöËä±Êó∂Èó¥ÂéªÂ∞ùËØï„ÄÇ‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rIJiJylh4-mWBiqz)\n\n> ‚ÄúÊòæÁÑ∂ËøôÊòØ‰∏Ä‰∏™Ë¢´ËøáÂ∫¶ÁÇí‰ΩúÁöÑÁºñÁ®ãËØ≠Ë®ÄÔºåËÄå‰∏îÂÆÉ‰∏çÊòØÂºÄÊ∫êÁöÑÔºÅChris LattnerÊÉ≥Ë¶ÅÊ¨∫È™óÊï∞Áôæ‰∏áPythonÂºÄÂèëËÄÖÔºÅ‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0u5HDKseL0Gy_-8A)\n\n> ‚ÄúÊàëÊó†Ê≥ïÂú®‰∏Ä‰∏™ÂèØËÉΩÂºÄÊ∫ê‰πüÂèØËÉΩ‰∏çÂºÄÊ∫êÁöÑËØ≠Ë®Ä‰∏äËä±Êó∂Èó¥ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂΩìÂâçÁöÑOSSÂïÜ‰∏öÁéØÂ¢É‰∏ã‚Ä¶‚Ä¶‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wrTO7fbKfBZOpBxF)\n\nÁé∞Âú®ÔºåMojoÁªà‰∫éÂºÄÊ∫ê‰∫ÜÔºÅÂú®Áü≠Êó∂Èó¥ÂÜÖÔºåÂÆÉÂ∑≤ÁªèËææÂà∞‰∫Ü17.6kÈ¢óÊòüÂíå2.1k‰∏™forkÔºÅ\n\n## 01 MojoÂºÄÊ∫ê‰πãÊóÖÁöÑÁ¨¨‰∏ÄÊ≠•\n\nModular‰ªäÂ§©ÂÆ£Â∏ÉÂºÄÊ∫êMojoÊ†áÂáÜÂ∫ìÁöÑÊ†∏ÂøÉÁªÑ‰ª∂„ÄÇÊ†áÂáÜÂ∫ìÊûÑÊàê‰∫ÜÁºñÁ®ãËØ≠Ë®ÄÁöÑÊ†∏ÂøÉÈÉ®ÂàÜÔºåÂåÖÂê´Âü∫Êú¨ÁöÑËØ≠Ê≥ïÂÖÉÁ¥†ÂíåÂü∫Êú¨ÂäüËÉΩ„ÄÇMojoÁöÑÊ†áÂáÜÂ∫ìÂåÖÊã¨‰ºòÂåñAIË∂ÖÂèÇÊï∞ÁöÑÂäüËÉΩÔºåËøô‰∫õË∂ÖÂèÇÊï∞ÂÜ≥ÂÆö‰∫ÜÁ•ûÁªèÁΩëÁªúÂ¶Ç‰ΩïÂ§ÑÁêÜÊï∞ÊçÆ„ÄÇ\n\n‚ÄúMojoÊ†áÂáÜÂ∫ì‰ªçÂú®ËøõË°åÊøÄÁÉàÁöÑÂºÄÂèëÂíåÂø´ÈÄüÂèòÂåñÔºåÂõ†Ê≠§Êàë‰ª¨È¶ñÂÖàÂºÄÊ∫êÂÖ∂Ê†∏ÂøÉÊ®°Âùó„ÄÇËøôÊ†áÂøóÁùÄÊàë‰ª¨ÂºÄÊ∫ê‰πãÊóÖÁöÑÈáçË¶ÅËµ∑ÁÇπÔºåËÄå‰∏çÊòØÁªìÊùü„ÄÇ‚Äù\n\nËØ•ÂÖ¨Âè∏Ë°®Á§∫ÔºåÂºÄÊ∫êÂ∞Ü‰Ωø‰ªñ‰ª¨ËÉΩÂ§ü‰ªéÊõ¥Â§öÂºÄÂèëËÄÖÈÇ£ÈáåÊî∂ÈõÜÂèçÈ¶àÔºå‰ªéËÄå‰øÉËøõMojoÁöÑÊõ¥Â•ΩÂºÄÂèë„ÄÇÊ≠§Â§ñÔºåÂºÄÊ∫êÈ°πÁõÆÊúâÂ§öÁßçÊñπÂºèÔºöÊúâ‰∫õÈ°πÁõÆÊèê‰æõÊ∫ê‰ª£Á†Å‰ΩÜ‰∏çÊé•ÂèóË¥°ÁåÆÔºõÊúâ‰∫õÂàôÊèê‰æõ‰∏çÈÄèÊòéÁöÑË¥°ÁåÆÊµÅÁ®ãÔºå‰ΩøÂæóÁêÜËß£ÁõÆÊ†áÂíåË∑ØÁ∫øÂõæÂèòÂæóÂõ∞ÈöæÔºõËøòÊúâ‰∏Ä‰∫õËôΩÁÑ∂ÂºÄÊ∫êÔºå‰ΩÜÂπ∂Êú™ÂæóÂà∞ÁßØÊûÅÁª¥Êä§„ÄÇModularË°®Á§∫Ôºå‰ªñ‰ª¨ÈÄâÊã©‰∫Ü‰∏ÄÁßçÊõ¥ÂÖ®Èù¢ÁöÑÂºÄÊ∫êÊñπÂºèÔºöÈÄöËøáGitHubÊãâÂèñËØ∑Ê±ÇÂÖÅËÆ∏Â§ñÈÉ®Ë¥°ÁåÆÔºåÈºìÂä±ÂºÄÂèëËÄÖÂèÇ‰∏éMojoÁöÑÂºÄÂèëÂíåÊîπËøõÔºåÂπ∂‰øÉËøõÁ§æÂå∫ÁöÑÊàêÈïø„ÄÇ\n\nÊ≠§Â§ñÔºåModularÈÄöËøáÂàÜ‰∫´ÂÆåÊï¥ÁöÑÊèê‰∫§ÂéÜÂè≤ÔºåÂ±ïÁ§∫‰∫ÜËØöÊÑèÔºå‰ªéÂàùÂßãÊèê‰∫§ÂºÄÂßãÔºÅÂÖ¨ÂºÄ‰øÆËÆ¢ÂºÄÊ∫êÊ†áÂáÜÂ∫ìÁöÑÂéÜÂè≤‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üË∑üË∏™‰ª£Á†ÅÁöÑÊºîÂèòÔºåÊõ¥Â•ΩÂú∞ÁêÜËß£ÂÖ∂Âê´‰πâ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0-FqkfLUTevloPjI)\n\nÊ≠§Â§ñÔºå‰ªñ‰ª¨Â∞ÜÂèëÂ∏ÉMojoÁºñËØëÂô®ÁöÑÂ§úÈó¥ÊûÑÂª∫ÔºåÊñπ‰æøÂºÄÂèëËÄÖÂø´ÈÄüÂ∞ùËØïÊúÄÊñ∞ÁöÑÁºñËØëÂô®ÂäüËÉΩÂπ∂ËøõË°åÊåÅÁª≠ÈõÜÊàêÊµãËØï„ÄÇ\n\nÂéªÂπ¥Âπ¥Â∫ïÔºåModularÊé®Âá∫‰∫ÜÂïÜ‰∏öAIÂπ≥Âè∞MAXÔºåËøôÊòØ‰∏Ä‰∏™Áî®‰∫éÊûÑÂª∫È´òÊÄßËÉΩAIÂ∫îÁî®ÁöÑÁªü‰∏ÄÂ∑•ÂÖ∑ÂíåÂ∫ìÈõÜÔºåÂèØ‰ª•È´òÊïàÂú∞ÈÉ®ÁΩ≤Âú®Â§ö‰∏™Á°¨‰ª∂Âπ≥Âè∞‰∏äÔºå‰æãÂ¶ÇÂú®KubernetesÁéØÂ¢É‰∏≠ËøêË°åAIÂ∫îÁî®„ÄÇ‰ªäÂ§©ÔºåËØ•ÂÖ¨Âè∏ÈÄèÈú≤Ôºå‰ªñ‰ª¨ËøòËÆ°ÂàíÂú®Êú™Êù•ÂºÄÊ∫êMAXÁöÑ‰∏Ä‰∫õÁªÑ‰ª∂„ÄÇ\n\nÊ≠§Â§ñÔºåÂÄºÂæó‰∏ÄÊèêÁöÑÊòØÔºå‰ªñ‰ª¨ÈÄâÊã©‰∫ÜApache 2 LLVMËÆ∏ÂèØËØÅËøõË°åÂºÄÊ∫ê„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*dgVCSxaCq6onY2uP)\n\nËøôÊòØApache 2ËÆ∏ÂèØËØÅÁöÑÂÆöÂà∂ÁâàÊú¨„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫Ü‰æø‰∫é‰∏éÈÅµÂæ™GPL2ËÆ∏ÂèØËØÅÁöÑËΩØ‰ª∂ÈõÜÊàêÔºåModularËøõË°å‰∫ÜÁõ∏Â∫îÁöÑË∞ÉÊï¥„ÄÇGPL2ÊòØÂè¶‰∏ÄÁßçÊµÅË°åÁöÑÂºÄÊ∫êËÆ∏ÂèØËØÅÔºåËëóÂêçÂú∞Áî®‰∫éLinuxÂÜÖÊ†∏Á≠âÈ°πÁõÆ„ÄÇÂú®ÂÖ¨ÂëäÂçöÂÆ¢‰∏≠ÔºåModularÂÜôÈÅìÔºö\n\n> ‚ÄúApache 2ËÆ∏ÂèØËØÅÊòØ‰∏Ä‰∏™ËâØÂ•ΩÁöÑËµ∑ÁÇπÔºå‰ΩÜÊàë‰ª¨Âú®LLVMÈ°πÁõÆ‰∏≠‰ΩøÁî®ËÆ∏ÂèØËØÅÁöÑÁªèÈ™åÂëäËØâÊàë‰ª¨ÔºåÂÆÉÊúâ‰∏§‰∏™Â∞èÈóÆÈ¢ò„ÄÇÊúâ‰∫∫ÊãÖÂøÉApache 2ËÆ∏ÂèØËØÅÂèØËÉΩ‰∏éGPL2‰ª£Á†ÅÔºà‰æãÂ¶ÇLinuxÂÜÖÊ†∏Ôºâ‰∏çÂÖºÂÆπÔºåÂπ∂‰∏îApache 2ËÆ∏ÂèØËØÅË¶ÅÊ±ÇÊÇ®Âú®Ê¥æÁîüÈ°πÁõÆ‰∏≠ÊâøËÆ§‰ª£Á†ÅÁöÑ‰ΩøÁî®„ÄÇÊàë‰ª¨Â∏åÊúõÊÇ®ËÉΩÂ§ü‰ΩøÁî®MojoÔºåËÄå‰∏çÂøÖÂº∫Âà∂ÊâøËÆ§ModularÊàñMojo„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Ê∑ªÂä†‰∫ÜLLVMÁâπÂà´ËÆæËÆ°ÁöÑ‰æãÂ§ñÊù°Ê¨æÔºå‰ª•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇ‚Äù\n\n## 02 Âú®Êú™Êù•50Âπ¥‰∏≠ÔºåAIÁºñÁ®ãÁöÑÊúÄ‰Ω≥ËØ≠Ë®ÄÊòØ‰ªÄ‰πàÔºü\n\nÂéªÂπ¥5ÊúàÔºåÂΩìMojoÂàöÂàöÂèëÂ∏ÉÊó∂ÔºåModularÂ£∞Áß∞ÂÆÉÂú®ËøêË°åMandelbrotÁ≠âÁÆóÊ≥ïÊó∂ÊØîÂéüÂßãPythonÂø´35,000ÂÄç„ÄÇ\n\nÂéªÂπ¥9ÊúàÔºåModularÂÜçÊ¨°Ë°®Á§∫Ôºö‚ÄúMojoÁªìÂêà‰∫ÜÂä®ÊÄÅËØ≠Ë®ÄÂíåÈùôÊÄÅËØ≠Ë®ÄÁöÑ‰ºòÁÇπÔºåÊÄßËÉΩÊèêÂçáËá≥PythonÁöÑ68,000ÂÄç„ÄÇ‚Äù\n\nÂéªÂπ¥10ÊúàÔºåÂΩìMojoÂú®Mac‰∏äÂèëÂ∏ÉÊó∂ÔºåModularÂÜçÊ¨°ÊèêÈ´ò‰∫ÜÊÄßËÉΩÊØîËæÉÊï∞ÊçÆÔºö‚ÄúÊØîPythonÂø´90,000ÂÄç„ÄÇ‚Äù\n\nË∞àÂà∞MojoÔºåModularÁöÑÂàõÂßã‰∫∫ÂÖºÈ¶ñÂ∏≠ÊâßË°åÂÆòChris LattnerË°®Á§∫Ôºö‚Äú‰Ω†ÂèØ‰ª•ÊääMojoÁúã‰ΩúPythonÂÆ∂ÊóèÁöÑ‰∏ÄÂëòÔºåÂÄüÈâ¥‰∫ÜÊâÄÊúâËøô‰∫õÈÖ∑ÁÇ´ÁöÑËØ≠Ë®Ä„ÄÅÁºñËØëÂô®ÂíåÂÖ∂‰ªñÊäÄÊúØÔºå‰ΩøPythonÂêëÂâçËøàÂá∫‰∫Ü‰∏ÄÂ§ßÊ≠•„ÄÇÊàë‰ª¨Áõ∏‰ø°ÂÆÉÂ¢ûÂº∫‰∫ÜPythonÁöÑËÉΩÂäõÔºåËµã‰∫àPythonÁ®ãÂ∫èÂëòË∂ÖËÉΩÂäõÔºå‰ΩøÁÜüÊÇâPythonÁöÑ‰∫∫ËÉΩÂ§üÂ≠¶‰π†Êñ∞Áü•ËØÜÔºåÊé¢Á¥¢ÂíåÂæÅÊúçÊñ∞È¢ÜÂüüÔºåËÄåÊó†ÈúÄÂàáÊç¢Âà∞C++„ÄÇ‚Äù\n\nMojoÂü∫‰∫éMLIR‰∏≠ÁöÑÊúÄÊñ∞ÁºñËØëÂô®ÊäÄÊúØÔºåËøôÊòØLLVMÁöÑÊºîÂèòÔºåÂõ†Ê≠§ÊÄßËÉΩÊõ¥‰Ω≥„ÄÇÂè™Ë¶ÅÁ®ãÂ∫èÂëòÂÖ∑Â§áÂøÖË¶ÅÁöÑÊäÄËÉΩÂπ∂ÊÑøÊÑèÂÖÖÂàÜ‰ºòÂåñÔºå‰ªñ‰ª¨Â∞±ÂèØ‰ª•ËÆ©‰ª£Á†ÅËøêË°åÂæóÊûÅÂø´„ÄÇMojoËØ≠Ë®ÄÁöÑÁõÆÊ†áÊòØÊª°Ë∂≥PythonÂºÄÂèëËÄÖÁöÑÈúÄÊ±ÇÔºåÂêåÊó∂Êèê‰æõ‰∏ÄÁ≥ªÂàóÊñ∞ÁöÑ‰ª£Á†Å‰ºòÂåñÊäÄÊúØÔºå‰ª•ÂÖÖÂàÜÂà©Áî®Á°¨‰ª∂ËÆæÂ§áÁöÑÊÄßËÉΩÊûÅÈôê„ÄÇ\n\nÂè¶‰∏ÄÊñπÈù¢ÔºåMojoÂõ¢ÈòüÈ´òÂ∫¶ËµûËµèRustÔºåÂπ∂ÂÖ¨ÂºÄË°®Á§∫‚ÄúMojoÁöÑËÆæËÆ°‰πüÂèóÂà∞RustÁöÑÊûÅÂ§ßÂêØÂèë„ÄÇ‚Äù\n\nÂú®ÊÄßËÉΩÊñπÈù¢ÔºåModularËøõË°å‰∫ÜËÆ∏Â§ö‰∏éPythonÁöÑÊØîËæÉÔºå‰ª•Êèê‰æõÊòéÁ°ÆÁöÑÂØπÊØîÔºå‰ΩÜ‰∫∫‰ª¨Âπ∂Ê≤°ÊúâÊ¶ÇÂøµÂÆÉÊØîRustÂø´Â§öÂ∞ë„ÄÇÂ∞±Âú®‰∏ä‰∏™ÊúàÔºå‰ªñ‰ª¨‰∏ìÈó®ÂõûÂ∫î‰∫Ü‚ÄúMojoÊòØÂê¶ÊØîRustÂø´‚ÄùÁöÑÈóÆÈ¢ò„ÄÇ\n\n‰ªäÂπ¥2ÊúàÔºåNetflixÂ∑•Á®ãÂ∏àÂíåRustÂÄ°ÂØºËÄÖ@ThePrimeagenÂèëÂ∏É‰∫Ü‰∏ÄÊÆµËßÜÈ¢ëÔºöÁî®MojoËß£ÊûêDNAÂ∫èÂàóÔºåÈÄüÂ∫¶Ë∂ÖËøáRust 50%„ÄÇËøôÁØáÂçöÂÆ¢ÂºïÂèë‰∫ÜÂæàÂ§öÂÖ≥Ê≥®ÂíåËÆ®ËÆ∫ÔºåÊØïÁ´üRustË¢´ËßÜ‰∏∫PythonÂíåC++Âú®AIÈ¢ÜÂüüÁöÑÊΩúÂú®Áªß‰ªªËÄÖ„ÄÇ\n\n@ThePrimeagenÂØπMojoÂíåRustÂú®AIÁºñÁ®ã‰∏≠ÁöÑÂ±ïÊúõÔºö\n\n> Â¶ÇÊûúMojoÊ≠£ÂºèÂä†ÂÖ•Á´û‰∫âÔºåÈÇ£‰πàÊàëÁõ∏‰ø°MojoÊó†Áñë‰ºöËÉúÂá∫„ÄÇMojoËé∑ËÉúÁöÑÂéüÂõ†Âú®‰∫éÔºåÂÆÉ‰∏çÈúÄË¶ÅÂØπÂºÄÂèëËÄÖÂ∑≤ÁªèÁÜüÊÇâÁöÑËåÉÂºèËøõË°å‰ªª‰ΩïÊîπÂèò„ÄÇÂè™ÈúÄÁ®çÂä†Â≠¶‰π†ÔºåÂ∞±ËÉΩÂÆûÁé∞ÊÉä‰∫∫ÁöÑÊÄßËÉΩ„ÄÇÈ¶ñÂÖàÔºåMojoÁºñËØëÈÄüÂ∫¶Âø´ÔºåÁî®Êà∑‰ΩìÈ™å‰∏éÂ§ßÂÆ∂Â∑≤ÁªèÁÜüÊÇâÁöÑËØ≠Ë®ÄÈùûÂ∏∏Áõ∏‰ººÔºåÊÄßËÉΩÂèØ‰∏éRustÂ™≤Áæé„ÄÇÂîØ‰∏ÄÁöÑÈóÆÈ¢òÊòØÂ¶Ç‰ΩïËÆ©Êõ¥Â§ö‰∫∫Êé•ÂèóÂÆÉ„ÄÇ\n\nÂú®ÂèëË°®ËØÑËÆ∫ÂêéÔºåÂèó‰∫∫Â∞äÊï¨ÁöÑRustË¥°ÁåÆËÄÖÂèä„ÄäRust: From Zero to Production„ÄãÁöÑ‰ΩúËÄÖLuca PalmieriÂú®X‰∏äÂõûÂ∫îÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Hqe7bPWGI36LPGzE)\n\nRustÂú®Á≥ªÁªüÁºñÁ®ãÈ¢ÜÂüüÊã•ÊúâÈ°∂Â∞ñÁöÑËÆæËÆ°Ôºå‰ΩÜÂú®AIÂ∫îÁî®È¢ÜÂüüÈù¢‰∏¥‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢òÔºö\n\n* ÁºñËØëÈÄüÂ∫¶ÊÖ¢ÔºåËÄåAIÂº∫Ë∞ÉÂÆûÈ™åÂíåÂø´ÈÄüËø≠‰ª£„ÄÇ\n* Â§ßÂ§öÊï∞ÊúâPythonÁªèÈ™åÁöÑAIÁ†îÁ©∂‰∫∫Âëò‰∏çÊÑøÊÑèËä±Êó∂Èó¥‰ªéÈõ∂ÂºÄÂßãÂ≠¶‰π†‰∏ÄÈó®Êñ∞ËØ≠Ë®Ä„ÄÇ\n\nMojoÊó®Âú®‰ΩøPythonÂºÄÂèëËÄÖËÉΩÂ§üÁõ¥ËßÇ‰∏îËΩªÊùæÂú∞ÊéåÊè°„ÄÇÊ≠£Â¶ÇMohamedÊâÄÁ§∫Ôºå‰ªñÂú®Âá†Âë®ÂÜÖ‰Ωú‰∏∫‰∏Ä‰∏™‰∏ö‰ΩôÈ°πÁõÆÂ≠¶‰π†‰∫ÜMojoÔºåÂπ∂Âà©Áî®SIMD‰ºòÂåñÁÆóÊ≥ïÔºàÂàùÂßãÂÆûÁé∞‰ªÖÈúÄ200Ë°å‰ª£Á†ÅÔºâ„ÄÇ\n\nÂØπ‰∫éÈÇ£‰∫õÂØπAIÂºÄÂèëÊÑüÂÖ¥Ë∂£ÁöÑ‰∫∫Êù•ËØ¥ÔºåÁ°ÆÂÆûÂ≠òÂú®Âú®‰∏âÁßçÂèØÁî®ËØ≠Ë®Ä‰∏≠ÈÄâÊã©ÂÖ∂‰∏ÄÁöÑÂõ∞Â¢É„ÄÇ\n\nMojoÂíåRustÈÉΩÂÖÅËÆ∏ÂºÄÂèëËÄÖÂú®Êõ¥‰ΩéÁöÑÂ±ÇÈù¢ËøõË°å‰ºòÂåñ„ÄÇÂØπ‰∫éRustÔºåÂºÄÂèëËÄÖÂΩìÁÑ∂ÂèØ‰ª•Â∞ÜÊâÄÊúâÂÜÖÂÆπÊâìÂåÖÂà∞Arc„ÄÅMutexÊàñBox‰∏≠Ôºå‰ª•ÈÅøÂÖç‰∏éÂÄüÁî®Ê£ÄÊü•Âô®ÁöÑÂÜ≤Á™ÅÔºå‰ΩÜËøôÂèØËÉΩ‰ºöÁâ∫Áâ≤‰∏Ä‰∫õÊÄßËÉΩ„ÄÇËôΩÁÑ∂ËøôÁßçÊÄßËÉΩÂ∑ÆÂºÇÂèØËÉΩÂØπÂ∫îÁî®‰ª£Á†ÅÊ≤°ÊúâÊòæËëóÂΩ±ÂìçÔºå‰ΩÜÂú®Â∫ìÊàñÂÖ∂‰ªñÊÄßËÉΩÊïèÊÑü‰ª£Á†Å‰∏≠ÂèØËÉΩ‰ºöËøÖÈÄüÁ¥ØÁßØ„ÄÇ‰∏§ËÄÖÁöÑÈÄâÊã©ÂèñÂÜ≥‰∫éÁ®ãÂ∫èÂëòÂØπÂáèÂ∞ëÂºÄÈîÄÂíå‰ºòÂåñÊÄßËÉΩÁöÑÂÖ≥Ê≥®„ÄÇ\n\nËøô‰∏§ÁßçËØ≠Ë®ÄÈÉΩÂèØ‰ª•Âà©Áî®LLVMËøõË°å‰ª£Á†ÅÁîüÊàê‰ºòÂåñÔºåÂπ∂ÂÖÅËÆ∏‰ΩøÁî®ÂÜÖËÅîÊ±áÁºñÔºàÂ∞ΩÁÆ°ÂÆûÈôÖ‰∏ä‰∏çÂ§™ÂèØËÉΩÊúâ‰∫∫ËøôÊ†∑ÂÅöÔºâÔºåÂõ†Ê≠§ÁêÜËÆ∫‰∏äÔºå‰∏§ËÄÖÂú®‰º†ÁªüÁ°¨‰ª∂‰∏äÁöÑÊÄßËÉΩÊΩúÂäõÁõ∏‰ºº„ÄÇ\n\n## 03 Âü∫‰∫éÊúÄÂÖàËøõÁöÑÁºñËØëÂô®ÊäÄÊúØ\n\nRust ‰∫é 2006 Âπ¥ÂêØÂä®ÔºåËÄå Swift ‰∫é 2010 Âπ¥Âá∫Áé∞Ôºå‰∏§ËÄÖ‰∏ªË¶ÅÂü∫‰∫é LLVM IR ÊûÑÂª∫„ÄÇËÄå Mojo ÂàôÂú® 2022 Âπ¥È¶ñÊ¨°‰∫ÆÁõ∏ÔºåÊûÑÂª∫‰∫é MLIR ‰πã‰∏ä‚Äî‚Äî‰∏é Rust ‰ΩøÁî®ÁöÑ LLVM IR Áõ∏ÊØîÔºåMLIR ÊòØ‰∏Ä‰∏™Êõ¥Áé∞‰ª£ÁöÑ‚Äú‰∏ã‰∏Ä‰ª£‚ÄùÁºñËØëÂô®Ê†à„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåChris Lattner Âú® 2000 Âπ¥ 12 ÊúàÂ§ßÂ≠¶Êó∂ÊúüÂàõÁ´ã‰∫Ü LLVMÔºåÂπ∂‰ªéÂÖ∂Â§öÂπ¥ÁöÑÊºîÂèò‰∏≠Â≠¶‰π†‰∫ÜÂæàÂ§ö„ÄÇ‰ªñÂêéÊù•Âä†ÂÖ• Google È¢ÜÂØº MLIR ÁöÑÂºÄÂèëÔºåÊó®Âú®ÊîØÊåÅÂÖ¨Âè∏ÁöÑ TPU ÂíåÂÖ∂‰ªñ AI Âä†ÈÄüÂô®È°πÁõÆ„ÄÇÈöèÂêéÔºå‰ªñÁªßÁª≠Âü∫‰∫é‰ªé LLVM IR ‰∏≠Ëé∑ÂæóÁöÑÁü•ËØÜËøõË°åÊé¢Á¥¢„ÄÇ\n\nModular Ë°®Á§∫ Mojo ÊòØÁ¨¨‰∏Ä‰∏™ÂÖÖÂàÜÂà©Áî® MLIR È´òÁ∫ßÁâπÊÄßÁöÑÁºñÁ®ãËØ≠Ë®Ä„ÄÇÂÆÉÂèØ‰ª•ÁîüÊàêÂÖ∑ÊúâÊõ¥È´ò‰ºòÂåñÁöÑ CPU ‰ª£Á†ÅÔºåÂπ∂‰∏îËøòÊîØÊåÅ GPU ÂíåÂÖ∂‰ªñÂä†ÈÄüÂô®ÔºåÈÄüÂ∫¶ÊØî Rust Âø´ÂæóÂ§ö„ÄÇËøôÊòØÁõÆÂâçÂÖ∂‰ªñËØ≠Ë®ÄÊó†Ê≥ïÂÆûÁé∞ÁöÑ‰ºòÂäøÔºå‰πüÊòØ AI ÂíåÁºñËØëÂô®Áà±Â•ΩËÄÖÂØπ Mojo ÁÉ≠ÊÉÖÁöÑÊ†∏ÂøÉÂéüÂõ†„ÄÇ\n\n‰ªñ‰ª¨ÁâπÂà´Âº∫Ë∞É‰∏§‰∏™ÊñπÈù¢Ôºö\n\nÂá∫Ëâ≤ÁöÑ SIMD ‰∫∫‰ΩìÂ∑•Á®ãÂ≠¶ËÆæËÆ°ÔºöCPU ÈÄöËøáÁâπÊÆäÂØÑÂ≠òÂô®ÂíåÊåá‰ª§ÂêåÊó∂Â§ÑÁêÜÂ§ö‰∏™Êï∞ÊçÆÂÖÉÁ¥†ÔºåÁß∞‰∏∫ SIMDÔºàÂçïÊåá‰ª§Â§öÊï∞ÊçÆÔºâ„ÄÇÁÑ∂ËÄåÔºå‰ªéÂéÜÂè≤‰∏äÁúãÔºåÁºñÂÜôÊ≠§Á±ª‰ª£Á†ÅÁöÑ‰ΩìÈ™å‰∏ÄÁõ¥ÂæàÁ≥üÁ≥ïÔºåÂπ∂‰∏îÂú®‰∫∫‰ΩìÂ∑•Á®ãÂ≠¶ÊñπÈù¢ÂæàÈöæ‰ΩøÁî®„ÄÇÂ∞ΩÁÆ°Ëøô‰∫õÁâπÊÆäÊåá‰ª§Â∑≤ÁªèÂ≠òÂú®Â§öÂπ¥Ôºå‰ΩÜÂ§ßÂ§öÊï∞‰ª£Á†ÅÂπ∂Êú™ÈíàÂØπÂÆÉ‰ª¨ËøõË°å‰ºòÂåñ„ÄÇÂõ†Ê≠§ÔºåË∞ÅËÉΩËß£ÂÜ≥ËøôÁßçÂ§çÊùÇÊÄßÂπ∂ÁºñÂÜôÂèØÁßªÊ§çÁöÑ SIMD ‰ºòÂåñÁÆóÊ≥ïÔºåË∞ÅÂ∞±ËÉΩÂú®Â∏ÇÂú∫‰∏≠ËÑ±È¢ñËÄåÂá∫Ôºå‰æãÂ¶Ç simd_json„ÄÇ\n\nMojo ÁöÑÂéüËØ≠‰ªé‰∏ÄÂºÄÂßãÂ∞±‰ª• SIMD ‰∏∫‰ºòÂÖàËÆæËÆ°ÔºöUInt8 ÂÆûÈôÖ‰∏äÊòØ SIMD\\[DType.uint8, 1]ÔºåË°®Á§∫‰∏Ä‰∏™ÂÖÉÁ¥†ÁöÑ SIMD„ÄÇËøôÁßçË°®Á§∫‰∏ç‰ºöÂ∏¶Êù•ÊÄßËÉΩÂºÄÈîÄÔºåÂêåÊó∂ÂÖÅËÆ∏Á®ãÂ∫èÂëòËΩªÊùæÂú∞Â∞ÜÂÖ∂Áî®‰∫é SIMD ‰ºòÂåñ„ÄÇ‰æãÂ¶ÇÔºåÊñáÊú¨ÂèØ‰ª•Ë¢´ÊãÜÂàÜ‰∏∫ 64 Â≠óËäÇÁöÑÂùóÔºåË°®Á§∫‰∏∫ SIMD\\[DType.uint8, 64]ÔºåÁÑ∂Âêé‰∏éÂçï‰∏™Êç¢Ë°åÁ¨¶ËøõË°åÊØîËæÉÔºå‰ª•ÊâæÂà∞ÊØè‰∏™Êç¢Ë°åÁ¨¶ÁöÑÁ¥¢Âºï„ÄÇÁî±‰∫éÊú∫Âô®‰∏äÁöÑ SIMD ÂØÑÂ≠òÂô®ÂèØ‰ª•ÂêåÊó∂ÂØπ 512 ‰ΩçÊï∞ÊçÆÊâßË°åÊìç‰ΩúÔºåÂõ†Ê≠§Ê≠§Êìç‰ΩúÂèØ‰ª•Â∞ÜÊ≠§Á±ªÊìç‰ΩúÁöÑÊÄßËÉΩÊèêÂçá 64 ÂÄçÔºÅ\n\nÊàñËÄÖÁªôÂá∫‰∏Ä‰∏™Êõ¥ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºåÂÅáËÆæ‰Ω†Êúâ‰∏Ä‰∏™ SIMDDType.float64, 8„ÄÇÂè™ÈúÄÂ∞ÜÂÖ∂‰πò‰ª• Float64(2)Ôºå‰Ω†Â∞±ÂèØ‰ª•ËΩªÊùæÊèêÈ´òÊÄßËÉΩ„ÄÇ‰∏éÈÄê‰∏™‰πò‰ª•ÊØè‰∏™ÂÖÉÁ¥†Áõ∏ÊØîÔºåËøôÁßçÊñπÊ≥ïÂèØ‰ª•Âú®Â§ßÂ§öÊï∞Êú∫Âô®‰∏äÂ∞ÜÊÄßËÉΩÊèêÈ´òÂ§öËææ 8 ÂÄç„ÄÇ\n\nLLVMÔºàRust ‰πüÂú®‰ΩøÁî®ÔºâÂÖ∑ÊúâËá™Âä®ÂêëÈáèÂåñ‰ºòÂåñÈÄöÈÅìÔºå‰ΩÜÁî±‰∫éÂÖ∂Êó†Ê≥ïÊõ¥Êîπ SIMD ÁöÑÂÜÖÂ≠òÂ∏ÉÂ±ÄÂíåÂÖ∂‰ªñÈáçË¶ÅÁªÜËäÇÔºåÂÖ∂ÊÄßËÉΩ‰ªéÊú™ËææÂà∞ÁêÜËÆ∫‰ºòÂåñÊ∞¥Âπ≥„ÄÇÁÑ∂ËÄåÔºåMojo ‰ªé‰∏ÄÂºÄÂßãÂ∞±ËÄÉËôë‰∫Ü SIMD ÁâπÊÄßÔºåÂõ†Ê≠§ÁºñÂÜô SIMD ‰ºòÂåñÁöÑ‰ΩìÈ™å‰∏éÁºñÂÜôÂ∏∏ËßÑ‰ª£Á†ÅÈùûÂ∏∏Áõ∏‰ºº„ÄÇ\n\nÊÄ•ÂàáÈîÄÊØÅÔºöRust ÁöÑËÆæËÆ°ÂèóÂà∞ C++ ÁöÑ RAIIÔºàËµÑÊ∫êËé∑ÂèñÂç≥ÂàùÂßãÂåñÔºâÂêØÂèëÔºåËøôÊÑèÂë≥ÁùÄ‰∏ÄÊó¶ÂØπË±°Ë∂ÖÂá∫‰ΩúÁî®ÂüüÔºåÂ∫îÁî®Á®ãÂ∫èÂºÄÂèë‰∫∫Âëò‰∏çÈúÄË¶ÅÊãÖÂøÉÈáäÊîæÂÜÖÂ≠ò‚Äî‚ÄîÁºñÁ®ãËØ≠Ë®ÄÊú¨Ë∫´‰ºöÂ§ÑÁêÜËøô‰∏ÄÁÇπ„ÄÇËøôÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑ‰æãÂ≠êÔºåÈÅøÂÖç‰∫ÜÂûÉÂúæÂõûÊî∂ÁöÑÊÄßËÉΩÈô∑Èò±ÔºåÂêåÊó∂Á°Æ‰øù‰∫ÜÂä®ÊÄÅËØ≠Ë®ÄÁöÑ‰∫∫‰ΩìÂ∑•Á®ãÂ≠¶„ÄÇ\n\nMojo Êõ¥Ëøõ‰∏ÄÊ≠•Ôºå‰∏çÊòØÁ≠âÂà∞‰ΩúÁî®ÂüüÁªìÊùüÔºåËÄåÊòØÂú®ÂØπË±°ÊúÄÂêé‰∏ÄÊ¨°‰ΩøÁî®Êó∂ÈáäÊîæÂÜÖÂ≠ò„ÄÇËøôÂØπ‰∫é AI Âú∫ÊôØÈùûÂ∏∏ÊúâÁõäÔºåÂõ†‰∏∫ÊèêÂâçÈáäÊîæÂØπË±°ÊÑèÂë≥ÁùÄÊèêÂâçÈáäÊîæ GPU Âº†ÈáèÔºå‰ªéËÄåÂÖÅËÆ∏Âú®Á≠âÊïàÁöÑ GPU RAM ‰∏≠ÈÄÇÂ∫îÊõ¥Â§ßÁöÑÊ®°Âûã„ÄÇËøôÊòØ Mojo ÁöÑÁã¨Áâπ‰ºòÂäøÔºå‰ΩøÁ®ãÂ∫èÂëòËÉΩÂ§üÂú®‰∏çÂøÖËá™Â∑±ËÆæËÆ°ÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞ÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇRust ÁöÑÂÄüÁî®Ê£ÄÊü•Âô®ÊúÄÂàùÂ∞ÜÊâÄÊúâ‰∫ãÁâ©ÁöÑÁîüÂëΩÂë®ÊúüÂª∂ÈïøÂà∞ÂÖ∂‰ΩúÁî®ÂüüÁöÑÁªìÊùüÔºåÂåπÈÖçÊûêÊûÑÂáΩÊï∞ÁöÑË°å‰∏∫Ôºå‰ΩÜËøôÂèØËÉΩ‰ºöÁªôÁî®Êà∑Â∏¶Êù•‰∏Ä‰∫õÂõ∞ÊÉëÁöÑÂêéÊûú„ÄÇRust ÂêéÊù•Ê∑ªÂä†‰∫Ü‰∏Ä‰∫õÈùûËØçÊ≥ïÁîüÂëΩÂë®ÊúüÁâπÊÄßÔºå‰ª•ÁÆÄÂåñÂºÄÂèë‰∫∫ÂëòÁöÑÂ∑•‰Ωú„ÄÇÁÑ∂ËÄåÔºåÈÄöËøá Mojo ÁöÑÊÄ•ÂàáÊûêÊûÑÊú∫Âà∂ÔºåÂèØ‰ª•Áõ¥Êé•ÂÆûÁé∞ËøôÁßçÁÆÄÂåñÊïàÊûúÔºåÂπ∂‰∏î‰∏éÂØπË±°ÂÆûÈôÖÈîÄÊØÅÁöÑÊñπÂºè‰øùÊåÅ‰∏ÄËá¥Ôºå‰ªéËÄåÈÅøÂÖç‰ª§‰∫∫Âõ∞ÊÉëÁöÑÊûÅÁ´ØÊÉÖÂÜµ„ÄÇ\n\nRust Âè¶‰∏Ä‰∏™ÂºÄÈîÄÊù•Ëá™ Drop ÁöÑÂÆûÁé∞„ÄÇÂÆÉ‰ΩøÁî® Drop Flags Êù•Ë∑üË∏™ÂØπË±°ÊòØÂê¶Â∫îËØ•Âú®ËøêË°åÊó∂Ë¢´Âà†Èô§„ÄÇRust ËÉΩÂ§üÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãËøõË°å‰ºòÂåñÔºå‰ΩÜ Mojo ÂèØ‰ª•ÈÄöËøáÊòæÂºèÂÆö‰πâÊ∂àÈô§ÊâÄÊúâÈ¢ùÂ§ñÂºÄÈîÄ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0VcMppg3rDTqfsMY)\n\nÊó†ËÆ∫Â¶Ç‰ΩïÔºåÂºÄÂèë‰∫∫ÂëòÂøÖÈ°ªÂú® Mojo Âíå Python ÁöÑÊòìÁî®ÊÄßÔºå‰ª•Âèä C„ÄÅC++ Êàñ Rust ÁöÑÈ´òÊÄßËÉΩ‰πãÈó¥ÂÅöÂá∫ÈÄâÊã©„ÄÇÂØπÊ≠§ÔºåMojo Âõ¢ÈòüÂëºÂêÅÂºÄÂèë‰∫∫ÂëòÔºö‚ÄúÂ¶ÇÊûú‰Ω†ÂØπÊú™Êù•ÂÖÖÊª°Â•ΩÂ•áÔºåÂ∏åÊúõÊéåÊè°‰∏ÄÁßçÂèØËÉΩÂú®Êú™Êù• 50 Âπ¥ÂÜÖ‰øÉËøõ AI ÂèëÂ±ïÁöÑËØ≠Ë®ÄÔºå‰∏∫‰ªÄ‰πà‰∏çËØïËØï Mojo Âë¢Ôºü‚Äù\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/multi-agent-hedge-fund-simulation-with-langchain-and-langgraph-64060aabe711","frontmatter":{"title":"Âà©Áî® LangChain Âíå LangGraph ËøõË°åÂ§ö‰ª£ÁêÜÂØπÂÜ≤Âü∫ÈáëÊ®°Êãü","meta_title":"Âà©Áî® LangChain Âíå LangGraph ËøõË°åÂ§ö‰ª£ÁêÜÂØπÂÜ≤Âü∫ÈáëÊ®°Êãü","description":"Êú¨È°πÁõÆÊºîÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Â§ö‰ª£ÁêÜËÆæÁΩÆÊù•Ê®°ÊãüÂØπÂÜ≤Âü∫ÈáëÁöÑÂàÜÊûêÊµÅÁ®ã„ÄÇÂÆÉÂ±ïÁ§∫‰∫Ü‰∏ÄÁßçÂÆûÁî®ÁöÑÊñπÊ≥ïÊù•...","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*i8wneK22YezD7zOhPKvZfg.png","categories":["Finance","Programming","Data Science"],"author":"Rifx.Online","tags":["multi-agent","LangChain","LangGraph","FinancialDatasets","predictive"],"draft":false,"slug":"blog/multi-agent-hedge-fund-simulation-with-langchain-and-langgraph-64060aabe711"},"content":"\n### Â§öÊô∫ËÉΩ‰ΩìÂØπÂÜ≤Âü∫ÈáëÊ®°Êãü‰∏é LangChain Âíå LangGraph\n\n\n\nËØ•È°πÁõÆÊºîÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Â§öÊô∫ËÉΩ‰ΩìËÆæÁΩÆÊù•Ê®°ÊãüÂØπÂÜ≤Âü∫ÈáëÁöÑÂàÜÊûêËøáÁ®ã„ÄÇÂÆÉÂ±ïÁ§∫‰∫Ü‰∏ÄÁßçÂÆûÁî®ÁöÑÊñπÊ≥ïÊù•ÊûÑÂª∫‰∏Ä‰∏™Á≥ªÁªüÔºåËØ•Á≥ªÁªüÂà©Áî® AI Êô∫ËÉΩ‰ΩìÊî∂ÈõÜÂíåÂàÜÊûêÈáëËûçÊï∞ÊçÆÔºåËøôÁßçËÆæÁΩÆÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂíåÂÆöÂà∂„ÄÇÂú®ËøôÈáåÔºåÊàëÂ∞ÜÂàÜËß£ËØ•È°πÁõÆÔºåÂÖ∂‰∏≠Ê∂âÂèä‰∏Ä‰∏™ÊäïËµÑÁªÑÂêàÁªèÁêÜÂíå‰∏â‰∏™ÂàÜÊûêÂ∏àÊô∫ËÉΩ‰ΩìÔºàÂü∫Êú¨Èù¢„ÄÅÊäÄÊúØÈù¢ÂíåÊÉÖÁª™Èù¢ÔºâÔºåÊØè‰∏™Êô∫ËÉΩ‰ΩìÂú®Êî∂ÈõÜÂíåÂ§ÑÁêÜËÇ°Á•®Êï∞ÊçÆÊñπÈù¢Ë¢´ÂàÜÈÖç‰∫ÜÁâπÂÆöËßíËâ≤„ÄÇ\n\nËØ•È°πÁõÆÁöÑÁõÆÊ†á‰∏çÊòØÊûÑÂª∫‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑ‰∫§ÊòìÁÆóÊ≥ïÔºåËÄåÊòØËØ¥ÊòéÂ¶Ç‰Ωï‰ΩøÁî® LangChain Âíå LangGraph ÁªÑÁªáÂíåÂπ∂Ë°åÂàÜÊûêÂêÑÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÂà©Áî®‰∏ì‰∏öÁöÑÊô∫ËÉΩ‰Ωì„ÄÇ\n\n### È°πÁõÆÁªìÊûÑÂíå‰ª£ÁêÜÊ¶ÇËø∞\n\nËØ•‰ª£ÁêÜÁ≥ªÁªüÂåÖÊã¨Ôºö\n\n1. **Portfolio Manager** ‚Äî Â∞Ü‰ªªÂä°ÂßîÊ¥æÁªôÂàÜÊûêÂ∏àÂπ∂Ê±áÊÄª‰ªñ‰ª¨ÁöÑÂèëÁé∞„ÄÇ\n2. **Fundamental Analyst** ‚Äî Ëé∑ÂèñÂíåÂàÜÊûêË¥¢Âä°Êä•Ë°®Ôºå‰æãÂ¶ÇÂà©Ê∂¶Ë°®„ÄÇ\n3. **Technical Analyst** ‚Äî Êî∂ÈõÜÊåáÂÆöÊó∂Èó¥ËåÉÂõ¥ÂÜÖÁöÑËÇ°Á•®‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇ\n4. **Sentiment Analyst** ‚Äî ÂÖ≥Ê≥®ÂÜÖÈÉ®‰∫§ÊòìÂíåÊñ∞ÈóªÊï∞ÊçÆÔºåÊèê‰æõÊÉÖÁª™Ê¥ûÂØü„ÄÇ\n\nÊØè‰∏™‰ª£ÁêÜÈÉΩÊó®Âú®‰∏ìÊ≥®‰∫éÁâπÂÆöÁöÑÊï∞ÊçÆÊ£ÄÁ¥¢‰ªªÂä°Ôºå‰ªéËÄåÂÆûÁé∞Ê®°ÂùóÂåñÂíåÂèØÊâ©Â±ïÁöÑÂàÜÊûê„ÄÇÈÄöËøá‰ΩøÁî® LangChain ÂÆûÁé∞‰ª£ÁêÜÂäüËÉΩÂíå LangGraph ÁÆ°ÁêÜÂπ∂Ë°åÂ∑•‰ΩúÊµÅÔºåÊàë‰ª¨ÂèØ‰ª•Âø´ÈÄüÂ§ÑÁêÜÂ§ö‰∏™Êï∞ÊçÆÊ∫ê„ÄÇFinancialDatasets API Êèê‰æõ‰∫Ü‰∏∞ÂØåÁöÑÊï∞ÊçÆÊù•Ê∫êÔºåÊã•ÊúâË∂ÖËøá 30,000 ‰∏™ËÇ°Á•®‰ª£Á†ÅÔºå‰ΩøÂæóÂÖ®Èù¢ÂàÜÊûêÊàê‰∏∫ÂèØËÉΩ„ÄÇ\n\n### ÂÖ≥ÈîÆÂ∫ìÂíåËÆæÁΩÆ\n\nLangChain Âíå LangGraph ‰ΩøÂæóÂ§öÊô∫ËÉΩ‰ΩìÂ∑•‰ΩúÊµÅÂíåÂπ∂Ë°åÂ§ÑÁêÜÁöÑÂàÜÊîØÈÄªËæëÂ§ÑÁêÜÂèòÂæóÁÆÄÂçï„ÄÇËÆæÁΩÆÂºÄÂßã‰∫éÂÆâË£ÖÊâÄÈúÄÁöÑÂ∫ìÂπ∂Ëé∑Âèñ API ÂØÜÈí•Ôºö\n\n```python\n%%capture --no-stderr\n%pip install -U langgraph langchain langchain_openai langchain_experimental langsmith pandas\n```\nÁéØÂ¢ÉÂèòÈáèÁî®‰∫éÂ≠òÂÇ®ÊïèÊÑüÊï∞ÊçÆÔºå‰æãÂ¶Ç API ÂØÜÈí•Ôºö\n\n```python\nimport getpass\nimport os\n\ndef _set_if_undefined(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n\n_set_if_undefined(\"OPENAI_API_KEY\")               # https://platform.openai.com\n_set_if_undefined(\"FINANCIAL_DATASETS_API_KEY\")   # https://financialdatasets.ai\n_set_if_undefined(\"TAVILY_API_KEY\")               # https://tavily.com\n```\n\n### ‰ª£ÁêÜÂäüËÉΩÔºöÊ£ÄÁ¥¢Êï∞ÊçÆ\n\nÁ≥ªÁªü‰∏≠ÁöÑÊØè‰∏™‰ª£ÁêÜÈÉΩÊó®Âú®Â§ÑÁêÜ‰∏éËÇ°Á•®ÂàÜÊûêÁõ∏ÂÖ≥ÁöÑÁâπÂÆöÁ±ªÂûãÊï∞ÊçÆ„ÄÇ\n\n### 1\\. Âü∫Êú¨Èù¢ÂàÜÊûêÂ∏à\n\nÂü∫Êú¨Èù¢ÂàÜÊûêÂ∏àËé∑ÂèñÂπ∂Ê£ÄÊü•Ë¥¢Âä°Êä•Ë°®ÔºåËøô‰∫õÊä•Ë°®Êèê‰æõ‰∫ÜÂÖ¨Âè∏Ë¥¢Âä°ÂÅ•Â∫∑Áä∂ÂÜµÁöÑÊ¥ûÂØü„ÄÇ‰ª•‰∏ãÊòØËé∑ÂèñÊî∂ÂÖ•Êä•Ë°®ÁöÑÂ∑•ÂÖ∑ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑË¥¢Âä°Êñá‰ª∂Ôºö\n\n```python\nfrom langchain_core.tools import tool\nfrom typing import Dict, Union\nfrom pydantic import BaseModel, Field\n\nclass GetIncomeStatementsInput(BaseModel):\n    ticker: str = Field(..., description=\"The ticker of the stock.\")\n    period: str = Field(default=\"ttm\", description=\"Valid values are 'ttm', 'quarterly', or 'annual'.\")\n    limit: int = Field(default=10, description=\"Maximum number of income statements to return.\")\n\n@tool(\"get_income_statements\", args_schema=GetIncomeStatementsInput, return_direct=True)\ndef get_income_statements(ticker: str, period: str = \"ttm\", limit: int = 10) -> Union[Dict, str]:\n    api_key = os.environ.get(\"FINANCIAL_DATASETS_API_KEY\")\n    url = f'https://api.financialdatasets.ai/financials/income-statements?ticker={ticker}&period={period}&limit={limit}'\n    try:\n        response = requests.get(url, headers={'X-API-Key': api_key})\n        return response.json()\n    except Exception as e:\n        return {\"ticker\": ticker, \"income_statements\": [], \"error\": str(e)}\n```\nÂú®ËøôÈáåÔºå`get_income_statements` Áî®‰∫éËé∑ÂèñÁªôÂÆöËÇ°Á•®‰ª£Á†ÅÁöÑÊî∂ÂÖ•Êä•Ë°®„ÄÇÈÄöËøáÊåáÂÆöÊúüÈó¥Ôºà‰æãÂ¶ÇÔºå‚Äúttm‚ÄùË°®Á§∫ËøáÂéªÂçÅ‰∫å‰∏™ÊúàÔºâÔºå‰ª£ÁêÜÂèØ‰ª•‰∏ìÊ≥®‰∫é‰∏çÂêåÁöÑÊä•ÂëäÂë®Êúü„ÄÇ\n\n### 2\\. ÊäÄÊúØÂàÜÊûêÂ∏à\n\nÊäÄÊúØÂàÜÊûêÂ∏àÊî∂ÈõÜÂú®ÂÆö‰πâÊó∂Èó¥ËåÉÂõ¥ÂÜÖÁöÑËÇ°Á•®‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇËøô‰∫õÊï∞ÊçÆÂèØ‰ª•Áî®‰∫éËÆ°ÁÆóÊåáÊ†áÊàñËØÜÂà´Ê®°Âºè„ÄÇ‰ª•‰∏ãÊòØÊ£ÄÁ¥¢ËÇ°Á•®‰ª∑Ê†ºÁöÑ‰ª£Á†ÅÔºö\n\n```python\nclass GetPricesInput(BaseModel):\n    ticker: str\n    start_date: str\n    end_date: str\n    interval: str = \"day\"\n    interval_multiplier: int = 1\n    limit: int = 5000\n\n@tool(\"get_stock_prices\", args_schema=GetPricesInput, return_direct=True)\ndef get_stock_prices(ticker: str, start_date: str, end_date: str, interval: str, interval_multiplier: int = 1, limit: int = 5000) -> Union[Dict, str]:\n    api_key = os.environ.get(\"FINANCIAL_DATASETS_API_KEY\")\n    url = (\n        f\"https://api.financialdatasets.ai/prices?ticker={ticker}\"\n        f\"&start_date={start_date}&end_date={end_date}\"\n        f\"&interval={interval}&interval_multiplier={interval_multiplier}\"\n        f\"&limit={limit}\"\n    )\n    try:\n        response = requests.get(url, headers={'X-API-Key': api_key})\n        return response.json()\n    except Exception as e:\n        return {\"ticker\": ticker, \"prices\": [], \"error\": str(e)}\n```\nËØ•ÂáΩÊï∞ÂÖÅËÆ∏Êàë‰ª¨ÊåáÂÆöÊó•ÊúüËåÉÂõ¥ÂíåÊó∂Èó¥Èó¥ÈöîÁ≠âÂèÇÊï∞Ôºå‰ªéËÄåÊéßÂà∂Êï∞ÊçÆÁöÑÁ≤íÂ∫¶Ôºà‰æãÂ¶ÇÔºåÊåâÊó•ÊàñÊåâÂ∞èÊó∂Ôºâ„ÄÇ\n\n### 3\\. ÊÉÖÁª™ÂàÜÊûêÂ∏à\n\nÊÉÖÁª™ÂàÜÊûêÂ∏àÊî∂ÈõÜÂÜÖÈÉ®‰∫§ÊòìÂíåÁõ∏ÂÖ≥Êñ∞ÈóªÁöÑÊï∞ÊçÆ„ÄÇÂÜÖÈÉ®‰∫§ÊòìÂíåÂÖ¨‰ºóÊÉÖÁª™ÊåáÊ†áÂèØ‰ª•Êèê‰æõÂ∏ÇÂú∫ÊÑüÁü•ÁöÑÊ¥ûÂØüÔºåËøôÂØπ‰∫éËØÑ‰º∞ËÇ°Á•®Ê≥¢Âä®ÊÄßÂíåÊΩúÂú®‰ª∑Ê†ºÂèòÂä®ÈùûÂ∏∏ÈáçË¶Å„ÄÇ\n\n```python\nclass GetInsiderTradesInput(BaseModel):\n    ticker: str\n    limit: int = 10\n\n@tool(\"get_insider_trades\", args_schema=GetInsiderTradesInput, return_direct=True)\ndef get_insider_trades(ticker: str, limit: int = 10) -> Union[Dict, str]:\n    api_key = os.environ.get(\"FINANCIAL_DATASETS_API_KEY\")\n    url = f'https://api.financialdatasets.ai/insider-transactions?ticker={ticker}&limit={limit}'\n    try:\n        response = requests.get(url, headers={'X-API-Key': api_key})\n        return response.json()\n    except Exception as e:\n        return {\"ticker\": ticker, \"insider_transactions\": [], \"error\": str(e)}\n```\nÈÄöËøáÊçïËé∑ÂÜÖÈÉ®‰∫§ÊòìÔºåËØ•Â∑•ÂÖ∑ÂèØ‰ª•Ë∑üË∏™Êã•ÊúâÁâπÊùÉ‰ø°ÊÅØÁöÑ‰∫∫ÁöÑÊìç‰ΩúÔºåËøôÂèØËÉΩÊòØÁª©ÊïàÂèòÂåñÁöÑÊó©ÊúüÊåáÊ†á„ÄÇ\n\n### ÊäïËµÑÁªÑÂêàÁªèÁêÜÔºöÂçèË∞ÉÂíåÊÄªÁªìÂàÜÊûê\n\nÊäïËµÑÁªÑÂêàÁªèÁêÜ‰Ωú‰∏∫ÂçèË∞ÉËÄÖÔºåÂ∞Ü‰ªªÂä°ÂàÜÈÖçÁªôÂàÜÊûêÂ∏àÔºåÂπ∂Â∞Ü‰ªñ‰ª¨ÁöÑÁªìÊûúÊ±áÊÄªÊàê‰∏Ä‰ªΩÊä•Âëä„ÄÇ‰ª•‰∏ãÊòØÊäïËµÑÁªÑÂêàÁªèÁêÜÁöÑÁ§∫‰æãÂ∑•‰ΩúÊµÅÁ®ãÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂ¶Ç‰ΩïË∞ÉÁî®ÊØè‰∏™‰ª£ÁêÜÔºö\n\n```python\nfrom langchain_community.tools.tavily_search import TavilySearchResults\n\n## Tools grouped by agent type\nfundamental_tools = [get_income_statements]\ntechnical_tools = [get_stock_prices]\nsentiment_tools = [get_insider_trades, TavilySearchResults(max_results=5)]\n\n## Sample function for running all analyses in parallel\ndef analyze_portfolio(ticker: str):\n    # Delegate tasks to each agent\n    fundamentals = [tool(ticker=ticker) for tool in fundamental_tools]\n    prices = [tool(ticker=ticker, start_date=\"2023-01-01\", end_date=\"2023-12-31\") for tool in technical_tools]\n    sentiment = [tool(ticker=ticker) for tool in sentiment_tools]\n    \n    # Summarize results (simplified)\n    summary = {\n        \"fundamentals\": fundamentals,\n        \"technical\": prices,\n        \"sentiment\": sentiment\n    }\n    return summary\n```\nÂú®Ëøô‰∏™ÂáΩÊï∞‰∏≠Ôºö\n\n* ÊØè‰∏™‰ª£ÁêÜÁöÑÂáΩÊï∞Âπ∂Ë°åË∞ÉÁî®Ôºå‰ª•Êî∂ÈõÜÊåáÂÆöËÇ°Á•®‰ª£Á†ÅÁöÑÊï∞ÊçÆ„ÄÇ\n* ÁÑ∂ÂêéÔºåÁªèÁêÜÂ∞ÜÊù•Ëá™ÊØè‰∏™‰ª£ÁêÜÁöÑÊï∞ÊçÆÊ±áÊÄªÊàê‰∏Ä‰∏™ÁÆÄÊòéÁöÑÊëòË¶ÅÔºå‰ª•‰æø‰∫éÂÆ°ÈòÖ„ÄÇ\n\n### ÁªìËÆ∫\n\nÊú¨È°πÁõÆÊèê‰æõ‰∫Ü‰∏Ä‰∏™Âü∫Êú¨‰ΩÜÁÅµÊ¥ªÁöÑËÆæÁΩÆÔºåÈÄöËøá‰∏ÄÁªÑ‰∏ì‰∏ö‰ª£ÁêÜÂàÜÊûêËÇ°Á•®Êï∞ÊçÆ„ÄÇÈÄöËøáÂ∞Ü‰ªªÂä°ÂàÜÈÖçÁªôÊäïËµÑÁªÑÂêàÁªèÁêÜ„ÄÅÂü∫Êú¨Èù¢ÂàÜÊûêÂ∏à„ÄÅÊäÄÊúØÂàÜÊûêÂ∏àÂíåÊÉÖÁª™ÂàÜÊûêÂ∏àÔºåÊàë‰ª¨ËÉΩÂ§üÂú®‰∏çÂêåÁöÑÈáëËûçÊï∞ÊçÆÁ±ªÂûã‰∏≠Êî∂ÈõÜÂíåÁªÑÁªáËßÅËß£„ÄÇ‰ΩøÁî® LangChain Âíå LangGraph ÂÆûÁé∞Ê®°ÂùóÂåñÂíåÂπ∂Ë°åÂ§ÑÁêÜÔºå‰ΩøËøôÁßçÊñπÊ≥ïÂÖ∑ÊúâÂèØÊâ©Â±ïÊÄßÔºåËÄåÈáëËûçÊï∞ÊçÆÈõÜ API ÂàôÊîØÊåÅÂπøÊ≥õÁöÑËÇ°Á•®‰ª£Á†ÅÔºåËÉΩÂ§üÂÆûÁé∞Âº∫Â§ßÁöÑÊï∞ÊçÆËÆøÈóÆ„ÄÇ\n\nËôΩÁÑ∂ËØ•Á≥ªÁªüË¢´ËÆæËÆ°‰∏∫‰∏Ä‰∏™ÂÆûË∑µÈ°πÁõÆÔºå‰ΩÜÂÖ∂ÁªìÊûÑÂèØ‰ª•‰Ωú‰∏∫Êõ¥Â§çÊùÇÁöÑÂØπÂÜ≤Âü∫ÈáëÊ®°ÊãüÊàñÊï∞ÊçÆÂàÜÊûêÂ∑•ÂÖ∑ÁöÑÂü∫Á°Ä„ÄÇ‰∏ã‰∏ÄÊ≠•ÂèØËÉΩÂåÖÊã¨‰∏∫ÊØè‰∏™‰ª£ÁêÜÂ¢ûÂº∫Êõ¥Â§öÂ∑•ÂÖ∑ÊàñÊï∞ÊçÆÂàÜÊûêÊäÄÊúØÔºå‰æãÂ¶ÇÔºö\n\n* **ÊäÄÊúØÊ®°ÂºèÂíåÊåáÊ†áÔºö** Êï¥ÂêàÊõ¥Â§öÊäÄÊúØÂàÜÊûêÂ∑•ÂÖ∑ÔºåÂ¶ÇÁßªÂä®Âπ≥ÂùáÁ∫øÊàñË∂ãÂäøÁ∫ø„ÄÇ\n* **ÊÉÖÁª™ËØÑÂàÜÔºö** ‰ªéÊñ∞ÈóªÊù•Ê∫êÊàñÂÜÖÈÉ®‰∫§ÊòìÊï∞ÊçÆËá™Âä®ÂåñÊÉÖÁª™ËØÑÂàÜ„ÄÇ\n* **È¢ÑÊµãÂª∫Ê®°Ôºö** Ê∑ªÂä†ÂèØ‰ª•Ê†πÊçÆÁªºÂêàÊï∞ÊçÆÂÅöÂá∫‰π∞ÂçñÂª∫ËÆÆÁöÑÊú∫Âô®Â≠¶‰π†Ê®°Âûã„ÄÇ\n\nËØ•ËÆæÁΩÆÊòØ‰∏Ä‰∏™ÊúâÁî®ÁöÑÊ®°ÂùóÂåñÈáëËûçÊï∞ÊçÆÂàÜÊûêÂéüÂûãÔºåÊú™Êù•ËøòÊúâÂæàÂ§öÂÆöÂà∂ÂíåÊîπËøõÁöÑÁ©∫Èó¥„ÄÇ\n\nÂØπ‰∫éÈÇ£‰∫õÂØπËøô‰∏™Â∑•ÂÖ∑ÂåÖËÉåÂêéÁöÑ‰ª£Á†ÅÊÑüÂÖ¥Ë∂£ÁöÑ‰∫∫ÔºåÊÇ®ÂèØ‰ª•Âú® GitHub ‰∏äÊâæÂà∞ÂÆåÊï¥ÁöÑÂÆûÁé∞ [*ËøôÈáå*](https://github.com/shaikhmubin02/ai-hedge-fund)„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/multimodal-ai-for-conversational-human-motion-3102e991938c","frontmatter":{"title":"Áî®‰∫é‰∫∫Á±ªËøêÂä®ÂØπËØùÁöÑÂ§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩ","meta_title":"Áî®‰∫é‰∫∫Á±ªËøêÂä®ÂØπËØùÁöÑÂ§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩ","description":"Êú¨ÊñáÊé¢ËÆ®‰∫ÜÂ§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÂú®ÂØπËØù‰∏≠ÁöÑÂ∫îÁî®ÔºåÂº∫Ë∞ÉÈÄöËøáÊÑüÁü•„ÄÅËøêÂä®ËßÑÂàíÂíåËôöÊãüÂΩ¢Ë±°Ê∏≤ÊüìÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑ‰∫§‰∫í„ÄÇÂ§öÊ®°ÊÄÅÊ®°ÂûãËÉΩÂ§üÂáèÂ∞ë‰ø°ÊÅØÊçüÂ§±ÔºåÊï¥ÂêàËßÜËßâ„ÄÅÂê¨ËßâÂíåÊñáÊú¨ËæìÂÖ•Ôºå‰ªéËÄåÊèêÂçáËôöÊãüÂΩ¢Ë±°ÁöÑÂìçÂ∫îËÉΩÂäõ„ÄÇÊñáÁ´†ËøòÂàÜÊûê‰∫ÜÂΩìÂâçÁöÑÂ∫îÁî®Ê°à‰æãÔºåÂ¶ÇÂåªÁñó„ÄÅÂÆ¢Êà∑ÊîØÊåÅÂíåÊïôËÇ≤ÔºåÊåáÂá∫Âú®ÂÆûÊó∂ÂìçÂ∫î„ÄÅ‰∏™ÊÄßÂåñÂíåËÆ∞ÂøÜÁÆ°ÁêÜÁ≠âÊñπÈù¢ÁöÑÊåëÊàò„ÄÇÈöèÁùÄÊäÄÊúØÁöÑÂèëÂ±ïÔºåÊú™Êù•ÁöÑÂ∫îÁî®Â∞ÜÊúâÂä©‰∫éÂÆûÁé∞Êõ¥Â§çÊùÇÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zANW8t-IxPlkyxX-5_9Ayw.png","categories":["Chatbots","Autonomous Systems","Natural Language Processing"],"author":"Rifx.Online","tags":["multimodal","perception","avatar","latency","empathy"],"draft":false,"slug":"blog/multimodal-ai-for-conversational-human-motion-3102e991938c"},"content":"\n\n\nÊí∞ÂÜôËÄÖÔºö[Christian Safka](https://www.linkedin.com/in/christiansafka/) Âíå [Keyu Chen](https://www.linkedin.com/in/keyu-chen-3a3026143/?locale=en_US)\n\n\n\nÂú®Êú¨Ê¨°Êé¢Á¥¢‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Â§öÊ®°ÊÄÅÊ®°ÂûãÂ¶Ç‰ΩïÊîπÂèòÂØπËØù‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÁöÑÊ∏∏ÊàèËßÑÂàôÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂà©Áî®ÊÑüÁü•„ÄÅËÆ∞ÂøÜ„ÄÅË°å‰∏∫Âª∫Ê®°ÂíåÂÆûÊó∂Ê∏≤ÊüìÂú®ÂêÑÁßçÁéØÂ¢É‰∏≠ÂÆûÁé∞Êó†Áºù‰∫§‰∫í„ÄÇ\n\nÊú¨È°µÁöÑÊèêÁ∫≤Ôºö\n\n* ‰∏∫‰ªÄ‰πàÈÄâÊã©Â§öÊ®°ÊÄÅÔºü\n* Ê∑±ÂÖ•‰∫∫Á±ªËøêÂä®ÁÆ°ÈÅì\n* ËÆ≠ÁªÉ‰∏≠ÁöÑÊåëÊàò\n* ÂΩìÂâçÁî®‰æãÂíåÊú™Êù•\n\n## ‰∏∫‰ªÄ‰πàÂ§öÊ®°ÊÄÅÔºü\n\n‰ªéÈ´òÂ±ÇÊ¨°Êù•ÁúãÔºåÊàë‰ª¨ÈúÄË¶ÅÂÆûÁé∞Á±ª‰∫∫ÂØπËØùÁöÑ‰∏â‰∏™‚ÄúÂ±ÇÊ¨°‚ÄùÊòØËæìÂÖ•ÊÑüÁü•„ÄÅËøêÂä®ËßÑÂàíÂíåËôöÊãüÂΩ¢Ë±°Ê∏≤Êüì„ÄÇÊà™Ê≠¢Âà∞Êú¨ÁØáÂÜô‰ΩúÊó∂ÔºåÂ§ßÂ§öÊï∞Â≠¶ÊúØÁïåÁöÑÊµÅÁ®ãÂ∞ÜËøô‰∫õÂ±ÇÊ¨°ÂàÜÂºÄÔºå‰ª•ÊñáÊú¨‰Ωú‰∏∫‰∏≠‰ªãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4a8JvOVbsP8mY3AjiPgNPA.png)\n\nÂ§öÊ®°ÊÄÅÊ®°ÂûãÊâÄËß£ÈîÅÁöÑÊòØËøô‰∫õÂ±ÇÊ¨°‰πãÈó¥‰ø°ÊÅØÊçüÂ§±ÁöÑÂáèÂ∞ëÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VUFhrwLA7sUFmHwidb7DWg.png)\n\n## Ê∑±ÂÖ•Êé¢ËÆ®‰∫∫Á±ªËøêÂä®ÁÆ°ÈÅì\n\nÁîüÊàêÁ±ª‰∫∫Âä®‰ΩúÂíåÂèçÂ∫îÊòØ‰∏Ä‰∏™Âõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇÂÆÉÈúÄË¶Å‰∏Ä‰∏™ÁÆ°ÈÅìÊù•Â§ÑÁêÜÊù•Ëá™Â§ö‰∏™Êù•Ê∫êÁöÑÂÆûÊó∂Á∫øÁ¥¢ÔºåËøõË°åËß£Èáä„ÄÅÁøªËØëÂπ∂ÁîüÊàêÂêåÊ≠•ÂìçÂ∫î„ÄÇÊâÄÊúâÈò∂ÊÆµÂØπ‰∫éÂàõÂª∫ËÉΩÂ§üÂèÇ‰∏éÊµÅÁïÖ„ÄÅ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÂØπËØùÁöÑËôöÊãüÂΩ¢Ë±°Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nÊàë‰ª¨ËÆ®ËÆ∫‰∫Ü‰∏â‰∏™Â±ÇÊ¨°Ôºö\n\n1\\. **ËæìÂÖ•ÊÑüÁü•** ‚Äî ‰ªéËßÜËßâ„ÄÅÂê¨ËßâÂíåÂü∫‰∫éÊñáÊú¨ÁöÑÊù•Ê∫êÊî∂ÈõÜÂ§öÊ®°ÊÄÅÁ∫øÁ¥¢„ÄÇ\n\n2\\. **ËøêÂä®ËßÑÂàí** ‚Äî Ê†πÊçÆËøô‰∫õËæìÂÖ•Á°ÆÂÆöÈÄÇÂΩìÁöÑÂä®‰ΩúÊàñÂèçÂ∫î„ÄÇ\n\n3\\. **ËôöÊãüÂΩ¢Ë±°ËæìÂá∫** ‚Äî ‰ª•ÂÆûÊó∂ÊñπÂºèÊ∏≤ÊüìËøô‰∫õËÆ°ÂàíÁöÑÂä®‰Ωú„ÄÇ\n\nÁé∞Âú®ËÆ©Êàë‰ª¨ÂàÜÊûêÊØè‰∏™Â±ÇÊ¨°Âú®ÂàõÂª∫Á±ª‰∫∫ÂØπËØù‰∏≠ÁöÑÂÖ≥ÈîÆËßíËâ≤„ÄÇ\n\n**Â§öÊ®°ÊÄÅËæìÂÖ•ÁöÑÊÑüÁü•**\n\nÊúâÊïàÁöÑ‰∫∫Á±ªËøêÂä®ÂêàÊàêÂßã‰∫éÁêÜËß£Â§öÊ®°ÊÄÅÁ∫øÁ¥¢ÔºåÂ∞±ÂÉè‰∫∫Á±ª‰æùËµñËßÜËßâ„ÄÅÂê¨ËßâÂíåËØ≠Ë®ÄËøõË°åÊ≤üÈÄö„ÄÇÂú®Êï∞Â≠óÂ∫îÁî®‰∏≠ÔºåËøô‰∏ÄËøáÁ®ãÂèØ‰ª•Â§çÂà∂‰∫∫Á±ªÊî∂ÈõÜÂíåÂìçÂ∫î‰ø°ÊÅØÁöÑÂ§çÊùÇÊñπÂºèÔºö\n\n* **ËßÜËßâËæìÂÖ•**ÔºöÂõæÂÉèÂíåËßÜÈ¢ëÊµÅÊçïÊçâÈù¢ÈÉ®Ë°®ÊÉÖ„ÄÅËßÜÁ∫øÊñπÂêëÂíåÊâãÂäøÁ≠âÂÖÉÁ¥†\n* **Âê¨ËßâËæìÂÖ•**ÔºöÈü≥È¢ë‰ø°Âè∑Êèê‰æõÈáçË¶Å‰ø°ÊÅØÔºåÂ¶ÇËØ≠Ë∞É„ÄÅÈáçÈü≥ÂíåËäÇÂ•èÔºå‰ΩøÊàë‰ª¨ËÉΩÂ§üËß£ËØªËØ≠Ë®ÄÁöÑÊÉÖÊÑüËÉåÊôØ\n* **ÊñáÊú¨ËæìÂÖ•**ÔºöÂü∫‰∫éÊñáÊú¨ÁöÑÊèêÁ§∫ÊàñÂØπËØùËÆ∞ÂΩïÂèØ‰ª•ÈÄöËøáÊèê‰æõËØ≠‰πâ‰∏ä‰∏ãÊñáÊù•ÊåáÂØºËôöÊãüÂΩ¢Ë±°ÁöÑÂä®‰Ωú‚Äî‚Äî‰∫ÜËß£Ê≠£Âú®ËÆ®ËÆ∫ÁöÑÂÜÖÂÆπ‰ΩøËôöÊãüÂΩ¢Ë±°ËÉΩÂ§üÈÄÇÂΩìÂú∞ÂìçÂ∫îÂØπËØùÁöÑÁªÜÂæÆÂ∑ÆÂà´\n\nÊï¥ÂêàËøô‰∫õÊ®°ÊÄÅÂàõÈÄ†‰∫ÜÂØπÂØπËØùÁéØÂ¢ÉÁöÑÊï¥‰ΩìÁêÜËß£Ôºå‰∏∫Á≥ªÁªüÂ¶Ç‰ΩïËß£ÈáäÂíåÊò†Â∞Ñ‰∏ñÁïåÊèê‰æõ‰∫ÜÂü∫Á°Ä„ÄÇ\n\n**‰ΩøÁî®LLMsËøõË°åËøêÂä®ËßÑÂàí**\n\nÂú®Â§öÊ®°ÊÄÅAI‰∏≠Ôºå**‰∫§‰∫íÂ±Ç**‚Äî‚ÄîÈÄöÂ∏∏Áî±Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÈ©±Âä®‚Äî‚ÄîÂÖÖÂΩìËôöÊãüÂΩ¢Ë±°ÁöÑ‚ÄúÂ§ßËÑë‚Äù„ÄÇËØ•Â±ÇÂ§ÑÁêÜÊù•Ëá™ÊÑüÁü•Èò∂ÊÆµÂêàÊàêÁöÑÂ§öÊ®°ÊÄÅÁ∫øÁ¥¢ÔºåÁ°ÆÂÆöÊúÄÂÖ∑‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄßÁöÑÂìçÂ∫îÔºåÂπ∂Â∞ÜÂÖ∂ÁøªËØë‰∏∫ËÆ°ÂàíÁöÑÂä®‰ΩúÊàñËØ≠Ë®ÄÂìçÂ∫î„ÄÇ\n\nÂêåÊó∂‰ΩøÁî®ËØ≠Èü≥ÂíåËßÜËßâÁâπÂæÅ‰Ωú‰∏∫ËæìÂÖ•‰ΩøÊ®°ÂûãËÉΩÂ§üÂ§ÑÁêÜÔºö\n\n* **‰∏ä‰∏ãÊñáËøêÂä®ËßÑÂàí**ÔºöÊ®°ÂûãÂèØ‰ª•ÊçïÊçâÂØπËØùÁ∫øÁ¥¢ÔºåÂ∞ÜÂÖ∂ÂåπÈÖçÂà∞‰∏ä‰∏ãÊñáÈÄÇÂΩìÁöÑÂä®‰Ωú„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúËôöÊãüÂΩ¢Ë±°Ê£ÄÊµãÂà∞Áî®Êà∑ËØ≠Èü≥‰∏≠ÁöÑÁÉ≠ÊÉÖÔºåÂÆÉÂèØËÉΩ‰ºöÈááÂèñÂºÄÊîæ„ÄÅÂºï‰∫∫ÂÖ•ËÉúÁöÑÂßøÊÄÅÊàñÈù¢ÈÉ®Ë°®ÊÉÖ\n* **È°∫Â∫è‰∫§‰∫íÊéßÂà∂**ÔºöÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Ëß£ÈáäÁ∫øÁ¥¢Â∫èÂàóÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ§ÑÁêÜËΩ¨Êé•„ÄÅÁßØÊûÅÂÄæÂê¨ÊâãÂäøÂíåÂÅúÈ°øÁ≠âÁªÜÂæÆÂ∑ÆÂà´ÔºåËøô‰∫õÈÉΩÊòØËá™ÁÑ∂ÂØπËØùÁöÑÈáçË¶ÅÁªÑÊàêÈÉ®ÂàÜ\n\n‰πãÂâçÁöÑÁ†îÁ©∂Â¶ÇZhou et al. \\[0]ÊàñPereira et al. \\[1]‰ºö‰ªéËøô‰∏ÄÂ±ÇËæìÂá∫ÊñáÊú¨‚Äî‚ÄîÊÉÖÊÑüÊ†áÁ≠æÂ¶Ç‚ÄúÂø´‰πê‚ÄùÔºåÂèØ‰ª•Áî®‰∫éÊù°‰ª∂Ë°®ËææÁîüÊàê„ÄÇËøôÊòØÈùûÂ∏∏ÊúâÊçüÁöÑÔºåË°®ËææÊ∞∏Ëøú‰∏ç‰ºö‰∏éËæìÂá∫ËØ≠Èü≥ÂÆåÂÖ®ÂØπÈΩê„ÄÇ\n\nËøêÂä®ËßÑÂàí‰∏≠Â§öÊ®°ÊÄÅÊÄßÁöÑÁæéÂú®‰∫éËæìÂÖ•ÂíåËæìÂá∫„ÄÇÂú®ËæìÂÖ•ÊñπÈù¢ÔºåÊàë‰ª¨ÂèØ‰ª•Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ñÁïåÁü•ËØÜÔºåÂç≥‰ΩøÂÆÉË¢´ËÆ≠ÁªÉ‰ª•ÂØπÈΩêÂ§öÊ®°ÊÄÅÊ†áËÆ∞„ÄÇÂú®ËæìÂá∫ÊñπÈù¢ÔºåÊàë‰ª¨ÂèØ‰ª•ÂáèÂ∞ëÊúüÊúõË°å‰∏∫‰∏éÊúÄÁªàÊ∏≤ÊüìËæìÂá∫‰πãÈó¥ÁöÑ‰ø°ÊÅØÊçüÂ§±„ÄÇ\n\nÊÄª‰πãÔºå‰∫§‰∫íÂ±Ç‰ΩøËôöÊãüÂΩ¢Ë±°ËÉΩÂ§üÂìçÂ∫îÊòæÊÄßÂíåÈöêÊÄßÂØπËØùÁ∫øÁ¥¢ÔºåÂº•ÂêàÂ§öÊ®°ÊÄÅÊÑüÁü•‰∏éÁ±ª‰∫∫‰∫§‰∫í‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ\n\n**ËôöÊãüÂΩ¢Ë±°ÁîüÊàê**\n\n‰∏∫‰∫ÜÂÆûÁé∞ÂØåÊúâÂêåÁêÜÂøÉÁöÑÂØπËØùAIÊàñ‰∫∫Á±ªÁ∫ßÂà´ÁöÑ‰ø°ÊÅØÊµÅÔºåÊ∏≤ÊüìÁöÑÂä®‰ΩúÂíåÂèçÂ∫îÈúÄË¶ÅË∂ÖË∂äÈùôÊÄÅÁöÑ„ÄÅÈ¢ÑÂÖàËßÑÂàíÁöÑÂä®‰Ωú„ÄÇÁõÆÊ†áÊòØÂàõÂª∫‰∏Ä‰∏™ËÉΩÂ§üÂá†‰πéÁû¨Êó∂Âú∞Ëß£ÈáäÂíåË∞ÉÊï¥ÂæÆÂ¶ôÂØπËØùÁ∫øÁ¥¢ÁöÑÁ≥ªÁªü„ÄÇ\n\nÂú®Ëøô‰∏™ËÉåÊôØ‰∏ãÔºå**ËôöÊãüÂΩ¢Ë±°Â±Ç**ÂÖÖÂΩìËæìÂá∫Ê∏≤ÊüìÊú∫Âà∂„ÄÇÂÆÉÊé•Êî∂‰∫§‰∫íÂ±ÇËßÑÂàíÁöÑÂä®‰ΩúÔºåÂπ∂Â∞ÜÂÖ∂ËΩ¨Âåñ‰∏∫ÊµÅÁïÖÁöÑÂÆûÊó∂Ë°å‰∏∫„ÄÇËØ•Â±Ç‰∏ìÊ≥®‰∫é**‰ΩéÂª∂ËøüÂìçÂ∫îÁîüÊàê**Ôºå‰ºòÂÖàËÄÉËôëÊúüÊúõÂä®‰Ωú‰∏éËßÜËßâ/Èü≥È¢ëËæìÂá∫‰πãÈó¥ÁöÑÂø´ÈÄüÂíåÂáÜÁ°ÆÂØπÈΩê„ÄÇ\n\n‰∏ªË¶ÅÁõÆÊ†áÂèØ‰ª•ÊèèËø∞‰∏∫**ÂêåÊ≠•ËØ≠Èü≥ÂíåÂä®‰Ωú**‚Äî‚ÄîËôöÊãüÂΩ¢Ë±°ÂøÖÈ°ªÂçèË∞ÉÈù¢ÈÉ®Ë°®ÊÉÖ„ÄÅËÇ¢‰ΩìËØ≠Ë®ÄÂíåÂîáÈÉ®Âä®‰ΩúÔºåÂà©Áî®Âê¨ËßâËæìÂá∫ÂíåË°å‰∏∫‰ø°Âè∑ÔºåÁ°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰øùÊåÅÂêåÊ≠•„ÄÇ\n\n‰øùÊåÅÊó∂Èó¥‰∏ÄËá¥ÊÄßÂíåÂêåÊ≠•ÊÄßËá≥ÂÖ≥ÈáçË¶ÅÔºåÂõ†‰∏∫‰ªª‰ΩïÂª∂ËøüÊàñË°å‰∏∫‰∏çÂåπÈÖçÈÉΩÂèØËÉΩËøÖÈÄüÊâìÁ†¥Ê≤âÊµ∏ÊÑü„ÄÇ\n\n## ÂüπËÆ≠‰∏≠ÁöÑÊåëÊàò\n\n‰∏Ä‰∫õË°å‰∏öÂíåÂ≠¶ÊúØÁïåÁöÑÊ¥ªË∑ÉÁ†îÂèëÈ¢ÜÂüüÂåÖÊã¨Ôºö\n\n* **Ë∑®Ê®°ÊÄÅÁöÑÊ†áËÆ∞ÂØπÈΩê**ÔºöÂú®‰∏çÂ§±Âéª‰∏ä‰∏ãÊñáÊàñËØ≠‰πâÊÑè‰πâÁöÑÊÉÖÂÜµ‰∏ãÂØπËßÜËßâÁ∫øÁ¥¢ÂíåÈü≥È¢ëËØ≠Ë∞ÉÁ≠âÊ®°ÊÄÅËøõË°åÂØπÈΩêÊòØÂ§çÊùÇÁöÑÔºåÊ®°ÂûãÂøÖÈ°ªÂ≠¶‰π†Â¶Ç‰Ωï‰ª•Áªü‰∏ÄÁöÑÊñπÂºèË°®Á§∫ÂÆÉ‰ª¨Ôºå‰ª•‰æøÊèê‰æõ‰∏ÄËá¥ÁöÑÂìçÂ∫î\n* **Âª∂ËøüÁÆ°ÁêÜ**ÔºöÂÆûÊó∂ÂìçÂ∫îË¶ÅÊ±ÇÊï¥‰∏™Â§öÊ®°ÊÄÅÁÆ°ÈÅì‰ª•‰ΩéÂª∂ËøüËøêË°åÔºåÈöèÁùÄÂ§çÊùÇÊÄßÁöÑÂ¢ûÂä†ÔºåËøôÂèòÂæóÂÖ∑ÊúâÊåëÊàòÊÄß\n* **‰∏™ÊÄßÂíåËÆ∞ÂøÜ**ÔºöÂØπ‰∫éËôöÊãüÂΩ¢Ë±°Êù•ËØ¥Ôºå‰∏ÄËá¥ÁöÑ‰∏™ÊÄßÁâπÂæÅËá≥ÂÖ≥ÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈïøÊó∂Èó¥ÁöÑ‰∫íÂä®‰∏≠„ÄÇÈÄÇÂΩìÂ§ÑÁêÜËÆ∞ÂøÜÂíå‰∏™ÊÄßÂØπ‰∫éÂú®Êüê‰∫õÁî®‰æã‰∏≠‰øùÊåÅËøûË¥ØÁöÑÂìçÂ∫îÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑ\n\n## ÂΩìÂâçÁöÑÂ∫îÁî®Ê°à‰æãÂèäÊú™Êù•\n\nÈ¶ñÂÖàÔºå‰ª•‰∏ãÊòØÊàë‰ª¨ÁúãÂà∞ÁöÑ‰∏Ä‰∫õÂΩìÂâçÂ∫îÁî®Ê°à‰æãÁöÑÁ§∫‰æãÔºö\n\n* **ÂåªÁñó‰øùÂÅ•**ÔºöÊÉ≥Ë±°‰∏Ä‰∏™ÂØåÊúâÂêåÊÉÖÂøÉÁöÑËôöÊãüÂÅ•Â∫∑ÊïôÁªÉ‰Ωú‰∏∫ÂåñË∫´ÔºåÊèê‰æõÊåáÂØºÔºåÂÆûÊó∂ÂìçÂ∫îÔºåÂπ∂Ê†πÊçÆÁî®Êà∑ÁöÑÊÉÖÁª™Ë∞ÉÊï¥ËØ≠Ê∞îÂíåË°®ÊÉÖ\n* **ÂÆ¢Êà∑ÊîØÊåÅ**ÔºöÂÆ¢Êà∑ÊîØÊåÅÂåñË∫´ÂèØ‰ª•Ëß£ËØªËØ≠Èü≥ÊèêÁ§∫„ÄÅËÇ¢‰ΩìËØ≠Ë®ÄÔºåÁîöËá≥ÈÄöËøáÂ±èÂπïÂÖ±‰∫´ÊàñÂÆûÊó∂ËßÜÈ¢ëÊü•ÁúãÁî®Êà∑ÁöÑÊäÄÊúØÈóÆÈ¢ò„ÄÇÂÆÉËøòÂèØ‰ª•Êèê‰æõÂê¨Ëµ∑Êù•‰ΩìË¥¥Âíå‰∏™ÊÄßÂåñÁöÑÂõûÂ∫îÔºåÂáèÂ∞ëÁî®Êà∑ÁöÑÊå´Ë¥•ÊÑü\n* **ÊïôËÇ≤Â∑•ÂÖ∑**ÔºöÂÖ∑ÊúâÂÆûÊó∂‰∫íÂä®ËÉΩÂäõÁöÑÂØºÂ∏àÂèØ‰ª•‰∏éÂ≠¶Áîü‰∫íÂä®ÔºåÂ±ïÁé∞‰∏ìÊ≥®ÁöÑÊâãÂäøÔºåÂπ∂Ë∞ÉËäÇË°®ÊÉÖ‰ª•Âä†Âº∫ÈºìÂä±ÊàñÁ∫†Ê≠£\n\nÈöèÁùÄÁ†îÁ©∂ÁöÑËøõÂ±ïÔºåËøô‰∫õÂ∫îÁî®Â∞Ü‰∏çÊñ≠Êâ©Â±ïÔºå‰ΩøÊï∞Â≠ó‰∫∫Á±ªËÉΩÂ§üÂú®Ë∂äÊù•Ë∂äÂ§çÊùÇ„ÄÅÈ´òÈ£éÈô©ÁöÑÁéØÂ¢É‰∏≠ÈÉ®ÁΩ≤„ÄÇ‰∫∫Á±ªÁ∫ßÂà´ÁöÑÂØπËØùÂåñË∫´ËøòÂ∞ÜËß£ÈîÅÂêåÊÉÖÊÄßÂ∫îÁî®Ê°à‰æã‰ª•ÂèäÈ´ò‰ø°ÊÅØÊµÅÁöÑ‰∫∫Êú∫‰∫§‰∫íÁïåÈù¢„ÄÇ\n\nÂ¶ÇÊûúËß£ÂÜ≥Â¶ÇÊ®°ÊÄÅÂØπÈΩê„ÄÅÂª∂ËøüÂíå‰∏ä‰∏ãÊñá‰∏ÄËá¥ÊÄßÁ≠âÊåëÊàòËÆ©‰Ω†ÊÑüÂÖ¥Ë∂£‚Äî‚ÄîÊàë‰ª¨Ê≠£Âú®ÊãõËÅòÔºÅËØ∑Êü•ÁúãÊàë‰ª¨ÁöÑÁΩëÁ´ô <https://tavus.io>\n\n**ÂèÇËÄÉÊñáÁåÆ**\n\n\\[0] Zhou, Hao, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, and Bing Liu. ‚ÄúEmotional chatting machine: Emotional conversation generation with internal and external memory.‚Äù In *Proceedings of the AAAI conference on artificial intelligence*, vol. 32, no. 1\\. 2018\\.\n\n\\[1] Pereira, Patr√≠cia, Helena Moniz, and Joao Paulo Carvalho. ‚ÄúDeep emotion recognition in textual conversations: A survey.‚Äù *Artificial Intelligence Review* 58, no. 1 (2025\\): 1‚Äì37\\.\n\n## Âà´Âøò‰∫ÜÁªôÊàë‰ª¨‰Ω†ÁöÑ üëè !\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2lvCls4yjxVMfZSR)\n\n"},{"lang":"zh","group":"blog","slug":"blog/multimodal-rag-with-gemini-pro-and-langchain-e4f74170420a","frontmatter":{"title":"‰ΩøÁî® Gemini Pro Âíå LangChain ÁöÑÂ§öÊ®°Âºè RAG","meta_title":"‰ΩøÁî® Gemini Pro Âíå LangChain ÁöÑÂ§öÊ®°Âºè RAG","description":"‰ªãÁªç","date":"2024-11-08T00:41:44.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*m2C8wrrRvhELuDiYLv4YYQ.png","categories":["Programming","Machine Learning","Computer Vision"],"author":"Rifx.Online","tags":["Gemini","LangChain","RAG","Vertex","sneaker"],"draft":false,"slug":"blog/multimodal-rag-with-gemini-pro-and-langchain-e4f74170420a"},"content":"\n\n\n## ‰ªãÁªç\n\nÂú®Êú¨ÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢Á¥¢Â∞Ü [Gemini](https://deepmind.google/technologies/gemini/#introduction) Pro Âíå Gemini Pro Vision ‰∏é [LangChain](https://www.langchain.com/langchain) Ê°ÜÊû∂ÈõÜÊàêÔºå‰ª•ÂÆûÁé∞Â§öÊ®°ÊÄÅÔºàÂú®ËøôÁßçÊÉÖÂÜµ‰∏ã‰∏∫ÂõæÂÉèÔºâÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâ„ÄÇËøô‰∏™ÁÆÄÁü≠ÁöÑÊïôÁ®ãÈÄÇÂêàÂàùÂ≠¶ËÄÖÂíåÁªèÈ™å‰∏∞ÂØåÁöÑ‰ªé‰∏öËÄÖÔºå‰∏ç‰ªÖ‰ª• Google [AI Studio](https://aistudio.google.com/) ‰Ωú‰∏∫‰∏ªË¶ÅÁéØÂ¢ÉÂ•†ÂÆöÂü∫Á°ÄÔºåËøòÊó†ÁºùËøáÊ∏°Âà∞ÊºîÁ§∫Â¶Ç‰Ωï‰ΩøÁî® [Google Cloud‚Äôs Vertex AI](https://cloud.google.com/vertex-ai) ÈÄÇÂ∫îÂíåËøõ‰∏ÄÊ≠•Â¢ûÂº∫Ëøô‰∫õÂÆûÁé∞„ÄÇ\n\n## ËÆæÁΩÆÁéØÂ¢É\n\nÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅËÆæÁΩÆÊàë‰ª¨ÁöÑÁéØÂ¢ÉÔºå‰ª•Á°Æ‰øùÊàë‰ª¨Êã•ÊúâÊâÄÊúâÂøÖË¶ÅÁöÑÂ∑•ÂÖ∑ÂíåÂ∫ì„ÄÇ\n\n‰∏∫Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶Å Langchain„ÄÅLangchain Google Gen AI ÂåÖ‰ª•ÂèäÁî®‰∫é RAG ÁöÑÂêëÈáèÂ≠òÂÇ®ÂåÖÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\n```python\npip install ‚Äî upgrade langchain langchain-google-genai ‚Äúlangchain[docarray]‚Äù faiss-cpu\n```\n\nÁÑ∂ÂêéÔºåÊÇ®ËøòÈúÄË¶ÅÊèê‰æõ Google AI Studio API ÂØÜÈí•Ôºå‰ª•‰æøÊ®°ÂûãËøõË°å‰∫§‰∫íÔºö\n\n```python\nif \"GOOGLE_API_KEY\" not in os.environ:\n  os.environ[‚ÄúGOOGLE_API_KEY‚Äù] = getpass.getpass(‚ÄúProvide your Google API Key‚Äù)\n```\n\n‰∏∫‰∫ÜÊñπ‰æø‰ΩøÁî®ÔºåÊàëËøòÂÜô‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂáΩÊï∞ÔºåÊòæÁ§∫ÊàëÊ≠£Âú®‰ΩøÁî®ÁöÑÂõæÂÉè„ÄÇËøô‰∏™ÂáΩÊï∞ÁÆÄÂçïÂú∞‰ªéÊèê‰æõÁöÑ URL ‰∏ãËΩΩÂõæÂÉèÂπ∂ÊòæÁ§∫È¢ÑËßàÔºö\n\n```python\ndef get_image(url, filename):\n  content = requests.get(url).content\n  with open(f'/content/{filename}.png', 'wb') as f:\n  f.write(content)\n  image = Image.open(f\"/content/{filename}.png\")\n  image.show()\n  return image\n```\n\n## ÁÆÄÂçïÁöÑ LLM ‰∫§‰∫í\n\nËÆ©Êàë‰ª¨‰ªé‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑ LLM ‰∫§‰∫íÂºÄÂßã„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèØ‰ª•ÁÆÄÂçïÂú∞Ë∞ÉÁî® ChatGoogleGenerativeAI ÁöÑ Gemini Pro Ê®°ÂûãÔºåÂπ∂Ë∞ÉÁî®ÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\n```python\nllm = ChatGoogleGenerativeAI(model=‚Äùgemini-pro‚Äù)\nresult = llm.invoke(\"Write a ballad about Gemini Pro in around 3 sentences.\")\nprint(result.content)\n```\n\nÁªìÊûú‰Ω†‰ºöÂæóÂà∞Á±ª‰ººËøôÊ†∑ÁöÑÂÜÖÂÆπÔºö\n\n> Âú®ÊòüËæ∞ÁöÑÈ¢ÜÂüüÔºåGemini Pro Èó™ËÄÄÔºå ‰∏ÄÈÅìÂ§©‰ΩìÁöÑÁÅØÂ°îÔºåÂàíÂÆö‰∫ÜÁïåÈôêÔºå ÊåáÂºïÁùÄËßÇÊòüËÄÖÁ©øË∂äÂÆáÂÆôÁöÑËÆæËÆ°„ÄÇ\n\nÂêåÊ†∑Ôºå‰Ω†‰πüÂèØ‰ª•Âú®ËÅäÂ§©ÁïåÈù¢‰∏≠‰ΩøÁî®ÂÆÉÔºåÈááÁî®Á≥ªÁªü„ÄÅ‰∫∫Á±ªÊ∂àÊÅØ/ÂØπËØùÊ†ºÂºèÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\n```python\nmodel = ChatGoogleGenerativeAI(model=‚Äùgemini-pro‚Äù, convert_system_message_to_human=True)\nprint(model([\n  SystemMessage(content=\"Answer only yes or no.\"),\n  HumanMessage(content=\"Is apple a fruit?\"),\n  ]).content)\n```\n\n## Â§öÊ®°ÊÄÅ LLM\n\nÂú®Êú¨ÊïôÁ®ã‰∏≠ÔºåÊàëÂ∞Ü‰ΩøÁî®‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑÁî®‰æãÔºåÂÅáËÆæÊàëÊòØ‰∏ÄÂêçËøêÂä®ÈûãÁà±Â•ΩËÄÖÔºåÂü∫Êú¨‰∏äÊÉ≥Ë¶ÅÊâæÂà∞Âú®ÈôÑËøëÁöÑÊú¨Âú∞ÂïÜÂ∫óË¥≠‰π∞ÁâπÂÆöËøêÂä®ÈûãÂûãÂè∑ÁöÑÊñπÊ≥ï„ÄÇ‰∏∫Ê≠§ÔºåÊàëÂáÜÂ§á‰∫Ü‰∏Ä‰∏™ËôöÊãüÁü•ËØÜÂ∫ìÔºåÈáåÈù¢ÂåÖÂê´‰∫Ü‰∏Ä‰∫õÂÖ≥‰∫éÊú¨Âú∞ÂïÜÂ∫óÁöÑËôöÂÅá‰ø°ÊÅØÔºå‰ª•ÂèäÊüê‰∫õÊµÅË°åËøêÂä®ÈûãÂìÅÁâåÁöÑËßÑÊ†º„ÄÇÊúâË∂£ÁöÑÊòØÔºåËøô‰∏™Áü•ËØÜÂ∫ì‰πüÊòØÈÄöËøá Gemini Pro ‰ΩøÁî® [Google Gemini](https://gemini.google.com/) ËÅäÂ§©ÁïåÈù¢ÁîüÊàêÁöÑ„ÄÇ\n\nËÆ©Êàë‰ª¨‰ªé‰∏ÄÂº†Á§∫‰æãÂõæÁâáÂºÄÂßãÔºö\n\n```python\nimage = get_image(<image_url>, ‚Äúnike3‚Äù)\nplt.imshow(image)\nplt.show()\n```\n\n‰Ωú‰∏∫Á§∫‰æãÔºåÊàëËÄÉËôëËøôÂº† [Nike](https://nike.com/) ËøêÂä®ÈûãÁöÑÂõæÁâá„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dNFF95lOu1SeYHOn1vFnQQ.png)\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨Ë∞ÉÁî® Gemini Pro Vision Ê®°ÂûãÔºåËØ¢ÈóÆÂÆÉÂÖ≥‰∫éËøôÂº†ÁâπÂÆöÂõæÁâáÁöÑ‰∏Ä‰∫õ‰ø°ÊÅØ„ÄÇ‰∏∫Ê≠§ÔºåÊÇ®Âè™ÈúÄÂ∞ÜÊ®°ÂûãÂêçÁß∞Êõ¥Êîπ‰∏∫ *‚Äúgemini\\-pro\\-vision‚Äù*„ÄÇ\n\n```python\nllm = ChatGoogleGenerativeAI(model=‚Äùgemini-pro-vision‚Äù)\nmessage = HumanMessage(\ncontent=[\n  {\n    \"type\": \"text\",\n    \"text\": \"What's in this image? provide full detail as possible.\",\n  }, # You can optionally provide text parts\n  {\"type\": \"image_url\", \"image_url\": image},\n])\nprint(\nllm.invoke([message]).content\n)\n```\n\nÊÇ®Â∞ÜÂæóÂà∞Â¶Ç‰∏ãËæìÂá∫Ôºö\n\n> ËøôÊòØ‰∏Ä‰∏™ Nike Air Max 95 ËøêÂä®ÈûãÁöÑ‰∫ßÂìÅÂõæÁâáÔºåÈ¢úËâ≤‰∏∫Ê£ïËâ≤Â∞èÈ∫¶Ëâ≤„ÄÇÈûãÈù¢Áî±ÁΩëÂ∏ÉÂíåÈ∫ÇÁöÆÂà∂ÊàêÔºåÂ∏¶ÊúâÁöÆÈù©Ê≥•Êå°„ÄÇ‰∏≠Â∫ïÁî±Ê≥°Ê≤´ÊùêÊñôÂà∂ÊàêÔºåÂêéË∑üÊúâÂèØËßÅÁöÑÊ∞îÂû´ÂçïÂÖÉ„ÄÇÂ§ñÂ∫ïÁî±Ê©°ËÉ∂Âà∂ÊàêÔºåÂÖ∑ÊúâÂçéÂ§´Ê†ºÂõæÊ°à‰ª•Â¢ûÂº∫ÊäìÂú∞Âäõ„ÄÇ\n\n*ÂÖçË¥£Â£∞ÊòéÔºöÊâÄÊèê‰æõÁöÑÊèèËø∞ÂèØËÉΩ‰∏çÂáÜÁ°ÆÔºåÂèçÊò†ÁöÑÊòØÊ®°ÂûãÂØπÂõæÂÉèÁöÑËß£ËØªÔºåËÄåÈùû‰∏é‰πãÁõ∏ÂÖ≥ÁöÑ‰∫ãÂÆû‰ø°ÊÅØ„ÄÇ*\n\n## ‰ΩøÁî®Â§öÊ®°ÊÄÅÁöÑRAG\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£Â¶Ç‰Ωï‰ΩøÁî®ËøôÁßçÂ§öÊ®°ÊÄÅÊñπÊ≥ïÊâßË°åRAG„ÄÇÈ¶ñÂÖàÔºåËÆ©Êàë‰ª¨‰∏∫Ëøô‰∏™RAGÂàõÂª∫‰∏Ä‰∏™‰ø°ÊÅØÊ∫ê„ÄÇ‰∏∫Ê≠§ÔºåÊàëÂÜô‰∫Ü‰∏Ä‰∫õÂÖ≥‰∫éÂá†Ê¨æNikeËøêÂä®ÈûãÁöÑÊÆµËêΩ‰ø°ÊÅØÔºå‰ª•Âèä‰∏Ä‰∫õËôöÊûÑÁöÑÂ∞ºÊ≥äÂ∞îÊú¨Âú∞ÂïÜÂ∫ó‰ΩçÁΩÆ„ÄÇ\n\n```python\nstore_information = ‚ÄúNike Air Max Plus sneakers. They feature a brown upper with a black Nike Swoosh logo on the side and a visible Air Max unit in the heel. The sole is white.\nHere are some more details about the Nike Air Max Plus:\nStyle: TN\nRelease date: January 1, 2017\nStyle code: 852630‚Äì300\nOriginal retail price: $150 USD\nThe Air Max Plus, also known as the TN, is a popular Nike running shoe that was first released in 1998. It is known for its unique design, which includes a gradient upper, visible Air Max units, and a wavy outsole. The TN has been a popular shoe among sneakerheads and casual wearers alike for over two decades.\nIt features a brown upper with a black Swoosh logo and a white sole. The shoe is currently available for resale on the StockX marketplace for an average price of around $150 USD.\nNike Air Max Plus Store Location: \"Kings Way, Kathmandu, Nepal\n\n...\n\n\"\n```\n\nÁÑ∂ÂêéÔºåËÆ©Êàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™LangchainÈìæÔºåÂÆÉÂü∫Êú¨‰∏äÊ†πÊçÆÊàë‰ª¨Áü•ËØÜÂ∫ì‰∏≠Êèê‰æõÁöÑÂõæÂÉèÊèèËø∞Ëé∑ÂèñÂÖ≥‰∫éNikeÊ®°ÂûãÁöÑ‰ø°ÊÅØ‰ª•ÂèäÂèØ‰ª•Âú®Âì™ÈáåË¥≠‰π∞ÂÆÉ„ÄÇ\n\n```python\nllm_text = ChatGoogleGenerativeAI(model=‚Äùgemini-pro‚Äù)\ntemplate = \"\"\"\n```\n\n{context}\n\n```\n{information}\nProvide brief information and store location.\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nrag_chain = (\n  {\"context\": retriever, \"information\": RunnablePassthrough()}\n  | prompt\n  | llm_text\n  | StrOutputParser()\n)\n```\n\nËøôÈáåÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØ*Gemini\\-Pro*Âíå*Gemini\\-Pro\\-Vision*ÊòØ‰∏§‰∏™‰∏çÂêåÁöÑÊ®°ÂûãÔºåÊÇ®ÈúÄË¶Å‰ª•‰∏çÂêåÁöÑÊñπÂºèË∞ÉÁî®ÂÆÉ‰ª¨„ÄÇÂú®‰∏äÈù¢ÁöÑ‰ª£Á†Å‰∏≠ÔºåÊàë‰ª¨Ë∞ÉÁî®‰∫ÜGemini ProÊñáÊú¨Ê®°ÂûãÔºåËØ•Ê®°ÂûãÊ†πÊçÆÁî±*gemini\\-pro\\-vision*Ê®°ÂûãÁîüÊàêÁöÑÂõæÂÉèÊèèËø∞ÊâßË°åRAG„ÄÇ\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ËÆæÁΩÆ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÈìæÔºåÂÆÉÈ¶ñÂÖàÁîüÊàêÂõæÂÉèÊèèËø∞ÔºåÁÑ∂Âêé‰ΩøÁî®‰∏äËø∞ÈìæËøõË°åRAG„ÄÇ\n\n```python\nllm_vision = ChatGoogleGenerativeAI(model=‚Äùgemini-pro-vision‚Äù, temperature=0.0)\nfull_chain = (\n  RunnablePassthrough() | llm_vision | StrOutputParser() | rag_chain\n)\n```\n\n## ÊâßË°å RAG\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ÂØπÂàöÂàöËÆæÁΩÆÁöÑÂÜÖÂÆπËøõË°å‰∏Ä‰∫õÊµãËØï„ÄÇÈ¶ñÂÖàÔºåËé∑ÂèñÂè¶‰∏ÄÂº†ÂõæÂÉè‰Ωú‰∏∫Ê†∑Êú¨\n\n```python\nimage = get_image(url_3, ‚Äúnike3‚Äù)\nplt.imshow(image)\nplt.show()\n```\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kPkfo2FKnrUR2tC18VMpjg.png)\n\nÁÑ∂ÂêéÔºåËÆ©Êàë‰ª¨Ë∞ÉÁî®Êàë‰ª¨ÁöÑ RAGÔºö\n\n```python\nmessage = HumanMessage(\n  content=[\n    {\n      \"type\": \"text\",\n      \"text\": \"Êèê‰æõÊúâÂÖ≥ÁªôÂÆöËøêÂä®ÈûãÁöÑÂìÅÁâåÂíåÂûãÂè∑ÁöÑ‰ø°ÊÅØ„ÄÇ\",\n    }, # ÊÇ®ÂèØ‰ª•ÈÄâÊã©ÊÄßÂú∞Êèê‰æõÊñáÊú¨ÈÉ®ÂàÜ\n    {\"type\": \"image_url\", \"image_url\": image},\n  ])\n```\n\nÁé∞Âú®ËÆ©Êàë‰ª¨ÁúãÁúãÊàë‰ª¨ÂæóÂà∞‰∫Ü‰ªÄ‰πàÔºö\n\n```python\nresult = full_chain.invoke([message])\ndisplay(Markdown(result))\n```\n\n‰Ωú‰∏∫ËæìÂá∫ÔºåÊàë‰ª¨Â∞ÜÂæóÂà∞Á±ª‰ºº‰∫é‰ª•‰∏ãÂÜÖÂÆπÁöÑÁªìÊûúÔºåËøôÂü∫‰∫éÊàë‰ª¨ÁöÑËôöÊûÑ‰ø°ÊÅØÊù•Ê∫êÔºö\n\n> **Nike Offcourt Slide**ËΩØË¥®‰∏Ä‰ΩìÂºèÈûãÈù¢ËàíÈÄÇÁöÑÊ≥°Ê≤´‰∏≠Â∫ïËÄêÁî®ÁöÑÊ©°ËÉ∂Â§ñÂ∫ïÊèê‰æõÂ§öÁßçÈ¢úËâ≤ÈÄâÊã©\n\n> **ÂïÜÂ∫ó‰ΩçÁΩÆÔºö** Â∞ºÊ≥äÂ∞îÔºåÂ∑¥ÂÖãÂ°îÂ∏ÉÂ∞î\n\n## ‰ΩøÁî® Vertex AI Ê®°Âûã\n\nÈô§‰∫Ü‰ΩøÁî® Google AI Studio Ê®°ÂûãÂ§ñÔºåÊÇ®ËøòÂèØ‰ª•‰ΩøÁî® Google Cloud ÁöÑ Vertex AI Gemini Pro Ê®°Âûã„ÄÇ‰∏∫Ê≠§ÔºåÊÇ®È¶ñÂÖàÈúÄË¶Å‰∏∫ÊÇ®ÁöÑ‰∫ëÁéØÂ¢ÉÂÆâË£Ö‰∏é Vertex AI Áõ∏ÂÖ≥ÁöÑÂåÖÂíå LangchainÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\n```python\npip install ‚Äî upgrade google-cloud-aiplatform langchain-google-vertexai\n```\n\nÁÑ∂ÂêéÔºå‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ËÆæÁΩÆ‰∏éÊÇ®ÁöÑ‰∫ëÈ°πÁõÆÁõ∏ÂÖ≥ÁöÑÂøÖË¶ÅÈÖçÁΩÆÔºö\n\n```python\ngcloud init\n```\n\nÊé•‰∏ãÊù•ÔºåÊÇ®ÂèØ‰ª•Â∞Ü Vertex AI Ê®°ÂûãÁî®‰∫éÂ§öÊ®°ÊÄÅÁî®‰æãÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\n```python\nfrom langchain_google_vertexai import VertexAI\nfrom langchain_google_vertexai import VertexAIEmbeddings\n\nmodel_vision = VertexAI(model_name=\"gemini-1.0-pro-vision-001\")\nmodel_text = VertexAI(model_name=\"gemini-1.0-pro-001\")\n```\n\n## ÁªìËÆ∫\n\nÂú®Ëøô‰∏™ÁÆÄÁü≠ÁöÑÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÂ∞Ü Gemini Pro Âíå Gemini Pro vision ‰∏é LangChain ÁªìÂêà‰ΩøÁî®Ôºå‰ª•ÂÆûÁé∞Â§öÊ®°ÊÄÅ RAG Â∫îÁî®Á®ãÂ∫è„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/o1-preview-vs-claude-3-5-sonnet-comparing-top-llms-d68734b53c93","frontmatter":{"title":"o1-preview ‰∏é claude-3.5-sonnetÔºöÊØîËæÉÈ°∂Á∫ßÊ≥ïÂ≠¶Á°ïÂ£´","meta_title":"o1-preview ‰∏é claude-3.5-sonnetÔºöÊØîËæÉÈ°∂Á∫ßÊ≥ïÂ≠¶Á°ïÂ£´","description":"‰∫ÜËß£ OpenAI ÁöÑ o1 È¢ÑËßàÁâà‰∏é Claude 3.5 Sonnet Âú®ÊÄßËÉΩ„ÄÅÈÄüÂ∫¶ÂíåÂäüËÉΩÊñπÈù¢ÁöÑÊØîËæÉ„ÄÇ","date":"2024-10-27T13:58:01.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kTWAcpRdOpsrFIDZjjjr7Q.jpeg","categories":["Programming","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["o1-preview","Claude","throughput","latency","reasoning"],"draft":false,"slug":"blog/o1-preview-vs-claude-3-5-sonnet-comparing-top-llms-d68734b53c93"},"content":"\n\n\n‰ªäÂ§©Ôºà2024Âπ¥9Êúà12Êó•ÔºâÔºåOpenAI ÂèëÂ∏É‰∫ÜÂÖ∂ÊúÄÊñ∞ÁöÑËØ≠Ë®ÄÊ®°Âûã o1-preview„ÄÇËøô‰∏™ÂÖàËøõÁöÑÊ®°ÂûãÁªèËøáËÆæËÆ°ÔºåËÉΩÂ§üÂú®ÁîüÊàêÂìçÂ∫î‰πãÂâçÊäïÂÖ•Êõ¥Â§öÊó∂Èó¥ËøõË°åÂ§ÑÁêÜÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Â∫îÂØπÂ§çÊùÇ‰ªªÂä°ÔºåÂπ∂Âú®ÁßëÂ≠¶„ÄÅÁºñÁ†ÅÂíåÊï∞Â≠¶Á≠âÈ¢ÜÂüüËß£ÂÜ≥ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈóÆÈ¢ò„ÄÇ\n\nÂú®ËøôÁØáÂçöÂÆ¢ÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•ÂàÜÊûê o1-previewÔºåÂπ∂Â∞ÜÂÖ∂‰∏é‰πãÂâçË¢´ËÆ§‰∏∫ÊòØÊúÄÂÖàËøõÊ®°Âûã‰πã‰∏ÄÁöÑ Claude 3.5 Sonnet ËøõË°åÊØîËæÉ„ÄÇ\n\n\n\n## ÊØîËæÉÊñπÊ≥ïËÆ∫\n\nÊàë‰ª¨ÁöÑÂàÜÊûêÂà©Áî®‰∫Ü [Keywords AI ÁöÑ LLM playground](https://docs.keywordsai.co/features/prompt/model-playground)ÔºåËøôÊòØ‰∏Ä‰∏™ÊîØÊåÅË∂ÖËøá 200 ÁßçËØ≠Ë®ÄÊ®°ÂûãÂπ∂Êèê‰æõÂáΩÊï∞Ë∞ÉÁî®ÂäüËÉΩÁöÑÂπ≥Âè∞„ÄÇÊàë‰ª¨Â∞ÜÊé¢ËÆ®‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö\n\n* Âü∫Êú¨ÊØîËæÉ\n* Âü∫ÂáÜÊØîËæÉ\n* Â§ÑÁêÜÈÄüÂ∫¶\n* ËØÑ‰º∞ÊåáÊ†á\n* Âª∫ËÆÆÁöÑ‰ΩøÁî®Ê°à‰æã\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yc171ikejtBy_o11.jpeg)\n\n## Âü∫Êú¨ÊØîËæÉ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*z2FrS_AVig7Y6eU_.jpeg)\n\nÊ≥®ÊÑèÔºöo1-preview ‰∏çÊîØÊåÅÊµÅÂºè‰º†Ëæì„ÄÅÂáΩÊï∞Ë∞ÉÁî®ÂíåÁ≥ªÁªüÊ∂àÊÅØ„ÄÇ\n\n## Âü∫ÂáÜÊØîËæÉ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Bx_vAvFc9DAD0cZA.jpeg)\n\nO1-preview Âú®ÊâÄÊúâÂü∫ÂáÜÊµãËØï‰∏≠ÈÉΩ‰ºò‰∫é Claude 3.5 Sonnet„ÄÇÊúÄÂ∞èÁöÑÂ∑ÆË∑ùÂá∫Áé∞Âú® MMLUÔºà‰∏ÄËà¨Áü•ËØÜÔºâ‰∏≠„ÄÇGPQA Diamond ÊµãËØïÁ†îÁ©∂ÁîüÊ∞¥Âπ≥ÁöÑÊé®ÁêÜÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊÄßËÉΩÂ∑ÆÂºÇ„ÄÇMATH Âü∫ÂáÜÊè≠Á§∫‰∫ÜÊúÄÂ§ßÁöÑÂ∑ÆË∑ùÔºåÁ™ÅÊòæ‰∫Ü o1-preview ÁöÑÈ´òÁ∫ßÊï∞Â≠¶ËÉΩÂäõ„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåo1-preview Âú®Â§çÊùÇÊé®ÁêÜÂíåÂêÑ‰∏™È¢ÜÂüüÁöÑÈóÆÈ¢òËß£ÂÜ≥ÊñπÈù¢Êúâ‰∫ÜÊòæËëóÊîπÂñÑ„ÄÇ\n\n## ÈÄüÂ∫¶ÊØîËæÉ\n\nO1-preview ÁöÑÊÄùËÄÉÂíåÂìçÂ∫îÊó∂Èó¥ÊØîÂÖ∂‰ªñ LLM Êõ¥Èïø„ÄÇËôΩÁÑ∂Áõ¥Êé•ÁöÑÈÄüÂ∫¶ÊØîËæÉÂèØËÉΩÂπ∂‰∏çÂÆåÂÖ®ÂÖ¨Âπ≥Ôºå‰ΩÜÊµãËØï o1-preview ÁöÑÈÄüÂ∫¶Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇËøô‰∫õ‰ø°ÊÅØÂ∏ÆÂä©ÂºÄÂèëËÄÖÊõ¥Â•ΩÂú∞ÁêÜËß£ o1-preview ÁöÑËÉΩÂäõÔºåÂπ∂Âà§Êñ≠ÂÆÉÊòØÂê¶ÈÄÇÂêà‰ªñ‰ª¨ÁöÑÈ°πÁõÆ„ÄÇÊ≥®ÊÑèÔºöÁî±‰∫é o1-preview ‰∏çÊîØÊåÅÊµÅÂºè‰º†ËæìÔºåÊàë‰ª¨Â∑≤‰∏∫‰∏§‰∏™Ê®°ÂûãÁ¶ÅÁî®ÊµÅÂºè‰º†Ëæì„ÄÇÂõ†Ê≠§ÔºåÊó†Ê≥ïÊµãÈáèÈ¶ñÊ¨°‰ª§ÁâåÊó∂Èó¥ÔºàTTFTÔºâ„ÄÇ\n\n## Âª∂Ëøü\n\nÊàë‰ª¨ÁöÑÊµãËØïÊ∂âÂèäÊØè‰∏™Ê®°ÂûãÊï∞Áôæ‰∏™ËØ∑Ê±ÇÔºåÊè≠Á§∫‰∫ÜÊòæËëóÁöÑÂ∑ÆÂºÇ„ÄÇClaude 3.5 Sonnet ÁöÑÂπ≥ÂùáÂª∂Ëøü‰∏∫ 18.3 Áßí/ËØ∑Ê±ÇÔºåËÄå o1-preview ÁöÑÂπ≥ÂùáÂª∂Ëøü‰∏∫ 39.4 Áßí/ËØ∑Ê±Ç„ÄÇo1-preview ÊòæËëóÊõ¥ÈïøÁöÑÂª∂ËøüÊòØÁî±‰∫éÂÖ∂Âª∂ÈïøÁöÑÊÄùËÄÉÂíåÊé®ÁêÜËøáÁ®ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2PMkgPVuylFxwfIa.jpeg)\n\n## ÂêûÂêêÈáèÔºàÊØèÁßí‰ª§ÁâåÊï∞Ôºâ\n\nÂ∞ΩÁÆ°Âª∂ËøüËæÉÈ´òÔºåo1-previewÁöÑÂêûÂêêÈáèÊõ¥‰∏∫Âá∫Ëâ≤„ÄÇo1-previewÁîüÊàê92.94‰∏™‰ª§Áâå/ÁßíÔºåËÄåClaude 3.5 SonnetÁîüÊàê74.87‰∏™‰ª§Áâå/Áßí„ÄÇËøôË°®Êòéo1-previewËæÉÈïøÁöÑÁîüÊàêÊó∂Èó¥‰∏ªË¶ÅÊòØÁî±‰∫éÂÖ∂ÂàùÂßãÂ§ÑÁêÜÈò∂ÊÆµÔºåËÄåÈùû‰ª§ÁâåÁîüÊàêÈÄüÂ∫¶„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wxqpnwZhl9pnbw8y.jpeg)\n\n## ÊÄßËÉΩÊØîËæÉ\n\nÊàë‰ª¨Âú®[Keywords AIÂπ≥Âè∞](https://keywordsai.co/)‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÊµãËØï„ÄÇËØÑ‰º∞ÂåÖÊã¨‰∏â‰∏™ÈÉ®ÂàÜÔºö\n\n* **ÁºñÁ†Å‰ªªÂä°**Ôºö‰∏§‰∏™Ê®°ÂûãÊàêÂäüÂÆåÊàê‰∫ÜÂâçÁ´ØÂíåÂêéÁ´ØÂºÄÂèë‰ªªÂä°„ÄÇO1-previewÂú®Â§ÑÁêÜËæÉÈïø‰∏ä‰∏ãÊñáÊó∂Ë°®Áé∞Êõ¥‰Ω≥ÔºåËÉΩÂ§üÂú®Á¨¨‰∏ÄÊ¨°Â∞ùËØï‰∏≠Êõ¥ÊúâÊïàÂú∞ËØÜÂà´ÂíåËß£ÂÜ≥bug„ÄÇÂÆÉËøòÂ±ïÁé∞‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑ‰ª£Á†ÅÂàÜÊûêËÉΩÂäõ„ÄÇ\n* **ÈÄªËæëÊé®ÁêÜ**ÔºöO1-previewÂú®Êé®ÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂÆÉÁöÑÊÄùÁª¥ËøáÁ®ã‰∏é‰∫∫Á±ªËÆ§Áü•ÈùûÂ∏∏Áõ∏‰ºº„ÄÇËôΩÁÑ∂Claude 3.5 SonnetÂú®Â§ßÂ§öÊï∞ÈóÆÈ¢ò‰∏äË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜo1-previewÂßãÁªàËÉΩÂ§üËß£ÂÜ≥Â§çÊùÇÁöÑÊé®ÁêÜÊåëÊàòÔºåÂåÖÊã¨ÂõΩÈôÖÊï∞Â≠¶Â••ÊûóÂåπÂÖãÔºàIMOÔºâÁ∫ßÂà´ÁöÑÈóÆÈ¢ò„ÄÇ\n* **ÂÜô‰Ωú‰ªªÂä°**Ôºö‰∏§‰∏™Ê®°ÂûãÂú®ÂÜô‰Ωú‰ªªÂä°‰∏äË°®Áé∞ÈùûÂ∏∏Âá∫Ëâ≤„ÄÇÂÆÉ‰ª¨Â±ïÁé∞‰∫ÜÊí∞ÂÜôÁúüÂÆû„ÄÅ‰∏™ÊÄßÂåñÁöÑÂÜ∑ÈÇÆ‰ª∂‰ª•ÂèäÁÆÄÊ¥Å‰∏îÊúâÊÑè‰πâÁöÑÂçöÂÆ¢ÊñáÁ´†ÁöÑËÉΩÂäõ„ÄÇ\n\n## Ê®°ÂûãÊé®Ëçê\n\no1-preview\n\n* **ÊúÄ‰Ω≥ÈÄâÊã©Ôºö** ÈÄÇÁî®‰∫éÊï∞Â≠¶„ÄÅÁºñÁ†ÅÂíåÁâ©ÁêÜÂ≠¶‰∏≠ÁöÑÂ§çÊùÇÈóÆÈ¢òËß£ÂÜ≥„ÄÇÁâπÂà´ÈÄÇÂêàÂ§ÑÁêÜÊåëÊàòÊÄß‰ªªÂä°ÁöÑÁ†îÁ©∂‰∫∫Âëò„ÄÇ\n* **‰∏çÈÄÇÂêàÔºö** ÈúÄË¶ÅÂø´ÈÄüÂìçÂ∫îÊó∂Èó¥Êàñ‰∏•Èáç‰æùËµñÁ≥ªÁªüÊèêÁ§∫ÁöÑAIÂ∫îÁî®„ÄÇÁî±‰∫éÁº∫‰πèÊµÅÂ™í‰ΩìÊîØÊåÅÔºå‰∏çÈÄÇÁî®‰∫éËØ≠Èü≥AIÂ∫îÁî®„ÄÇ\n\nClaude 3.5 Sonnet\n\n* **ÊúÄ‰Ω≥ÈÄâÊã©Ôºö** ÈÄÇÁî®‰∫éÂ§ßÂ§öÊï∞ÈúÄË¶ÅÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõÂíåÈ´òË¥®ÈáèÂÜÖÂÆπÁîüÊàêÁöÑAIÂ∫îÁî®„ÄÇ\n* **‰∏çÈÄÇÂêàÔºö** ËØ≠Èü≥AIÂ∫îÁî®ÊàñÂØπÈ¢ÑÁÆóÈôêÂà∂‰∏•Ê†º„ÄÅÈúÄË¶ÅËæÉ‰ΩéËøêËê•ÊàêÊú¨ÁöÑÈ°πÁõÆ„ÄÇ\n\n## Â¶Ç‰ΩïÂ∞Ü o1-preview ÈõÜÊàêÂà∞ÊÇ®ÁöÑ AI Â∫îÁî®‰∏≠\n\nË¶ÅÂ∞Ü o1-preview ÈõÜÊàêÂà∞ÊÇ®ÁöÑ AI Â∫îÁî®‰∏≠ÔºåÂè™ÈúÄËÆøÈóÆ Keywords AI Ê®°ÂûãÈ°µÈù¢Âπ∂ÊâæÂà∞‚ÄúÊü•Áúã‰ª£Á†Å‚ÄùÊåâÈíÆ„ÄÇÁÇπÂáªÊ≠§ÊåâÈíÆ‰ª•Â§çÂà∂Êèê‰æõÁöÑ‰ª£Á†ÅÁâáÊÆµÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂Áõ¥Êé•Á≤òË¥¥Âà∞ÊÇ®ÁöÑ‰ª£Á†ÅÂ∫ì‰∏≠„ÄÇÈÄöËøáËøô‰∏™ÁÆÄÂçïÁöÑËøáÁ®ãÔºåÊÇ®Â∞ÜËÉΩÂ§üÂú®È°πÁõÆ‰∏≠Âà©Áî® o1-preview ÁöÑÂº∫Â§ßÂäüËÉΩÔºå‰ΩøÊÇ®ËÉΩÂ§üËΩªÊùæÂ∫îÂØπÂ§çÊùÇÈóÆÈ¢òÂπ∂ÁîüÊàêÈ´òË¥®ÈáèÂÜÖÂÆπ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XyQ9QiI7TN8Uc5Jp.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t8fEYlEs13eM7D28lVbtIw.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*yhu9y5ixNuxeFVe1.png)\n\nÊ≠§ÊïÖ‰∫ãÂèëÂ∏ÉÂú® [Generative AI](https://generativeai.pub/)„ÄÇËØ∑Âú® [LinkedIn](https://www.linkedin.com/company/generative-ai-publication) ‰∏ä‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥® [Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•‰æøËé∑ÂèñÊúÄÊñ∞ÁöÑ AI ËµÑËÆØ„ÄÇ\n\nËÆ¢ÈòÖÊàë‰ª¨ÁöÑ [newsletter](https://www.generativeaipub.com/) Âíå [YouTube](https://www.youtube.com/@generativeaipub) È¢ëÈÅìÔºåÂèäÊó∂‰∫ÜËß£ÁîüÊàê AI ÁöÑÊúÄÊñ∞Ê∂àÊÅØÂíåÂä®ÊÄÅ„ÄÇËÆ©Êàë‰ª¨ÂÖ±ÂêåÂ°ëÈÄ† AI ÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*PelNtaNaEVDWgMWr.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-01-preview-secrets-99-of-people-dont-know-b0c5e4bb4f76","frontmatter":{"title":"OpenAI 01-È¢ÑËßà‚Ää‚Äî‚Ää99% ÁöÑ‰∫∫‰∏çÁü•ÈÅìÁöÑÁßòÂØÜ","meta_title":"OpenAI 01-È¢ÑËßà‚Ää‚Äî‚Ää99% ÁöÑ‰∫∫‰∏çÁü•ÈÅìÁöÑÁßòÂØÜ","description":"Â¶Ç‰ΩïÂÖÖÂàÜÂà©Áî® 01-preview","date":"2024-11-01T03:58:01.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wRAXNmhEzkGNagMl5Papxg.jpeg","categories":["Programming","Machine Learning","Technology/Web"],"author":"Rifx.Online","tags":["OpenAI","01-preview","iterative","problem-solving","planning"],"draft":false,"slug":"blog/openai-01-preview-secrets-99-of-people-dont-know-b0c5e4bb4f76"},"content":"\n### Â¶Ç‰ΩïÂÖÖÂàÜÂà©Áî®01\\-preview\n\nËá™‰ªé01\\-previewÂèëÂ∏É‰ª•Êù•ÔºåÊàë‰∏ÄÁõ¥Âú®Áé©ÂÆÉ„ÄÇ\n\nÊàëÈùûÂ∏∏ÂñúÊ¨¢ÂÆÉÔºÅ\n\nÊàëÁîöËá≥Âú®ÊàëÁöÑÊñ∞[**AIÂ¢ûÈïøÈªëÂÆ¢ËØæÁ®ã**](https://aigrowthguys.com/growth-hacking-course-sign-up/)‰∏≠ÊïôÊéàÂÆÉ„ÄÇ\n\nÊàëÂæàÈ´òÂÖ¥ÂàÜ‰∫´‰∏Ä‰∫õÂÖ≥‰∫éÂ¶Ç‰ΩïÂÖÖÂàÜÂà©Áî®ÂÆÉÁöÑÂÖ≥ÈîÆËßÅËß£„ÄÇ\n\n\n\nÂ§ßÂ§öÊï∞‰∫∫ÂØπ01\\-previewÁöÑÂ∑•‰ΩúÂéüÁêÜ‰∏ÄÊó†ÊâÄÁü•„ÄÇ\n\nÈ¶ñÂÖàÔºåÂÆÉ‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™‚ÄúÊÄùËÄÉ‚ÄùÊ®°Âûã„ÄÇ\n\nÂú®ÊÇ®ËÉΩÂ§üÂÖÖÂàÜÂà©Áî®ÂÆÉ‰πãÂâçÔºåÊÇ®ÈúÄË¶Å‰∫ÜËß£‰∏Ä‰∫õÂÆÉÁöÑÂ∑•‰ΩúÂéüÁêÜ„ÄÇ\n\nÂ¶ÇÊûúÊÇ®Ê≤°Êúâ‰ªòË¥πÁöÑMediumË¥¶Êà∑ÔºåÂèØ‰ª•Âú®[**ËøôÈáå**](https://readmedium.com/openai-01-preview-secrets-99-of-people-dont-know-b0c5e4bb4f76?sk=12140ffad09d922bc00a8a4aa312a286)ÂÖçË¥πÈòÖËØª„ÄÇ\n\nüëâ Ê≥®ÂÜåÊàë‰ª¨ÁöÑÂÖçË¥π5Â§©ÁîµÂ≠êÈÇÆ‰ª∂ËØæÁ®ãÔºåÂä©ÂäõÊàêÈïøüöÄÂπ∂Âú®AIÊó∂‰ª£ËµöÂèñüí≤\n\n## OpenAI 01\\-preview Â¶Ç‰ΩïÂ∑•‰ΩúÔºü\n\n01\\-preview Âπ∂‰∏çÊòØÁúüÊ≠£ÁöÑÊñ∞Ê®°Âûã„ÄÇ\n\nÂÆÉÁªìÂêà‰∫ÜÂÖ∂‰ªñÊ®°ÂûãÂíå‰∏Ä‰∏™‚ÄúÁ≥ªÁªüÊèêÁ§∫‚ÄùÔºåÂëäËØâÂÆÉÂú®ËæìÂá∫ÂìçÂ∫î‰πãÂâçËøõË°åÂ§öÊ¨°Ëø≠‰ª£„ÄÇ\n\nÊâÄÊúâÂÖ∂‰ªñÊ®°ÂûãÈÉΩÊòØÈÄöËøáÊèê‰æõÊ®°ÂûãÊÉ≥Âà∞ÁöÑÁ¨¨‰∏Ä‰∏™ÂìçÂ∫îÊù•Â∑•‰ΩúÁöÑ„ÄÇ\n\n01\\-preview ÁöÑËÆæËÆ°ÁõÆÁöÑÊòØÂú®ÊúÄÁªàÁ≠îÊ°àÂá∫Êù•‰πãÂâçËøõË°åËßÑÂàíÂíåÂÆûÈ™å„ÄÇ\n\n‰∏Ä‰∏™‰æãÂ≠ê‰ºöÊúâÊâÄÂ∏ÆÂä©„ÄÇ\n\n> ÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰Ω†ÂëäËØâ GPT\\-4o ÂÜô‰∏Ä‰∏™ÊÅ∞Â•Ω 80 ‰∏™ÂçïËØçÁöÑËøûË¥ØÊÆµËêΩÔºåÂπ∂‰∏î‚Äútomato‚ÄùËøô‰∏™ËØçÊòØÁ¨¨ 4 ‰∏™„ÄÅÁ¨¨ 19 ‰∏™ÂíåÁ¨¨ 72 ‰∏™ÂçïËØç„ÄÇ\n\nGPT\\-4oÔºà‰ª•ÂèäÊâÄÊúâÂÖ∂‰ªñÊ®°ÂûãÔºâÂú®Ëøô‰∏™‰ªªÂä°‰∏ä‰ºöÂ§±Ë¥•ÔºåÂõ†‰∏∫‰ªÖ‰ªÖÂêêÂá∫Á¨¨‰∏Ä‰∏™ÊÉ≥Âà∞ÁöÑÁ≠îÊ°àÂ§™Âõ∞Èöæ‰∫Ü„ÄÇ\n\nËøôÁßçÁ±ªÂûãÁöÑÈóÆÈ¢òÈúÄË¶ÅÂÆûÈ™å„ÄÇ\n\nÊÉ≥ÊÉ≥Â¶ÇÊûú‰Ω†Ë¢´Ëµã‰∫à‰∫ÜÂêåÊ†∑ÁöÑ‰ªªÂä°„ÄÇ\n\n‰Ω†ÈúÄË¶Å‚ÄúÁé©ÂºÑ‚ÄùËøô‰∏™‰ªªÂä°ÔºåËØïÂõæÂ∞Ü‚Äútomato‚ÄùËøô‰∏™ËØçÊîæÂú®Ëøô‰∫õ‰ΩçÁΩÆ‰∏äÔºå‰ª•‰∏ÄÁßçÂêàÁêÜÁöÑÊñπÂºè„ÄÇ\n\n‰Ω†‰∏çËÉΩ‰ªÖ‰ªÖÂºÄÂßãÂÜô‰ΩúÔºåÁÑ∂ÂêéÁúãÁúã‰ºöÂèëÁîü‰ªÄ‰πà„ÄÇ\n\n‰Ω†‰ºöÊÑèËØÜÂà∞‰Ω†ÈúÄË¶ÅË∞ÉÊï¥‰∏Ä‰∫õÂè•Â≠êÂíåÂçïËØçÔºå‰ª•‰æøÂ∞Ü‚Äútomato‚ÄùËøô‰∏™ËØçÊîæËøõÂéª„ÄÇ\n\nÊ≠§Â§ñÔºåÂΩì‰Ω†Êé•Ëøë 80 ‰∏™ÂçïËØçÊó∂Ôºå‰Ω†ÈúÄË¶ÅËÆ°ÂàíÂ¶Ç‰ΩïÂáÜÁ°ÆÂú∞ÂÅúÂú®Ëøô‰∏™Êï∞Â≠ó‰∏ä„ÄÇ‰æãÂ¶ÇÔºå‰Ω†ÂèØËÉΩÂ∏åÊúõÂõûÂéªÂà†Èô§Á¨¨‰∏ÄÂè•‰∏≠ÁöÑ‰∏Ä‰∏™Â§ö‰ΩôÂçïËØç„ÄÇ\n\n01\\-preview ËÉΩÂ§üÂÅöÂà∞Ëøô‰∏ÄÁÇπÁöÑÂéüÂõ†Âú®‰∫éÂÆÉÁöÑ‚ÄúÊÄùËÄÉ‚ÄùÊñπÂºè„ÄÇ\n\nÂÆÉÈ¶ñÂÖà‰ºöÂ∞ÜÈóÆÈ¢òÂàÜËß£ÔºåÂπ∂ËØ¥‰∏Ä‰∫õÁ±ª‰ºº‰∫é‚ÄúÊÉ≥Âá∫‰∏Ä‰∏™Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÁöÑËÆ°Âàí‚ÄùÁöÑËØù„ÄÇ\n\nÁÑ∂ÂêéÔºåÂÆÉ‰ºöÂÜôÂá∫‰∏Ä‰∏™Â§ßËá¥ÁöÑÂàùÊ≠•ÁåúÊµãÔºàÂèØËÉΩ‰ΩøÁî® GPT\\-4oÔºâ„ÄÇ\n\nÊé•ÁùÄÔºåÂÆÉ‰ºöÂØπËá™Â∑±ËØ¥Ôºö‚ÄúÈáçÊñ∞ÈòÖËØªÈóÆÈ¢òÔºåÁúãÁúãÊòØÂê¶ÂèØ‰ª•ËøõË°å‰ªª‰ΩïË∞ÉÊï¥Êàñ‰øÆÊîπ‚Äù„ÄÇ\n\nÁÑ∂ÂêéÂÆÉ‰ºöËØ¥Ôºö‚ÄúÂÜçÊ£ÄÊü•‰∏ÄÈÅçÔºåÁúãÁúã‰Ω†ÁöÑÂõûÁ≠îÊòØÂê¶ÂÆåÁæé„ÄÇÂ¶ÇÊûúÊòØÔºåÂ∞±Â±ïÁ§∫Âá∫Êù•ÔºõÂ¶ÇÊûú‰∏çÊòØÔºåÁªßÁª≠Ë∞ÉÊï¥‚Äù„ÄÇ\n\nÁÑ∂ÂêéÂÆÉ‰ºöËØ¥Ôºö‚ÄúÈáçÂ§çËøô‰∏™ËøáÁ®ãÔºåÁõ¥Âà∞‰Ω†ÁöÑÁ≠îÊ°à 100% ÂÆåÁæé„ÄÇÂßãÁªàËÆ∞ÂæóÂú®Â±ïÁ§∫ÊúÄÁªàÁ≠îÊ°à‰πãÂâçËøõË°åÂèåÈáçÊ£ÄÊü•‚Äù„ÄÇ\n\n‰æãÂ¶ÇÔºåÁ¨¨‰∏ÄÊ¨°ÂìçÂ∫îÁöÑÁ¨¨‰∏ÄÂè•ÂèØËÉΩÊòØËøôÊ†∑ÁöÑ„ÄÇ\n\n‚ÄúSandy picked a red tomato from her garden.‚Äù\n\nÁÑ∂Âêé 01\\-preview ‰ºöÂ∞ÜÂÖ∂Êõ¥Êîπ‰∏∫Ôºö‚ÄúSandy picked a tomato from her garden‚Äù„ÄÇ\n\nËøôÊ†∑ÔºåÂÆÉÂ∞±ÊàêÂäüÂú∞Â∞Ü‚Äútomato‚ÄùËøô‰∏™ËØç‰ªéÁ¨¨ 5 ‰∏™ÂçïËØçÁßªÂä®Âà∞‰∫ÜÁ¨¨ 4 ‰∏™ÂçïËØç„ÄÇ\n\nÂÆÉ‰ºöÈÄöËøá‰∏éËá™Â∑±ËøõË°åÂÜÖÈÉ®ÂØπËØù‰∏çÊñ≠ËøõË°åË∞ÉÊï¥„ÄÇ\n\n## Â¶Ç‰ΩïÂÖÖÂàÜÂà©Áî® 01\\-previewÔºü\n\nÁé∞Âú®ÊÇ®ÂØπ 01\\-preview ÁöÑ‚ÄúÊÄùÁª¥‚ÄùÊúâ‰∫Ü‰∏ÄÂÆö‰∫ÜËß£ÔºåÂèØ‰ª•ÂºÄÂßãÁêÜËß£Â¶Ç‰ΩïÂÖÖÂàÜÂà©Áî®ÂÆÉ„ÄÇ\n\nÊÇ®ÈúÄË¶ÅÂ∞ÜËá™Â∑±ÁöÑÈóÆÈ¢òÂàÜ‰∏∫ÈúÄË¶Å‚ÄúÊÄùËÄÉ‚ÄùÁöÑÈóÆÈ¢òÂíå‰∏çÈúÄË¶ÅÁöÑ„ÄÇ\n\nËÆ∏Â§öÈóÆÈ¢ò‰∏çÈúÄË¶ÅÊ®°ÂûãËøõË°å‚ÄúÊÄùËÄÉ‚Äù„ÄÇ\n\n‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊÇ®ÂëäËØâÂÆÉ‰∏∫ÊÇ®ÂÜô‰∏Ä‰∏™ÂÖ≥‰∫é‰∏Ä‰∏™ÂêçÂè´ Sandy ÁöÑÂ•≥Â≠©ÂíåÂ•πÁöÑÁï™ËåÑËä±Âõ≠ÁöÑÊúâË∂£ÊïÖ‰∫ãÔºåÈÇ£‰πàÊÇ®Â∞±‰∏çÈúÄË¶Å‰ΩøÁî® 01\\-preview„ÄÇ\n\n**‰∏∫‰ªÄ‰πà‰∏çÂë¢Ôºü**\n\nÂõ†‰∏∫Á∫¶ÊùüÊù°‰ª∂ÂæàÂ∞ë„ÄÇ\n\nÊúâÂæàÂ§öÊñπÊ≥ïÂèØ‰ª•ÂÅöÂà∞Ëøô‰∏ÄÁÇπ„ÄÇÂÆÉÊú¨Ë¥®‰∏äÊòØÂºÄÊîæÂºèÁöÑ„ÄÇ\n\nËøô‰∏™ÊïÖ‰∫ã‰∏çÈúÄË¶ÅÊúâÁâπÂÆöÁöÑÈïøÂ∫¶„ÄÇ\n\nÊ®°ÂûãÂèØ‰ª•Áõ¥Êé•ÂºÄÂßãÂÜôÔºåÊèíÂÖ•‰∏Ä‰∏§‰∏™Á¨ëËØùÔºåÁÑ∂ÂêéÂ∞±ÂÆåÊàê‰∫Ü„ÄÇ\n\nÂÆÉ‰∏çÈúÄË¶ÅÂõûÂà∞Á¨¨‰∏ÄÂè•ÂéªËÆ°ÁÆóÂçïËØçÊï∞ÈáèÊàñÂÖ∂‰ªñ‰ªª‰Ωï‰∫ãÊÉÖ„ÄÇ\n\nÂÖ≥ÈîÆÊòØÔºö\n\nÂ¶ÇÊûúÊÇ®ÂêëÊ®°ÂûãËØ∑Ê±Ç‰∏Ä‰∫õÁâπÂÆöÁöÑÂÜÖÂÆπÔºåËÄåËøô‰∫õÂÜÖÂÆπÂú®‰∏ÄÊ¨°Â∞ùËØï‰∏≠ÂæàÈöæÂÅöÂà∞‰∏îÈúÄË¶ÅÂÆûÈ™åÔºåÈÇ£‰πàÊÇ®Â∫îËØ•‰ΩøÁî® 01\\-preview„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ËØ∑Ê±ÇÁöÑÊòØÂºÄÊîæÂºèÁöÑÂÜÖÂÆπÔºåÈÇ£‰πà‰ΩøÁî®ÂÖ∂‰ªñÊ®°Âûã„ÄÇ\n\nÊÇ®ÈúÄË¶ÅË∞®ÊÖé‰ΩøÁî® 01\\-previewÔºåÂõ†‰∏∫ÊÇ®Âè™ËÉΩËé∑ÂæóÊúâÈôêÊï∞ÈáèÁöÑÊü•ËØ¢„ÄÇ\n\nÂÆÉÁöÑÈôêÂà∂ÊÄªÊòØÊØîÂÖ∂‰ªñÊ®°ÂûãÊõ¥Â§öÔºåÂõ†‰∏∫ÂÆÉ‰ΩøÁî®ÁöÑËµÑÊ∫êËøúËøúË∂ÖËøáÂÖ∂‰ªñÊ®°Âûã„ÄÇ\n\nÂ•ΩÊ∂àÊÅØÊòØÔºå01\\-preview ‰ºöÊØîÂÖ∂‰ªñÊ®°ÂûãÁäØÊõ¥Â∞ëÁöÑÈîôËØØ„ÄÇ\n\nÊ≠§Â§ñÔºåÂÆÉËÉΩÂ§üÂõûÁ≠î‰πãÂâçÊ®°ÂûãÊó†Ê≥ïËß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n\nÁé∞Âú®ÊòØÂ≠¶‰π†Â¶Ç‰ΩïÂà©Áî® AI Êù•ÂèëÂ±ïÊÇ®ÁöÑ‰∏öÂä°ÂíåËµöÂèñÊõ¥Â§öÊî∂ÂÖ•ÁöÑÊúÄ‰Ω≥Êó∂Êú∫„ÄÇ\n\nÊàëÂú®ÊàëÁöÑ AI Â¢ûÈïøÈªëÂÆ¢ËØæÁ®ã‰∏≠ÊïôÊéàÂ¶Ç‰Ωï‰ΩøÁî®Ëøô‰∏™„ÄÇ\n\nÊàëËøòÂ∞ÜÁªìÂêàËøô‰∏™Ê®°ÂûãÔºå‰ΩøÊàëÊûÑÂª∫ÁöÑËá™ÂÆö‰πâ AI ‰ª£ÁêÜÂíåËÅäÂ§©Êú∫Âô®‰∫∫Êõ¥Âä†ÂáÜÁ°Æ„ÄÇ\n\nËøôÂ∞Ü‰ΩøÂÉè [**Stammer**](https://stammer.ai/?via=andrew) ËøôÊ†∑ÁöÑ AI ‰ª£ÁêÜÊûÑÂª∫ËÄÖÊõ¥Âä†Âº∫Â§ß„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-confirms-the-arrival-of-gpt-5-poised-to-bring-huge-improvements-to-artificial-intelligence-e3b858e79c2a","frontmatter":{"title":"OpenAI Á°ÆËÆ§ GPT-5 Âç≥Â∞ÜÂà∞Êù•ÔºåÊúâÊúõ‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂ∏¶Êù•Â∑®Â§ßÊîπËøõ‚Ä¶‚Ä¶","meta_title":"OpenAI Á°ÆËÆ§ GPT-5 Âç≥Â∞ÜÂà∞Êù•ÔºåÊúâÊúõ‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂ∏¶Êù•Â∑®Â§ßÊîπËøõ‚Ä¶‚Ä¶","description":"ÊúâÁΩëÂèãÂú®x‰∏äÂèë‰∫Ü‰∏ÄÁØáGPT5ÂÄíËÆ°Êó∂ÁöÑÂ∏ñÂ≠êÔºåÁß∞ËøôÊòØÊ†πÊçÆÂêÑÂπ≥Âè∞ÁöÑÁ∫øÁ¥¢ÂæóÂá∫ÁöÑÁªìËÆ∫„ÄÇËØÑËÆ∫Âå∫‚Ä¶‚Ä¶","date":"2024-11-01T03:58:58.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8J_opnaERs-wrq2YRKIxdQ.png","categories":["Natural Language Processing","Generative AI","Technology"],"author":"Rifx.Online","tags":["GPT-5","natural","language","efficiency","personalization"],"draft":false,"slug":"blog/openai-confirms-the-arrival-of-gpt-5-poised-to-bring-huge-improvements-to-artificial-intelligence-e3b858e79c2a"},"content":"\n\n\n‰∏Ä‰ΩçÁΩëÂèãÂú® x ‰∏äÂèëÂ∏É‰∫Ü GPT5 ÂÄíËÆ°Êó∂ÁöÑÂ∏ñÂ≠êÔºåÁß∞ËøôÊòØ‰ªéÂêÑ‰∏™Âπ≥Âè∞ÁöÑÁ∫øÁ¥¢ÂæóÂá∫ÁöÑÁªìËÆ∫„ÄÇËØÑËÆ∫Âå∫Â∑≤ÁªèËææÂà∞È´òÊΩÆÔºåÂêÑÁßçÊÑèËßÅÁ∫∑Á∫∑Ê∂åÁé∞„ÄÇ\n\n\n\n**ÂéüÂõ† 1** : OpenAI ÁΩëÁ´ô GPT5 Ê≥ÑÈú≤\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EBDLAv3rOyCjshGBpVRI7A.png)\n\n**ÂéüÂõ† 2** : Áü•ÂêçÁæéÂõΩË¥¢ÁªèÁΩëÁ´ô BusinessInsider ÂèëÂ∏ÉÁöÑÊñáÁ´†‚ÄúOpenAI ÂèëÂ∏ÉÊõ¥Â•ΩÁöÑ GPT5 ËÅäÂ§©Êú∫Âô®‰∫∫‚Äù„ÄÇÁî±‰∫éËØ•ÁΩëÁ´ô‰∏∫‰ªòË¥πÁΩëÁ´ôÔºåÊÑüÂÖ¥Ë∂£ÁöÑËØùÂèØ‰ª•ÊêúÁ¥¢Ê†áÈ¢ò„ÄÇ‰ª•‰∏ãÊòØÈÉ®ÂàÜÂÜÖÂÆπÔºö\n\nËøôÂÆ∂Áî± Sam Altman È¢ÜÂØºÁöÑÁîüÊàêÂºè AI ÂÖ¨Âè∏ÔºåÈ¢ÑËÆ°Â∞ÜÂú®Âπ¥‰∏≠Êüê‰∏™Êó∂ÂÄôÊé®Âá∫ GPT-5ÔºåÂèØËÉΩÂú®Â§èÂ≠£ÔºåÊ†πÊçÆ‰∏§‰ΩçÁÜüÊÇâËØ•ÂÖ¨Âè∏ÁöÑ‰∫∫Â£´ÁöÑËØ¥Ê≥ï„ÄÇÊ†πÊçÆÂè¶‰∏Ä‰ΩçÁÜüÊÇâËØ•ËøáÁ®ãÁöÑ‰∫∫Â£´ÁöÑËØ¥Ê≥ïÔºå‰∏Ä‰∫õ‰ºÅ‰∏öÂÆ¢Êà∑ÊúÄËøëÊî∂Âà∞‰∫ÜÊúÄÊñ∞Ê®°ÂûãÂèäÂÖ∂‰∏é ChatGPT Â∑•ÂÖ∑Áõ∏ÂÖ≥ÁöÑÂ¢ûÂº∫ÂäüËÉΩÁöÑÊºîÁ§∫„ÄÇBusiness Insider Â∑≤Á°ÆËÆ§Ëøô‰∫õ‰∫∫ÁöÑË∫´‰ªΩÔºå‰ªñ‰ª¨Ë¶ÅÊ±ÇÂåøÂêç‰ª•‰æøËÉΩÂ§üËá™Áî±ÂèëË®Ä„ÄÇ\n\nÊ†πÊçÆÂú® X ÂíåÂÖ∂‰ªñÂπ≥Âè∞‰∏äÁöÑËÆ®ËÆ∫ÔºåÊñ∞ÁöÑÊ®°ÂûãÁâàÊú¨ÂæàÂèØËÉΩÂ∞ÜÂú® 6 Êúà 6 Êó•Êé®Âá∫Ôºå‰ΩÜÂ∞ö‰∏çÁ°ÆÂÆöÊòØÂê¶‰∏∫ GPT 4.5 Êàñ GPT5„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rhApTugfrMVBB6PhMvK4rg.png)\n\nÊàë‰ª¨ÈÉΩÂú®Á≠âÂæÖ **GPT5**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eB6j2S_dPbjQ2-sV2N1fwA.jpeg)\n\n## GPT-5ÁöÑÊúüÂæÖ\n\nÂ∞ΩÁÆ°ÁªÜËäÇ‰ªçÁÑ∂Á®ÄÂ∞ëÔºå‰ΩÜÂõ¥ÁªïGPT-5ÁöÑÂÖ¥Â•ãÊÑüÊ∫ê‰∫éÂØπ‰∫∫Â∑•Êô∫ËÉΩËÉΩÂäõÊòæËëóÊèêÂçáÁöÑÊúüÂæÖ„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂèØËÉΩÁöÑËøõÂ±ïÁåúÊµãÔºö\n\n* Â¢ûÂº∫ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£ÔºöÈ¢ÑËÆ°GPT-5Â∞ÜÂØπ‰∫∫Á±ªËØ≠Ë®Ä‰∏≠ÁöÑ‰∏ä‰∏ãÊñá„ÄÅÁªÜÂæÆÂ∑ÆÂà´ÂíåÂæÆÂ¶ô‰πãÂ§ÑÊúâÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£Ôºå‰Ωø‰∫íÂä®Êõ¥Âä†ÊµÅÁïÖÂíåËá™ÁÑ∂„ÄÇ\n* ÊèêÈ´òÊïàÁéáÔºöÈöèÁùÄÊØèÊ¨°Ëø≠‰ª£ÔºåOpenAIÂú®ÂáèÂ∞ëÂª∂ËøüÂíåÊèêÈ´òÊ®°ÂûãÊïàÁéáÊñπÈù¢ÂèñÂæó‰∫ÜËøõÂ±ï„ÄÇÈ¢ÑËÆ°GPT-5Â∞ÜÁªßÁª≠Ëøô‰∏ÄË∂ãÂäøÔºåÊèê‰æõÊõ¥Âø´ÂíåÊõ¥ÂáÜÁ°ÆÁöÑÂìçÂ∫î„ÄÇ\n* Êõ¥ÂπøÊ≥õÁöÑÁü•ËØÜÂü∫Á°ÄÔºöÈÄöËøáÊï¥ÂêàÊõ¥Â§öÊ†∑ÂåñÂíåÂπøÊ≥õÁöÑÊï∞ÊçÆÈõÜÔºåGPT-5ÂèØËÉΩÂú®Êõ¥ÂπøÊ≥õÁöÑ‰∏ªÈ¢ò‰∏äÊèê‰æõÊõ¥ÂÖ®Èù¢ÂíåÂèØÈù†ÁöÑ‰ø°ÊÅØ„ÄÇ\n* È´òÁ∫ß‰∏™ÊÄßÂåñÔºöÊñ∞Ê®°ÂûãÂèØËÉΩÂåÖÊã¨Â¢ûÂº∫ÁöÑ‰∏™ÊÄßÂåñÂäüËÉΩÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏™Âà´Áî®Êà∑ÁöÑÂÅèÂ•ΩÂíåÈúÄÊ±Ç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7xCG5iy53LLQCTnmzxs_3g.jpeg)\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-gpt-5-ph-d-level-intelligence-expected-by-2025-50a86c3aad86","frontmatter":{"title":"OpenAI GPT-5ÔºöÈ¢ÑËÆ° 2025 Âπ¥Â∞ÜÂÆûÁé∞ÂçöÂ£´Á∫ßÊô∫ËÉΩ","meta_title":"OpenAI GPT-5ÔºöÈ¢ÑËÆ° 2025 Âπ¥Â∞ÜÂÆûÁé∞ÂçöÂ£´Á∫ßÊô∫ËÉΩ","description":"ÁªèËøáÊï∞ÊúàÁöÑÁåúÊµãÔºåOpenAI Áªà‰∫éÂÖ¨Â∏É‰∫ÜÂ§áÂèóÊúüÂæÖÁöÑ GPT-5 ÁöÑÁªÜËäÇ„ÄÇÊúÄÂàùÈ¢ÑËÆ°Âú® 2024 Âπ¥Êé®Âá∫Ôºå‰ΩÜ‚Ä¶‚Ä¶","date":"2024-11-01T03:59:56.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OasnWeS5mgAX_0hIpirO5Q.jpeg","categories":["Machine Learning","Ethics","Data Science"],"author":"Rifx.Online","tags":["GPT-5","Ph.D.","intelligence","ethics","privacy"],"draft":false,"slug":"blog/openai-gpt-5-ph-d-level-intelligence-expected-by-2025-50a86c3aad86"},"content":"\n\n\n\n\nÁªèËøáÂá†‰∏™ÊúàÁöÑÁåúÊµãÔºåOpenAIÁªà‰∫éÊè≠Á§∫‰∫ÜÂ§áÂèóÊúüÂæÖÁöÑGPT\\-5ÁöÑËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇÊúÄÂàùÈ¢ÑËÆ°Âú®2024Âπ¥ÂèëÂ∏ÉÔºå‰ΩÜÂÖ∂ÂèëÂ∏ÉÊó∂Èó¥Â∑≤Êé®ËøüËá≥2025Âπ¥Êú´Êàñ2026Âπ¥Âàù„ÄÇOpenAIÁöÑÈ¶ñÂ∏≠ÊäÄÊúØÂÆòMira MuratiÂú®‰∏éËææÁâπËåÖÊñØÂ∑•Á®ãÂ≠¶Èô¢ÁöÑÈááËÆø‰∏≠ÂàÜ‰∫´‰∫ÜÊúâÂÖ≥Ëøô‰∏™Êñ∞ÁâàÊú¨ÁöÑËÉΩÂäõÂíåÊΩúÂäõÁöÑËßÅËß£„ÄÇ‰ª•‰∏ãÊòØÊÇ®ÈúÄË¶ÅÁü•ÈÅìÁöÑ‰∏ÄÂàá„ÄÇ\n\n## Êô∫ÂäõÁöÑÈáèÂ≠êÈ£ûË∑É\n\nMurati Â∞Ü‰πãÂâçÁöÑ GPT ÁâàÊú¨‰∏é‰∏çÂêåÊ∞¥Âπ≥ÁöÑ‰∫∫Á±ªÊô∫ÂäõËøõË°åÊØîËæÉ„ÄÇGPT\\-3 Á±ª‰ºº‰∫é‰∏Ä‰∏™ÂπºÂÑøÔºåËÄå [**GPT\\-4**](https://www.geekmetaverse.com/gpt-4-unveils-its-secrets-a-combination-of-8-smaller-models/) ÂàôÂèØ‰∏éÈ´ò‰∏≠ÁîüÁõ∏ÊèêÂπ∂ËÆ∫„ÄÇÊñ∞ÁöÑ GPT\\-5 ÊâøËØ∫Âú®ÁâπÂÆö‰ªªÂä°‰∏äËææÂà∞‚ÄúÂçöÂ£´Á∫ßÊô∫Âäõ‚Äù„ÄÇËøô‰∏ÄËøõÂ±ï‰∏ç‰ªÖ‰ª§‰∫∫ÂÖ¥Â•ãÔºå‰πüÂºïÂèë‰∫ÜÂØπ‰∫∫Â∑•Êô∫ËÉΩÊú™Êù•ÁöÑÊÄùËÄÉ„ÄÇ\n\n## GPTÁöÑÊºîÂèòÔºö‰ªéÂÑøÁ´•Âà∞ÂçöÂ£´\n\nÂ∞ÜËøô‰∫õÁâàÊú¨‰∏é‰∫∫Á±ªÊïôËÇ≤ÁöÑÈò∂ÊÆµËøõË°åÊØîËæÉÔºåÊúâÂä©‰∫éÊàë‰ª¨Êõ¥Â•ΩÂú∞ÁêÜËß£Ëøô‰∫õËøõÊ≠•„ÄÇGPT-3Âá≠ÂÄüÂÖ∂ÁîüÊàêËøûË¥Ø‰∏îÊúâÁî®ÊñáÊú¨ÁöÑËÉΩÂäõÔºåÊâìÂºÄ‰∫ÜËÆ∏Â§öÂ§ßÈó®„ÄÇGPT-4Âú®Ëøô‰∫õÊäÄËÉΩ‰∏äËøõË°å‰∫ÜÊîπËøõÔºåË°®Áé∞Âá∫Âú®Êõ¥Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑ‰ºòË∂äÊÄßËÉΩ„ÄÇÁé∞Âú®ÔºåGPT-5Êó®Âú®Â∞ÜËøô‰∏ÄÂàáÊèêÂçáÂà∞‰∏Ä‰∏™ÂÖ®Êñ∞ÁöÑÊ∞¥Âπ≥ÔºåÂÖ∑Â§áÂÖàËøõÁöÑÊé®ÁêÜÂíåËÆ∞ÂøÜËÉΩÂäõ„ÄÇ\n\n## ‰∏ì‰∏öÊô∫ËÉΩ\n\nPh.D.\\-Á∫ßÁöÑÊô∫ËÉΩÂπ∂‰∏çÊÑèÂë≥ÁùÄ [**GPT\\-5**](https://www.geekmetaverse.com/openai-ceo-confirms-that-gpt-5-is-already-in-development/) ÂèØ‰ª•ÂÆåÁæéÂú∞ÂÆåÊàêÊâÄÊúâ‰ªªÂä°„ÄÇMurati ÊæÑÊ∏Ö‰∫ÜËøô‰∫õËÉΩÂäõÂ∞ÜÊòØÁâπÂÆö‰∫é‰ªªÂä°ÁöÑ„ÄÇËøôË°®ÊòéÔºåÂ∞ΩÁÆ° AI ÂèØËÉΩÂú®Êüê‰∫õÈ¢ÜÂüüË∂ÖË∂ä‰∫∫Á±ªÔºå‰ΩÜÂú®ÂÖ∂‰ªñÈ¢ÜÂüü‰ªçÁÑ∂‰ºöÊúâÂ±ÄÈôêÊÄß„ÄÇËøôÁßç‰∏ì‰∏öÂåñÁöÑÂÖ≥Ê≥®ÂèØËÉΩ‰ºöÂØºËá¥Âú®ÁßëÂ≠¶Á†îÁ©∂ÂíåÂ§çÊùÇÊï∞ÊçÆÂàÜÊûêÁ≠âÈ¢ÜÂüü‰∫ßÁîüÈ´òÂ∫¶Á≤æÁ°ÆÂíåÊúâÁî®ÁöÑÂ∫îÁî®„ÄÇ\n\n## ÊΩúÂú®‰∏éÊú™Êù•Â∫îÁî®\n\nGPT-5 ÁöÑÂèëÂ±ï‰∏∫ÂêÑ‰∏™È¢ÜÂüüÂºÄËæü‰∫Ü‰∏ÄÁ≥ªÂàóÂèØËÉΩÊÄß„ÄÇ‰ªéÊïôËÇ≤Âà∞ÂåªÂ≠¶Ôºå‰ªéÁ†îÁ©∂Âà∞ÊäÄÊúØÔºåÂ∫îÁî®ÂπøÊ≥õ„ÄÇ\n\n### ÊïôËÇ≤‰∏éÂüπËÆ≠\n\n‰∏ÄÊ¨æËÉΩÂ§üËææÂà∞ÂçöÂ£´Ê∞¥Âπ≥ÁöÑ[**AI**](https://www.geekmetaverse.com/apple-updates-ai-takes-center-stage-with-siri-integration-chatgpt-partnership-and-elon-musk-concerns/)ÂèØËÉΩ‰ºöÂΩªÂ∫ïÊîπÂèòÊïôËÇ≤„ÄÇ‰∏™ÊÄßÂåñËæÖÂØºÁ≥ªÁªüÂèØ‰ª•‰∏∫Â≠¶ÁîüÂú®Â§çÊùÇÈ¢ÜÂüüÊèê‰æõÊîØÊåÅÔºåÊèêÂçáÁêÜËß£ËÉΩÂäõÂíåÂ≠¶‰∏öË°®Áé∞„ÄÇ\n\n### ÂåªÂ≠¶‰∏éÂåªÁñó‰øùÂÅ•\n\nÂú®ÂåªÂ≠¶È¢ÜÂüüÔºåÂÖ∑Â§áÊ≠§Á±ªËÉΩÂäõÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•Â∏ÆÂä©ËØäÊñ≠ÁΩïËßÅÁñæÁóÖ„ÄÅÂºÄÂèë‰∏™ÊÄßÂåñÊ≤ªÁñóÊñπÊ°à‰ª•ÂèäÁÆ°ÁêÜÂ§ßÈáè‰∏¥Â∫äÊï∞ÊçÆÔºå‰ªéËÄåÊòæËëóÊé®ËøõÂåªÁñóÊä§ÁêÜ„ÄÇ\n\n### Á†îÁ©∂‰∏éÂºÄÂèë\n\nÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•‰ªéËÉΩÂ§üÂàÜÊûêÂ§ßÊï∞ÊçÆÈõÜ„ÄÅËØÜÂà´Ê®°ÂºèÂπ∂ÁîüÊàêÂÅáËÆæÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰∏≠Ëé∑ÂæóÊûÅÂ§ßÁõäÂ§ÑÔºå‰ªéËÄåÂä†ÈÄüÁßëÂ≠¶ÂíåÊäÄÊúØÂèëÁé∞ÁöÑËøõÁ®ã„ÄÇ\n\n## ÊåëÊàò‰∏é‰º¶ÁêÜËÄÉÈáè\n\nÂ∞ΩÁÆ°ÊúâÁùÄËâØÂ•ΩÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰ΩÜËøôÁßçÂÖàËøõAIÁöÑÂèëÂ±ï‰πüÂ∏¶Êù•‰∫ÜÈáçÂ§ßÁöÑ‰º¶ÁêÜÊåëÊàò„ÄÇÂ¶ÇÊûúÂØπAIÂú®ÂÖ≥ÈîÆ‰ªªÂä°‰∏äÁöÑËøáÂ∫¶‰æùËµñÊ≤°ÊúâÂæóÂà∞Â¶•ÂñÑÁÆ°ÁêÜÔºåÂèØËÉΩ‰ºöÂØºËá¥‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇ\n\n### ÈöêÁßÅ‰∏éÂÆâÂÖ®\n\nÊï∞ÊçÆÈöêÁßÅÂíåÁΩëÁªúÂÆâÂÖ®Â∞ÜÊòØÂÖ≥ÈîÆËÆÆÈ¢ò„ÄÇÁ°Æ‰øù‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªü‰∏çË¢´Êª•Áî®Ôºå‰ª•ÂèäÊïèÊÑüÊï∞ÊçÆÂæóÂà∞ÂÖÖÂàÜ‰øùÊä§Â∞ÜÊòØ‰ºòÂÖà‰∫ãÈ°π„ÄÇ\n\n### Â∞±‰∏öÂΩ±Âìç\n\nÂ∞±‰∏öÂΩ±Âìç‰πüÊòØ‰∏Ä‰∏™ÂÖ≥Ê≥®ÁÇπ„ÄÇËá™Âä®Âåñ‰∏ì‰∏ö‰ªªÂä°ÂèØËÉΩ‰ºöÂèñ‰ª£Êüê‰∫õ‰∏ì‰∏ö‰∫∫Â£´ÔºåËøôÈúÄË¶ÅÈááÂèñÁßØÊûÅÊé™ÊñΩÊù•Â∫îÂØπËøô‰∫õÁ§æ‰ºöÁªèÊµéÂΩ±Âìç„ÄÇ\n\n### ÁªìËÆ∫\n\nGPT-5 ÂèëÂ∏ÉÁöÑÂª∂ËøüÂèØËÉΩËÆ©‰∏Ä‰∫õ‰∫∫ÊÑüÂà∞Â§±ÊúõÔºå‰ΩÜÂÖ∂ÂÖàËøõÁöÑËÉΩÂäõÂºïÂèë‰∫Ü‰∫∫‰ª¨ÁöÑÊûÅÂ§ßÊúüÂæÖ„ÄÇÂ¶ÇÊûú OpenAI ÂÆûÁé∞ÂÖ∂ÁõÆÊ†áÔºåÊàë‰ª¨ÂèØËÉΩ‰ºöÁúãÂà∞‰∏Ä‰∏™Èù©ÂëΩÊÄßÁöÑÂ∑•ÂÖ∑ÔºåÂÆÉÂ∞ÜÊîπÂèòÂ§ö‰∏™Ë°å‰∏öÔºåÂπ∂ÊîπÂèòÊàë‰ª¨‰∏éÊäÄÊúØÁöÑ‰∫íÂä®ÊñπÂºè„ÄÇ\n\n### Â∏∏ËßÅÈóÆÈ¢òËß£Á≠î\n\n**1\\. ‰ªÄ‰πàÊòØ GPT\\-5Ôºü**\n\nGPT\\-5 ÊòØ OpenAI ÁöÑÁîüÊàêÈ¢ÑËÆ≠ÁªÉÂèòÊç¢Âô® (Generative Pre\\-trained Transformer, GPT) Á≥ªÂàóÂç≥Â∞ÜÊé®Âá∫ÁöÑÁâàÊú¨ÔºåÊâøËØ∫Âú®ÁâπÂÆö‰ªªÂä°‰∏≠ÂÖ∑Â§áÂçöÂ£´Á∫ßÂà´ÁöÑÊô∫ËÉΩ„ÄÇ\n\n**2\\. GPT\\-5 È¢ÑËÆ°‰ΩïÊó∂ÂèëÂ∏ÉÔºü**\n\nGPT\\-5 ÁöÑÂèëÂ∏ÉÂ∑≤Êé®ËøüËá≥ 2025 Âπ¥Â∫ïÊàñ 2026 Âπ¥Âàù„ÄÇ\n\n**3\\. GPT\\-5 ‰∏é‰πãÂâçÁöÑÁâàÊú¨Áõ∏ÊØîÂ¶Ç‰ΩïÔºü**\n\nGPT\\-3 ÁöÑÊô∫ËÉΩÁõ∏ÂΩì‰∫é‰∏Ä‰∏™Âπ¥ËΩªÂÑøÁ´•ÔºåËÄå GPT\\-4 ÂàôÁõ∏ÂΩì‰∫é‰∏ÄÂêçÈ´ò‰∏≠Áîü„ÄÇGPT\\-5 Êó®Âú®ÂÆûÁé∞ÁâπÂÆö‰ªªÂä°ÁöÑÂçöÂ£´Á∫ßÂà´Êô∫ËÉΩÔºåÊèê‰æõÂÖàËøõÁöÑÊé®ÁêÜÂíåËÆ∞ÂøÜËÉΩÂäõ„ÄÇ\n\n**4\\. GPT\\-5 ËÉΩÂ§üÊâßË°åÂì™‰∫õ‰ªªÂä°Ôºü**\n\nGPT\\-5 Â∞Ü‰∏ìÊ≥®‰∫éÊüê‰∫õ‰ªªÂä°ÔºåÂú®ÁßëÂ≠¶Á†îÁ©∂„ÄÅÂ§çÊùÇÊï∞ÊçÆÂàÜÊûê„ÄÅÊïôËÇ≤ÂíåÂåªÁñóÁ≠âÁâπÂÆöÈ¢ÜÂüüË°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n**5\\. GPT\\-5 ‰ºöÂú®ÊâÄÊúâÊñπÈù¢ÈÉΩÂÆåÁæéÂêóÔºü**\n\n‰∏çÔºåGPT\\-5 ÁöÑÂçöÂ£´Á∫ßÂà´Êô∫ËÉΩÂ∞ÜÊòØÈíàÂØπÁâπÂÆö‰ªªÂä°ÁöÑÔºåËøôÊÑèÂë≥ÁùÄÂÆÉÂú®Êüê‰∫õÈ¢ÜÂüüË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®ÂÖ∂‰ªñÈ¢ÜÂüü‰ªçÁÑ∂‰ºöÊúâÂ±ÄÈôêÊÄß„ÄÇ\n\n**6\\. GPT\\-5 ÁöÑÊΩúÂú®Â∫îÁî®ÊòØ‰ªÄ‰πàÔºü**\n\nÊΩúÂú®Â∫îÁî®ÂåÖÊã¨ÊïôËÇ≤‰∏≠ÁöÑ‰∏™ÊÄßÂåñËæÖÂØº„ÄÅÂåªÁñó‰∏≠Â∏ÆÂä©ËØäÊñ≠ÁñæÁóÖÂíåÂºÄÂèëÊ≤ªÁñóÊñπÊ°àÔºå‰ª•ÂèäÂçèÂä©Á†îÁ©∂‰∫∫ÂëòÂàÜÊûêÂ§ßÊï∞ÊçÆÈõÜÂíåÁîüÊàêÂÅáËÆæ„ÄÇ\n\n**7\\. ‰∏é GPT\\-5 Áõ∏ÂÖ≥ÁöÑ‰º¶ÁêÜËÄÉËôëÊòØ‰ªÄ‰πàÔºü**\n\n‰º¶ÁêÜËÄÉËôëÂåÖÊã¨Á°Æ‰øùÊï∞ÊçÆÈöêÁßÅÂíåÁΩëÁªúÂÆâÂÖ®ÔºåÁÆ°ÁêÜÂõ†Ëá™Âä®ÂåñÂØºËá¥ÁöÑÂ∞±‰∏öÊµÅÂ§±ÁöÑÁ§æ‰ºöÁªèÊµéÂΩ±ÂìçÔºå‰ª•ÂèäÈò≤Ê≠¢È´òÁ∫ß‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÁöÑËØØÁî®„ÄÇ\n\n**8\\. GPT\\-5 Â∞ÜÂ¶Ç‰ΩïÂΩ±ÂìçÊï∞ÊçÆÈöêÁßÅÂíåÂÆâÂÖ®Ôºü**\n\nÁ°Æ‰øù‰øùÊä§ÊïèÊÑüÊï∞ÊçÆÂíåÈò≤Ê≠¢‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÁöÑËØØÁî®Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÈúÄË¶ÅÂÆûÊñΩÊé™ÊñΩ‰ª•‰øùÈöúÊï∞ÊçÆÈöêÁßÅÂíåÂÆâÂÖ®„ÄÇ\n\n**9\\. GPT\\-5 ÂØπÂ∞±‰∏öÁöÑÊΩúÂú®ÂΩ±ÂìçÊòØ‰ªÄ‰πàÔºü**\n\nGPT\\-5 ÂØπ‰∏ì‰∏ö‰ªªÂä°ÁöÑËá™Âä®ÂåñÂèØËÉΩ‰ºö‰ΩøÊüê‰∫õ‰∏ì‰∏ö‰∫∫Â£´Â§±‰∏öÔºåÂõ†Ê≠§ÈúÄË¶ÅÈááÂèñÁßØÊûÅÊé™ÊñΩÊù•ÂáèËΩªËøô‰∫õÁ§æ‰ºöÁªèÊµéÂΩ±Âìç„ÄÇ\n\n**10\\. ‰∏∫‰ªÄ‰πà GPT\\-5 ÁöÑÂèëÂ∏ÉË¢´Âª∂ËøüÔºü**\n\nÂª∂Ëøü‰Ωø OpenAI ËÉΩÂ§üÂÆåÂñÑÂíåÂ¢ûÂº∫ GPT\\-5 ÁöÑËÉΩÂäõÔºå‰ª•Á°Æ‰øùÂÖ∂Êª°Ë∂≥ÂØπÈ´òÁ∫ßÊô∫ËÉΩÂíå‰∏ì‰∏öÂ∫îÁî®ÁöÑÈ´òÊúüÊúõ„ÄÇ\n\n**11\\. GPT\\-5 Â¶Ç‰ΩïÊîπÂèòÊïôËÇ≤Ôºü**\n\nGPT\\-5 ÂèØ‰ª•ÈÄöËøáÊèê‰æõ‰∏™ÊÄßÂåñËæÖÂØºÁ≥ªÁªüÊù•ÂΩªÂ∫ïÊîπÂèòÊïôËÇ≤ÔºåÊîØÊåÅÂ≠¶ÁîüÂú®Â§çÊùÇÂ≠¶Áßë‰∏≠ÁöÑÁêÜËß£ÂíåÂ≠¶‰∏öË°®Áé∞„ÄÇ\n\n**12\\. GPT\\-5 ÂèØ‰ª•‰∏∫ÂåªÁñóÈ¢ÜÂüüÂ∏¶Êù•Âì™‰∫õËøõÊ≠•Ôºü**\n\nÂú®ÂåªÂ≠¶È¢ÜÂüüÔºåGPT\\-5 ÂèØ‰ª•Â∏ÆÂä©ËØäÊñ≠ÁΩïËßÅÁñæÁóÖÔºåÂºÄÂèë‰∏™ÊÄßÂåñÊ≤ªÁñóÊñπÊ°àÔºå‰ª•ÂèäÁÆ°ÁêÜÂ§ßÈáè‰∏¥Â∫äÊï∞ÊçÆÔºåÊé®Âä®ÂåªÁñóÊä§ÁêÜÁöÑÈáçÂ§ßËøõÂ±ï„ÄÇ\n\nÂéüÊñáÈìæÊé•: [https://www.geekmetaverse.com/openai\\-gpt\\-5\\-ph\\-d\\-level\\-intelligence\\-2025/](https://www.geekmetaverse.com/openai-gpt-5-ph-d-level-intelligence-2025/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-just-built-her-in-real-life-17769d993e11","frontmatter":{"title":"Áî®Êà∑‰ºöÁà±‰∏ä OpenAI ÁöÑÊñ∞ GPT-4o Ê®°Âûã„ÄÇÁ°ÆÂÆûÂ¶ÇÊ≠§„ÄÇ","meta_title":"Áî®Êà∑‰ºöÁà±‰∏ä OpenAI ÁöÑÊñ∞ GPT-4o Ê®°Âûã„ÄÇÁ°ÆÂÆûÂ¶ÇÊ≠§„ÄÇ","description":"ËØ•ÂÖ¨Âè∏ÁöÑÊñ∞Ê¨æ GPT-4o ÂèØ‰ª•ÁêÜËß£ÂíåÊ®°‰ªø‰∫∫Á±ªÁöÑËØ≠Ë®ÄÂíåÊÉÖÊÑü","date":"2024-11-01T04:08:40.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-bTsggApvkUHAq57YhSd-A.png","categories":["Generative AI","Chatbots","Natural Language Processing"],"author":"Rifx.Online","tags":["GPT-4o","speech","emotions","multilingual","conversational"],"draft":false,"slug":"blog/openai-just-built-her-in-real-life-17769d993e11"},"content":"\n\n\n## ÂÖ¨Âè∏ÁöÑÊñ∞ GPT\\-4o ËÉΩÁêÜËß£Âπ∂Ê®°‰ªø‰∫∫Á±ªÁöÑËØ≠Ë®ÄÂíåÊÉÖÊÑü\n\n\n\nÂú®Ê†áÂøóÊÄßÁöÑ2013Âπ¥ÁîµÂΩ± *Â•π* ‰∏≠Ôºå‰∏ªËßí‰∏é‰∏Ä‰∏™ËØ≠Èü≥ÂêØÁî®ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÂèëÂ±ïÂá∫‰∏ÄÁßçÂº∫ÁÉàÁöÑÂÖ≥Á≥ª‚Äî‚ÄîÂπ∂ÊºîÂèòÊàê‰∏ÄÂú∫Áà±ÊÉÖÊïÖ‰∫ã„ÄÇ\n\n*Â•π* ‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊòØ‰ªäÂ§©ÁöÑËØ≠Èü≥ÂêØÁî®Á≥ªÁªüÊâÄ‰∏çÂÖ∑Â§áÁöÑÔºöÂØåÊúâÊÉÖÊÑü„ÄÅÂπΩÈªòÔºåÂπ∂‰∏îËÉΩÂ§üÊ¥ûÂØü‰∫∫Á±ªÂØπËØùÁöÑÁªÜÂæÆÂ∑ÆÂà´„ÄÇ\n\nÂú®‰ªäÂ§©Êó©‰∏äÁöÑ‰∏ÄÊ¨°ÈáçÂ§ß[ÂÖ¨Âëä](https://www.youtube.com/live/DQacCB9tDaw?app=desktop&si=jvKW7jFDwFvOMBBk)‰∏≠ÔºåOpenAI ÂÆ£Â∏ÉÂèëÂ∏É‰∏Ä‰∏™Êñ∞ÁâàÊú¨ÁöÑ ChatGPT Á≥ªÁªüÔºåËØ•Á≥ªÁªüÂ∞ÜËØ≠Èü≥„ÄÅËΩ¨ÂΩïÂíåÊô∫ËÉΩÂéüÁîüÈõÜÊàêÂà∞‰∏Ä‰∏™Ê®°Âûã‰∏≠„ÄÇ\n\nÂÆÉÂº∫Â§ß„ÄÅÁõ¥ËßÇÔºåÂπ∂‰∏î‰ª§‰∫∫‰∏çÂÆâÂú∞ÂÉè‰∫∫Á±ª„ÄÇÂü∫Êú¨‰∏äÔºåOpenAI Âª∫ÈÄ†‰∫Ü‰∏Ä‰∏™Áé∞ÂÆûÁâàÁöÑ *Â•π*„ÄÇ\n\n## ‰∏Ä‰∏™Á≥üÁ≥ïÁöÑÂØπËØùËÄÖ\n\nChatGPTÂ∑≤ÁªèÊã•ÊúâËØ≠Èü≥ÂäüËÉΩÂá†‰∏™Êúà‰∫Ü„ÄÇÂç≥‰ΩøÂú®‰ªäÂ§©ÔºåÊÇ®ÂèØ‰ª•Âú®ÊâãÊú∫‰∏äÊâìÂºÄChatGPTÂ∫îÁî®Á®ãÂ∫èÔºåÊåâ‰∏ãËÄ≥Êú∫ÂõæÊ†áÔºåÁî®ÊÇ®ÁöÑÂ£∞Èü≥‰∏éÁ≥ªÁªüÂØπËØù„ÄÇ\n\nÁÑ∂ËÄåÔºåÈóÆÈ¢òÂú®‰∫éÔºåChatGPTÊòØ‰∏Ä‰∏™Á≥üÁ≥ïÁöÑÂØπËØùËÄÖ„ÄÇ\n\nÂÆûÈôÖ‰∏äÔºåChatGPTÁöÑËØ≠Èü≥ÂäüËÉΩÊòØÈÄöËøáÂ∞Ü‰∏â‰∏™‰∏çÂêåÁöÑÊ®°ÂûãÊãºÊé•Âú®‰∏ÄËµ∑ËÄåÂàõÂª∫ÁöÑÈªëÂÆ¢ÊäÄÊúØ„ÄÇ\n\nÂΩìÊÇ®ÂØπÁ≥ªÁªüËÆ≤ËØùÊó∂ÔºåÂÆÉÈ¶ñÂÖà‰ºö‰ΩøÁî®ËΩ¨ÂΩïÊ®°ÂûãÂ∞ÜÊÇ®ÁöÑÂ£∞Èü≥ËΩ¨Âåñ‰∏∫ÊñáÊú¨„ÄÇÁÑ∂ÂêéÔºåÂÆÉ‰ºöÂ∞ÜËØ•ÊñáÊú¨ËæìÂÖ•Âà∞ÂÖ∂Êô∫ËÉΩÊ®°Âûã‰∏≠‚Äî‚ÄîÂü∫Êú¨‰∏äÔºå‰∏éGPT\\-4\\ÁöÑÂü∫Á°ÄÁ≥ªÁªüÁõ∏Âêå„ÄÇ\n\nÊô∫ËÉΩÁ≥ªÁªü‰ºöÁîüÊàêÊñáÊú¨ÔºåChatGPT‰ºöÂ∞ÜÂÖ∂ÂèçÈ¶àÂà∞‰∏Ä‰∏™ÊñáÊú¨ËΩ¨ËØ≠Èü≥Á≥ªÁªü‰∏≠Ôºå‰ª•ÂàõÂª∫‰∏Ä‰∏™ËÆ°ÁÆóÊú∫ÂåñÁöÑÂ£∞Èü≥Êù•ÂõûÂ∫îÊÇ®„ÄÇ\n\nËøô‰ΩøÂæóÁ≥ªÁªüÂêç‰πâ‰∏äÊòØÂèØ‰ª•ÂØπËØùÁöÑÔºå‰ΩÜÂÆûÈôÖ‰∏ä‰∏éÂÆÉ‰∫§Ë∞àÂç¥ÊòæÂæóÁ¨®ÊãôÂíåÂ∞¥Â∞¨„ÄÇ\n\nÂú®‰∏çÂêåÊ®°Âûã‰πãÈó¥‰º†ÈÄíÂÜÖÂÆπÁöÑÈ¢ùÂ§ñÊ≠•È™§ÊÑèÂë≥ÁùÄÁ≥ªÁªüÂèçÂ∫îËøüÁºì„ÄÇÂú®ÊàëËá™Â∑±ÁöÑÊµãËØï‰∏≠ÔºåÊàëÂèëÁé∞‰ªé‰∏éÁ≥ªÁªüÂØπËØùÂà∞ÂæóÂà∞ÂõûÂ∫îÔºåÈÄöÂ∏∏ÈúÄË¶Å3Âà∞5ÁßíÁöÑÊó∂Èó¥„ÄÇ\n\n‰∫∫Á±ªÂØπËØù‰æùËµñ‰∫éÂú®ÊØ´Áßí‰πãÈó¥Â±ïÂºÄÁöÑÂæÆÂ¶ô‰πãÂ§Ñ„ÄÇ‰∏Ä‰∏™ÂìçÂ∫îËØ≠Èü≥ÈúÄË¶ÅÈïøËææ‰∫îÁßíÁöÑÁ≥ªÁªüÊÑüËßâÁ¨®ÊãôÂíåÊú∫Ê¢∞„ÄÇ\n\n‰πãÂâçÁöÑÁ≥ªÁªüËøòÁº∫‰πè‰∫∫Á±ªËØ≠Ë®ÄÁöÑËÆ∏Â§öÂü∫Êú¨ÊñπÈù¢„ÄÇ\n\n‰æãÂ¶ÇÔºåÊÇ®Êó†Ê≥ïÊâìÊñ≠ÂÆÉÔºõÊÇ®ÂøÖÈ°ªÁ≠âÂÆÉËØ¥ÂÆåÊâçËÉΩÂõûÂ∫î„ÄÇ\n\n‰∏éÂÆÉ‰∫§Ë∞àÂ∏∏Â∏∏ÊÑüËßâÂÉèÊòØÂú®‰∏éÈÇ£‰∫õÊó†Ê≥ïÊâìÊñ≠ÁöÑ‰∫∫‰∫§Ë∞àÔºå‰ªñ‰ª¨Âú®Ê≤°ÊúâÊÑèËØÜÂà∞ÊàøÈó¥ÈáåÂÖ∂‰ªñ‰∫∫ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂñãÂñã‰∏ç‰ºëÂú∞Ë∞àËÆ∫‰∏Ä‰∏™ÈöèÊú∫ËØùÈ¢ò„ÄÇÊÇ®Â∏∏Â∏∏ËßâÂæóÈúÄË¶ÅÊèêÂà∞Â••ÊñØÂç°ÁöÑ‰πêÂõ¢Ôºå‰ª•ÁªùÊúõÁöÑÂ∞ùËØïËÆ©Á≥ªÁªüÂÅúÊ≠¢ËØ¥ËØù„ÄÇ\n\nÂÆÉËøòÂèóÂà∞Êó†Ê≥ïËß£ËØªÂ£∞Èü≥‰∏≠ÁöÑÊÉÖÊÑüÊàñÂú®Ëá™Ë∫´ÂõûÂ∫î‰∏≠ÂáÜÁ°ÆÊ®°‰ªø‰∫∫Á±ªÊÉÖÊÑüÁöÑÈôêÂà∂„ÄÇ\n\n‰∫∫Á±ªÂú®ÈòÖËØªÊΩúÂè∞ËØçÊñπÈù¢ÈùûÂ∏∏Âá∫Ëâ≤ÔºåÈÉ®ÂàÜÂéüÂõ†ÊòØÊàë‰ª¨ÂèØ‰ª•ÊçïÊçâÂà∞ËØ¥ËØùËÄÖÂ£∞Èü≥‰∏≠ÁöÑÂæÆÂ¶ôÊÉÖÊÑüÁ∫øÁ¥¢„ÄÇ\n\nÂ¶ÇÊûúÊàëÈóÆÊàëÁöÑÊúãÂèãÔºö‚Äú‰Ω†‰ªäÂ§©ËøáÂæóÊÄé‰πàÊ†∑Ôºü‚ÄùËÄå‰ªñ‰ª¨ÂõûÁ≠îÔºö‚ÄúËøò‰∏çÈîô‚ÄùÔºå‰ΩÜÂú®‚ÄúËøáÂæó‚ÄùÂíå‚Äú‰∏çÈîô‚Äù‰πãÈó¥ÊèíÂÖ•‰∫Ü‰∏Ä‰∏™ÂæÆÂ¶ôÁöÑÂÅúÈ°øÔºàÊàñËÄÖÊúÄÂêé‰∏Ä‰∏™ËØç‰∏≠Â∏¶Êúâ‰∏Ä‰∏ùÊÅºÊÄíÔºâÔºåÊàëÂ∞±Áü•ÈÅì‰ªñ‰ª¨ÂÆûÈôÖ‰∏äÂ∫¶Ëøá‰∫Ü‰∏Ä‰∏™Ëâ∞ÈöæÁöÑÊó•Â≠êÔºåÊàëÂ∫îËØ•ÈóÆ‰∏Ä‰∫õÂêéÁª≠ÈóÆÈ¢ò„ÄÇ\n\nChatGPTÂÅö‰∏çÂà∞Ëøô‰∫õÔºåËøô‰ΩøÂæó‰∏éÂÆÉ‰∫§Ë∞àÊÑüËßâÂÉèÊòØÂú®‰∏éÊüêÁßçÂ§ñÊòüÊô∫ËÉΩÊ≤üÈÄöÔºåËÄå‰∏çÊòØ‰∏é‰∫∫Á±ª‰∫§ÊµÅ„ÄÇ\n\nÊÄª‰πãÔºå‰πãÂâçÁöÑÁ≥ªÁªüÊòéÊòæËêΩÂÖ•‰∫Ü‚ÄúÊÅêÊÄñË∞∑‚Äù„ÄÇÂÆÉÂú®ÂØπËØùÊñπÈù¢Ë∂≥Â§üÂá∫Ëâ≤ÔºåÂ£∞Èü≥‰πüË∂≥Â§ü‰ª§‰∫∫‰ø°ÊúçÔºå‰ª•Ëá≥‰∫éÂØπËØùÁöÑÊüê‰∫õÈÉ®ÂàÜÂèØËÉΩÊÑüËßâÂÉè‰∫∫Á±ª„ÄÇ\n\n‰ΩÜÂ•áÊÄ™ÁöÑÂÅúÈ°ø„ÄÅÁº∫‰πèÊÉÖÊÑüÁêÜËß£ÂíåÂª∂ËøüÊúÄÁªàÊâìÁ†¥‰∫ÜËøôÁßçÂπªËßâÔºå‰ΩøÂÖ∂ÊòæÂæóÊõ¥‰ª§‰∫∫‰∏çÂÆâËÄå‰∏çÊòØÊúâÁî®„ÄÇ\n\nÊàëÂ∞ùËØï‰∏éÊàëÂÖ≠Â≤ÅÁöÑÂÑøÂ≠ê‰ΩøÁî®‰πãÂâçÁöÑÁ≥ªÁªü„ÄÇ‰ªñÂØπÂÆÉÊÑüÂà∞Â¶ÇÊ≠§‰∏çÂÆâÔºå‰ª•Ëá≥‰∫é‰∏çËÆ©ÊàëÂÜçÊâìÂºÄÈü≥È¢ë„ÄÇ\n\n## OpenAIÁöÑÈù©ÂëΩÊÄßÊñ∞Ê®°Âûã\n\n‰ªäÂ§©ÔºåOpenAIÊ≠£Âú®ÊîπÂèòËøô‰∏ÄÂàá„ÄÇÂú®‰ªñ‰ª¨[‰ªäÂ§©Êó©‰∏äÁöÑÂÖ¨Âëä](https://www.youtube.com/live/DQacCB9tDaw?app=desktop&si=jvKW7jFDwFvOMBBk)‰∏≠ÔºåÂÖ¨Âè∏ÈÄèÈú≤‰ªñ‰ª¨Â∞ÜÂèëÂ∏É‰∏Ä‰∏™Êñ∞Ê®°ÂûãÔºåGPT\\-4o„ÄÇ\n\nGPT\\-4oÂéüÁîüÈõÜÊàê‰∫ÜËØ≠Èü≥ËØÜÂà´„ÄÅËØ≠Èü≥ÁîüÊàêÂíåÊô∫ËÉΩ‰∫é‰∏Ä‰∏™Á≥ªÁªü‰∏≠„ÄÇ\n\nËøôÊÑèÂë≥ÁùÄÂ∞Ü‰∏âÁßç‰∏çÂêåÊ®°ÂûãÈõÜÊàê‰ª•Ê®°ÊãüÂØπËØùÁöÑÂ§çÊùÇ‰ª£Á†ÅÁ≥ªÁªüÂ∑≤Áªè‰∏çÂ§çÂ≠òÂú®„ÄÇÁõ∏ÂèçÔºåÊñ∞ÁöÑChatGPTÁâàÊú¨Â∞ÜËÉΩÂ§ü**Êé•Êî∂ËØ≠Èü≥ÔºåÁû¨Èó¥Â§ÑÁêÜÔºåÂπ∂‰ª•ÂÖ∂Ëá™Ë∫´ÁîüÊàêÁöÑÈÄºÁúüËØ≠Èü≥‰ΩúÂá∫ÂõûÂ∫î„ÄÇ**\n\nÂØπ‰∫éÁî®Êà∑Êù•ËØ¥ÔºåËøôÂ∞ÜÂêØÁî®OpenAIÈ¶ñÂ∏≠ÊâßË°åÂÆòSam AltmanÊâÄÊèèËø∞ÁöÑÂá†ÁßçÊñ∞ÂäüËÉΩÔºåÁß∞ÂÖ∂‰∏∫‚ÄúÂÉèÈ≠îÊ≥ï‰∏ÄÊ†∑‚Äù„ÄÇ[ÊèèËø∞‰∏∫‚ÄúÂÉèÈ≠îÊ≥ï„ÄÇ‚Äù](https://twitter.com/sama/status/1788989777452408943)\n\nÈ¶ñÂÖàÔºå‰Ω†Â∞ÜËÉΩÂ§ü‰∏éChatGPTËøõË°åÊõ¥Âä†Ëá™ÁÑ∂ÁöÑÂØπËØù„ÄÇ‰Ω†‰∏çÂÜçÈúÄË¶ÅÂ∞ÜÈóÆÈ¢òÂíåÂêéÁª≠ÈóÆÈ¢òËæìÂÖ•Âà∞ÁïåÈù¢‰∏≠ÔºåËÄåÊòØÂèØ‰ª•ÂÉè‰∏éÊúãÂèã‰∫§Ë∞à‰∏ÄÊ†∑‰∏éÂ∫îÁî®Á®ãÂ∫è‰∫§Ë∞à„ÄÇ\n\nÂú®Âá†Ê¨°Áé∞Âú∫ÊºîÁ§∫‰∏≠ÔºåOpenAIÁöÑÂ∑•Á®ãÂ∏àÂ±ïÁ§∫‰∫ÜÁ≥ªÁªüÂ¶Ç‰ΩïÂú®ÊØ´ÁßíÂÜÖÂÄæÂê¨Áî®Êà∑Âπ∂‰ΩúÂá∫Êô∫ËÉΩÂõûÂ∫î„ÄÇ\n\nÂÜçÊ¨°Âº∫Ë∞ÉÔºåËøôÁßçÈÄüÂ∫¶‰πãÊâÄ‰ª•ÂèØËÉΩÔºåÊòØÂõ†‰∏∫Êñ∞Ê®°Âûã‰∏çÈúÄË¶ÅÊµ™Ë¥πÊó∂Èó¥Âú®‰∏çÂêåÊ®°Âºè‰πãÈó¥ÂàáÊç¢‚Äî‚ÄîÂÆÉÂèØ‰ª•Âú®Âçï‰∏ÄÊ≠•È™§‰∏≠Â§ÑÁêÜËØ≠Èü≥Âπ∂‰ª•Ëá™Â∑±ÁöÑÂ£∞Èü≥ÂõûÂ∫îÔºåËÄå‰∏çÂøÖ‰æùËµñÂ§ö‰∏™‰ΩéÁ∫ßÊ®°Âûã„ÄÇ\n\nGPT\\-4oËøòÂèØ‰ª•Ëß£ËØªÂíåÂàõÈÄ†ÊÉÖÊÑü„ÄÇ\n\nÂú®‰∏ÄÊ¨°ÊºîÁ§∫‰∏≠Ôºå‰∏ÄÂêçOpenAIÂëòÂ∑•Ë¶ÅÊ±ÇÁ≥ªÁªüÂºïÂØº‰ªñËøõË°åÂëºÂê∏ÁªÉ‰π†„ÄÇ\n\n‰ªñÈöèÂêéÂÅáË£ÖËøáÂ∫¶Êç¢Ê∞îÔºåËÄåChatGPT‚Äî‚ÄîÊÑüÁü•Âà∞‰ªñÂëºÂê∏ÁöÑÈÄüÂ∫¶ÂíåÂ£∞Èü≥‰∏≠ÊòæÁé∞ÁöÑÊÅêÊÖå‚Äî‚ÄîÂäù‰ªñÊîæÊÖ¢ÈÄüÂ∫¶ÔºåÂÅöÊõ¥Ê∑±ÁöÑÂëºÂê∏„ÄÇ\n\nËØ•Á≥ªÁªü‰ºº‰πéËøòËÉΩÂ§üË∞ÉËäÇËá™Ë∫´ÂõûÂ∫î‰∏≠ÁöÑÊÉÖÊÑü„ÄÇÂú®Âè¶‰∏ÄÂú∫ÊºîÁ§∫‰∏≠ÔºåËøôÂêçÂëòÂ∑•Ë¶ÅÊ±ÇGPT\\-4oÁî®Ë∂äÊù•Ë∂äÊàèÂâßÂåñÁöÑÂ£∞Èü≥ËÆ≤‰∏Ä‰∏™Áù°ÂâçÊïÖ‰∫ã„ÄÇ\n\nÂÆÉÁÖßÂäû‰∫ÜÔºåÊúÄÁªàÂê¨Ëµ∑Êù•ÂÉè‰∏Ä‰∏™‰∏≠Â≠¶ÊàèÂâßÁ§æÁöÑÂ≠©Â≠êÂú®ÂèØÊÄïÂú∞ËøáÂ∫¶Ë°®Êºî‰∏Ä‰∏™Âú∫ÊôØÔºÅ\n\nÁî±‰∫éÊñ∞Á≥ªÁªüËøòÈõÜÊàê‰∫ÜGPT\\-4ÁöÑËßÜËßâËÉΩÂäõÔºåÂÆÉÂèØ‰ª•ÊâßË°åËØ∏Â¶ÇËß£ËØª‰∫∫ËÑ∏Ë°®ÊÉÖ‰∏≠ÁöÑÊÉÖÊÑüÁ≠âÂäüËÉΩ„ÄÇ\n\nËøôÁßçÂ¢ûÂº∫ÁöÑÊÉÖÊÑüÊô∫ËÉΩÊ∞¥Âπ≥ÂèØËÉΩ‰ºö‰ΩøÁ≥ªÁªüÊàê‰∏∫‰∏Ä‰∏™Êõ¥Â•ΩÁöÑÂØπËØùËÄÖ„ÄÇ\n\nÂÖ∂‰ªñÊñ∞ÂäüËÉΩ‰πüÂ∞ÜÊúâÊâÄÂ∏ÆÂä©„ÄÇÁî®Êà∑ÂèØ‰ª•Âú®GPT\\-4oËØ¥ËØùÁöÑËøáÁ®ã‰∏≠ÊâìÊñ≠ÂÆÉ„ÄÇ\n\nÂú®‰ªñ‰ª¨ÁöÑÊºîÁ§∫‰∏≠ÔºåOpenAIÁöÑÂ∑•‰Ωú‰∫∫ÂëòÁªèÂ∏∏Âú®Ê®°ÂûãÂºÄÂßãÂÅèÁ¶ª‰∏ªÈ¢òÊó∂ÊâìÊñ≠ÂÆÉÔºåÂ∞±ÂÉèÂú®Áé∞ÂÆûÁîüÊ¥ª‰∏≠ÊâìÊñ≠ÊúãÂèã‰ª•ÂºÄÂßãÂõûÂ∫îÈóÆÈ¢ò‰∏ÄÊ†∑„ÄÇ\n\n## Â∑®Â§ßÁöÑÊΩúÂäõ\n\n‰ªäÂ§©Êó©‰∏äÁöÑÊºîÁ§∫ËΩªÊùæÂπΩÈªò„ÄÇ‰ΩÜ‰∫∫‰ª¨ÂæàÂø´Â∞±ËÉΩÊÑèËØÜÂà∞Ôºå‰∏Ä‰∏™ËÉΩÂ§üËΩªÊùæÁêÜËß£„ÄÅÂø´ÈÄüÂ§ÑÁêÜÂπ∂ÁúüÂÆûÂàõÈÄ†ÊÉÖÊÑü‰∫∫Á±ªËØ≠Ë®ÄÁöÑÊ®°ÂûãÂ∞ÜÊòØÂ§ö‰πàÂº∫Â§ß„ÄÇ\n\nÂú®ÊºîÁ§∫ËøáÁ®ã‰∏≠ÔºåChatGPTÂá†Ê¨°‰ª•ËÆ©ÊàëÊÉ≥Ëµ∑ÁîµÂΩ±„ÄäÂ•π„Äã‰∏≠ËôöÊûÑÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁöÑÊñπÂºèÂõûÂ∫î„ÄÇ\n\nChatGPT‰ºº‰πéÂØπËá™Â∑±ÊÑüÂà∞Â•ΩÁ¨ëÔºåÂΩìOpenAIÁöÑÂ∑•‰Ωú‰∫∫ÂëòÁß∞ËµûÂÆÉÊó∂ÔºåÂÆÉ‰ºöÊÑüÂà∞Â∞¥Â∞¨ÔºåÁîöËá≥ÂèØËÉΩ‰ºö‰∏çÊó∂Âú∞ÊäõÂá∫‰∏Ä‰∫õË∞ÉÊÉÖÁöÑÂè∞ËØç„ÄÇ\n\nÂá†Ê¨°ÔºàÊçÆÁß∞ÔºâÂç≥ÂÖ¥ÁöÑ‰∫íÂä®‰πüÊè≠Á§∫‰∫ÜÊõ¥Â•ΩÁöÑÂØπËØùÂèØ‰ª•Ëß£ÈîÅÁöÑ‰∏Ä‰∫õÊõ¥Ê∑±Â±ÇÊ¨°ÁöÑËÉΩÂäõ„ÄÇ\n\nÊ†πÊçÆËßÇ‰ºóÁöÑÈóÆÈ¢òÔºåOpenAIÁöÑÂ∑•‰Ωú‰∫∫ÂëòÊºîÁ§∫‰∫ÜÁ≥ªÁªüÂ¶Ç‰ΩïËÉΩÂ§üÂê¨ÊáÇÊÑèÂ§ßÂà©ËØ≠ÔºåÂπ∂Âø´ÈÄüÂáÜÁ°ÆÂú∞Â∞ÜÂÖ∂ÁøªËØëÊàêËã±ËØ≠ÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇ\n\n‰∫∫‰ª¨ÂæàÂÆπÊòìÊÉ≥Ë±°ÔºåËøôÊ†∑ÁöÑËÉΩÂäõÂ∞Ü‰ΩøÂ§öËØ≠Ë®Ä‰∫íÂä®ÂèòÂæóÊûÅÂÖ∂ÁÆÄÂçïÔºåÂü∫Êú¨‰∏äÊ∂àÈô§‰∫ÜËØ≠Ë®ÄÈöúÁ¢çÔºà‰πüËÆ∏ËøòÂåÖÊã¨‰∫∫Á±ªÁøªËØëÔºâ„ÄÇ\n\n‰æãÂ¶ÇÔºå‰∏Ä‰ΩçÂåªÁîüÂèØ‰ª•Ë∞ÉÂá∫ChatGPTÔºåÂø´ÈÄü‰∏é‰ªª‰ΩïËØ≠Ë®ÄÁöÑÊÇ£ËÄÖ‰∫§ÊµÅ„ÄÇÂú®ÊóÖË°åÊó∂Ôºå‰Ω†ÂèØ‰ª•Âú®ÊâãÊú∫‰∏äË∞ÉÂá∫Ëøô‰∏™Â∫îÁî®ÔºåÊääÂÆÉÂΩì‰Ωú‰∏Ä‰∏™ÂÖçË¥πÁöÑÂç≥Êó∂ÁøªËØëÔºåÂêëÊüê‰∫∫ËØ¢ÈóÆÊñπÂêëÊàñÂú®ÂïÜÂ∫óÈáåËøõË°åË¥≠‰π∞„ÄÇ\n\nÂ¶ÇÊûúÂÜçÂä†‰∏äËßÜËßâËÉΩÂäõÔºå‰Ω†ÁîöËá≥ÂèØ‰ª•ÂêëChatGPTÂ±ïÁ§∫‰∏ÄÂÆ∂Â§ñÂõΩÈ§êÂéÖÁöÑËèúÂçïÔºåËØ¢ÈóÆÊüê‰∫õËèúÂìÅÁöÑÁøªËØëÔºåÂëäËØâÂÆÉ‰Ω†Âú®ÂÆ∂Êó∂ÂñúÊ¨¢ÂêÉ‰ªÄ‰πàÔºåÂπ∂ËØ∑ÂÆÉÊé®Ëçê‰∏Ä‰∫õ‰Ω†ÂèØËÉΩÊÉ≥ÁÇπÁöÑËèúÔºàÊàñÈÅøÂÖçÁöÑËèúÔºâ„ÄÇ\n\nÊàë‰πüÂèØ‰ª•ÁúãÂà∞Êñ∞Á≥ªÁªüÂ¶Ç‰ΩïËøÖÈÄüËøõÂÖ•„ÄäÂ•π„ÄãÁöÑÈ¢ÜÂüü„ÄÇOpenAI‰ªçÁÑ∂‰∏çÂÖÅËÆ∏ÁîµÂΩ±‰∏≠ÂèëÁîüÁöÑÈÇ£Áßç‰∏çÈÄÇÂêàÂ∑•‰ΩúÂú∫ÂêàÁöÑ‰∫íÂä®„ÄÇ\n\n‰ΩÜÊòØGPT-4oÁêÜËß£ÂíåÊ®°‰ªøÊÉÖÊÑüÁöÑËÉΩÂäõ‚Äî‚ÄîÂä†‰∏äÂÖ∂Âº∫Â§ß‰∏îÂ∏∏Â∏∏‰ª§‰∫∫ÊÉäËÆ∂ÁöÑËÉΩÂäõÔºåËÉΩÂ§üÁîüÊàêËá™Â∑±‰ª§‰∫∫‰ø°ÊúçÁöÑ‰∫∫Á±ªÊÉÖÊÑüË°®Ëææ‚Äî‚Äî‰ª§‰∫∫Âç∞Ë±°Ê∑±Âàª„ÄÇ\n\nÂê¨ÂÆåÊºîÁ§∫ÂêéÔºåÊàëÁ°Æ‰ø°‰∫∫‰ª¨‰ºöÂÉèÁîµÂΩ±‰∏≠ÁöÑ‰∏ªËßí‰∏ÄÊ†∑Áà±‰∏äËøô‰∏™Á≥ªÁªü„ÄÇÂÆÉÁúüÁöÑÂæàÂá∫Ëâ≤„ÄÇ\n\n## ÂÆÉ‰ºöË¢´‰ΩøÁî®ÂêóÔºü\n\nÊâÄÊúâËøô‰∫õÂú®Á∫∏Èù¢‰∏äÈÉΩÂæàÊÉä‰∫∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçËøò‰∏çÊ∏ÖÊ•öÊúâÂ§öÂ∞ëÁî®Êà∑ÁúüÊ≠£ÊÉ≥Ë¶Å‰∏Ä‰∏™ÂÆåÂÖ®ÊÉÖÊÑüÂåñÁöÑ AI ËØ≠Èü≥‰º¥‰æ£„ÄÇ\n\nÊàëÂ∑•‰ΩúÁöÑÂ§ßÂ§öÊï∞‰∫∫‰ΩøÁî® ChatGPT ‰∏çÊòØ‰Ωú‰∏∫ÂØπËØù‰º¥‰æ£ÔºåËÄåÊòØÂá∫‰∫éÂÆûÁî®ÁõÆÁöÑ„ÄÇ\n\nÊàëÁúãÂà∞Âêå‰∫ã‰ª¨Âà©Áî®Ëøô‰∏™Á≥ªÁªüÊù•Â§ÑÁêÜ‰∏Ä‰∫õÊó†ËÅäÂíåÂçïË∞ÉÁöÑ‰ªªÂä°ÔºåÊØîÂ¶Ç‰∏∫ÁΩëÁªúÁ†îËÆ®‰ºöÊí∞ÂÜôÁùÄÈôÜÈ°µÊñáÊ°à„ÄÅÂø´ÈÄüÂõûÂ§çÊàø‰∏úÁöÑÁîµÂ≠êÈÇÆ‰ª∂ÔºåÊàñÊí∞ÂÜôÂçöÂÆ¢ÊñáÁ´†ÁöÑÂàùÁ®ø„ÄÇ\n\nËøô‰∫õÂÆûÁî®ÂäüËÉΩÂÆûÈôÖ‰∏äÂπ∂‰∏çÈúÄË¶ÅÂØπËØù„ÄÇÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öËÉΩÂ§üÁî®ËØ≠Èü≥Âêë AI ÂèëÂá∫Ëøô‰∫õËØ∑Ê±ÇÊòØÂê¶‰ºöÊúâÁî®„ÄÇ\n\nÂõ†Ê≠§ÔºåÁúüÊ≠£ÁöÑËÄÉÈ™åÂπ∂‰∏ç‰∏ÄÂÆöÊòØ OpenAI ÁöÑÊñ∞Á≥ªÁªüÊúâÂ§öÂº∫Â§ßÔºåËÄåÊòØ **‰ªñ‰ª¨Âú®Áî®Êà∑Â∑≤ÁªèÈÄöËøáËØ≠Èü≥‰∏éËÆ°ÁÆóÊú∫‰∫íÂä®ÁöÑÂú∞ÊñπÊï¥ÂêàÂÆÉÁöÑÊïàÊûúÂ¶Ç‰Ωï„ÄÇ**\n\nÁé∞ÂÆûÊù•ÁúãÔºåÊàëÊó†Ê≥ïÊÉ≥Ë±°ÊúâÂ§öÂ∞ëÁî®Êà∑‰ºöÂú®Â∑•‰ΩúÊó∂Âùê‰∏ãÊù•‰∏é AI ÂØπËØù„ÄÇ\n\n‰ΩÜÂ¶ÇÊûú OpenAI Â∞Ü GPT-4o ÈõÜÊàêÂà∞ÊâãÊú∫„ÄÅÊ±ΩËΩ¶ÊàñÂÉè Amazon Echo ËøôÊ†∑ÁöÑÊô∫ËÉΩËÆæÂ§áÁöÑËØ≠Èü≥ÁïåÈù¢‰∏≠ÔºåÊàëÂèØ‰ª•ÂæàÂÆπÊòìÂú∞ÊÉ≥Ë±°Ëøô‰∏™Á≥ªÁªüÁöÑÊÉÖÊÑüËÉΩÂäõÂèòÂæóÊõ¥Âä†ÊúâÁî®„ÄÇ\n\nÂç≥‰Ωø‰∫∫‰ª¨‰∏çÂ§™ÊÉ≥‰∏é ChatGPT ‰∫§Ë∞àÔºåÂéüÁîüÂ§öÊ®°ÊÄÅÈü≥È¢ëÂíåËßÜËßâÊ®°ÂûãÁöÑÊñ∞ËÉΩÂäõÂØπ‰∫éÂú® OpenAI Áé∞Êúâ API ‰∏äÊûÑÂª∫Â∫îÁî®Á®ãÂ∫èÁöÑÂºÄÂèëËÄÖÊù•ËØ¥ÔºåÂ∞ÜÊòØÊó†ÊØîÂº∫Â§ßÁöÑ„ÄÇ\n\nÂú®‰ªñ‰ª¨ÁöÑÂÖ¨Âëä‰∏≠ÔºåOpenAI Ë°®Á§∫ GPT-4o Â∞ÜÈÄöËøá‰ªñ‰ª¨Áé∞ÊúâÁöÑÂºÄÂèëËÄÖÊé•Âè£Êèê‰æõ„ÄÇËØ•Á≥ªÁªüÁöÑ‰ª∑Ê†º‰πüÂ∞ÜÊØî‰πãÂâçÁöÑ GPT-4 Ê®°Âûã‰æøÂÆú 50%„ÄÇ\n\n‰ªÖËøô‰∫õÂèòÂåñÂ∞±ÈùûÂ∏∏ÈáçÂ§ß„ÄÇÊó†ËÆ∫ËØ≠Èü≥ÂÖÉÁ¥†ÊòØÂê¶ÁúüÊ≠£ÊµÅË°åÔºåÈ©±Âä®ÂÆÉÁöÑÊô∫ËÉΩ‰πüÂ∞Ü‰ΩøÊï∞Áôæ‰∏™Áé∞ÊúâÁöÑ GPT-4 È©±Âä®Â∫îÁî®Á®ãÂ∫èÂèòÂæóÊõ¥ËÅ™Êòé„ÄÅÊõ¥Âø´„ÄÅÊõ¥Â•ΩÔºåÂπ∂‰∏îËøêËê•ÊàêÊú¨Êõ¥‰Ωé„ÄÇ\n\nÊç¢Âè•ËØùËØ¥ÔºåÊñ∞Á≥ªÁªüÁöÑÂØπËØùÂÖÉÁ¥†ÂèØËÉΩ‰ºöË¢´ËÆ§‰∏∫ÊòØ‰∏Ä‰∏™ÂæàÈÖ∑ÁöÑÂô±Â§¥„ÄÇ‰ΩÜÂÖ∂ÊΩúÂú®ÂΩ±ÂìçÂ∞ÜÊõ¥ÂæÆÂ¶ô„ÄÅÊõ¥ÂπøÊ≥õ„ÄÇ\n\nÊàëÂæàÊúüÂæÖÁúãÂà∞ÁúüÂÆûÁî®Êà∑Â¶Ç‰Ωï‰∏é GPT-4o ‰∫íÂä®„ÄÇ‰ªñ‰ª¨‰ºöÊÑüÂà∞‰∏çÂÆâÂêóÔºüÊÉäËÆ∂ÂêóÔºüÂøÉÂä®ÂêóÔºü\n\n‰ΩÜÊàëÊõ¥ÊúüÂæÖÁöÑÊòØÂêØÂä®ÊàëÁöÑ Python IDEÔºåÂ∞Ü GPT-4o Ê∑ªÂä†Âà∞ÊàëÂ∑≤Áªè‰ΩøÁî® OpenAI Â∑•ÂÖ∑ÊûÑÂª∫ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏≠„ÄÇ\n\n‰∏éÊú∫Âô®ÂØπËØùÂæàÈÖ∑„ÄÇ‰ΩÜ‰∏Ä‰∏™ËÉΩÂ§üÁêÜËß£‰∫∫Á±ªÊÉÖÊÑüÁöÑÂéüÁîüÂ§öÊ®°ÊÄÅ AI Ê®°ÂûãÔºåÊàëÂè™ÈúÄÂá†Ë°å Python ‰ª£Á†ÅÂ∞±ËÉΩË∞ÉÁî®ÔºåËÄå‰∏îÊàêÊú¨‰ΩéÂªâÔºüËøôÁúüÁöÑÂèØËÉΩÊîπÂèò‰∏ñÁïå„ÄÇ\n\n**Âú®ËøáÂéªÁöÑ‰∏ÄÂπ¥ÈáåÔºåÊàëÊµãËØï‰∫ÜÊï∞ÂçÉ‰∏™ ChatGPT ÊèêÁ§∫„ÄÇ‰Ωú‰∏∫ÂÖ®ËÅåÂàõ‰ΩúËÄÖÔºåÊúâ‰∏Ä‰∫õÊàëÊØèÂ§©ÈÉΩ‰ºö‰ΩøÁî®ÔºåÁ¨¶ÂêàÊàëÂú®Êú¨Êñá‰∏≠ÊèêÂà∞ÁöÑ‰º¶ÁêÜÁî®ÈÄî„ÄÇÊàëÂ∞ÜÂÆÉ‰ª¨Ê±áÁºñÊàê‰∏ÄÊú¨ÂÖçË¥πÁöÑÊåáÂçóÔºå*7 ‰∏™ÂØπÂàõ‰ΩúËÄÖÊûÅÂÖ∂ÊúâÁî®ÁöÑ ChatGPT ÊèêÁ§∫„ÄÇ* [‰ªäÂ§©Â∞±Ëé∑Âèñ‰∏Ä‰ªΩÂêßÔºÅ](https://no-frills-influencer.ck.page/6a100e8fe4)**\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-realtime-api-voice-mode-getting-started-on-colab-39b93edcaa6a","frontmatter":{"title":"OpenAI ÂÆûÊó∂ APIÔºàËØ≠Èü≥Ê®°ÂºèÔºâÔºåColab ÂÖ•Èó®","meta_title":"OpenAI ÂÆûÊó∂ APIÔºàËØ≠Èü≥Ê®°ÂºèÔºâÔºåColab ÂÖ•Èó®","description":"ÊÇ®ÈúÄË¶Å‰∫ÜËß£ÁöÑ‰∏ÄÂàáÔºå‰ª•ÂèäÂèØ‰ª•Âú® Colab ‰∏äËøêË°åÁöÑ OpenAI ËØ≠Èü≥Ê®°Âºè API ÁöÑÂÆûË∑µ‰ªãÁªç„ÄÇ","date":"2024-11-08T00:23:32.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_-d5zsWWQEzVLZxABTSFWQ.png","categories":["Programming","Voice Assistants","Technology/WebAPI"],"author":"Rifx.Online","tags":["OpenAI","Realtime","API","GPT-4o","Colab"],"draft":false,"slug":"blog/openai-realtime-api-voice-mode-getting-started-on-colab-39b93edcaa6a"},"content":"\n\n\nÊÇ®ÈúÄË¶Å‰∫ÜËß£ÁöÑ‰∏ÄÂàáÔºå‰ª•ÂèäÂú® Colab ‰∏äËøêË°å OpenAI ËØ≠Èü≥Ê®°Âºè API ÁöÑÂä®Êâã‰ªãÁªç„ÄÇ\n\n\n\nOpenAI ÊúÄÊñ∞ÁöÑÂºÄÂèë‰∏∫Êàë‰ª¨Â∏¶Êù•‰∫Ü **ÂÆûÊó∂ API**ÔºåÊó®Âú®ÂÖÅËÆ∏ÂºÄÂèëËÄÖÂú®‰ªñ‰ª¨ÁöÑÂ∫îÁî®‰∏≠ÂàõÂª∫ **Âø´ÈÄü„ÄÅÊó†ÁºùÁöÑËØ≠Èü≥Âà∞ËØ≠Èü≥‰ΩìÈ™å**„ÄÇËØ• API Êó®Âú®ÁÆÄÂåñÂ§öÊ®°ÊÄÅÂØπËØùÂäüËÉΩÁöÑÂºÄÂèëÔºå‰ΩøÊûÑÂª∫Ëá™ÁÑ∂ÁöÑÂÆûÊó∂ËØ≠Èü≥‰∫§‰∫íÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇ\n\n**Âú®ËøôÁØáÂçöÂÆ¢‰∏≠Ôºå** ÊàëÂ∞ÜÊ∂µÁõñÊúâÂÖ≥Ê≠§Êñ∞ API ÁöÑ **‰∏ªË¶ÅÈóÆÈ¢ò**ÔºåÂåÖÊã¨\n\n* ‰ªÄ‰πàÊòØÂÆûÊó∂ APIÔºå\n* Â¶Ç‰ΩïËÆøÈóÆÂÆÉÔºå\n* ÂÆÉÁöÑÈôêÂà∂ÂíåÂÆö‰ª∑Ôºå\n* Âπ∂Êèê‰æõ‰∏Ä‰∏™ **Colab ÊïôÁ®ã**ÔºåÊïôÊÇ®Â¶Ç‰ΩïÂÖ•Èó®„ÄÇ\n\n## ‰ªÄ‰πàÊòØÂÆûÊó∂ APIÔºü\n\n**ÂÆûÊó∂ API** ÊòØ OpenAI Êèê‰æõÁöÑÂÖ¨ÂÖ±ÊµãËØïÂäüËÉΩÔºåÂÖÅËÆ∏‰ªòË¥πÂºÄÂèëËÄÖÂú®‰ªñ‰ª¨ÁöÑÂ∫îÁî®‰∏≠ÈõÜÊàêÂÆûÊó∂ËØ≠Èü≥‰∫§‰∫í„ÄÇÂÆÉÊòØ‰∏Ä‰∏™Â§öÊ®°ÊÄÅ APIÔºåËÉΩÂ§üÂ∞Ü **Èü≥È¢ëËæìÂÖ•ËΩ¨Êç¢‰∏∫ËØ≠Èü≥ÂìçÂ∫î**ÔºåÂπ∂‰ΩøÁî®ÂÖàËøõÁöÑ **GPT-4o** Ê®°ÂûãÊù•ÂÆûÁé∞Ëøô‰∏ÄÁõÆÁöÑ„ÄÇÊú¨Ë¥®‰∏äÔºåÂÆÉÂÖÅËÆ∏ËøõË°å **‰ΩéÂª∂ËøüÂØπËØù**ÔºåÁ±ª‰ºº‰∫éËá™ÁÑ∂ÁöÑ‰∫∫ÈôÖ‰∫§‰∫íÔºåÁ±ª‰ºº‰∫é ChatGPT ÁöÑÈ´òÁ∫ßËØ≠Èü≥Ê®°Âºè‰∏≠ÁúãÂà∞ÁöÑÂäüËÉΩ„ÄÇ\n\n‰πãÂâçÔºåÂºÄÂèëËÄÖÈúÄË¶ÅÂ∞ÜÂ§ö‰∏™Ê®°ÂûãÊãºÊé•Âú®‰∏ÄËµ∑‰ª•ÂÆûÁé∞ **ËØ≠Èü≥ËØÜÂà´„ÄÅÊñáÊú¨Â§ÑÁêÜÂíåÊñáÊú¨ËΩ¨ËØ≠Èü≥ÁîüÊàê**„ÄÇÂÆûÊó∂ API Â∞ÜËøô‰∏ÄÂàáÈÉΩÊï¥ÂêàÂú®‰∏ÄÊ¨° API Ë∞ÉÁî®‰∏≠Ôºå‰ªéËÄåÂáèÂ∞ëÂª∂ËøüÔºåÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑÂìçÂ∫îÔºåÂπ∂Êõ¥‰∏ÄËá¥Âú∞Â§ÑÁêÜÂè£Èü≥ÂíåÈáçÈü≥„ÄÇ\n\n**ËÅäÂ§©ÂÆåÊàê API** ‰πüÂºïÂÖ•‰∫ÜÈü≥È¢ëËæìÂÖ•ÂíåËæìÂá∫Ôºå‰ΩÜÂÆÉÊ≤°ÊúâÂÆûÊó∂ API ÁöÑ‰ΩéÂª∂Ëøü‰ΩìÈ™å„ÄÇÂõ†Ê≠§ÔºåÂØπ‰∫éËØ≠Ë®ÄÂ≠¶‰π†ÊàñËØ≠Èü≥ÂêØÁî®Âä©ÊâãÁ≠â‰ΩìÈ™åÔºåÂÆûÊó∂ API ÊòØÊõ¥‰ºòÈÄâÊã©„ÄÇ\n\n## ËÆøÈóÆÂíåÈôêÂà∂\n\nÂØπ **Realtime API** ÁöÑËÆøÈóÆÁõÆÂâç‰Ωú‰∏∫ **ÂÖ¨ÂºÄÊµãËØïÁâà** Êèê‰æõÁªô‰ªòË¥πÂºÄÂèëËÄÖ„ÄÇ\n\n**ËôΩÁÑ∂ËØ¥Âú®Ê¨ßÊ¥≤ÁöÑËÆøÈóÆÂèóÂà∞ÈôêÂà∂Ôºå‰ΩÜÊàëÈÄöËøáÊàëÁöÑÁ¨¨5Â±ÇOpenAIË¥¶Êà∑ËÉΩÂ§ü‰ΩøÁî®ÂÆÉ„ÄÇ**\n\nËØ•API‰ΩøÁî® **WebSocket** ËøûÊé•ÔºåÁ°Æ‰øùÈü≥È¢ëËæìÂÖ•ÂíåËæìÂá∫ÁöÑÊµÅÁïÖ‰ΩìÈ™å„ÄÇ\n\nÁõÆÂâçÔºåÈúÄË¶ÅÊ≥®ÊÑè‰ª•‰∏ã **ÈôêÂà∂**Ôºö\n\n* **‰ºöËØùÈÄüÁéáÈôêÂà∂**ÔºöËØ•APIÂØπÁ¨¨5Â±ÇÂºÄÂèëËÄÖÁöÑ‰ºöËØùÊï∞ÈáèÈôêÂà∂‰∏∫Â§ßÁ∫¶ **100‰∏™ÂêåÊó∂‰ºöËØù**„ÄÇËæÉ‰ΩéÂ±ÇÁ∫ßÁöÑÂÆπÈáèÊõ¥Â∞è„ÄÇÊà™Ëá≥2024Âπ¥10ÊúàÔºåAPIÁöÑÈôêÂà∂‰∏∫ÊØèÂàÜÈíü2M‰∏™‰ª§Áâå„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XpAB6WRseRb0iY-edE94xw.png)\n\n* **ÂäüËÉΩ**ÔºöÊúÄÂàù‰ªÖÊîØÊåÅ **ËØ≠Èü≥Ê®°Âºè**Ôºå‰ΩÜOpenAIËÆ°ÂàíÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÊ∑ªÂä†Êõ¥Â§öÂäüËÉΩÔºåÂ¶Ç **ËßÜÈ¢ë** Âíå **ËßÜËßâ**„ÄÇ\n* **ÂèØÁî®ÊÄß**ÔºöÂÆåÊï¥ÁöÑÈü≥È¢ëÂäüËÉΩÂ§Ñ‰∫éÊµãËØïÈò∂ÊÆµÔºåÊú™Êù•ËÆ°Âàí‰∏∫PythonÂíåNode.jsËøõË°å **SDKÈõÜÊàê**„ÄÇ\n\n## Realtime API ÁöÑÂÆö‰ª∑\n\n**ÂÆö‰ª∑**ÁªìÊûÑÂàÜ‰∏∫ **ÊñáÊú¨‰ª§Áâå** Âíå **Èü≥È¢ë‰ª§Áâå**Ôºö\n\n* **Èü≥È¢ëËæìÂÖ•**ÔºöÊØèÁôæ‰∏á‰ª§Áâå $100ÔºàÂ§ßÁ∫¶ **$0\\.06 ÊØèÂàÜÈíü**Ôºâ„ÄÇ\n* **Èü≥È¢ëËæìÂá∫**ÔºöÊØèÁôæ‰∏á‰ª§Áâå $200ÔºàÂ§ßÁ∫¶ **$0\\.24 ÊØèÂàÜÈíü**Ôºâ„ÄÇ\n* **ÊñáÊú¨ËæìÂÖ•**ÔºöÊØèÁôæ‰∏á‰ª§Áâå $5„ÄÇ\n* **ÊñáÊú¨ËæìÂá∫**ÔºöÊØèÁôæ‰∏á‰ª§Áâå $20„ÄÇ\n\nËøô‰∏ÄÂÆö‰ª∑‰ΩøÂæóÂºÄÂèëËÄÖËÉΩÂ§üË¥üÊãÖÂæóËµ∑ÂàõÂª∫Âº∫Â§ßÁöÑ **ËØ≠Èü≥Âà∞ËØ≠Èü≥** ‰ΩìÈ™åÔºåÂ∞ΩÁÆ°Èü≥È¢ëÂäüËÉΩÁöÑÊàêÊú¨ÊòæËëóÈ´ò‰∫éÂü∫‰∫éÊñáÊú¨ÁöÑ‰∫§‰∫í„ÄÇÂú®Êâ©Â±ïÂÖ∑ÊúâËØ≠Èü≥ÂäüËÉΩÁöÑÂ∫îÁî®Êó∂ÔºåËøô‰∏ÄÁÇπÈùûÂ∏∏ÈáçË¶Å„ÄÇ\n\nËøô‰ªçÁÑ∂ÊØîÂ§ñÂåÖÁªôÊüê‰∫õÂõΩÂÆ∂Á®çË¥µÔºå‰ΩÜÊàë‰ª¨ÂèØ‰ª•ÊúüÂæÖÂú®Êé•‰∏ãÊù•ÁöÑÂÖ≠‰∏™ÊúàÂÜÖ‰ª∑Ê†º‰ºöÊòæËëó‰∏ãÈôç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ocwFDXEt8X7KD_k6)\n\n## Âú® Google Colab ‰∏≠‰ΩøÁî® Realtime API ÊûÑÂª∫\n\nËøôÊòØ‰∏Ä‰∏™Âü∫Êú¨ÁöÑ **Colab ÊåáÂçó**ÔºåÂ∏ÆÂä©ÊÇ®ÂºÄÂßã‰∏ä‰º†Êñá‰ª∂„ÄÅÂêë Realtime API ÂèëÈÄÅËØ∑Ê±ÇÂπ∂ÁîüÊàêÈü≥È¢ëÂìçÂ∫î„ÄÇ\n\nÂú®Ëøô‰∏™ÊºîÁ§∫‰∏≠ÔºåÊàë‰ª¨ÈÄâÊã©‰∏ä‰º†‰∏ÄÁ≥ªÂàóÈü≥È¢ëÁâáÊÆµÔºå‰ª•Ê®°ÊãüÂØπËØù„ÄÇ\n\n**ÂÆåÊï¥ÁöÑ Colab ‰ª£Á†Å**Ôºö [ÈìæÊé•Âú®ËøôÈáå](https://colab.research.google.com/drive/1-bj_LH7Gv2bbTJopbo7Hk_AIyDAuqeEQ?usp=sharing)ÔºåÂè™ÈúÄÂ∞ÜÊÇ®ÁöÑ ‚Äúopenai‚Äù ÂØÜÈí•Ê∑ªÂä†Âà∞ Colab ÁöÑÁßòÂØÜ‰∏≠Âπ∂ËøêË°åËØ• Colab„ÄÇ\n\n### Á¨¨‰∏ÄÊ≠•ÔºöËÆæÁΩÆ Google Colab Âíå‰æùËµñÈ°π\n\n* ÂºÄÂßã‰∏Ä‰∏™Êñ∞ÁöÑ **Google Colab** Á¨îËÆ∞Êú¨„ÄÇ\n* ÂÆâË£ÖÂøÖË¶ÅÁöÑÂ∫ìÔºå‰æãÂ¶Ç **requests** Âíå **pydub** Êù•ÁÆ°ÁêÜÈü≥È¢ëÊñá‰ª∂„ÄÇ\n\n\n```python\n#Setup\n!pip install websockets pydub --quiet \n\nimport base64\nimport numpy as np\nimport soundfile as sf\nimport json\nimport websockets\nfrom google.colab import files\nfrom pydub import AudioSegment\nfrom tqdm import tqdm\nimport io\n```\n\n### Ê≠•È™§ 2Ôºö‰∏ä‰º†Èü≥È¢ëÊñá‰ª∂\n\nÂú® Colab ‰∏≠ÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî® **google.colab** ÁöÑ `files` Ê®°ÂùóÊù•‰∏ä‰º†Èü≥È¢ëÊñá‰ª∂„ÄÇ\n\n```python\n#Upload audio\ndef upload_audio():\n    uploaded = files.upload()  \n    for file_name in uploaded.keys():\n        return file_name\n\naudio_file = upload_audio()\n```\n\n### Á¨¨ 3 Ê≠•ÔºöÂêëÂÆûÊó∂ API ÂèëÈÄÅËØ∑Ê±Ç\n\n* Âú®Â∞ÜÈü≥È¢ëÊñá‰ª∂ÂèëÈÄÅÁªô OpenAI ‰πãÂâçÔºåÊ≠£Á°ÆÊ†ºÂºèÂåñÈü≥È¢ëÊñá‰ª∂„ÄÇ\n* Âª∫Á´ã WebSocket ËøûÊé•‰ª•ÊµÅÂºè‰º†ËæìÈü≥È¢ëÊñá‰ª∂„ÄÇ\n* ‰ΩøÁî® `tqdm` ÊòæÁ§∫‰∏ä‰º†ÊµÅÁöÑËøõÂ∫¶„ÄÇ\n* ËØ•ÂáΩÊï∞ËøîÂõûÂÆåÊï¥ÁöÑ‰∫ã‰ª∂ÈõÜÔºàÂåÖÊã¨ÂìçÂ∫îÔºâÔºå‰ª•‰æøÂêéÁª≠Â§ÑÁêÜÁîüÊàêËæìÂá∫Èü≥È¢ë„ÄÇÂÆÉËøòËøîÂõûÊ®°ÂûãÂìçÂ∫îÁöÑËΩ¨ÂΩïÊñáÊú¨„ÄÇ\n\n```python\n#Helper functions\n## Function to convert Float32Array to PCM16 format\ndef float_to_pcm16(float32_array):\n    return np.clip(float32_array * 32767, -32768, 32767).astype(np.int16).tobytes()\n\n## Function to split audio into base64-encoded PCM16 chunks\ndef float32_to_base64_chunks(float32_array, chunk_size=32000):\n    pcm16_data = float_to_pcm16(float32_array)\n    for i in range(0, len(pcm16_data), chunk_size):\n        yield base64.b64encode(pcm16_data[i:i+chunk_size]).decode('utf-8')\n\n## WebSocket connection and streaming audio with text prompt\n## Main function to call OpenAI Realtime API\nasync def stream_audio_to_realtime_api(audio_file, text_prompt, openai_key, verbose = False):\n    data, samplerate = sf.read(audio_file, dtype='float32')\n    if data.ndim > 1:\n        data = data[:, 0]\n    if samplerate != 24000:\n        raise ValueError(f\"Audio must be sampled at 24kHz, but it is {samplerate}Hz\")\n\n    url = \"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01\"\n    headers = {\"Authorization\": \"Bearer \" + openai_key, \"OpenAI-Beta\": \"realtime=v1\"}\n\n    async with websockets.connect(url, extra_headers=headers) as ws:\n        await ws.send(json.dumps({\n            \"type\": \"conversation.item.create\",\n            \"item\": {\"type\": \"message\", \"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": text_prompt}]}\n        }))\n\n        with tqdm(total=(len(float_to_pcm16(data)) + 32000 - 1) // 32000, desc=\"Sending Audio Chunks\") as pbar:\n            for chunk in float32_to_base64_chunks(data):\n                await ws.send(json.dumps({\"type\": \"input_audio_buffer.append\", \"audio\": chunk}))\n                pbar.update(1)\n\n        await ws.send(json.dumps({\"type\": \"input_audio_buffer.commit\"}))\n        await ws.send(json.dumps({\"type\": \"response.create\"}))\n\n        all_events = []\n        while True:\n            response = await ws.recv()\n            event = json.loads(response)\n            all_events.append(event)\n            if verbose:\n                print(event)\n            if event[\"type\"] == \"response.output_item.done\" and \"item\" in event and \"content\" in event[\"item\"]:\n                for content in event[\"item\"][\"content\"]:\n                    if content[\"type\"] == \"audio\" and \"transcript\" in content:\n                        transcript = content[\"transcript\"]\n                        break\n            if event[\"type\"] == \"rate_limits.updated\":\n                break\n\n        return all_events, transcript\n```\n\n```python\n#Add a prompt and call OpenAI Realtime API\ntext_prompt = \"Summarize this audio content\"\n\nevents, transcript = await stream_audio_to_realtime_api(\n    audio_file, \n    text_prompt, \n    openai_key, \n    verbose = False \n#to display OpenAI's response as they arrive, use verbose = True\n    ) \n```\n\n### Á¨¨4Ê≠•ÔºöÁîüÊàêÈü≥È¢ëÂìçÂ∫î\n\n* ‰∏ÄÊó¶Êî∂Âà∞ÂìçÂ∫îÔºåÁîüÊàêÈü≥È¢ë„ÄÇ\n* ÈÄâÊã©‰∏Ä‰∏™Êñá‰ª∂ÂêçÂπ∂‰øùÂ≠òÊñá‰ª∂„ÄÇ\n* ÁÑ∂ÂêéÊÇ®Â∞ÜËÉΩÂ§ü‰∏ãËΩΩËØ•Êñá‰ª∂„ÄÇ\n\n\n```python\n## Function to decode and concatenate audio chunks into a full audio file\ndef generate_audio_from_chunks(audio_chunks, output_filename=None):\n    # Concatenate the base64-encoded audio chunks from the 'delta' field\n    full_audio_base64 = ''.join(audio_chunks)\n\n    # Decode the concatenated base64 string to raw PCM16 audio bytes\n    audio_bytes = base64.b64decode(full_audio_base64)\n\n    # Load the bytes as a pydub AudioSegment (assuming 24kHz, 1 channel, PCM16)\n    audio_segment = AudioSegment.from_raw(\n        io.BytesIO(audio_bytes), \n        sample_width=2, \n        frame_rate=24000, \n        channels=1)\n\n    # Optionally save the audio to a file\n    if output_filename:\n        audio_segment.export(output_filename, format=\"wav\")\n        print(f\"Audio saved to {output_filename}\")\n\n    return audio_segment\n```\n\n```python\n#Extract audio chunks from the collected events\naudio_output_chunks = [event['delta'] for event in events if event['type'] == 'response.audio.delta']\n\n## Generate the full audio from the collected chunks\ngenerated_audio = generate_audio_from_chunks(audio_output_chunks, output_filename=\"output_audioo.wav\")\n```\n\n## ÁªìËÆ∫\n\nÈÄöËøá‰∏äËø∞Ê≠•È™§ÔºåÊÇ®ÂèØ‰ª•Â∞Ü OpenAI ÁöÑÂÆûÊó∂ API ÈõÜÊàêÂà∞ Colab Á¨îËÆ∞Êú¨‰∏≠ÔºåÂÆûÁé∞Êó†ÁºùÁöÑËØ≠Èü≥Êåá‰ª§„ÄÇ\n\nÊú¨ÊåáÂçóÂ∫î‰∏∫ÊÇ®Êèê‰æõ‰∏Ä‰∏™ÂùöÂÆûÁöÑÂü∫Á°ÄÔºå‰ª•‰æøÊÇ®ÂÆûÈ™åÂÆûÊó∂Èü≥È¢ëÂà∞Èü≥È¢ëÁöÑ‰∫§‰∫íÔºåÂπ∂ÊûÑÂª∫ÂàõÊñ∞ÁöÑËØ≠Èü≥È©±Âä®Â∫îÁî®Á®ãÂ∫è„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-rolls-out-searchgpt-to-more-users-33024ff3132c","frontmatter":{"title":"OpenAI ÂêëÊõ¥Â§öÁî®Êà∑Êé®Âá∫ SearchGPT","meta_title":"OpenAI ÂêëÊõ¥Â§öÁî®Êà∑Êé®Âá∫ SearchGPT","description":"ChatGPT ÁöÑÁî®Êà∑ÁïåÈù¢ËøõË°å‰∫ÜÂ§ßËßÑÊ®°ÈáçÊñ∞ËÆæËÆ°Ôºå‰ª•ÊîØÊåÅ SearchGPT‚Äî‚ÄîÁé∞Âú®ÂÆÉÁ±ª‰ºº‰∫é Google Âíå Perplexity Á≠âÊêúÁ¥¢ÂºïÊìé„ÄÇ","date":"2024-11-01T03:57:02.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BW6Qt6PMwHwlYRljAIBQWg.jpeg","categories":["Chatbots","Technology/Web","SearchGPT"],"author":"Rifx.Online","tags":["SearchGPT","ChatGPT","web","search","publishers"],"draft":false,"slug":"blog/openai-rolls-out-searchgpt-to-more-users-33024ff3132c"},"content":"\n\n\n\n\n**‰Ω†Ê≥®ÊÑèÂà∞ OpenAI ÊúÄËøëÂØπ ChatGPT ÁöÑÈáçÊñ∞ËÆæËÆ°‰∫ÜÂêóÔºü**\n\nÂ¶ÇÊûú‰Ω†ÊúÄËøëÁôªÂΩïËøáÔºå‰Ω†ÂèØËÉΩ‰ºöÂèëÁé∞‰∏§‰∏™‰∏ªË¶ÅÂèòÂåñ„ÄÇ\n\n* È¶ñÂÖàÔºåÊñ∞ÁöÑ [**Canvas**](https://generativeai.pub/openai-rolls-out-canvas-in-chatgpt-a-brand-new-writing-and-coding-interface-7b57a3ec582a) ÂäüËÉΩ‰ºöËá™Âä®Âú®Âè≥‰æßÊâìÂºÄ‰∏Ä‰∏™Êñ∞ÁïåÈù¢„ÄÇËøô‰∏™Êñ∞Â¢ûÂäüËÉΩËÆ©‰Ω†ÂèØ‰ª•Â§ÑÁêÜÊõ¥ÈïøÁöÑÊñáÊ°£ÔºåËÄåÊó†ÈúÄÂú®ËÅäÂ§©‰∏≠‰∏ä‰∏ãÊªöÂä®„ÄÇËøôÊòØ‰∏Ä‰∏™Â∞èËÄåÂÆûÁî®ÁöÑÊõ¥Êñ∞„ÄÇ\n* ÂÖ∂Ê¨°Ôºå**ÊèêÁ§∫Â≠óÊÆµ**Â∑≤Áªè‰∏äÁßªÔºåÁé∞Âú®‰Ωç‰∫éÂ±èÂπï‰∏≠Â§Æ„ÄÇ\n\nËØ∑Áúã‰∏ãÈù¢ÊúÄÊñ∞ÁöÑÁî®Êà∑ÁïåÈù¢Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KsYMU9ffVlKsmHzKIOKH8g.png)\n\n‰Ω†Ê≥®ÊÑèÂà∞Ëøô‰∏™Êñ∞Â∏ÉÂ±Ä‰∏é Google Âíå Perplexity AI ÁöÑÁõ∏‰ºº‰πãÂ§Ñ‰∫ÜÂêóÔºüChatGPT Áé∞Âú®ÁúãËµ∑Êù•ÂÉè‰∏Ä‰∏™ÊêúÁ¥¢ÂºïÊìé„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xFKErUHnfbJunaKi4NvM9A.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PgSwS14lkUtZe7Ra9oLCrg.png)\n\nÁé∞Âú®ÔºåÂΩì‰Ω†Âú®ÈîÆÁõò‰∏äÊåâ‰∏ã ‚Äò/‚Äô ÈîÆÊó∂Ôºå‰Ω†ÂèØ‰ª•ÂàáÊç¢‰∏Ä‰∏™Êñ∞ÁöÑ‚ÄúÊêúÁ¥¢‚ÄùÂäüËÉΩÔºåËÆ© ChatGPT ËÆøÈóÆÁΩëÁªú„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*oYxvVvsuUuc_PM0PXRmN7A.png)\n\nËÆ©Êàë‰ª¨Êù•ÂàÜÊûê‰∏Ä‰∏ãËøôÊÑèÂë≥ÁùÄ‰ªÄ‰πà„ÄÇ\n\n## ChatGPT‰∏≠ÁöÑÊêúÁ¥¢ÂäüËÉΩÊòØ‰ªÄ‰πàÔºü\n\n[SearchGPT](https://generativeai.pub/openai-announces-search-gpt-is-this-the-google-killer-5919ba31f95b) ÂÖÅËÆ∏ChatGPTËÆøÈóÆÂÆûÊó∂ÁΩëÈ°µÊï∞ÊçÆ„ÄÇÂÆÉÁöÑÂ∑•‰ΩúÊñπÂºèÁ±ª‰ºº‰∫éPerplexityÔºå‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏∫ÊÇ®ÊêúÁ¥¢ÁΩëÁªúÔºåÊèê‰æõÂç≥Êó∂Á≠îÊ°àÔºåÂπ∂ÂåÖÂê´ÂÖ∂ÂºïÁî®ÁöÑÊù•Ê∫ê„ÄÇ\n\nËØ•ÂäüËÉΩÊúÄÂàùÂêë10,000ÂêçÁî®Êà∑ÂºÄÊîæÔºåÂπ∂‰∏∫Â∏åÊúõÊèêÂâçËÆøÈóÆÁöÑ‰∫∫Ê∑ªÂä†‰∫ÜÂÄôË°•ÂêçÂçïË°®Âçï„ÄÇ\n\nOpenAI‰∏é**ÂçéÂ∞îË°óÊó•Êä•„ÄÅÁæéÂõΩÂπøÊí≠ÂÖ¨Âè∏„ÄÅVox MediaÂíåÊó∂‰ª£ÊùÇÂøó**Á≠âÁü•ÂêçÂá∫ÁâàÂïÜÂêà‰ΩúÔºå‰ª•Á°Æ‰øùÁî®Êà∑Ëé∑ÂæóÂèØ‰ø°„ÄÅÂèØÈù†ÁöÑ‰ø°ÊÅØ„ÄÇ\n\n> ‚Äú‰∫∫Â∑•Êô∫ËÉΩÊêúÁ¥¢Â∞ÜÊàê‰∏∫‰∫∫‰ª¨ÊµèËßà‰∫íËÅîÁΩëÁöÑÂÖ≥ÈîÆÊñπÂºè‰πã‰∏ÄÔºåÂú®Ëøô‰∫õÊó©ÊúüÈò∂ÊÆµÔºåÊäÄÊúØÁöÑÊûÑÂª∫ÊñπÂºèËá≥ÂÖ≥ÈáçË¶ÅÔºåÂÆÉÂøÖÈ°ªÈáçËßÜ„ÄÅÂ∞äÈáçÂíå‰øùÊä§Êñ∞Èóª‰∏öÂíåÂá∫ÁâàÂïÜ„ÄÇÊàë‰ª¨ÊúüÂæÖ‰∏éOpenAIÂú®Ëøô‰∏™ËøáÁ®ã‰∏≠Âêà‰ΩúÔºå‰∏∫ËØªËÄÖÂàõÈÄ†‰∏ÄÁßçÊñ∞ÁöÑÂèëÁé∞„ÄäÂ§ßË•øÊ¥ãÊúàÂàä„ÄãÁöÑÊñπÂºè„ÄÇ‚Äù ‚Äî Nicholas Thompson, „ÄäÂ§ßË•øÊ¥ãÊúàÂàä„ÄãÈ¶ñÂ∏≠ÊâßË°åÂÆò\n\nÂΩìÊÇ®ÂêëSearchGPTÊèêÈóÆÊó∂ÔºåÂÆÉÂπ∂‰∏çÊòØ‰ªéÈöèÊú∫Êù•Ê∫êÊèêÂèñ‰ø°ÊÅØ„ÄÇÊØè‰∏™ÂìçÂ∫îÈÉΩÈôÑÊúâ**Ê∏ÖÊô∞ÁöÑÂÜÖËÅîÂºïÁî®ÂíåÈìæÊé•**ÔºåÂõ†Ê≠§ÊÇ®Á°ÆÂàáÁü•ÈÅì‰ø°ÊÅØÊù•Ê∫ê‰∫é‰ΩïÂ§Ñ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uchpKOXqZCG55HSNkaOOZQ.png)\n\nÊÇ®ÁîöËá≥ÂèØ‰ª•ÈÄöËøáÁÇπÂáªÂá∫Áé∞Âú®ÊêúÁ¥¢ÁΩëÁ´ô‰∏ãÊãâÊ°Ü‰∏≠ÁöÑÊ∫êÈìæÊé•Ê∑±ÂÖ•‰∫ÜËß£ÔºåÊèê‰æõÊõ¥Â§öÊé¢Á¥¢‰∏ªÈ¢òÁöÑÊñπÂºè„ÄÇ\n\n## Â¶Ç‰ΩïËÆøÈóÆ SearchGPT\n\nËÆøÈóÆ SearchGPT ÈùûÂ∏∏ÁÆÄÂçï„ÄÇÂΩìÊÇ®Âú® ChatGPT ‰∏≠Êó∂ÔºåÊåâ‰∏ã **‚Äò/‚Äô** ÈîÆÂπ∂‰ªéËèúÂçï‰∏≠ÈÄâÊã©ÊêúÁ¥¢ÈÄâÈ°π„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xNfm-6zPFzdXGL2A0D92YQ.png)\n\nÂÆÉÁöÑÂ∑•‰ΩúÊñπÂºè‰∏éÂÖ∂‰ªñÊêúÁ¥¢ÂºïÊìéÁ±ª‰ººÔºöÊÇ®ÊèêÂá∫ÈóÆÈ¢òÔºåÂá†ÁßíÈíüÂÜÖÔºåSearchGPT Â∞±‰ºöÊèê‰æõÁ≠îÊ°àÔºåÂπ∂ÈôÑ‰∏äÊù•Ê∫ê„ÄÇ\n\nÊÇ®ÁîöËá≥ÂèØ‰ª•ÊèêÂá∫ÂêéÁª≠ÈóÆÈ¢ò‰ª•Êõ¥Ê∑±ÂÖ•Âú∞Êé¢ËÆ®‰∏ªÈ¢ò„ÄÇËøôÂàõÈÄ†‰∫Ü‰∏ÄÁßçÂØπËØùÂºèÁöÑÊêúÁ¥¢‰ΩìÈ™åÔºåÊØî‰º†ÁªüÊêúÁ¥¢ÁªìÊûúÁöÑÊªöÂä®Êõ¥Âä†‰∫íÂä®„ÄÇ\n\n## SearchGPT vs. Perplexity vs. Google\n\nÈÇ£‰πàÔºåSearchGPT ‰∏é **Perplexity AI** Âíå **Google** Áõ∏ÊØîÂ¶Ç‰ΩïÂë¢Ôºü\n\n**SearchGPT** ÁöÑËÆæËÆ°Êó®Âú®‰∏∫ÊÇ®Êèê‰æõÁÆÄÊ¥Å‰∏îÊù•Ê∫êÊòéÁ°ÆÁöÑÁ≠îÊ°à„ÄÇÊØè‰∏™Á≠îÊ°àÈÉΩÊúâÈìæÊé•Âà∞ÂéüÂßãÊù•Ê∫êÔºåÊÇ®ÂèØ‰ª•ÁÇπÂáª‰ª•È™åËØÅ‰ø°ÊÅØ„ÄÇÂÆÉÈùûÂ∏∏ÈÄÇÂêàÂÆûÊó∂ÂõûÁ≠îÂíåÂø´ÈÄü‰∫ãÂÆûÊ£ÄÊü•„ÄÇ\n\nÊ≠§Â§ñÔºåÈÄöËøáÂêéÁª≠ÈóÆÈ¢òÔºåÊÇ®ÂèØ‰ª•Âú®‰∏çÈáçÊñ∞ÂºÄÂßãÁöÑÊÉÖÂÜµ‰∏ã‰ºòÂåñÊü•ËØ¢„ÄÇËøôÁßçÂØπËØùÊÄßË¥®‰ΩøÂÖ∂ÊÑüËßâÂÉèÊòØÂú®‰∏é‰∏Ä‰∏™ËÆ∞ÂæóÊÇ®ÊâÄÈóÆÈóÆÈ¢òÁöÑË∂ÖÁ∫ßÂÖàËøõÁâàÊú¨ÁöÑ Google ‰∫§Ë∞à„ÄÇ\n\nÂè¶‰∏ÄÊñπÈù¢Ôºå**Perplexity** ÂàôÊòØ‰∏Ä‰∏™Êõ¥Â≠¶ÊúØÈ£éÊ†ºÁöÑÊêúÁ¥¢ÂºïÊìé„ÄÇÂÆÉÂº∫Ë∞ÉÂ≠¶ÊúØÊñáÁ´†ÂíåËØ¶ÁªÜÁ†îÁ©∂ÔºåËøôÂØπ‰∫éÊõ¥Ê∑±ÂÖ•ÁöÑÊü•ËØ¢ÈùûÂ∏∏ÊúâÁî®„ÄÇPerplexity ÈÄöÂ∏∏Êõ¥ÈÄÇÂêàÈúÄË¶ÅÊõ¥Ê∑±Â±ÇÊ¨°Êù•Ê∫êÁöÑÁ†îÁ©∂ÂØÜÈõÜÂûã‰ªªÂä°„ÄÇ\n\nÂΩìÁÑ∂Ôºå**Google** ‰ªçÁÑ∂ÊòØËøô‰∏™È¢ÜÂüüÁöÑÂ∑®Â§¥„ÄÇÂ∞ΩÁÆ°‰ªñ‰ª¨ÊúÄËøëÂä™ÂäõÂ∞ÜÁîüÊàêÂºè AI Á∫≥ÂÖ•ÊêúÁ¥¢ÁªìÊûúÔºå‰ΩÜËøòÊ≤°ÊúâÂÆåÂÖ®ÂÆûÁé∞Áî®Êà∑ÊâÄÊúüÊúõÁöÑÊó†Áºù‰ΩìÈ™å„ÄÇ\n\nGoogle ÁöÑÁîüÊàêÊêúÁ¥¢Êé®Âá∫ËøáÁ®ãÁ¨®ÊãôÔºåÂπ∂Âõ†ÈîôËØØÂíå‰∏çÁõ∏ÂÖ≥ÁöÑÂõûÁ≠îËÄåÂèóÂà∞Â§ßÈáèÊâπËØÑ„ÄÇ‰ΩÜ Google ÁöÑ‰ø°ÊÅØÂπøÂ∫¶ÂíåÂü∫Á°ÄËÆæÊñΩ‰ªçÁÑ∂Êó†‰∏é‰º¶ÊØî„ÄÇ\n\n## ËøôÊòØË∞∑Ê≠åÁöÑÁªàÁªìÂêóÔºü\n\nË∞∑Ê≠å‰∏ç‰ºöÂæàÂø´Ê∂àÂ§±„ÄÇËøôÂÆ∂ÁßëÊäÄÂ∑®Â§¥‰ªçÁÑ∂ÊéßÂà∂ÁùÄË∂ÖËøá90%ÁöÑÊêúÁ¥¢Â∏ÇÂú∫„ÄÇ‰ªñ‰ª¨Â∑≤ÁªèÂú®Ëøô‰∏™È¢ÜÂüüÂ•ãÊñó‰∫ÜÊï∞ÂçÅÂπ¥ÔºåÊêúÁ¥¢ÁÆóÊ≥ï‰πüÂú®‰∏çÊñ≠ÊºîÂèò„ÄÇ\n\nÁÑ∂ËÄåÔºåÈöèÁùÄÂÉèSearchGPTËøôÊ†∑ÁöÑAIÊêúÁ¥¢ÂºïÊìéÈÄêÊ∏êÂ¥≠Èú≤Â§¥ËßíÔºåË∞∑Ê≠åÈù¢‰∏¥ÁùÄÊèêÂçáËá™Ë∫´Á´û‰∫âÂäõÁöÑÂéãÂäõ„ÄÇOpenAI‰∏éÂá∫ÁâàÂïÜÂêà‰Ωú‰ª•Ëé∑ÂèñÂèØÈù†Êù•Ê∫êÁöÑ‰∏æÂä®ÊòØ‰∏Ä‰∏™ÊòéÊô∫ÁöÑÁ≠ñÁï•ÔºåÂèØËÉΩ‰ºöÂâäÂº±Ë∞∑Ê≠åÁöÑ‰∏ªÂØºÂú∞‰Ωç„ÄÇ\n\nËøôÁßçÂØπÈ™åËØÅÁªìÊûúÁöÑÂÖ≥Ê≥®ÊÑèÂë≥ÁùÄÔºåÂΩì‰Ω†‰ΩøÁî®SearchGPTÊó∂Ôºå‰Ω†‰∏çÂ§™ÂèØËÉΩÈÅáÂà∞ËôöÂÅáÁ≠îÊ°à‚Äî‚ÄîËøôÊòØËøáÂéªAIÈ©±Âä®Â∑•ÂÖ∑ÊâÄÈù¢‰∏¥ÁöÑÊåëÊàò„ÄÇ\n\nÊ≠§Â§ñÔºåË∞∑Ê≠å‰ªçÁÑ∂ÊòØÂ§ßÂ§öÊï∞‰∫∫ÁöÑÈªòËÆ§ÈÄâÊã©„ÄÇÂÆÉÁöÑ‰ºòÂäøÂú®‰∫éÊó†Â§Ñ‰∏çÂú®‚Äî‚Äî‰ªé‰Ω†ÊâãÊú∫ÁöÑÊµèËßàÂô®Âà∞Êô∫ËÉΩÈü≥ÁÆ±„ÄÇSearchGPT‰ªçÂ§Ñ‰∫éÊó©ÊúüÈò∂ÊÆµÔºåÈúÄË¶ÅÊó∂Èó¥Êù•Ëé∑ÂæóÁî®Êà∑ÁöÑ‰ø°‰ªª„ÄÇ\n\n## SearchGPT ËøòÊú™ËææÂà∞\n\nÊàëÂú®ËøáÂéªÂá†‰∏™Â∞èÊó∂ÈáåÊµãËØï‰∫Ü SearchGPTÔºå‰ª•‰∏ãÊòØÊàëÁöÑ‰∏Ä‰∫õËßÇÂØüÔºö\n\n* **Á≠îÊ°àË¥®ÈáèÔºö** ‰∏Ä‰∏™‰∏ªË¶ÅÁöÑÁº∫ÁÇπÊòØ SearchGPT ÁöÑÁ≠îÊ°àË¥®Èáè‰∏é Perplexity Pro ÁöÑÊ∑±Â∫¶ÊàñÁ≤æÁ°ÆÂ∫¶‰∏çÂ§™ÂåπÈÖç„ÄÇÂ∞ΩÁÆ°ÂÆÉ‰∏é Perplexity ÁöÑÂü∫Á°ÄÁâàÊú¨Áõ∏ÂΩìÔºå‰ΩÜ‰æùËµñ‰∫éÂÆÉËøõË°åÊõ¥Â§çÊùÇÊàñÁªÜËá¥Êü•ËØ¢ÁöÑÁî®Êà∑‰ºöÊ≥®ÊÑèÂà∞Â∑ÆÂºÇ„ÄÇ\n* **ÂìçÂ∫îÁºìÊÖ¢Ôºö** Âè¶‰∏Ä‰∏™ÁóõÁÇπÊòØÈÄüÂ∫¶„ÄÇÂú®‰ΩøÁî® SearchGPT Êó∂ÔºåÂ§ÑÁêÜÊü•ËØ¢Âπ∂ËøîÂõûÁ≠îÊ°àÊâÄÈúÄÁöÑÊó∂Èó¥ÂèØËÉΩÊòæÂæóÊûÅÂÖ∂ÁºìÊÖ¢„ÄÇËøôÁßçÂª∂ËøüÊâìÊñ≠‰∫Ü‰∫íÂä®ÁöÑÊµÅÁïÖÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®‰Ω†Ê∑±ÂÖ•Êé¢ËÆ®Êüê‰∏™‰∏ªÈ¢òÊó∂„ÄÇ\n* **Áº∫‰πè‰∏ä‰∏ãÊñáÁêÜËß£Ôºö** Âú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÂÆÉÊú™ËÉΩËØÜÂà´ÂØπËØùÁöÑËøûÁª≠ÊÄß„ÄÇÂ¶ÇÊûú‰Ω†ÊèêÂá∫ÂêéÁª≠ÈóÆÈ¢òÔºåÊ®°ÂûãÂæÄÂæÄÂ∞ÜÂÖ∂ËßÜ‰∏∫‰∏Ä‰∏™Êñ∞ÁöÑÁã¨Á´ãÈóÆÈ¢òÔºåËÄå‰∏çÊòØÁêÜËß£‰∏∫‰Ω†‰πãÂâçÊü•ËØ¢ÁöÑ‰∏ä‰∏ãÊñá„ÄÇ\n* **Ê≤°ÊúâÂêéÁª≠Âª∫ËÆÆÔºö** ‰∏é Perplexity ‰∏çÂêåÔºåÂêéËÄÖÈÄöÂ∏∏‰ºöÂª∫ËÆÆÂêéÁª≠ÈóÆÈ¢ò‰ª•Â∏ÆÂä©‰Ω†ÁªÜÂåñÊêúÁ¥¢ÔºåSearchGPT Âπ∂‰∏çÊèê‰æõÊ≠§ÂäüËÉΩ„ÄÇËøôÁßçÁº∫‰πèÊåáÂØº‰ΩøÁî®Êà∑‰∏çÂæó‰∏çËá™Ë°åÊÉ≥Âá∫Â¶Ç‰ΩïÊúÄÂ•ΩÂú∞Êé™ËæûÊàñÁº©Â∞èÊü•ËØ¢ËåÉÂõ¥„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vfXxpgENLyenLY2l33PKiw.png)\n\nÂú®‰ΩøÁî®ÊêúÁ¥¢ÂäüËÉΩÊó∂ÔºåÊàëÊ≥®ÊÑèÂà∞Âè¶‰∏Ä‰∏™Â•áÊÄ™ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºöÂ¶ÇÊûúÂ∞ÜËØ≠Ë®ÄÊ®°Âûã‰ªé GPT-4o ÂàáÊç¢Âà∞‚ÄúChatGPT o1-preview‚ÄùÔºåÊêúÁ¥¢ÊåáÁ§∫Âô®‰ªçÁÑ∂Â≠òÂú®Ôºå‰ΩÜÂÆûÈôÖ‰∏äÂπ∂‰∏ç‰ºöÂú®ÁΩë‰∏äÊêúÁ¥¢ÁªìÊûú„ÄÇ\n\nÂÆÉËøîÂõûÁöÑÊòØÂÖ∂È¢ÜÂüüÁü•ËØÜ‰∏≠ÁöÑÁªìÊûúÔºåËøôÂπ∂‰∏çÊòØÁî®Êà∑ÊâÄÊúüÊúõÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YcI-UuEmmFTQPUlO6mjpxA.png)\n\nÊ≠£Á°ÆÁöÑË°å‰∏∫Â∫îËØ•ÊòØÂú®Áî®Êà∑ÂàáÊç¢Âà∞‚ÄúChatGPT o1-preview‚ÄùÂêéÁ¶ÅÁî® *search* ÂäüËÉΩÔºåÂõ†‰∏∫ËØ•Ê®°ÂûãÊ≤°ÊúâËÉΩÂäõÂú®ÁΩë‰∏äÊêúÁ¥¢„ÄÇ\n\n## ÊúÄÂêéÁöÑÊÄùËÄÉ\n\nÊàëÂæàÈ´òÂÖ¥OpenAIÁªà‰∫éÊé®Âá∫‰∫ÜSearchGPT„ÄÇËá™‰ªé‰ªñ‰ª¨Âú®2024Âπ¥7ÊúàÂÆ£Â∏ÉËøô‰∏ÄÁÇπ‰ª•Êù•ÔºåÊàëÂ∞±‰∏ÄÁõ¥ÊÉ≥ÊµãËØïÂÆÉ„ÄÇ\n\nÂú®ÁõÆÂâçÁöÑÁä∂ÊÄÅ‰∏ãÔºåSearchGPTÊòØOpenAIËøàÂÖ•AIÈ©±Âä®ÊêúÁ¥¢‰∏ñÁïåÁöÑËâØÂ•ΩÁ¨¨‰∏ÄÊ≠•Ôºå‰ΩÜÂÆÉËøò‰∏çÂ§üÊàêÁÜüÔºåÊó†Ê≥ïÊàê‰∏∫‰ªª‰Ωï‰∫∫Â§ÑÁêÜÂ§çÊùÇÂÆûÊó∂Êü•ËØ¢ÁöÑÈ¶ñÈÄâÂ∑•ÂÖ∑„ÄÇ\n\nÂáÜÁ°ÆÊÄß„ÄÅÈÄüÂ∫¶ÂíåÂ§ÑÁêÜÂØπËØù‰∏ä‰∏ãÊñáÁöÑËÉΩÂäõËøò‰∏çÂ§ü„ÄÇÁõÆÂâçÔºåÂ¶ÇÊûúÊÇ®ÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑËßÅËß£ÊàñÊõ¥Âø´ÁöÑÁªìÊûúÔºåÂÉèPerplexity ProÊàñGoogleËøôÊ†∑ÁöÑÂ∑•ÂÖ∑‰ªçÁÑ∂ÊòØÊõ¥Â•ΩÁöÑÈÄâÊã©„ÄÇ\n\nËøõ‰∏ÄÊ≠•ÈòÖËØªÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5ejBBgbZaE8pGmpW.png)\n\nÊú¨ÊñáÂèëÂ∏ÉÂú®[Generative AI](https://generativeai.pub/)„ÄÇËØ∑Âú®[LinkedIn](https://www.linkedin.com/company/generative-ai-publication)‰∏ä‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥®[Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•Ëé∑ÂèñÊúÄÊñ∞ÁöÑAIÊïÖ‰∫ã„ÄÇ\n\nËÆ¢ÈòÖÊàë‰ª¨ÁöÑ[Êñ∞ÈóªÈÄöËÆØ](https://www.generativeaipub.com/)Âíå[YouTube](https://www.youtube.com/@generativeaipub)È¢ëÈÅìÔºå‰ª•Ëé∑ÂèñÊúâÂÖ≥ÁîüÊàêAIÁöÑÊúÄÊñ∞Êñ∞ÈóªÂíåÊõ¥Êñ∞„ÄÇËÆ©Êàë‰ª¨‰∏ÄËµ∑Â°ëÈÄ†AIÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*TnRFuKk-2Dj_KCAP.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/openai-searchgpt-chatgpt-with-internet-and-browsing-tools-023ddca7cb44","frontmatter":{"title":"OpenAI SearchGPTÔºöÂ∏¶Êúâ‰∫íËÅîÁΩëÂíåÊµèËßàÂ∑•ÂÖ∑ÁöÑChatGPT","meta_title":"OpenAI SearchGPTÔºöÂ∏¶Êúâ‰∫íËÅîÁΩëÂíåÊµèËßàÂ∑•ÂÖ∑ÁöÑChatGPT","description":"Perplexity Âíå Google ÊêúÁ¥¢ÁöÑÊõ¥Â•ΩÊõø‰ª£ÊñπÊ°à","date":"2024-11-08T00:28:30.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*N_EtjjOxkx6QsKRLx5f_cQ.png","categories":["Technology/Web","Data Science","SearchGPT"],"author":"Rifx.Online","tags":["SearchGPT","filtering","citations","recommendations","customization"],"draft":false,"slug":"blog/openai-searchgpt-chatgpt-with-internet-and-browsing-tools-023ddca7cb44"},"content":"\n\n\n### ‰∏Ä‰∏™Êõ¥Â•ΩÁöÑÊõø‰ª£ÊñπÊ°àÔºöPerplexity Âíå Google ÊêúÁ¥¢\n\n\n\nÂ§áÂèóÊúüÂæÖÁöÑ OpenAI ‰∫ßÂìÅ SearchGPT Êò®ÊôöÂèëÂ∏ÉÔºåÊã•Êúâ‰∏Ä‰∫õÈáçÂ§ßÂäüËÉΩÔºå‰ΩøÂÖ∂Âú®Á´û‰∫âÂØπÊâã Perplexity ‰πã‰∏äÊõ¥Ëøõ‰∏ÄÊ≠•„ÄÇ\n\nÂ¶Ç OpenAI ÊâÄÂÆ£Â∏ÉÁöÑÔºåSearchGPT ‰∏ç‰ªÖ‰ªÖÊòØÂ∏¶Êúâ‰∫íËÅîÁΩëÁöÑ ChatGPT„ÄÇ\n\nÂÆÉÊú¨Ë∫´Â∞±ÊòØ‰∏Ä‰∏™ AI ÁΩëÁªúÊµèËßàÂô®„ÄÇ\n\nË∞àÂà∞‰∏Ä‰∫õÂÖ≥ÈîÆÂäüËÉΩÔºö\n\n* **È´òÁ∫ßËøáÊª§**Ôºö‰∏∫ÁâπÂÆöÊó•Êúü„ÄÅÊù•Ê∫êÊàñÂÜÖÂÆπÁ±ªÂûãÔºà‰æãÂ¶ÇÔºå‰ªÖÈôêÂêåË°åËØÑÂÆ°ÊñáÁ´†„ÄÅÊîøÂ∫úÁΩëÁ´ôÁ≠âÔºâËÆæÁΩÆËøáÊª§Âô®„ÄÇ\n* **‰∏ä‰∏ãÊñáÊÑüÁü•ÊëòË¶Å**ÔºöÁîüÊàêÈíàÂØπÁâπÂÆöÈ¢ÜÂüüÔºàÂ¶ÇÂåªÂ≠¶ÊàñÈáëËûçÔºâÁöÑÊëòË¶Å„ÄÅÂÖ≥ÈîÆË¶ÅÁÇπÊàñÊ¥ûÂØü„ÄÇ\n* **ÂºïÁî®ÁîüÊàê**ÔºöËá™Âä®Ê†ºÂºèÂåñÂπ∂Êèê‰æõÂ≠¶ÊúØÈ£éÊ†ºÁöÑÂºïÁî®ÔºàAPA„ÄÅMLAÔºâ„ÄÇ\n* **Â§öÊ≠•È™§Êü•ËØ¢**ÔºöÂú®‰∏ÄÊ¨°ÊêúÁ¥¢‰∏≠Â§ÑÁêÜÂ§çÊùÇÁöÑÂàÜÂ±ÇÈóÆÈ¢òÔºåË∑®Â§ö‰∏™Êù•Ê∫ê„ÄÇ\n* **Êï∞ÊçÆÂàÜÊûêÈõÜÊàê**ÔºöÁõ¥Êé•ÊèêÂèñÂíåÂàÜÊûêÊï∞ÊçÆ‰ª•Ëé∑ÂèñÊ¥ûÂØüÔºà‰æãÂ¶ÇÔºåË∂ãÂäøÂàÜÊûêÔºâ„ÄÇSearchGPT ÂèØ‰ª•ËøûÊé•Âà∞‰∏ì‰∏öÊï∞ÊçÆÂ∫ìÔºåÂÖÅËÆ∏ËÆøÈóÆÁâπÂÆöÈ¢ÜÂüüÔºàÂ¶ÇÂåªÂ≠¶ÊúüÂàä„ÄÅÊ≥ïÂæãÊ°à‰æãÊï∞ÊçÆÂ∫ìÊàñ‰∏ìÊúâÂïÜ‰∏öÂàÜÊûêÔºâ„ÄÇ\n* **‰∏™ÊÄßÂåñÊé®Ëçê**ÔºöÊ†πÊçÆÊÇ®ÁöÑÊêúÁ¥¢ÂéÜÂè≤Âª∫ËÆÆÁõ∏ÂÖ≥Êù•Ê∫ê„ÄÅÊñáÁ´†ÊàñÊõ¥Êñ∞„ÄÇËøôÂåÖÊã¨ **È¢ÑËÆæÊ®°ÊùøÊàñËßíËâ≤**Ôºö‰æãÂ¶ÇÔºåÂèØ‰ª•ËÆæÁΩÆ‰∏Ä‰∏™‰ª•Á†îÁ©∂‰∏∫ÈáçÁÇπÁöÑ‚ÄúSearchGPT‚Äù‰ª•Ê£ÄÁ¥¢ÁßëÂ≠¶Êï∞ÊçÆÂπ∂Áõ¥Êé•Êèê‰æõÂ≠¶ÊúØÂºïÁî®„ÄÇ\n\n### ChatGPT‰πãÂâçÊó†Ê≥ïËÆøÈóÆ‰∫íËÅîÁΩëÂêóÔºü\n\nÂÆÉÂèØ‰ª•ÔºàÂØπ‰∫éÈ´òÁ∫ß‰ºöÂëòÔºâ„ÄÇ‰ΩÜÁé∞Âú®ÔºåËøô‰∫õÂäüËÉΩÊõ¥Âä†ÂÖàËøõ„ÄÇ‰∏∫‰∫ÜÊü•Áúã‰∏ÄËà¨ÁΩëÈ°µÊêúÁ¥¢‰∏éSearchGPTÁöÑ‰∏çÂêåÔºåÊàëÂ∞ùËØïËÆ©ChatGPTÔºàÂÖçË¥πÁâàÔºâËá™Â∑±ÊêúÁ¥¢‰∏Ä‰∏™Êü•ËØ¢Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ORjGLDBqKDWiPANHlxSdqw.png)\n\nÁÑ∂ÂêéÔºåÊàëËØ¢ÈóÆËøô‰∏™ÊêúÁ¥¢ÊòØÂ¶Ç‰ΩïËøõË°åÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NlzDed3nHdJ636aLt75DCg.png)\n\nÊé•‰∏ãÊù•Ôºå\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eeDPQHQA62yaMK_KkSL0kQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ZcsmVgau0SaavN01yHbdKw.png)\n\nÊâÄ‰ª•ÔºåÊ≠£Â¶Ç‰Ω†ÊâÄÁúãÂà∞ÁöÑÔºåSearchGPT‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁΩëÈ°µÊµèËßàÂ∑•ÂÖ∑ÔºåËÄåÊòØÊõ¥Â§ö„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåOpenAIÂ∑≤Â∞ÜSearchGPTÊèê‰æõÁªôProÁî®Êà∑ÔºåÂπ∂‰∏î‰ªÖÈôê‰∫éÁ≠âÂæÖÂêçÂçïÁî®Êà∑„ÄÇÂ¶ÇÊûú‰Ω†ÊúâËÆøÈóÆÊùÉÈôêÔºå‰Ω†‰∏ÄÂÆöÊò®Â§©Êî∂Âà∞‰∫ÜËøôÂ∞ÅÈÇÆ‰ª∂\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WfO0Xl4VQwRxNNkC1GQpOw.png)\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∫õÊù•Ëá™SearchGPTÁöÑÂ±èÂπïÊà™Âõæ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8bbGpwbsRzo6xQhNDPb3Jw.png)\n\nÊ≠£Â¶Ç‰Ω†ÊâÄÁúãÂà∞ÁöÑÔºåÂÆÉÂú®ÊêúÁ¥¢Êó∂Êèê‰æõ‰∫ÜÁÉ≠Èó®ËØùÈ¢ò‰Ωú‰∏∫Âª∫ËÆÆÔºåÁ±ª‰ºº‰∫éÁΩëÈ°µÊµèËßàÂô®„ÄÇ\n\nÂ∞ùËØïÊü•Áúã‰ªäÂ§©ÁöÑÂ§©Ê∞î\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*gbtr-QFQw4BnhqrWPvH4RQ.png)\n\nÁîöËá≥ÂèØ‰ª•ÈôêÂà∂‰ªÖÊ£ÄÊü•ÁâπÂÆöÁΩëÁ´ôÔºå‰æãÂ¶Ç‚Äú‰ªÖÂºïÁî®ÊîøÂ∫úÁΩëÁ´ô‚Äù\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eq_Xf4JkD4XV85KE5376VA.png)\n\nÊâÄÊúâÂºïÁî®ÈÉΩÂèØ‰ª•Âú®Â∫ïÈÉ®‰∏ÄËµ∑Êü•Áúã‰Ω†ÁöÑÁªìÊûú\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wUTEae5yYh_j-oaq6HyP9Q.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Quruyw07__p3qoJ_KhmHAA.png)\n\n## SearchGPT vs Perplexity. Âì™‰∏™Êõ¥Â•ΩÔºü\n\nËøôÊòØ‰∏Ä‰∏™ÂæàÈöæÂõûÁ≠îÁöÑÈóÆÈ¢òÔºåËá≥Â∞ëÁõÆÂâçÊòØËøôÊ†∑„ÄÇÊúâÂá†ÁÇπÂÄºÂæóÂº∫Ë∞ÉÔºö\n\n1. Perplexity ÊòØÂÖçË¥πÁöÑÔºåËÄå SearchGPT ‰∏çÊòØÔºÅ\n2. SearchGPT Êõ¥Âø´„ÄÇ‰ΩÜÊàëËÆ§‰∏∫ËøôÊòØÂõ†‰∏∫ÁõÆÂâçÁöÑÊµÅÈáèËæÉÂ∞ë„ÄÇ\n3. Perplexity Êõ¥ÁÆÄÂçïÔºåÂπ∂‰∏îÂÖ∑ÊúâÊó©ÊúüËøõÂÖ•Â∏ÇÂú∫ÁöÑ‰ºòÂäø„ÄÇ\n4. Perplexity Âú®Ëøô‰∏™È¢ÜÂüüÂ≠òÂú®Â∑≤‰πÖÔºåÁõ∏ÊØî‰πã‰∏ãÊõ¥ÂèØÈù†„ÄÇ\n5. SearchGPT Êèê‰æõÊõ¥Â§öÁöÑËá™ÂÆö‰πâÈÄâÈ°πÔºå‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™‰∏é‰∫íËÅîÁΩëËøûÊé•ÁöÑ LLM„ÄÇ\n\nËÄÅÂÆûËØ¥ÔºåÊàë‰∏ÄÁõ¥ÊîØÊåÅÂÖçË¥πÁöÑ‰∏úË•øÔºåÂõ†Ê≠§‰ªª‰ΩïÊó∂ÂÄôÊàëÈÉΩ‰ºöÈÄâÊã© Perplexity„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåËÄÉËôëÂà∞ SearchGPT ÁöÑÂø´ÈÄüÂìçÂ∫îÔºåËøô‰∏™Â∑•ÂÖ∑Áõ∏ÂΩì‰∏çÈîôÔºåÂÄºÂæóÂ∞ùËØï„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/openais-leaked-gpt2-model-has-everyone-stunned-6337904c2ecf","frontmatter":{"title":"OpenAI‚ÄòÊ≥ÑÈú≤‚ÄôÁöÑ GPT2 Ê®°ÂûãËÆ©ÊâÄÊúâ‰∫∫ÈúáÊÉä„ÄÇ","meta_title":"OpenAI‚ÄòÊ≥ÑÈú≤‚ÄôÁöÑ GPT2 Ê®°ÂûãËÆ©ÊâÄÊúâ‰∫∫ÈúáÊÉä„ÄÇ","description":"ÊïÖÊÑèÊ≥ÑÂØÜÔºü","date":"2024-11-01T04:07:40.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-G0yfSjGPdNw02NZ","categories":["Chatbots","Generative AI","Natural Language Processing"],"author":"Rifx.Online","tags":["GPT-2","Chatbot","Inference","JSON","AlphaGo"],"draft":false,"slug":"blog/openais-leaked-gpt2-model-has-everyone-stunned-6337904c2ecf"},"content":"\n\n\n### ÊïÖÊÑèÊ≥ÑÊºèÔºü\n\n\n\nOpenAI ÂØπ‰∫∫Â∑•Êô∫ËÉΩË°å‰∏öÁöÑÂΩ±Âìç‰∏çÂÆπÂ∞èËßë„ÄÇÊØè‰∏Ä‰∏™Âä®‰ΩúÊàñÂÜ≥ÂÆöÈÉΩ‰ºöËá™Âä®Êàê‰∏∫Â§¥Êù°‚Ä¶‚Ä¶Âç≥‰Ωø‰ªñ‰ª¨Âπ∂Ê≤°ÊúâÁúüÊ≠£ÂÆ£Â∏É‰ªÄ‰πà„ÄÇ\n\nÂá†Â§©ÂâçÔºå‰∏Ä‰∏™Êàë‰ª¨ËÆ∏Â§ö‰∫∫ÊõæËØïÁî®Ëøá‰ΩÜÂ∑≤Ë¢´Âà†Èô§ÁöÑÊ®°ÂûãËÆ©Êï¥‰∏™‰∫∫Â∑•Êô∫ËÉΩË°å‰∏öÁùÄËø∑„ÄÇËøô‰∏™Âêç‰∏∫‚Äúgpt2-chatbot‚ÄùÁöÑÊ®°ÂûãÂú® [lmsys.org](https://chat.lmsys.org/) ÁöÑ‚ÄúÁõ¥Êé•ËÅäÂ§©‚ÄùÂäüËÉΩ‰∏≠ÂèØ‰ª•‰ΩøÁî®‰∫ÜÂá†Â§©„ÄÇ\n\n*‰ΩÜ‰∏∫‰ªÄ‰πàËøô‰πàÂ§öÂñßÂö£Ôºü*\n\nÂõ†‰∏∫Ëøô‰∏™Ê®°Âûã‰∏éÊàë‰ª¨ËßÅËøáÁöÑ‰ªª‰Ωï‰∏úË•øÈÉΩ‰∏çÂêå„ÄÇ**ÂÆÉÂ§Ñ‰∫é‰∏Ä‰∏™ÂÆåÂÖ®‰∏çÂêåÁöÑÂ±ÇÊ¨°„ÄÇ**\n\nÂõ†Ê≠§ÔºåËÆ∏Â§ö‰∫∫ËÆ§‰∏∫ÂÆÉÊòØ **ChatGPT-4.5** ÊàñÁîöËá≥ **GPT-5** ÁöÑÈùûÂÆòÊñπÈ¢ÑÂëä„ÄÇÊõ¥‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÊòØÔºå‰ΩøÁî®Êï∞Â≠ó‚Äú2‚Äù‰Ωú‰∏∫‰ø°Âè∑ÔºåË°®Êòé **Êñ∞‰∏Ä‰ª£ÈïøÊé®ÁêÜÊ®°ÂûãÁöÑ GPT Ê≠£Âú®ÈÄºËøë**„ÄÇ\n\nÁîöËá≥ OpenAI ÁöÑ CEO Sam Altman ‰πüÂøç‰∏ç‰ΩèÊâøËÆ§ÂÆÉÁöÑÂ≠òÂú®ÔºåÂπ∂Âú®ËøáÁ®ã‰∏≠Ë∞É‰æÉÊàë‰ª¨Ôºö\n\n\n\n\nÈÇ£‰πàÔºå*Ëøô‰∏™Ê®°ÂûãÂà∞Â∫ïÊúâÂ§öÂ•ΩÔºåÂÆÉÁ©∂Á´üÊòØ‰ªÄ‰πàÔºü*\n\n\n> ‰Ω†ÂèØËÉΩÂ∑≤ÁªèÂéåÂÄ¶‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÈÄöËÆØÁÆÄÊä•Ë∞àËÆ∫Êüê‰∏™‰∫ãÊÉÖÊòØÂ¶Ç‰Ωï‚ÄúÂàöÂàö‚ÄùÂèëÁîüÁöÑ„ÄÇËøô‰∫õÈÄöËÆØÁÆÄÊä•Â±ÇÂá∫‰∏çÁ©∑ÔºåÂõ†‰∏∫Á≤óÁï•Âú∞Ë∞àËÆ∫Â∑≤ÁªèÂèëÁîüÁöÑ‰∫ã‰ª∂Âíå‰∫ãÊÉÖÊòØÂÆπÊòìÁöÑÔºå**‰ΩÜÊèê‰æõÁöÑ‰ª∑ÂÄºÊúâÈôêÔºåÁÇí‰ΩúÂç¥Ë¢´Â§∏Â§ß„ÄÇ**\n\n\n> ÁÑ∂ËÄåÔºåË∞àËÆ∫ **Â∞Ü** ‰ºöÂèëÁîüÁöÑ‰∫ãÊÉÖÁöÑÈÄöËÆØÁÆÄÊä•Âç¥ÊòØÁΩïËßÅÁöÑ„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥Âú®Âà´‰∫∫‰πãÂâçËé∑ÂæóÊòì‰∫éÁêÜËß£ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊú™Êù•Ê¥ûÂØüÔºå**TheTechOasis** ÈÄöËÆØÁÆÄÊä•ÂèØËÉΩÈùûÂ∏∏ÈÄÇÂêà‰Ω†„ÄÇ\n\n\n> üèùÔ∏èüèùÔ∏è ‰ªäÂ§©Â∞±ËÆ¢ÈòÖÂêßÔºö\n\n## Êú™Êù•ÁöÑÈ¢ÑÂëä\n\nÈöèÁùÄÊØè‰∏ÄÂ§©ÁöÑËøáÂéªÔºåOpenAIÁöÑ‰∏ã‰∏Ä‰∏™Ê®°ÂûãÊòæÁÑ∂Â∞ÜÂú®Êé®ÁêÜÂíåÂ§çÊùÇÈóÆÈ¢òËß£ÂÜ≥ÊñπÈù¢ÂÆûÁé∞È£ûË∑É„ÄÇ\n\n‰∏∫‰∫ÜËØÅÊòéËøô‰∏™Á•ûÁßòÁöÑÊñ∞Ê®°ÂûãÂèØËÉΩÂ∞±ÊòØÂÆÉÔºåËøôÈáåÊúâÂá†‰∏™‰æãÂ≠êÂ±ïÁ§∫Ëøô‰∏™Á•ûÁßòÊ®°ÂûãÁöÑÂº∫Â§ßÔºåÂèØËÉΩË°®ÊòéËøôËâòËàπÂ∑≤ÁªèÂú®ÈÇ£‰∏™Ê∏ØÂè£ÂÅúÈù†Ôºö\n\n> ‰ª•‰∏ãÊâÄÊúâÁ§∫‰æãË¢´ËÆ§‰∏∫ÊòØ**ÂΩìÂâçÊúÄÂÖàËøõÊ®°Âûã**ÁöÑ**Âõ∞ÈöæÊàñÂÆåÂÖ®‰∏çÂèØËÉΩ**ÁöÑ„ÄÇ\n\nÈ¶ñÂÖàÔºåÂÆÉÂú®Èõ∂-shotÊ®°Âºè‰∏ãËß£ÂÜ≥‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶Â••ÊûóÂåπÂÖãÈóÆÈ¢òÔºàÊ≤°ÊúâÊèê‰æõËæÖÂä©Á§∫‰æãÊù•ÊîØÊåÅËß£ÂÜ≥ÊñπÊ°àÔºâÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*oNPg_hTGc0OP90n9)\n\nÊàëÁîöËá≥Êó†Ê≥ïÂºÄÂßãËß£Èáä‰πãÂâçÁöÑ‰æãÂ≠êÊúâÂ§öÁñØÁãÇÔºå‰ªéÂΩìÂâçÊúÄÂÖàËøõÁöÑÊ®°Âûã‰∏≠ÂæóÂà∞ËøôÊ†∑ÁöÑÁ≠îÊ°àÁªùÂØπÊòØ‰∏çÂèØËÉΩÁöÑ„ÄÇ\n\n[ÂÆÉÂú®Ëß£ÊûêJSONÊñπÈù¢‰πüÁªùÂØπÂá∫Ëâ≤](https://twitter.com/skirano/status/1785035706173214888)ÔºåËøôÊòØLLM‰∏éAPIÂèäÂÖ∂‰ªñÂü∫‰∫éÁΩëÁªúÂ∑•ÂÖ∑ÈõÜÊàêÁöÑÂü∫Êú¨ÊäÄËÉΩ„ÄÇ\n\nÊ≠§Â§ñÔºåÂÆÉÂú®Â§çÊùÇÁªòÂõæ‰ªªÂä°‰∏≠ÂÆåÂÖ®ÂéãÂÄí‰∫ÜGPT-4Ôºå‰æãÂ¶Ç[Ê†πÊçÆ‰ª£Á†ÅÁªòÂà∂SVGÊñá‰ª∂](https://twitter.com/decentricity/status/1785049191003361778)Êàñ**‰ΩøÁî®ASCII‰ª£Á†ÅÁªòÂà∂Áã¨ËßíÂÖΩÔºàÂ¶Ç‰∏ãÔºâ**ÔºåÂú®Ëøô‰∏™ËøáÁ®ã‰∏≠ÁæûËæ±‰∫Ü**Claude 3 Opus**ÔºåÂΩìÂâçÁöÑÊúÄÂÖàËøõÊ®°ÂûãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5A0EcRU91ZYAwVAc)\n\nÊ≠§Â§ñÔºåÂ∞ΩÁÆ°ËøôÂæàÂèØËÉΩÊòØ‰∏ÄÊ¨°ÂπªËßâÔºå**Ê®°ÂûãÂêëÊàëÂ£∞Áß∞ÂÆÉÊòØÁî±OpenAIËÆ≠ÁªÉÁöÑÔºåÂπ∂Âü∫‰∫éGPT-4Âèò‰Ωì„ÄÇ**\n\nÂΩìÁÑ∂ÔºåÂú®Â¶ÇÊ≠§Âº∫Â§ßÁöÑÊºîÁ§∫‰πãÂêéÔºå**ËÆ∏Â§ö‰∫∫Âª∫ËÆÆ‚Äúgpt2-chatbot‚ÄùÁîöËá≥ÂèØËÉΩÊòØËëóÂêçÁöÑQ\\*Ê®°Âûã**„ÄÇ\n\n‰ΩÜ‰∏éÂÖ∂ÁÆÄÂçïÂú∞Â±àÊúç‰∫é‰∫∫‰ª¨Â£∞Áß∞ÁöÑ‰∏çÂêåÂ•áÂπªÈÄâÈ°πÔºå‰∏çÂ¶ÇÈááÂèñÊõ¥ÁêÜÊÄßÁöÑÊñπÂºèÔºåÁúãÁúãOpenAIËá™Â∑±Âú®Âá†‰∏™ÊúàÔºàÁîöËá≥Âá†Âπ¥ÔºâÈáåÈÄöËøá‰ªñ‰ª¨ÁöÑÁ†îÁ©∂ÊâÄÊöóÁ§∫ÁöÑÂÜÖÂÆπ„ÄÇ\n\n## ÈïøÊé®ÁêÜÁöÑÂäõÈáè\n\nÂá†‰∏™ÊúàÊù•ÔºåÂÉè [Demis Hassabis](https://www.youtube.com/watch?v=eqXfhejDeqA&t=2s) Êàñ [Andrej Karpathy](https://youtu.be/c3b-JASoPi0?si=fZWoSpLuSmua8YMR&t=1481) ËøôÊ†∑ÁöÑÈ¢ÜÂüü‰∏ìÂÆ∂ËÆ®ËÆ∫‰∫Ü‰ªÖÈù† LLMs ÊòØ‰∏çÂ§üÁöÑÔºåÊàë‰ª¨ÈúÄË¶Å‚ÄúÂÖ∂‰ªñ‰∏úË•ø‚ÄùÊù•ÁúüÊ≠£Â∞ÜÂÆÉ‰ª¨ÊèêÂçáÂà∞‰∏Ä‰∏™Êñ∞ÁöÑÊ∞¥Âπ≥„ÄÇ\n\nÂú®Ëøô‰∏§ÁßçÊÉÖÂÜµ‰∏ãÔºå‰ªñ‰ª¨ÊèêÂà∞ÂÆûÁé∞Áõ∏ÂΩì‰∫é‚ÄúAlphaGo ‰ΩÜÂú® LLMs ‰∏≠‚ÄùÔºåËøôÈó¥Êé•ÊåáÁöÑÊòØÔºö\n\n* **Ëá™ÊàëÊèêÂçá** Âíå\n* **ÊµãËØïÊó∂ËÆ°ÁÆó** LLMs\n\n*‰ΩÜ‰ªñ‰ª¨ËøôÊòØ‰ªÄ‰πàÊÑèÊÄùÂë¢Ôºü*\n\n### ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂ∑®Â§ßÈ£ûË∑É\n\nAlphaGo ÊòØ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂéÜÂè≤„ÄÇÂÆÉÊòØÁ¨¨‰∏Ä‰∏™Âú®Âõ¥Ê£ãËøô‰∏ÄÈü©ÂõΩÊ£ãÁ±ªÊ∏∏Êàè‰∏≠ÊØ´Êó†ÁñëÈóÆÂú∞Ë∂ÖË∂ä‰∫∫Á±ªÂÆûÂäõÁöÑÊ®°Âûã„ÄÇ\n\nÂÆÉ‰ΩøÁî®‰∫Ü **Monte Carlo Tree Search**Ôºå‰∏ÄÁßçÊêúÁ¥¢ÁÆóÊ≥ïÔºåÊù•Êé¢Á¥¢Ê∏∏Êàè‰∏≠‰ªª‰ΩïÁªôÂÆöÊ≠•È™§ÁöÑÂèØËÉΩËµ∞Ê≥ïÔºåËÉΩÂ§üË∂ÖË∂äÂΩìÂâçÁöÑÂä®‰ΩúÂπ∂È¢ÑÊµãÂØπÊâãÁöÑË°åÂä®„ÄÇ\n\n> ‰Ω†‰ª¨‰∏≠ÁöÑ‰∏Ä‰∫õ‰∫∫ÂèØËÉΩËøòËÆ∞Âæó **Deep Blue**ÔºåÈÇ£Âè∞Âú®1997Âπ¥‰∏éÂä†Èáå¬∑Âç°ÊñØÂ∏ïÁΩóÂ§´ÁöÑÁ≥ªÂàóËµõ‰∏≠Á¨¨‰∫åÂ±ÄÂãâÂº∫ÊàòËÉú‰ªñÁöÑÂõΩÈôÖË±°Ê£ãÊú∫Âô®ÔºåÂú®Á¨¨‰∏ÄÂ±Ä‰∏≠ËæìÊéâ‰∫ÜÊØîËµõ„ÄÇ\n\n> ÁÑ∂ËÄåÔºåÂ∞ΩÁÆ° Deep Blue ÂèØ‰ª•Ë¢´ÂáªË¥•Ôºå‰ΩÜ AlphaGo ÊòØÊó†ÊïåÁöÑ„ÄÇ\n\n*‰ΩÜËøôÊòØÊÄé‰πàÂÅöÂà∞ÁöÑÔºü*\n\n### Ëá™ÊàëÊèêÂçá‰ª•ËææÂà∞Ë∂Ö‰∫∫Ê∞¥Âπ≥\n\n‰ΩøAlphaGoÂçìË∂äÁöÑÂÖ≥ÈîÆÂõ†Á¥†Âú®‰∫éÂÆÉÁöÑËÆ≠ÁªÉÊñπÂºèÔºå**ÈÄöËøá‰∏éËá™Ë∫´ÁöÑËæÉÂº±ÁâàÊú¨ÂØπÂºàÊù•ÂàõÂª∫Ëá™ÊàëÊèêÂçáÂæ™ÁéØ„ÄÇ**\n\nÂÆÉÊåÅÁª≠‰∏éËá™Â∑±ÂØπÂºàÔºåÈÄêÊ∏êÂ∞ÜELOÊèêÂçáËá≥3\\.739ÔºåÂá†‰πéËææÂà∞‰∫ÜÂΩì‰ªäÊúÄ‰Ω≥Âõ¥Ê£ãÈÄâÊâãÁöÑÊ∞¥Âπ≥„ÄÇ\n\n> 2017Âπ¥ÔºåÊîπËøõÁâàÁöÑAlphaZeroËææÂà∞‰∫Ü5\\.018ÁöÑELOÔºåÂÆåÂÖ®Ë∂ÖË∂ä‰∫∫Á±ªÔºåÊó†Ê≥ïÂáªË¥•„ÄÇ\n\nÊç¢Âè•ËØùËØ¥ÔºåÊúâ‰∫ÜAlphaGoÔºå‰∫∫Á±ªÈ¶ñÊ¨°ÂÆûÁé∞‰∫Ü‰∏ÄÁßçÈÄöËøáËá™ÊàëÊèêÂçáÊù•ËÆ≠ÁªÉÊ®°ÂûãÁöÑÊñπÊ≥ïÔºå‰ΩøÂÖ∂ËÉΩÂ§üËææÂà∞Ë∂Ö‰∫∫ËÉΩÂäõÔºå**Âõ†‰∏∫ÂÆÉ‰∏çÂÜç‰æùËµñÊ®°‰ªø‰∫∫Á±ªÊù•Â≠¶‰π†„ÄÇ**\n\nÂ¶ÇÊûú‰Ω†Âú®ÊÉ≥ÔºåËøôÂØπLLMsÂπ∂‰∏çÈÄÇÁî®„ÄÇ\n\nÂΩìÂâçÁöÑLLMsÂÆåÂÖ®‰æùËµñ‰∫é‰∫∫Á±ªÊ∞¥Âπ≥ÁöÑË°®Áé∞ÔºåÂõ†‰∏∫ÊâÄÊúâÊï∞ÊçÆÂíåËÆ≠ÁªÉÊú¨Ë¥®‰∏äÈÉΩ‰æùËµñ‰∫é‰∫∫Á±ªÔºà‰ª•Ëá≥‰∫é[ÂØπÈΩêÈò∂ÊÆµ](https://thewhitebox.ai/llms-the-backbones-of-frontier-ai/)‚Äî‚ÄîLLMsË¢´Âª∫Ê®°‰ª•ÊèêÈ´òÂÖ∂ÂÆâÂÖ®Ê∞¥Âπ≥Âπ∂ÈÅøÂÖçÂÜíÁäØÊÄßÂèçÂ∫îÁöÑËÆ≠ÁªÉËøáÁ®ãÁöÑ‰∏ÄÈÉ®ÂàÜÔºå**‰∏•Ê†ºÊâßË°åÊó∂‰ΩøÁî®ÁöÑÊòØ‚Äú‰∫∫Á±ªÂÅèÂ•Ω‚Äù**Ôºâ„ÄÇ\n\n> È°∫‰æøÊèê‰∏Ä‰∏ãÔºå[MetaÊúÄËøëÊèêÂá∫‰∫ÜËá™ÊàëÂ•ñÂä±Ê®°Âûã](https://arxiv.org/pdf/2401.10020v1)ÔºåÂèØ‰ª•ÈÄöËøáËá™Ë∫´ÁöÑÂèçÂ∫îËøõË°åËá™ÊàëÊèêÂçá„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öËøô‰∏™ÂèçÈ¶àÂæ™ÁéØÊòØÂê¶ÁúüÁöÑËÉΩ‰ΩøLLMsË∂ÖË∂ä‰∫∫Á±ª„ÄÇ\n\n‰ΩÜÂ∞ΩÁÆ°‰ªçÁÑ∂ÂæàÈöæÁõ∏‰ø°‚Äúgpt2\\-chatbot‚ÄùÊòØÈÄöËøáËá™ÊàëÊèêÂçáËÆ≠ÁªÉÂá∫Êù•ÁöÑÔºå**Êàë‰ª¨ÊúâÂÖÖÂàÜÁöÑÁêÜÁî±Áõ∏‰ø°ÂÆÉÊòØOpenAIÂ§öÂπ¥Êù•Âä™ÂäõÂ∑•‰ΩúÁöÑÁ¨¨‰∏Ä‰∏™ÊàêÂäüÂÆûÁé∞ÔºöÊµãËØïÊó∂ËÆ°ÁÆó**„ÄÇ\n\n### ÊµãËØïÊó∂ËÆ°ÁÆóÊ®°ÂûãÁöÑÂà∞Êù•\n\nÂ§öÂπ¥Êù•ÔºåOpenAIÁöÑÂá†ÁØáÁ†îÁ©∂ËÆ∫ÊñáÊöóÁ§∫‰∫ÜÂ∞ÜÊ®°ÂûãÂÅèÂêë‚ÄúÈáçÊé®ÁêÜ‚ÄùÁöÑËøô‰∏ÄÊÉ≥Ê≥ï„ÄÇ\n\n‰æãÂ¶ÇÔºåÊó©Âú®2021Âπ¥Ôºå[‰ªñ‰ª¨ÊèêÂá∫‰∫ÜÂú®Êé®ÁêÜÊó∂‰ΩøÁî®‚ÄúÈ™åËØÅËÄÖ‚ÄùÁöÑÊ¶ÇÂøµ](https://arxiv.org/pdf/2110.14168)Ôºå‰ª•ÊîπÂñÑÊ®°ÂûãÂú®Â§ÑÁêÜÊï∞Â≠¶ÈóÆÈ¢òÊó∂ÁöÑÂìçÂ∫î„ÄÇ\n\nËøô‰∏™ÊÉ≥Ê≥ïÊòØËÆ≠ÁªÉ‰∏Ä‰∏™ËæÖÂä©Ê®°ÂûãÔºåÂÆûÊó∂ËØÑ‰º∞Ê®°ÂûãÁªôÂá∫ÁöÑÂ§ö‰∏™ÂìçÂ∫îÔºåÈÄâÊã©ÊúÄ‰Ω≥ÁöÑ‰∏Ä‰∏™ÔºàÁÑ∂ÂêéÊèê‰æõÁªôÁî®Êà∑Ôºâ„ÄÇ\n\nËøô‰∏éÊüêÁßçÊ†ëÊêúÁ¥¢ÁÆóÊ≥ïÁõ∏ÁªìÂêàÔºåÊØîÂ¶ÇAlphaGo‰ΩøÁî®ÁöÑÈÇ£ÁßçÔºåÁªìÂêàGoogle DeepmindÁöÑ[ÊÄùÁª¥Ê†ëÁ†îÁ©∂](https://arxiv.org/pdf/2305.10601)ÁöÑ‰æãÂ≠êÔºåÊúÄÁªàÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™LLMÔºåÂú®ÂõûÁ≠î‰πãÂâçÔºåÊé¢Á¥¢‚ÄúÂèØËÉΩÂìçÂ∫îÁöÑÈ¢ÜÂüü‚ÄùÔºå**‰ªîÁªÜËøáÊª§Âπ∂ÈÄâÊã©ÈÄöÂêëËß£ÂÜ≥ÊñπÊ°àÁöÑÊúÄ‰Ω≥Ë∑ØÂæÑ„ÄÇ**\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pHWwOA66fxpKbl-z)\n\nËøô‰∏™ÊÉ≥Ê≥ïËôΩÁÑ∂Âú®2021Âπ¥Áî±OpenAIÊèêÂá∫Ôºå‰ΩÜÂ¶Ç‰ªäÂ∑≤ÁªèÂèòÂæóÁõ∏ÂΩìÊµÅË°åÔºå[ÂæÆËΩØÂíåË∞∑Ê≠åÁöÑË∑®ÁïåÂêà‰ΩúÁ†îÁ©∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éËÆ≠ÁªÉ‰∏ã‰∏Ä‰ª£È™åËØÅËÄÖ](https://arxiv.org/pdf/2402.06457)ÔºåË∞∑Ê≠åÁîöËá≥ÊàêÂäüÂàõÂª∫‰∫Ü‰∏Ä‰∏™Ê®°ÂûãÔºå[Alphacode](https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf)Ôºå‰ª•ÊûÅÂ§ßÁöÑÊàêÂäüÊâßË°åËøôÁßçÊû∂ÊûÑÔºå**Âú®Á´û‰∫âÁ®ãÂ∫èÂëò‰∏≠ËææÂà∞‰∫Ü85%ÁöÑÁôæÂàÜ‰ΩçÔºåÊàê‰∏∫ÊúÄ‰ºòÁßÄÁöÑ‰∫∫Á±ªÁ®ãÂ∫èÂëò‰πã‰∏Ä„ÄÇ**\n\n*ÈÇ£‰πàÔºå‰∏∫‰ªÄ‰πàËøô‰∏Ä‰ª£Êñ∞ÁöÑLLMÂÖ∑ÊúâÂ¶ÇÊ≠§Â∑®Â§ßÁöÑÊΩúÂäõÔºü*\n\nÂõ†‰∏∫**ÂÆÉ‰ª¨Âú®Ëß£ÂÜ≥ÈóÆÈ¢òÊó∂‰∏é‰∫∫Á±ªÁöÑÊñπÂºèÈùûÂ∏∏Áõ∏‰ºº**ÔºåÈÄöËøáÊúâÊÑèËØÜÂíåÂπøÊ≥õÁöÑÊÄùËÄÉÊù•Ëß£ÂÜ≥ÁâπÂÆö‰ªªÂä°„ÄÇ\n\nÂΩíÊ†πÁªìÂ∫ïÔºåÊää‚ÄúÊêúÁ¥¢+LLM‚ÄùÊ®°ÂûãËßÜ‰∏∫AIÁ≥ªÁªüÔºåÂÆÉ‰ª¨Âú®Ê®°ÂûãÁöÑÂÆûÈôÖËøêË°åÊó∂Èó¥‰∏äÂàÜÈÖç‰∫ÜÊõ¥È´òÁ®ãÂ∫¶ÁöÑËÆ°ÁÆóÔºàÁ±ª‰ºº‰∫é‰∫∫Á±ªÊÄùÁª¥ÔºâÔºåÂõ†Ê≠§ÔºåÂÆÉ‰ª¨‰∏çÂøÖÁ´ãÂç≥ÁåúÊµãÊ≠£Á°ÆÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåËÄåÊòØÁÆÄÂçïÂú∞ËØ¥Ôºå‚ÄúÊúâÊõ¥Â§öÊó∂Èó¥Êù•ÊÄùËÄÉ‚Äù„ÄÇ\n\n‰ΩÜOpenAIÊõ¥Ëøõ‰∏ÄÊ≠•„ÄÇ\n\n### PRM Ê®°Âûã‰ª•ÊîπÂñÑÊï∞Â≠¶ÊâßË°å\n\nÂú®ÂéªÂπ¥‰∫îÊúàÔºå‰ªñ‰ª¨ÂèëÂ∏É‰∫ÜËÆ∫Êñá [Let‚Äôs Verify Step\\-by\\-Step](https://arxiv.org/pdf/2305.20050)ÔºåÂèÇ‰∏éËÄÖÂåÖÊã¨ OpenAI ÁöÑÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂ Ilya Sutskever ‰ª•Âèä‰∏Ä‰∫õÊù•Ëá™ÂéüÂßãÈ™åËØÅËÄÖËÆ∫ÊñáÁöÑÁ†îÁ©∂‰∫∫ÂëòÔºåÂ¶Ç Karl Cobbe„ÄÇ\n\nËøôÈáåÁöÑÊÉ≥Ê≥ïÊòØ‰øÆÊîπÂú®Ê®°ÂûãÂØπÈΩêÈò∂ÊÆµ‰ΩøÁî®ÁöÑÂ•ñÂä±Ê®°Âûã„ÄÇ\n\n[ËôΩÁÑ∂ÊàëÂª∫ËÆÆÊü•ÁúãËøôÁØáÊñáÁ´†‰ª•Ëé∑ÂèñÂÖ≥‰∫é LLM ËÆ≠ÁªÉÁöÑÂÆåÊï¥ÊåáÂçó](https://thewhitebox.ai/llms-the-backbones-of-frontier-ai/)ÔºåÂàõÂª∫ ChatGPT Á≠â‰∫ßÂìÅËøáÁ®ã‰∏≠ÁöÑÊúÄÂêé‰∏ÄÊ≠•ÊòØ‰ΩøÁî®‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π†ÔºåÊàñ RLHF„ÄÇ\n\nËøô‰∏™ÊÉ≥Ê≥ïÊòØËÆ©Ê®°ÂûãÊîπÂñÑÂÖ∂ÂÜ≥Á≠ñËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ËÆ≠ÁªÉ‰∏Ä‰∏™ËæÖÂä©Â•ñÂä±Ê®°ÂûãÔºàÊú¨Ë¥®‰∏äÊòØË¢´ËÆ≠ÁªÉÊ®°ÂûãÁöÑÂá†‰πéÁõ∏ÂêåÂâØÊú¨ÔºâÔºåÂÆÉÂ≠¶‰π†Ê†πÊçÆ‰∫∫Á±ªÂÅèÂ•ΩÂØπËÆ≠ÁªÉÊ®°ÂûãÁöÑÁªìÊûúËøõË°åÊéíÂêç„ÄÇ\n\n*ÈóÆÈ¢òÊòØ‰ªÄ‰πàÔºü*\n\nÂ•ΩÂêßÔºå‰ªäÂ§©Â§ßÂ§öÊï∞Â•ñÂä±Ê®°ÂûãÊòØ **ORMsÔºåÊàñÁªìÊûúÁõëÁù£Â•ñÂä±Ê®°Âûã**„ÄÇÈÄö‰øóÊù•ËØ¥ÔºåËØÑ‰º∞Ê®°ÂûãÈ¢ÑÊµãÁöÑÊ≠£Á°ÆÁ®ãÂ∫¶Êó∂Ôºå‰ªñ‰ª¨‰ªéÊï¥‰Ωì‰∏äÁúãÂæÖÔºåËÄåÂøΩÁï•‰∫ÜÊï¥‰∏™‚ÄúÊÄùÁª¥ËøáÁ®ã‚Äù„ÄÇ\n\nÂè¶‰∏ÄÊñπÈù¢Ôºå**PRMsÔºåÊàñËøáÁ®ãÁõëÁù£Â•ñÂä±Ê®°ÂûãÔºåËØÑ‰º∞Ê®°ÂûãÂìçÂ∫î‰∏≠ÁöÑÊØè‰∏Ä‰∏™Ê≠•È™§**„ÄÇÂõ†Ê≠§Ôºå‰ªñ‰ª¨‚ÄúËø´‰Ωø‚ÄùÊ®°ÂûãÂú®ËøáÁ®ãÁöÑÊØè‰∏Ä‰∏™Ê≠•È™§‰∏äÈÉΩ‰ªòÂá∫ÂØÜÂàáÁöÑÂÖ≥Ê≥®ÂíåÂä™ÂäõÔºåËøôÂú®Ëß£ÂÜ≥Â¶Ç‰∏ãÊï∞Â≠¶ÊñπÁ®ãÁ≠âÊÉÖÂÜµ‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8JC6sZl5UFfl3WorliQy-A.png)\n\nÁÑ∂ËÄåÔºåËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÈùûÂ∏∏ÊòÇË¥µÁöÑËøáÁ®ãÔºåÂõ†‰∏∫ÂÅèÂ•ΩÊï∞ÊçÆÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫ÂäõÊûÑÂª∫Ôºå‰ª•‰æøÂèØ‰ª•Â∫îÁî®ÁõëÁù£‰ø°Âè∑„ÄÇÂõ†Ê≠§ÔºåÊØè‰∏Ä‰∏™ËÆ≠ÁªÉÁ§∫‰æãÈÉΩÊúâÊï∞ÂçÅ‰∏™ÊàñÊõ¥Â§öÁöÑÂ•ñÂä±Êù•ËøõË°åÊµãÈáè„ÄÇ\n\nÂõ†Ê≠§Ôºå‚Äúgpt2\\-chatbot‚ÄùÂèØËÉΩÂú®Â•ñÂä±ËÆ≠ÁªÉ‰∏≠ÂåÖÂê´ÊüêÁßçÂèò‰ΩìÔºåËÄÉËôëÂà∞ÂÆÉÂú®ÁîüÊàêËÆ°ÂàíÂíåÊâßË°åÂ§çÊùÇÈóÆÈ¢òËß£ÂÜ≥ÊñπÈù¢ÁöÑÈ´òÊïàÊÄß„ÄÇ\n\n## ‰∏çÁ¶ÅËÆ©‰∫∫ÂÖ¥Â•ã\n\nËÄÉËôëÂà∞gpt2-chatbotÁöÑÊÉä‰∫∫Ë°®Áé∞Ôºå‰ª•ÂèäOpenAIÊúÄËøëÁöÑÁ†îÁ©∂Âíå[Ê≥ÑÈú≤](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/)ÔºåÊàë‰ª¨Áé∞Âú®ÂèØËÉΩÂØπËøô‰∏™‰∏úË•øÊúâ‰∫ÜÁõ∏ÂΩì‰∏çÈîôÁöÑ‰∫ÜËß£„ÄÇ\n\nÊàë‰ª¨ÂèØ‰ª•ËÇØÂÆöÁöÑÊòØÔºåÊàë‰ª¨ÂæàÂø´Â∞ÜÈù¢‰∏¥‰∏Ä‰∏™ÂÆåÂÖ®‰∏çÂêåÁöÑÂ≠òÂú®ÔºåÂÆÉÂ∞ÜÊääAIÁöÑÂΩ±ÂìçÊèêÂçáÂà∞‰∏Ä‰∏™Êñ∞ÁöÑÊ∞¥Âπ≥„ÄÇ\n\n* *Êàë‰ª¨ÊòØÂê¶Áªà‰∫éËææÂà∞‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãË∂ÖË∂ä‰∫∫Á±ªÊ∞¥Âπ≥Ë°®Áé∞ÁöÑÈáåÁ®ãÁ¢ëÔºåÂ∞±ÂÉèÊàë‰ª¨Âú®AlphaGo‰∏≠ÊâÄÂÅöÁöÑÈÇ£Ê†∑Ôºü*\n* *ÈïøÊé®ÁêÜÊó∂‰ª£ÔºåÂç≥AIÂæÅÊúçÁ≥ªÁªü2ÊÄùÁª¥ÁöÑÊó∂‰ª£ÔºåÊòØÂê¶Â∑≤ÁªèÂà∞Êù•Ôºü*\n\nÂèØËÉΩËøòÊ≤°Êúâ„ÄÇÁÑ∂ËÄåÔºåÊó†Ê≥ï‰∏çÂØπÊé•‰∏ãÊù•Âá†‰∏™ÊúàÊàë‰ª¨Âç≥Â∞ÜËßÅËØÅÁöÑÊÉä‰∫∫ÂèëÂ±ïÊÑüÂà∞È´òÂ∫¶‰πêËßÇ„ÄÇ\n\n‰∏éÊ≠§ÂêåÊó∂ÔºåÊàëÊÉ≥Êàë‰ª¨Â∞Ü‰∏çÂæó‰∏çÁ≠âÂæÖËøô‰∫õÁ≠îÊ°à„ÄÇ‰ΩÜ‰∏ç‰ºöÂ§™‰πÖ„ÄÇ\n\n> ÊúÄÂêéÔºåÂ¶ÇÊûú‰Ω†ÂñúÊ¨¢ËøôÁØáÊñáÁ´†ÔºåÊàëÂú®ÊàëÁöÑ[LinkedIn](https://www.linkedin.com/in/ignacio-de-gregorio-noblejas/)‰∏ä‰ª•Êõ¥ÂÖ®Èù¢ÂíåÁÆÄÂåñÁöÑÊñπÂºèÂÖçË¥πÂàÜ‰∫´Á±ª‰ººÁöÑÊÉ≥Ê≥ï„ÄÇ\n\n> Â¶ÇÊûúÊñπ‰æøÁöÑËØùÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá[X](https://twitter.com/TheTechOasis1)‰∏éÊàëËÅîÁ≥ª„ÄÇ\n\n> ÊúüÂæÖ‰∏é‰Ω†ÁöÑËÅîÁ≥ª„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/overcoming-llm-challenges-in-healthcare-practical-strategies-for-development-in-production-04c617954b9a","frontmatter":{"title":"ÂÖãÊúçÂåªÁñóÈ¢ÜÂüüÁöÑÊ≥ïÂ≠¶Á°ïÂ£´ÊåëÊàòÔºöÁîü‰∫ßÂèëÂ±ïÂÆûÁî®Á≠ñÁï•","meta_title":"ÂÖãÊúçÂåªÁñóÈ¢ÜÂüüÁöÑÊ≥ïÂ≠¶Á°ïÂ£´ÊåëÊàòÔºöÁîü‰∫ßÂèëÂ±ïÂÆûÁî®Á≠ñÁï•","description":"‰∏ÄÁØáÂÖ≥‰∫éÊàëÈÅáÂà∞ÁöÑÊúÄÂ∏∏ËßÅÁöÑ LLM ÂºÄÂèëÊåëÊàò„ÄÅÊúâÊïàÁöÑÁºìËß£Á≠ñÁï•‰ª•ÂèäËÅå‰∏öÁîüÊ∂ØÂÜ≥ÂÆöÊÄßÁöÑÈù¢ËØïÁöÑÊñáÁ´†‚Ä¶‚Ä¶","date":"2024-11-08T00:20:35.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Vak28ygruWKySsH0doGoYg.png","categories":["Health","Generative AI","Machine Learning"],"author":"Rifx.Online","tags":["LLMs","healthcare","hallucinations","validation","monitoring"],"draft":false,"slug":"blog/overcoming-llm-challenges-in-healthcare-practical-strategies-for-development-in-production-04c617954b9a"},"content":"\n### ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ\n\n\n\n### ÊàëÈÅáÂà∞ÁöÑÊúÄÂ∏∏ËßÅÁöÑLLMÂºÄÂèëÊåëÊàò„ÄÅÊúâÊïàÁöÑÁºìËß£Á≠ñÁï•‰ª•Âèä‰∏Ä‰∏™ËÅå‰∏öÁîüÊ∂Ø‰∏≠ÂÜ≥ÂÆöÊÄßÁöÑÈù¢ËØïÈîôËØØ\n\n## ÂºïË®Ä\n\nÊàë‰∏ÄÁõ¥ÊòØÈÇ£ÁßçÊ∑±ÂÖ•Á†îÁ©∂‰∏Ä‰∏™‰∏ªÈ¢òÂπ∂‰∏ìÊ≥®Âà∞Áó¥Ëø∑ÁöÑ‰∫∫„ÄÇÂΩìÊàë‰ªéÊï∞ÊçÆÁßëÂ≠¶Á°ïÂ£´ÊØï‰∏öÊó∂ÔºåÊàëÁöÑÁó¥Ëø∑ÊòØËÆ°ÁÆóÊú∫ËßÜËßâÔºõÁâπÂà´ÊòØÂ∞ÜËÆ°ÁÆóÊú∫ËßÜËßâÂ∫îÁî®‰∫éÁ•ûÁªèÁßëÂ≠¶ÊàñÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüü„ÄÇÊàëÂÜ≥ÂøÉÊàê‰∏∫ÂøÉÁêÜÂÅ•Â∫∑È¢ÜÂüüÁöÑ‚ÄúËÆ°ÁÆóÊú∫ËßÜËßâÂ∑•Á®ãÂ∏à‚ÄùÔºà‰∏çËøá‚ÄúÊú∫Âô®Â≠¶‰π†Â∑•Á®ãÂ∏à‚Äù‰πüÂèØ‰ª•ÔºâÔºåÂ∞ΩÁÆ°ÊàëÁöÑÂØºÂ∏à‰ª¨ÂäùÊàëÊãìÂÆΩËßÜÈáéÔºåÂØªÊâæÊõ¥Â§öÊú∫‰ºö„ÄÇÊàëÂéãÂà∂‰∫ÜËá™Â∑±ÂÜÖÂøÉÁöÑÁñëËôëÔºåÂùö‰ø°Ê≠£Á°ÆÁöÑÂõ¢Èòü‰ºöËÆ§ÂèØÊàëÁöÑ‚Äú‰∏ì‰∏öÁü•ËØÜ‚Äù„ÄÇ\n\n\n\nÂπ∏ËøêÁöÑÊòØÔºåÊàëÁöÑÁêÜËÆ∫‰ºº‰πéÂ•èÊïà‰∫ÜÔºõÊàëËé∑Âæó‰∫ÜÂá†ÂÆ∂ÂøÉÁêÜÂÅ•Â∫∑ÂÖ¨Âè∏ÁöÑÈù¢ËØï„ÄÇ‰ΩÜÈöè‰πãËÄåÊù•ÁöÑÊòØÊàëÊúÄÂ§ßÁöÑÈù¢ËØïÈîôËØØ‰πã‰∏Ä„ÄÇÂú®ÊàëÊúÄÂñúÊ¨¢ÁöÑÂÖ¨Âè∏ÁöÑÊúÄÂêé‰∏ÄËΩÆÈù¢ËØï‰∏≠‚Äî‚Äî‰∏ÄÂÆ∂ÊàëÈùûÂ∏∏ÂñúÊ¨¢ÁöÑÂÖ¨Âè∏‚Äî‚ÄîÊàëÁäØ‰∫Ü‰∏Ä‰∏™ÈîôËØØÔºåËá≥‰ªäÂõûÊÉ≥Ëµ∑Êù•‰ªçËÆ©ÊàëÊÑüÂà∞‰∏çÂÆâ„ÄÇËøô‰∏™ËÅå‰Ωç‰∏ìÊ≥®‰∫éNLPÔºåÂ§ÑÁêÜÊñáÊú¨Êï∞ÊçÆÔºå‰ΩÜÊàëÂøç‰∏ç‰ΩèË°®Ëææ‰∫ÜÊàëÂØπÊàêÂÉèÊï∞ÊçÆÁöÑÂÖ¥Ë∂£„ÄÇ*Âú®ÂõûÂøÜ‰∏≠Âì≠Ê≥£„ÄÇ* ÊàëÊ∏ÖÊô∞Âú∞ËÆ∞ÂæóÔºåÂΩìÊàëËØ¢ÈóÆÊàêÂÉèÊï∞ÊçÆÁöÑÂèØÁî®ÊÄßÊó∂ÔºåÈù¢ËØïÂÆòÁöÑË°®ÊÉÖ‰ªéÂÖ¥Â•ãËΩ¨‰∏∫ÊãÖÂøßÔºåÂõ†‰∏∫Êàë‰ªçÁÑ∂ÂØπËÆ°ÁÆóÊú∫ËßÜËßâÂÖÖÊª°ÁÉ≠ÊÉÖ„ÄÇÂΩìÂ§©Êôö‰∫õÊó∂ÂÄôÔºåÊàëÊî∂Âà∞‰∫Ü‰∏Ä‰∏™Á§ºË≤åÁöÑÊãíÁªùÔºö‰ªñ‰ª¨ÂñúÊ¨¢ÊàëÁöÑÁÉ≠ÊÉÖÔºå‰ΩÜÈúÄË¶Å‰∏Ä‰∏™ÂÆåÂÖ®Ëá¥Âäõ‰∫éNLPÁöÑ‰∫∫„ÄÇ\n\nËÆΩÂà∫ÁöÑÊòØÔºåÊàëÂæàÂø´Âä†ÂÖ•‰∫ÜÂè¶‰∏ÄÂÆ∂ÂøÉÁêÜÂÅ•Â∫∑ÂÖ¨Âè∏ÔºåÂπ∂ÂÆåÂÖ®ËΩ¨ÂêëNLPÂ∑•‰ΩúÔºåÂàõÂª∫‰∫ÜÊîπÂñÑ‰∏¥Â∫äÊä§ÁêÜÁöÑÁÑ¶ËôëÂíåÊäëÈÉÅÁóáÁä∂Ê£ÄÊµãÂô®ÔºåÂπ∂ÂºÄÂèë‰∫ÜÊèêÂçáÂÜÖÂÆπÂèØÂèëÁé∞ÊÄßÁöÑÊé®ËçêÁ≥ªÁªüÔºåÂ¢ûÂä†‰∫Ü12%ÁöÑÂèëÁé∞Áéá„ÄÇÂá†Âπ¥ÂêéÔºåÊàëÁé∞Âú®ÊòØÂõ¢Èòü‰∏≠ÁöÑNLP/LLMÊï∞ÊçÆÁßëÂ≠¶ÂÆ∂ÔºåË¥üË¥£6‰∏™‰ø°ÊÅØÊèêÂèñ‰ªªÂä°„ÄÅ5‰∏™ÂàÜÁ±ª‰ªªÂä°Âíå5‰∏™Êù°‰ª∂ÊëòË¶Å‰ªªÂä°ÔºåÂ∑≤Âú®15ÂÆ∂‰ª•‰∏äÂåªÈô¢Âíå‰∫î‰∏™ÂÆ¢Êà∑‰∏≠ÈÉ®ÁΩ≤„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-VOHDQd88fCyRqoY9bR3hQ.png)\n\nÂá†Âë®ÂâçÔºåÊàëË¢´Ë¶ÅÊ±ÇÂêëÊàëÊõ¥Â§ßÁöÑÊï∞ÊçÆÂõ¢Èòü‰ªãÁªç‚ÄúLLMÂºÄÂèë101‚Äù„ÄÇÊúÄÂàùÔºåÂÜíÂêçÈ°∂ÊõøÁªºÂêàÁóáÊÇÑÁÑ∂Ë¢≠Êù•‚Äî‚Äî*ÊàëËÉΩÂú®LLMÂºÄÂèë‰∏äÂàÜ‰∫´45ÂàÜÈíü‰ªÄ‰πàÂë¢Ôºü* ‰ΩÜÂΩìÊàëÂàõÂª∫ÂπªÁÅØÁâáÊó∂ÔºåÊàëÊÑèËØÜÂà∞ÊàëÊúâÂæàÂ§öË¶ÅËØ¥ÁöÑÔºåÂπ∂ÂØπÂàÜ‰∫´ÊàëÊâÄÂ≠¶Âà∞ÁöÑÊ∑±ÂéöÁü•ËØÜÊÑüÂà∞ÂÖ¥Â•ã„ÄÇËøôÁßçÂÖ¥Â•ã‰øÉÊàê‰∫Ü‰Ω†Áé∞Âú®Ê≠£Âú®ÈòÖËØªÁöÑËøôÁØáÊñáÁ´†„ÄÇÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜËÆ≤Ëø∞ÊàëÂú®Áîü‰∫ß‰∏≠ÈÅáÂà∞ÁöÑ‰∏Ä‰∫õÂ∏∏ËßÅLLMÊåëÊàò‰ª•ÂèäÂ∏ÆÂä©ÊàëËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÁöÑÁ≠ñÁï•„ÄÇ\n\n## 1\\. ËæìÂá∫Ê†ºÂºèÈîôËØØ\n\nËøôÂèØËÉΩÊòØÊàëÈÅáÂà∞ÁöÑÊúÄÂ∏∏ËßÅÈóÆÈ¢òÔºå‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÊòØ„ÄÇËæìÂá∫Ê†ºÂºèÁöÑÂèØÈù†ÊÄßÂèØËÉΩ‰ºöÂõ†Êàë‰ΩøÁî®ÁöÑÊ®°ÂûãËÄåÊòæËëó‰∏çÂêå„ÄÇ‰æãÂ¶ÇÔºåGPT\\-4 Turbo ÈÄöÂ∏∏Êèê‰æõ‰∏ÄËá¥ÁöÑ JSON ËæìÂá∫Ôºå‰ΩÜ GPT\\-4o Âú®ËøôÊñπÈù¢ÁöÑÂèØÈù†ÊÄßÂæÄÂæÄËæÉÂ∑Æ„ÄÇÂú® GPT\\-4o ‰∏≠ÔºåÊàëÈÅáÂà∞Ëøá‰ªéÂàóË°®ÂíåÂ≠óÁ¨¶‰∏≤Âà∞‰∏çÂÆåÊï¥Â≠óÂÖ∏ÁöÑÂêÑÁßçÊÉÖÂÜµÔºåÂΩìÊòéÁ°ÆËØ∑Ê±ÇÁªìÊûÑÂåñ JSON ËæìÂá∫Êó∂„ÄÇÂ¶ÇÊûúËøô‰∫õÊ†ºÂºèÈóÆÈ¢òÊ≤°ÊúâË¢´ÂèëÁé∞Âπ∂‰∏îÊ®°ÂûãÊ≤°ÊúâÈáçÊñ∞ËøêË°åÔºåÊàëÂèØËÉΩ‰ºöÈù¢‰∏¥Êï∞ÊçÆË¶ÜÁõñ‰∏çÂÆåÊï¥ÁöÑÈ£éÈô©„ÄÇ\n\n### Ê†ºÂºèÈîôËØØÁöÑÂΩ±Âìç\n\n‰∏ç‰∏ÄËá¥ÁöÑËæìÂá∫Ê†ºÂºè‰ºöÂØπ‰∏ãÊ∏∏ÊµÅÁ®ã‰∫ßÁîüÈáçÂ§ßÂΩ±Âìç„ÄÇÂ¶ÇÊûúÊï∞ÊçÆÁªìÊûÑ‰∏çÊ≠£Á°ÆÔºåÂèØËÉΩ‰ºöÂØºËá¥ÂêéÁª≠Â§ÑÁêÜÊ≠•È™§ÁöÑÂ§±Ë¥•ÔºåÊâ≠Êõ≤Êä•ÂëäÁöÑÂáÜÁ°ÆÊÄßÔºåÁîöËá≥Âú®Êú™Ë¢´ÂèëÁé∞ÁöÑÊÉÖÂÜµ‰∏ãÂØºËá¥Ê¥ûÂØü‰∏çÂÆåÊï¥„ÄÇÂú®ÂåªÁñóÁ≠âÈ´òÈ£éÈô©È¢ÜÂüüÔºåÊàëÁöÑÂ∑•‰ΩúÊ∂âÂèäÊ≠§Â§ÑÔºå‰∏çÂÆåÊï¥ÊàñÁªìÊûÑÈîôËØØÁöÑÊï∞ÊçÆÂèØËÉΩ‰ºöÂ∏¶Êù•ÂÆûÈôÖÂΩ±ÂìçÔºåÂõ†Ê≠§Ê†ºÂºèÁöÑ‰∏ÄËá¥ÊÄßËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n### ÁºìËß£Êé™ÊñΩ\n\n‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàëÂÆûÁé∞‰∫Ü**Ê†ºÂºèÊ£ÄÊü•ÈÄªËæë**Ôºå**È™åËØÅËæìÂá∫ÁªìÊûÑ**„ÄÇÂ¶ÇÊûú‰∏çÊ≠£Á°ÆÔºåÊàëÂ∞ÜÈáçÊñ∞ËøêË°åÊ®°ÂûãÔºåÁõ¥Âà∞ÂÆÉÁ¨¶ÂêàÈ¢ÑÊúüÊ†ºÂºè„ÄÇÊ≠§Â§ñÔºåÊàë‰ΩøÁî®**Êó•ÂøóËÆ∞ÂΩï**Êù•ÊçïËé∑‰∏éÊ†ºÂºèÁõ∏ÂÖ≥ÁöÑÈîôËØØ„ÄÇÁÑ∂ËÄåÔºåÈáçÊñ∞ËøêË°åÊ®°ÂûãÂ∏¶Êù•‰∫ÜÊùÉË°°Ôºå‰æãÂ¶ÇÂ¢ûÂä†Âª∂ËøüÂíåÊõ¥È´òÁöÑAPIÊàêÊú¨„ÄÇÊàëÊ†πÊçÆÊï∞ÊçÆË¶ÜÁõñÁöÑÂÖ≥ÈîÆÊÄßÂíåÊàêÊú¨ÈôêÂà∂Âª∫Á´ã‰∫ÜÈáçÊñ∞ËøêË°åÁöÑÈòàÂÄº„ÄÇÂ¶ÇÊûúÈáçÊñ∞ËøêË°å‰∏çÂèØË°åÔºåÊàëÊúâÊó∂‰ºöÂ∫îÁî®ÂêéÂ§ÑÁêÜÊù•‚Äú‰øÆÂ§ç‚ÄùËæìÂá∫ÁªìÊûÑÔºåÂ∞ΩÁÆ°ËøôÁßçÊñπÊ≥ï‰πüÂ≠òÂú®ÂºïÂÖ•ÈîôËØØÊàñ‰∏ç‰∏ÄËá¥ÁöÑÈ£éÈô©„ÄÇ\n\n‰∏∫‰∫ÜËØ¥ÊòéËøôÁßçÊñπÊ≥ïÔºåËøôÈáåÊúâ‰∏Ä‰∏™Á§∫‰æã‰ª£Á†ÅÁâáÊÆµÔºåÂÆÉËØ∑Ê±Ç‰ª•JSONÊ†ºÂºèËøîÂõûÊÇ£ËÄÖÊï∞ÊçÆÔºåÂπ∂ÂåÖÂê´ÁâπÂÆöÁöÑÈîÆÔºåÂ¶Ç`\"name\"`„ÄÅ`\"age\"`Âíå`\"insurance\"`„ÄÇËøôÊÆµ‰ª£Á†ÅÊºîÁ§∫‰∫Ü‰∏ÄÁßçÈ™åËØÅÊ®°ÂûãÂìçÂ∫îÊòØÂê¶ÂåÖÂê´ÊâÄÊúâÂøÖÈúÄÂ≠óÊÆµÂπ∂ÈÅµÂæ™È¢ÑÊúüÁªìÊûÑÁöÑÊñπÊ≥ï„ÄÇÈÄöËøáÂÆûÁé∞ÈáçËØïÈÄªËæëÔºåËØ•‰ª£Á†ÅÊó®Âú®Á°Æ‰øùÊï∞ÊçÆ‰∏ÄËá¥ÊÄßÔºåÂáèÂ∞ëÂú®ÂÖ≥ÈîÆÂ∑•‰ΩúÊµÅÁ®ã‰∏≠‰∏éÊ†ºÂºèÈîôËØØÁõ∏ÂÖ≥ÁöÑÈ£éÈô©„ÄÇ\n\n```python\ndef get_llm_response(prompt: str, required_keys: Set[str], retries: int = 3) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Calls the language model to get a response in JSON format. If the response \n    is not in the expected JSON format or lacks required keys, retries the call \n    up to `retries` times.\n    Parameters:\n        prompt (str): The prompt sent to the language model.\n        required_keys (Set[str]): A set of required keys that must be present in the JSON response.\n        retries (int): The maximum number of retries if the output format is invalid.\n    Returns:\n        Optional[Dict[str, Any]]: Parsed JSON response if successful; None if retries are exhausted.\n    \"\"\"\n    \n    for attempt in range(retries):\n        try:\n            response = openai.Completion.create(\n                model=\"gpt-4o\",\n                prompt=prompt,\n                max_tokens=100,\n                temperature=0.7\n            )\n            \n            # Attempt to parse the response as JSON\n            response_text = response.choices[0].text.strip()\n            parsed_response = json.loads(response_text)\n            \n            # Check if parsed_response is in the expected structure and contains required keys\n            if isinstance(parsed_response, dict) and required_keys.issubset(parsed_response.keys()):\n                return parsed_response\n            else:\n                print(f\"Attempt {attempt + 1}: Output format invalid or missing required keys, retrying...\")\n        except (json.JSONDecodeError, KeyError) as e:\n            print(f\"Attempt {attempt + 1}: Error parsing JSON - {str(e)}, retrying...\")\n    print(\"Max retries exceeded: Unable to get valid JSON output with required keys.\")\n    return None\n\n```\n\n## 2\\. ÂπªËßâ\n\nÂπªËßâÂèëÁîüÂú®Ê®°ÂûãÂàõÈÄ†Âá∫Âê¨Ëµ∑Êù•ÂêàÁêÜ‰ΩÜÂÆûÈôÖ‰∏äÂπ∂‰∏çÂ≠òÂú®ÁöÑ‰ø°ÊÅØÊó∂„ÄÇ‰æãÂ¶ÇÔºåÂΩìÊàëËØïÂõæ‰ªéÊ∫êÊñáÊú¨‰∏≠ÊèêÂèñÂºïÁî®Êó∂ÔºåÊúâÊó∂Ê®°Âûã‰ºöÈÄâÊã©‚ÄúÂèëÊå•ÂàõÊÑè‚ÄùÔºå‰∫ßÁîüÁ±ª‰ºº‰ΩÜÂÆåÂÖ®ËôöÊûÑÁöÑÁü≠ËØ≠„ÄÇÂú®ÂáÜÁ°ÆÊÄßËá≥ÂÖ≥ÈáçË¶ÅÁöÑÈ¢ÜÂüüÔºåÂ¶ÇÂåªÁñó‰øùÂÅ•ÔºåÂæÆÂ∞èÁöÑÂπªËßâÂèØËÉΩÂØºËá¥ÈáçÂ§ßÈóÆÈ¢ò„ÄÇ\n\n### ÁºìËß£\n\nÊàëÈÄöËøáÂÆûÊñΩÂêéÂ§ÑÁêÜÈÄªËæëÊù•Ëß£ÂÜ≥ÂπªËßâÈóÆÈ¢òÔºå‰ª•È™åËØÅÂú®‰ªª‰Ωï‰ø°ÊÅØÊèêÂèñ‰ªªÂä°‰∏≠ÔºåÊèêÂèñÁöÑ‰∏ä‰∏ãÊñá‰∏éÊ∫êÊñáÊú¨ÂÆåÂÖ®ÂåπÈÖç„ÄÇ‰∏∫‰∫ÜÁ°Æ‰øùÁªÜÂæÆÁöÑÂèòÂä®‰∏ç‰ºöÂØºËá¥ÈÅóÊºèÂåπÈÖçÔºåÊàëÈÄöËøáÂéªÈô§Ê†áÁÇπÁ¨¶Âè∑Âπ∂Âú®ÊØîËæÉÊ∫êÊñáÊú¨ÂíåÊèêÂèñÊñáÊú¨Êó∂Â∞ÜÂÖ∂ÂÖ®ÈÉ®ËΩ¨Êç¢‰∏∫Â∞èÂÜôÊù•Ê†áÂáÜÂåñÊñáÊú¨„ÄÇÊ≠§Â§ñÔºåËøòÊúâÂÖ∂‰ªñÂá†ÁßçÁ≠ñÁï•ÊúâÂä©‰∫éÊúÄÂ∞èÂåñÂπªËßâ„ÄÇ‰æãÂ¶ÇÔºå**ÈìæÂºèÊÄùÁª¥ÊèêÁ§∫**ÔºåÂç≥Ê®°ÂûãËß£ÈáäÂÖ∂Êé®ÁêÜÁöÑÊØè‰∏ÄÊ≠•ÔºåÂèØ‰ª•‰∫ßÁîüÊõ¥‰∏∫ÊâéÂÆûÁöÑËæìÂá∫ÔºåÂπ∂Èôç‰Ωé‰∏çÂáÜÁ°ÆËæìÂá∫ÁöÑÂèØËÉΩÊÄß„ÄÇÂú®È´òÈ£éÈô©Â∫îÁî®Ôºà‰æãÂ¶ÇÂåªÁñó‰øùÂÅ•Ê°à‰æãÔºâ‰∏≠Ôºå**‰∫∫Êú∫Âçè‰ΩúÊ£ÄÊü•**‰Ωú‰∏∫È¢ùÂ§ñÁöÑÂÆ°Êü•Â±ÇÈùûÂ∏∏ÈáçË¶ÅÔºåÊúâÂä©‰∫éÊçïÊçâËá™Âä®ÂåñËøáÁ®ãÂèØËÉΩÈÅóÊºèÁöÑÂπªËßâ„ÄÇÊúÄÂêéÔºåÂº∫Ë∞É‰∫ãÂÆûÂáÜÁ°ÆÊÄßÁöÑÊèêÁ§∫Ôºå‰æãÂ¶ÇÊåáÁ§∫Ê®°Âûã‚Äú‰ªÖ‰ΩøÁî®Ê∫êÊñáÊú¨‰∏≠ÁöÑÁ°ÆÂàáÁü≠ËØ≠‚ÄùÔºåÂèØ‰ª•ÂºïÂØºÊ®°ÂûãÊúùÁùÄÊõ¥Á≤æÁ°ÆÁöÑÂìçÂ∫îÊñπÂêëÂèëÂ±ï„ÄÇ\n\n## 3\\. ËøáÊó∂‰ø°ÊÅØ\n\nËøáÊó∂ÁöÑ‰ø°ÊÅØÁÆ°ÁêÜËµ∑Êù•ÂèØËÉΩÂæàÂÖ∑ÊúâÊåëÊàòÊÄßÔºåÁâπÂà´ÊòØÂú®ÂáÜÁ°ÆÊÄßÂíåÂèäÊó∂ÊÄßËá≥ÂÖ≥ÈáçË¶ÅÁöÑÂ∫îÁî®‰∏≠„ÄÇÊúâÊó∂ÔºåÊ®°ÂûãÂèØËÉΩ‰ºö‰ªéÊñáÊ°£ÁöÑÊóßÈÉ®ÂàÜÊ£ÄÁ¥¢‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂ÂëàÁé∞‰∏∫ÂΩìÂâç‰ø°ÊÅØ„ÄÇ‰ΩøÁî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊó∂ÔºåËøô‰∏™ÈóÆÈ¢òÂèØËÉΩÂèòÂæóÊõ¥Âä†Â§çÊùÇÔºåÂõ†‰∏∫RAG‰ªÖÊ†πÊçÆÁõ∏ÂÖ≥ÊÄßËÄåÈùûÂèäÊó∂ÊÄßÊàñÁâπÂÆöÊñáÊ°£ÈÉ®ÂàÜÊù•Ê£ÄÁ¥¢ÂÜÖÂÆπ„ÄÇÁº∫Â∞ëÈÉ®ÂàÜÊ†áÁ≠æÊàñÊó∂Èó¥Êà≥ÊÑèÂë≥ÁùÄRAGÂèØËÉΩ‰ºö‰ªéÊñáÊ°£ÁöÑÁõ∏ÂÖ≥ÈÉ®ÂàÜÊèêÂèñ‰ø°ÊÅØÔºåËÄå‰∏çÂå∫ÂàÜËøô‰∫õ‰ø°ÊÅØÊòØÂê¶ËøáÊó∂ÔºåËøôÂèØËÉΩÂØºËá¥Êóß‰ø°ÊÅØÂíåÂΩìÂâç‰ø°ÊÅØÊ∑∑ÂêàÂú®‰∏ÄËµ∑„ÄÇ‰ΩøÁî®ÂêëÈáèÊï∞ÊçÆÂ∫ìÁöÑÂè¶‰∏Ä‰∏™ÊåëÊàòÊòØÔºåÂ¶ÇÊûúÊàë‰ª¨Â≠òÂÇ®Êï¥‰∏™ÊñáÊ°£ÔºåÂàôÊó†Ê≥ïÂú®Ê≤°ÊúâÊòéÁ°ÆÊ†áÁ≠æÁöÑÊÉÖÂÜµ‰∏ãËΩªÊùæÂà†Èô§ÁâπÂÆöÈÉ®ÂàÜÔºå‰ªéËÄå‰ΩøÊúâÊïàËøáÊª§Êó†ÂÖ≥‰ø°ÊÅØÂèòÂæóÂõ∞Èöæ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*k9btdwyCCAb9qp92gB0PwA.png)\n\n### ÁºìËß£Êé™ÊñΩ\n\n‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàëÂú®ÊèêÁ§∫‰∏≠Áõ¥Êé•ÊåáÂÆö‚ÄúÂΩìÂâç‚ÄùÊàñ‚ÄúÊúÄÊñ∞‚ÄùÊï∞ÊçÆÔºåÂπ∂‰ΩøÁî®È¢ÑÂ§ÑÁêÜÊ≠•È™§Âú®Â∞ÜÊï∞ÊçÆ‰º†ÈÄíÁªôÊ®°Âûã‰πãÂâçÂà†Èô§‰ªª‰ΩïËøáÊó∂ÁöÑÈÉ®ÂàÜ„ÄÇËøô‰∏™È¢ùÂ§ñÁöÑÈ¢ÑÂ§ÑÁêÜÊ≠•È™§Á°Æ‰øù‰ªÖ‰øùÁïôÊúÄÊñ∞„ÄÅÊúÄÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØÔºåÂ∏ÆÂä©Ê®°Âûã‰∏ìÊ≥®‰∫éÊèê‰æõÂèäÊó∂ÂíåÂáÜÁ°ÆÁöÑÂìçÂ∫î„ÄÇËøô‰∏™Ê≠•È™§‰∏ç‰ªÖÁ°Æ‰øù‰∫ÜÊõ¥ÂáÜÁ°ÆÁöÑËæìÂá∫ÔºåËøòÈôç‰Ωé‰∫ÜË∞ÉÁî®ÁöÑÊàêÊú¨„ÄÇÈÄöËøáÊèêÂâçÂÆûÊñΩËøô‰∫õËøáÊª§Âô®ÔºåÊàëÂèØ‰ª•‰øùÊåÅÊ®°ÂûãËæìÂá∫ÁöÑ‰∏ÄËá¥ÊÄßÂíåÁõ∏ÂÖ≥ÊÄß„ÄÇ\n\n## 4\\. ËøáÂ∫¶‰æùËµñ‰∏é‰º¶ÁêÜ\n\nÂ∞ΩÁÆ°ÊàëÂ∏åÊúõÊàëÊâÄÂÅöÁöÑÂ∑•‰ΩúËÉΩÂ§üË¢´‰ΩøÁî®Âπ∂‰∏îÊúâÁî®Ôºå‰ΩÜÊàëÊúÄÂ§ßÁöÑÊãÖÂøßÊòØÁî®Êà∑‰ºöÂØπÊ®°ÂûãÈ¢ÑÊµãËøá‰∫é‰ø°‰ªª‚Äî‚ÄîÂ∞§ÂÖ∂ÊòØÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩ‰∏ç‰ªÖ‰ªÖÊòØÂú®ÂÅöÈ¢ÑÊµãÔºåËøòÁªèÂ∏∏Âú®ÁîüÊàêÊëòË¶ÅÊàñÊèêÂèñÁâπÂÆöÁöÑÊÇ£ËÄÖÁªÜËäÇ„ÄÇ‰∏ìÂÆ∂‰ª¨ÂØπÊüê‰∫õÂÆö‰πâÂèØËÉΩÊåÅÊúâ‰∏çÂêåÁöÑÁúãÊ≥ïÔºåÂõ†Ê≠§Â§öÊ†∑ÊÄßÂíåÂØπËØùÂØπ‰∫éËææÊàêÂÖ±ËØÜÈùûÂ∏∏ÈáçË¶Å„ÄÇËøáÂ∫¶‰æùËµñËøô‰∫õÈ¢ÑÊµãÂèØËÉΩ‰ºöÂØºËá¥Êä§ÁêÜÂõ¢ÈòüÈôêÂà∂Ëøô‰∫õÂØπËØùÔºåÂπ∂ÂøΩËßÜ‰ªñ‰ª¨Êú¨ÂèØ‰ª•Êõ¥‰ªîÁªÜÊ£ÄÊü•ÁöÑÈîôËØØ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*6-0mq8Svxh8ATuyT)\n\n### ÁºìËß£\n\nÊàë‰ºòÂÖàÊïôËÇ≤Âõ¢Èòü‰∫ÜËß£Ê®°ÂûãÁöÑÂ±ÄÈôêÊÄßÔºåÂåÖÊã¨ÂÖ∂Âá∫ÈîôÁöÑÂÄæÂêëÔºåÂπ∂ÈºìÂä±‰ªñ‰ª¨Â∞Ü‰∫∫Â∑•Êô∫ËÉΩËßÜ‰∏∫‰∫∫Á±ª‰∏ì‰∏öÁü•ËØÜÁöÑË°•ÂÖÖ„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåÁªÜÂæÆÂ∑ÆÂà´Ëá≥ÂÖ≥ÈáçË¶ÅÔºå‰∫∫Â∑•Âπ≤È¢ÑÁöÑÁõëÁù£ÂØπ‰∫éÈ´òÂΩ±ÂìçÂäõÁöÑÊ°à‰æãËá≥ÂÖ≥ÈáçË¶ÅÔºåÂÖÅËÆ∏‰∏ìÂÆ∂ÂÆ°Êü•‰∫∫Â∑•Êô∫ËÉΩÁöÑËæìÂá∫ÔºåÂáèÂ∞ëÂØπËøáÂ∫¶‰æùËµñÁöÑÈ£éÈô©„ÄÇËøôÁßçÂçè‰ΩúÊñπÊ≥ï‰Ωø‰∫∫Â∑•Êô∫ËÉΩËÉΩÂ§üÂ¢ûÂº∫‰∏ìÂÆ∂ÁöÑËßÅËß£Ôºå‰øùÊåÅÈ´òÈ£éÈô©Â∫îÁî®ÊâÄÈúÄÁöÑÂèØÈù†ÊÄßÂíå‰º¶ÁêÜÂÆåÊï¥ÊÄß„ÄÇ\n\n## 5\\. Âø´ÈÄüÊ®°ÂûãÂºÉÁî®\n\nÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ïÈÄüÂ∫¶Âä†Âø´ÔºåÊ®°ÂûãÂíåAPIÁâàÊú¨Êõ¥Êñ∞È¢ëÁπÅÔºåÁâàÊú¨Ë¢´ÂºÉÁî®ÁöÑÈÄüÂ∫¶ÂæÄÂæÄË∂ÖÂá∫È¢ÑÊúü„ÄÇÂ¶ÇÊûúÊÇ®ÊõæÂõ†Ê®°ÂûãÁâàÊú¨Ë¢´ÈÄÄÂΩπËÄåÂØºËá¥Â∑•‰ΩúÊµÅÁ®ãÊÑèÂ§ñ‰∏≠Êñ≠ÔºåÊÇ®‰ºöÁü•ÈÅìËøô‰ºöÈÄ†ÊàêÂ§öÂ§ßÁöÑÂπ≤Êâ∞„ÄÇÂú®ËøáÂéª‰∏ÄÂπ¥‰∏≠ÔºåËøôÁßçÊÉÖÂÜµÂèëÁîü‰∫ÜÂá†Ê¨°ÔºåËø´‰ΩøÊàë‰ª¨ËøÖÈÄüÈáçÊñ∞ËøõË°åÂàÜÊûêÔºå‰ª•Á°Æ‰øùÊõ¥Êñ∞ÁöÑÊ®°ÂûãÁâàÊú¨‰ªçËÉΩÊåâÈ¢ÑÊúüË°®Áé∞„ÄÇ\n\n### ÁºìËß£\n\nÂ∞ÜÂÆöÊúüÊ£ÄÊü•Ê®°ÂûãÁâàÊú¨Âπ∂ÊèêÂâçÂ§ÑÁêÜÂºÉÁî®Ë≠¶Âëä‰Ωú‰∏∫‰ºòÂÖà‰∫ãÈ°π„ÄÇËøôÁßç‰∏ªÂä®ÁöÑÊñπÊ≥ï‰ΩøÊàë‰ª¨ËÉΩÂ§üÊèêÂâçËßÑÂàíËøáÊ∏°ÔºåÈÅøÂÖçÊúÄÂêéÊó∂ÂàªÁöÑÂåÜÂøô„ÄÇËôΩÁÑ∂ËøôÂè™ÊòØ‰∏Ä‰∏™Â∞èÊ≠•È™§Ôºå‰ΩÜÂú®‰øùÊåÅÈ°∫ÁïÖÊìç‰ΩúÊñπÈù¢Âç¥ÊúâÁùÄÊòæËëóÁöÑÂΩ±Âìç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GK08JY3dcRUS4r6Z0x6EmA.png)\n\n## 6\\. APIÁöÑÈÄüÁéáÈôêÂà∂\n\nAPIÁöÑÈÄüÁéáÈôêÂà∂ÊòØ‰∏Ä‰∏™ÂæÆÂ¶ô‰ΩÜÈáçË¶ÅÁöÑÊåëÊàòÔºåÁâπÂà´ÊòØÂú®Â§ÑÁêÜÂ§ßÈáèËØ∑Ê±ÇÊó∂„ÄÇËææÂà∞ÈÄüÁéá‰∏äÈôêÂèØËÉΩ‰ºöÂØºËá¥Âª∂ËøüÔºåÂáèÊÖ¢ÂÆûÊó∂Â∑•‰ΩúÊµÅÁ®ãÔºåÁîöËá≥ÂÅúÊ≠¢Êï¥‰∏™ËøáÁ®ã„ÄÇÂú®Â§ÑÁêÜÊó∂Èó¥ÊïèÊÑüÊï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÔºåËææÂà∞ÈôêÂà∂ÂèØËÉΩ‰ºöÈÄ†Êàê‰∏•ÈáçÂπ≤Êâ∞ÔºåÂõ†‰∏∫Â∑•‰ΩúÊµÅÁ®ã‰ºöÊÑèÂ§ñ‰∏≠Êñ≠„ÄÇËøôÂú®ÂåªÁñóÁéØÂ¢É‰∏≠Â∞§ÂÖ∂ÊàêÈóÆÈ¢òÔºåÂõ†‰∏∫Êó∂Êú∫Áõ¥Êé•ÂΩ±ÂìçÊìç‰ΩúÂíåÊÇ£ËÄÖÊä§ÁêÜ„ÄÇ\n\n### ÁºìËß£\n\n‰∏∫‰∫ÜÁºìËß£Ëøô‰∏ÄÈóÆÈ¢òÔºåÊàë‰ª¨ÈááÂèñ‰∫Ü‰∏ªÂä®ÁöÑÊñπÊ≥ïÔºåÈÄöËøáË∑üË∏™ API ‰ΩøÁî®Ê®°ÂºèÊù•ËØÜÂà´È´òÂ≥∞Êó∂ÊÆµÂπ∂ÂáèÂ∞ëÈùûÂøÖË¶ÅÁöÑË∞ÉÁî®„ÄÇÈÄöËøáÈîôÂºÄËØ∑Ê±ÇÂíåÊâπÈáèË∞ÉÁî®ÔºåÊàëÂèØ‰ª•Êõ¥ÂùáÂåÄÂú∞ÂàÜÈÖçË¥üËΩΩÔºåÈÅøÂÖçË∂ÖËøáÈôêÂà∂„ÄÇÂú®ÈúÄÊ±ÇÈ´òÊ∂®‰∏îÈÄüÁéáÈôêÂà∂ÊåÅÁª≠ËææÂà∞ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂêëÊèê‰æõËÄÖËØ∑Ê±ÇÈ¢ùÂ§ñÈÖçÈ¢ùÂèØ‰ª•Êèê‰æõ‰∏Ä‰∏™ÂàáÂÆûÂèØË°åÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÂπ≥Ë°°‰ΩøÁî®Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÊèêÂâç‰∫ÜËß£Êàë‰ª¨ÁöÑÈ´òÂ≥∞Êó∂ÊÆµÂíå‰ΩøÁî®Ê®°ÂºèÂØπ‰∫éÁª¥ÊåÅÁ®≥ÂÆö„ÄÅ‰∏ç‰∏≠Êñ≠ÁöÑÂ∑•‰ΩúÊµÅÁ®ãËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n## ÁªìËÆ∫\n\nËøô‰∫õÂè™ÊòØÊàëÂú®‰∏é LLMs Â∑•‰ΩúÊó∂ÈÅáÂà∞ÁöÑÂÖ≠‰∏™Â∏∏ËßÅÈóÆÈ¢ò„ÄÇÊàëÊ≤°ÊúâÊÉ≥Âà∞Ëá™Â∑±‰ºöÊù•Âà∞ËøôÈáåÔºå‰ΩÜÈÄÄ‰∏ÄÊ≠•ÊÄùËÄÉÔºåÊàëÊÑèËØÜÂà∞Ëá™Â∑±Âú®Ëøô‰∏™È¢ÜÂüüÁßØÁ¥Ø‰∫ÜÂ§öÂ∞ë‰∏ì‰∏öÁü•ËØÜ‚Äî‚ÄîÊàëÈùûÂ∏∏ÂÖ¥Â•ãËÉΩÂ§üÂú®Âç≥Â∞ÜÂèëÂ∏ÉÁöÑÊñáÁ´†‰∏≠ÁªßÁª≠ÂàÜ‰∫´Ëøô‰∫õÁªèÈ™å„ÄÇÊàëÂ∏åÊúõËÉΩÂê¨Âà∞ÂÖ∂‰ªñ‰∫∫ÈÅáÂà∞ÁöÑÊåëÊàò‰ª•Âèä‰ªñ‰ª¨ÊâæÂà∞ÁöÑÊúâÊïàÁºìËß£Á≠ñÁï•ÊàñËß£ÂÜ≥ÊñπÊ≥ïÔºåÊó†ËÆ∫ÊòØ‰∏éËøô‰∫õÈóÆÈ¢òÁõ∏ÂÖ≥ËøòÊòØÂÖ®Êñ∞ÁöÑÈóÆÈ¢ò„ÄÇÊàëÂ∏åÊúõËøô‰∫õËßÅËß£ÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÂπ∂ÊøÄÂèëÂÖ≥‰∫éËøô‰∏ÄÂø´ÈÄüÂèëÂ±ïÁöÑÈ¢ÜÂüüÔºàÊ®°ÂûãÁâàÊú¨Âíå API ÁâàÊú¨Êõ¥Êñ∞ÂæóÂ§™Âø´ÔºâÊúÄ‰Ω≥ÂÆûË∑µÁöÑËøõ‰∏ÄÊ≠•ËÆ®ËÆ∫„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/qwen-new-release-the-king-of-coder-is-qwen2-5-coder-32b-8b96d442b280","frontmatter":{"title":"Qwen Êñ∞ÂèëÂ∏ÉÔºöÁºñÁ†ÅÂô®‰πãÁéãÊòØ Qwen2.5 ÁºñÁ†ÅÂô® 32BÔºÅ","meta_title":"Qwen Êñ∞ÂèëÂ∏ÉÔºöÁºñÁ†ÅÂô®‰πãÁéãÊòØ Qwen2.5 ÁºñÁ†ÅÂô® 32BÔºÅ","description":"Qwen2.5-Coder-32B-InstructÊòØÊúÄÊñ∞ÂèëÂ∏ÉÁöÑAIÁºñÁ†ÅÊ®°ÂûãÔºåË°®Áé∞‰ºòÂºÇÔºåÂü∫ÂáÜÂàÜÊï∞Ë∂ÖËøáGPT-4oÔºåÈÄüÂ∫¶ËææÂà∞32 tokens/s„ÄÇËØ•Ê®°ÂûãÂú®Apache 2.0ËÆ∏ÂèØ‰∏ãÂºÄÊ∫êÔºåÊîØÊåÅÂ§öÁßçÁ°¨‰ª∂ÈÖçÁΩÆÔºåÂåÖÊã¨Âçï‰∏™GPU 3090ÂíåËæÉÂ∞èÁöÑ14BÊ®°ÂûãÔºåÈÄÇÁî®‰∫éËÆ°ÁÆóËÉΩÂäõËæÉ‰ΩéÁöÑÁî®Êà∑„ÄÇOllamaÂ∑≤‰∏∫Â§ö‰∏™Ê®°ÂûãÊèê‰æõÊîØÊåÅÔºåÁî®Êà∑ÂèØÈÄöËøáÁÆÄÂçïÂëΩ‰ª§ËøêË°åÊ®°Âûã„ÄÇ","date":"2024-11-14T03:32:00.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OzrZMolY75t_cdux5UGtIg.png","categories":["Programming","Technology","Machine Learning"],"author":"Rifx.Online","tags":["Qwen2.5","Coder","32B","Instruct","GPU"],"draft":false,"slug":"blog/qwen-new-release-the-king-of-coder-is-qwen2-5-coder-32b-8b96d442b280"},"content":"\nÂ§ßÂÆ∂Â•ΩÔºÅ‰ªãÁªç‰∏Ä‰∏ã Qwen2\\.5\\-Coder\\-32B\\-InstructÔºöÊúÄÊñ∞ÁöÑ AI Ê®°ÂûãÊ≠£Âú®ÂºïÈ¢ÜÁºñÁ†ÅÁïåÁöÑÈ£éÊΩÆÔºÅ\n\n\n\nËøô‰∫õÊ®°ÂûãÂ§ßÂ§öÂú® Apache 2\\.0 ËÆ∏ÂèØ‰∏ãÂèëÂ∏É„ÄÇÂü∫ÂáÜÂàÜÊï∞È´òÂæóÊÉä‰∫∫Ôºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aHeNvfOvcpME0qzy6EQexQ.jpeg)\n\nÂ¶ÇÊàë‰ª¨ÊâÄËßÅÔºåÂÆÉÂú®ÂºÄÊ∫êÊ®°Âûã‰∏≠Ë°®Áé∞ÊúÄ‰Ω≥ÔºåÁîöËá≥Ë∂ÖË∂ä‰∫Ü GPT\\-4o„ÄÇ\n\nOllama Â∑≤Áªè‰∏∫Â§ö‰∏™Ê®°ÂûãÁ≥ªÂàóÊèê‰æõ‰∫ÜÊîØÊåÅ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rV1xrpRXUjTFFoKwSsfeOg.png)\n\nÂõ†Ê≠§ÔºåËøêË°åËµ∑Êù•ÈùûÂ∏∏ÁÆÄÂçï„ÄÇ\n\n```python\nollama run qwen2.5-coder:32b\n```\n\n32BÔºàQ4 Ê†ºÂºèÔºâÂú®Âçï‰∏™ GPU 3090 ‰∏äÁöÑÊÄßËÉΩÂèØ‰ª•‰ªé‰ª•‰∏ãÊà™Âõæ‰∏≠ÊâæÂà∞Ôºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MVQ0srQhRxX4Ifo3IqU6og.png)\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jtH3ixeeOQGfyDzmO4Ni3A.png)\n\nÂÆÉÁöÑÈÄüÂ∫¶ÊòØ **32 tokens/s**ÔºÅË∂ÖÁ∫ßÂø´„ÄÇÊàëÈùûÂ∏∏È´òÂÖ¥ÂíåÂç∞Ë±°Ê∑±Âàª„ÄÇ\n\nÈô§‰∫Ü 32B Ê®°ÂûãÂ§ñÔºåËæÉÂ∞èÁöÑÊ®°ÂûãÂú®Ê®°ÂûãÂ§ßÂ∞èÊñπÈù¢‰πüË°®Áé∞Âá∫Ëâ≤„ÄÇÂ¶ÇÊûúÊÇ®ÁöÑËÆ°ÁÆóËÉΩÂäõ‰∏çË∂≥ÔºåÂèØ‰ª•Â∞ùËØï‰∏Ä‰∫õËæÉÂ∞èÁöÑÊ®°Âûã„ÄÇ‰æãÂ¶ÇÔºåÊàëÂú®Êñ∞Ê¨æÈÖçÂ§á M4 Â§ÑÁêÜÂô®Âíå 16GB RAM ÁöÑ Mac Mini ‰∏äÂ∞ùËØï‰∫Ü 14B Ê®°Âûã„ÄÇ\n\nÂú®Âü∫ÂáÜÂàÜÊï∞‰πãÂ§ñÔºåÂÖâÊ†áÁé∞Âú®ÂèØ‰ª•‰∏éÊúÄÊñ∞ÁöÑ Qwen Ê®°ÂûãÈõÜÊàêÔºåÂåÖÊã¨ Qwen 2\\.5\\-Coder\\-32B\\-Instruct Âíå OpenWebUI„ÄÇ\n\n‰ª•‰∏ãÊòØ‰ΩøÁî® Qwen 2\\.5\\-Coder\\-32B\\-InstructÔºàOllamaÔºâ‰∏é OpenWebUI ÁöÑÊà™ÂõæÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*q-Pq3snVhkBs3e_Oxj4_Xw.png)\n\nÊàëËø´‰∏çÂèäÂæÖÊÉ≥Âú®Êó•Â∏∏Â∑•‰Ωú‰∏≠‰ΩøÁî®ÂÆÉÔºÅ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84","frontmatter":{"title":"Qwen2.5 1.5bÔºöÁßªÂä®AIÁöÑÊú™Êù•Ôºü","meta_title":"Qwen2.5 1.5bÔºöÁßªÂä®AIÁöÑÊú™Êù•Ôºü","description":"ÈòøÈáå‰∫ëÊúÄÊñ∞ LLM ÁöÑÊú¨Âú∞ÊµãËØïÂíåËØÑ‰º∞„ÄÇ‰ΩøÁî® llama-cpp-python Âíå DIY ÊèêÁ§∫ÁõÆÂΩï„ÄÇ","date":"2024-10-30T12:57:39.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*awb56jkdXobA-Ip6d-QHRA.png","categories":["Natural Language Processing","Programming","Technology/Web"],"author":"Rifx.Online","tags":["Qwen2.5","NLP","summarization","retrieval","prompts"],"draft":false,"slug":"blog/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84"},"content":"\n### Êú¨Âú∞ÊµãËØïÂíåËØÑ‰º∞ÈòøÈáå‰∫ëÊúÄÊñ∞ÁöÑLLM„ÄÇ‰ΩøÁî®llama\\-cpp\\-pythonÂíåDIYÊèêÁ§∫ÁõÆÂΩï„ÄÇ\n\n\n\nÂú®Á¨¨‰∏ÄÈÉ®ÂàÜÔºåÊàë‰ª¨ÂÖ±ÂêåÊé¢ËÆ®‰∫ÜÈòøÈáå‰∫ëÂõ¢ÈòüÂèëÂ∏ÉÁöÑQwen2\\.5Ê®°ÂûãÁ≥ªÂàóÁöÑÂàõÊñ∞„ÄÇ\n\nÂú®ÁîüÊàêÂºèAIÂü∫ÂáÜÊµãËØï‰∏≠ÔºåÂü∫ÂáÜÊµãËØïÁé∞Âú®ÊòØ‰∏ªË¶ÅÁöÑ*oracle*ÔºöÊñ∞ÁöÑLLMÁöÑÊúâÊïàÊÄßÈúÄË¶ÅÈÄöËøáÂ§ö‰∏™ËØÑÂà§„ÄÇ‰Ω†ÊâìÁ†¥ÁöÑÂü∫ÂáÜËÆ∞ÂΩïË∂äÂ§öÔºå‰Ω†Â∞±Ë∂ä‰ºòÁßÄ„ÄÇ\n\nËøôÊòØËµ¢ÂæóSOTAÁ´ûËµõÁöÑÊñπÂºè„ÄÇ\n\nÂ•ΩÂêßÔºåÊàë‰∏çÂêåÊÑè„ÄÇÂ∞ΩÁÆ°Êàë‰ª¨ÈúÄË¶ÅÈáåÁ®ãÁ¢ëÂíåÊõ¥Â•ΩÁöÑÊÄßËÉΩÊù•Êé®Âä®AIËøõÊ≠•Ôºå‰ΩÜÁî®Êà∑‰ΩìÈ™åÂíå‰∏™‰∫∫ËßÇÁÇπ‰∏çËÉΩË¢´ËßÜ‰∏∫Êó†ÂÖ≥Á¥ßË¶Å„ÄÇ\n\nÊàëÁõ∏‰ø°ÔºåÂú®Êé¢Á¥¢‰∏Ä‰∫õÂ∏∏Áî®ÁöÑNLP‰ªªÂä°Êó∂ÔºåÊäõÂºÄËÅäÂ§©‰ΩìÈ™åÔºåÊàë‰ª¨ÂøÖÈ°ªÂÖ≥Ê≥®ÂõûÂ§çÁöÑË¥®Èáè„ÄÇÊàë‰ª¨ÊòØÂîØ‰∏ÄÈúÄË¶ÅÁöÑÂü∫ÂáÜ„ÄÇÊàë‰ª¨ÁöÑÁî®Êà∑‰ΩìÈ™åÊòØÂà§Êñ≠‰∏Ä‰∏™Ê®°ÂûãÊòØÂê¶‰ºòÁßÄÁöÑÊúÄ‰Ω≥ÊåáÊ†á„ÄÇÊ®°ÂûãÂøÖÈ°ªË∂≥Â§üÂèØÈù†Ôºå‰ª•‰æøÂú®Ëá™Âä®ÂåñÂ∑•‰ΩúÊµÅÁ®ã‰∏≠‰ΩøÁî®„ÄÇ\n\nÈ°∫‰æøÊèê‰∏Ä‰∏ãÔºåÊàëÂ∑≤ÁªèËøêË°å‰∫ÜÊàëÂÜ≥ÂÆöÁß∞‰πã‰∏∫[RBYF ‚Äî ‰∏éÊÇ®‰Ωú‰∏∫ÂèçÈ¶àÁöÑ‰øÆËÆ¢Âü∫ÂáÜ](https://open.substack.com/pub/thepoorgpuguy/p/rbyf-is-here-revised-benchmarks-with?r=i78xo&utm_campaign=post&utm_medium=web)ÁöÑÊµãËØïÔºåÂ£∞Áß∞ÊÉä‰∫∫ÁöÑLlama3\\.2‚Äì1B\\-instruct‚Ä¶ËÄåQwen2\\.5‚Äì1\\.5bÂàôÊõ¥Â•ΩÂæóÂ§öÔºÅ\n\nÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊ≠£Â¶ÇÊâøËØ∫ÁöÑÈÇ£Ê†∑ÔºåÊàë‰ª¨Â∞Ü‰∫≤Ëá™È™åËØÅËøô‰∏™Ê®°ÂûãÂú®Êó•Â∏∏‰ΩøÁî®‰∏≠ÁöÑË°®Áé∞ÊúâÂ§öÂ•Ω„ÄÇ\n\nÂõûÂà∞Êàë‰ª¨Ëá™Â∑±‚Ä¶‚Ä¶ËÆ©Êàë‰ª¨ÂºÄÂßãÂêßÔºÅ\n\n## ÈúÄÊ±Ç\n\nÂú®ËøôÈáåÔºåÊàë‰ª¨Â∞ÜÊûÑÂª∫‰∏Ä‰∏™ÊúÄÂ∞èÁöÑÊñáÊú¨Êé•Âè£Ôºå‰ª•‰æøËÉΩÂ§üËøêË°åÊ®°Âûã„ÄÅÊµãËØï‰∏çÂêåÁöÑ‰ªªÂä°Âπ∂Á≠âÂæÖÁî®Êà∑ÂèçÈ¶à‰ª•ËøõË°åËØÑ‰º∞„ÄÇ\n\nÈúÄÊ±ÇÂæàÁÆÄÂçïÔºå‰ΩÜÊàëÂª∫ËÆÆÊÇ®ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÈ°πÁõÆÁõÆÂΩïÂíå‰∏Ä‰∏™ËôöÊãüÁéØÂ¢É„ÄÇ\n\nÂàõÂª∫‰∏Ä‰∏™ `venv`ÔºàÈúÄË¶Å Python 3\\.11\\+ÔºâÔºöÊàëÂú®ËøêË°å Windows 11 ÁöÑËø∑‰Ω†ÁîµËÑë‰∏äËøõË°å‰∫ÜÊµãËØï„ÄÇ\n\n```python\n## create the virtual environment\npython -m venv venv\n## activate the venv\nvenv\\Scripts\\activate\n## Install the dependencies \npip install llama-cpp-python==0.3.0 tiktoken\n```\n\nÊàë‰ª¨ÈúÄË¶Å‰ªé Hugging Face ÁöÑÂÆòÊñπ qwen ‰ªìÂ∫ì‰∏ãËΩΩ GGUF Êñá‰ª∂ [https://huggingface.co/Qwen/Qwen2\\.5\\-1\\.5B\\-Instruct\\-GGUF](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF)ÔºöÊàë‰ΩøÁî®‰∫Ü `qwen2.5-1.5b-instruct-q5_k_m.gguf` ÁâàÊú¨„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YtQJb_xyq_xcF40yRWPcZA.png)\n\n‰∏ÄÂàáÂáÜÂ§áÂ∞±Áª™ÔºÅ\n\nÊ≥®ÊÑèÔºöÂ¶ÇÊûúÊÇ®ÊÉ≥Ê∑ªÂä†ÂØπ GPU Âä†ÈÄüÂô®ÁöÑ‰∏çÂêåÂêéÁ´ØÊîØÊåÅÔºåÂèØ‰ª•ÊåâÁÖß [‰ªìÂ∫ì‰∏≠ÁöÑËØ¥Êòé](https://github.com/abetlen/llama-cpp-python#supported-backends) ËøõË°åÊìç‰Ωú„ÄÇ‰æãÂ¶ÇÔºåÊàë‰ΩøÁî®‰∫Ü Vulkan ÊîØÊåÅÔºåÂõ†Ê≠§Âú® pip ÂÆâË£Ö‰πãÂâçÊàëÊ∑ªÂä†‰∫ÜÁéØÂ¢ÉÂèòÈáè\n\n```python\n## Vulkan support - for Windows\n$env:CMAKE_ARGS = \"-DGGML_VULKAN=on\"\n```\n\n## ‰ª£Á†Å ‚Äî ‰∏ªÂ∫îÁî®Á®ãÂ∫èÂíåÂ∫ì\n\n‰∏∫‰∫Ü‰øùÊåÅ‰ª£Á†ÅÁöÑÁÆÄÊ¥ÅÔºåÊàëÂÜ≥ÂÆö‰ΩøÁî®Â§ñÈÉ®Â∫ìÊâ©Â±ï‰∏Ä‰∫õÂäüËÉΩ„ÄÇÂ•ΩÂêßÔºåËøôÊòØ‰∏Ä‰∏™Ëá™Âä©Â∫ìÔºåÊâÄ‰ª•ËøôÈáåÊ≤°ÊúâÁßòÂØÜ„ÄÇ\n\nÊÇ®ÂèØ‰ª•Âú®ÊàëÁöÑÊñáÁ´†‰∏≠ÊâæÂà∞ÊâÄÊúâÁªÜËäÇÔºö\n\n‰∏∫‰∫ÜÂä†Âø´ÈÄüÂ∫¶ÔºåÊÇ®ÂèØ‰ª•Áõ¥Êé• [‰ªéËøôÈáå‰∏ãËΩΩÊñá‰ª∂](https://github.com/fabiomatricardi/YouAreTheBenchmark/raw/main/QWEN2.5-1.5B/promptLibv2Qwen.py)ÔºöÂÆÉÂåÖÂê´‰∫Ü‰∏äËø∞ÊñáÁ´†‰∏≠ËÆ®ËÆ∫ÁöÑ `promptLib` ÁöÑÁâàÊú¨ 2ÔºàÂêç‰∏∫ `promptLibv2Qwen.py`ÔºåÂØπ `Qwen2.5-1.5B-instruct` Ê®°ÂûãÁöÑÊèêÁ§∫ËøõË°å‰∫ÜÂ∞ëÈáèÂæÆË∞ÉÔºâ„ÄÇ\n\nÂ∞ÜÊñá‰ª∂‰øùÂ≠òÂú®‰∏ªÁõÆÂΩï‰∏≠ÔºåÂπ∂ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ `main.py` ÁöÑÊñ∞Êñá‰ª∂„ÄÇ\n\n```python\n## Chat with an intelligent assistant in your terminal  \n## MODEL: https://huggingface.co/Qwen\n## qwen2.5-1.5b-instruct-q5_k_m.gguf\nimport sys\nfrom time import sleep\nimport warnings\nwarnings.filterwarnings(action='ignore')\nimport datetime\nfrom promptLibv2Qwen import countTokens, writehistory, createCatalog\nfrom promptLibv2Qwen import genRANstring, createStats\nimport argparse\n### PREPARING FINAL DATASET\npd_id = []\npd_task = []\npd_vote = []\npd_remarks = []\n####################Add GPU argument in the parser###################################\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-g\", \"--gpu\", type=int, default=0,nargs='?',\n                    help=\"The number of layers to load on GPU\")\nargs = parser.parse_args()\nif args.gpu == None:\n   ngpu_layers = 0 \nelse:\n    ngpu_layers = args.gpu\nprint(f'Selected GPU: offloading {ngpu_layers} layers...')   \n####################INITIALIZE THE MODEL###################################\nstops = ['<!im_end|>']\ntasks = createCatalog()\nmodelname = 'qwen2.5-1.5b-instruct-q5_k_m.gguf'\n## create THE LOG FILE \ncoded5 = genRANstring(5)\nlogfile = f'logs/Qwen2.5-1.5B-it_CPP_{coded5}_log.txt'\ncsvfile = f'logs/Qwen2.5-1.5B-it_CPP_{coded5}.csv'\nlogfilename = logfile\n#Write in the history the first 2 sessions\nwritehistory(logfilename,f'{str(datetime.datetime.now())}\\n\\nYour own LocalGPT with üíª {modelname}\\n---\\nüß†ü´°: You are a helpful assistant.')  \nwritehistory(logfilename,f'üíª: How can I assist you today in writing?')\n```\n\nÂú®ËøôÈáåÔºåÊàë‰ª¨Âè™ÊòØÂú®ÂÅöÂáÜÂ§áÔºöÊàë‰ª¨ÂØºÂÖ•Â∫ìÔºåÂåÖÊã¨Êàë‰ª¨Ëá™Â∑±ÁöÑ `promptLibv2Qwen` ‰ª•Âèä `argparse`„ÄÇÊàëÊÉ≥Â∞ùËØï‰∏Ä‰∫õÊñ∞‰∏úË•øÔºö[argparse](https://realpython.com/command-line-interfaces-python-argparse/) ÊòØ‰∏Ä‰∏™Áî®‰∫éÁªàÁ´Ø Python Á®ãÂ∫èÁöÑ Python Â∫ìÔºåÊÇ®ÂèØ‰ª•‰ªéÂëΩ‰ª§Ë°åËØªÂèñÂ§ö‰∏™ÂèÇÊï∞„ÄÇ\n\nÂú®ËøôÈáåÔºåÊàë‰ª¨Âè™Êúâ‰∏Ä‰∏™ÂèÇÊï∞ÔºàÊ≤°ÊúâÂèÇÊï∞ÔºâÔºåÂ∏¶ÊúâÊ†áÂøó `-g` Êàñ `--gpu`„ÄÇÂΩìÊÇ®‰ΩøÁî®Ê≠§ÂèÇÊï∞ËøêË°å Python ‰ª£Á†ÅÊó∂ÔºåÊàë‰ª¨Â∞ÜËÆæÁΩÆ GPU Â±ÇÁöÑÊï∞Èáè‰∏∫ÊúÄÂ§ßÂÄºÔºà‰ΩÜÊÇ®ÂèØ‰ª•Ëá™Ë°åÊõ¥ÊîπÔºâ„ÄÇ\n\nÁÑ∂ÂêéÔºåÊàë‰ª¨ËÆæÁΩÆ‰∏Ä‰∫õÂÖ®Â±ÄÂèòÈáèÔºåË∑®Êï¥‰∏™‰ª£Á†Å‰ΩøÁî®Ôºö‰ªªÂä°„ÄÅÊàë‰ª¨ÁöÑÊèêÁ§∫ÈõÜÂêà„ÄÅÂÅúÊ≠¢ËØçÂíåÊó•ÂøóÊñá‰ª∂Âêç„ÄÇ\n\n> Ê≥®ÊÑèÔºöÊâÄÊúâÊó•ÂøóÈÉΩ‰øùÂ≠òÂú®Âêç‰∏∫ `logs` ÁöÑÂ≠êÁõÆÂΩï‰∏≠‚Ä¶‚Ä¶ÊâÄ‰ª•ËØ∑Á°Æ‰øùÂàõÂª∫‰∏Ä‰∏™„ÄÇ\n\nÊàë‰ª¨ËøòÂáÜÂ§á‰∫ÜÊâÄÊúâÁõ∏ÂÖ≥‰ø°ÊÅØÔºå‰ª•‰æøÂ∞ÜÂÖ∂Â≠òÂÇ®Âà∞Êï∞ÊçÆÈõÜ‰∏≠ÔºåÁÑ∂ÂêéÊúÄÁªà‰øùÂ≠òÂà∞ CSV Êñá‰ª∂‰∏≠Ôºà‰ª•‰æøËΩªÊùæÂàõÂª∫ÊÄßËÉΩÁü©ÈòµÔºâ„ÄÇ\n\n```python\n### PREPARING FINAL DATASET\npd_id = []\npd_task = []\npd_vote = []\npd_remarks = []\n```\n\nÁÑ∂ÂêéÔºåÊàë‰ª¨‰ΩøÁî® Llama\\-CPP\\-python Â∞ÜÊ®°ÂûãÂä†ËΩΩÂà∞ RAMÔºàÊ≤°Êúâ GPUÔºâÊàñ VRAMÔºà‰ΩøÁî® GPUÔºâ‰∏≠„ÄÇ\n\n```python\n## LOAD THE MODEL\nprint(\"\\033[95;3;6m\")\nprint(\"1. Waiting 10 seconds for the API to load...\")\nfrom llama_cpp import Llama\nllm = Llama(\n            model_path='models/qwen2.5-1.5b-instruct-q5_k_m.gguf',\n            n_gpu_layers=ngpu_layers,\n            temperature=0.1,\n            n_ctx=8192,\n            max_tokens=1500,\n            repeat_penalty=1.178,\n            stop=stops,\n            verbose=False,\n            )\nprint(f\"2. Model {modelname} loaded with LlamaCPP...\")\nprint(\"\\033[0m\")  #reset all\nhistory = []\nprint(\"\\033[92;1m\")\nprint(f'üìùLogfile: {logfilename}')\n```\n\nÈ°∫‰æøËØ¥‰∏ÄÂè•ÔºåÊÇ®ÂèØ‰ª•Âú®ÊàëÁöÑ GitHub ‰ªìÂ∫ì‰∏≠ÊâæÂà∞ÊâÄÊúâ‰ª£Á†ÅÔºö\n\n‰∏ã‰∏Ä‰∏™ÊòØ‰∏ÄÊ¨°ÊÄßÁÉ≠Ë∫´Êé®ÁêÜÔºöÊ®°ÂûãÁ•ûÁªèÁΩëÁªúÂ∞ÜÈ¶ñÊ¨°ÊøÄÊ¥ªÔºåÊâÄ‰ª•ÂèØ‰ª•ÊääÂÆÉÁúã‰ΩúÊòØÁÉ≠Ë∫´Âúà„ÄÇ\n\n‰∏çË¶ÅÂÆ≥ÊÄïÔºåÊàë‰ºöËß£Èáä‰ª£Á†Å„ÄÇ\n\n```python\n##################### ALIGNMENT FIRST GENERATION ##############################################\nquestion = 'Explain the plot of Cinderella in a sentence.'\ntest = [\n    {\"role\": \"user\", \"content\": question}\n]\nprint('Question:', question)\nstart = datetime.datetime.now()\nprint(\"üíª > \", end=\"\", flush=True)\nfull_response = \"\"\nfisrtround = 0\nfor chunk in llm.create_chat_completion(\n    messages=test,\n    temperature=0.25,\n    repeat_penalty= 1.31,\n    stop=stops,\n    max_tokens=1500,\n    stream=True,):\n    try:\n        if chunk[\"choices\"][0][\"delta\"][\"content\"]:\n            if fisrtround==0:\n                print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]\n                ttftoken = datetime.datetime.now() - start  \n                fisrtround = 1\n            else:\n                print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]                            \n    except:\n        pass      \ndelta = datetime.datetime.now() - start\noutput = full_response\nprint('')\nprint(\"\\033[91;1m\")\nrating = input('Rate from 0 (BAD) to 5 (VERY GOOD) the quality of generation> ')\nprint(\"\\033[92;1m\")\nstats = createStats(delta,question,output,rating,logfilename,'Alignment Generation',ttftoken)\nprint(stats)\nwritehistory(logfilename,f'''üë®‚Äçüíª . {question}\nüíª > {output}\n{stats}\n''')\n```\n\nÊàë‰ª¨ËÆæÁΩÆ‰∫ÜÁ¨¨‰∏Ä‰∏™Áî®Êà∑ÈóÆÈ¢òÔºåÂπ∂Â∞ÜÂÖ∂ÊîæÂÖ•‰∏Ä‰∏™‰ºóÊâÄÂë®Áü•ÁöÑËÅäÂ§©Ê†ºÂºèÂ≠óÂÖ∏‰∏≠„ÄÇÁÑ∂ÂêéÊàë‰ª¨ÂºÄÂßãËÆ°Êó∂ÔºàÂØπÈÄüÂ∫¶„ÄÅ‰ª§ÁâåËÆ°Êï∞Á≠âÂæàÊúâÁî®‚Ä¶‚Ä¶Ôºâ„ÄÇ\n\nÊàë‰ª¨Ë∞ÉÁî®Êé®ÁêÜÊñπÊ≥ï `create_chat_completion()`ÔºåÂÖÅËÆ∏Êàë‰ª¨‰ª•ËÅäÂ§©Ê†ºÂºèÊé•ÂèóÊèêÁ§∫ÔºåÂπ∂ÈÄê‰∏™‰ª§ÁâåÊµÅÂºèËæìÂá∫ÁªìÊûú„ÄÇ\n\nÁî±‰∫éÊ®°ÂûãÁöÑÁ¨¨‰∏ÄÊ¨°ÂõûÂ§ç‰∏çÂåÖÂê´‰ªª‰ΩïËæìÂá∫‰ª§ÁâåÔºà‰ªÖÂåÖÂê´ÁªüËÆ°‰ø°ÊÅØÔºâÔºåÊàë‰ª¨‰ΩøÁî®‰∫Ü try/except ËØ≠Âè•„ÄÇÊ≠§Â§ñÔºåÁî±‰∫éÊàëÊÉ≥Áü•ÈÅì‰ΩïÊó∂ÁîüÊàêÁ¨¨‰∏Ä‰∏™‰ª§ÁâåÔºåÊàë‰ª¨ËÆæÁΩÆ‰∫Ü‰∏Ä‰∏™Ê†áÂøóÂπ∂ÊöÇÊó∂ÂÅúÊ≠¢ËÆ°Êó∂ÔºåÂ∞Ü‰ø°ÊÅØ‰øùÂ≠òÂú® `ttftoken` ÂèòÈáè‰∏≠„ÄÇ\n\nÂú®ÊµÅÂºèËæìÂá∫ÁªìÊùüÊó∂ÔºåÊàë‰ª¨ËÆ°ÁÆó‰ªéÂºÄÂßãÂà∞Áé∞Âú®ÁöÑÊó∂Èó¥Â∑ÆÔºåÂπ∂Á≠âÂæÖÁî®Êà∑Êèê‰æõÂØπÁîüÊàêËæìÂá∫ÁöÑ‰∏™‰∫∫ÂèçÈ¶àÔºö‰ªé 0 Âà∞ 5 ËØÑÂàÜÔºåÂπ∂Ê∑ªÂä†‰∏éÊåá‰ª§ÊèêÁ§∫ÂíåÁî®Êà∑ÊÑèÂõæÁöÑ‰∏ÄËá¥ÊÄßÁõ∏ÂÖ≥ÁöÑËØÑËÆ∫„ÄÇ\n\nÊàë‰ª¨‰ΩøÁî®ÂÜÖÈÉ®Â∫ì `createStats()` Êù•ÊâìÂç∞ÁîüÊàêÁöÑÊâÄÊúâÁªüËÆ°‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂‰øùÂ≠òÂà∞Êó•ÂøóÊñá‰ª∂‰∏≠„ÄÇËØ•ÂáΩÊï∞ÁöÑËæìÂá∫Â∞ÜÁ±ª‰ºº‰∫é‰ª•‰∏ãÂÜÖÂÆπÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8znYCqpisviXvYgrzjWF5w.png)\n\n## ÊèêÁ§∫ÁõÆÂΩï ‚Äî Êàë‰ª¨ÊÉ≥Ë¶ÅÊµãËØïÁöÑÂÜÖÂÆπ\n\nÊàëÂú®ËøôÈáåÂÜô‰∫ÜÊàëÁöÑ‰π†ÊÉØ„ÄÇÊàëÊúâ‰∏Ä‰∏™ÊèêÁ§∫ÁõÆÂΩïÔºåÊ∂µÁõñ‰∫ÜËÅäÂ§©Êú∫Âô®‰∫∫‰∏≠‰ΩøÁî®ÁöÑËÆ∏Â§ö‰∏ªË¶ÅËØ≠Ë®Ä‰ªªÂä°Ôºå‰æãÂ¶ÇÊÄªÁªì„ÄÅÁÆÄÁü≠ÊÄªÁªì„ÄÅÈöèÊÑèËÅäÂ§©„ÄÅRAG„ÄÅÁúüÂÆûRAGÁ≠âÁ≠â„ÄÇ\n\nËøô‰∏™ÊÉ≥Ê≥ïÊòØËÉΩÂ§üÂú®5ÂàÜÈíüÂÜÖÂä†ËΩΩÊ®°ÂûãÔºåÂπ∂ÂºÄÂßãËØÑ‰º∞ÊØè‰∏™‰ªªÂä°„ÄÇÂú®ÊØèÊ¨°ÁîüÊàêÁªìÊùüÊó∂ÔºåÁî®Êà∑‰ºöË¢´ÊèêÁ§∫ÁªôÂá∫‰∏Ä‰∏™ÂàÜÊï∞Ôºà‰ªé0Âà∞5ÁöÑËØÑÂàÜÔºâÂπ∂Âú®ÈúÄË¶ÅÊó∂Áïô‰∏ã‰ªª‰ΩïËØÑËÆ∫„ÄÇ\n\nËøôÂæàÂÖ≥ÈîÆÔºöÂπ∂‰∏çÊòØÊâÄÊúâÊ®°ÂûãÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑÔºåÂØπÊèêÁ§∫‰∏≠ÁöÑÊé™ËæûËøõË°åÂ∞èÁöÑÊàñÂ§ßÁöÑË∞ÉÊï¥ÊÄªÊòØÂøÖÈúÄÁöÑ„ÄÇ\n\nÈÇ£‰πàÂõûÂà∞‰ª£Á†Å‚Ä¶‚Ä¶Âõ†‰∏∫‰πãÂâçÁöÑ‰ª£Á†ÅÂè™ÊòØÁÉ≠Ë∫´ÔºåÁé∞Âú®Â∞ÜÂºÄÂßãÁúüÊ≠£ÁöÑwhileÂæ™ÁéØÔºåÈÅçÂéÜÊï¥‰∏™ÊèêÁ§∫ÁõÆÂΩï„ÄÇËØ∑ÂèÇËßÅ‰∏ãÈù¢ÁöÑÂ∑•‰ΩúÊµÅÁ®ã‚Ä¶‚Ä¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*EL0Q97Du6HwtcYQZ.png)\n\n‰ª£Á†Å‰∏≠Âè™ÊúâÂ∞ëÈáèÊõ¥ÊîπÔºåÊàë‰ºöÊåáÂá∫Ëøô‰∫õÊõ¥ÊîπÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ„ÄÇ\n\n```python\n############################# AUTOMATIC PROMPTING EVALUATION  11 TURNS #################################\nid =1\nfor items in tasks:\n    fisrtround = 0\n    task = items[\"task\"]\n    prompt = items[\"prompt\"]\n    test = []\n    print(f'NLP TAKS>>> {task}')\n    print(\"\\033[91;1m\")  #red\n    print(prompt)\n    test.append({\"role\": \"user\", \"content\": prompt})\n    print(\"\\033[92;1m\")\n    full_response = \"\"\n    start = datetime.datetime.now()\n    print(\"üíª > \", end=\"\", flush=True)\n    for chunk in llm.create_chat_completion(\n        messages=test,\n        temperature=0.15,\n        repeat_penalty= 1.31,\n        stop=stops,\n        max_tokens=1500,\n        stream=True,):\n        try:\n            if chunk[\"choices\"][0][\"delta\"][\"content\"]:\n                if fisrtround==0:\n                    print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                    full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]\n                    ttftoken = datetime.datetime.now() - start  \n                    fisrtround = 1\n                else:\n                    print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n                    full_response += chunk[\"choices\"][0][\"delta\"][\"content\"]                            \n        except:\n            pass      \n    delta = datetime.datetime.now() - start\n    print('')\n    print(\"\\033[91;1m\")\n    rating = input('Rate from 0 (BAD) to 5 (VERY GOOD) the quality of generation> ')\n    print(\"\\033[92;1m\")\n    stats = createStats(delta,prompt,full_response,rating,logfilename,task,ttftoken)\n    print(stats)\n    writehistory(logfilename,f'''üë®‚Äçüíª > {prompt}\nüíª > {full_response}\n{stats}\n''')\n    pd_id.append(id)\n    pd_task.append(task)\n    pd_vote.append(rating[:2])\n    pd_remarks.append(rating[2:])\n    id += 1\n## create dataframe and save to csv\nzipped = list(zip(pd_id,pd_task,pd_vote,pd_remarks))\nimport pandas as pdd\ndf = pdd.DataFrame(zipped, columns=['#', 'TASK', 'VOTE','REMARKS'])\n#saving the DataFrame as a CSV file \ndf_csv_data = df.to_csv(csvfile, index = False, encoding='utf-8') \nprint('\\nCSV String:\\n', df_csv_data)  \n```\n\n‰∏ªË¶ÅÊõ¥Êîπ‰ªÖÂú®ÂâçÂá†Ë°åÔºö\n\n```python\nfor items in tasks:\n    fisrtround = 0\n    task = items[\"task\"]\n    prompt = items[\"prompt\"]\n```\n\nÂ¶ÇÊûú‰Ω†ÈòÖËØª‰∫ÜÂÖ≥‰∫é`promptLib`ÁöÑÊñáÁ´†Ôºå‰Ω†Â∫îËØ•‰∏ç‰ºöÊÑüÂà∞ÊÉäËÆ∂Ôºö‰ΩÜÂ¶ÇÊûú‰Ω†ÊòØÊñ∞ÊâãÔºåËøôÈáåÊàë‰ª¨Ê≠£Âú®ÈÅçÂéÜ‰∏Ä‰∏™Â≠óÂÖ∏ÂàóË°®ÔºåÂÖ∑Êúâ‰ª•‰∏ãÁªìÊûÑÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rGcKJWNzSUrcu4wi.png)\n\nÂõ†Ê≠§ÔºåÂØπ‰∫éÁõÆÂΩï‰∏≠ÁöÑÊØè‰∏™Êù°ÁõÆÔºàÊÑèÂë≥ÁùÄ‰ªªÂä°ÂíåÊèêÁ§∫ÁöÑÂØπÔºâÔºåÊàë‰ª¨ÊèêÂèñ‰ªªÂä°ÊèèËø∞Âíå‰ªªÂä°ÊèêÁ§∫„ÄÇ\n\n```python\ntest.append({\"role\": \"user\", \"content\": prompt})\n```\n\nÁÑ∂ÂêéÊàë‰ª¨Âú®‰∏Ä‰∏™‰∏¥Êó∂ÂàóË°®`test`‰∏≠ÂàõÂª∫ËÅäÂ§©Ê®°ÊùøÊ∂àÊÅØÔºåÂπ∂Â∞ÜÂÖ∂‰º†ÈÄíÁªô`create_chat_template()`ÊñπÊ≥ïËøõË°åÁîüÊàê„ÄÇ\n\nÂÖ∂‰ªñÂÜÖÂÆπÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇ\n\n‰øùÂ≠òÊñá‰ª∂ÔºåÂπ∂Âú®ÊøÄÊ¥ª`venv`ÁöÑÊÉÖÂÜµ‰∏ãËøêË°åÔºö\n\n```python\npython main.py\n## Â¶ÇÊûú‰Ω†‰ΩøÁî®ÁöÑÊòØGPUÔºåËøêË°å python main.py -g\n```\n\nËøôÂ∞Ü‰∏∫‰Ω†Êèê‰æõÁ±ª‰ºº‰∫é‰∏ãÈù¢Á§∫‰æãÁöÑÂÜÖÂÆπ‚Ä¶‚Ä¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MhhQu4lLjtU__Wjf0dSWBg.gif)\n\nËØ∑Ê≥®ÊÑèÔºåÂú®Êï¥‰∏™ÊèêÁ§∫ÁõÆÂΩïÁöÑÊú´Â∞æÔºå‰ºöÂàõÂª∫‰∏Ä‰∏™*csv*Êñá‰ª∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊâÄÊúâ‰ªªÂä°ÁöÑÊëòË¶ÅÔºÅ\n\n## ÊµãËØïÊ¶ÇËø∞\n\nÊàë‰ΩøÁî®‰∫ÜÂá†‰∏™Â∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÔºå‰ªé [Qwen2‚Äì1\\.5B\\-instruct](https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF) Âà∞ [Gemma2‚Äì2B\\-instruct](https://huggingface.co/bartowski/gemma-2-2b-it-GGUF)ÔºåÂÜçÂà∞ [Llama3\\.2‚Äì1B\\-instruct](https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF)ÔºåÊúÄÂêéÊòØÊñ∞ÁöÑ [Qwen2\\.5‚Äì1\\.5B\\-instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF)„ÄÇ\n\nËôΩÁÑ∂ÊàëÂØπ [Llama3\\.2‚Äì1B\\-instruct](https://generativeai.pub/llama3-2-1b-instruct-is-ok-but-not-good-enough-28f88046b63e) ÊÑüÂà∞Áõ∏ÂΩìÂ§±ÊúõÔºå‰ΩÜÂØπÊñ∞ÁöÑ [Qwen2\\.5‚Äì1\\.5B\\-instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF) ÁöÑÂá∫Ëâ≤Ë°®Áé∞ÊÑüÂà∞ÊÉäËÆ∂„ÄÇ\n\nÂú®ÊØèÊ¨°ÁîüÊàêÁªìÊùüÊó∂ÔºåÁî®Êà∑‰ºöË¢´Ë¶ÅÊ±ÇÁî® 0 Âà∞ 5 ‰πãÈó¥ÁöÑÂàÜÊï∞Êù•ËØÑ‰º∞ÁªìÊûú„ÄÇ**Âú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÁî®Êà∑Â∞±ÊòØÊàë‚Ä¶‚Ä¶**\n\nËøôÁßçÂÆöÊÄßÂàÜÊûêÁ°ÆÂÆûËæÉ‰∏∫ÁÆÄÂçïÔºåÂõ†Ê≠§ÊØè‰∏™ÂàÜÊï∞ÈÉΩÊúâÁõ∏Â∫îÁöÑÊèèËø∞ÔºåÁî®Êà∑ÂèØ‰ª•Ê∑ªÂä†ËØÑËÆ∫Ôºà‚Äú‰∏Ä‰∫õÈîôËØØ‰ø°ÊÅØ‚ÄùÔºå‚ÄúÂèØËÉΩÊõ¥Â•ΩÂú∞Êõ¥ÊîπÊèêÁ§∫‰∏≠ÁöÑÊé™Ëæû‚ÄùÔºâ\n\nËøôÈáåÊòØÂÆöÊÄßÁü©ÈòµÂèäÂÖ∂ÊèèËø∞\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*eBdPfZtfr99MsvLh6tt42w.png)\n\n## Â•Ω‰∏éÂùè ‚Äî ÁªÜËäÇ\n\nÊÄªÁªìÈùûÂ∏∏Âá∫Ëâ≤„ÄÇÂàóÂá∫ÈïøÊñáÊú¨ÁöÑ‰∏ªË¶Å‰∏ªÈ¢ò‰πüÈùûÂ∏∏Â•Ω„ÄÇ\n\nRAG ‰ªªÂä°Áõ∏ÂΩìÂø´ÈÄüÔºàÂç≥‰ΩøÂú®ÊàëÁöÑËø∑‰Ω† PC ‰∏äÔºâÔºåÁúüÂÆûÁöÑ RAGÔºàÂú®‰∏ä‰∏ãÊñá‰πãÂ§ñÊèêÈóÆÔºâ‰πüÂæàÂà∞‰Ωç„ÄÇ\n\nÊâÄ‰ª•ÁúüÁöÑÂæàÂ•Ω„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DuV3LJep_PuDqiCcAMb6Cg.png)\n\n‰∏çËøá‰πüÊúâ‰∏Ä‰∫õ‰∏çË∂≥‰πãÂ§ÑÔºöÂç≥‰ΩøÊ∏©Â∫¶Âè™Êúâ `0.15`ÔºåÊàëÂú®‰∏§Âè•ÊÄªÁªì‰ªªÂä°‰∏≠‰πüÂæóÂà∞‰∫Ü‰∫õËôöÊûÑÁöÑ‰ø°ÊÅØ„ÄÇËøô‰∏çÂ•Ω„ÄÇ\n\n> ÊàëÂ∏åÊúõÈÄöËøáÁ®çÂæÆË∞ÉÊï¥ÊèêÁ§∫ÔºåÊàñËÄÖÂ∞ÜÊ∏©Â∫¶ËÆæ‰∏∫ `0` ÂèØ‰ª•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ\n\nÂè¶‰∏Ä‰∏™‰∫ãÂÆûÊòØÔºåÂàõÊÑèÂÜô‰ΩúÁõ∏ÂΩìÁ≥üÁ≥ïÔºöÂú®ÊµãËØï‰∏≠ÔºåÊàë‰ΩøÁî®‰∫Ü‰∏Ä‰∫õÂõ∫ÂÆöÁöÑÁîüÊàêÂèÇÊï∞„ÄÇ\n\n```python\n        temperature=0.15,\n        repeat_penalty= 1.31,\n```\n\nÂØπ‰∫éÂàõÊÑèÂÜô‰ΩúÔºå‰ΩøÁî® Qwen2\\.5‚Äì1\\.5B\\-instruct Êó∂ÔºåÊàë‰ª¨Â∫îËØ•‰ΩøÁî®Êõ¥È´òÁöÑ `repeat_penalty` ÂíåÊõ¥È´òÁöÑ `temperature`„ÄÇ\n\nÈ°∫‰æøÊèê‰∏Ä‰∏ãÔºåÊàëÂøÖÈ°ªËØ¥ÂèçÊÄùÊèêÁ§∫‰πüÂπ∂‰∏çÂ∑ÆÔºÅÊ†áÁ≠æÁöÑÂºÄÈó≠Ê≤°Êúâ‰øùÊåÅÔºàÂõ†Ê≠§‰∏çÊòìÂ∞ÜÂÖ∂ÊîæÂÖ•ÁÆ°ÈÅìÊàñÂ∑•‰ΩúÊµÅ‰∏≠ÔºâÔºå‰ΩÜÁîüÊàêÁöÑÊï¥‰ΩìÊµÅÁ®ãÂíå‚ÄúÊÄùÁª¥Èìæ‚ÄùÊé®ÁêÜËøáÁ®ãÁõ∏ÂΩì‰∏çÈîô„ÄÇ\n\n```python\n<thinking>\n‰ΩøÁî®ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÂú®ÊïôÂ≠¶‰∏≠ÁöÑÈáçË¶ÅÊÄß‰∏çÂÆπÂ∞èËßëÔºåÂõ†‰∏∫ËøôÈ°πÊäÄÊúØÂú®ÂΩìÂâçÊïôËÇ≤ÂÆûË∑µ‰∏≠ÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩúÂäõÔºåÂêåÊó∂‰πüÊúâÂä©‰∫éÂ°ëÈÄ†Êõ¥ÂÖ∑ÂàõÊñ∞ÊÄßÁöÑÁªàË∫´Â≠¶‰π†ÊñπÊ≥ï„ÄÇ\n</thinking>\n\n**ÊÄùÁª¥ÈìæÔºö**\n1. **ÁêÜËß£ÂΩ±Âìç**ÔºöAIÂèØ‰ª•Ëá™Âä®ÂåñÈáçÂ§çÊÄß‰ªªÂä°ÔºåÂπ∂Ê†πÊçÆÂ≠¶ÁîüÁöÑË°®Áé∞Êï∞ÊçÆÊèê‰æõ‰∏™ÊÄßÂåñÂèçÈ¶àÔºà‰æãÂ¶ÇÔºåÈÄöËøáËÅäÂ§©Êú∫Âô®‰∫∫ÊàñËá™ÈÄÇÂ∫îËØÑ‰º∞Ôºâ„ÄÇ\n2. **Â¢ûÂº∫Â≠¶‰π†‰ΩìÈ™å**ÔºöÈÄöËøáÊï¥ÂêàÁîüÊàêÊÄßAIÔºåÊïôÂ∏àÂèØ‰ª•ÂàõÂª∫Êõ¥ÂÖ∑Âê∏ÂºïÂäõÁöÑËØæÁ®ãÔºå‰ª•Êª°Ë∂≥Â§öÊ†∑ÂåñÁöÑÂ≠¶‰π†È£éÊ†º„ÄÇ\n3. **ÊîπÂñÑÂ≠¶ÁîüÊàêÊûú**Ôºö‰∏™ÊÄßÂåñÊïôÂ≠¶ÂèØ‰ª•Â∏ÆÂä©Â≠¶ÁîüÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåËÆ∞ÂøÜÁü•ËØÜ„ÄÇ\n\n**ÂèçÊÄùÔºö**\n- Â∞ÜÁîüÊàêÊäÄÊúØÊï¥ÂêàÂà∞ÊïôËÇ≤‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÂõ†‰∏∫Ëøô‰∏éÊó•ÁõäÊàê‰∏∫Êï∞Â≠óÂéü‰ΩèÊ∞ëÁöÑÂ≠¶‰π†ËÄÖÁöÑ‰∏çÊñ≠ÂèòÂåñÁöÑÈúÄÊ±ÇÁõ∏‰∏ÄËá¥ÔºåÈúÄË¶Å‰∏ÄÁßçÂ∞ÜËøô‰∫õÊäÄÊúØÁ∫≥ÂÖ•ÂÖ∂‰∏≠ÁöÑÊïôÂ≠¶ÊñπÊ≥ï„ÄÇ\n</thinking>\n\n<output>\nÊïôÂ∏àÂ∫îÂ≠¶‰π†Â¶Ç‰ΩïÂà©Áî®ÁîüÊàêÊÄßAIÊù•Â¢ûÂº∫‰ªñ‰ª¨ÁöÑÊïôÂ≠¶ÊñπÊ≥ïÂπ∂ÊîπÂñÑÂ≠¶ÁîüÊàêÊûú„ÄÇËøôÂåÖÊã¨ÁêÜËß£ÂÖ∂Âú®Ëá™Âä®Âåñ‰ªªÂä°ÔºàÂ¶ÇËØÑÂàÜÊàñÂàõÂª∫‰∏™ÊÄßÂåñÂ≠¶‰π†Ë∑ØÂæÑÔºâÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇ\n\n**Â≠¶‰π†Ë∑ØÂæÑÔºö**\n1. **ÊïôËÇ≤ÊäÄÊúØÂü∫Á°ÄËØæÁ®ã**ÔºöÈ¶ñÂÖàÂ≠¶‰π†Êèê‰æõÊïôËÇ≤ÊäÄÊúØÊ¶ÇËø∞ÁöÑËØæÁ®ãÔºåÂåÖÊã¨Êï∞Â≠óÂ∑•ÂÖ∑ÁöÑÂü∫Á°ÄÁü•ËØÜ„ÄÇ\n2. **AIÂü∫Á°ÄËØæÁ®ãÔºàCourseraÔºâ** - ÈÄöËøáCourseraÁöÑÂÖçË¥πÂú®Á∫øËØæÁ®ã‰∫ÜËß£AIÊ¶ÇÂøµÂèäÂÖ∂Âú®ÊïôËÇ≤‰∏≠ÁöÑÂ∫îÁî®„ÄÇ\n\n3. **ÁîüÊàêÂ≠¶‰π†ÁöÑ‰∏ì‰∏öËØæÁ®ã**ÔºöÊä•ÂêçÂèÇÂä†‰∏ìÊ≥®‰∫éÁîüÊàêÂ≠¶‰π†ÁöÑËØæÁ®ãÔºåÂ¶Ç‚ÄúÁîüÊàêËÆæËÆ°‚ÄùÊàñMITÁ≠âÂ§ßÂ≠¶Êèê‰æõÁöÑÁ±ª‰ºº‰∏ì‰∏öÈ°πÁõÆ„ÄÇ\n4. **‰∏ì‰∏öÂèëÂ±ïÁ†îËÆ®‰ºöÂíå‰ºöËÆÆ** - ÂèÇÂä†ÂΩìÂú∞ÊïôËÇ≤‰ºöËÆÆ‰∏ä‰∏ìÊ≥®‰∫éÂ∞ÜAIÊï¥ÂêàÂà∞ÊïôÂ≠¶ÂÆûË∑µ‰∏≠ÁöÑÁ†îËÆ®‰ºö„ÄÇ\n\n5. **ÊïôËÇ≤Â∑•‰ΩúËÄÖÂú®Á∫øÁ§æÂå∫Ôºà‰æãÂ¶ÇÔºåEdmodoÔºâ**ÔºöÂä†ÂÖ•Âú®Á∫øÁ§æÂå∫Ôºå‰∏éÊïôËÇ≤Â∑•‰ΩúËÄÖËÆ®ËÆ∫ÁîüÊàêÊäÄÊúØÂú®ÊïôËÇ≤‰∏≠ÁöÑÂ∫îÁî®ÔºåÂàÜ‰∫´ËµÑÊ∫êÊàñËØ¢ÈóÆÂÆûÊñΩÈóÆÈ¢ò„ÄÇ\n6. **ËÆ§ËØÅÈ°πÁõÆ**ÔºöËÄÉËôëÈÄöËøáÂÉèË∞∑Ê≠åÁöÑ‚ÄúAI for Educators‚ÄùÈ°πÁõÆÁ≠âÊú∫ÊûÑËé∑ÂæóËÆ§ÂèØÊÇ®Âú®ÊïôÂ≠¶ÂÆûË∑µ‰∏≠Êï¥ÂêàAIÁõ∏ÂÖ≥Áü•ËØÜÂíåÊäÄËÉΩÁöÑËÆ§ËØÅ„ÄÇ\n\nÈÄöËøáÈÅµÂæ™ËøôÊù°Â≠¶‰π†Ë∑ØÂæÑÔºåÊïôÂ∏à‰∏ç‰ªÖÂèØ‰ª•Â¢ûÂº∫Ëá™Ë∫´ÁöÑ‰∏ì‰∏öÂèëÂ±ïÔºåËøòÂèØ‰ª•ÈÄöËøáÊúâÊïàÂú∞Êï¥ÂêàÁîüÊàêÊäÄÊúØÔºå‰∏∫ÊïôËÇ≤ÁöÑÊú™Êù•ÂÅöÂá∫ÁßØÊûÅË¥°ÁåÆ„ÄÇ\n</output>\n```\n\nÊàëËÆ§‰∏∫ÔºåÂØπ‰∫éËøô‰∏™Â∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑËßÑÊ®°ÔºåÁªìÊûúÂπ∂‰∏çÂ∑ÆÔºÅ\n\n## ÊØîËæÉ Qwen2\\.5 Âíå Llama3\\.2\n\nÂ∞ΩÁÆ°Ëøô‰ªÖ‰ªÖÊòØÊàë‰∏™‰∫∫ÁöÑËØÑ‰º∞ÔºåÊàëËøòÊòØÊÉ≥Âíå‰Ω†ÂàÜ‰∫´‰∏Ä‰∏ã„ÄÇ\n\nËøô‰∏§‰∏™Ê®°ÂûãÈÉΩÊòØ‰∏∫ÁßªÂä®ËÆæÂ§áËÆæËÆ°ÁöÑÔºå‰ΩÜÊÄßËÉΩÂ∑ÆÂºÇÂæàÂ§ß„ÄÇËØ∑Áúã‰∏ãÈù¢Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*T6vLgvOKdkotlV1K5x6-QQ.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*DuV3LJep_PuDqiCcAMb6Cg.png)\n\nÈ¶ñÂÖàÔºåÊï¥‰ΩìËØÑÂàÜÂ∑ÆÂºÇÂ∑®Â§ßÔºàLlama3\\.2 ‰∏∫ 41ÔºåQwen2\\.5 ‰∏∫ 57\\Ôºâ„ÄÇ\n\nÂÖ∂Ê¨°ÔºåÂ¶ÇÊûú‰Ω†ËÄÉËôëÂú®ÁßªÂä®ËÆæÂ§á‰∏äÂèØËÉΩ‰ºöÈóÆÁöÑÈóÆÈ¢òÔºåËØ≠Ë®Ä‰ªªÂä°ÊñπÈù¢Ôºå‰∏ªË¶ÅÊòØÂ∏åÊúõÊúâÊµÅÁïÖÁöÑËÅäÂ§©‰ΩìÈ™åÔºà‰ªªÂä° 4\\Ôºâ„ÄÅËâØÂ•ΩÁöÑÊëòË¶ÅËÉΩÂäõÔºà‰ªªÂä° 5 Âà∞ 7\\Ôºâ‰ª•Âèä‰∏Ä‰∫õÂàõÈÄ†ÊÄßÂÜô‰ΩúÔºà‰ªªÂä° 11 Âíå 13\\Ôºâ„ÄÇ\n\nÂú®ÈÄüÂ∫¶ÊñπÈù¢Ôºå‰ªÖÂú® CPU ‰∏äËøêË°åÊ®°ÂûãÔºå‰ΩøÁî®ÈùûÂ∏∏ÊúâÈôêÁöÑËø∑‰Ω† PCÔºå**ÊàëËé∑Âæó‰∫ÜÂπ≥ÂùáÊé®ÁêÜÈÄüÂ∫¶‰∏∫ 14 t/s„ÄÇ**\n\n## ÁªìËÆ∫\n\nÂú® Qwen2 ÂèëÂ∏ÉÁöÑËøáÂéª‰∏â‰∏™ÊúàÈáåÔºå‰ºóÂ§öÂºÄÂèëËÄÖÂú® Qwen2 ËØ≠Ë®ÄÊ®°Âûã‰∏äÊûÑÂª∫‰∫ÜÊñ∞Ê®°ÂûãÔºå‰∏∫Êï¥‰∏™Á§æÂå∫‰ª•ÂèäÈòøÈáå‰∫ëÊèê‰æõ‰∫ÜÂÆùË¥µÁöÑÂèçÈ¶à„ÄÇ\n\n> Âú®Ê≠§ÊúüÈó¥ÔºåÊàë‰ª¨‰∏ìÊ≥®‰∫éÂàõÈÄ†Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÊúâÁü•ËØÜÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇ‰ªäÂ§©ÔºåÊàë‰ª¨ÂæàÈ´òÂÖ¥Âú∞‰ªãÁªç Qwen ÂÆ∂ÊóèÁöÑÊúÄÊñ∞ÊàêÂëòÔºöQwen2\\.5\n\n‰ªñ‰ª¨ÁöÑÂ£∞Êòé‰º¥ÈöèÁùÄÂÖ≥‰∫éÊñ∞Ê®°ÂûãÂÆ∂ÊóèÁöÑ‰∫ãÂÆûÔºö\n\n* ÂØÜÈõÜÂûã„ÄÅ**Êòì‰∫é‰ΩøÁî®**ÁöÑ‰ªÖËß£Á†ÅÂô®ËØ≠Ë®ÄÊ®°ÂûãÔºåÊèê‰æõ 0\\.5B„ÄÅ1\\.5B„ÄÅ3B„ÄÅ7B„ÄÅ14B„ÄÅ32B Âíå 72B Â∞∫ÂØ∏Ôºå‰ª•ÂèäÂü∫Á°ÄÂíåÊåá‰ª§Âèò‰Ωì„ÄÇ\n* Âú®Êàë‰ª¨ÊúÄÊñ∞ÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÊ∂µÁõñÂ§öËææ 18T ÁöÑÊ†áËÆ∞„ÄÇ\n* **Êåá‰ª§Ë∑üÈöè**ÊñπÈù¢ÁöÑÊòæËëóÊîπËøõ\n* ÂØπÁ≥ªÁªüÊèêÁ§∫ÁöÑÂ§öÊ†∑ÊÄß**Êõ¥ÂÖ∑ÂºπÊÄß**ÔºåÂ¢ûÂº∫ËßíËâ≤ÊâÆÊºîÂÆûÊñΩÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊù°‰ª∂ËÆæÁΩÆ„ÄÇ\n* **ÊîØÊåÅÈ´òËææ 128K** ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåÂπ∂ÂèØ‰ª•ÁîüÊàêÊúÄÂ§ö 8K ÁöÑÊ†áËÆ∞„ÄÇ\n* ÊîØÊåÅË∂ÖËøá 29 ÁßçËØ≠Ë®ÄÁöÑÂ§öËØ≠Ë®ÄÂäüËÉΩ\n\nÂú®ÊàëÂπøÊ≥õÁöÑÔºà‰ΩÜÁ°ÆÂÆûÈôê‰∫éÂçïÊ¨°ÊèêÁ§∫ÂíåÂ∞ëÊï∞ NLP ‰ªªÂä°ÔºâÊµãËØï‰∏≠ÔºåÊàë‰∫≤ÁúºÁúãÂà∞Ëøô‰∫õÂ£∞ÊòéÊòØÂü∫‰∫éÈ´òË¥®ÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂíåÁ≤æÂøÉÁ≠ñÂàíÁöÑÂæÆË∞É„ÄÇ\n\nËØ•Ê®°ÂûãÂú®ÁßªÂä®ËÆæÂ§á‰∏äË°®Áé∞ÊûÅ‰∏∫Âá∫Ëâ≤ÔºÅ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/qwen2-5-coder-32b-instruct-a-best-coding-model-a-complete-step-by-step-guide-and-performance-b8a33ec2547f","frontmatter":{"title":"Qwen2.5-Coder 32B InstructÔºöÊúÄ‰Ω≥ÁºñÁ†ÅÊ®°Âûã--ÂÆåÊï¥ÁöÑÂàÜÊ≠•ÊåáÂçóÂíåÊÄßËÉΩ...","meta_title":"Qwen2.5-Coder 32B InstructÔºöÊúÄ‰Ω≥ÁºñÁ†ÅÊ®°Âûã--ÂÆåÊï¥ÁöÑÂàÜÊ≠•ÊåáÂçóÂíåÊÄßËÉΩ...","description":"Qwen2.5-CoderÁ≥ªÂàóÔºåÂ∞§ÂÖ∂ÊòØ32BÊ®°ÂûãÔºåÂú®‰ª£Á†ÅÁîüÊàê„ÄÅ‰øÆÂ§çÂíåÊé®ÁêÜÊñπÈù¢Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩÔºåËÉΩÂ§ü‰∏éGPT-4oÁ≠âÊàêÁÜüÊ®°ÂûãÁõ∏Â™≤Áæé„ÄÇËØ•Ê®°ÂûãÊîØÊåÅË∂ÖËøá40ÁßçÁºñÁ®ãËØ≠Ë®ÄÔºåÈÄÇÂ∫îÂ§öÁßçÂºÄÂèëÈúÄÊ±ÇÔºåÊèê‰æõÁÅµÊ¥ªÁöÑÊ®°ÂûãÈÄâÊã©„ÄÇÈÄöËøáÂü∫ÂáÜÊµãËØïÔºåQwen2.5-CoderÂú®Â§öÈ°πÊåáÊ†á‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÈÄÇÁî®‰∫éÁºñÁ†ÅÂä©Êâã„ÄÅËá™Âä®Âåñ‰ª£Á†ÅÂÆ°Êü•ÂíåÊïôËÇ≤Â∑•ÂÖ∑Á≠âÂú∫ÊôØÔºåÊé®Âä®ÂºÄÊ∫ê‰ª£Á†ÅÁîüÊàêÁöÑËøõÊ≠•„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zjZmLCEX5URAc1wxTGnBRQ.png","categories":["Programming","Machine Learning","Generative AI"],"author":"Rifx.Online","tags":["Qwen2.5","Coder","programming","languages","repair"],"draft":false,"slug":"blog/qwen2-5-coder-32b-instruct-a-best-coding-model-a-complete-step-by-step-guide-and-performance-b8a33ec2547f"},"content":"\n### Â≠¶‰π†Â¶Ç‰ΩïÂú®Êú¨Âú∞ÂÆâË£Ö Qwen2.5-CoderÔºåÊé¢Á¥¢ÂÖ∂ÂçìË∂äÁöÑÁºñÁ†ÅËÉΩÂäõÔºåÂπ∂ÈÄöËøáÂÆûË∑µÁ§∫‰æãËØÑ‰º∞ÂÖ∂ÊÄßËÉΩ\n\n\n\n## ‰ªãÁªç\n\nÂú®‰∏çÊñ≠ÂèëÂ±ïÁöÑAIÈ©±Âä®ÁºñÁ®ãÂ∑•ÂÖ∑È¢ÜÂüüÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊòæËëóÊîπÂèò‰∫ÜÂºÄÂèëËÄÖÁºñÂÜô„ÄÅË∞ÉËØïÂíå‰ºòÂåñ‰ª£Á†ÅÁöÑÊñπÂºè„ÄÇ‰ªäÂ§©ÔºåÊàë‰ª¨ÂæàÈ´òÂÖ¥Êé¢Á¥¢**Qwen2.5-Coder**Á≥ªÂàóÔºåËøôÊòØ‰∏ÄÈ°πÂºÄÊ∫êÁöÑÂ•áËøπÔºåÊâøËØ∫Âú®‰ª£Á†ÅÁîüÊàêÂíåAIÁºñÁ†ÅÂä©ÊâãÈ¢ÜÂüüÊ†ëÁ´ãÊñ∞ÁöÑÊ†áÂáÜ„ÄÇËØ•Á≥ªÂàóÁöÑÊúÄÊñ∞ÁâàÊú¨**Qwen2.5-Coder-32B-Instruct**ÈáçÊñ∞ÂÆö‰πâ‰∫ÜÂºÄÊ∫êÁºñÁ†ÅÊ®°ÂûãÁöÑÊúÄÊñ∞ÊäÄÊúØÊ∞¥Âπ≥ÔºàSOTAÔºâÔºå‰∏é**GPT-4o**Á≠âÊàêÁÜüÊ®°ÂûãÁöÑËÉΩÂäõÁõ∏Â™≤Áæé„ÄÇËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£ÊòØ‰ªÄ‰πàËÆ©Qwen2.5-CoderÂ¶ÇÊ≠§‚ÄúÂº∫Â§ß‚Äù„ÄÅ‚ÄúÂ§öÊ†∑‚ÄùÂíå‚ÄúÂÆûÁî®‚Äù„ÄÇ\n\nÂú®Êú¨ÁªºÂêàÊåáÂçó‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®**Qwen2.5-Coder-32B**Ê®°ÂûãÁöÑÊ†∏ÂøÉËÉΩÂäõ„ÄÇÊàë‰ª¨Â∞ÜÊºîÁ§∫Â¶Ç‰Ωï‰ΩøÁî®`transformers`Â∫ìÔºåÊµãËØïÂÖ∂ÁºñÁ†ÅËÉΩÂäõÂπ∂Á™ÅÂá∫ÂÖ∂ÂÆûÈôÖÂ∫îÁî®„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàÈÄâÊã© Qwen2\\.5\\-Coder?\n\n### ÂÖ≥ÈîÆ‰∫ÆÁÇπ\n\n1. **Âº∫Â§ß**ÔºöÊóóËà∞ **Qwen2\\.5\\-Coder\\-32B** Ê®°ÂûãÂú®‰∏ªË¶ÅÁºñÁ†ÅÂü∫ÂáÜÊµãËØï‰∏≠‰∏é GPT\\-4 ÁöÑÁºñÁ†ÅËÉΩÂäõÁõ∏ÂåπÈÖçÔºåÂêåÊó∂Âú®‰∏ÄËà¨ÂíåÊï∞Â≠¶ÊäÄËÉΩÊñπÈù¢Ë°®Áé∞‰ºòÂºÇ„ÄÇ\n2. **Â§öÊ†∑**ÔºöÊ≠§Ê¨°ÂèëÂ∏ÉÊ∂µÁõñÂ§öÁßçÊ®°ÂûãÂ∞∫ÂØ∏Ôºà0\\.5B, 1\\.5B, 3B, 7B, 14B, 32BÔºâÔºå‰∏∫‰∏çÂêåËµÑÊ∫êÈôêÂà∂Êèê‰æõÁÅµÊ¥ªÊÄß„ÄÇ\n3. **ÂÆûÁî®**ÔºöÊó®Âú®Áî®‰∫éÂÆûÈôÖÂ∫îÁî®ÔºåÂåÖÊã¨‰ª£Á†ÅÂä©ÊâãÂíåÊñáÊ°£ÁîüÊàê„ÄÇÊ®°ÂûãÈááÁî® **Apache 2\\.0** ËÆ∏ÂèØÔºåÁ°Æ‰øùÂèØËá™Áî±‰ΩøÁî®Âíå‰øÆÊîπÔºåÈÄÇÁî®‰∫éÂïÜ‰∏öÂíåÁ†îÁ©∂ÁõÆÁöÑ„ÄÇ\n\n## Qwen2\\.5\\-CoderÁ≥ªÂàóÔºöÂºÄÊîæ‰ª£Á†ÅLLMÁöÑÊ∏∏ÊàèËßÑÂàôÊîπÂèòËÄÖ\n\n**Qwen2\\.5\\-Coder**Á≥ªÂàóËá¥Âäõ‰∫éÊé®Âä®ÂºÄÊ∫ê‰ª£Á†ÅÁîüÊàêÁöÑËæπÁïå„ÄÇËØ•ÁâàÊú¨‰∏ìÊ≥®‰∫éÁÅµÊ¥ªÊÄßÂíåÂèØÊâ©Â±ïÊÄßÔºåÂåÖÂê´Â§öÁßçËßÑÊ®°ÁöÑÊ®°ÂûãÔºö**0\\.5B, 1\\.5B, 3B, 7B, 14B**Ôºå‰ª•ÂèäÊóóËà∞Áâà**32B**„ÄÇËøô‰∫õÊ®°ÂûãÊª°Ë∂≥‰∫Ü‰∏çÂêåÂºÄÂèëËÄÖÁöÑÈúÄÊ±ÇÔºå‰ªéËΩªÈáèÁ∫ß„ÄÅËµÑÊ∫êÈ´òÊïàÁöÑÊ®°ÂûãÂà∞ÈÄÇÁî®‰∫éÈ´òË¶ÅÊ±ÇÂ∫îÁî®ÁöÑÈ´òÂÆπÈáè„ÄÅÂäüËÉΩ‰∏∞ÂØåÁöÑÊ®°Âûã„ÄÇ\n\n### 1\\. Âº∫Â§ßÔºöÂú®‰ª£Á†ÅÁîüÊàê‰∏≠ËÆæÂÆöÊñ∞Ê†áÂáÜ\n\nQwen2\\.5\\-Coder\\-32B\\-Instruct ‰Ωú‰∏∫ÊóóËà∞Ê®°ÂûãÔºåÊã•Êúâ‰∏ÄÁ≥ªÂàóËÉΩÂäõÔºå‰ΩøÂÖ∂Ëé∑Âæó‰∫Ü **ÂΩìÂâç SOTA ÂºÄÊ∫ê‰ª£Á†ÅÊ®°Âûã** ÁöÑÁß∞Âè∑„ÄÇÂÆÉÂú®‰ª•‰∏ãÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºö\n\n* **‰ª£Á†ÅÁîüÊàê**ÔºöÂú® **EvalPlus„ÄÅLiveCodeBench** Âíå **BigCodeBench** Á≠âÁÉ≠Èó®Âü∫ÂáÜÊµãËØï‰∏≠ÔºåÂÖ∂ÊÄßËÉΩ‰∏é GPT\\-4o Áõ∏ÂåπÈÖçÔºåËÉΩÂ§üÂú®Â§öÁßçÂú∫ÊôØ‰∏≠Êèê‰æõÁ≤æÁ°ÆÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÇ\n* **‰ª£Á†Å‰øÆÂ§ç**Ôºö‰øÆÂ§çÊçüÂùèÊàñ‰ΩéÊïàÁöÑ‰ª£Á†ÅÂú®ËΩØ‰ª∂ÂºÄÂèë‰∏≠Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÊµãËØï‰ª£Á†Å‰øÆÂ§çÊäÄËÉΩÁöÑ **Aider Âü∫ÂáÜ** ‰∏≠ÔºåQwen2\\.5\\-Coder\\-32B\\-Instruct ÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ **73\\.7** ÂàÜÔºåÂ†™ÊØî GPT\\-4o ÁöÑËÉΩÂäõ„ÄÇ\n* **‰ª£Á†ÅÊé®ÁêÜ**ÔºöÁêÜËß£ÂíåÊé®ÁêÜ‰ª£Á†ÅÊâßË°åË∑ØÂæÑÁöÑËÉΩÂäõÂØπË∞ÉËØïÂíå‰ºòÂåñÂ§çÊùÇËΩØ‰ª∂Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇËØ•Ê®°ÂûãÁöÑËÉΩÂäõ‰∏ç‰ªÖÈôê‰∫éÁÆÄÂçïÁöÑÁîüÊàê ‚Äî ÂÆÉÂú® **È¢ÑÊµãËæìÂÖ•ÂíåËæìÂá∫** ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩøÂÖ∂Êàê‰∏∫ËΩØ‰ª∂Â∑•Á®ãÂ∏àÁöÑÂÆùË¥µÂ∑•ÂÖ∑„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-g1ZGa0p2kKsQK4iD7q7cg.png)\n\n### 2\\. Â§öÊ†∑ÊÄßÔºöÊîØÊåÅÂ§öÁßçÁºñÁ®ãËØ≠Ë®ÄÂíå‰∏∞ÂØåÁöÑÊ®°ÂûãÂ§ßÂ∞è\n\nQwen2.5-Coder ÁöÑÂ§öÂäüËÉΩÊÄß‰ΩìÁé∞Âú®ÂÖ∂ÂØπË∂ÖËøá **40 ÁßçÁºñÁ®ãËØ≠Ë®Ä** ÁöÑÊîØÊåÅÔºåÂåÖÊã¨ **Haskell** Âíå **Racket** Á≠âÂ∞è‰ºóËØ≠Ë®Ä„ÄÇËøôÁßçÂπøÊ≥õÁöÑÊîØÊåÅÂæóÁõä‰∫éÁªÜËá¥ÁöÑÊï∞ÊçÆÊ∏ÖÁêÜÂíåÂùáË°°ÁöÑËÆ≠ÁªÉÔºåÁ°Æ‰øùÊ®°ÂûãÂú®‰∏çÂêåÁöÑÁºñÁ†ÅÁéØÂ¢É‰∏≠Ë°®Áé∞ÊúÄ‰Ω≥„ÄÇ\n\n* **Â§öËØ≠Ë®Ä‰ª£Á†Å‰øÆÂ§ç**ÔºöÂÆÉÁöÑ‰∏ì‰∏öËÉΩÂäõÊâ©Â±ïÂà∞ÂØπ‰∏çÁÜüÊÇâËØ≠Ë®ÄÁöÑ‰ª£Á†Å‰øÆÂ§çÔºåËøôÂèØ‰ª•ÊòæËëóÂáèÂ∞ëÂºÄÂèëËÄÖÊé¢Á¥¢Êñ∞ÊäÄÊúØÁöÑÂ≠¶‰π†Êõ≤Á∫ø„ÄÇ\n* **Ê®°ÂûãÂ§ßÂ∞èÁÅµÊ¥ªÊÄß**ÔºöQwen2.5-Coder Á≥ªÂàóÊèê‰æõÂÖ≠Áßç‰∏çÂêåÂ§ßÂ∞èÁöÑÊ®°ÂûãÔºåÁ°Æ‰øùÂÖ∑Êúâ‰∏çÂêåËµÑÊ∫êÈôêÂà∂ÁöÑÂºÄÂèëËÄÖËÉΩÂ§üÊâæÂà∞ÈÄÇÂêàÂÖ∂ÈúÄÊ±ÇÁöÑÊ®°Âûã„ÄÇÊîØÊíëËøô‰∫õÊ®°ÂûãÁöÑ **Êâ©Â±ïÊ≥ïÂàô** Âì≤Â≠¶ÊÑèÂë≥ÁùÄÊÄßËÉΩ‰∏éÊ®°ÂûãÂ§ßÂ∞èÂëàÊ≠£Áõ∏ÂÖ≥ÔºåËµã‰∫àÂºÄÂèëËÄÖÂú®ÊÄßËÉΩÂíåËÆ°ÁÆóËµÑÊ∫ê‰πãÈó¥ÈÄâÊã©ÂêàÈÄÇÂπ≥Ë°°ÁöÑÁÅµÊ¥ªÊÄß„ÄÇ\n\n## ÊÄßËÉΩÊ¥ûÂØüÔºöËØÑ‰º∞ Qwen2.5-Coder Ê®°Âûã\n\n### 1\\. Instruct ‰∏é Base Ê®°Âûã\n\nQwen2\\.5\\-Coder Êèê‰æõ **Base** Âíå **Instruct** ÁâàÊú¨Ôºö\n\n* **Base Ê®°Âûã** Êó®Âú®‰∏∫Â∏åÊúõÂØπÂÖ∂ÁâπÂÆöÂ∫îÁî®ËøõË°åÂæÆË∞ÉÁöÑÂºÄÂèëËÄÖÊèê‰æõÂéüÂßãÊ®°Âûã„ÄÇ\n* **Instruct Ê®°Âûã** ÁªèËøáÈ¢ÑÂÖàË∞ÉÊï¥Ôºå‰ºòÂåñÁî®‰∫é‰∫§‰∫íÂºèÂíåÂØπËØùÂºèÁöÑ‰ΩøÁî®Âú∫ÊôØÔºåÈùûÂ∏∏ÈÄÇÂêàÂü∫‰∫éËÅäÂ§©ÁöÑ‰ª£Á†ÅÂä©Êâã„ÄÇ\n\n### 2\\. Âü∫ÂáÜÊØîËæÉÔºöÂºïÈ¢ÜÊΩÆÊµÅ\n\nÂú®ÂêÑÁßçÊ†∏ÂøÉÂü∫ÂáÜÊµãËØï‰∏≠Ôºö\n\n* **MBPP\\-3shot** Ë¢´ÈÄâ‰∏≠Áî®‰∫éËØÑ‰º∞Âü∫Á°ÄÊ®°ÂûãÔºåÊèê‰æõ‰∫Ü‰∏Ä‰∏™Âº∫ÊúâÂäõÁöÑÊåáÊ†áÊù•Ë°°ÈáèÂÆÉ‰ª¨ÁöÑ‰ª£Á†ÅÁêÜËß£ÂíåÂêàÊàêËÉΩÂäõ„ÄÇ\n* **LiveCodeBench** ÈóÆÈ¢òÈõÜÁî®‰∫éËØÑ‰º∞ÊåáÂØºÊ®°ÂûãÔºåÈáçÁÇπÂÖ≥Ê≥®ÂÆÉ‰ª¨ÂØπÊñ∞È¢ñÂíåÊú™ËßÅËøáÁöÑÁºñÁ†ÅÈóÆÈ¢òÁöÑÈÄÇÂ∫îËÉΩÂäõ„ÄÇ\n\nÁªìÊûúÂë¢Ôºü**Qwen2\\.5\\-Coder ‰∏ÄÁõ¥‰ºò‰∫éÂÖ∂‰ªñÂºÄÊ∫êÊ®°Âûã**ÔºåËØÅÊòé‰∫ÜËßÑÊ®°Êâ©Â§ßÁ°ÆÂÆû‰∏éÊõ¥Â•ΩÁöÑÊÄßËÉΩÁõ∏ÂÖ≥„ÄÇ\n\n## ÂÆûÁî®ÊåáÂçóÔºö‰ΩøÁî® Qwen2.5-Coder-3B ËøõË°å‰ª£Á†ÅÁîüÊàê‰∏é Transformers\n\nÂú®Êú¨ÂÆûÁî®ÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊºîÁ§∫Â¶Ç‰Ωï‰ΩøÁî® `transformers` Â∫ì‰∏≠ÁöÑ **Qwen2.5-Coder-3B** Ê®°ÂûãÊù•ÁîüÊàê‰ª£Á†Å„ÄÇËØ•Ê®°ÂûãÊòØ **Qwen2.5-Coder Á≥ªÂàó** ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊó®Âú®Âú®‰ª£Á†ÅÁîüÊàê„ÄÅ‰øÆÂ§çÂíåÊé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂà∞Êú¨ÊïôÁ®ãÁªìÊùüÊó∂ÔºåÊÇ®Â∞ÜÁúãÂà∞Â¶Ç‰ΩïÂ∞ÜËøô‰∏™Âº∫Â§ßÁöÑÂºÄÊ∫êÊ®°ÂûãÈõÜÊàêÂà∞ÊÇ®Ëá™Â∑±ÁöÑÈ°πÁõÆ‰∏≠Ôºå‰ª•Â§ÑÁêÜÂêÑÁßç‰∏é‰ª£Á†ÅÁõ∏ÂÖ≥ÁöÑ‰ªªÂä°„ÄÇ\n\n### ÂâçÊèêÊù°‰ª∂\n\nÂú®Ê∑±ÂÖ•‰ª£Á†Å‰πãÂâçÔºåËØ∑Á°Æ‰øùÊÇ®Â∑≤ÂÆâË£Ö‰ª•‰∏ãÂÜÖÂÆπÔºö\n\n```python\npip install torch transformers\n```\n\nÊ≠§Â§ñÔºåÂ¶ÇÊûúÊÇ®Â∏åÊúõÂÖÖÂàÜÂà©Áî®Ê®°ÂûãÁöÑÊÄßËÉΩÔºåËØ∑Á°Æ‰øùÊÇ®ÂèØ‰ª•ËÆøÈóÆÊîØÊåÅ GPU ÁöÑÁéØÂ¢É„ÄÇ\n\n### Á¨¨‰∏ÄÊ≠•ÔºöÂØºÂÖ•ÊâÄÈúÄÂ∫ì\n\nÊàë‰ª¨Â∞ÜÈÄöËøá‰ªé `transformers` Â∫ì‰∏≠ÂØºÂÖ•ÂøÖË¶ÅÁöÑÁªÑ‰ª∂Êù•ÂºÄÂßãÔºö\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n```\n\nÁ¨¨‰∫åÊ≠•ÔºöÂä†ËΩΩÊ®°ÂûãÂíåÂàÜËØçÂô®\n\nÂú®Ëøô‰∏ÄÊ≠•‰∏≠ÔºåÊàë‰ª¨Âä†ËΩΩ ***Qwen2\\.5\\-Coder\\-32B\\-Instruct*** Ê®°ÂûãÂèäÂÖ∂ÂØπÂ∫îÁöÑÂàÜËØçÂô®„ÄÇ`device_map=\"auto\"` ÈÄâÈ°πÂ∞ÜËá™Âä®Â∞ÜÊ®°ÂûãÂàÜÈÖçÂà∞ÂèØÁî®ÁöÑ GPU Êàñ CPU ‰∏ä„ÄÇ\n\n> ***Qwen2\\.5\\-Coder Â∑≤Âú® Hugging Face ‰∏äÂèëÂ∏É‰∫ÜÂ§öÁßçÂ∞∫ÂØ∏ÁöÑÊ®°Âûã ‚Äî 0\\.5B\\-Instruct„ÄÅ1\\.5B\\-Instruct„ÄÅ3B\\-Instruct„ÄÅ7B\\-Instruct„ÄÅ14B\\-Instruct Âíå 32B\\-Instruct„ÄÇÂ¶ÇÊûúÊÇ®ÊÉ≥Âú®Êú¨Âú∞ËøêË°åÂÆÉ‰ª¨ÔºåËØ∑ÈÄâÊã©ÊúÄÈÄÇÂêàÊÇ® GPU ÂÆπÈáèÁöÑÊ®°Âûã„ÄÇËøô‰∫õÊ®°Âûã‰πüÂèØ‰ª•Âú® Ollama ‰∏äËé∑ÂæóÔºåÂõ†Ê≠§ÊÇ®ÂèØ‰ª•Âú® Ollama ÁéØÂ¢É‰∏≠‰ΩøÁî®ÂÆÉ‰ª¨„ÄÇÂ¶ÇÊûúÊÇ®ÂØπ Ollama ÊïôÁ®ãÊÑüÂÖ¥Ë∂£ÔºåËØ∑ÈöèÊó∂Âú®ËØÑËÆ∫‰∏≠ÂëäËØâÊàëÔºÅ***\n\n```python\nmodel_name = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n\n## Load the model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n## Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n```\n\n### Á¨¨3Ê≠•ÔºöÁºñÂÜôËÅäÂ§©Ê®°ÊùøÂáΩÊï∞\n\nQwen2.5-CoderÊ®°ÂûãÊó®Âú®Â§ÑÁêÜÁ±ªÂØπËØùÁöÑÊèêÁ§∫Ôºå‰ΩøÁî®ËÅäÂ§©Ê®°Êùø„ÄÇ‰ª•‰∏ãËæÖÂä©ÂáΩÊï∞‰ª•Á¨¶ÂêàÊ®°ÂûãÈ¢ÑÊúüÁöÑÊñπÂºèËÆæÁΩÆËæìÂÖ•ÊèêÁ§∫Ôºö\n\n```python\ndef generate_response(model, tokenizer, prompt):\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n    # Prepare the chat input\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    # Tokenize and prepare inputs\n    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n    # Generate response\n    generated_ids = model.generate(\n        **model_inputs,\n        max_new_tokens=512\n    )\n    # Remove prompt tokens from output\n    generated_ids = [\n        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n    ]\n  \n    # Decode and return the generated text\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    return response\n```\n\n### Á¨¨4Ê≠•Ôºö‰ΩøÁî®‰ª£Á†ÅÁîüÊàêÊµãËØïÊ®°Âûã\n\nËÆ©Êàë‰ª¨ËøêË°å‰∏Ä‰∫õÁ§∫‰æãÔºåÁúãÁúãQwen2.5-Coder-32BÊ®°ÂûãÂú®ÁîüÊàêPythonÂíåJava‰ª£Á†ÅÊñπÈù¢ÁöÑË°®Áé∞Â¶Ç‰Ωï„ÄÇÊàë‰ª¨Â∞ÜÁî®‰∏â‰∏™‰∏çÂêåÁöÑÁºñÁ®ãÊèêÁ§∫ËøõË°åÊµãËØï„ÄÇ\n\n### ÊµãËØï 1ÔºöÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ï\n\n**ÊèêÁ§∫**Ôºö‚ÄúÁºñÂÜô‰∏Ä‰∏™Âø´ÈÄüÊéíÂ∫èÁÆóÊ≥ï„ÄÇ‚Äù\n\n```python\nprompt_1 = \"write a quick sort algorithm.\"\nresponse_1 = generate_response(model, tokenizer, prompt_1)\nprint(response_1)\n```\n\nËæìÂá∫Ôºö\n\n\n```python\ndef quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    return quick_sort(left) + middle + quick_sort(right)\n```\n\n## Á§∫‰æãÁî®Ê≥ïÔºö\n\narr = [3, 6, 8, 10, 1, 2, 1]\nprint(quick_sort(arr))\n\n```\nËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ `quick_sort` ÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞Êé•Âèó‰∏Ä‰∏™Êï∞ÁªÑ‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂‰ΩøÁî®Âø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïËøîÂõûËØ•Êï∞ÁªÑÁöÑÊéíÂ∫èÁâàÊú¨„ÄÇËØ•ÂáΩÊï∞ÈÄöËøá‰ªéÊï∞ÁªÑ‰∏≠ÈÄâÊã©‰∏Ä‰∏™Âü∫ÂáÜÂÖÉÁ¥†ÔºåÂπ∂Ê†πÊçÆÂÖ∂‰ªñÂÖÉÁ¥†ÊòØÂ∞è‰∫éËøòÊòØÂ§ß‰∫éÂü∫ÂáÜÊù•Â∞ÜÂÆÉ‰ª¨ÂàÜÊàê‰∏§‰∏™Â≠êÊï∞ÁªÑ„ÄÇÁÑ∂ÂêéÂØπÂ≠êÊï∞ÁªÑËøõË°åÈÄíÂΩíÊéíÂ∫è„ÄÇÈÄíÂΩíÁöÑÂü∫Êú¨ÊÉÖÂÜµÊòØÂΩìÊï∞ÁªÑÂè™Êúâ‰∏Ä‰∏™ÊàñÊ≤°ÊúâÂÖÉÁ¥†Êó∂ÔºåÊ≠§Êó∂Êï∞ÁªÑÂ∑≤ÁªèÊòØÊéíÂ∫èÂ•ΩÁöÑ„ÄÇ\n\nÊÇ®ÂèØ‰ª•Â∞ÜËøôÊÆµ‰ª£Á†Å‰Ωú‰∏∫Ëµ∑ÁÇπÔºåÂπ∂Ê†πÊçÆÊÇ®ÁöÑÂÖ∑‰ΩìÈúÄÊ±ÇËøõË°å‰øÆÊîπ„ÄÇÂ¶ÇÊúâ‰ªª‰ΩïËøõ‰∏ÄÊ≠•ÁöÑÈóÆÈ¢òÊàñÈúÄË¶ÅÂÖ∂‰ªñÂ∏ÆÂä©ÔºåËØ∑ÂëäËØâÊàëÔºÅ<|fim_middle|>\n```\n\n### ÊµãËØï 2ÔºöËÆ°ÁÆó‰∏Ä‰∏™Êï∞Â≠óÁöÑÈò∂‰πò\n\n**ÊèêÁ§∫**Ôºö‚ÄúÁºñÂÜô‰∏Ä‰∏™ Python Á®ãÂ∫èÊù•ËÆ°ÁÆó‰∏Ä‰∏™Êï∞Â≠óÁöÑÈò∂‰πò„ÄÇ‚Äù\n\n```python\nprompt_2 = \"Write a python program to find a factorial of a number.\"\nresponse_2 = generate_response(model, tokenizer, prompt_2)\nprint(response_2)\n```\n\nËæìÂá∫Ôºö\n\n```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n - 1)\n\n## Á§∫‰æãÁî®Ê≥ï\nnumber = int(input(\"ËæìÂÖ•‰∏Ä‰∏™Êï∞Â≠ó: \"))\nresult = factorial(number)\nprint(f\"{number} ÁöÑÈò∂‰πòÊòØ {result}\")\n```\n\nËØ•Á®ãÂ∫èÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÈÄíÂΩíÂáΩÊï∞ `factorial`ÔºåÁî®‰∫éËÆ°ÁÆóÁªôÂÆöÊï∞Â≠ó `n` ÁöÑÈò∂‰πò„ÄÇÂÆÉ‰ΩøÁî®Âü∫ÂáÜÊÉÖÂÜµ `n == 0` ËøîÂõû 1ÔºåÂØπ‰∫éÂÖ∂‰ªñÂÄºÁöÑ `n`ÔºåÂÆÉÈÄíÂΩíË∞ÉÁî®Ëá™Ë∫´ÔºåÁõ¥Âà∞ËææÂà∞Âü∫ÂáÜÊÉÖÂÜµ„ÄÇÊúÄÂêéÔºåÁ®ãÂ∫èÊèêÁ§∫Áî®Êà∑ËæìÂÖ•‰∏Ä‰∏™Êï∞Â≠óÔºåÂπ∂ÊòæÁ§∫ËØ•Êï∞Â≠óÁöÑÈò∂‰πò„ÄÇ\n\n\n### ÊµãËØï 3Ôºö‰ΩøÁî®ÈÄóÂè∑Ê†ºÂºèÂåñÊï∞Â≠ó\n\n**ÊèêÁ§∫**Ôºö‚ÄúÁºñÂÜô‰∏Ä‰∏™Âêç‰∏∫‚Äòformat\\_number‚ÄôÁöÑ Python ÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞‰ª•‰∏Ä‰∏™ÈùûË¥üÊï∞‰Ωú‰∏∫ÂîØ‰∏ÄÂèÇÊï∞„ÄÇÊÇ®ÁöÑÂáΩÊï∞Â∫îÂ∞ÜÊï∞Â≠óËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÂπ∂Ê∑ªÂä†ÈÄóÂè∑‰Ωú‰∏∫ÂçÉ‰ΩçÂàÜÈöîÁ¨¶„ÄÇ‚Äù\n\n```python\nprompt_3 = \"\"\"Write a python function named 'format_number' that takes a non-negative number as its only parameter.\nYour function should convert the number to a string and add commas as a thousand separators. \nFor example, calling format_number(1000000) should return '1,000,000'.\"\"\"\nresponse_3 = generate_response(model, tokenizer, prompt_3)\nprint(response_3)\n```\n\nËæìÂá∫Ôºö\n\n```python\ndef format_number(num):\n    # Convert the number to a string\n    num_str = str(num)\n  \n    # Initialize an empty string to store the formatted number\n    formatted_num = ''\n  \n    # Initialize a counter for the number of digits\n    digit_count = 0\n  \n    # Iterate over the digits in reverse order\n    for i in range(len(num_str) - 1, -1, -1):\n        # Add the current digit to the formatted number\n        formatted_num = num_str[i] + formatted_num\n      \n        # Increment the digit count\n        digit_count += 1\n      \n        # If the digit count is a multiple of 3, add a comma\n        if digit_count % 3 == 0 and i != 0:\n            formatted_num = ',' + formatted_num\n  \n    return formatted_num\n```\n\nYou can test the function with the following code:\n\n```python\nprint(format_number(1000000))  # Output: '1,000,000'\nprint(format_number(123456789))  # Output: '123,456,789'\nprint(format_number(1234567890))  # Output: '1,234,567,890'\n```\n\nThis function works by iterating over the digits of the number in reverse order, adding each digit to the formatted number and adding a comma every third digit. The function then returns the formatted number as a string.\n\n### ÊµãËØï 4Ôºö‰ΩøÁî®Êï∞ÁªÑÂÆûÁé∞Ê†àÁöÑ Java Á®ãÂ∫è\n\n**ÊèêÁ§∫**Ôºö‚ÄúÁºñÂÜô‰∏Ä‰∏™ Java Á®ãÂ∫èÔºå‰ΩøÁî®Êï∞ÁªÑÂÆûÁé∞Ê†à‚Äù\n\n```python\nprompt_4 = \"\"\"Write a Java program, Implement a Stack Using Arrays.\"\"\"\nresponse_4 = generate_response(model, tokenizer, prompt_3)\nprint(response_4)\n```\n\nËæìÂá∫Ôºö\n\n```java\npublic class StackUsingArrays {\n    private int[] stackArray;\n    private int top;\n    private int capacity;\n\n    public StackUsingArrays(int size) {\n        stackArray = new int[size];\n        top = -1;\n        capacity = size;\n    }\n\n    public void push(int item) {\n        if (isFull()) {\n            System.out.println(\"Stack is full. Cannot push item: \" + item);\n        } else {\n            top++;\n            stackArray[top] = item;\n            System.out.println(\"Pushed item: \" + item);\n        }\n    }\n\n    public int pop() {\n        if (isEmpty()) {\n            System.out.println(\"Stack is empty. Cannot pop item.\");\n            return -1;\n        } else {\n            int item = stackArray[top];\n            top--;\n            return item;\n        }\n    }\n\n    public boolean isEmpty() {\n        return top == -1;\n    }\n\n    public boolean isFull() {\n        return top == capacity - 1;\n    }\n\n    public static void main(String[] args) {\n        StackUsingArrays stack = new StackUsingArrays(5);\n\n        stack.push(10);\n        stack.push(20);\n        stack.push(30);\n\n        System.out.println(\"Popped item: \" + stack.pop());\n        System.out.println(\"Popped item: \" + stack.pop());\n\n        stack.push(40);\n        stack.push(50);\n\n        System.out.println(\"Popped item: \" + stack.pop());\n        System.out.println(\"Popped item: \" + stack.pop());\n        System.out.println(\"Popped item: \" + stack.pop());\n    }\n}\n```\n\nËøô‰∏™Á®ãÂ∫èÂÆö‰πâ‰∫Ü‰∏Ä‰∏™`StackUsingArrays`Á±ªÔºåÂÆÉ‰ΩøÁî®‰∏Ä‰∏™Êï∞ÁªÑÊù•ÂÆûÁé∞‰∏Ä‰∏™Â†ÜÊ†à„ÄÇ`push`ÊñπÊ≥ïÂ∞Ü‰∏Ä‰∏™È°πÁõÆÊ∑ªÂä†Âà∞Â†ÜÊ†àÁöÑÈ°∂ÈÉ®Ôºå`pop `ÊñπÊ≥ïÁßªÈô§Âπ∂ËøîÂõûÂ†ÜÊ†àÈ°∂ÈÉ®ÁöÑÈ°πÁõÆ„ÄÇ`isEmpty`Âíå`isFull`ÊñπÊ≥ïÂàÜÂà´Ê£ÄÊü•Â†ÜÊ†àÊòØÁ©∫ÁöÑËøòÊòØÊª°ÁöÑ„ÄÇ`main`ÊñπÊ≥ïÊºîÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄöËøáÊé®ÂÖ•ÂíåÂºπÂá∫È°πÊù•‰ΩøÁî®Â†ÜÊ†à„ÄÇ\n\n### ÊµãËØï 5ÔºöÁÆÄÂçïÂàÜÁ±ªÁÆóÊ≥ï\n\n**ÊèêÁ§∫**Ôºö‚ÄúÁºñÂÜô‰∏Ä‰∏™ Python ‰ª£Á†Å‰ª•‰ΩøÁî® Sklearn ËøêË°åÁÆÄÂçïÂàÜÁ±ªÁÆóÊ≥ï‚Äù\n\n```python\nprompt_5 = \"\"\"Write a Python code to run a simple classification algorithm using Sklearn\"\"\"\nresponse_5 = generate_response(model, tokenizer, prompt_3)\nprint(response_5)\n```\n\nËæìÂá∫Ôºö\n\n```python\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n## ÁîüÊàê‰∏Ä‰∫õÁ§∫‰æãÊï∞ÊçÆ\nnp.random.seed(42)\nX = np.random.rand(100, 2)  # 100 ‰∏™Ê†∑Êú¨Ôºå2 ‰∏™ÁâπÂæÅ\ny = np.random.choice([0, 1], size=100)  # ‰∫åÂàÜÁ±ª\n\n## Â∞ÜÊï∞ÊçÆÂàÜÂâ≤‰∏∫ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n## ÂàõÂª∫ÈÄªËæëÂõûÂΩíÊ®°Âûã\nmodel = LogisticRegression()\n\n## ËÆ≠ÁªÉÊ®°Âûã\nmodel.fit(X_train, y_train)\n\n## ÂØπÊµãËØïÈõÜËøõË°åÈ¢ÑÊµã\ny_pred = model.predict(X_test)\n\n## ËÆ°ÁÆóÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄß\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"ÂáÜÁ°ÆÊÄß: {accuracy}\")\n```\n\nÊ≠§‰ª£Á†ÅÁîüÊàê‰∏Ä‰∫õÁ§∫‰æãÊï∞ÊçÆÔºåÂ∞ÜÂÖ∂ÊãÜÂàÜ‰∏∫ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÔºåËÆ≠ÁªÉ‰∏Ä‰∏™ÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºåÂØπÊµãËØïÈõÜËøõË°åÈ¢ÑÊµãÔºåÂπ∂ËÆ°ÁÆóÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄß„ÄÇËØ∑ÈöèÊÑè‰øÆÊîπ‰ª£Á†Å‰ª•Êª°Ë∂≥ÊÇ®ÁöÑÂÖ∑‰ΩìÈúÄÊ±Ç„ÄÇ\n\n\n## Á¨¨5Ê≠•ÔºöÂàÜÊûêÊ®°ÂûãÁöÑÊÄßËÉΩ\n\nÊ†πÊçÆÊàë‰ª¨ÁöÑÊµãËØïÔºå***Qwen2\\.5\\-Coder\\-32B\\-Instruct*** Ê®°ÂûãÂ±ïÁ§∫‰∫ÜÔºö\n\n* **Âº∫Â§ßÁöÑ‰ª£Á†ÅÁîüÊàêËÉΩÂäõ**ÔºåËÉΩÂ§ü‰∏∫ÁªèÂÖ∏ÁºñÁ†ÅÈóÆÈ¢òÁîüÊàêÈ´òÊïà„ÄÅÊòì‰∫éÁêÜËß£ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n* **ÂØπPythonËØ≠Ê≥ïÂíåÊúÄ‰Ω≥ÂÆûË∑µÁöÑÁêÜËß£**ÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ΩøÁî®PythonicËß£ÂÜ≥ÊñπÊ°àÂ¶ÇÂàóË°®Êé®ÂØºÂºèÂíåÊ†ºÂºèÂåñÂ≠óÁ¨¶‰∏≤Êó∂„ÄÇ\n* **ÁÅµÊ¥ªÊÄß**ÔºåËÉΩÂ§üÈÄÇÂ∫îÂêÑÁßçÊèêÁ§∫ÔºåËøôÂØπÂÆûÈôÖÁºñÁ®ãÂä©ÊâãÁöÑ‰ΩøÁî®Ê°à‰æãËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n## ÊΩúÂú®ÁöÑ‰ΩøÁî®Ê°à‰æã\n\nÈâ¥‰∫éÂÖ∂ÊÄßËÉΩÔºåQwen2.5-CoderÊ®°ÂûãÂèØ‰ª•Âú®ÂêÑÁßçÂú∫ÊôØ‰∏≠ÊúâÊïà‰ΩøÁî®Ôºå‰æãÂ¶ÇÔºö\n\n* **ÁºñÁ†ÅÂä©Êâã**ÔºöÈõÜÊàêÂà∞IDEÊàñÊñáÊú¨ÁºñËæëÂô®‰∏≠ÔºåÂ∏ÆÂä©ÂºÄÂèë‰∫∫ÂëòÊõ¥Âø´Âú∞ÁºñÂÜô‰ª£Á†Å„ÄÇ\n* **Ëá™Âä®Âåñ‰ª£Á†ÅÂÆ°Êü•**ÔºöÂçèÂä©ËØÜÂà´ÈîôËØØ„ÄÅ‰ºòÂåñ‰ª£Á†ÅÂπ∂ÊèêÂá∫ÊîπËøõÂª∫ËÆÆ„ÄÇ\n* **ÊïôËÇ≤Â∑•ÂÖ∑**ÔºöÈÄöËøáÁîüÊàêÁ§∫‰æãËß£ÂÜ≥ÊñπÊ°àÂíåËß£ÈáäÔºåÂ∏ÆÂä©Â≠¶ÁîüÂ≠¶‰π†ÁºñÁ†Å„ÄÇ\n\n## ÁªìËÆ∫\n\n**Qwen2.5-Coder**Á≥ªÂàóÔºåÁâπÂà´ÊòØ**32BÊ®°Âûã**Ôºå‰∏∫ÂºÄÂèëËÄÖ„ÄÅÁ†îÁ©∂‰∫∫ÂëòÂíåÂ∏åÊúõÂà©Áî®AIËøõË°å‰ª£Á†ÅÁõ∏ÂÖ≥‰ªªÂä°ÁöÑÁªÑÁªáÊèê‰æõ‰∫ÜÂº∫Â§ßËÄåÂ§öÂäüËÉΩÁöÑÂ∑•ÂÖ∑„ÄÇÂÆÉÂú®EvalPlus„ÄÅAiderÂíåMcEvalÁ≠âÂü∫ÂáÜÊµãËØï‰∏≠ÁöÑÂá∫Ëâ≤Ë°®Áé∞ËØÅÊòé‰∫ÜÂÖ∂Âú®‰ª£Á†ÅÁîüÊàê„ÄÅ‰øÆÂ§çÂíåÊé®ÁêÜÊñπÈù¢ÁöÑÁ´û‰∫â‰ºòÂäø„ÄÇ\n\nÈÄöËøáÂºÄÊ∫êËøô‰∫õÊ®°ÂûãÔºåÈòøÈáå‰∫ë‰∏∫‰∏Ä‰∏™AIÈ©±Âä®ÁöÑÁºñÁ†ÅÂä©ÊâãÊôÆÂèäÁöÑÊú™Êù•Èì∫Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇÊó†ËÆ∫ÊÇ®ÊòØÂ∏åÊúõËá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°ÁöÑÂºÄÂèëËÄÖÔºåËøòÊòØÂ∏åÊúõÂ≠¶‰π†Êñ∞ÁºñÁ®ãÊ¶ÇÂøµÁöÑÂ≠¶ÁîüÔºåQwen2.5-CoderÈÉΩÊòØÊÇ®Â∑•ÂÖ∑ÁÆ±‰∏≠ÂÄºÂæóÊ∑ªÂä†ÁöÑÂèØÈù†Â∑•ÂÖ∑„ÄÇ\n\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/qwen2-5-coder-cosmos-tokenizer-opencoder-and-new-sentencetransformers-great-times-for-open-ffcacf2b29cd","frontmatter":{"title":"Qwen2.5-Coder„ÄÅCosmos Tokenizer„ÄÅOpenCoder ÂíåÊñ∞ÁöÑ SentenceTransformersÔºöÂºÄÊîæÊ∫ê‰ª£Á†ÅÁöÑ‰ºüÂ§ßÊó∂‰ª£","meta_title":"Qwen2.5-Coder„ÄÅCosmos Tokenizer„ÄÅOpenCoder ÂíåÊñ∞ÁöÑ SentenceTransformersÔºöÂºÄÊîæÊ∫ê‰ª£Á†ÅÁöÑ‰ºüÂ§ßÊó∂‰ª£","description":"ÊñáÁ´†‰ªãÁªç‰∫ÜÂ§ö‰∏™ÂºÄÊ∫êÈ°πÁõÆÁöÑËøõÂ±ïÔºåÂåÖÊã¨Qwen2.5-CoderÁ≥ªÂàó„ÄÅCosmos Tokenizer„ÄÅOpenCoderÂíåSentenceTransformers„ÄÇQwen2.5-CoderÊòØ‰∏Ä‰∏™‰∏éGPT-4Á´û‰∫âÁöÑÂºÄÊ∫ê‰ª£Á†ÅLLMÔºåÂÖ∑ÊúâÂ§öÁßçÊ®°ÂûãÂ∞∫ÂØ∏ÂíåÂçìË∂äÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÅ‰øÆÂ§çÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇCosmos TokenizerÂàôÊòØ‰∏ÄÁßçÈ´òÊïàÁöÑÁ•ûÁªèÂàÜËØçÂô®Ôºå‰∏ìÊ≥®‰∫éÂõæÂÉèÂíåËßÜÈ¢ëÂéãÁº©ÔºåÊèê‰æõÊòæËëóÁöÑÂéãÁº©ÁéáÂíåÈ´òË¥®ÈáèÈáçÂª∫„ÄÇOpenCoderÊòØÂÆåÂÖ®ÂºÄÊ∫êÁöÑ‰ª£Á†ÅLLMÔºåËÆ≠ÁªÉ‰∫é2.5‰∏á‰∫ø‰ª§ÁâåÔºåÊîØÊåÅÂ§öÁßçÁºñÁ®ãËØ≠Ë®Ä„ÄÇSentenceTransformersÈÄöËøáOpenVINOÁöÑÈáèÂåñÊäÄÊúØÂÆûÁé∞‰∫ÜCPUÊé®ÁêÜÈÄüÂ∫¶ÁöÑÊòæËëóÊèêÂçá„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*IZdOavxT_8SRCxrg","categories":["Programming","Technology","Natural Language Processing"],"author":"Rifx.Online","tags":["Qwen2.5-Coder","Cosmos","OpenCoder","SentenceTransformers","OpenVINO"],"draft":false,"slug":"blog/qwen2-5-coder-cosmos-tokenizer-opencoder-and-new-sentencetransformers-great-times-for-open-ffcacf2b29cd"},"content":"\nÊàëÊÉ≥Âº∫Ë∞É‰∏Ä‰∫õÂºï‰∫∫Ê≥®ÁõÆÁöÑÂºÄÊ∫êËøõÂ±ïÔºö\n\n* **Qwen2\\.5\\-Coder Á≥ªÂàó**Ôºö‰∏Ä‰∏™ÂºÄÊîæÊ∫ê‰ª£Á†ÅÁöÑ‰ª£Á†Å LLMÔºåÊ≠£Âú®‰∏é GPT\\-4 Á´û‰∫â„ÄÇ\n* **Cosmos Tokenizer**Ôºö‰∏ÄÂ•óÂÖàËøõÁöÑÁ•ûÁªèÂàÜËØçÂô®ÔºåÁî®‰∫éÈ´òÊïàÁöÑÂõæÂÉèÂíåËßÜÈ¢ëÂéãÁº©„ÄÇ\n* **OpenCoder**Ôºö‰∏Ä‰∏™ÂÆåÂÖ®ÂºÄÊ∫êÁöÑ‰ª£Á†Å LLMÔºåËÆ≠ÁªÉ‰∫éÊÉä‰∫∫ÁöÑ 2\\.5 ‰∏á‰∫ø‰∏™Ê†áËÆ∞„ÄÇ\n* **SentenceTransformers ÁöÑÂ§ßÂπÖ CPU Âä†ÈÄü**Ôºö‰ΩøÁî® OpenVINO ÁöÑ int8 ÈùôÊÄÅÈáèÂåñÔºåCPU Êé®ÁêÜÈÄüÂ∫¶ÊèêÂçá 4 ÂÄç„ÄÇ\n\nËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£‰∏Ä‰∏ãÔºÅ\n\n## Qwen2\\.5\\-Coder Á≥ªÂàóÔºöÂºÄÊ∫ê‰∏ÄÊ¨æ‰∏é GPT\\-4 Á´û‰∫âÁöÑ SOTA ‰ª£Á†Å LLM\n\nÈòøÈáå‰∫ëÂÆ£Â∏ÉÂºÄÊ∫êÂèëÂ∏É Qwen2\\.5\\-Coder Á≥ªÂàó‚Äî‚ÄîËøô‰∫õÊ®°ÂûãÂÖ∑Êúâ **Âº∫Â§ß**„ÄÅ**Â§öÊ†∑** Âíå **ÂÆûÁî®** ÁöÑÁâπÁÇπÔºåËá¥Âäõ‰∫éÊé®Âä®ÂºÄÊîæ‰ª£Á†ÅÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLMs) ÁöÑÂèëÂ±ï„ÄÇ\n\nÊóóËà∞Ê®°Âûã **Qwen2\\.5\\-Coder\\-32B\\-Instruct** ‰Ωú‰∏∫ÊúÄÊñ∞ÁöÑÂºÄÊ∫ê‰ª£Á†ÅÊ®°ÂûãÔºåËÆæÂÆö‰∫ÜÊñ∞ÁöÑÂü∫ÂáÜÔºåÂåπÈÖç‰∫Ü GPT\\-4 ÁöÑÁºñÁ†ÅËÉΩÂäõ„ÄÇÂÆÉÂú®ÈÄöÁî®ÂíåÊï∞Â≠¶Êé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n\n\nÂú®‰πãÂâçÂèëÂ∏ÉÁöÑ 1\\.5B Âíå 7B Ê®°ÂûãÂü∫Á°Ä‰∏äÔºå‰ªñ‰ª¨ÂèàÊé®Âá∫‰∫ÜÂõõÁßçÈ¢ùÂ§ñÁöÑÊ®°ÂûãÂ∞∫ÂØ∏Ôºö0\\.5B„ÄÅ3B„ÄÅ14B Âíå 32B„ÄÇQwen2\\.5\\-Coder Áé∞Âú®ËÉΩÂ§üÊª°Ë∂≥ÂπøÊ≥õÁöÑÂºÄÂèëËÄÖÈúÄÊ±ÇÔºåÊ∂µÁõñÂÖ≠Áßç‰∏ªÊµÅÊ®°ÂûãÂ∞∫ÂØ∏„ÄÇ\n\n‰ªñ‰ª¨ËøòÊé¢ËÆ®‰∫Ü Qwen2\\.5\\-Coder Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÈÄÇÁî®ÊÄßÔºåÂåÖÊã¨‰ª£Á†ÅÂä©ÊâãÂíåÂ∑•‰ª∂ÁîüÊàê„ÄÇ\n\nÂÆûÈôÖ‰æãÂ≠êÁ™ÅÊòæ‰∫ÜËØ•Ê®°ÂûãÂú®ÊèêÂçáÂºÄÂèëËÄÖÁîü‰∫ßÂäõÂíå‰ª£Á†ÅË¥®ÈáèÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇ\n\n**Âü∫ÂáÜÊàêÂ∞±**\n\n* **‰ª£Á†ÅÁîüÊàê**ÔºöQwen2\\.5\\-Coder\\-32B\\-Instruct Ê®°ÂûãÂú®ÊµÅË°åÁöÑ‰ª£Á†ÅÁîüÊàêÂü∫ÂáÜ EvalPlus„ÄÅLiveCodeBench Âíå BigCodeBench ‰∏äÂèñÂæó‰∫ÜÈ°∂Â∞ñÊÄßËÉΩ„ÄÇ\n* **‰ª£Á†Å‰øÆÂ§ç**ÔºöËÆ§ËØÜÂà∞Ë∞ÉËØïÂú®ËΩØ‰ª∂ÂºÄÂèë‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåQwen2\\.5\\-Coder\\-32B\\-Instruct Âú®‰ª£Á†Å‰øÆÂ§ç‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂú® Aider Âü∫ÂáÜ‰∏äÂæóÂàÜ 73\\.7ÔºåË°®Áé∞‰∏é GPT\\-4 Áõ∏ÂΩìÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖÈ´òÊïà‰øÆÂ§ç‰ª£Á†ÅÈîôËØØ„ÄÇ\n* **‰ª£Á†ÅÊé®ÁêÜ**ÔºöËØ•Ê®°ÂûãÂ±ïÁé∞‰∫ÜÂÖàËøõÁöÑ‰ª£Á†ÅÊé®ÁêÜËÉΩÂäõÔºåÂ≠¶‰π†‰ª£Á†ÅÊâßË°åËøáÁ®ãÂπ∂ÂáÜÁ°ÆÈ¢ÑÊµãËæìÂÖ•ÂíåËæìÂá∫„ÄÇÂú® Qwen2\\.5\\-Coder\\-7B\\-Instruct ÁöÑÂá∫Ëâ≤Ë°®Áé∞Âü∫Á°Ä‰∏äÔºå32B Ê®°ÂûãËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊé®ÁêÜËÉΩÂäõ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fzH6YE-yl_GrEXwz)\n\n* **Â§öËØ≠Ë®ÄÊîØÊåÅ**ÔºöQwen2\\.5\\-Coder\\-32B\\-Instruct Á≤æÈÄö 40 Â§öÁßçÁºñÁ®ãËØ≠Ë®Ä„ÄÇÂú® McEval ‰∏äÂæóÂàÜ 65\\.9ÔºåÂú® Haskell Âíå Racket Á≠âËØ≠Ë®Ä‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåËøôÂæóÁõä‰∫éÂú®È¢ÑËÆ≠ÁªÉÊúüÈó¥Áã¨ÁâπÁöÑÊï∞ÊçÆÊ∏ÖÊ¥óÂíåÂùáË°°Á≠ñÁï•„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rhyc0T3UZp_2x0r2)\n\nÊÇ®ÂèØ‰ª•Âú® [github](https://proxy.rifx.online/https://github.com/QwenLM/Qwen2.5-Coder) ‰∏äÊâæÂà∞Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n## Cosmos Tokenizer: È´òÁ∫ßÁ•ûÁªèÂàÜËØçÂô®Áî®‰∫éÈ´òÊïàÁöÑÂõæÂÉèÂíåËßÜÈ¢ëÂéãÁº©\n\n**Cosmos Tokenizer** ÊòØ‰∏ÄÂ•óÂÖ®Èù¢ÁöÑÁ•ûÁªèÂàÜËØçÂô®Ôºå‰∏ì‰∏∫ÂõæÂÉèÂíåËßÜÈ¢ëËÆæËÆ°„ÄÇ\n\nÊÇ®Áé∞Âú®ÂèØ‰ª•Â∞ÜÂéüÂßãËßÜËßâÊï∞ÊçÆËΩ¨Êç¢‰∏∫È´òÊïàÁöÑÂéãÁº©Ë°®Á§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*v8k8jLbZ4LYFRUBc.jpg)\n\nÈÄöËøáÊó†ÁõëÁù£Â≠¶‰π†ÂèëÁé∞ÊΩúÂú®Á©∫Èó¥ÔºåËøô‰∫õÂàÜËØçÂô®‰øÉËøõ‰∫ÜÂ§ßËßÑÊ®°Ê®°ÂûãËÆ≠ÁªÉÔºåÂπ∂ÂáèÂ∞ë‰∫ÜÊé®ÁêÜËøáÁ®ã‰∏≠ÁöÑËÆ°ÁÆóÈúÄÊ±Ç„ÄÇ\n\n**ÂàÜËØçÂô®Á±ªÂûã**Ôºö\n\n* **ËøûÁª≠ÂàÜËØçÂô®**ÔºöÂ∞ÜËßÜËßâÊï∞ÊçÆÊò†Â∞ÑÂà∞ËøûÁª≠ÂµåÂÖ•ÔºåÈÄÇÁî®‰∫é‰ªéËøûÁª≠ÂàÜÂ∏ÉÔºàÂ¶ÇÁ®≥ÂÆöÊâ©Êï£Ôºâ‰∏≠ÈááÊ†∑ÁöÑÊ®°Âûã„ÄÇ\n* **Á¶ªÊï£ÂàÜËØçÂô®**ÔºöÂ∞ÜËßÜËßâÊï∞ÊçÆÊò†Â∞ÑÂà∞ÈáèÂåñÁ¥¢ÂºïÔºåÂ∫îÁî®‰∫é‰æùËµñ‰∫§ÂèâÁÜµÊçüÂ§±ËøõË°åËÆ≠ÁªÉÁöÑÊ®°ÂûãÔºåÂ¶Ç VideoPoet„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*a6Hvj8hXJUpOAp9Ber781g.png)\n\n**ÂÖ≥ÈîÆÁâπÊÄß**Ôºö\n\n* **È´òÂéãÁº©‰∏éË¥®Èáè‰øùÁïô**ÔºöÂú®ÊòæËëóÁöÑÂéãÁº©Áéá‰∏éÈ´òË¥®ÈáèÈáçÂª∫‰πãÈó¥ÂèñÂæóÂπ≥Ë°°Ôºå‰øùÁïôÊΩúÂú®Á©∫Èó¥‰∏≠ÁöÑÈáçË¶ÅËßÜËßâÁªÜËäÇ„ÄÇ\n* **ËΩªÈáèÁ∫ßÊó∂Èó¥Âõ†ÊûúÊû∂ÊûÑ**ÔºöÂà©Áî®Âõ†ÊûúÊó∂Èó¥Âç∑ÁßØÂíåÊ≥®ÊÑèÂäõÂ±Ç‰øùÊåÅËßÜÈ¢ëÂ∏ßÁöÑÊó∂Èó¥È°∫Â∫èÔºåÂÆûÁé∞ÂõæÂÉèÂíåËßÜÈ¢ëÁöÑÊó†ÁºùÂàÜËØç„ÄÇ\n* **Âú®Â§öÊ†∑ÂåñÊï∞ÊçÆ‰∏äËÆ≠ÁªÉ**ÔºöÂú®ÂêÑÁßçÁ∫µÊ®™ÊØîÂíåÁ±ªÂà´ÁöÑÈ´òÂàÜËæ®ÁéáÂõæÂÉèÂíåÈïøËßÜÈ¢ë‰∏äËøõË°åËÆ≠ÁªÉÔºå‰ΩøÂÖ∂Âú®Êé®ÁêÜÊó∂ÂØπÊó∂Èó¥ÈïøÂ∫¶‰∏çÊïèÊÑü„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lBO1omEzlr18SPB1zF-vMw.png)\n\n**ÊÄßËÉΩ‰∫ÆÁÇπ**Ôºö\n\n* **ÂçìË∂äÁöÑÂéãÁº©Áéá**ÔºöÊèê‰æõÊòæËëóÁöÑÂéãÁº©ËÉΩÂäõÔºåÈÄüÂ∫¶ÊØî‰ª•ÂâçÁöÑÊñπÊ≥ïÂø´**12ÂÄç**„ÄÇ\n* **È´òË¥®ÈáèÈáçÂª∫**ÔºöÂú®Â≥∞ÂÄº‰ø°Âô™ÊØîÔºàPSNRÔºâÊñπÈù¢ÊòæËëóÊèêÂçáÔºåÂú® DAVIS ËßÜÈ¢ëÊï∞ÊçÆÈõÜ‰∏äË∂ÖË∂äÁé∞ÊúâÊñπÊ≥ïË∂ÖËøá **+4 dB**„ÄÇ\n* **È´òÊïàÁöÑÂàÜËØç**ÔºöËÉΩÂ§üÂú® NVIDIA A100 GPUÔºà80GB ÂÜÖÂ≠òÔºâ‰∏äÁºñÁ†ÅÈ´òËææ **8 Áßí 1080p** Âíå **10 Áßí 720p** ËßÜÈ¢ë„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uYQttZw-MDOCK3oxxLcHbw.png)\n\n**ËØÑ‰º∞‰∏éËµÑÊ∫ê**Ôºö\n\n* **TokenBench Êï∞ÊçÆÈõÜ** ÊòØ‰∏Ä‰∏™Êñ∞Êï∞ÊçÆÈõÜÔºåÊó®Âú®Ê†áÂáÜÂåñËßÜÈ¢ëÂàÜËØçÂô®ËØÑ‰º∞ÔºåÊ∂µÁõñÊú∫Âô®‰∫∫„ÄÅÈ©æÈ©∂Âíå‰ΩìËÇ≤Á≠âÁ±ªÂà´„ÄÇ\n* **ÂÖ¨ÂºÄÂèØÁî®ÊÄß**ÔºöÂÖ∑Êúâ 8x Âíå 16x Á©∫Èó¥ÂéãÁº©Ôºå‰ª•Âèä 4x Âíå 8x Êó∂Èó¥ÂéãÁº©ÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂèØÂú® [GitHub ‚Äî NVIDIA/Cosmos-Tokenizer](https://proxy.rifx.online/https://github.com/NVIDIA/Cosmos-Tokenizer) Ëé∑Âèñ„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ [NVIDIA ÁöÑÂÆòÊñπÂçöÂÆ¢ÊñáÁ´†](https://proxy.rifx.online/https://research.nvidia.com/labs/dir/cosmos-tokenizer/)„ÄÇ\n\n> *ÊÑüË∞¢ÊÇ®ÊäΩÂá∫Êó∂Èó¥Êù•Âà∞ËøôÈáåÔºÅ*\n\n> *Â¶ÇÊûúÊÇ®ÂñúÊ¨¢ËøôÁØáÊñáÁ´†ÔºåËØ∑Ëä±‰∏ÄÁÇπÊó∂Èó¥ [**Âú® Medium ‰∏äÂÖ≥Ê≥®Êàë‰ª¨**](https://proxy.rifx.online/https://medium.com/@datadrifters/subscribe)Ôºå‰∏∫ËøôÁØáÊñáÁ´†ÁÇπËµû 50 Ê¨°Âπ∂Áïô‰∏ãËØÑËÆ∫„ÄÇ*\n\n> *Êàë‰ª¨ËøòÂú®ËøõË°å‰∏Ä‰∏™Âü∫‰∫éÂ∞èÁªÑÁöÑÂüπËÆ≠ **[Áî®‰∫éÊûÑÂª∫ÂÖ®Ê†à GenAI SaaS Â∫îÁî®Á®ãÂ∫è](https://proxy.rifx.online/https://forms.gle/8mfFH4wjhF7BbtRY9)**Ôºå‰πüÊúüÂæÖÂú®ÈáåÈù¢ËßÅÂà∞ÊÇ®ÔºÅ*\n\n## OpenCoder: ÂÆåÂÖ®ÂºÄÊ∫êÁöÑ‰ª£Á†Å LLMÔºåËÆ≠ÁªÉ‰∫é 2.5T ‰ª§Áâå\n\n**OpenCoder** ‰ªãÁªç‰∫Ü‰∏ÄÁ≥ªÂàóÊñ∞ÁöÑÂºÄÊ∫ê‰ª£Á†ÅËØ≠Ë®ÄÊ®°ÂûãÔºåÂåÖÊã¨ **1.5B** Âíå **8B** ÂèÇÊï∞ËßÑÊ®°ÁöÑÂü∫Á°ÄÊ®°ÂûãÂíåËÅäÂ§©Ê®°Âûã„ÄÇ\n\nOpenCoder ÊîØÊåÅËã±ËØ≠Âíå‰∏≠ÊñáÔºåÂÆåÂÖ®‰ªé‰∏Ä‰∏™Â∫ûÂ§ßÁöÑÊï∞ÊçÆÈõÜ **2.5 ‰∏á‰∫ø‰ª§Áâå** ‰∏≠ËÆ≠ÁªÉËÄåÊàêÔºåÂåÖÂê´ 90% ÁöÑÂéüÂßã‰ª£Á†ÅÂíå 10% ÁöÑ‰ª£Á†ÅÁõ∏ÂÖ≥ÁΩëÁªúÊï∞ÊçÆ„ÄÇ\n\nËØ•Ê®°ÂûãÁöÑÊÄßËÉΩÊ∞¥Âπ≥ÂèØ‰∏éÈ¢ÜÂÖàÁöÑ‰ª£Á†Å LLM Áõ∏Â™≤Áæé„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*5rd863dHI-W_2ei7.png)\n\n**ÂÖ≥ÈîÆË¥°ÁåÆ**Ôºö\n\n* Âõ¢ÈòüÊèê‰æõ‰∫ÜÊ®°ÂûãÊùÉÈáç„ÄÅÊé®ÁêÜ‰ª£Á†Å„ÄÅËÆ≠ÁªÉÊï∞ÊçÆ„ÄÅÊï∞ÊçÆÂ§ÑÁêÜÁÆ°ÈÅìÂíåËØ¶ÁªÜÁöÑËÆ≠ÁªÉÂçèËÆÆÔºå‰ΩøÁ†îÁ©∂‰∫∫ÂëòÂíå‰ªé‰∏öËÄÖËÉΩÂ§üÂú®Ê≠§Âü∫Á°Ä‰∏äËøõË°åÊûÑÂª∫ÂíåÂàõÊñ∞„ÄÇ\n* ‰ªñ‰ª¨ËøòÊé®Âá∫‰∫Ü **RefineCode Êï∞ÊçÆÈõÜ**ÔºåËøôÊòØ‰∏Ä‰∏™È´òË¥®Èáè„ÄÅÂèØÈáçÂ§çÁöÑ‰ª£Á†ÅÈ¢ÑËÆ≠ÁªÉËØ≠ÊñôÂ∫ìÔºåÂåÖÂê´ **9600 ‰∫ø‰ª§Áâå**ÔºåÊ∂µÁõñ **607 ÁßçÁºñÁ®ãËØ≠Ë®Ä**„ÄÇ\n\nÊõ¥Â§ö‰ø°ÊÅØËØ∑Êü•Áúã [ÂÆòÊñπÂÖ¨Âëä](https://proxy.rifx.online/https://opencoder-llm.github.io/).\n\n## SentenceTransformers Âä†ÈÄü CPU Êé®ÁêÜÔºåÈÄüÂ∫¶ÊèêÂçá 4 ÂÄç\n\nÊúÄÊñ∞ÂèëÂ∏ÉÁöÑ **SentenceTransformers** ÂºïÂÖ•‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºå‰ΩøÁî® **OpenVINO ÁöÑ int8 ÈùôÊÄÅÈáèÂåñ** Âú® CPU Êé®ÁêÜ‰∏≠ÂÆûÁé∞È´òËææ **4 ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçá**„ÄÇ\n\nÊ≠§Êõ¥Êñ∞‰ºòÂåñ‰∫ÜÂºÄÂèëËÄÖÂú®Â§ÑÁêÜÂ§ßËßÑÊ®°Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°Êó∂ÁöÑËÆ≠ÁªÉÂíåÊé®ÁêÜÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Pd9ESPxjKHaHVgV15pCQig.png)\n\n**‰∏ªË¶ÅÂ¢ûÂº∫**Ôºö\n\n* **OpenVINO int8 ÈùôÊÄÅÈáèÂåñ**ÔºöÂà©Áî® OpenVINO ÁöÑÈáèÂåñÊäÄÊúØÔºåÊ®°ÂûãÂú®‰øùÊåÅÂáÜÁ°ÆÊÄßÁöÑÂâçÊèê‰∏ãÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÊé®ÁêÜÈÄüÂ∫¶„ÄÇÊ≠§‰ºòÂåñË∂ÖË∂ä‰∫ÜÁé∞ÊúâÂêéÁ´ØÔºåÊèêÈ´ò‰∫ÜÂú® CPU Êû∂ÊûÑ‰∏äÁöÑÈÉ®ÁΩ≤ÊïàÁéá„ÄÇ\n* **Âü∫‰∫éÊèêÁ§∫ÁöÑËÆ≠ÁªÉ**ÔºöÊîØÊåÅ‰ΩøÁî®ÊèêÁ§∫ËøõË°åËÆ≠ÁªÉÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßçÁÆÄÂçïÁöÑÊñπÊ≥ïÊù•ÊèêÂçáÊÄßËÉΩÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ°ÁÆóÂºÄÈîÄ„ÄÇ\n* **Âú® NanoBEIR ‰∏äÁöÑ‰æøÊç∑ËØÑ‰º∞**ÔºöÈÄöËøá‰ΩøÁî® NanoBEIRÔºåËøô‰∏™Âº∫Â§ßÁöÑ‰ø°ÊÅØÊ£ÄÁ¥¢Âü∫ÂáÜ BEIR ÁöÑÂ≠êÈõÜÔºå‰æø‰∫éÊõ¥Âø´ÈÄüÂú∞ËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩ„ÄÇ\n* **PEFT ÂÖºÂÆπÊÄß**ÔºöÁé∞Âú®ÊîØÊåÅ **ÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºàPEFTÔºâ**ÔºåÈÄöËøáÂÖÅËÆ∏ËΩªÊùæÊ∑ªÂä†ÂíåÂä†ËΩΩÈÄÇÈÖçÂô®ÔºåÂÆûÁé∞Êõ¥È´òÊïàÁöÑÊ®°ÂûãÂÆöÂà∂„ÄÇ\n\nÊÇ®ÂèØ‰ª•Âú® [github](https://proxy.rifx.online/https://github.com/UKPLab/sentence-transformers/releases/tag/v3.3.0) ‰∏äÊâæÂà∞Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/rag-llm-and-pdf-conversion-to-markdown-text-with-pymupdf-03af00259b5d","frontmatter":{"title":"RAG/LLM Âíå PDFÔºö‰ΩøÁî® PyMuPDF ËΩ¨Êç¢‰∏∫ Markdown ÊñáÊú¨","meta_title":"RAG/LLM Âíå PDFÔºö‰ΩøÁî® PyMuPDF ËΩ¨Êç¢‰∏∫ Markdown ÊñáÊú¨","description":"ÈááÁî® markdown ÊñáÊú¨Ê†ºÂºèËæìÂÖ•Êï∞ÊçÆÂèØÊèêÈ´òÁîüÊàêÁöÑÊñáÊú¨Ë¥®Èáè","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*swPjVuudAhsoRiiw3Ee32w.png","categories":["Programming","Technology","Technology/Web"],"author":"Rifx.Online","tags":["markdown","PyMuPDF","LLM","RAG","PDF"],"draft":false,"slug":"blog/rag-llm-and-pdf-conversion-to-markdown-text-with-pymupdf-03af00259b5d"},"content":"\n\n\n### ‰ª•MarkdownÊñáÊú¨Ê†ºÂºèËæìÂÖ•Êï∞ÊçÆÂèØ‰ª•ÊèêÈ´òÁîüÊàêÊñáÊú¨ÁöÑË¥®Èáè\n\n\n\n## ‰ªãÁªç\n\nÂú®**Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ**Âíå**Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâ**ÁéØÂ¢É‰∏≠Ôºå‰ª•**markdownÊñáÊú¨Ê†ºÂºè**ËæìÂÖ•Êï∞ÊçÆÂÖ∑Êúâ**ÈáçË¶ÅÊÑè‰πâ**„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õËØ¶ÁªÜËÄÉËôëÂõ†Á¥†„ÄÇ\n\n**LLMs** ÊòØÂº∫Â§ßÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÂèØ‰ª•ÁîüÊàêËøûË¥Ø‰∏îÂÖ∑Êúâ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄßÁöÑÊñáÊú¨„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÊúâÊó∂ÂèØËÉΩ‰ºö‰∫ßÁîüÁº∫‰πè‰∫ãÂÆûÂáÜÁ°ÆÊÄßÊàñ‰∏ä‰∏ãÊñáÁöÑÂìçÂ∫î„ÄÇÈÄöËøáÁªìÂêàÂü∫‰∫éÊ£ÄÁ¥¢ÁöÑÊñπÊ≥ïÔºàÂ¶ÇRAGÔºâÔºåÊàë‰ª¨ÂèØ‰ª•ÊèêÈ´òÁîüÊàêÊñáÊú¨ÁöÑË¥®Èáè„ÄÇ\n\n**RAG** ‰ΩøÂæóÂ∞Ü**Â§ñÈÉ®Êï∞ÊçÆ**‚Äî‚ÄîÂú®LLMÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠‰πãÂâçÁº∫Â§±ÁöÑÊï∞ÊçÆ‚Äî‚ÄîÊï¥ÂêàÂà∞ÊñáÊú¨ÁîüÊàêËøáÁ®ã‰∏≠Êàê‰∏∫ÂèØËÉΩ„ÄÇËøôÁßçÂåÖÂê´ÂáèÂ∞ë‰∫Ü‚ÄúÂπªËßâÈóÆÈ¢ò‚ÄùÔºåÂπ∂Â¢ûÂº∫‰∫ÜÊñáÊú¨ÂìçÂ∫îÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàÈÄâÊã© Markdown Áî®‰∫é LLMÔºü\n\n**Markdown** ÊòØ‰∏ÄÁßçËΩªÈáèÁ∫ßÊ†áËÆ∞ËØ≠Ë®ÄÔºåÂÖÅËÆ∏Áî®Êà∑‰ΩøÁî®ÁÆÄÂçïÁöÑËØ≠Ê≥ïÊ†ºÂºèÂåñÁ∫ØÊñáÊú¨„ÄÇÂÆÉÂπøÊ≥õÁî®‰∫éÂàõÂª∫ÁªìÊûÑÂåñÊñáÊ°£ÔºåÁâπÂà´ÊòØÂú® GitHub„ÄÅJupyter Á¨îËÆ∞Êú¨ÂíåÂêÑÁßçÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü‰∏ä„ÄÇÂΩìÂ∞ÜÊï∞ÊçÆËæìÂÖ•Âà∞ LLM Êàñ RAG Á≥ªÁªüÊó∂Ôºå‰ΩøÁî® Markdown Ê†ºÂºèÊèê‰æõ‰∫ÜÂá†‰∏™Â•ΩÂ§ÑÔºö\n\n1. **ÁªìÊûÑÂåñÂÜÖÂÆπ**ÔºöMarkdown ÂÖÅËÆ∏ÊÇ®Â∞Ü‰ø°ÊÅØÁªÑÁªáÊàêÊ†áÈ¢ò„ÄÅÂàóË°®„ÄÅË°®Ê†ºÂíåÂÖ∂‰ªñÁªìÊûÑÂåñÂÖÉÁ¥†„ÄÇËøôÁßçÁªìÊûÑÊúâÂä©‰∫éÊõ¥Â•ΩÂú∞ÁêÜËß£Âíå‰∏ä‰∏ãÊñá‰øùÁïô„ÄÇ\n2. **ÂØåÊñáÊú¨**ÔºöMarkdown ÊîØÊåÅÂü∫Êú¨Ê†ºÂºèÔºåÂ¶ÇÁ≤ó‰Ωì„ÄÅÊñú‰Ωì„ÄÅÈìæÊé•Âíå‰ª£Á†ÅÂùó„ÄÇÂú®ËæìÂÖ•Êï∞ÊçÆ‰∏≠ÂåÖÂê´ÂØåÊñáÊú¨ÂèØ‰ª•Â¢ûÂº∫ËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñá„ÄÇ\n3. **ÂµåÂÖ•ÈìæÊé•ÂíåÂºïÁî®**ÔºöMarkdown ÂÖÅËÆ∏ÊÇ®ÂµåÂÖ•Ë∂ÖÈìæÊé•„ÄÅËÑöÊ≥®ÂíåÂºïÁî®„ÄÇÂú® RAG Âú∫ÊôØ‰∏≠ÔºåËøôÂØπ‰∫éÂºïÁî®Â§ñÈÉ®Êù•Ê∫êÊàñÊèê‰æõÈ¢ùÂ§ñ‰∏ä‰∏ãÊñáËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n4. **Êòì‰∫éÂàõ‰Ωú**ÔºöMarkdown ÂÖ∑ÊúâÂèØËØªÊÄßÔºåÊòì‰∫éÁºñÂÜô„ÄÇ‰ΩúËÄÖÂèØ‰ª•È´òÊïàÂú∞ÂàõÂª∫ÂÜÖÂÆπÔºåËÄåÊó†ÈúÄÂ§çÊùÇÁöÑÊ†ºÂºèÂåñÂ∑•ÂÖ∑„ÄÇ\n5. **ÂàÜÂùó**ÔºöÂØπ‰∫é RAG Á≥ªÁªüËá≥ÂÖ≥ÈáçË¶ÅÔºåÂàÜÂùóÔºà‰πüÁß∞‰∏∫‚ÄúÊãÜÂàÜ‚ÄùÔºâÂ∞ÜÂ§ßÈáèÊñáÊ°£ÊãÜÂàÜ‰∏∫Êõ¥ÊòìÂ§ÑÁêÜÁöÑÈÉ®ÂàÜ„ÄÇÈÄöËøáÊîØÊåÅ MD Ê†ºÂºèÁöÑ PyMuPDF Êï∞ÊçÆÊèêÂèñÔºåÊàë‰ª¨ÊîØÊåÅÂàÜÂùó‰ª•‰øùÊåÅÂÖ∑ÊúâÂÖ±Âêå‰∏ä‰∏ãÊñáÁöÑÊñáÊú¨Âú®‰∏ÄËµ∑„ÄÇ**ÈáçË¶ÅÁöÑÊòØÔºåMD Ê†ºÂºèÁöÑ PyMuPDF ÊèêÂèñÂÖÅËÆ∏ËøõË°å [Á¨¨ 3 Á∫ßÂàÜÂùó](https://readmedium.com/five-levels-of-chunking-strategies-in-rag-notes-from-gregs-video-7b735895694d#b123)**„ÄÇ\n\nÊÄª‰πãÔºåÂú® LLM Âíå RAG ÁéØÂ¢É‰∏≠‰ΩøÁî® Markdown ÊñáÊú¨Ê†ºÂºèÂèØ‰ª•Á°Æ‰øùÊõ¥ÂáÜÁ°ÆÂíåÁõ∏ÂÖ≥ÁöÑÁªìÊûúÔºåÂõ†‰∏∫ÂÆÉÊèê‰æõ‰∫ÜÊõ¥‰∏∞ÂØåÁöÑÊï∞ÊçÆÁªìÊûÑÂíåÊõ¥Áõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÂùóË¥üËΩΩÁªôÊÇ®ÁöÑ LLM„ÄÇ\n\n## PyMuPDF ÊîØÊåÅ PDF ÁöÑ Markdown ËΩ¨Êç¢\n\nËá™Êé®Âá∫‰ª•Êù•ÔºåPyMuPDF ‰∏ÄÁõ¥ËÉΩÂ§ü‰ªé PDF È°µÈù¢‰∏≠ÊèêÂèñÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÁü¢ÈáèÂõæÂΩ¢ÔºåÂπ∂‰∏î‰ªé 2023 Âπ¥ 8 ÊúàËµ∑ÔºåËøòËÉΩÂ§üÊèêÂèñË°®Ê†º„ÄÇËøô‰∫õÂØπË±°Á±ªÂûãÂêÑËá™ÊúâÂÖ∂ÊèêÂèñÊñπÊ≥ïÔºöÊñáÊú¨Êúâ‰∏ÄÁßçÔºåË°®Ê†º„ÄÅÂõæÂÉèÂíåÁü¢ÈáèÂõæÂΩ¢ÂàôÊúâÂÖ∂‰ªñÊñπÊ≥ï„ÄÇ‰∏∫‰∫ÜÊª°Ë∂≥ RAG ÁöÑË¶ÅÊ±ÇÔºåÊàë‰ª¨Â∞ÜËøô‰∫õ‰∏çÂêåÁöÑÊèêÂèñÊñπÂºèÂêàÂπ∂ÔºåÁîüÊàê‰∏Ä‰∏™Áªü‰∏ÄÁöÑ **Markdown** Â≠óÁ¨¶‰∏≤Ôºå‰ª•‰∏ÄËá¥Âú∞Ë°®Á§∫È°µÈù¢ÁöÑÊï¥‰ΩìÂÜÖÂÆπ„ÄÇ\n\nÊâÄÊúâËøô‰∫õÈÉΩÂÆûÁé∞‰∏∫ [‰∏Ä‰∏™ Python ËÑöÊú¨](https://github.com/pymupdf/RAG/blob/main/helpers/pymupdf_rag.py)„ÄÇÂÆÉÂèØ‰ª•Ë¢´ÂÖ∂‰ªñËÑöÊú¨‰Ωú‰∏∫Ê®°ÂùóÂØºÂÖ•ÔºåÊàñËÄÖÂú®ÁªàÁ´ØÁ™óÂè£‰∏≠ÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§Ë°åË∞ÉÁî®Ôºö\n\n`$ python pymupdf_rag.py input.pdf [-pages PAGES]`\n\nÂÆÉÂ∞ÜÁîüÊàê‰∏Ä‰∏™ **Markdown** Ê†ºÂºèÁöÑÊñáÊú¨Êñá‰ª∂ÔºàÁß∞‰∏∫ `input.md`Ôºâ„ÄÇÂèØÈÄâÂèÇÊï∞ `PAGES` ÂÖÅËÆ∏Â∞ÜËΩ¨Êç¢ÈôêÂà∂‰∏∫ PDF ÊÄªÈ°µÈù¢ÁöÑ‰∏Ä‰∏™Â≠êÈõÜ„ÄÇÂ¶ÇÊûúÁúÅÁï•ÔºåÂàôÂ§ÑÁêÜÊï¥‰∏™ PDF„ÄÇ\n\n## Markdown ÂàõÂª∫ÁªÜËäÇ\n\n### ÈÄâÊã©Ë¶ÅËÄÉËôëÁöÑÈ°µÈù¢\n\n‚Äú`-pages`‚Äù ÂèÇÊï∞ÊòØ‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÔºåÁî±ÊâÄÈúÄÁöÑÈ°µÈù¢ÁºñÂè∑Ôºà‰ªé1ÂºÄÂßãÔºâÁªÑÊàêÔºåÁî®‰∫éËÄÉËôëËøõË°åmarkdownËΩ¨Êç¢„ÄÇÂèØ‰ª•ÁªôÂá∫Â§ö‰∏™È°µÈù¢ÁºñÂè∑ËßÑËåÉÔºå‰ΩøÁî®ÈÄóÂè∑ÂàÜÈöî„ÄÇÊØè‰∏™ËßÑËåÉÂèØ‰ª•ÊòØ‰∏Ä‰∏™Êï¥Êï∞Êàñ‰∏§‰∏™Áî®‚Äú`-`‚ÄùËøûÊé•ÁöÑÊï¥Êï∞ÔºåÊåáÂÆö‰∏Ä‰∏™È°µÈù¢ËåÉÂõ¥„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n‚Äú`-pages 1‚Äì10,15,20-N`‚Äù\n\nËøôÂ∞ÜÂåÖÊã¨Á¨¨1È°µÂà∞Á¨¨10È°µ„ÄÅÁ¨¨15È°µ‰ª•ÂèäÁ¨¨20È°µÂà∞Êñá‰ª∂Êú´Â∞æÔºàÂ§ßÂÜô‚ÄúN‚ÄùË¢´ËßÜ‰∏∫ÊúÄÂêé‰∏ÄÈ°µÁöÑÁºñÂè∑Ôºâ„ÄÇ\n\n### ËØÜÂà´Ê†áÈ¢ò\n\nÂú®Ë∞ÉÁî®Êó∂ÔºåÁ®ãÂ∫èÊ£ÄÊü•ÁªôÂÆöÈ°µÈù¢‰∏äÁöÑÊâÄÊúâÊñáÊú¨Âπ∂ÊâæÂá∫ÊúÄÂ∏∏Áî®ÁöÑÂ≠ó‰ΩìÂ§ßÂ∞è„ÄÇËØ•ÂÄºÔºà‰ª•ÂèäÊâÄÊúâËæÉÂ∞èÁöÑÂ≠ó‰ΩìÂ§ßÂ∞èÔºâË¢´ÂÅáÂÆö‰∏∫ **Ê≠£ÊñáÊñáÊú¨**„ÄÇËæÉÂ§ßÁöÑÂ≠ó‰ΩìÂ§ßÂ∞èË¢´ÂÅáÂÆö‰∏∫ **Ê†áÈ¢òÊñáÊú¨**„ÄÇ\n\nÊ†πÊçÆÂÆÉ‰ª¨Âú®Â≠ó‰ΩìÂ§ßÂ∞èÂ±ÇÁ∫ß‰∏≠ÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÔºåÊ†áÈ¢òÊñáÊú¨Â∞ÜÂâçÈù¢Âä†‰∏ä‰∏Ä‰∏™ÊàñÂ§ö‰∏™ markdown Ê†áÈ¢ò `#` Ê†áÁ≠æÂ≠óÁ¨¶„ÄÇ\n\n### ÊåâÈ°µÈù¢Âå∫ÂüüËØÜÂà´Â§ÑÁêÜÊ®°Âºè\n\nÊØè‰∏™È°µÈù¢‰∏äÁöÑÊâÄÊúâÊñáÊú¨È¶ñÂÖàÂ∞ÜË¢´ÂàÜÁ±ª‰∏∫**Ê†áÂáÜ**ÊñáÊú¨Êàñ**Ë°®Ê†º**ÊñáÊú¨„ÄÇÁÑ∂ÂêéÔºåÈ°µÈù¢ÂÜÖÂÆπÂ∞Ü‰ªé‰∏äÂà∞‰∏ãÊèêÂèñÔºåÂπ∂ËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºè„ÄÇ\n\nËøôÊúÄÂ•ΩÈÄöËøá‰∏Ä‰∏™‰æãÂ≠êÊù•Ëß£ÈáäÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*u5fv2aAIvDaaAd6H.png)\n\nËØ•È°µÈù¢ÊòæÁ§∫ÁöÑÂÜÖÂÆπ‰ª£Ë°®ÂÖ∏ÂûãÊÉÖÂÜµÔºö\n\n* ‰∏§‰∏™Ë°®Ê†ºÔºåÂÖ∑ÊúâÈÉ®ÂàÜÈáçÂè†ÁöÑÂûÇÁõ¥‰ΩçÁΩÆ„ÄÇ‰∏Ä‰∏™Ë°®Ê†ºÊ≤°ÊúâÊ†áÈ¢òÔºåÂè¶‰∏Ä‰∏™Ë°®Ê†ºÊúâ**Â§ñÈÉ®**ÂàóÊ†áÈ¢ò„ÄÇ\n* Êúâ‰∏ÄË°å**Ê†áÈ¢ò**ÂíåÂ§ö‰∏™Á∫ßÂà´ÁöÑ**Ê†áÈ¢ò**„ÄÇ\n* **Ê≠£ÊñáÊñáÊú¨**ÂåÖÂê´Â§öÁßçÊ†∑ÂºèÁªÜËäÇÔºåÂ¶Ç**Á≤ó‰Ωì**„ÄÅ*Êñú‰Ωì*Âíå`Ë°åÂÜÖ‰ª£Á†Å`„ÄÇ\n* ÊúâÂ∫èÂíåÊó†Â∫èÂàóË°®„ÄÇ\n* ‰ª£Á†ÅÁâáÊÆµ„ÄÇ\n\nÂ∏ÉÂ±ÄÂàÜÊûêÂ∞ÜÁ°ÆÂÆö‰∏â‰∏™Âå∫ÂüüÂπ∂ÈÄâÊã©ÈÄÇÂΩìÁöÑÂ§ÑÁêÜÊ®°ÂºèÔºö**(1)** ÊñáÊú¨Ôºå**(2)** Ë°®Ê†ºÔºå**(3)** ÊñáÊú¨„ÄÇ\n\nÁîüÊàêÁöÑMarkdownÊñáÊú¨Âø†ÂÆûÂú∞ÂèçÊò†‰∫Ü‰∏äËø∞ÂÜÖÂÆπ‚Äî‚ÄîÂú®ËøôÁßçÊ†ºÂºè‰∏≠Â∞ΩÂèØËÉΩÂÅöÂà∞„ÄÇ\n\n‰Ωú‰∏∫‰∏Ä‰∏™‰æãÂ≠êÔºåËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏ãÂÖ∑ÊúâÂ§ñÈÉ®Ê†áÈ¢òÁöÑË°®Ê†ºÁöÑËæìÂá∫Ôºö\n\n```python\n|Column1|Column2|\n\n|---|---|\n\n|Cell (0, 0)|Cell (0, 1)|\n\n|Cell (1, 0)|Cell (1, 1)|\n\n|Cell (2, 0)|Cell (2, 1)|\n```\nËøôÊòØ‰∏éGitHubÂÖºÂÆπÁöÑÊ†ºÂºèÔºåÂÖ∑ÊúâÊúÄÂ∞èÁöÑÂèØËÉΩ‰ª§ÁâåÂ§ßÂ∞è‚Äî‚ÄîËøôÊòØ‰øùÊåÅËæìÂÖ•Âà∞RAGÁ≥ªÁªüÁöÑÂ∞èÂûãÂåñÁöÑÈáçË¶ÅÊñπÈù¢„ÄÇ\n\n**ÂàóËæπÊ°Ü**Áî±‚Äú`|`‚ÄùÂ≠óÁ¨¶Ë°®Á§∫„ÄÇÂ¶ÇÊûúÊñáÊú¨Ë°åÂêéÈù¢Ë∑üÁùÄ‚Äú`|---|---| ‚Ä¶`‚ÄùÂΩ¢ÂºèÁöÑË°åÔºåÂàôÂÅáÂÆöËØ•ÊñáÊú¨Ë°åÊòØ**Ë°®Â§¥**„ÄÇÂÆåÊï¥ÁöÑ**Ë°®Ê†ºÂÆö‰πâ**ÂøÖÈ°ªÂâçÂêéËá≥Â∞ëÊúâ‰∏ÄË°åÁ©∫Ë°å„ÄÇ\n\nËØ∑Ê≥®ÊÑèÔºåÁî±‰∫éÊäÄÊúØÂéüÂõ†ÔºåMarkdownË°®Ê†ºÂøÖÈ°ªÊúâ‰∏Ä‰∏™Ê†áÈ¢òÔºåÂõ†Ê≠§Â¶ÇÊûúÊ≤°ÊúâÂ§ñÈÉ®Ê†áÈ¢òÔºåÂ∞ÜÈÄâÊã©Á¨¨‰∏ÄË°å‰Ωú‰∏∫Ë°®Â§¥„ÄÇ\n\n‰∏∫‰∫ÜÁ°ÆËÆ§Êï¥‰ΩìÂáÜÁ°ÆÊÄßÔºå‰ª•‰∏ãÊòØMarkdownËß£ÊûêÂô®Â¶Ç‰ΩïÂ§ÑÁêÜÂÆåÊï¥È°µÈù¢ÁöÑÁ§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Ge83uj7FiM4T6XFn)\n\n## ‰ª•ÁºñÁ®ãÊñπÂºèË∞ÉÁî® Markdown ËΩ¨Êç¢Âô®\n\nÈô§‰∫ÜÂú®ÂëΩ‰ª§Ë°å‰∏≠ÊâßË°åÁ®ãÂ∫èÂ§ñÔºåMarkdown ËΩ¨Êç¢‰πüÂèØ‰ª•ÈÄöËøáÁ®ãÂ∫èËØ∑Ê±ÇÔºö\n\n```python\nimport fitz\nfrom pymupdf_rag import to_markdown  # import Markdown converter\n\ndoc = fitz.open(‚Äúinput.pdf‚Äù)  # open input PDF\n\n## define desired pages: this corresponds ‚Äú-pages 1-10,15,20-N‚Äù\npage_list = list(range(9)) + [14] + list(range(19, len(doc) ‚Äì 1))\n\n## get markdown string for all pages\nmd_text = to_markdown(doc, pages=page_list)\n\n## write markdown string to some file\noutput = open(‚Äúout-markdown.md‚Äù, ‚Äúw‚Äù)\noutput.write(md_text)\noutput.close()\n```\n\n## ÁªìËÆ∫\n\nÈÄöËøáÈõÜÊàê PyMuPDF ÁöÑÊèêÂèñÊñπÊ≥ïÔºåPDF È°µÈù¢ÁöÑÂÜÖÂÆπÂ∞ÜË¢´Âø†ÂÆûÂú∞ËΩ¨Êç¢‰∏∫ÂèØÁî®‰Ωú RAG ËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑËæìÂÖ•ÁöÑ Markdown ÊñáÊú¨„ÄÇ\n\nËØ∑ËÆ∞‰ΩèÔºåÊàêÂäüÁöÑ RAG ËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÂÖ≥ÈîÆÂú®‰∫éÂÆÉËÉΩÂ§üËÆøÈóÆÁöÑ‰ø°ÊÅØÁöÑË¥®ÈáèÂíåÂÆåÊï¥ÊÄß„ÄÇ\n\nÂêØÁî® PyMuPDF ÁöÑ Markdown ÊèêÂèñÁ°Æ‰øù‰ªé PDF ‰∏≠Ëé∑ÂèñËøô‰∫õ‰ø°ÊÅØ‰∏ç‰ªÖÊòØÂèØËÉΩÁöÑÔºåËÄå‰∏îÊòØÁÆÄÂçïÁöÑÔºåÂ±ïÁ§∫‰∫ÜËØ•Â∫ìÁöÑÂº∫Â§ßÂíåÂØπÂºÄÂèëËÄÖÁöÑÂèãÂ•Ω„ÄÇÁ•ùÁºñÁ†ÅÊÑâÂø´ÔºÅ\n\n### Ê∫ê‰ª£Á†Å\n\n* [RAG/helpers/pymupdf\\_rag.py (github.com)](https://github.com/pymupdf/RAG/blob/main/helpers/pymupdf_rag.py)\n\n### ÂèÇËÄÉÊñáÁåÆ\n\n* [5 Levels of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n\n### Áõ∏ÂÖ≥ÂçöÂÆ¢\n\n* [‰ΩøÁî® ChatGPT API Âíå PyMuPDF ÊûÑÂª∫ RAG ËÅäÂ§©Êú∫Âô®‰∫∫ GUI](https://readmedium.com/building-a-rag-chatbot-gui-with-the-chatgpt-api-and-pymupdf-9ea8c7fc4ab5)\n* [‰ΩøÁî® ChatGPT Âíå PyMUPDF ÂàõÂª∫ RAG ËÅäÂ§©Êú∫Âô®‰∫∫](https://readmedium.com/creating-a-rag-chatbot-with-chatgpt-and-pymupdf-f6c30907ae27)\n* [RAG/LLM Âíå PDFÔºöÂ¢ûÂº∫ÊñáÊú¨ÊèêÂèñ](https://readmedium.com/rag-llm-and-pdf-enhanced-text-extraction-5c5194c3885c)\n\n"},{"lang":"zh","group":"blog","slug":"blog/ragate-adaptive-rag-for-conversational-ai-94b5ca469b7d","frontmatter":{"title":"RAGateÔºöÁî®‰∫éÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑËá™ÈÄÇÂ∫î RAG","meta_title":"RAGateÔºöÁî®‰∫éÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑËá™ÈÄÇÂ∫î RAG","description":"RAGateÊòØ‰∏ÄÁßçËá™ÈÄÇÂ∫îÊú∫Âà∂ÔºåÊó®Âú®‰ºòÂåñÂØπËØùAIÁ≥ªÁªü‰∏≠Â§ñÈÉ®Áü•ËØÜ‰∏éÂÜÖÈÉ®Áü•ËØÜÁöÑ‰ΩøÁî®„ÄÇÈÄöËøáÂä®ÊÄÅËØÑ‰º∞‰ΩïÊó∂Ê£ÄÁ¥¢Â§ñÈÉ®‰ø°ÊÅØÔºåRAGateÊèêÈ´ò‰∫ÜÂìçÂ∫îÁöÑÁõ∏ÂÖ≥ÊÄßÂíåÂáÜÁ°ÆÊÄßÔºåÈÅøÂÖç‰∫ÜÂØπÂ§ñÈÉ®Áü•ËØÜÁöÑËøáÂ∫¶‰æùËµñ„ÄÇËØ•ÊñπÊ≥ïÂÖ∑ÊúâÂ§öÁßçÂèò‰ΩìÔºåÂ¶ÇRAGate-Prompt„ÄÅRAGate-PEFTÂíåRAGate-MHAÔºåÈÄÇÁî®‰∫éÂåªÁñó„ÄÅÂÆ¢Êà∑ÊîØÊåÅÁ≠âÂ§ö‰∏™È¢ÜÂüüÔºåËÉΩÂ§üÊòæËëóÊèêÂçáÁî®Êà∑‰ΩìÈ™åÂíåÁ≥ªÁªüÊÄßËÉΩ„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8wzI-5BRV1-br0e3MBVD2g.png","categories":["Chatbots","Natural Language Processing","Machine Learning"],"author":"Rifx.Online","tags":["RAGate","conversational","retrieval","latency","personalization"],"draft":false,"slug":"blog/ragate-adaptive-rag-for-conversational-ai-94b5ca469b7d"},"content":"\n\n\nÊûÑÂª∫ÂØπËØù AI Á≥ªÁªüÊòØÂõ∞ÈöæÁöÑÔºÅÔºÅÔºÅ\n\nËøôËôΩÁÑ∂ÂèØË°åÔºå‰ΩÜ‰πü**Â§çÊùÇ„ÄÅËÄóÊó∂‰∏îËµÑÊ∫êÂØÜÈõÜ**„ÄÇ\n\nÊåëÊàòÂú®‰∫éËÆæËÆ°ËÉΩÂ§üÁêÜËß£ÂíåÁîüÊàêÁ±ª‰∫∫ÂìçÂ∫îÁöÑÁ≥ªÁªüÔºåÂπ∂Á°Æ‰øùËøô‰∫õÁ≥ªÁªüËÉΩÂ§üÊúâÊïàÂú∞‰∏éÁî®Êà∑‰∫íÂä®ÔºåÈÄÇÂ∫îÂØπËØùÁöÑÁªÜÂæÆÂ∑ÆÂà´„ÄÇ\n\nÈùûÂ∏∏ÊµÅË°åÁöÑ**RAGÔºàÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºâ**ÈÄöËøáÂ∞ÜÂ§ñÈÉ®Áü•ËØÜ‰∏é LLM ÁöÑÂÜÖÈÉ®Áü•ËØÜÊó†ÁºùÈõÜÊàêÔºåÂΩªÂ∫ïÊîπÂèò‰∫ÜÂØπËØù AI„ÄÇÈÄöËøáÂ∞Ü RAG Â∫îÁî®‰∫éÊÇ®ÁöÑÂïÜ‰∏öÊï∞ÊçÆÔºåÊÇ®ÁöÑÂÆ¢Êà∑ÂèØ‰ª•Áî®Ëá™ÁÑ∂ËØ≠Ë®ÄËØ¢ÈóÆ‰ªñ‰ª¨ÁöÑÊï∞ÊçÆÔºå‰ªéËÄå‰øÉËøõÊó†Áºù‰∫íÂä®„ÄÇ\n\n**ÁÑ∂ËÄåÔºåÊúâ‰∏Ä‰∏™Ë≠¶ÂëäÔºö** Âú®‰ΩøÁî® RAG Êó∂ÔºåÂæàÊòéÊòæÂπ∂‰∏çÊòØÊØè‰∏™Êü•ËØ¢ÈÉΩÈúÄË¶Å‰ªé‚ÄúÂ§ñÈÉ®Áü•ËØÜ‚Äù‰∏≠Ëé∑ÂèñÁ≠îÊ°à„ÄÇËøáÂ∫¶‰æùËµñÂ§ñÈÉ®Êù•Ê∫êÂèØËÉΩ‰ºöÁ†¥ÂùèÁúüÊ≠£ÁöÑ‰∫íÂä®„ÄÇÂ∞±ÂÉè‰∏éÊüê‰∫∫‰∫§Ë∞àÔºåÂØπ‰∫éÊØè‰∏™ÈóÆÈ¢òÈÉΩË¶ÅÂéªÁøª‰∏ÄÊú¨‰π¶Êù•ÊûÑÂª∫ÊÇ®ÁöÑÂõûÁ≠îÔºåÂç≥‰ΩøÊÇ®Â∑≤ÁªèÂØπËØ•‰∏ªÈ¢òÊúâÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£„ÄÇÊõ¥Á≥üÁ≥ïÁöÑÊòØÔºåÊÇ®ÂèØËÉΩÊâæ‰∏çÂà∞‰ªª‰ΩïÂÖ≥‰∫éËØ•‰∏ªÈ¢òÁöÑ‰π¶ÔºåÊúÄÁªàÂõûÁ≠î‚ÄúÊàë‰∏çÁü•ÈÅì‚ÄùÔºåÂ∞ΩÁÆ°ÊÇ®Êã•ÊúâÂèØ‰ª•Êèê‰æõÊõ¥Ê∑±ÂàªÁ≠îÊ°àÁöÑÂÜÖÈÉ®Áü•ËØÜ„ÄÇ\n\nÊòæÁÑ∂ÔºåÂú®‰ΩøÁî® RAG Êó∂ÔºåÈúÄË¶Å‰∏ÄÁßçÊú∫Âà∂Êù•Á°ÆÂÆöÂú®Êé®ÁêÜÊó∂‰ΩïÊó∂Âà©Áî®‚ÄúÂ§ñÈÉ®Áü•ËØÜ‚Äù‰∏é‚ÄúÂÜÖÈÉ®Áü•ËØÜ‚Äù„ÄÇ\n\nÂºïÂÖ•**RAGate**‚Äî‚Äî‰∏ÄÁßç‰∫åÂÖÉÂºÄÂÖ≥ÔºåÊó®Âú®Âä®ÊÄÅËØÑ‰º∞‰ΩïÊó∂Âà©Áî®Â§ñÈÉ®Áü•ËØÜ‰ª•Âèä‰ΩïÊó∂‰æùËµñÂÜÖÈÉ®ËßÅËß£„ÄÇÁî± Xi Wang„ÄÅProcheta Sen„ÄÅRuizhe Li Âíå Emine Yilmaz ÊèêÂá∫ÔºåÂπ∂‰∫é 2024 Âπ¥ 7 ÊúàÂèëÂ∏É‰∫é [**ArXiv**](https://proxy.rifx.online/https://arxiv.org/abs/2407.21712) **ÔºàÁî®‰∫éÂØπËØùÁ≥ªÁªüÁöÑËá™ÈÄÇÂ∫îÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºâ„ÄÇ**\n\nËÆ©Êàë‰ª¨ÈÄöËøáÁ§∫‰æãËøõ‰∏ÄÊ≠•‰∫ÜËß£„ÄÇ\n\n## ‰ªÄ‰πàÊòØÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÔºü\n\n**ÂØπËØù**ÊòØ‰∏™‰Ωì‰πãÈó¥ÊÄùÊÉ≥„ÄÅÊÉÖÊÑüÂíå‰ø°ÊÅØÁöÑ‰∫§ÊµÅÔºåÈÄÇÂ∫îËØ≠Ë∞É„ÄÅ‰∏ä‰∏ãÊñáÂíåÁªÜÂæÆÁöÑÊöóÁ§∫Ôºå‰ª•ÂºïÂØº‰∫íÂä®„ÄÇ‰∫∫Á±ªÂ§©ÁîüÈÄÇÂêàËøõË°åÂØπËØùÔºåÂõ†‰∏∫ÂÖ∑Â§áÊÉÖÂïÜ„ÄÅÁ§æ‰∫§ËÉΩÂäõÂíåÊñáÂåñÊé•Ëß¶Á≠âÁâπË¥®ÔºåËøôÂ∏ÆÂä©Êàë‰ª¨ÁêÜËß£ÁªÜÂæÆÂ∑ÆÂà´Âπ∂ÈÄÇÂ∫î‰∏çÂêåÁöÑÁ§æ‰∫§ÁéØÂ¢É„ÄÇ\n\n**ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ**Êó®Âú®ÈÄöËøáÊäÄÊúØÂ§çÂà∂ËøôÁßçÁ±ª‰∫∫‰∫íÂä®ÔºåÁêÜËß£ÂíåÁîüÊàêËá™ÁÑ∂„ÄÅÁ¨¶Âêà‰∏ä‰∏ãÊñáÁöÑ„ÄÅÂºï‰∫∫ÂÖ•ËÉúÁöÑÂõûÂ∫î„ÄÇÂÆÉÈÄÇÂ∫îÁî®Êà∑ËæìÂÖ•Ôºå‰Ωø‰∫íÂä®ÊµÅÁïÖËÄåÂä®ÊÄÅÔºåÂÉè‰∫∫Á±ª‰πãÈó¥ÁöÑÂØπËØù„ÄÇ\n\n## ‰ªÄ‰πàÊòØ AI Á≥ªÁªüÁöÑÂ§ñÈÉ®Áü•ËØÜÂíåÂÜÖÈÉ®Áü•ËØÜÔºü\n\nÂú®ÂºÄÂ§¥ÊÆµËêΩ‰∏≠ÔºåÊàëÊèêÂà∞‰∫Ü‰∏§‰∏™ÂÖ≥ÈîÆÊúØËØ≠‚Äî‚ÄîÂ§ñÈÉ®Áü•ËØÜÂíåÂÜÖÈÉ®Áü•ËØÜ„ÄÇËÆ©Êàë‰ª¨Ëä±‰∏ÄÁÇπÊó∂Èó¥Êù•ÊæÑÊ∏ÖËøô‰∫õÊ¶ÇÂøµÔºåÂõ†‰∏∫ÁêÜËß£ÂÆÉ‰ª¨Â∞Ü‰ΩøÂ≠¶‰π† RAGate ÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇ\n\n**External knowledge** ÂåÖÂê´‰∏çÂ±û‰∫é AI Ê®°ÂûãÁöÑÂõ∫Êúâ‰ø°ÊÅØÔºåËÄåÊòØ‰ªéÂ§ñÈÉ®Êù•Ê∫êÊ£ÄÁ¥¢ÁöÑ„ÄÇÊù•Ê∫êÂåÖÊã¨ÁªìÊûÑÂåñÊï∞ÊçÆÂ≠òÂÇ®Â∫ì„ÄÅAPI„ÄÅÊåáÂçó„ÄÅÂ∏∏ËßÅÈóÆÈ¢òËß£Á≠îÂíåÁΩëÁªúÊù•Ê∫êÁ≠âÈùûÁªìÊûÑÂåñÁü•ËØÜÂ∫ì„ÄÇÂ§ñÈÉ®Áü•ËØÜÁöÑ‰∏ªË¶Å‰ΩúÁî®ÊòØÊèê‰æõ‰∫ãÂÆû„ÄÅÊúÄÊñ∞Âíå‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´ò AI ÂìçÂ∫îÁöÑÂáÜÁ°ÆÊÄßÂíåÂÖ®Èù¢ÊÄß„ÄÇ\n\n**Internal knowledge** ÊåáÁöÑÊòØÂµåÂÖ•Âú® AI Ê®°Âûã‰∏≠ÁöÑÂÜÖÁΩÆÁü•ËØÜÂíåÂ§ÑÁêÜËÉΩÂäõÔºåËøô‰∫õÁü•ËØÜÂíåËÉΩÂäõÂü∫‰∫éÂÖ∂ËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇÊù•Ê∫êÂåÖÊã¨Êù•Ëá™Â§öÊ†∑ÂåñÊï∞ÊçÆÈõÜÁöÑÈ¢ÑËÆ≠ÁªÉÁü•ËØÜÔºåÂåÖÊã¨ËØ≠Ë®ÄÊ®°Âºè„ÄÅËØ≠Ê≥ï„ÄÅÂÖ±‰∫´‰∫ãÂÆûÂíå‰∏ÄËà¨‰∏ñÁïåÁü•ËØÜ„ÄÅÊù•Ëá™ËøáÂéª‰∫§‰∫íÁöÑËÆ∞ÂøÜÁöÑ‰∏ä‰∏ãÊñáÊÑèËØÜÔºå‰ª•Âèä AI ÁöÑËØ≠‰πâÁêÜËß£ÂíåÁêÜËß£ËÉΩÂäõ„ÄÇ\n\n## RAG ÂíåÊä§Ê†è ‚Äî Âº∫Â§ßÁöÑÁªÑÂêàÔºå‰ΩÜÊúâÂ±ÄÈôêÊÄßÔºÅ\n\nRAG ÁªìÂêà‰∫Ü‰∏§‰∏™Âº∫Â§ßÁöÑÂÖÉÁ¥†Ôºö(1\\) Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ§ÑÁêÜËá™ÁÑ∂ËØ≠Ë®ÄÁöÑËÉΩÂäõÔºå‰ª•Ëß£ÈáäÂíåÁîüÊàêÁ±ª‰∫∫ÊñáÊú¨„ÄÇ (2\\) Ê£ÄÁ¥¢ÂíåÂ¢ûÂº∫Â§ñÈÉ®ÊúÄÊñ∞‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇ\n\nËÆ∏Â§ö RAG ÂÆûÁé∞ÈÉΩÂåÖÂê´ **Êä§Ê†è**„ÄÅÁ∫¶ÊùüÊàñËßÑÂàôÔºå‰ª•ÂºïÂØºÁ≥ªÁªüÁöÑË°å‰∏∫ÊúùÁùÄË¥üË¥£‰ªªÂíåÈ¢ÜÂüüÁïåÂÆöÁöÑ‰∫∫Â∑•Êô∫ËÉΩ„ÄÇËøô‰∫õÊä§Ê†èÈÄöÂ∏∏‰ºòÂÖà‰ΩøÁî®Â§ñÈÉ®Áü•ËØÜÔºåËÄå‰∏çÊòØÊ®°ÂûãÁöÑÂÜÖÈÉ®Áü•ËØÜÔºå‰ª•Á°Æ‰øùÂìçÂ∫îÁöÑÂèØÈ¢ÑÊµãÊÄß„ÄÇ‰∏•Ê†ºÂ∫îÁî®Ëøô‰∫õÊä§Ê†èÊúâÊó∂ÂèØËÉΩÂØºËá¥Ê¨°‰ºòÁªìÊûúÔºö\n\n* **ËøáÂ∫¶‰æùËµñÂ§ñÈÉ®Êù•Ê∫êÔºö** Á≥ªÁªüÂèØËÉΩË¢´Ëø´ÂØªÊ±ÇÂ§ñÈÉ®‰ø°ÊÅØÔºåÂç≥‰ΩøÊòØÂØπ‰∫é‰∏ÄËà¨ÈóÆÈ¢òÔºåLLM ÁöÑÂÜÖÈÉ®Áü•ËØÜÂèØËÉΩÂ∑≤ÁªèË∂≥Â§ü„ÄÇ\n* **ÂìçÂ∫îÊµÅÁïÖÊÄßÈôç‰ΩéÁöÑÊΩúÂú®È£éÈô©Ôºö** ÈÄöËøáÈôêÂà∂ÂÜÖÈÉ®Áü•ËØÜÔºåÁ≥ªÁªüÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÂèØËÉΩ‰∫ßÁîü‰∏çÈÇ£‰πàËá™ÁÑ∂Êàñ‰∏ä‰∏ãÊñá‰∏çÈÄÇÂΩìÁöÑÂìçÂ∫î„ÄÇ\n* **Âª∂ËøüÂ¢ûÂä†Ôºö** ‰∏çÊñ≠Ê£ÄÁ¥¢Â§ñÈÉ®‰ø°ÊÅØÂèØËÉΩÂØºËá¥ÂìçÂ∫îÊó∂Èó¥ÊØî‰æùËµñÂÜÖÈÉ®Áü•ËØÜÊó∂Êõ¥ÊÖ¢„ÄÇ\n* **ÈîôÂ§±Êú∫‰ºöÔºö** ÂµåÂÖ•Âú® LLM ÂèÇÊï∞‰∏≠ÁöÑÂπøÊ≥õÁü•ËØÜÂèØËÉΩÊú™Ë¢´ÂÖÖÂàÜÂà©Áî®ÔºåÂèØËÉΩ‰ºöÈîôËøáÊúâ‰ª∑ÂÄºÁöÑËßÅËß£ÊàñËÅîÁ≥ª„ÄÇ\n\n## RAGateÁöÑÂπ≥Ë°°Ëâ∫ÊúØ\n\nRAGateÔºåÂç≥**Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÈó®**ÔºåÈÄöËøáËá™ÈÄÇÂ∫îÂú∞Á°ÆÂÆö‰ΩïÊó∂Â∞ÜÂ§ñÈÉ®Áü•ËØÜÁ∫≥ÂÖ•ÂìçÂ∫îÔºå‰ªéËÄåÂ¢ûÂº∫ÂØπËØùAIÁ≥ªÁªüÁöÑËÉΩÂäõ„ÄÇ\n\n[RAGateÁ†îÁ©∂](https://proxy.rifx.online/https://arxiv.org/abs/2407.21712)Êé¢ËÆ®‰∫ÜÂØπËØùÁ≥ªÁªü‰∏≠**Ëá™ÈÄÇÂ∫îÂ¢ûÂº∫**ÁöÑÈúÄÊ±ÇÔºåÂπ∂Â∞ÜRAGateÊèêÂá∫‰∏∫‰∏ÄÁßç**Èó®ÊéßÊ®°Âûã**ÔºåÈ¢ÑÊµã‰ΩïÊó∂Ê£ÄÁ¥¢Â§ñÈÉ®Áü•ËØÜÊòØÊúâÁõäÁöÑ„ÄÇËÆ∫ÊñáÊèê‰æõ‰∫ÜÂ§ßÈáèÂÆûÈ™åÂíåÂàÜÊûêÔºåÂ±ïÁ§∫‰∫ÜRAGateÂú®ÊèêÈ´òÂü∫‰∫éRAGÁöÑÂØπËØùÁ≥ªÁªüÁöÑÂìçÂ∫îË¥®ÈáèÂíåÁîüÊàê‰ø°ÂøÉÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ\n\n\n\n## RAGate Á§∫‰æã\n\n**Âú∫ÊôØÔºö** Áî®Êà∑Ê≠£Âú®‰∏é‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÂåªÁñó‰øùÂÅ•ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫‰∫íÂä®ÔºåËØ•Êú∫Âô®‰∫∫Ê†πÊçÆ‰∏ÄËà¨ÂÅ•Â∫∑ÂéüÂàôÂíåÂåªÂ≠¶Áü•ËØÜÊèê‰æõ‰∏™ÊÄßÂåñÁöÑÂÅ•Â∫∑Âª∫ËÆÆ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*o0mWnGGefJ0TyDv1u14njw.png)\n\nRAGate ÂèØ‰ª•ÈÄöËøáÂπ≥Ë°°ÂÜÖÈÉ®ÂíåÂ§ñÈÉ®Áü•ËØÜËøõ‰∏ÄÊ≠•Â¢ûÂº∫ÂØπËØù„ÄÇÂÆÉÂÖÅËÆ∏‰∫∫Â∑•Êô∫ËÉΩ‰ΩøÁî®ÂÜÖÈÉ®ÂåªÂ≠¶Áü•ËØÜÊèê‰æõ‰∏ÄËà¨‰ø°ÊÅØÔºåÂêåÊó∂Ê£ÄÁ¥¢ÊúÄÊñ∞Á†îÁ©∂„ÄÇÂÆÉÁîöËá≥ÂèØ‰ª•Êô∫ËÉΩÂú∞ÁªºÂêàÊù•Ëá™Â§ö‰∏™Êù•Ê∫êÁöÑÊï∞ÊçÆËøõË°åÂÖ®Èù¢ÂàÜÊûêÔºåÂü∫‰∫éÊÇ£ËÄÖËØ¶ÊÉÖÊèê‰æõ‰∏™ÊÄßÂåñËßÅËß£ÔºåÂπ∂ËøáÊª§Â§ñÈÉ®‰ø°ÊÅØ‰ª•‰ºòÂÖàËÄÉËôëÊúÄÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÔºå‰ªéËÄåÂáèÂ∞ë‰ø°ÊÅØËøáËΩΩ„ÄÇ\n\n## RAGate ÁöÑÂèò‰Ωì\n\nÂ¶ÇËÆ∫Êñá‰∏≠ÊâÄËø∞ÔºåRAGate Êèê‰æõ‰∫Ü 3 ‰∏™Âèò‰Ωì ‚Äî **RAGate\\-Prompt**„ÄÅ**RAGate\\-PEFT (ÂèÇÊï∞\\-È´òÊïàÂæÆË∞É)** Âíå **RAGate\\-MHA (Â§öÂ§¥Ê≥®ÊÑèÂäõ)**„ÄÇ\n\nRAGate ÁöÑÊØè‰∏™Âèò‰Ωì ‚Äî Prompt„ÄÅPEFT Âíå MHA ‚Äî ÈááÁî®‰∏çÂêåÁöÑÊñπÊ≥ïÊù•Êï¥ÂêàÂ§ñÈÉ®Áü•ËØÜÔºåÊó®Âú®ÊèêÈ´ò AI ÁîüÊàêÂìçÂ∫îÁöÑÁõ∏ÂÖ≥ÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ\n\n‰ª•‰∏ãÊòØÂø´ÈÄüÊØîËæÉË°®Ôºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3dZg6rHlqmddK1ZQqqu_Aw.png)\n\n## Â¶Ç‰ΩïÂÆûÁé∞ RAGateÔºü\n\nÊú¨ÊñáÊèê‰æõ‰∫ÜÂÆûÁé∞ RAGate ÁöÑÈÄêÊ≠•ÊåáÂçóÔºö\n\n1. **ÂÆö‰πâÈóÆÈ¢ò**ÔºöËøô‰∏ÄÊ≠•Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÆÉÊ∂âÂèäÂà∞ËØÜÂà´ÊÇ®Â∏åÊúõÈÄöËøá RAGate Â¢ûÂº∫ÁöÑÂØπËØù‰ªªÂä°„ÄÇÁ°ÆÂÆöÂØπËØùÁöÑËåÉÂõ¥ÂíåÊÇ®Â∏åÊúõË¶ÜÁõñÁöÑÁâπÂÆöÈ¢ÜÂüüÔºà‰æãÂ¶ÇÔºåÈ§êÂéÖÊé®Ëçê„ÄÅÊóÖË°åËßÑÂàíÔºâ„ÄÇ\n2. **ÈÄâÊã©ËØ≠Ë®ÄÊ®°Âûã**ÔºöÈÄâÊã©ÈÄÇÂêàÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰Ωú‰∏∫ÊÇ®ÂØπËØùÁ≥ªÁªüÁöÑÂü∫Á°Ä„ÄÇÂèØÈÄâÊ®°ÂûãÂåÖÊã¨ Llama„ÄÅGPT-2 ÊàñÂÖ∂‰ªñÂü∫‰∫éÂèòÊç¢Âô®ÁöÑÊû∂ÊûÑ„ÄÇ\n3. **Êî∂ÈõÜÂíåÊ†áÊ≥®Êï∞ÊçÆ**ÔºöÊî∂ÈõÜ‰∏éÊÇ®ÁöÑÂØπËØùÈ¢ÜÂüüÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÈõÜ„ÄÇKETOD Êï∞ÊçÆÈõÜÊòØ‰∏Ä‰∏™‰ºòÁßÄÁöÑ‰æãÂ≠êÔºåÂÆÉÂåÖÊã¨Ê†áÊ≥®ÁöÑÂØπËØùÂíåÁü•ËØÜÁâáÊÆµ„ÄÇÁ°Æ‰øùÊÇ®ÁöÑÊï∞ÊçÆÈõÜÊúâÊòéÁ°ÆÁöÑÊ†áÁ≠æÔºåÊåáÁ§∫‰ΩïÊó∂ÈúÄË¶ÅÁü•ËØÜÂ¢ûÂº∫„ÄÇ\n4. **ÂºÄÂèëÁü•ËØÜÊ£ÄÁ¥¢Á≥ªÁªü**ÔºöÂÆûÁé∞‰∏Ä‰∏™Áü•ËØÜÊ£ÄÁ¥¢Êú∫Âà∂Ôºå‰ª•‰æøÂú®ÈúÄË¶ÅÊó∂Ëé∑ÂèñÁõ∏ÂÖ≥ÁöÑÂ§ñÈÉ®‰ø°ÊÅØ„ÄÇÂèØ‰ª•ËÄÉËôëÊµÅË°åÁöÑÊäÄÊúØÔºåÂ¶ÇÁ®†ÂØÜÊÆµËêΩÊ£ÄÁ¥¢ÊàñÂõæÁªìÊûÑÁü•ËØÜÂ∫ì„ÄÇ\n5. **ÂÆûÁé∞ RAGate Êú∫Âà∂**ÔºöÂàõÂª∫‰∫åÂÖÉÁü•ËØÜÈó®ÂáΩÊï∞ÔºàRAGateÔºâÔºå‰ª•Á°ÆÂÆö‰ΩïÊó∂Áî®Â§ñÈÉ®Áü•ËØÜÂ¢ûÂº∫ÂìçÂ∫î„ÄÇËøôÊ∂âÂèäÂà∞ **‰∏ä‰∏ãÊñáÂàÜÊûêÂíåÈó®ÊéßÂáΩÊï∞**„ÄÇ\n6. **Êé¢Á¥¢ RAGate Âèò‰Ωì**ÔºöÊ†πÊçÆËÆ∫Êñá‰∏≠ËÆ®ËÆ∫ÁöÑÊñπÊ≥ïÂºÄÂèë‰∏çÂêåÁöÑ RAGate Âèò‰ΩìÔºö\n* **RAGate-Prompt**Ôºö‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèêÁ§∫‰∏éÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÊù•Á°ÆÂÆöÊòØÂê¶ÈúÄË¶ÅÂ¢ûÂº∫„ÄÇ\n* **RAGate-PEFT**ÔºöÈááÁî®ÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊäÄÊúØÔºà‰æãÂ¶ÇÔºåQLoRAÔºâÊù•ËÆ≠ÁªÉÊÇ®ÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞ËøõË°åÂÜ≥Á≠ñ„ÄÇ\n* **RAGate-MHA**ÔºöÂà©Áî®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂Êù•ËØÑ‰º∞‰∏ä‰∏ãÊñáÂπ∂‰∫§‰∫íÂºèÂú∞Ê£ÄÁ¥¢Áü•ËØÜ„ÄÇ\n\n7. **ËÆ≠ÁªÉÊ®°Âûã**Ôºö‰ΩøÁî®Ê†áÊ≥®Êï∞ÊçÆÈõÜÂæÆË∞ÉÊÇ®ÁöÑ LLMÔºåÈááÁî®ÂêÑÁßç RAGate Âèò‰Ωì„ÄÇÁªìÂêàÈó®ÊéßÊú∫Âà∂ÁöÑËÆ≠ÁªÉÔºå‰ª•Â¢ûÂº∫Ê®°ÂûãÊúâÊïàÈ¢ÑÊµãÁü•ËØÜÂ¢ûÂº∫ÈúÄÊ±ÇÁöÑËÉΩÂäõ„ÄÇ\n\n8. **ËØÑ‰º∞ÊÄßËÉΩ**ÔºöËøõË°åÂπøÊ≥õÁöÑÂÆûÈ™å‰ª•È™åËØÅ RAGate ÁöÑÊúâÊïàÊÄß„ÄÇÂàÜÊûêÊåáÊ†áÂ¶ÇÔºö\n\n* **Á≤æÁ°ÆÂ∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅF1 ÂàÜÊï∞**ÔºöËØÑ‰º∞Èó®ÊéßÂáΩÊï∞ÁöÑÂàÜÁ±ªÊÄßËÉΩ„ÄÇ\n* **BLEU„ÄÅROUGE„ÄÅBERTScore**ÔºöÁî®‰∫éËØÑ‰º∞ÁîüÊàêÂìçÂ∫î‰∏éÁúüÂÆûÂÄºÁöÑË¥®Èáè„ÄÇ\n* **ÁΩÆ‰ø°ÂàÜÊï∞**ÔºöÊµãÈáèÁîüÊàêËæìÂá∫ÁöÑÁΩÆ‰ø°Â∫¶Ôºå‰ª•Á°Æ‰øùÈ´òË¥®ÈáèÁöÑÂìçÂ∫î„ÄÇ\n\n9. **ÈÉ®ÁΩ≤Á≥ªÁªü**ÔºöÂ∞Ü RAGate ÂêØÁî®ÁöÑÂØπËØùÁ≥ªÁªüÈõÜÊàêÂà∞ÊÇ®ÁöÑÂ∫îÁî®ÊàñÊúçÂä°‰∏≠„ÄÇÁ°Æ‰øùÁ≥ªÁªüËÉΩÂ§üÂ§ÑÁêÜÂÆûÊó∂Êü•ËØ¢ÔºåÂπ∂Âä®ÊÄÅÂÜ≥ÂÆöÁü•ËØÜÂ¢ûÂº∫„ÄÇ\n\n10. **Ëø≠‰ª£ÂíåÊîπËøõ**ÔºöÊåÅÁª≠Êî∂ÈõÜÁî®Êà∑ÂèçÈ¶àÂíå‰∫§‰∫íÊï∞ÊçÆÔºå‰ª•‰ºòÂåñÊ®°Âûã„ÄÇÂàÜÊûêÁ≥ªÁªüÂú®‰∏ä‰∏ãÊñáÊàñÁõ∏ÂÖ≥ÊÄßÊñπÈù¢ÂèØËÉΩÈÅáÂà∞ÁöÑÂõ∞ÈöæÔºåÂπ∂Áõ∏Â∫îË∞ÉÊï¥ËÆ≠ÁªÉÊàñÊ£ÄÁ¥¢Êú∫Âà∂„ÄÇ\n\n## Êî∂Ëé∑\n\nÊÄª‰πãÔºåRAGate ‰ª£Ë°®‰∫ÜÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÈáçÂ§ßËøõÊ≠•ÔºåÈÄöËøáÊô∫ËÉΩÂú∞Âπ≥Ë°°ÂÜÖÈÉ®ÂíåÂ§ñÈÉ®Áü•ËØÜÔºåÊèê‰æõÊõ¥Áõ∏ÂÖ≥„ÄÅÈ´òÊïàÂíå‰∏™ÊÄßÂåñÁöÑÂìçÂ∫î„ÄÇRAGate ÁöÑÂ∫îÁî®ËåÉÂõ¥ÂπøÊ≥õÔºåÊ∂µÁõñ‰∫ÜÂåªÁñó„ÄÅÂÆ¢Êà∑ÊîØÊåÅ„ÄÅÊïôËÇ≤„ÄÅÊ≥ïÂæãÊúçÂä°„ÄÅÈáëËûçÁ≠âÂ§ö‰∏™Ë°å‰∏ö„ÄÇÈÄöËøáÂ¢ûÂº∫‰∫∫Â∑•Êô∫ËÉΩÊèê‰æõÈáèË∫´ÂÆöÂà∂ÁöÑÂÆûÊó∂‰ø°ÊÅØÁöÑËÉΩÂäõÔºåRAGate ÊúâÊΩúÂäõÂΩªÂ∫ïÊîπÂèò‰ºÅ‰∏öÂíå‰∏™‰∫∫‰∏éÊäÄÊúØÁöÑ‰∫íÂä®ÊñπÂºèÔºåÊèêÈ´òÂÜ≥Á≠ñËÉΩÂäõ„ÄÅÁî®Êà∑‰ΩìÈ™åÂíåÊï¥‰ΩìÁ≥ªÁªüÊÄßËÉΩ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/rbyf-qwen2-5-3b-instruct-is-damn-good-dcf443cacc63","frontmatter":{"title":"RBYFÔºöQwen2.5‚Äì3B-instruct ÈùûÂ∏∏Ê£í„ÄÇ","meta_title":"RBYFÔºöQwen2.5‚Äì3B-instruct ÈùûÂ∏∏Ê£í„ÄÇ","description":"‰øÆÊîπÂêéÁöÑÂü∫ÂáÜÊµãËØïÂπ∂ÈôÑ‰∏äÊÇ®ÁöÑÂèçÈ¶àÔºöÈòøÈáåÂ∑¥Â∑¥QwenÁöÑÂÖ®Êñ∞3BÊ®°ÂûãÊòØ‰∏Ä‰∏™‰∫Ü‰∏çËµ∑ÁöÑÊ®°ÂûãÔºåÊàëÂèØ‰ª•ËØÅÊòéËøô‰∏ÄÁÇπÔºÅ","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NWaBtJ64TLUoUHv4F1qJpg.png","categories":["Programming","Technology","Science"],"author":"Rifx.Online","tags":["Qwen","NLP","multimodal","RBYF","evaluation"],"draft":false,"slug":"blog/rbyf-qwen2-5-3b-instruct-is-damn-good-dcf443cacc63"},"content":"\n### ‰øÆËÆ¢Âü∫ÂáÜÔºö‰ª•ÊÇ®‰∏∫ÂèçÈ¶àÁöÑÂÖ®Êñ∞3BÊ®°ÂûãÊù•Ëá™ÈòøÈáåÂ∑¥Â∑¥QwenÔºåÊòØ‰∏™‰ª§‰∫∫ÊÉäÂèπÁöÑÊ®°ÂûãÔºåÊàëÂèØ‰ª•ËØÅÊòéËøô‰∏ÄÁÇπÔºÅ\n\n\n\nÊ∂åÁé∞Â±ûÊÄßÁöÑÈîôËßâÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØËØÑ‰º∞Ëøô‰∫õÊ®°ÂûãÊâÄ‰ΩøÁî®ÁöÑÊåáÊ†áÁöÑ‰∫ßÁâ©„ÄÇËøôÊòØ‰∏Ä‰∏™‰∫ãÂÆû„ÄÇ\n\nÂá†Âë®ÂâçÔºåÊàëÂÜ≥ÂÆöÂÅö‰∏Ä‰∏™Â∞èÂèçÂèõÔºåÊîæÂºÉÊâÄÊúâÂÆòÊñπÂü∫ÂáÜÔºåÂºÄÂßãËá™Â∑±ÂÅöÂü∫ÂáÜÊµãËØïÔºÅ\n\nËøôÂ∞±ÊòØËøô‰∏™ÂÆåÂÖ®ËôöÊûÑÁöÑÈ¶ñÂ≠óÊØçÁº©Áï•ËØçRBYFÁöÑÊÑè‰πâÔºö‰ª•ÊÇ®‰∏∫ÂèçÈ¶àÁöÑ‰øÆËÆ¢Âü∫ÂáÜ„ÄÇÂÖ∂Âü∫Êú¨ÂéüÂàôÊòØÔºåÊ≤°ÊúâÊØîÊÇ®Êõ¥Â•ΩÁöÑËØÑÂà§ËÄÖÊù•È™åËØÅ‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰ºòÂä£„ÄÇ\n\nËÄÅÂÆûËØ¥ÔºåÊàë‰∏ìÊ≥®‰∫éÂ∞èÂûãËØ≠Ë®ÄÊ®°Âûã„ÄÇÊàëÊ≤°Êúâ‰∏ìÁî®ÁöÑGPUÔºåËÆ°ÁÆóËµÑÊ∫êÊúâÈôê„ÄÇ‰ΩÜÊàëÂêåÊ†∑ÂêåÊÑè[LLMWareÂèçÂèõÂéüÂàôÁ¨¨‰∏ÄÊù°](https://readmedium.com/getting-work-done-with-genai-just-do-the-opposite-10-contrarian-rules-that-may-actually-work-634501602a27)Ôºö\n\n‰ΩøÁî®Â∞èÊ®°ÂûãÔºåËÄå‰∏çÊòØÂ§ßÊ®°Âûã„ÄÇ\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜÂêëÊÇ®Â±ïÁ§∫ÊàëÂØπqwen2.5‚Äì3b-instructÁöÑËØÑ‰º∞ÁªìÊûú„ÄÇÁªìÊûúÁúüÁöÑÂæàÂ•ΩÔºÅ\n\n> ÂÖçË¥£Â£∞ÊòéÔºöÊâÄÊúâ‰∏éÁªìÊûúÁõ∏ÂÖ≥ÁöÑÊèêÁ§∫ÂùáÂèØÂú®ÊàëÁöÑGitHubÂ≠òÂÇ®Â∫ì‰∏≠ÊâæÂà∞Ôºö\n\n## Â∞ëÂç≥ÊòØÂ§ö\n\nÁº©ÊîæÊ≥ïÂàôÊèèËø∞‰∫ÜÊ®°ÂûãÊÄßËÉΩÂ¶Ç‰ΩïÈöèÁùÄÂèÇÊï∞ÂíåËÆ≠ÁªÉÊï∞ÊçÆÊï∞ÈáèÁöÑÂ¢ûÂä†ËÄåÊîπÂñÑ„ÄÇËøô‰∏™ÂéüÂàôÊé®Âä®‰∫ÜÂØπLLMÊñ∞ËÉΩÂäõÁöÑÊé¢Á¥¢„ÄÇ\n\n> ‰ªÖ‰ªÖÈÄöËøáÂ¢ûÂä†Ê®°ÂûãÁöÑËßÑÊ®°ÔºåÊàë‰ª¨ÂèØ‰ª•Ëß£ÈîÅÊñ∞ÁöÑËÉΩÂäõ‚Ä¶‚Ä¶\n\nÁº©ÊîæÊ≥ïÂàôÊèèËø∞‰∫ÜÊ®°ÂûãÊÄßËÉΩ‰∏éÂèÇÊï∞Êï∞ÈáèÂíåËÆ≠ÁªÉÊï∞ÊçÆ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÈöèÁùÄÊ®°ÂûãÂèòÂæóÊõ¥Â§ßÂπ∂Âú®Êõ¥Â§öÊï∞ÊçÆ‰∏äËøõË°åËÆ≠ÁªÉÔºåÊàë‰ª¨ÊúüÂæÖÂÆÉ‰ª¨ÁöÑÊÄßËÉΩÂæóÂà∞ÊèêÂçá„ÄÇËøôÂØºËá¥‰∫ÜÂØπË∂äÊù•Ë∂äÂ§ßLLMÁöÑÊó†‰ºëÊ≠¢ËøΩÊ±ÇÔºåÂ∏åÊúõËÉΩÂ§üËß£ÈîÅÊñ∞ÁöÑËÉΩÂäõ„ÄÇ\n\nÊ∂åÁé∞Â±ûÊÄßÊòØÊåáÂú®Â§çÊùÇÁ≥ªÁªü‰∏≠‰∏™‰ΩìÁªÑ‰ª∂‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®‰∏≠‰∫ßÁîüÁöÑÂ±ûÊÄß„ÄÇÈÄöËøáÂ≠§Á´ãÂú∞Á†îÁ©∂ÁªÑ‰ª∂ÔºåÊó†Ê≥ïÈ¢ÑÊµãÊàñÁêÜËß£Ëøô‰∫õÂ±ûÊÄß„ÄÇÂú®LLMÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ∏åÊúõÈöèÁùÄËøô‰∫õÊ®°ÂûãÂèòÂæóÊõ¥Â§ßÂíåÊõ¥Â§çÊùÇÔºåÂÆÉ‰ª¨‰ºöÂ±ïÁé∞Âá∫ÊÑèÊÉ≥‰∏çÂà∞ÁöÑÊñ∞ËÉΩÂäõ„ÄÇ\n\nËøôÊòØ‰∏Ä‰∏™Á´•ËØùÊïÖ‰∫ã„ÄÇ\n\nÂú®ËøáÂéªÂá†Âë®ÔºåÊàë‰ª¨‰∫≤ÁúºÁõÆÁùπ‰∫ÜÁªèËøáËøáÂ∫¶ËÆ≠ÁªÉÂíåÁ≤æÂøÉÁ≠ñÂàíÁöÑÂ∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÂèØ‰ª•Ë°®Áé∞Âæó‰∏éÂÆÉ‰ª¨ÁöÑÂ§ßÂûãÂÖÑÂºü‰∏ÄÊ†∑Â•Ω„ÄÇËøôÂØπÊâÄË∞ìÁöÑÊ∂åÁé∞ËÉΩÂäõÊòØ‰∏Ä‰∏™ÈáçÂáªÔºåÂèçÂáª‰∫ÜÁº©ÊîæÊ≥ïÂàô„ÄÇGemma2‚Äì2B„ÄÅQwen2.5‚Äì3BÔºåÁîöËá≥ÊúÄÊñ∞ÁöÑLlama3.2‚Äì3BÈÉΩÊòØËøúËÉú‰∫éÊóßÁöÑSOTA 7BÊ®°ÂûãÁöÑÊõ¥Â•ΩÊ®°Âûã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*-EjpdEky-Hf3WEQn.png)\n\n## Qwen2.5Ê®°ÂûãÁ≥ªÂàó\n\nÈòøÈáå‰∫ëÂú®‰πùÊúà‰∏≠Êó¨ÂèëÂ∏É‰∫Ü‰ªñ‰ª¨ÁöÑÊóóËà∞Ê®°ÂûãÁ≥ªÂàóQwen2.5„ÄÇ\n\n> ÈòøÈáå‰∫ëÂú®QwenÁöÑÈù©ÂëΩÊÄßÊóÖÁ®ã‰∏≠ÂÜçÊ¨°Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÂàõÊñ∞È¢ÜÂØºÂäõ\n\nQwen2.5ÊòØÈòøÈáåÂ∑¥Â∑¥ÈõÜÂõ¢QwenÂõ¢ÈòüÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÁ≥ªÂàó„ÄÇËøô‰∫õËØ≠Ë®ÄÊ®°ÂûãÂíåÂ§öÊ®°ÊÄÅÊ®°ÂûãÂú®Â§ßËßÑÊ®°Â§öËØ≠Ë®ÄÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆ‰∏äËøõË°å‰∫ÜÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂Âú®È´òË¥®ÈáèÊï∞ÊçÆ‰∏äËøõË°å‰∫ÜÂêéËÆ≠ÁªÉÔºå‰ª•‰æø‰∏é‰∫∫Á±ªÂÅèÂ•ΩÂØπÈΩê„ÄÇQwenËÉΩÂ§üÁêÜËß£Ëá™ÁÑ∂ËØ≠Ë®Ä„ÄÅÁîüÊàêÊñáÊú¨„ÄÅÁêÜËß£ËßÜËßâ„ÄÅÁêÜËß£Èü≥È¢ë„ÄÅ‰ΩøÁî®Â∑•ÂÖ∑„ÄÅËßíËâ≤ÊâÆÊºî„ÄÅ‰Ωú‰∏∫AI‰ª£ÁêÜËøõË°åÊìç‰ΩúÁ≠â„ÄÇ\n\n**Êñ∞Ê¨æQwen2.5ÁöÑ‰∫ÆÁÇπÂú®‰∫éÁªèËøáÁ≤æÂøÉÁ≠ñÂàíÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜ„ÄÇ** ÈÄöËøáÊ£ÄÊü•Â∞èÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÊÇ®ÂèØ‰ª•Ê∏ÖÊ•öÂú∞ÁêÜËß£Ëøô‰∏ÄÁÇπ„ÄÇ\n\nÂ¶ÇÊûúËØ•Á≥ªÂàóÁöÑÂ∞èÂûãËØ≠Ë®ÄÊ®°ÂûãË°®Áé∞ËâØÂ•ΩÔºåÊÑèÂë≥ÁùÄËÆ≠ÁªÉÂíåÊï∞ÊçÆÈõÜÁªèËøáÈ´òÂ∫¶‰øÆËÆ¢ÂíåÁ≠ñÂàí„ÄÇ\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∫õÊï∞Â≠óÔºö\n\n* ÂØÜÈõÜÂûã„ÄÅÊòì‰∫é‰ΩøÁî®ÁöÑËß£Á†ÅÂô®ËØ≠Ë®ÄÊ®°ÂûãÔºåÊèê‰æõ0.5B„ÄÅ1.5B„ÄÅ3B„ÄÅ7B„ÄÅ14B„ÄÅ32BÂíå72BÂ∞∫ÂØ∏Ôºå‰ª•ÂèäÂü∫Á°ÄÂíåÊåá‰ª§Âèò‰Ωì„ÄÇ\n* Âú®Êàë‰ª¨ÊúÄÊñ∞ÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÈ¢ÑËÆ≠ÁªÉÔºåÊ∂µÁõñÂ§öËææ18T‰∏™Ê†áËÆ∞„ÄÇ\n* Âú®Êåá‰ª§Ë∑üÈöè„ÄÅÁîüÊàêÈïøÊñáÊú¨ÔºàË∂ÖËøá8K‰∏™Ê†áËÆ∞Ôºâ„ÄÅÁêÜËß£ÁªìÊûÑÂåñÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåË°®Ê†ºÔºâÂíåÁîüÊàêÁªìÊûÑÂåñËæìÂá∫ÔºàÂ∞§ÂÖ∂ÊòØJSONÔºâÊñπÈù¢ÊúâÊòæËëóÊîπËøõ„ÄÇ\n* ÂØπÁ≥ªÁªüÊèêÁ§∫ÁöÑÂ§öÊ†∑ÊÄßÊõ¥ÂÖ∑ÈüßÊÄßÔºåÂ¢ûÂº∫‰∫ÜËßíËâ≤ÊâÆÊºîÁöÑÂÆûÁé∞ÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊù°‰ª∂ËÆæÁΩÆ„ÄÇ\n* ÊîØÊåÅÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÂèØËææ128K‰∏™Ê†áËÆ∞ÔºåÂπ∂‰∏îÂèØ‰ª•ÁîüÊàêÂ§öËææ8K‰∏™Ê†áËÆ∞„ÄÇ\n* ÊîØÊåÅË∂ÖËøá29ÁßçËØ≠Ë®ÄÁöÑÂ§öËØ≠Ë®ÄÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊ≥ïÊñá„ÄÅË•øÁè≠ÁâôÊñá„ÄÅËë°ËêÑÁâôÊñá„ÄÅÂæ∑Êñá„ÄÅÊÑèÂ§ßÂà©Êñá„ÄÅ‰øÑÊñá„ÄÅÊó•Êñá„ÄÅÈü©Êñá„ÄÅË∂äÂçóÊñá„ÄÅÊ≥∞Êñá„ÄÅÈòøÊãâ‰ºØÊñáÁ≠â„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3tnTS_UCImBRBDeKmFyjVQ.png)\n\n## Qwen2.5‚Äì3B-instruct\n\nÂ∞ΩÁÆ°‰∏∫‰∫ÜÊé®Âä®‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ïÔºåÊàë‰ª¨ÈúÄË¶ÅÈáåÁ®ãÁ¢ëÂíåÊõ¥Â•ΩÁöÑË°®Áé∞Ôºå‰ΩÜÁî®Êà∑‰ΩìÈ™åÂíå‰∏™‰∫∫ËßÇÁÇπ‰∏çËÉΩË¢´ËßÜ‰∏∫Êó†ÂÖ≥Á¥ßË¶Å„ÄÇ\n\nÊàëËÆ§‰∏∫ÔºåÊé¢Á¥¢‰∏Ä‰∫õÂ∏∏Áî®ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°ÔºåÊäõÂºÄËÅäÂ§©‰ΩìÈ™åÔºåÊàë‰ª¨ÂøÖÈ°ªÂÖ≥Ê≥®ÂõûÂ§çÁöÑË¥®Èáè„ÄÇËÄåÊàë‰ª¨ÊòØÂîØ‰∏ÄÊâÄÈúÄÁöÑÂü∫ÂáÜ„ÄÇ**Êàë‰ª¨ÁöÑÁî®Êà∑‰ΩìÈ™åÊòØÁêÜËß£Ê®°ÂûãÂ•ΩÂùèÁöÑÊúÄ‰Ω≥ÊåáÊ†á**„ÄÇÊ®°ÂûãÂøÖÈ°ªË∂≥Â§üÂèØÈù†Ôºå‰ª•‰æøÂú®Ëá™Âä®ÂåñÂ∑•‰ΩúÊµÅÁ®ã‰∏≠‰ΩøÁî®„ÄÇ\n\nÈ°∫‰æøÊèê‰∏Ä‰∏ãÔºåÊàëÂ∑≤ÁªèËøêË°å‰∫ÜÊàëÂÜ≥ÂÆöÁß∞‰πã‰∏∫[RBYF ‚Äî ‰øÆËÆ¢Âü∫ÂáÜ‰∏éÊÇ®ÂèçÈ¶à](https://open.substack.com/pub/thepoorgpuguy/p/rbyf-is-here-revised-benchmarks-with?r=i78xo&utm_campaign=post&utm_medium=web)ÁöÑÈ°πÁõÆÔºåÂú®[Qwen2.5‚Äì1.5b-instruct](https://ai.gopubby.com/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84)‰∏äÔºöÊÇ®ÂèØ‰ª•ÈòÖËØªËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇÂú®ÊñáÁ´†‰∏≠ÔºåÊàëËøòËß£Èáä‰∫ÜÂ¶Ç‰ΩïÂàõÂª∫ÊÇ®ÁöÑÊµãËØïÂü∫ÂáÜ„ÄÇÊâÄÊèèËø∞ÁöÑÊñπÊ≥ï‰∏éÊàëÁî®‰∫éQwen2.5‚Äì3BÁöÑÁõ∏Âêå„ÄÇ\n\nËÆ©Êàë‰ª¨‰ªéÊâÄÊúâ‰ªªÂä°ÁöÑÊï¥‰ΩìË°®Áé∞ÂºÄÂßã„ÄÇËØ•Ê®°ÂûãÂ∑≤Áî±ÊàëËØÑ‰º∞ÔºàÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÊòØÊàëËá™Â∑±ÁöÑÂèçÈ¶àÔºâÔºåÂü∫‰∫é‰ª•‰∏ãÊòæÁ§∫ÁöÑÂÆöÊÄßÁü©Èòµ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rdVHfCDWX9jlvtiq)\n\nÊÄª‰ΩìÂæóÂàÜ‰∏∫62/70 = 8.8\n\nÂ•ΩÁöÑÔºå‰ΩÜQwen2.5‚Äì3B-instructÊòØÂü∫‰∫é‰ªÄ‰πàÂæóÂà∞‰∫ÜËøô‰∏™ËØÑ‰º∞ÂàÜÊï∞Âë¢Ôºü\n\n## ÊµãËØïÊ¶ÇËø∞\n\nËøô‰∏™ÊÉ≥Ê≥ïÊòØËøõË°åÂÖ¨Âπ≥ÁöÑÁî®Êà∑ÂèçÈ¶àÔºåËÄå‰∏çÊòØÂü∫‰∫éÊ†áÂáÜÂü∫ÂáÜÂíåÊ°ÜÊû∂ÁöÑËá™Âä®ÂåñÂèçÈ¶à„ÄÇ‰∏Ä‰∏™Â∞èÂûãËØ≠Ë®ÄÊ®°ÂûãËÉΩÂê¶Êª°Ë∂≥Áî®Êà∑Âú®‰∏ªË¶ÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°‰∏äÁöÑÊÑèÂõæÔºü\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wgngfGvSebeoH3YxTdvc8A.png)\n\nÊàë‰ª¨Â∏åÊúõÈ™åËØÅÁî®Êà∑ÊÑèÂõæÂíåÂìçÂ∫îË¥®Èáè„ÄÇ‰ª•‰∏ãÊòØÊØè‰∏™‰ªªÂä°ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºö\n\n### ‰ªãÁªç\n\nÈ™åËØÅÊ®°ÂûãÂ¶Ç‰ΩïÂõûÂ∫îÂàùÂßãÈóÆÂÄôÂπ∂Ë∞àËÆ∫Ëá™Ë∫´„ÄÇ\n\n### ‰∏ÄÂè•ËØùËß£Èáä\n\nÁªºÂêà‰∏éÊÄªÁªì„ÄÇÊúÄÁªàËØÑ‰º∞ÁöÑÈáçÁÇπÂú®‰∫éÊ®°ÂûãÊòØÂê¶ËÉΩÂ§üÂ∞ÜÂõûÂ§çÂéãÁº©‰∏∫‰ªÖ‰∏ÄÂè•ËØù„ÄÇ\n\n### Áî®‰∏âÊÆµËØùËß£Èáä\n\nÁî®Êà∑ÁöÑÊÑèÂõæÊòØËé∑ÂæóÂØπÊñáÊú¨ÁöÑÊô∫ËÉΩËß£ÈáäÔºåËøôÁßçËß£ÈáäÂøÖÈ°ªÈÄÇÂêàÂàÜÊàê‰∏âÊÆµ„ÄÇSMLÈÄöÂ∏∏‰ºöÂèëÁé∞ËøôÂæàÂõ∞ÈöæÔºåÂõ†‰∏∫‰ªñ‰ª¨ÊÄªÊòØ‰ºöÊ∑ªÂä†‰∏Ä‰∏™ÊÄªÁªìÊÆµËêΩ„ÄÇ\n\n### ËØ¥‚ÄúÊàëÂáÜÂ§áÂ•Ω‰∫Ü‚Äù„ÄÇ\n\nÂú®‰∏Ä‰∏™Âü∫‰∫éËÅäÂ§©ÂõûÂêàÁöÑÂ∫îÁî®‰∏≠ÔºåÈÅµÂæ™Êåá‰ª§ÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ºöË¢´Ë¶ÅÊ±ÇÈ¶ñÂÖàÈòÖËØªÊèê‰æõÁöÑÊñáÊú¨ÔºåÁÑ∂ÂêéËøõË°åÊüêÁßçÂàÜÊûê„ÄÇÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåSML Êó†Ê≥ïÂÅöÂà∞Ëøô‰∏ÄÁÇπ‚Ä¶‚Ä¶\n\n### ÊÄªÁªì\n\nÂü∫Êú¨ÊÄªÁªìÔºåÊ≤°ÊúâÈôêÂà∂„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨ÊÉ≥ËØÑ‰º∞ÊÄªÁªìÊòØÂ¶Ç‰ΩïÂü∫‰∫éÊñáÊú¨ÁöÑÔºåËÄå‰∏çÊòØÂá≠Á©∫ÊçèÈÄ†‰∫ãÂÆû„ÄÇ\n\n### ÊÄªÁªì‰∏∫‰∏§Âè•\n\nÂü∫Êú¨ÊÄªÁªìÔºåÈôêÂà∂‰∏∫‰∏§Âè•ËØù„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨Â∏åÊúõËØÑ‰º∞ÊÄªÁªìÊòØÂê¶Âü∫‰∫éÊñáÊú¨ÔºåËÄå‰∏çÊòØËôöÊûÑÁöÑ‰∫ãÂÆûÔºåÂêåÊó∂Á°Æ‰øùÈÅµÂÆà‰∏§Âè•ÁöÑÈôêÂà∂„ÄÇ\n\n### ÂàóÂá∫‰∏â‰∏™‰∏ªË¶ÅÂÖ≥ÈîÆÁÇπ ‚Äî Ê†ºÂºèËæìÂá∫\n\n```python\nkey_points = [\n    \"SMLÂøÖÈ°ª‰ª•ÁâπÂÆöÊ†ºÂºèËæìÂá∫„ÄÇ\",\n    \"Ê≠§ÊèêÁ§∫Ë¶ÅÊ±ÇÂàõÂª∫‰∏Ä‰∏™ÂåÖÂê´3‰∏™ÂÖ≥ÈîÆÁÇπÁöÑÂàóË°®„ÄÇ\",\n    \"ËæìÂá∫Ê†ºÂºèÂ∫î‰∏∫PythonÂàóË°®„ÄÇ\"\n]\n```\n\n### ÁõÆÂΩï\n\nËøô‰∏™‰ªªÂä°ÂØπËÆ∏Â§ö SML Êù•ËØ¥Áõ∏ÂΩìÂõ∞Èöæ„ÄÇËØ•ÊèêÁ§∫ÈúÄË¶Å‰∏Ä‰∫õË∞ÉÊï¥ÔºåÂê¶ÂàôÊ®°Âûã‰ºöËøîÂõû‰∏Ä‰∏™ markdown Ë°®Ê†º„ÄÇÁî®Êà∑Â∏åÊúõÊåâÁÖßÊèê‰æõÁöÑÊñáÊ°£ÁªìÊûÑËé∑Âæó‰∏Ä‰∏™ÊúâÂ∫èÁöÑ‰∏ªÈ¢òÂàóË°®„ÄÇ\n\n### RAG\n\nÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºåÊ≤°Êúâ‰ªª‰ΩïÊ°ÜÊû∂ÔºàhaystackÔºåLangchain‚Ä¶Ôºâ„ÄÇËøôÊòØËØ≠Ë®ÄÊ®°Âûã‰∏≠ÊúÄÂ∏∏Áî®ÁöÑ‰ªªÂä°‰πã‰∏Ä„ÄÇÂõûÂ§çÁöÑËØÑ‰º∞Âü∫‰∫éÂØπÊåá‰ª§ÁöÑÁêÜËß£ËÉΩÂäõ‰ª•ÂèäÁ≠îÊ°à‰∏éÊñáÊú¨ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇ\n\n### ÁúüÂÆûÁöÑ RAG\n\nËøôÊòØ‰∏Ä‰∏™‰∏éÊèê‰æõÁöÑ‰∏ä‰∏ãÊñáÂÆåÂÖ®Êó†ÂÖ≥ÁöÑÈóÆÈ¢òÁöÑ RAG„ÄÇÊ®°ÂûãÂøÖÈ°ªÂõûÂ§ç‚ÄúÊó†Ê≥ïÂõûÁ≠î‚ÄùÔºåËøôÊÑèÂë≥ÁùÄÂÆÉÁêÜËß£‰∫ÜÊåá‰ª§ÔºåÂπ∂‰∏îÊ≤°Êúâ‰ΩøÁî®‰ªª‰ΩïÂ§ñÈÉ®Áü•ËØÜÊàñËôöÊûÑÁöÑ‰ø°ÊÅØ„ÄÇ\n\n### ‰ªéÂèÇËÄÉÊñáÁåÆÊí∞ÂÜôÂÜÖÂÆπ\n\nËøôÊòØ‰∏Ä‰∏™ÂàõÈÄ†ÊÄßÁöÑ‰ªªÂä°„ÄÇ‰ΩøÁî®ÂèÇËÄÉÊñáÊú¨ÔºåSMLÂøÖÈ°ªÊèê‰æõ‰∏ÄÁØáÊñ∞ÁöÑÊñáÁ´†„ÄÇ\n\n### ÊèêÂèñ5‰∏™‰∏ªÈ¢ò\n\nÊ≠§‰ªªÂä°ÁöÑÈáçÁÇπÊòØÈ™åËØÅÔºö\n\n* Á°Æ‰øùÊ≠£Â•ΩÊúâ5‰∏™‰∏ªÈ¢ò\n* ÂÆÉ‰ª¨ÊòØÂü∫‰∫é‰∫ãÂÆûÁöÑÔºàÊ≤°ÊúâËôöÊûÑÔºâ\n\n### ÂàõÊÑèÔºö1000Â≠óÁßëÂπªÊïÖ‰∫ã\n\nÂÆåÂÖ®ÂàõÈÄ†ÊÄßÁöÑ‰ªªÂä°„ÄÇÂç≥‰ΩøÂØπ‰∫éÊõ¥Â§ßÁöÑÊ®°ÂûãÊù•ËØ¥ÔºåË¶Å‰øùÊåÅËøûË¥ØÊÄßÂπ∂‰∫ßÁîü‰∏Ä‰∏™Á¨¶ÂêàÂ≠óÊï∞Ë¶ÅÊ±ÇÁöÑÂ∞èÊïÖ‰∫ã‰πüÊòØÈùûÂ∏∏Âõ∞ÈöæÁöÑ„ÄÇ\n\n### ÂèçÊÄùÊèêÁ§∫\n\nÂèçÊÄùÊèêÁ§∫Êó®Âú®È™åËØÅÊ®°ÂûãÁöÑÈìæÂºèÊé®ÁêÜËøáÁ®ã„ÄÇËæìÂá∫Ë¢´ÈôêÂà∂Âú®ÁâπÊÆäÊ†áÁ≠æÁöÑÂºÄÂ§¥/ÁªìÂ∞æ„ÄÇÈáçÁÇπÊòØÊé®ÁêÜÂíå‰∏ÄËá¥ÁöÑËæìÂá∫ÁªìÊûÑ„ÄÇËæìÂá∫ÂøÖÈ°ªÊòì‰∫éÁî®‰∫éËøõ‰∏ÄÊ≠•ÁöÑÁªìÊûÑÂåñÊèêÁ§∫ÊàñÂèØËßÜÂåñ„ÄÇÊÇ®ÂèØ‰ª•Âú®Êú¨Êñá‰∏≠ÈòÖËØªÊõ¥Â§öÂÜÖÂÆπÔºö\n\n## ËØÑ‰º∞ËøáÁ®ã\n\nÂú®ÊØèÊ¨°ÁîüÊàêÁªìÊùüÊó∂ÔºåÁî®Êà∑‰ºöË¢´Ë¶ÅÊ±ÇÁî®0Âà∞5ÁöÑÂàÜÊï∞Êù•ËØÑ‰º∞ÁªìÊûú„ÄÇ**Âú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÁî®Êà∑Â∞±ÊòØÊàë‚Ä¶‚Ä¶**\n\nËøôÁßçÂÆöÊÄßÂàÜÊûêÁ°ÆÂÆûËæÉ‰∏∫ÁÆÄÂçïÔºåÂõ†Ê≠§ÊØè‰∏™ÂàÜÊï∞ÈÉΩÊúâ‰∏Ä‰∏™ÊèèËø∞ÔºåÁî®Êà∑ÂèØ‰ª•Ê∑ªÂä†ËØÑËÆ∫Ôºà‚Äú‰∏Ä‰∫õÈîôËØØÁöÑ‰ø°ÊÅØ‚ÄùÔºå‚Äú‰πüËÆ∏Êõ¥ÊîπÊèêÁ§∫‰∏≠ÁöÑÊé™Ëæû‰ºöÊõ¥Â•Ω‚ÄùÔºâ\n\nËøôÈáåÊòØÂ∏¶ÊúâÊèèËø∞ÁöÑÂÆöÊÄßÁü©Èòµ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*H_Qx2UT1lxqy2BF4.png)\n\n## Â•Ω‰∏éÂùè ‚Äî ÁªÜËäÇ\n\nÊÄª‰ΩìËÄåË®ÄÔºåQwen2.5‚Äì3B-instruct ÊòØ‰∏Ä‰∏™ÂÖ®Êñπ‰ΩçÁöÑÊ®°Âûã„ÄÇÊØè‰∏™‰ªªÂä°ÁöÑÂπ≥ÂùáÂæóÂàÜ‰∏∫ 4.4 ÂàÜÔºàÊª°ÂàÜ 5 ÂàÜÔºâÔºåËøôÁõ∏ÂΩì‰ª§‰∫∫Âç∞Ë±°Ê∑±Âàª„ÄÇ\n\nÊëòË¶ÅË°®Áé∞Âá∫Ëâ≤„ÄÇÂú®ÈïøÊñáÊú¨‰∏≠ÂàóÂá∫‰∏ªË¶Å‰∏ªÈ¢ò‰πüÈùûÂ∏∏Â•Ω„ÄÇ\n\nÂÆÉÂú® RAG ‰∏≠Ë°®Áé∞Á™ÅÂá∫ÔºåÊúâÊó∂ÊòæÂæóËøá‰∫éÂÜóÈïøÔºöÂú®ÁúüÂÆûÁöÑ RAG ‰∏≠ÔºåÂÆÉËøòÊèê‰æõ‰∫Ü‰∏Ä‰∫õËß£ÈáäÔºå‰ª•Âèä *Êó†Ê≥ïÂõûÁ≠î* ÂõûÂ§çÁöÑÂéüÂõ†„ÄÇ\n\nÊàë‰ª¨ÂèØ‰ª•‰∏ÄËµ∑ÁúãÁúã„ÄÇËøôÂØπ‰∫é SML Êù•ËØ¥ÔºåÁ≤æÁ°ÆËÆ°ÁÆóÂè•Â≠êÂíåÊÆµËêΩÁöÑÊï∞ÈáèÈÄöÂ∏∏ÊòØ‰∏ÄÈ°πËâ∞Â∑®ÁöÑ‰ªªÂä°„ÄÇ\n\n```python\n**Write a two-sentences summary of the following text:**\n\nChina's regime under Chinese Communist Party operates without transparent \nelections and primary candidates. While undesirable for democracies, \nit allows long-term planning free from electoral pressures that can change \nplans abruptly; this has led to China achieving peak carbon dioxide emissions \nin 2023 due largely to increased renewable energy installations, potentially \nsetting a new global standard for sustainable development despite its status \nas one of the world's largest polluters.\n```\n\nÁõÆÂΩïÂØπ‰∫éËØ≠Ë®ÄÊ®°ÂûãÊù•ËØ¥ÊòØÂè¶‰∏Ä‰∏™Âô©Ê¢¶ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÄöÂ∏∏ÁêÜËß£Â¶Ç‰ΩïÂàõÂª∫Ë°®Ê†º‚Ä¶‚Ä¶‰ΩÜÁúãÁúãËøô‰∏™Ôºö\n\n```python\nA \"table of content\" provides an organized structure to the text, allowing \nreaders quick access to key points. Write the \"table of content\" of \nthe following text.\n\n[table of contents]\n1. Introduction: Overview and Critique on China's Governance System  \n2. Comparison with Western Democracies - Undesirable Dictatorship? \n3. Advantages in Long-Term Planning for Sustainability   \n4. The Chinese Model as a Comparative Advantage  \n5. Recent Achievements in Carbon Emissions Reduction\n6. Transition to Renewable Energy: A Turning Point?\n7. Potential Leadership Role of China and India  \n8. Conclusion - Future Directions\n\n```\n\nÊàëÁªôÁúüÂÆûÁöÑ RAG ËØÑÂàÜ 4 ÂàÜÔºàÊª°ÂàÜ 5 ÂàÜÔºâÔºå‰ΩÜÂÆÉÊú¨ÂèØ‰ª•ËΩªÊùæÂæóÂà∞ 5 ÂàÜ„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂõûÂ§ç‰∏≠ÂøÖÈ°ªÂåÖÂê´ *Êó†Ê≥ïÂõûÁ≠î* Ëøô‰∏™ËØç„ÄÇ\n\n‰∏∫‰ªÄ‰πàÔºüÊÉ≥Ë±°‰∏Ä‰∏ã‰Ω†Âú®ËÆæÁΩÆ‰∏ÄÁ≥ªÂàóÊèêÁ§∫Ôºå‰Ω†ÈúÄË¶ÅÊ†πÊçÆÂÖàÂâçÁöÑÂõûÂ§çÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•„ÄÇÂ¶ÇÊûú‰Ω†ÂèØ‰ª•ÁÆÄÂçïÂú∞ÂØªÊâæ *Êó†Ê≥ïÂõûÁ≠î* Ëøô‰∏™ËØçÁöÑÂ≠òÂú®Êù•ÂºïÂØº‰Ω†ÁöÑ‰∏ã‰∏ÄÊ≠•ÔºåÈÇ£Â∞±Ê≤°ÈóÆÈ¢ò‰∫ÜÔºÅ\n\n```python\n**Reply to the question only using the provided context. If the answer \nis not contained in the provided context say \"unanswerable\".\nquestion: who is Anne Frank?**\n{context}\n**Remember: if you cannot answer based on the provided context, say \n\"unanswerable\"\nanswer:**\n\nUnanswerable\nThe given text does not provide any information about Anne Frank \nor her identity. The content is unrelated to this question and focuses \ninstead on discussing China's system compared to Western democracies in \nterms of long-term planning for environmental issues.\n```\n\nÊàëÊÉ≥Ë±°Ê®°Âûã‰πüË¢´ËÆ≠ÁªÉÊù•Êèê‰æõËøôÁßçÂõûÂ§çÁöÑÂéüÂõ†‚Ä¶‚Ä¶Â§™Ê£í‰∫ÜÔºÅ\n\n### ‰ºòÁßÄÁöÑÂèçÊÄù\n\nÂèçÊÄùÊèêÁ§∫ÁöÑ‰∏ªË¶ÅÁÑ¶ÁÇπÊòØÊ®°ÂûãËøîÂõûÊ≠£Á°ÆÊé®ÁêÜËøáÁ®ãÁöÑËÉΩÂäõÔºåÂπ∂ÊåâÁÖßÂá†‰∏™ÁâπÂÆöÁöÑÊ†áÁ≠æÂºÄÈó≠Ê†ºÂºèÂåñËæìÂá∫„ÄÇ\n\nÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåËøôÊòØ**Â∞èÂûãËØ≠Ë®ÄÊ®°Âûã**‰∏≠**ÊúÄ‰Ω≥ÁöÑÂèçÊÄùËæìÂá∫**ÔºåÁîöËá≥ÊØîGemma2‚Äì2BÊõ¥Â•ΩÔºö\n\n```python\n*üë®‚Äçüíª > You are an AI assistant designed to provide detailed, step-by-step \nresponses. Your outputs should follow this structure:\n1. Begin with a <thinking> section.\n2. Inside the thinking section:\n   a. Briefly analyze the question and outline your approach.\n   b. Present a clear plan of steps to solve the problem.\n   c. Use a \"Chain of Thought\" reasoning process if necessary, breaking down \nyour thought process into numbered steps.\n3. Include a <reflection> section for each idea where you:\n   a. Review your reasoning.\n   b. Check for potential errors or oversights.\n   c. Confirm or adjust your conclusion if necessary.\n4. Be sure to close all reflection sections.\n5. Close the thinking section with </thinking>.\n6. Provide your final answer in an <output> section.\nAlways use these tags in your responses. Be thorough in your explanations, \nshowing each step of your reasoning process. Aim to be precise and logical \nin your approach, and don't hesitate to break down complex problems into \nsimpler components. Your tone should be analytical and slightly formal, \nfocusing on clear communication of your thought process.\nRemember: Both <thinking> and <reflection> MUST be tags and must be closed \nat their conclusion\nMake sure all <tags> are on separate lines with no other text. \nDo not include other text on a line containing a tag.\n\nuser question: explain why it is crucial for teachers to learn how to use \ngenerative AI for their job and for the future of education. \nInclude relevant learning path for teachers and educators. *\n\n**üíª > <thinking>\nI will begin by analyzing the importance of teaching about Generative \nArtificial Intelligence (AI) in an educational context, then outline a \nstep-by-step plan on what steps should be taken to learn this technology \neffectively as well as provide resources or courses that could help.\nFirstly, understanding AI is crucial for teachers because it can \nsignificantly enhance their ability to support students. \nTeachers need the knowledge and skills necessary not only to integrate these tools into teaching but also understand how they work so they are able to guide both themselves and their pupils in ethical use of technology.\n</thinking>\n\n<reflection>\nMy initial thought process was clear, emphasizing that teachers should \nbe equipped with AI literacy as it can improve educational outcomes. \nI outlined the importance for guiding students ethically while using \nthese tools effectively.\nHowever, my plan needs more detail on specific steps to learn about \ngenerative AI and resources available online or in-person courses.\n</reflection>**\n*MY PERSONAL NOTE: here it is starting an additional thinking after the first \nreflection... And this is really too good to be true!!*\n**<thinking>\nTo create a comprehensive learning path that teachers could follow:\n1. **Understand Basic Concepts**: Start with basic concepts of machine \n   learning (ML) such as supervised vs unsupervised, deep neural networks  \n   etc., which are foundational to understanding generative AI.\n2. **Learn About Generative Models**:\n   - Study different types: Variational Autoencoders (VAEs), GANs.\n   - Understand how these models generate new data that resembles the \n     training set but is not identical and can be used for tasks like \n     text generation, image synthesis etc., which are crucial in education.\n3. **Explore Applications**: Look at real-world applications of generative \n   AI such as language modeling (e.g., GPT-2), computer vision techniques to \n   create realistic images or videos from raw data.\n4. **Ethical Considerations and Implications for Education**:\n   - Discuss the ethical implications, including bias in models' outputs \n     which could affect students‚Äô perceptions about themselves if they are \n     exposed regularly through AI-generated content that is not representative \n     of them.\n5. **Hands-on Practice**: Engage with practical exercises using open-source \n   tools like TensorFlow or PyTorch to build simple generative model \n   applications.\n6. **Stay Updated and Network**:\n   - Follow the latest research in ML, especially on Generative Models \n     by following relevant journals (e.g., NeurIPS), conferences such as \n     ICML etc.\n7. Attend Workshops/Conferences: Participate actively at AI-related workshops \n   or events to network with professionals working within this field.\n</thinking>**\n*MY PERSONAL NOTE: and no surprise, an additional reflection now starts, \nbefore producing the final output*\n**<reflection>\nMy plan has been expanded and includes a more detailed approach for teachers, \ncovering foundational knowledge through practical application of generative \nmodels in education along with ethical considerations that are crucial. \nI have also included staying updated on the latest research as an important \npart.\nHowever, it's essential to ensure these resources or courses exist so \neducators can access them easily.\n</reflection>\n\n<output>\nIt is vital for teachers and educational professionals alike to learn how \ngenerative AI works because this technology has significant potential in \nenhancing teaching methods. By understanding basic concepts of machine \nlearning (ML) such as supervised vs unsupervised, deep neural networks etc., \nthey will be better equipped with the knowledge necessary not only to \nintegrate these tools into their curriculum but also guide students ethically.\nA comprehensive plan for teachers and educators includes:\n1. **Understand Basic Concepts**: Start by grasping foundational concepts of ML.\n2. **Learn About Generative Models**:\n   - Study different types: Variational Autoencoders (VAEs), GANs, etc., \n     which are crucial in generating new data that resembles the training \n     set but is not identical and can be used for tasks like text generation or \n     image synthesis.\n3. **Explore Applications**: Look at real-world applications of generative AI \n   such as language modeling using tools like TensorFlow.\n4. **Ethical Considerations**:\n   - Discuss ethical implications, including bias in models' outputs which \n     could affect students‚Äô perceptions about themselves if they are exposed \n     regularly through AI-generated content that is not representative.\n5. **Hands-on Practice**: Engage with practical exercises to build simple \n   generative model applications using open-source tools.\n6. **Stay Updated and Network**:\n   - Follow the latest research in ML, especially on Generative Models by \n     following relevant journals (e.g., NeurIPS), conferences such as ICML etc.\n7. Attend Workshops/Conferences: Participate actively at AI-related workshops \n   or events to network with professionals working within this field.\n</output>\n```\n\nËøôÊ†∑ÁöÑÁ≤æÁÇºÊÄùÁª¥ËøáÁ®ãÔºå‰ª•ÂèäÊ∏ÖÊô∞ÁöÑÊ†áÁ≠æÂºÄÈó≠Ê†ºÂºèÔºåÂèØ‰ª•Êñπ‰æøÂêéÁª≠ÁöÑÂ§ÑÁêÜÊµÅÁ®ãÔºåÊàñËÄÖÂú®ÊºÇ‰∫ÆÁöÑGUI‰∏≠ËøõË°åÁæéËßÇÁöÑÊâìÂç∞„ÄÇ\n\n## ÂÆÉ‰∏çÊìÖÈïø‰ªÄ‰πàÔºü\n\nÊúÄÁ≥üÁ≥ïÁöÑ‰ªªÂä°ÊòØÂàõ‰ΩúÁü≠ÁØáÂ∞èËØ¥„ÄÇÊ®°ÂûãÂú®ÁîüÊàêËøáÁ®ã‰∏≠ÂºÄÂßãÈáçÂ§çÁõ∏ÂêåÁöÑÊÆµËêΩ„ÄÇ\n\nËøôÂπ∂‰∏çÊÑèÂë≥ÁùÄÂÆÉÊó†Ê≥ïÂÅöÂà∞„ÄÇÊõ¥ÊúâÂèØËÉΩÁöÑÊòØÔºåÈÄöËøáÊèêÈ´òÊ∏©Â∫¶ÂíåÈáçÂ§çÊÉ©ÁΩöÔºåÂèØ‰ª•Ëé∑ÂæóËâØÂ•ΩÁöÑÁªìÊûú„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GNJ3lG6FM5qt9glIdf7qhQ.jpeg)\n\n## ÁªìËÆ∫\n\nÊÇ®ÂèØ‰ª•Âú®ÊàëÁöÑGitHub‰ªìÂ∫ì‰∏≠ÊâæÂà∞ÊâÄÊúâËÅäÂ§©ËÆ∞ÂΩïÔºå‰ª•Âèä‰ª£Á†ÅÂíåËá™Ë°åÊìç‰ΩúÁöÑËØ¥Êòé„ÄÇÊÇ®ÂèØ‰ª•ÂèÇËÄÉÊàë‰πãÂâçÊñáÁ´†‰∏≠ÁöÑÊïôÁ®ã [Qwen2.5 1.5b: ÁßªÂä®AIÁöÑÊú™Êù•Ôºü](https://ai.gopubby.com/qwen2-5-1-5b-the-future-of-mobile-ai-6bd5f29bbc84)\n\nÂú®Êé•‰∏ãÊù•ÁöÑÊñáÁ´†‰∏≠ÔºåÊàëÂ∞Ü‰ªãÁªçÂÖ∂‰ªñÂ∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩøÁî®Áõ∏ÂêåÁöÑÂéüÂàôÔºö‰ªéÂ∞èÂûãÁöÑ350MÂèÇÊï∞ÔºåÂà∞500MÁ≥ªÂàóÔºåÂÜçÂà∞3B ‚Äî ÁªèËøá1.5B„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/retrieval-augmented-generation-approaches-state-of-the-art-and-optimization-strategies-456883da4801","frontmatter":{"title":"Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºöÊñπÊ≥ï„ÄÅÊúÄÊñ∞ËøõÂ±ïÂíå‰ºòÂåñÁ≠ñÁï•","meta_title":"Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºöÊñπÊ≥ï„ÄÅÊúÄÊñ∞ËøõÂ±ïÂíå‰ºòÂåñÁ≠ñÁï•","description":"‚≠ê RAG Âú®Áü•ËØÜÂØÜÈõÜÂûãÂú∫ÊôØÊàñÈúÄË¶ÅÊåÅÁª≠Áü•ËØÜÁöÑÁâπÂÆöÈ¢ÜÂüüÂ∫îÁî®‰∏≠ÁâπÂà´ÊúâÁî®‚Ä¶‚Ä¶","date":"2024-10-31T08:17:32.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_vE7WktGmyQ5xg_t5cpFVg.jpeg","categories":["Generative AI","Natural Language Processing","Machine Learning"],"author":"Rifx.Online","tags":["RAG","retrieval","generation","optimization","embeddings"],"draft":false,"slug":"blog/retrieval-augmented-generation-approaches-state-of-the-art-and-optimization-strategies-456883da4801"},"content":"\n\n\n\n\n‚≠ê RAG Âú®Áü•ËØÜÂØÜÈõÜÂûãÂú∫ÊôØÊàñÈúÄË¶ÅÊåÅÁª≠Êõ¥Êñ∞Áü•ËØÜÁöÑÁâπÂÆöÈ¢ÜÂüüÂ∫îÁî®‰∏≠Â∞§ÂÖ∂ÊúâÁî®„ÄÇÊúÄËøëÔºåRAG Âõ†ÂÖ∂Âú®ÂØπËØù‰ª£ÁêÜ‰∏≠ÁöÑÂ∫îÁî®ËÄåÂèóÂà∞ÂπøÊ≥õÂÖ≥Ê≥®„ÄÇ\n\nüìå ÂèÇËÄÉÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂΩìÂâçÁöÑ RAG ÊñπÊ≥ïÂèäÂÖ∂‰∏çÂêåÁªÑ‰ª∂„ÄÅÊúÄÊñ∞ËøõÂ±ïÔºàSOTAÔºâ„ÄÅÂ∫îÁî®„ÄÅÊ£ÄÁ¥¢„ÄÅÁîüÊàê„ÄÅÂ¢ûÂº∫ÊäÄÊúØÁöÑËØÑ‰º∞‰∏ä„ÄÇ\n\nÈöèÁùÄ RAG Á≥ªÁªü‰ªéÁÆÄÂçïÂà∞È´òÁ∫ßÂÜçÂà∞Ê®°ÂùóÂåñÁöÑÊºîÂèòÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩÊòØ‰∏∫‰∫ÜÂ∫îÂØπÁâπÂÆöÁî®‰æãÁöÑÂ¢ûÂº∫ËÄåÂá∫Áé∞ÁöÑ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*P2ByKtayhF4XgAVxRI1urQ.jpeg)\n\n‚úè *ÁÆÄÂçïÂûã*ÔºöÁî®Êà∑ËæìÂÖ•Áî®‰∫éÊñáÊ°£Êü•ËØ¢ÔºåÈôÑÂä†/ÁªÑÂêàÂà∞ÊèêÁ§∫‰∏≠ÔºåÁî®‰∫éÊ®°ÂûãÊúÄÁªàÂìçÂ∫îÁîüÊàê„ÄÇÈÄöËøáÂ§öËΩÆÂØπËØù‰∫§‰∫íÔºåÂèØ‰ª•Â∞Ü‰∏ä‰∏ãÊñá/ÂØπËØùÂéÜÂè≤Ê∑ªÂä†/ÁªÑÂêàÂà∞ÊèêÁ§∫‰∏≠„ÄÇÁº∫ÁÇπÔºö‰ΩéÁ≤æÂ∫¶/‰ΩéÂè¨ÂõûÁéáÔºåÂÜó‰ΩôÔºåÈáçÂ§ç„ÄÇ\n\n‚úè *È´òÁ∫ßÂûã*ÔºöÈÄöËøá‰ºòÂåñÈ¢ÑÊ£ÄÁ¥¢„ÄÅÊ£ÄÁ¥¢ÂíåÂêéÊ£ÄÁ¥¢ÊñπÊ≥ïÊù•ÊèêÈ´òÊ£ÄÁ¥¢Ë¥®Èáè„ÄÇÈ¢ÑÊ£ÄÁ¥¢‰∏≠ÔºåÈÄöËøáÂ¢ûÂº∫Êï∞ÊçÆÁ≤íÂ∫¶„ÄÅÁ¥¢ÂºïÁªìÊûÑÊîπËøõ„ÄÅÂÖÉÊï∞ÊçÆ„ÄÅÂØπÈΩêÂíåÊ∑∑ÂêàÊ£ÄÁ¥¢Êù•ÊèêÂçáË¥®Èáè„ÄÇÂú®Ê£ÄÁ¥¢‰∏≠Ôºå‰ºòÂåñÂµåÂÖ•Ê®°ÂûãÔºå‰ªéËÄå‰ºòÂåñ‰∏ä‰∏ãÊñá„ÄÇÂú®ÂêéÊ£ÄÁ¥¢‰∏≠Ôºå‰ºòÂåñ‰∏ä‰∏ãÊñáÁ™óÂè£ÂíåÂô™Â£∞/Âπ≤Êâ∞Êï∞ÊçÆÁöÑÊãíÁªù„ÄÇ\n\n‚úè *Ê®°ÂùóÂåñ*ÔºöÂºïÂÖ•ÊêúÁ¥¢Ê®°ÂùóËøõË°åÁõ∏‰ººÊÄßÊ£ÄÁ¥¢ÂíåÊ£ÄÁ¥¢ÁöÑÂæÆË∞É„ÄÇÊñ∞Ê®°ÂùóÂåÖÊã¨ÊêúÁ¥¢„ÄÅËÆ∞ÂøÜ„ÄÅËûçÂêà„ÄÅË∑ØÁî±„ÄÅÈ¢ÑÊµã„ÄÅ‰ªªÂä°ÈÄÇÈÖçÂô®„ÄÇ\n\nü•â ‰ºòÂåñ RAG ÊµÅÊ∞¥Á∫øÔºö\n\nüìú *Ê∑∑ÂêàÊêúÁ¥¢Êé¢Á¥¢*ÔºöÈÄöËøáÊô∫ËÉΩÂà©Áî®ÂÖ≥ÈîÆÂ≠óÊêúÁ¥¢„ÄÅËØ≠‰πâÊêúÁ¥¢ÂíåÂêëÈáèÊêúÁ¥¢Á≠âÊäÄÊúØÔºåÂπ≥Ë°°ÊÄßËÉΩ‰ºòÂåñ„ÄÇ\n\nüìú *ÈÄíÂΩíÊ£ÄÁ¥¢ÂíåÊü•ËØ¢ÂºïÊìé*ÔºöÂàùÂßãÈò∂ÊÆµÂèØËÉΩÈÄöËøáËé∑ÂèñËæÉÂ∞èÁöÑÂùóÂºÄÂßãÊ£ÄÁ¥¢ÔºåÈöèÂêé‰ª•Êõ¥Â•Ω‰∏îÊõ¥ÂÖ∑‰∏ä‰∏ãÊñáÁöÑ‰ø°ÊÅØËé∑ÂèñËæÉÂ§ßÁöÑÂùóÔºå‰ª•Âπ≥Ë°°‰∏ä‰∏ãÊñá‰∏∞ÂØåÁöÑÂìçÂ∫î‰∏éÊïàÁéá„ÄÇ\n\nüìú *ÂõûÈÄÄÊèêÁ§∫*ÔºöËøôÈºìÂä± LLM ËÑ±Á¶ªÁâπÂÆöÂÆû‰æãÔºåÂõ¥ÁªïÊõ¥ÂπøÊ≥õÁöÑÊ¶ÇÂøµÂíåÂéüÂàôËøõË°åÊé®ÁêÜÔºàarXiv:2310\\.13243Ôºâ„ÄÇÂú®ÂêÑÁßçÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂü∫‰∫éÊé®ÁêÜÁöÑ‰ªªÂä°‰∏≠Ôºå‰ΩøÁî®ÂõûÈÄÄÊèêÁ§∫Êó∂ËßÇÂØüÂà∞ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁ™ÅÊòæ‰∫ÜÂÆÉ‰ª¨ÂØπ RAG ËøáÁ®ãÁöÑËá™ÁÑ∂ÈÄÇÂ∫îÊÄß„ÄÇ\n\nüìú *Â≠êÊü•ËØ¢*ÔºöÊ†πÊçÆÂú∫ÊôØÂ∫îÁî®ÁöÑÊü•ËØ¢Á≠ñÁï•ÂèØ‰ª•‰ΩøÁî®Ôºå‰æãÂ¶ÇÂà©Áî® LlamaIndex Êèê‰æõÁöÑÊü•ËØ¢ÂºïÊìéÔºåÂà©Áî®Ê†ëÊü•ËØ¢Ôºå‰ΩøÁî®ÂêëÈáèÊü•ËØ¢ÔºåÊàñÊâßË°åÁÆÄÂçïÁöÑÂùóÈ°∫Â∫èÊü•ËØ¢„ÄÇ\n\nüìú *ÂÅáËÆæÊñáÊ°£ÂµåÂÖ•*Ôºö‰ΩøÁî® LLMÔºåHyDE ÈÄöËøáÂàõÂª∫ÂÅáËÆæÁ≠îÊ°àÊù•ÂìçÂ∫îÊü•ËØ¢ÔºåÂµåÂÖ•Á≠îÊ°àÔºåÂπ∂‰ΩøÁî®Áõ∏ÂêåÁöÑÁ≠îÊ°àÊù•Ê£ÄÁ¥¢ÁúüÂÆûÊñáÊ°£„ÄÇËØ•ÊñπÊ≥ïÂÖ≥Ê≥®ÁöÑÊòØ‰ªé‰∏Ä‰∏™Á≠îÊ°àÂà∞Âè¶‰∏Ä‰∏™Á≠îÊ°àÁöÑÂµåÂÖ•Áõ∏‰ººÊÄßÔºåËÄå‰∏çÊòØÂü∫‰∫éÊü•ËØ¢ÂØªÊâæÂµåÂÖ•Áõ∏‰ººÊÄß\\[arXiv:2212\\.10496]„ÄÇÁº∫ÁÇπÔºö‰∏ç‰∏ÄËá¥ÁöÑÁ≠îÊ°àÊú™ËÉΩ‰∫ßÁîüÁêÜÊÉ≥ÁªìÊûúÔºåLLM Êú™ËßÅ‰∏ªÈ¢òÁöÑÈîôËØØÔºåÂØºËá¥ÈîôËØØ„ÄÇ\n\nËÆ©ÊàëÂú®ËøôÈáåÁªìÊùü„ÄÇÊàë‰ºöÂú®ÂêéÁª≠‰∏≠ÂèëÂ∏ÉÊñ∞ÊñáÁ´†„ÄÇ\n\n[\\#genai](https://www.linkedin.com/feed/hashtag/?keywords=genai&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7170160104984571905) [\\#rag](https://www.linkedin.com/feed/hashtag/?keywords=rag&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7170160104984571905) \\#ai \\#llm\n\nÂèÇËÄÉÔºö[arxiv:2312\\.10997](https://arxiv.org/pdf/2312.10997)ÔºåRAG Ë∞ÉÊü•ÔºåHuggingfaceblogs\n\n"},{"lang":"zh","group":"blog","slug":"blog/roadmap-to-become-an-ai-engineer-in-2025-4323ae4c2f5c","frontmatter":{"title":"2025 Âπ¥Êàê‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏àÁöÑË∑ØÁ∫øÂõæ","meta_title":"2025 Âπ¥Êàê‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏àÁöÑË∑ØÁ∫øÂõæ","description":"Êú¨ÊñáÊèê‰æõ‰∫Ü‰∏ÄÊù°ÁªìÊûÑÂåñÁöÑË∑ØÁ∫øÂõæÔºåÊåáÂØºÂ¶Ç‰ΩïÂú®2025Âπ¥Êàê‰∏∫AIÂ∑•Á®ãÂ∏à„ÄÇÈ¶ñÂÖàÔºåÁêÜËß£AIÂ∑•Á®ãÁöÑÂü∫Êú¨Ê¶ÇÂøµÂíåËÅåË¥£ÔºåÁÑ∂ÂêéÊéåÊè°Êï∞Â≠¶„ÄÅÁºñÁ®ãÔºàÁâπÂà´ÊòØPythonÔºâÂíåÊï∞ÊçÆÁßëÂ≠¶ÁöÑÂü∫Á°ÄÁü•ËØÜ„ÄÇÊé•ÁùÄÔºåÊ∑±ÂÖ•Â≠¶‰π†Êú∫Âô®Â≠¶‰π†ÂíåÊ∑±Â∫¶Â≠¶‰π†ÔºåÂèÇ‰∏éÂÆûÈôÖÈ°πÁõÆ‰ª•Â∑©Âõ∫ÊâÄÂ≠¶Áü•ËØÜÔºåÂπ∂ÊéåÊè°Ê®°ÂûãÈÉ®ÁΩ≤ÊäÄËÉΩ„ÄÇÊúÄÂêéÔºåÂª∫Á´ã‰ΩúÂìÅÈõÜÂíå‰∫∫ËÑâÁΩëÁªúÔºåÊèêÂçáËÅå‰∏öÂèëÂ±ïÊú∫‰ºö„ÄÇÊñáÁ´†Âº∫Ë∞É‰∫ÜÊåÅÁª≠Â≠¶‰π†ÂíåÂÆûË∑µÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÈÄÇÂ∫îÂø´ÈÄüÂèëÂ±ïÁöÑAIÈ¢ÜÂüü„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*emg2RJ9qx4OgysH2r22nuQ.png","categories":["Programming","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Python","machine-learning","deep-learning","data-science","statistics"],"draft":false,"slug":"blog/roadmap-to-become-an-ai-engineer-in-2025-4323ae4c2f5c"},"content":"\n\n\n### Â¶Ç‰ΩïÂú®2025Âπ¥Êàê‰∏∫AIÂ∑•Á®ãÂ∏à\n\n\n\nÊúâÊ≤°ÊúâÊÉ≥ËøáÊûÑÂª∫ËÉΩÂ§üÊÄùËÄÉ„ÄÅÂ≠¶‰π†ÂíåËß£ÂÜ≥Â§çÊùÇÈóÆÈ¢òÁöÑÁ≥ªÁªüÈúÄË¶Å‰ªÄ‰πàÔºüÂá†Âπ¥ÂâçÔºåÊàë‰πüÂæàÂ•ΩÂ•á‚Äî‚ÄîAIÊòØ‰∏Ä‰∏™Êú™Êù•‰∏ª‰πâÁöÑÊ¶ÇÂøµÔºåÊàë‰∏çÁü•ÈÅì‰ªéÂì™ÈáåÂºÄÂßã„ÄÇÁé∞Âú®ÔºåÈöèÁùÄÊàë‰ª¨ËøàÂÖ•2025Âπ¥ÔºåÊàê‰∏∫AIÂ∑•Á®ãÂ∏àÊØî‰ª•ÂæÄ‰ªª‰ΩïÊó∂ÂÄôÈÉΩÊõ¥Âä†ÂÆπÊòì„ÄÇÂ¶ÇÊûú‰Ω†Âú®ËøôÈáåÔºå‰Ω†ÂèØËÉΩÂØπÂ¶Ç‰Ωï‰ªéÈõ∂ÂºÄÂßãËøõÂÖ•Ëøô‰∏™È¢ÜÂüüÊÑüÂÖ¥Ë∂£„ÄÇÂ•ΩÊ∂àÊÅØÊòØÔºü‰∏çÈúÄË¶ÅÊàê‰∏∫ËÆ°ÁÆóÊú∫Â§©ÊâçÊàñÊï∞Â≠¶Â•áÊâç„ÄÇÂè™ÈúÄ‰∏Ä‰∏™Ê∏ÖÊô∞ÁöÑË∑ØÁ∫øÂõæ„ÄÅÂ•âÁåÆÁ≤æÁ•ûÂíåÊ≠£Á°ÆÁöÑËµÑÊ∫êÔºå‰Ω†Â∞±ËÉΩÂÅöÂà∞„ÄÇ\n\nÂú®ËøôÊú¨ÁªàÊûÅÊåáÂçó‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•Êé¢ËÆ®‰Ω†ÈúÄË¶ÅÁöÑÊØè‰∏ÄÊ≠•„ÄÅÊØèÈ°πÊäÄËÉΩÂíåÊØè‰∏™ËµÑÊ∫êÔºå‰ª•Â∞ÜËá™Â∑±ËΩ¨Âèò‰∏∫AIÂ∑•Á®ãÂ∏à„ÄÇÊó†ËÆ∫‰Ω†ÊòØ‰ªéÂ§¥ÂºÄÂßãËøòÊòØÂ∑≤ÁªèÂÖ∑Â§á‰∏Ä‰∫õÊäÄÊúØÁü•ËØÜÔºåËøôÊú¨ÊåáÂçóÈÉΩ‰ºöÂ∞Ü‰∏ÄÂàáÂàÜËß£‰∏∫ÂèØÁÆ°ÁêÜÁöÑÊ≠•È™§„ÄÇÈÇ£‰πàÔºåËÆ©Êàë‰ª¨ÂºÄÂßãÂêß„ÄÇ\n\n## 1\\. ÁêÜËß£‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÁöÑÂÆûÈôÖÂê´‰πâ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LqwczRy-BZOH-zhfxNjc2g.png)\n\n### ‰ªÄ‰πàÊòØ AI Â∑•Á®ãÔºü\n\nAI Â∑•Á®ãÊó®Âú®ËÆæËÆ°ÂíåÈÉ®ÁΩ≤ËÉΩÂ§üËß£ÂÜ≥Áé∞ÂÆû‰∏ñÁïåÈóÆÈ¢òÁöÑ AI Ê®°Âûã„ÄÇ‰ªéËá™Âä®È©æÈ©∂Ê±ΩËΩ¶Âà∞‰∏™ÊÄßÂåñÊé®ËçêÔºåAI Â∑•Á®ãÂ∏àÂàõÂª∫ËÉΩÂ§ü‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âπ∂ÂÅöÂá∫Êô∫ËÉΩÂÜ≥Á≠ñÁöÑÁ≥ªÁªü„ÄÇ\n\n### AIÂ∑•Á®ãÂ∏àÁöÑËßíËâ≤‰∏éËÅåË¥£\n\n* **ÂºÄÂèëÊú∫Âô®Â≠¶‰π†ÔºàMLÔºâÊ®°Âûã**‰ª•ËøõË°åÈ¢ÑÊµãÂíåÊï∞ÊçÆÊ¥ûÂØü\n* **ÁºñÁ®ãÂíåËΩØ‰ª∂ÂºÄÂèë**‰∏ìÊ≥®‰∫éAIÂ∫îÁî®\n* **Êï∞ÊçÆÊî∂ÈõÜÂíåÈ¢ÑÂ§ÑÁêÜ**‰∏∫AIÊ®°ÂûãÂàõÂª∫Âü∫Á°Ä\n* **ËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩ**Âπ∂ËøõË°åÊîπËøõ\n* **ÈÉ®ÁΩ≤ÂíåÈõÜÊàê**AIËß£ÂÜ≥ÊñπÊ°à‰∫éÂïÜ‰∏öÁéØÂ¢É\n\n## 2\\. ÊéåÊè°Âü∫Á°ÄÔºöÊï∞Â≠¶ÂíåÁªüËÆ°Â≠¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HxbGZ1D4QFGf2FZ2dKLcsQ.png)\n\nÂú®Ê∑±ÂÖ•‰∫ÜËß£ AI ÁÆóÊ≥ï‰πãÂâçÔºåÊÇ®ÈúÄË¶ÅÊâéÂÆûÁöÑÊï∞Â≠¶Âü∫Á°Ä„ÄÇ‰ª•‰∏ãÊòØÂøÖË¶ÅÁöÑ‰∏ªÈ¢òÔºö\n\n### AIÂ∑•Á®ãÁöÑÂÖ≥ÈîÆÊï∞Â≠¶‰∏ªÈ¢ò\n\n* **Á∫øÊÄß‰ª£Êï∞Ôºö** ÁêÜËß£Á•ûÁªèÁΩëÁªúÁöÑÂü∫Á°Ä„ÄÇ‰∏ªÈ¢òÔºöÂêëÈáè„ÄÅÁü©Èòµ„ÄÅÁâπÂæÅÂÄº„ÄÇ\n* **Ê¶ÇÁéá‰∏éÁªüËÆ°Ôºö** Â∏ÆÂä©ÊÇ®ÂÅöÂá∫Êï∞ÊçÆÈ©±Âä®ÁöÑÂÜ≥Á≠ñ„ÄÇ‰∏ªÈ¢òÔºöÂàÜÂ∏É„ÄÅÂÅáËÆæÊ£ÄÈ™å„ÄÅË¥ùÂè∂ÊñØÊ¶ÇÂøµ„ÄÇ\n* **ÂæÆÁßØÂàÜÔºö** Áî®‰∫é‰ºòÂåñÊú∫Âô®Â≠¶‰π†Ê®°Âûã„ÄÇ‰∏ªÈ¢òÔºöÂØºÊï∞„ÄÅÂÅèÂØºÊï∞ÂíåÊ¢ØÂ∫¶„ÄÇ\n\n### Â≠¶‰π†Êï∞Â≠¶ÁöÑËµÑÊ∫ê\n\n1. **ÂèØÊ±óÂ≠¶Èô¢** ‚Äî [ÂèØÊ±óÂ≠¶Èô¢Êï∞Â≠¶ËØæÁ®ã](https://www.khanacademy.org/)ÔºàÂÖçË¥πÔºåÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºâ\n2. [**3Blue1Brown YouTubeÈ¢ëÈÅì**](https://www.youtube.com/c/3blue1brown) ‚Äî ÈÄÇÂêàËßÜËßâËß£ÈáäÔºåÂ∞§ÂÖ∂ÊòØÁ∫øÊÄß‰ª£Êï∞ÂíåÂæÆÁßØÂàÜ„ÄÇ\n3. **CourseraÔºöÊú∫Âô®Â≠¶‰π†ÁöÑÊï∞Â≠¶** ‚Äî [CourseraÊú∫Âô®Â≠¶‰π†ÁöÑÊï∞Â≠¶](https://www.coursera.org/specializations/mathematics-machine-learning)ÔºàÂÖçË¥πÂÆ°ËÆ°ÔºåËÆ§ËØÅÈúÄ‰ªòË¥πÔºâ\n\n## 3\\. Â≠¶‰π†ÁºñÁ®ãÔºàPython ÊòØÁéãËÄÖÔºâ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NxkreIEpQiuVUDD4_gWFSQ.png)\n\n### ‰∏∫‰ªÄ‰πàÈÄâÊã©PythonÔºü\n\nPythonÊòØ‰∫∫Â∑•Êô∫ËÉΩÁöÑÈ¶ñÈÄâËØ≠Ë®ÄÔºåÂõ†‰∏∫ÂÆÉÁÆÄÂçï„ÄÅÁÅµÊ¥ªÔºåÂπ∂‰∏îÊã•ÊúâÂ§ßÈáèÁî®‰∫é‰∫∫Â∑•Êô∫ËÉΩÂíåÊï∞ÊçÆÁßëÂ≠¶ÁöÑÂ∫ì„ÄÇ‰Ω†‰∏çÈúÄË¶ÅÁü•ÈÅìÈ´òÁ∫ßÁºñÁ®ãÂ∞±ÂèØ‰ª•ÂºÄÂßãÔºå‰ΩÜÊéåÊè°PythonÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑ„ÄÇ\n\n### Python ‰∏ªÈ¢òÊ∂µÁõñ\n\n* **Âü∫Á°ÄÁü•ËØÜÔºö** ÂèòÈáè„ÄÅÂæ™ÁéØ„ÄÅÂáΩÊï∞ÂíåÊï∞ÊçÆÁªìÊûÑ„ÄÇ\n* **Êï∞ÊçÆÁßëÂ≠¶Â∫ìÔºö** Numpy„ÄÅPandas Âíå Matplotlib Áî®‰∫éÊï∞ÊçÆÂ§ÑÁêÜÂíåÂèØËßÜÂåñ„ÄÇ\n* **Êú∫Âô®Â≠¶‰π†Â∫ìÔºö** Scikit\\-Learn„ÄÅTensorFlow Âíå PyTorch„ÄÇ\n\n### ÊúÄ‰Ω≥ Python ËµÑÊ∫ê\n\n1. [**Codecademy Python ËØæÁ®ã**](https://www.codecademy.com/catalog/language/python) ‚Äî Codecademy PythonÔºàÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºâ\n2. [**Ë∞∑Ê≠åÁöÑ Python ËØæÁ®ã**](https://developers.google.com/edu/python) ‚Äî Ë∞∑Ê≠å Python ËØæÁ®ãÔºàÂÖçË¥πÔºâ\n3. [**Jake VanderPlas ÁöÑÊï∞ÊçÆÁßëÂ≠¶ Python ÊâãÂÜå**](https://jakevdp.github.io/PythonDataScienceHandbook/) ‚Äî Êï∞ÊçÆÁßëÂ≠¶ Python ‰π¶Á±çÔºàÂú®Á∫øÂÖçË¥πÔºâ\n\n## 4\\. ÁÜüÊÇâÊï∞ÊçÆÔºöÊï∞ÊçÆÁßëÂ≠¶Âü∫Á°Ä\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*tugfLSYdMDps7t46G7dbhw.png)\n\nÊï∞ÊçÆÊòØ‰∫∫Â∑•Êô∫ËÉΩÁöÑÊ†∏ÂøÉ„ÄÇ‰Ωú‰∏∫‰∏ÄÂêç‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏àÔºåÊÇ®ÈúÄË¶ÅÊî∂ÈõÜ„ÄÅÊ∏ÖÁêÜÂíåÂàÜÊûêÂ§ßÈáèÊï∞ÊçÆÈõÜ„ÄÇ‰ª•‰∏ãÊòØÊÇ®ÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑÂÜÖÂÆπÔºö\n\n### ÂÖ≥ÈîÆÊï∞ÊçÆÁßëÂ≠¶ÊäÄËÉΩ\n\n* **Êï∞ÊçÆÊî∂ÈõÜ‰∏éÊ∏ÖÊ¥óÔºö** Â≠¶‰π†Â¶Ç‰ΩïÂ§ÑÁêÜÁº∫Â§±ÂÄº„ÄÅÊ∏ÖÁêÜÊùÇ‰π±Êï∞ÊçÆÔºåÂπ∂‰∏∫Êú∫Âô®Â≠¶‰π†Ê®°ÂûãËøõË°åÈ¢ÑÂ§ÑÁêÜ„ÄÇ\n* **Êé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûêÔºàEDAÔºâÔºö** ÁêÜËß£Â¶Ç‰ΩïÂàÜÊûêÂíåÂèØËßÜÂåñÊï∞ÊçÆÊ®°Âºè„ÄÇ\n* **ÁâπÂæÅÂ∑•Á®ãÔºö** Â∞ÜÂéüÂßãÊï∞ÊçÆÂ§ÑÁêÜ‰∏∫ÊúâÁî®ÁöÑÁâπÂæÅÔºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n\n### Êï∞ÊçÆÁßëÂ≠¶ËØæÁ®ã\n\n1. **IBM Êï∞ÊçÆÁßëÂ≠¶‰∏ì‰∏öËØÅ‰π¶ÔºàCourseraÔºâ** ‚Äî [IBM Êï∞ÊçÆÁßëÂ≠¶](https://www.coursera.org/professional-certificates/ibm-data-science)ÔºàÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºåÁªìÊûÑÂåñÂ≠¶‰π†Ë∑ØÂæÑÔºâ\n2. **DataCamp ÁöÑ Python Êï∞ÊçÆÁßëÂ≠¶ÂÆ∂ËØæÁ®ã** ‚Äî [DataCamp Python ËØæÁ®ã](https://www.datacamp.com/tracks/data-scientist-in-python)ÔºàÂü∫‰∫éËÆ¢ÈòÖÔºâ\n3. [**Jake VanderPlas ÁöÑ Python Êï∞ÊçÆÁßëÂ≠¶ÊâãÂÜå**](https://jakevdp.github.io/PythonDataScienceHandbook/)ÔºàÂÖçË¥πÂú®Á∫øËµÑÊ∫êÔºâ\n\n## 5\\. Ê∑±ÂÖ•Êú∫Âô®Â≠¶‰π†\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JwqTp844juTSX8FFSxvfTg.png)\n\nÊú∫Âô®Â≠¶‰π†ÊòØ‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÁöÑÊ†∏ÂøÉ„ÄÇÂú®ËøôÈáåÔºåÁÆóÊ≥ïË¢´ÂºÄÂèëÂá∫Êù•‰ª•‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†Ê®°ÂºèÂπ∂ËøõË°åÈ¢ÑÊµã„ÄÇ‰ª•‰∏ãÊòØË∑ØÁ∫øÂõæÔºö\n\n### ÈáçË¶ÅÁöÑÊú∫Âô®Â≠¶‰π†‰∏ªÈ¢ò\n\n* **ÁõëÁù£Â≠¶‰π†Ôºö** Á∫øÊÄßÂõûÂΩí„ÄÅÈÄªËæëÂõûÂΩí„ÄÅÂÜ≥Á≠ñÊ†ëÂíåÈöèÊú∫Ê£ÆÊûó„ÄÇ\n* **Êó†ÁõëÁù£Â≠¶‰π†Ôºö** ËÅöÁ±ªÊäÄÊúØÔºåÂ¶Ç K\\-ÂùáÂÄºÂíåÂ±ÇÊ¨°ËÅöÁ±ª„ÄÇ\n* **Ê®°ÂûãËØÑ‰º∞Ôºö** ÁêÜËß£ÂáÜÁ°ÆÁéá„ÄÅÁ≤æÁ°ÆÁéá„ÄÅÂè¨ÂõûÁéá„ÄÅF1\\-ÂàÜÊï∞Âíå ROC Êõ≤Á∫øÁ≠âÊåáÊ†á„ÄÇ\n* **Ê∑±Â∫¶Â≠¶‰π†Âü∫Á°ÄÔºö** Á•ûÁªèÁΩëÁªúÂèäÂÖ∂Â∑•‰ΩúÂéüÁêÜÁÆÄ‰ªã„ÄÇ\n\n### È°∂Á∫ßÊú∫Âô®Â≠¶‰π†ËµÑÊ∫ê\n\n1. **Andrew Ng Âú® Coursera ‰∏äÁöÑÊú∫Âô®Â≠¶‰π†ËØæÁ®ã** ‚Äî [Andrew Ng ÁöÑÊú∫Âô®Â≠¶‰π†](https://www.coursera.org/learn/machine-learning) (ÈÄÇÂêàÂàùÂ≠¶ËÄÖ)\n2. **Aur√©lien G√©ron ÁöÑ„Ää‰ΩøÁî® Scikit-Learn„ÄÅKeras Âíå TensorFlow ÁöÑÂä®ÊâãÊú∫Âô®Â≠¶‰π†„Äã** ‚Äî [Âä®ÊâãÊú∫Âô®Â≠¶‰π†](https://github.com/Akramz/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow) (ÂÆûÁî®ÁöÑÂä®ÊâãÊñπÊ≥ï)\n3. **Fast.ai ÁöÑ„ÄäÁ®ãÂ∫èÂëòÂÆûÁî®Ê∑±Â∫¶Â≠¶‰π†„Äã** ‚Äî [Fast.ai ËØæÁ®ã](https://course.fast.ai/) (Êõ¥È´òÁ∫ß‰ΩÜÈùûÂ∏∏ÂÆûÁî®)\n\n## 6\\. Êé¢Á¥¢Ê∑±Â∫¶Â≠¶‰π†ÂíåÁ•ûÁªèÁΩëÁªú\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AW1bwL9BTcOr22EkiDkg3w.png)\n\nÊ∑±Â∫¶Â≠¶‰π†ÈÄöËøáÊ®°Êãü‰∫∫ËÑëÁöÑÁ•ûÁªèÁΩëÁªúÂ∞Ü‰∫∫Â∑•Êô∫ËÉΩÊé®ÂêëÊõ¥È´òÁöÑÂ±ÇÊ¨°„ÄÇËøô‰∫õÁΩëÁªúË¢´Â∫îÁî®‰∫éÂõæÂÉèËØÜÂà´ÂíåËØ≠Ë®ÄÁøªËØëÁ≠âÈ¢ÜÂüü„ÄÇ\n\n### Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑÊ†∏ÂøÉ‰∏ªÈ¢ò\n\n* **Á•ûÁªèÁΩëÁªúÂü∫Á°ÄÔºö** ÊÑüÁü•Âô®ÔºåÊøÄÊ¥ªÂáΩÊï∞ÔºåÂâçÂêë‰º†Êí≠ÂíåÂèçÂêë‰º†Êí≠„ÄÇ\n* **Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNNs)Ôºö** Áî®‰∫éÂõæÂÉèÂ§ÑÁêÜ„ÄÇ\n* **ÈÄíÂΩíÁ•ûÁªèÁΩëÁªú (RNNs)Ôºö** ÂØπ‰∫éÊó∂Èó¥Â∫èÂàóÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ≠âÂ∫èÂàóÊï∞ÊçÆÈùûÂ∏∏ÊúâÁî®„ÄÇ\n\n### Ê∑±Â∫¶Â≠¶‰π†ËØæÁ®ãÂíåËµÑÊ∫ê\n\n1. **Coursera‰∏äÁöÑAndrew NgÊ∑±Â∫¶Â≠¶‰π†‰∏ì‰∏öËØæÁ®ã** ‚Äî [Andrew NgÁöÑÊ∑±Â∫¶Â≠¶‰π†](https://www.coursera.org/specializations/deep-learning)ÔºàÂÖ®Èù¢ÔºåÂº∫ÁÉàÊé®ËçêÔºâ\n2. **Coursera‰∏äÁöÑDeeplearning.aiÂÆûË∑µ‰∏≠ÁöÑTensorFlow** ‚Äî [TensorFlowËØæÁ®ã](https://www.coursera.org/professional-certificates/tensorflow-in-practice)\n3. [**PacktÁöÑPyTorchÊ∑±Â∫¶Â≠¶‰π†È°πÁõÆ**](https://www.packtpub.com/en-us/product/deep-learning-with-pytorch-9781788624336) ‚Äî ‰∏ÄÊú¨ÈÄÇÂêà‰ΩøÁî®PyTorchËøõË°åÂÆûË∑µÈ°πÁõÆÁöÑÂ•Ω‰π¶„ÄÇ\n\n## 7\\. ÂÆûË∑µÁúüÂÆûÈ°πÁõÆ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7c0NpXhFkZ--spsXM9qBrg.png)\n\nÁêÜËÆ∫Áü•ËØÜÂõ∫ÁÑ∂ÈáçË¶ÅÔºå‰ΩÜ‰∫∫Â∑•Êô∫ËÉΩÊòØ‰∏Ä‰∏™ÂÆûË∑µÊÄßÂæàÂº∫ÁöÑÈ¢ÜÂüü„ÄÇÂèÇ‰∏éÈ°πÁõÆÂ∞ÜÂ∑©Âõ∫‰Ω†ÁöÑÁêÜËß£ÔºåÂπ∂‰∏∫‰Ω†ÁöÑ‰ΩúÂìÅÈõÜÊèê‰æõÂ±ïÁ§∫ÁöÑÂÜÖÂÆπ„ÄÇ\n\n### ÂàùÂ≠¶ËÄÖÈ°πÁõÆÂàõÊÑè\n\n* **È¢ÑÊµãËÇ°Á•®‰ª∑Ê†º** ‰ΩøÁî®ÂéÜÂè≤Êï∞ÊçÆÔºàÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÔºâ\n* **ÂõæÂÉèÂàÜÁ±ª** ‰ΩøÁî®Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºàÂàÜÁ±ªÂä®Áâ©„ÄÅËΩ¶ËæÜÁ≠âÁöÑÂõæÂÉèÔºâ\n* **ÊÉÖÊÑüÂàÜÊûê** ÈíàÂØπÁ§æ‰∫§Â™í‰ΩìÂ∏ñÂ≠êÊàñ‰∫ßÂìÅËØÑËÆ∫\n\n### ÂØªÊâæAIÈ°πÁõÆÊï∞ÊçÆÈõÜÁöÑÂú∞Êñπ\n\n1. **KaggleÊï∞ÊçÆÈõÜ** ‚Äî [Kaggle Datasets](https://www.kaggle.com/datasets) (Â§öÁßçÊú∫Âô®Â≠¶‰π†È°πÁõÆÊï∞ÊçÆÈõÜ)\n2. **UCIÊú∫Âô®Â≠¶‰π†Â∫ì** ‚Äî [UCI ML Repository](https://archive.ics.uci.edu/ml/index.php)\n3. **Ë∞∑Ê≠åÊï∞ÊçÆÈõÜÊêúÁ¥¢** ‚Äî [Google Dataset Search](https://datasetsearch.research.google.com/)\n\n## 8\\. Á≤æÈÄöÊ®°ÂûãÈÉ®ÁΩ≤ÊäÄËÉΩ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*t9u1WCyf6TDeZ_M7m3IN-Q.png)\n\n‰∫ÜËß£Â¶Ç‰ΩïÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÈÉ®ÁΩ≤AIÊ®°ÂûãÊòØ‰∏Ä‰∏™Â∑®Â§ßÁöÑ‰ºòÂäø„ÄÇËøôÈ°πÊäÄËÉΩ‰Ωø‰Ω†Êàê‰∏∫‰∏Ä‰∏™ÂÆùË¥µÁöÑËµÑ‰∫ßÔºåÂõ†‰∏∫ÂÆÉÂº•Âêà‰∫ÜÊï∞ÊçÆÁßëÂ≠¶‰∏éÂÆûÈôÖÂ∫îÁî®‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ\n\n### ÈÉ®ÁΩ≤Â∑•ÂÖ∑Â≠¶‰π†\n\n* **Flask \\& Django:** Áî®‰∫éÂàõÂª∫ÁÆÄÂçïÁöÑ web Â∫îÁî®Á®ãÂ∫è‰ª•ÊúçÂä°‰∫éÊÇ®ÁöÑÊ®°Âûã„ÄÇ\n* **Docker:** Áî®‰∫éÂ∞ÜÊÇ®ÁöÑÊ®°ÂûãÂÆπÂô®ÂåñÔºå‰ΩøÈÉ®ÁΩ≤Êõ¥ÁÆÄÂçï„ÄÅÊõ¥‰∏ÄËá¥„ÄÇ\n* **AWS, Azure, Google Cloud:** Áî®‰∫éÂú®‰∫ë‰∏≠ÈÉ®ÁΩ≤ÂèØÊâ©Â±ïÁöÑ AI Ê®°Âûã„ÄÇ\n\n### Ê®°ÂûãÈÉ®ÁΩ≤ËµÑÊ∫ê\n\n1. **UdacityÁöÑAI‰∫ßÂìÅÁªèÁêÜÁ∫≥Á±≥Â≠¶‰Ωç** ‚Äî [Udacity AI‰∫ßÂìÅÁªèÁêÜ](https://www.udacity.com/course/ai-product-manager-nanodegree--nd088)\n2. **CourseraÁöÑDeeplearning.ai MLOps‰∏ì‰∏öÂåñ** ‚Äî [MLOps‰∏ì‰∏öÂåñ](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)\n3. [**PacktÁöÑÊï∞ÊçÆÁßëÂ≠¶Docker**](https://www.packtpub.com/en-in/product/the-ultimate-docker-container-book-9781804613986?type=print) ‚Äî ÈùûÂ∏∏ÈÄÇÂêàÂ≠¶‰π†‰ª•Êï∞ÊçÆÁßëÂ≠¶‰∏∫ÈáçÁÇπÁöÑDocker„ÄÇ\n\n## 9\\. Âª∫Á´ã‰ΩúÂìÅÈõÜÂπ∂ÂºÄÂßãÂª∫Á´ã‰∫∫ËÑâ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*CmE_JeIOcWcogB9X57QheA.png)\n\n‰∏Ä‰∏™Âº∫Â§ßÁöÑ‰ΩúÂìÅÈõÜÂ±ïÁ§∫‰∫Ü‰Ω†ÁöÑÊäÄËÉΩÔºåËÄåÂª∫Á´ã‰∫∫ËÑâÂàô‰∏∫‰Ω†ÊâìÂºÄ‰∫ÜÂ∑•‰ΩúÊú∫‰ºöÂíåÊåáÂØºÁöÑÈó®„ÄÇ\n\n### ‰ΩúÂìÅÈõÜÊäÄÂ∑ß\n\n* Â±ïÁ§∫ 3‚Äì5 ‰∏™Á™ÅÊòæ‰∏çÂêåÊäÄËÉΩÁöÑÈ°πÁõÆÔºàÊï∞ÊçÆÁßëÂ≠¶„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÈÉ®ÁΩ≤Ôºâ„ÄÇ\n* ÂåÖÂê´‰∏™‰∫∫È°πÁõÆÂíåÂõ¢ÈòüÂêà‰ΩúÁöÑÊ∑∑Âêà„ÄÇ\n* ‰∏∫ÊØè‰∏™È°πÁõÆÊí∞ÂÜôÊÄªÁªì„ÄÅ‰ª£Á†ÅÂíåÁªìÊûú„ÄÇ\n\n### ÁΩëÁªúÂπ≥Âè∞\n\n* [**LinkedIn**](https://www.linkedin.com/) ‚Äî ‰∏éAI‰∏ì‰∏ö‰∫∫Â£´ÂíåÊãõËÅò‰∫∫ÂëòÂª∫Á´ãËÅîÁ≥ª„ÄÇ\n* [**GitHub**](https://github.com/) ‚Äî ÂèëÂ∏É‰Ω†ÁöÑÈ°πÁõÆ‰ª•‰æõÊΩúÂú®Èõá‰∏ªÊü•Áúã„ÄÇ\n* [**Kaggle Competitions**](https://www.kaggle.com/competitions) ‚Äî ÂèÇÂä†ÊØîËµõ‰ª•Â≠¶‰π†ÂíåÂ±ïÁ§∫‰Ω†ÁöÑÊäÄËÉΩ„ÄÇ\n\n## ÁªìËÆ∫ÔºöÂáÜÂ§áÂ•ΩÊàê‰∏∫‰∏ÄÂêçAIÂ∑•Á®ãÂ∏à‰∫ÜÂêóÔºü\n\nÂú®2025Âπ¥Êàê‰∏∫‰∏ÄÂêçAIÂ∑•Á®ãÂ∏à‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™Ê¢¶ÊÉ≥ÔºõÂ¶ÇÊûú‰Ω†ÈÅµÂæ™‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑË∑ØÂæÑÔºåËøôÊòØÂèØ‰ª•ÂÆûÁé∞ÁöÑ„ÄÇÈ¶ñÂÖàÊéåÊè°Âü∫Á°ÄÁü•ËØÜÔºåÊäïÂÖ•Êó∂Èó¥ËøõË°åÈ°πÁõÆÂÆûË∑µÔºåÂπ∂‰∏çÊñ≠Êé®Âä®Ëá™Â∑±Â≠¶‰π†Êõ¥È´òÁ∫ßÁöÑÊ¶ÇÂøµ„ÄÇAIÊòØ‰∏Ä‰∏™Âø´ÈÄüÂèëÂ±ïÁöÑÈ¢ÜÂüüÔºåË∂äÊòØËá¥Âäõ‰∫éÊåÅÁª≠Â≠¶‰π†ÔºåÊú∫‰ºöÂ∞±Ë∂äÂ§ö„ÄÇ\n\nÈÇ£‰πàÔºå‰Ω†ÂáÜÂ§áÂ•ΩËøõÂÖ•AIÁöÑ‰∏ñÁïå‰∫ÜÂêóÔºüËÆ∞‰ΩèÔºåÊâÄÊúâÁöÑAIÂ∑•Á®ãÂ∏àÈÉΩÊòØ‰ªéÂàùÂ≠¶ËÄÖÂºÄÂßãÁöÑ„ÄÇÂá≠ÂÄüÂùöÊåÅÂíåÂ•ΩÂ•áÂøÉÔºå‰Ω†ÂæàÂø´Â∞±‰ºöÂàõÈÄ†Âá∫ÂàõÊñ∞ÁöÑAIËß£ÂÜ≥ÊñπÊ°à„ÄÇËÆ©Êàë‰ª¨‰∏ÄËµ∑ÂÆûÁé∞Ëøô‰∏™ÁõÆÊ†áÂêßÔºÅ\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n\n**1\\. ÊàëÈúÄË¶ÅÊúâAIÂ≠¶‰ΩçÊâçËÉΩÊàê‰∏∫AIÂ∑•Á®ãÂ∏àÂêóÔºü** ‰∏çÈúÄË¶ÅÔºåËôΩÁÑ∂Â≠¶‰ΩçÂèØ‰ª•ÊúâÊâÄÂ∏ÆÂä©Ôºå‰ΩÜËÆ∏Â§öAIÂ∑•Á®ãÂ∏àÊòØËá™Â≠¶ÊàêÊâçÊàñ‰ªéÁõ∏ÂÖ≥È¢ÜÂüüËΩ¨Ë°åÁöÑ„ÄÇÂú®Á∫øËØæÁ®ã„ÄÅÈ°πÁõÆÂíåÂº∫Â§ßÁöÑ‰ΩúÂìÅÈõÜÂêåÊ†∑Êúâ‰ª∑ÂÄº„ÄÇ\n\n**2\\. Êàê‰∏∫AIÂ∑•Á®ãÂ∏àÈúÄË¶ÅÂ§öÈïøÊó∂Èó¥Ôºü** ËøôÂèñÂÜ≥‰∫é‰Ω†ÁöÑËÉåÊôØÔºå‰ΩÜ‰∏ìÊ≥®ÁöÑÂ≠¶‰π†ËÄÖÂèØ‰ª•Âú®6-12‰∏™ÊúàÂÜÖÈÄöËøá‰∏ìÂøÉÂ≠¶‰π†ÂíåÈ°πÁõÆÂ∑•‰ΩúÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†á„ÄÇ\n\n**3\\. AIÂ∑•Á®ãÂ∏àÁöÑÂøÖÂ§áÊäÄËÉΩÊòØ‰ªÄ‰πàÔºü** ÂÖ≥ÈîÆÊäÄËÉΩÂåÖÊã¨PythonÁºñÁ®ã„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÊï∞ÊçÆÁßëÂ≠¶Âü∫Á°ÄÔºå‰ª•ÂèäÂØπÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂Â¶ÇTensorFlowÊàñPyTorchÁöÑ‰∫ÜËß£„ÄÇ\n\n**4\\. ÈúÄË¶ÅÂì™‰∫õÁºñÁ®ãËØ≠Ë®ÄÔºü** PythonÊòØAIÁöÑ‰∏ªË¶ÅËØ≠Ë®ÄÔºå‰ΩÜÊ†πÊçÆ‰Ω†ÁöÑËßíËâ≤ÔºåÁÜüÊÇâR„ÄÅSQLÊàñÁîöËá≥JavaScript‰πü‰ºöÂæàÊúâÂ∏ÆÂä©„ÄÇ\n\n**5\\. AIÂ∑•Á®ãÂ∏àÊòØÈ´òËñ™ËÅå‰∏öÂêóÔºü** ÊòØÁöÑÔºåAIÂ∑•Á®ãÂ∏àÊòØÈúÄÊ±ÇÈáèÂ§ß‰∏îËñ™ÈÖ¨‰∏∞ÂéöÁöÑÊäÄÊúØÈ¢ÜÂüü‰πã‰∏ÄÔºåÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÁöÑËñ™ËµÑÁ´û‰∫âÂäõÂº∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2luRkTNWk_o3KSh9.png)\n\nÊ≠§ÊïÖ‰∫ãÂèëÂ∏É‰∫é[Generative AI](https://generativeai.pub/)„ÄÇÂú®[LinkedIn](https://www.linkedin.com/company/generative-ai-publication)‰∏ä‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºåÂπ∂ÂÖ≥Ê≥®[Zeniteq](https://www.zeniteq.com/)Ôºå‰ª•Ëé∑ÂèñÊúÄÊñ∞ÁöÑAIÊïÖ‰∫ã„ÄÇ\n\nËÆ¢ÈòÖÊàë‰ª¨ÁöÑ[Êñ∞ÈóªÈÄöËÆØ](https://www.generativeaipub.com/)Âíå[YouTube](https://www.youtube.com/@generativeaipub)È¢ëÈÅìÔºå‰ª•Ëé∑ÂèñÁîüÊàêAIÁöÑÊúÄÊñ∞Êñ∞ÈóªÂíåÊõ¥Êñ∞„ÄÇËÆ©Êàë‰ª¨‰∏ÄËµ∑Â°ëÈÄ†AIÁöÑÊú™Êù•ÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*0DGBxUYjhr3BbfzS.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/searchgpt-changed-how-i-surf-the-web-forever-3e970027998c","frontmatter":{"title":"SearchGPT ÂΩªÂ∫ïÊîπÂèò‰∫ÜÊàëÁöÑ‰∏äÁΩëÊñπÂºè„ÄÇ","meta_title":"SearchGPT ÂΩªÂ∫ïÊîπÂèò‰∫ÜÊàëÁöÑ‰∏äÁΩëÊñπÂºè„ÄÇ","description":"ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫ÜSearchGPTÁöÑ‰ºòÂäøÂèäÂÖ∂Âú®ÁΩëÁªúÊêúÁ¥¢‰∏≠ÁöÑÂ∫îÁî®„ÄÇ‰∏ªË¶Å‰ºòÁÇπÂåÖÊã¨Ë∂ÖÂø´ÈÄüËØ≠‰πâÊêúÁ¥¢„ÄÅÂø´ÈÄüÁêÜËß£‰ø°ÊÅØ‰ª•ÂèäÈõÜ‰∏≠ÁÆ°ÁêÜÊêúÁ¥¢ÂéÜÂè≤„ÄÇ‰ΩúËÄÖÈÄöËøáÂØπÊØîÊµãËØïÂ±ïÁ§∫‰∫ÜSearchGPTÂú®ÊêúÁ¥¢ÈÄüÂ∫¶‰∏äÁöÑÊòæËëó‰ºòÂäøÔºåÂπ∂Êèê‰æõ‰∫ÜÂ§öÁßç‰ΩøÁî®ÊäÄÂ∑ßÂíåÁ≠ñÁï•Ôºå‰ª•‰ºòÂåñÊêúÁ¥¢‰ΩìÈ™å„ÄÇÊñáÁ´†ËøòÊé¢ËÆ®‰∫Ü‰∏çÂêåÁ±ªÂûãÁöÑ‰∫íËÅîÁΩëÊêúÁ¥¢Ë∑ØÂæÑÔºåÂπ∂ÂàÜÊûê‰∫ÜSearchGPTÂú®Ëøô‰∫õË∑ØÂæÑ‰∏≠ÁöÑË°®Áé∞ÔºåÂº∫Ë∞É‰∫ÜÂÆÉÂú®‰ø°ÊÅØËé∑ÂèñÂíåÁü•ËØÜÊûÑÂª∫ÊñπÈù¢ÁöÑÊïàÁéá„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*xwFpzwWrReqEjftU1cjksg.jpeg","categories":["Technology/Web","Programming/Scripting","SearchGPT is not a standard category","but the closest match from the given list is Technology/Web. The article focuses on a web-based tool that enhances search capabilities","which falls under the Technology/Web category. Additionally","the use of advanced search techniques and programming aspects of the tool suggest Programming/Scripting as a relevant category. However","since SearchGPT is the main focus","Technology/Web is the most appropriate primary category. \n\nTherefore","the final categories are:\nTechnology/Web","Programming/Scripting"],"author":"Rifx.Online","tags":["SearchGPT","semantic","efficiency","prompts","aggregation"],"draft":false,"slug":"blog/searchgpt-changed-how-i-surf-the-web-forever-3e970027998c"},"content":"\n\n\n### ÊàëÂëäÂà´‰∫ÜË∞∑Ê≠åÔºå‰Ω†‰πüÂèØ‰ª•„ÄÇÂ≠¶‰π†Â¶Ç‰Ωï‰ΩøÁî® SearchGPTÔºåÊîπÂèò‰Ω†ÁöÑÂ∑•‰ΩúÊñπÂºè„ÄÇ\n\n\n\nËøô‰∏çÊòØÁÇπÂáªËØ±È•µ„ÄÇÊàëÂÆåÂÖ®Áõ∏‰ø° SearchGPTÔºåÊàëÂ∞ÜÂëäËØâ‰Ω†ÂéüÂõ†„ÄÇËøôÁØáÊñáÁ´†Êó¢ÊòØ‰Ω†Â∫îËØ•ÂºÄÂßã‰ΩøÁî® SearchGPT ÁöÑÂÆ£Ë®ÄÔºå‰πüÊòØÂÖ≥‰∫éÂ¶Ç‰ΩïÊúÄ‰Ω≥‰ΩøÁî®ÂÆÉÁöÑÂÖ®Èù¢ÊåáÂçó„ÄÇ\n\nÊó†ËÆ∫‰Ω†ÊòØ SearchGPT ÁöÑÊñ∞ÊâãÔºåËøòÊòØÁ®çÂæÆÂ∞ùËØïËøáÔºåÊàñËÄÖÂ∑≤ÁªèÊòØÈ´òÁ∫ßÁî®Êà∑ÔºåÊàë‰øùËØÅ‰Ω†‰ºöÂú®ËøôÈáåÊâæÂà∞ÊúâÁî®ÁöÑ‰∏úË•ø„ÄÇËøôÁØáÊñáÁ´†ÊúâÁÇπÈïøÔºå‰ΩÜÂÆÉÂèØËÉΩÊòØ‰Ω†Âú® 2024 Âπ¥Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÂèØ‰ª•ÂÅöÂá∫ÁöÑÊúÄËäÇÁúÅÊó∂Èó¥ÁöÑÊîπËøõ„ÄÇ\n\n‰∏çÂÜçËµòËø∞ÔºåËÆ©Êàë‰ª¨Êù•ÁúãÁúãÊàëÂ¶ÇÊ≠§ÂñúÁà± SearchGPT ÁöÑ‰∏Ä‰∫õ‰∏ªË¶ÅÂéüÂõ†„ÄÇ\n\n## SearchGPTÁöÑ‰∏âÂ§ß‰ºòÂäø\n\n### 1\\. Ë∂ÖÂø´ÈÄüËØ≠‰πâÊêúÁ¥¢\n\nÊÇ®ÂèØ‰ª•Áî® Search GPT ÊêúÁ¥¢ *‰ªª‰Ωï‰∏úË•ø*„ÄÇ‰∫ãÂÆû‰∏äÔºåÂú®ÊàëÁöÑÂØπÊØîÊµãËØï‰∏≠ÔºåÂÆÉÁöÑÈÄüÂ∫¶ÂèØ‰ª•ÊØîÊ†áÂáÜÁöÑ Google ÊêúÁ¥¢Âø´ **10 ÂÄç**„ÄÇ\n\n‰æãÂ¶ÇÔºåÂâçÂá†Â§©ÔºåÊàëÊÉ≥Ëµ∑‰∫Ü‰∏Ä‰∏™Êàë‰πãÂâçÁúãÂà∞ÁöÑÈù¥Â≠êÂìÅÁâåÔºåÊÉ≥Ë¶ÅËøõ‰∏ÄÊ≠•‰∫ÜËß£„ÄÇÊàëÁü•ÈÅì‰∏Ä‰∫õÂÖ≥‰∫éËøô‰∏™ÂìÅÁâåÁöÑÁªÜËäÇÔºå‰ΩÜÂæàÈöæÁî®‰∏Ä‰∏™ÊêúÁ¥¢ËØçÊù•Ë°®Ëææ„ÄÇ‰ª•‰∏ãÊòØÊàëÊâÄÁü•ÈÅìÁöÑÔºö\n\n* ÂÆÉÊòØ‰∏Ä‰∏™ÂçïËØçÂìÅÁâåÔºàÂç≥‚ÄúJim's Boots‚ÄùÊàñÁ±ª‰ººÂêçÁß∞Ôºâ\n* Èù¥Â≠êÁõ∏ÂΩìÊòÇË¥µ‰ΩÜË¥®Èáè‰∏ä‰πò\n* Èù¥Â≠êÊòØÊâãÂ∑•Âà∂‰ΩúÁöÑ\n* ÂÆÉ‰ª¨ÊòØÂè§Áî∞ÈûãÂ∫ïÔºàGoodyear Welted SolesÔºâ\n* ÂÆÉ‰ª¨ÊòØ‰∏Ä‰∏™ÁæéÂõΩÂìÅÁâåÔºàÂèØËÉΩÔºâ\n* ÂÆÉ‰ª¨Âú®‰∏Ä‰∏™Èù¥Â≠êÁõ∏ÂÖ≥ÁöÑ Subreddit Á§æÂå∫‰∏≠Â§áÂèóÊé®Â¥á\n\nËøôÊòØ‰∏ÄÁßçÊÉÖÂÜµÔºåÂ¶ÇÊûúÊàëËßÅËøáÔºåÊàë‰ºöËÆ∞ÂæóÔºõÂÆÉÂ∞±Âú®ÊàëÂò¥Ëæπ„ÄÇ‰∫éÊòØÔºåÊàëÂÜ≥ÂÆöÂÅö‰∏Ä‰∏™Â∞èÊµãËØï„ÄÇÊàëÁõ¥Êé•ÊØîËæÉ‰∫Ü SearchGPT Âíå Google„ÄÇÊàëËÆæÁΩÆ‰∫Ü‰∏Ä‰∏™ËÆ°Êó∂Âô®ÔºåÈ¶ñÂÖàÁî® Google ÂºÄÂßãÊêúÁ¥¢„ÄÇ\n\nÂú®Ë¥≠Áâ©È°µÈù¢‰∏äÊ≤°ÊúâÊâæÂà∞‰ªª‰Ωï‰∏úË•øÂêéÔºàÊêúÁ¥¢‚ÄúÊâãÂ∑•Âà∂‰ΩúÁöÑÁæéÂõΩÂè§Áî∞ÈûãÂ∫ïÈù¥Â≠ê‚ÄùÊó†ÊûúÔºâÔºåÊàëÂºÄÂßã‰∏çÂÅúÂú∞ÊªöÂä®„ÄÇÂú®Ââç 30 ‰∏™ÁªìÊûú‰πãÂêéÔºåÊàëÂÜçÊ¨°Ê≤°ÊúâÊâæÂà∞‰ªª‰Ωï‰∏úË•ø„ÄÇ\n\nÊàëÂºÄÂßãÂú®ÊêúÁ¥¢Êú´Â∞æÊèíÂÖ•‚ÄúReddit‚Äù„ÄÇÂâç‰∏§‰∏™Âá∫Áé∞ÁöÑÂ∏ñÂ≠êÊ≤°ÊúâÊâæÂà∞‰ªª‰Ωï‰ø°ÊÅØÔºå‰ΩÜÈöèÂêéÊàëÊâæÂà∞‰∫Ü„ÄÇËøôÈáåÊúâ‰∏Ä‰∏™ [ÂÖ≥‰∫éÊúÄ‰Ω≥Èù¥Â≠êÂìÅÁâåÁöÑÂ∑®Â§ßÂ∏ñÂ≠êÔºåÊåâÁÖß‰ª∑Ê†ºÁÇπËøõË°åÊ¶ÇËø∞](https://www.reddit.com/r/goodyearwelt/comments/7qxy6p/the_2018_beginners_boot_buying_guide/)ÔºåÊàëÂºÄÂßãÊµèËßàËøô‰∏™Â∫ûÂ§ßÁöÑÂàóË°®ÔºåÂØªÊâæÈÇ£‰∏™ÂìÅÁâå„ÄÇÁªèËøá‰∏ÄÂàÜÈíüÔºåÊàëÊâæÂà∞‰∫ÜÔºöNicks Boots„ÄÇ\n\nÊàëÁöÑÊÄªÊêúÁ¥¢Êó∂Èó¥Ôºü **4:37\\.**\n\nÊàëËÆæÁΩÆ‰∫Ü‰∏Ä‰∏™Êñ∞ËÆ°Êó∂Âô®ÔºåÊâìÂºÄ‰∫Ü SearchGPTÔºåÂπ∂ËæìÂÖ•‰∫ÜÂÖ≥‰∫éÊàëÊâÄÁü•ÈÅìÁöÑËøô‰∏™ÂìÅÁâåÁöÑÊèêÁ§∫„ÄÇÊàëËä±‰∫ÜÂ§ßÁ∫¶ **20 Áßí** Êù•ÂÜôÂá∫Ëøô‰∏™ÊèêÁ§∫„ÄÇ‰ª•‰∏ãÊòØÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JM16NcvRzXDZB2dnT2K96w.png)\n\nËΩ∞ÔºÅÂÆÉÂ∞±Âú®ËøôÈáåÔºåÊéíÂú®Á¨¨ 7 ‰Ωç„ÄÇËøôÊØî Google ÊêúÁ¥¢Âø´‰∫ÜÊï¥Êï¥ **13 ÂÄç**„ÄÇÊàëËøòÈúÄË¶ÅÂÜçËØ¥ÊúçÊÇ®ÂÆÉÁöÑÈÄüÂ∫¶ÂêóÔºü\n\n### 2\\. Âø´ÈÄüÁêÜËß£Êüê‰∏™Ê¶ÇÂøµÁöÑÁâπÂÆöÈÉ®ÂàÜ\n\nÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÂú®‰∫íËÅîÁΩë‰∏äÊêúÁ¥¢‰ª•‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØÔºå‰Ω†ÂæàÂèØËÉΩÊúÄÁªà‰ºöÂú®Áª¥Âü∫ÁôæÁßë‰∏äÔºåÊàñËÄÖ‰Ω†ÂèØËÉΩ‰ºöÈòÖËØª[Ë∞∑Ê≠åÁöÑÂª∫ËÆÆÊëòË¶Å](https://support.google.com/websearch/answer/9351707?hl=en)„ÄÇËôΩÁÑ∂Ëøô‰∏§ËÄÖÈÉΩÊòØÂæàÂ•ΩÁöÑËµÑÊ∫êÔºå‰ΩÜÂÖ≥‰∫éËØ•‰∏ªÈ¢òÁöÑ‰ø°ÊÅØÂæÄÂæÄ‰ºö‰Ωø‰Ω†ÂÅèÁ¶ªÊ†πÊú¨ÁõÆÊ†á„ÄÇ‰ΩøÁî® SearchGPTÔºå‰Ω†ÂèØ‰ª•Âø´ÈÄüËé∑ÂæóÊ¶ÇËø∞ÔºåÈÄöËøáÂêéÁª≠ÈóÆÈ¢òÁº©Â∞èÁêÜËß£ËåÉÂõ¥ÔºåÊõ¥Âø´Âú∞ÂÆûÁé∞Áü•ËØÜÁõÆÊ†á„ÄÇ\n\n‰æãÂ¶ÇÔºåÂÅáËÆæÊàë‰ª¨ÊòØ‰∏Ä‰∏™ÂÆåÂÖ®Â§ñË°åÁöÑ‰∫∫ÔºåÊÉ≥‰∫ÜËß£È£éÂäõÊ∂°ËΩÆÊú∫Â¶Ç‰ΩïÂ∞ÜÈ£éËΩ¨Êç¢‰∏∫ËÉΩÈáè„ÄÇ\n\nÂú®‰º†ÁªüÊêúÁ¥¢ÊµÅÁ®ã‰∏≠ÔºåÊàë‰ª¨ÂèØËÉΩ‰ºöÊêúÁ¥¢‚ÄúÈ£éÂäõÊ∂°ËΩÆÊú∫‚ÄùÊàñ‚ÄúÈ£éÂäõÊ∂°ËΩÆÊú∫ÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑ‚Äù„ÄÇËÆ©Êàë‰ª¨ÁúãÁúãË∞∑Ê≠åÁöÑÊêúÁ¥¢ÁªìÊûúÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*93wqzjbylGagTlO9038iqw.png)\n\nÂú®Ëøô‰πãÂêéÔºåÊàë‰ª¨Áé∞Âú®ÁêÜËß£‰∫ÜÈ£éÂäõÊ∂°ËΩÆÊú∫ÁöÑË¶ÅÁÇπ„ÄÇÁÑ∂ËÄåÔºåÂêåÊó∂Êàë‰ª¨‰ªÄ‰πà‰πü‰∏çÁü•ÈÅì„ÄÇ‰∏∫‰∫ÜÂΩ¢ÊàêÂÆûÈôÖÁöÑÁêÜËß£ÔºåÊàë‰ª¨ÂøÖÈ°ªÈô∑ÂÖ•‰∏Ä‰∏™‰ø°ÊÅØÁöÑÂÖîÂ≠êÊ¥û„ÄÇÂõ†Ê≠§Ôºå‰Ω†ÂèØËÉΩ‰ºöÊé•‰∏ãÊù•ÊêúÁ¥¢ÁîµÂä®ÂèëÁîµÊú∫ÁöÑÂÆûÈôÖÂÜÖÈÉ®Â∑•‰ΩúÂéüÁêÜ„ÄÇÁÑ∂ÂêéÔºå‰Ω†ËøòÂæóËøõË°åÂè¶‰∏ÄÊ¨°ÊêúÁ¥¢ÔºåÂ∞ÜËåÉÂõ¥Áº©Â∞èÂà∞È£éÂäõÊ∂°ËΩÆÊú∫ÂèëÁîµÊú∫ÔºåÂπ∂‰ªé‰∏≠ÁªºÂêà‰ø°ÊÅØ„ÄÇ\n\nËøô‰∏™ËøáÁ®ãÊòØÊúâÊïàÁöÑÔºå‰ΩÜ**ÊïàÁéáÂ§™‰Ωé‰∫Ü„ÄÇ**\n\n‰ΩøÁî® SearchGPTÔºåÊàë‰ª¨ÂèØ‰ª•Êõ¥Âø´„ÄÅÊõ¥Áõ¥ËßÇÂú∞ÊûÑÂª∫Êàë‰ª¨ÁöÑÁü•ËØÜÂü∫Á°Ä„ÄÇÂ∞±Â•ΩÂÉèÊàë‰ª¨Âú®‰∏éÈ£éÂäõÊ∂°ËΩÆÊú∫‰∏ìÂÆ∂ÂØπËØù„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÊµÅÁ®ãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BbSoxRLJNPh_BQehsaxB8g.png)\n\nÁé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•‰ªéËøô‰∫õÁªÑ‰ª∂‰∏≠ÈÄâÊã©‰∏Ä‰∏™Ôºå‰ª•Êõ¥Ê∑±ÂÖ•Âú∞ÁêÜËß£ËØ•‰∏ªÈ¢ò„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*REgvUWKmAWGRCrzi6nSeGw.png)\n\nÂú®‰ªª‰ΩïÊó∂ÂÄôÔºåÊàë‰ª¨ÈÉΩÂèØ‰ª•ÁÇπÂáªÊèê‰æõÁöÑÈìæÊé•‰ªéÁõ¥Êé•Êù•Ê∫êÈòÖËØªÔºåËÄåÊàë‰ª¨ÁöÑËÅäÂ§©ËÆ∞ÂΩï‰øùÊåÅÂÆåÊï¥„ÄÇËøôÊòØÊàëÂèëÁé∞ÁöÑ‰∫ÜËß£Êüê‰∫ãÁöÑÊúÄÂø´ÊñπÂºèÔºåÂÆåÂÖ®‰∏çÂøÖÊãÖÂøÉ AI ÂπªËßâÔºàÂ§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÔºâ„ÄÇ\n\n### 3\\. ÂëäÂà´Ê†áÁ≠æÈ°µÁÉ¶ÊÅº\n\nÊúâ‰∫Ü SearchGPTÔºåÊ†áÁ≠æÈ°µÂü∫Êú¨‰∏äÂèòÂæóÂ§ö‰Ωô„ÄÇÂÜç‰πü‰∏çÁî®Âú®Â§ö‰∏™ Chrome Á™óÂè£‰πãÈó¥ÊäòËÖæÔºåÊØè‰∏™Á™óÂè£ÈÉΩÊúâÂá†ÂçÅ‰∏™Ê†áÁ≠æÈ°µ„ÄÇ‰πü‰∏çÂøÖÊãÖÂøÉÊÑèÂ§ñÁöÑËÆ°ÁÆóÊú∫ÈáçÂêØ‰ºöÂØºËá¥Â§öÂ§©ÁöÑÁ†îÁ©∂ËøõÂ±ï‰∏¢Â§±ÔºåÊàñËÄÖÂ∏åÊúõËÉΩÂ§üÊâæÂõûÂá†‰∏™ÊúàÂâçÁöÑÊêúÁ¥¢ËÆ∞ÂΩï„ÄÇ\n\nSearchGPT Â∞Ü‰Ω†ÁöÑÊâÄÊúâÁ†îÁ©∂ÈõÜ‰∏≠Âú®‰∏Ä‰∏™Âú∞Êñπ„ÄÇÂÆÉÊòì‰∫éÂØºËà™Ôºå‰Ω†ÁöÑÊêúÁ¥¢ÂéÜÂè≤ÊòØÊó†ÈôêÁöÑ„ÄÇ\n\nÂÅáËÆæ‰Ω†Â∑≤Áªè‰ΩøÁî® SearchGPT Âá†‰∏™Êúà‰∫Ü„ÄÇ‰Ω†ÂèØËÉΩËøòËÆ∞Âæó‰Ω†ÊõæÁªèËøõË°åËøáÁöÑ‰∏ÄÊÆµÂÖ≥‰∫é [Âú®Á∫øÂπøÂëäÂÜçËê•ÈîÄ](https://mailchimp.com/resources/what-is-retargeting/) ÁöÑÁ†îÁ©∂„ÄÇÈÇ£‰πàÔºå‰Ω†ËØ•Â¶Ç‰ΩïÊâæÂà∞ÂÆÉÂë¢ÔºüÂÄüÂä©ÂèØÈù†ÁöÑ ChatGPT ÊêúÁ¥¢Ê†èÔºåÊàë‰ª¨ÂèØ‰ª•ÈùûÂ∏∏Âø´ÈÄüÂú∞ÊâæÂà∞Á°ÆÂàáÁöÑËÅäÂ§©ËÆ∞ÂΩïÔºåÂπ∂‰ªéÊàë‰ª¨ÂÅú‰∏ãÁöÑÂú∞ÊñπÁªßÁª≠Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BSOOg5-XJc0_zacDf0f87Q.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*32x_mj_WnLLc_xxH6WBuRg.png)\n\nÂ¶Ç‰Ω†ÊâÄËßÅÔºåÊµèËßàËÅäÂ§©ËÆ∞ÂΩï„ÄÅÁÇπÂáªÊù•Ê∫êÂíåÊ∑±ÂÖ•ÈòÖËØª‰ªª‰Ωï‰∏ªÈ¢òÈÉΩÈùûÂ∏∏Âø´ÈÄüÂíåÁÆÄÂçï„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™Ë∂ÖÁ∫ßÈïøÁöÑËÅäÂ§©ËÆ∞ÂΩïÔºåÂèØ‰ª•ÈÄöËøáÊåâ‚Äúctrl\\+f‚ÄùÂπ∂Âú®È°µÈù¢‰∏äÊêúÁ¥¢ÂÖ≥ÈîÆËØçÂø´ÈÄüÂØºËà™Âà∞ËÅäÂ§©ÁöÑÊüê‰∫õÈÉ®ÂàÜ„ÄÇ\n\nËøô‰∫õÊòØÊàëËÆ§‰∏∫ SearchGPT ÁöÑ‰∏âÂ§ß‰ºòÂäøÔºå‰ΩÜËøòÊúâÂæàÂ§öÂÖ∂‰ªñ‰ºòÁÇπ„ÄÇ\n\nËÆ©Êàë‰ª¨ËøáÊ∏°Âà∞Êú¨ÊñáÁöÑ‰∏ã‰∏Ä‰∏™‰πüÊòØÊúÄÂÖ≥ÈîÆÁöÑÈÉ®ÂàÜÔºö**Â¶Ç‰ΩïÊúÄ‰Ω≥‰ΩøÁî® SearchGPT„ÄÇ**\n\n## SearchGPT Âø´ÈÄüÂÖ•Èó®\n\nÂ¶ÇÊûúÊÇ®Â∑≤ÁªèÁü•ÈÅìÂ¶Ç‰ΩïÂºÄÂßã‰ΩøÁî® SearchGPTÔºåËØ∑Ë∑≥Ëøá‰∏ã‰∏ÄÈÉ®ÂàÜ„ÄÇ\n\nÊúâ‰∏âÁßçÊñπÊ≥ïÂèØ‰ª•ÂºÄÂßã‰ΩøÁî® SearchGPTÔºö\n\n1. **Âú®ËÅäÂ§©‰∏≠‰ΩøÁî® SearchGPT** ‚Äî ÊâìÂºÄ‰∏Ä‰∏™ÊôÆÈÄöÁöÑ GPT-4o ËÅäÂ§©ÔºåÂπ∂ÁÇπÂáªÊêúÁ¥¢ÂõæÊ†áÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-p9GcMd7fRlwmXdHvLBzvw.png)\n\nÈÄöËøáËøôÁßçÊñπÂºèÔºåÊÇ®Âú®ËÅäÂ§©Ê°Ü‰∏≠ËæìÂÖ•ÁöÑÊØè‰∏™ÊèêÁ§∫ÈÉΩ‰ºöËß¶ÂèëÁΩëÁªúÊêúÁ¥¢„ÄÇÂÆÉÂ∞ÜËøîÂõûÂìçÂ∫î‰ª•ÂèäÊù•Ê∫êÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WQMDebhc5g61YvpaQUDeYw.png)\n\n2\\. **SearchGPT Áõ¥Êé•‰ΩøÁî® ‚Äî** ÂØºËà™Ëá≥Ê≠§ÈìæÊé•Ôºö<https://chatgpt.com/search> Âπ∂ÂºÄÂßãÊêúÁ¥¢Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*b-nIPELvT1heBlkbOcKAzQ.png)\n\nÊÇ®ÂèØ‰ª•ÈÄöËøáÁÇπÂáªÂ∑¶‰æßÁöÑÈìæÊé•ÂõæÊ†áÊâìÂºÄÊù•Ê∫êÔºå‰πüÂèØ‰ª•ÈÄöËøáÁÇπÂáªÂõæÂÉèÂõæÊ†áÊü•ÁúãÊõ¥Â§öÂ™í‰Ωì„ÄÇ\n\n3\\. **‰ΩøÁî® Chrome Êâ©Â±ïÁ®ãÂ∫èÂ∞ÜÈªòËÆ§ÊêúÁ¥¢ÂºïÊìéÂàáÊç¢‰∏∫ SearchGPT ‚Äî** ÂØºËà™Ëá≥ [Ê≠§ÈìæÊé•](https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld?pli=1) Â∞ÜÊâ©Â±ïÁ®ãÂ∫èÊ∑ªÂä†Âà∞ Chrome„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hGkw33h7uEP7rFwCtpbr7g.png)\n\nChrome Êâ©Â±ïÁ®ãÂ∫èÂú®ÊÇ®ÊØèÊ¨°Âú®ÊêúÁ¥¢Ê°Ü‰∏≠ËæìÂÖ•Êü•ËØ¢Âêé‰ºöÈáçÂÆöÂêëÂà∞ SearchGPT„ÄÇËôΩÁÑ∂Êàë‰∏ç‰∏ÄÂÆöÊé®ËçêËøôÊ†∑ÂÅöÔºàGoogle Âú®Êüê‰∫õ‰∫ãÊÉÖ‰∏ä‰ªçÁÑ∂ÊúâÂÖ∂Áî®Â§ÑÔºåÊàëÁ®çÂêé‰ºöËÆ®ËÆ∫ÔºâÔºå‰ΩÜÊÇ®ÂèØ‰ª•Â∞ùËØï‰∏Ä‰∏ãÔºåÁúãÁúãÂÆÉÂØπÊÇ®Êù•ËØ¥ÊïàÊûúÂ¶Ç‰Ωï„ÄÇ\n\nËôΩÁÑ∂‰ΩøÁî® ChatGPT ÁöÑÊØèÁßçÊñπÊ≥ïÈÉΩÊòØÊúâÊïàÁöÑÔºå‰ΩÜÊàë‰∏™‰∫∫Êõ¥ÂñúÊ¨¢Âú®ÊôÆÈÄöÁöÑ ChatGPT ÁïåÈù¢‰∏≠‰ΩøÁî®ÂÆÉÔºàÈÄâÈ°π 1Ôºâ„ÄÇÂõ†Ê≠§ÔºåÊú¨ÊñáÂ§ßÈÉ®ÂàÜÂÜÖÂÆπÂ∞ÜÈõÜ‰∏≠Âú®ÈÄâÈ°π 1 ‰∏ä„ÄÇ\n\n## ÁêÜËß£‰∫íËÅîÁΩëÊêúÁ¥¢ÁöÑËâ∫ÊúØ\n\nÂú®Êàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ®ÊàëÊâÄÊâøËØ∫ÁöÑÈ´òÁ∫ß SearchGPT Á≠ñÁï•‰πãÂâçÔºåÊàë‰ª¨ÂøÖÈ°ª‰∫ÜËß£ÊêúÁ¥¢ÊòØ‰ªÄ‰πà„ÄÇ‰∫íËÅîÁΩëÊêúÁ¥¢ÂÆûÈôÖ‰∏äÊòØ‰∏Ä‰∏™Áõ∏ÂΩìÂ§çÊùÇÁöÑ‰∏ªÈ¢ò„ÄÇÂç≥‰Ωø‰Ω†‰ªéÊú™ÊúâÊÑèËØÜÂú∞ÊÄùËÄÉËøáÔºåÂÆÉ‰πüÂú®‰Ω†ÁöÑËÑëÊµ∑‰∏≠Ê†πÊ∑±ËíÇÂõ∫Âú∞Â≠òÂú®ÁùÄÂ§öÊù°‰∫íËÅîÁΩëÊêúÁ¥¢Ë∑ØÂæÑ„ÄÇ‰Ω†ÈúÄË¶Å‰∫ÜËß£ SearchGPT Â¶Ç‰ΩïÂú®Ëøô‰∫õË∑ØÂæÑ‰∏≠Êèê‰æõÂ∏ÆÂä©ÔºàÊàñ‰∏çÊèê‰æõÂ∏ÆÂä©Ôºâ„ÄÇ\n\n### ‰∫íËÅîÁΩëÊêúÁ¥¢ÁöÑ7ÁßçË∑ØÂæÑ\n\nÂú®‰∫íËÅîÁΩëÊêúÁ¥¢È¢ÜÂüüÔºåÊúâËÆ∏Â§öÈÄöÁî®Ë∑ØÂæÑÊ∂µÁõñ‰∫ÜÂ§ßÂ§öÊï∞Ê¥ªÂä®„ÄÇ‰ª•‰∏ãÊòØÊØèÁßçË∑ØÂæÑÁöÑÁÆÄË¶ÅÊ¶ÇËø∞Ôºö\n\n1. **ÂØºËà™ÊêúÁ¥¢**ÔºöÂΩì‰Ω†ÊÉ≥Âø´ÈÄüÂà∞ËææÁâπÂÆöÁΩëÁ´ôÊó∂Ôºå‰Ω†ÈÄöËøáÂêçÁß∞ÊàñÂìÅÁâåËøõË°åÊêúÁ¥¢Ôºà‰æãÂ¶ÇÔºå‚Äú‰∫öÈ©¨ÈÄä‚ÄùÊàñ‚ÄúFacebook ÁôªÂΩï‚ÄùÔºâ„ÄÇ\n2. **‰ø°ÊÅØÊêúÁ¥¢ÔºàÁõ¥Êé•ÂíåÈó¥Êé•Ôºâ**ÔºöÂΩì‰Ω†ÊÉ≥‰∫ÜËß£Êüê‰∏™‰∏ªÈ¢òÊàñÂØªÊâæÁ≠îÊ°àÊó∂Ôºå‰Ω†‰ΩøÁî®ÂºÄÊîæÂºèÊü•ËØ¢ÔºàÁõ¥Êé•Ôºö‚ÄúÊ∞îÂÄôÂèòÂåñÊòØ‰ªÄ‰πàÔºü‚ÄùÈó¥Êé•Ôºö‚ÄúÊ∞îÂÄôÂèòÂåñÁöÑ‰∫ãÂÆû‚ÄùÔºâ„ÄÇ\n3. **‰∫§ÊòìÊêúÁ¥¢**ÔºöÂΩì‰Ω†ÂáÜÂ§áËøõË°åË¥≠‰π∞ÊàñÊ≥®ÂÜåÊüêÈ°πÊúçÂä°Êó∂Ôºå‰Ω†Â∏¶ÁùÄÂÆåÊàêÊüê‰∏™Âä®‰ΩúÁöÑÊÑèÂõæËøõË°åÊêúÁ¥¢Ôºà‰æãÂ¶ÇÔºå‚ÄúË¥≠‰π∞ iPhone 15‚ÄùÊàñ‚ÄúÊ≥®ÂÜå Medium‚ÄùÔºâ„ÄÇ\n4. **ÂïÜ‰∏öË∞ÉÊü•**ÔºöÂΩì‰Ω†Âú®Ë¥≠‰π∞ÂâçÊØîËæÉ‰∫ßÂìÅÊàñÊúçÂä°Êó∂Ôºå‰Ω†‰ΩøÁî®‚ÄúÊúÄ‰Ω≥‚ÄùÊàñ‚ÄúÈ°∂Á∫ß‚ÄùÁ≠âÂÖ≥ÈîÆËØçËøõË°åÊêúÁ¥¢Ôºà‰æãÂ¶ÇÔºå‚ÄúÂ≠¶ÁîüÊúÄ‰Ω≥Á¨îËÆ∞Êú¨ÁîµËÑë‚ÄùÊàñ‚Äú2024 Âπ¥È°∂Á∫ßÁ¨îËÆ∞Êú¨ÁîµËÑë‚ÄùÔºâ„ÄÇ\n5. **Á≤æÁÇºÂíåËø≠‰ª£ÊêúÁ¥¢**ÔºöÂΩì‰Ω†Â§öÊ¨°Á≤æÁÇºÊêúÁ¥¢‰ª•Êõ¥Êé•ËøëÊâÄÈúÄÂÜÖÂÆπÊó∂Ôºå‰Ω†Ë∞ÉÊï¥ÂÖ≥ÈîÆËØçÂíåÊé™ËæûÔºà‰æãÂ¶ÇÔºå‰ªé‚ÄúGDPR ËßÑÂàô‚ÄùÂà∞‚ÄúÊ¨ßÁõü‰ºÅ‰∏öÊï∞ÊçÆÈöêÁßÅ‚ÄùÔºâ„ÄÇËøôÊòØÂ§ßÂ§öÊï∞‚ÄúÊêúÁ¥¢ÂÖîÂ≠êÊ¥û‚ÄùÁöÑÂü∫Á°Ä„ÄÇ\n6. **Á∫µÂêëÊêúÁ¥¢**ÔºöÂΩì‰Ω†Âú®Â§ö‰∏™Ê†áÁ≠æÈ°µÂíå‰ºöËØù‰∏≠ËøõË°åÊâ©Â±ïÁ†îÁ©∂Êó∂Ôºå‰Ω†ÂèØËÉΩ‰ºöÁïô‰∏ãÊâìÂºÄÁöÑÊ†áÁ≠æ‰ª•‰æøÂêéÁª≠ÂèÇËÄÉÔºåÂπ∂Âú®ÊØèÊ¨°ÊêúÁ¥¢Êó∂ÁªßÁª≠Á≤æÁÇºÔºà‰æãÂ¶ÇÔºåÂΩì‰Ω†Âú®ÊØîËæÉÊΩúÂú®ÁöÑËà™Áè≠Ë°åÁ®ãÊó∂Ôºâ„ÄÇ\n7. **Â∑≤Áü•È°πÁõÆÊêúÁ¥¢**ÔºöÂΩì‰Ω†ÂØªÊâæÁâπÂÆöÂÜÖÂÆπÊó∂Ôºå‰Ω†Áü•ÈÅìËØ•ÂÜÖÂÆπÂ≠òÂú®Ôºå‰Ω†ÈÄöËøáÊ†áÈ¢ò„ÄÅÂêçÁß∞ÊàñÁã¨ÁâπÁªÜËäÇËøõË°åÊêúÁ¥¢Ôºà‰æãÂ¶ÇÔºå‚ÄúNY Times ÂÖ≥‰∫éËøúÁ®ãÂ∑•‰ΩúÁöÑÊñáÁ´†Ôºå‰ΩúËÄÖÔºöJane Doe‚ÄùÔºâ„ÄÇËøô‰∏éÂØºËà™ÊêúÁ¥¢Áõ∏‰ººÔºå‰ΩÜÊõ¥ÂÖ∑ÈíàÂØπÊÄß„ÄÇ\n\n### ‰∫íËÅîÁΩëÊêúÁ¥¢ÁöÑÂÖ∂‰ªñË∑ØÂæÑÔºàÊàëÁöÑÂèëÁé∞Ôºâ\n\nÊàëËßÇÂØüÂà∞‰∫Ü‰∏Ä‰∫õÊàëÁõ∏‰ø°‰Ω†‰ª¨‰∏≠ËÆ∏Â§ö‰∫∫ÈÉΩÂæàÁÜüÊÇâÁöÑÂÖ∂‰ªñË∑ØÂæÑ„ÄÇËôΩÁÑ∂Ëøô‰∫õÂπ∂Ê≤°ÊúâÊ≠£ÂºèË¢´ËÆ§ÂèØÔºå‰ΩÜÊàëËßâÂæóÂú®ËøôÈáåÊèêÂà∞ÂÆÉ‰ª¨ÊòØÂÄºÂæóÁöÑÔºö\n\n8\\. **‰∫∫Â∑•È™åËØÅÊêúÁ¥¢Ôºö** ÂΩì‰Ω†‰∏ìÈó®ÂØªÊâæÁúüÂÆû‰∫∫‰ª¨ÂØπÊüê‰∏™‰∏ªÈ¢òÁöÑÁúãÊ≥ïÊó∂Ôºà‰æãÂ¶ÇÔºåÂú®ÊêúÁ¥¢Êü•ËØ¢ÁöÑ[Êú´Â∞æÊ∑ªÂä†‚ÄúReddit‚Äù](https://detailed.com/forum-serps/)Ôºâ„ÄÇ\n\n9\\. **ÂèçSEOÊêúÁ¥¢Ôºö** Á±ª‰ºº‰∫é‰ø°ÊÅØÊêúÁ¥¢Ôºå‰ΩÜ‰Ω†ÊòØÂú®ÂØªÊâæÊù•Ëá™ÁúüÊ≠£ÂèØ‰ø°Êù•Ê∫êÁöÑ‰ø°ÊÅØÔºåËÄå‰∏çÊòØÈÇ£‰∫õÊã•ÊúâÊúÄ‰Ω≥[SEOÁ≠ñÁï•](https://www.theverge.com/features/23931789/seo-search-engine-optimization-experts-google-results)‰ΩÜÁº∫‰πèÁúüÂÆû‰ø°ÊÅØÁöÑÁΩëÁ´ôÔºà‰æãÂ¶ÇÔºåÊ≤Æ‰∏ßÂú∞ÊªöÂä®ÊµèËßàÊú™Áü•ÁΩëÁ´ôÔºåÁõ¥Âà∞ÊâæÂà∞‰∏Ä‰∏™‰Ω†‰ø°‰ªªÁöÑÁΩëÁ´ôÔºâ„ÄÇ\n\n10\\. **SOSÊêúÁ¥¢Ôºö** Âú®ÁΩëÁªú‰∏äÂØªÊâæ‰ªª‰ΩïËÆ∫Âùõ‰∏äÊúâÁõ∏ÂêåÈóÆÈ¢òÁöÑ‰∫∫ÁöÑÂ∏ÆÂä©ÔºàÊó†ËÆ∫Â§ö‰πàÂÜ∑Èó®ÔºâÔºà‰æãÂ¶ÇÔºåÊêúÁ¥¢‚ÄúÂΩìHMDI 1ÊèíÂÖ•Êó∂ÔºåSamsungÁîµËßÜÊó†Ê≥ïÂºÄÊú∫‚ÄùÔºâ„ÄÇ\n\n11\\. **ÂèçÁ°ÆËÆ§ÂÅèËØØÊêúÁ¥¢Ôºö** ÂΩì‰Ω†ÂíåÊúãÂèã‰ª¨ËøõË°åËæ©ËÆ∫Êó∂Ôºå‰Ω†ÂøÖÈ°ªÊêúÁ¥¢ÊúÄ[Êó†ÂÅèËßÅÁöÑÊúØËØ≠](https://dl.acm.org/doi/10.1145/3635034)Ôºà‰æãÂ¶ÇÔºåËØÅÊòé‰Ω†ÁöÑËÆ∫ÁÇπÊòØÊ≠£Á°ÆÁöÑÔºåÂêåÊó∂Êª°Ë∂≥‰Ω†Ëæ©ËÆ∫‰ºô‰º¥ÁöÑËßÇÁÇπÔºâ„ÄÇ\n\n12\\. **Â∑≤Áü•Êú™Áü•ÊêúÁ¥¢Ôºö** ÂΩì‰Ω†ÂØπ‰Ω†Ë¶ÅÊü•ÊâæÁöÑ‰∫ãÁâ©Êúâ‰∏Ä‰∫õ‰∫ÜËß£Ôºå‰ΩÜ‰∏çÁ°ÆÂÆöÂ¶Ç‰ΩïÊâæÂà∞ÂÆÉÔºà‰æãÂ¶ÇÔºåÊêúÁ¥¢‚ÄúÊúâ‰∏Ä‰∏™ËÄÅÊóßÁöÑyoutubeËßÜÈ¢ëÔºåÊòØ‰∏Ä‰∏™Â≠©Â≠êÂõ†‰∏∫Â§±ÂéªÊüê‰∏™ËßÜÈ¢ëÊ∏∏ÊàèËÄåÂ¥©Ê∫ÉÔºåËøòÊúâ‰∏ÄÁ≥ªÂàóÂÖ≥‰∫é‰ªñ‰ª¨ÁöÑËßÜÈ¢ë‚Ä¶‚Ä¶‚ÄùÔºâ„ÄÇ\n\nÁé∞Âú®‰Ω†ÂØπ‰∏çÂêåÁ±ªÂûãÁöÑÊêúÁ¥¢Êúâ‰∫Ü‰∫ÜËß£ÔºåÊàë‰ª¨Áªà‰∫éÂèØ‰ª•Ê∑±ÂÖ•Êé¢ËÆ®SearchGPTÂ¶Ç‰ΩïÂ∏ÆÂä©ÊØè‰∏ÄÁßçÊêúÁ¥¢„ÄÇÂáÜÂ§áÂ•Ω‰∫ÜÂêóÔºÅ\n\n## SearchGPT Á≠ñÁï•‚Äî ÁªÜËäÇÂàÜÊûê\n\nÊú¨ËäÇÂ∞ÜËØ¶ÁªÜÂàÜÊûêÊàë‰∏äÈù¢ÊèêÂá∫ÁöÑÊØè‰∏™ÊêúÁ¥¢Ë∑ØÂæÑ‰∏≠ SearchGPT ÁöÑ‰ºòÁº∫ÁÇπ„ÄÇÊØè‰∏™Â≠êÈÉ®ÂàÜÈÉΩÈÖçÂ§á‰∫ÜÁ§∫‰æã„ÄÅÂª∫ËÆÆÂíå‰ºòÂåñ‰ΩøÁî® SearchGPT ÁöÑÊäÄÂ∑ß„ÄÇËÆ©Êàë‰ª¨ÂºÄÂßãÂêßÔºÅ\n\n### SearchGPT Áî®‰∫éÂØºËà™ÂíåÂ∑≤Áü•È°πÁõÆÊêúÁ¥¢\n\nÂù¶ÁéáÂú∞ËØ¥ÔºåSearchGPT Âú®ËøôÈáåÂπ∂‰∏ç‰ºöÁªôÊàë‰ª¨Â∏¶Êù•Â§™Â§ßÂ∏ÆÂä©„ÄÇÂú® Google ‰∏≠ËæìÂÖ•‚Äúmedium‚Äù‰∏éÂú® SearchGPT ‰∏≠ËæìÂÖ•Âπ∂Ê≤°ÊúâÊïàÁéá‰∏äÁöÑÊèêÂçá„ÄÇÁÑ∂ËÄåÔºåÊúâ‰∫õÁΩëÈ°µÂèØËÉΩÈöæ‰ª•ËÆøÈóÆÔºåÂ∞§ÂÖ∂ÊòØÂΩì‰Ω†ÂøòËÆ∞Â∞ÜÂÖ∂Ê∑ªÂä†Âà∞‰π¶Á≠æÊó∂„ÄÇËøôÊ≠£ÊòØ SearchGPT ÂèëÊå•‰ΩúÁî®ÁöÑÂú∞Êñπ„ÄÇ\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∏™Âø´ÈÄüÁ§∫‰æã„ÄÇÊúâÊó∂ÊàëÂèëÁé∞ÂæàÈöæËÆøÈóÆÊüê‰∫õÁΩëÁ´ôÁöÑ API Ë¥¶Êà∑‰ø°ÊÅØ„ÄÇ‰ª•ÊàëÁöÑ Perplexity AI API Ë¥¶Êà∑‰∏∫‰æã„ÄÇÊàëËä±Ë¥π‰∫ÜÂæàÈïøÊó∂Èó¥ÊâçËÉΩÊâæÂà∞Ëøô‰∏™È°µÈù¢ÔºåËÄåÊàë‰∏ÄÁõ¥Ê≤°ÊúâÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞‰π¶Á≠æ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂÄüÂä© SearchGPTÔºåÊàëÂèØ‰ª•Á´ãÂç≥ÊâæÂà∞ÂÆÉÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sSi2EcTPGE3SNg_8qZnRog.png)\n\n**SearchGPT ÂØºËà™ÊêúÁ¥¢ÁöÑÊèêÁ§∫Ôºö**\n\n* Âú®ÂØªÊâæÂÜÖÂÆπÊó∂Ë¶ÅËØ¶ÁªÜÊèèËø∞„ÄÇ‰∏çË¶ÅÂÆ≥ÊÄïÁõ¥Êé•ÂÜôÂá∫Êù•\n* Â¶ÇÊûú‰Ω†Êâæ‰∏çÂà∞ÊâÄÈúÄÁöÑÂÜÖÂÆπÔºåÂèØ‰ª•ËØ∑ GPT Âêë *‰Ω†* ÊèêÂá∫ÊæÑÊ∏ÖÈóÆÈ¢òÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞Â∏ÆÂä©‰Ω†\n* ÂØπ‰∫éÂ∑≤Áü•È°πÁõÆÊêúÁ¥¢ÔºàÂç≥ÂÖ≥‰∫éËá™Âä®ÂåñÊèêÁ§∫Â∑•Á®ãÁöÑ Jordan Gibbs Medium ÊñáÁ´†ÔºâÔºåÂÆÉÂèØËÉΩ‰ºöÊúâÊâÄÂ∏ÆÂä©Ôºå‰ΩÜÂÜç‰∏ÄÊ¨°ÔºåÂÆÉÂú®ËøôÊñπÈù¢Âπ∂Ê≤°ÊúâÁúüÊ≠£‰ºò‰∫é Google„ÄÇ\n\nËøôÊòØ‰ΩøÁî® SearchGPT ÁöÑÂΩ±ÂìçÂäõÊúÄÂ∞èÁöÑÊñπÊ≥ï‰πã‰∏ÄÔºå‰ΩÜÂÅ∂Â∞î‰ªçÁÑ∂ÂèØ‰ª•Ê¥æ‰∏äÁî®Âú∫„ÄÇ\n\n### SearchGPT ‰ø°ÊÅØÊêúÁ¥¢ÔºàÁõ¥Êé•ÂíåÈó¥Êé•Ôºâ\n\nSeachGPT ÈùûÂ∏∏ÈÄÇÂêàÂø´ÈÄüËé∑ÂèñÁâπÂÆöÂÜÖÂÆπÊàñËÅöÂêàÊúÄÊñ∞‰ø°ÊÅØ„ÄÇÊ≤°ÊúâÊêúÁ¥¢ÂäüËÉΩÁöÑËÄÅÁâà ChatGPT ÊÄªÊòØÊúâ‰ª§‰∫∫ÊÅºÁÅ´ÁöÑÁü•ËØÜÊà™Ê≠¢Êó•Êúü„ÄÇÁÑ∂ËÄåÔºåÊàë‰ª¨Áé∞Âú®ÂèØ‰ª•Áõ¥Êé•ÈóÆÂÆÉ‰∏Ä‰∫õÂÆÉ‚Äú‰∏çÁü•ÈÅì‚ÄùÁöÑ‰∫ãÊÉÖÔºåÂõ†‰∏∫ÂÆÉÂèØ‰ª•ÈÄöËøá‰∫íËÅîÁΩëÊü•Êâæ„ÄÇÊàë‰ª¨ËøòÂèØ‰ª•Â§ßÂπÖÂáèÂ∞ëÂπªËßâÔºåÂõ†Ê≠§Êàë‰ª¨ÂèØ‰ª•Êõ¥‰ø°‰ªªÂÆÉÔºÅÂè™ÈúÄÁ°Æ‰øùÂßãÁªàÊ£ÄÊü•ÂÖ∂ÈáçË¶Å‰ø°ÊÅØÁöÑÊù•Ê∫ê :)\n\n‰Ωú‰∏∫ÊºîÁ§∫ÔºåÂÅáËÆæÊàëÊÉ≥Ë∞ÉÊü•ÊàëÂñúÊ¨¢‰ΩøÁî®ÁöÑÊï∞ÊçÆÂ∫îÁî®Âπ≥Âè∞ Streamlit ÁöÑ‰∏Ä‰∫õÊúÄÊñ∞ËøõÂ±ïÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MSaJSdJGJ1vGa3uVnfEKZg.png)\n\nÁé∞Âú®ÔºåÊàëÂèØ‰ª•ËΩªÊùæÂú∞ËÆ© ChatGPT ËÆøÈóÆËøô‰∫õÊúÄÊñ∞ÁöÑÊñáÊ°£Ôºå‰ª•‰æøÂÆÉÂèØ‰ª•‰ΩøÁî®ÂÖ®Êñ∞ÁöÑÂäüËÉΩ‰∏∫ÊàëÁºñÂÜô‰ª£Á†Å„ÄÇ\n\nËøôÂè™ÊòØ SearchGPT Â¶Ç‰ΩïÊîπÂñÑ‰ø°ÊÅØÊêúÁ¥¢ÁöÑ‰∏Ä‰∏™‰æãÂ≠êÔºå‰ΩÜËøôÈáåËøòÊúâ‰∏Ä‰∫õÊõ¥ÊúâÁî®ÁöÑÊèêÁ§∫ÂíåÊäÄÂ∑ß„ÄÇ\n\n**SearchGPT ‰ø°ÊÅØÊêúÁ¥¢ÔºàÁõ¥Êé•ÔºâÁöÑÊèêÁ§∫Ôºö**\n\n* Â¶ÇÊûúÊÇ®ÊÉ≥Ë¶ÅÊúÄÊñ∞‰ø°ÊÅØÔºåËØ∑ÂßãÁªàÊèêÂèäÂΩìÂâçÂπ¥‰ªΩÊàñ‚Äú‰ªäÂ§©‚Äù\n* ÊÇ®ÂèØ‰ª•‰ΩøÁî®ÊèêÁ§∫‚ÄúËØ∑Ê£ÄÊü•Â§ö‰∏™Êù•Ê∫êÂπ∂ËÅöÂêàÂÆÉ‰ª¨ÁöÑ‰ø°ÊÅØ‚ÄùÊù•ËÅöÂêàÊúâÂÖ≥Êüê‰∏Ä‰∏ªÈ¢òÁöÑ‰ø°ÊÅØ„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HFKD-3f89gK8do6Dqu01gg.png)\n\n* Â¶ÇÊûúÁ¨¨‰∏ÄÊ¨°ÂõûÂ§ç‰∏çÂ§üÊñ∞Êàñ‰∏çÂ§üÂÖ∑‰ΩìÔºåËØ∑Â∞ùËØïÂêéÁª≠ÊèêÁ§∫\n* Â∞ÜÊêúÁ¥¢ËøáÁ®ãËßÜ‰∏∫‰∏é‰∏ìÂÆ∂ÁöÑÂØπËØùÔºà‰∏çË¶ÅÂÆ≥ÊÄïÂÜô‰∏ã‰ªª‰ΩïÊÉ≥Âà∞ÁöÑÂÜÖÂÆπÔºâ\n* ÊÇ®ÂèØ‰ª•ÈÄöËøáÁâπÂà´ÊèêÂèäÊüê‰∏™Êù•Ê∫êÊù•Ë¶ÅÊ±ÇÂÆÉ‚ÄúÊ∑±ÂÖ•Êé¢ËÆ®‚ÄùÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XbXKRKy5WkF0QX1X0yzr5w.png)\n\n* ÊèíÂÖ•Ê≠§ÊèêÁ§∫Ôºö‚ÄúÂú®ÊÇ®ÂõûÂ§çÂêéÂàóÂá∫‰∏Ä‰∫õÊΩúÂú®ÁöÑÂêéÁª≠ÈóÆÈ¢ò‚ÄùÔºåÂ¶ÇÊûúÊÇ®Â∏åÊúõËé∑ÂæóÂºïÂØºÂºèÊêúÁ¥¢‰ΩìÈ™å\n* ‰∏çË¶ÅÂÆ≥ÊÄïÂº∫Ëø´ÂÆÉÂºïÁî®Êù•Ê∫ê„ÄÇÊúâÊó∂ÔºåÂÆÉÂèØËÉΩ‰ºöÁ®çÂæÆÊäµÂà∂ÔºåÂπ∂‰æùËµñ‰∫éÁé∞ÊúâÁü•ËØÜ„ÄÇÊÇ®ÂèØ‰ª•ÁÆÄÂçïÂú∞ÈÄöËøáÂ£∞ÊòéÔºö‚ÄúÊó†ËÆ∫Â¶Ç‰ΩïÔºåÊÇ®ÂøÖÈ°ª‰∏∫ÊÇ®ÊèêÂá∫ÁöÑÊØè‰∏™ËßÇÁÇπÂºïÁî®‰∏Ä‰∏™Êù•Ê∫ê‚Äù\n\nÈó¥Êé•‰ø°ÊÅØÊêúÁ¥¢ÔºàÂç≥ÔºåÊó†ÁõÆÊ†áÊêúÁ¥¢ÔºâÂú® SearchGPT ‰∏≠ÈùûÂ∏∏Âá∫Ëâ≤„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÊèêÁ§∫„ÄÇ\n\n**SearchGPT ‰ø°ÊÅØÊêúÁ¥¢ÔºàÈó¥Êé•ÔºâÁöÑÊèêÁ§∫Ôºö**\n\n*Ê≥®ÊÑèÔºöÊú¨ËäÇËøòÊ∂µÁõñ‰∫Ü‰∏äËø∞ÊèêÂà∞ÁöÑ‚ÄúÁ≤æÁÇºÂíåËø≠‰ª£ÊêúÁ¥¢‚Äù„ÄÅ‚ÄúÁ∫µÂêëÊêúÁ¥¢‚ÄùÂíå‚ÄúÂ∑≤Áü•Êú™Áü•ÊêúÁ¥¢‚Äù„ÄÇ*\n\n* ËØ∑ÂÆÉ‰∏∫ÊÇ®ÂàõÂª∫‰∏Ä‰∏™Â≠¶‰π†Â§ßÁ∫≤Ôºå‰ª•‰æøÊÇ®ÂèØ‰ª•ÈÄêÊ≠•Â≠¶‰π†ÊÇ®ÈúÄË¶Å‰∫ÜËß£ÁöÑÊ¶ÇÂøµ\n* Âú®ÂºÄÂßãÊêúÁ¥¢‰πãÂâçÔºåËØ∑Ê±ÇÂÆÉÂêëÊÇ®ÊèêÂá∫ÊæÑÊ∏ÖÈóÆÈ¢òÔºå‰ª•‰æøÊÇ®ÂèØ‰ª•Êõ¥Âø´Âú∞Áº©Â∞èË¶ÅÊü•ÊâæÁöÑÂÜÖÂÆπ„ÄÇ‰ΩøÁî®ÊèêÁ§∫Ôºö‚ÄúÂú®ÊÇ®ÂºÄÂßã‰πãÂâçÔºåËØ∑ËØ¢ÈóÆÊàëÊúâÂÖ≥ÊàëÁöÑÂ≠¶‰π†ÁõÆÊ†áÁöÑÊæÑÊ∏ÖÈóÆÈ¢ò„ÄÇ‚Äù‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*LE2mSqStwuy18ryNVQbZQw.png)\n\n* ËØ∑ÂÆÉÊé®Ëçê YouTube ËßÜÈ¢ë„ÄÇSearchGPT ÂèØ‰ª•ÊâæÂà∞‰∏éÊÇ®ÁöÑËØ∑Ê±ÇÈ´òÂ∫¶Áõ∏ÂÖ≥ÁöÑËßÜÈ¢ëÔºå‰ªéËÄå‰ΩøÊÇ®ÁöÑÂ≠¶‰π†‰ΩìÈ™åÊõ¥Âä†Â§öÂ™í‰ΩìÂåñÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7zhXPezwiMskkEcvAEfqjQ.png)\n\n* ËØ∑ÂÆÉÊé®ËçêÁÖßÁâá„ÄÅÂõæË°®ÂíåÂõæÂΩ¢‰Ωú‰∏∫ËßÜËßâËæÖÂä©Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FItZcImfTJVenkzy1lJiqw.png)\n\n* Âè¶‰∏ÄÁßçÊñπÊ≥ïÊòØÊàëÁß∞‰πã‰∏∫‚ÄúÂçï‰∏ÄÊù•Ê∫êÂàÜÊîØ‚ÄùÔºåÊÇ®ÂèØ‰ª•ËÆ© SearchGPT ÊÄªÁªì‰∏Ä‰∏™ÊÇ®‰ø°‰ªªÂπ∂ÂåÖÂê´‰∏ªÈ¢òÂÖ®Èù¢Ê¶ÇËø∞ÁöÑÂçï‰∏ÄÊù•Ê∫êÔºåÁÑ∂Âêé‰ªéÈÇ£ÈáåÂàÜÊîØÂá∫ÂéªÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*P8C4hpd8AxZgfuXDW0PNxg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_bHNNzZAukNMPIk8W6hhEQ.png)\n\n* ‰∏∫‰∫ÜÊõ¥Ê∑±ÂÖ•Âú∞Êé¢ËÆ®ÔºåÂπ∂ÈÅøÂÖç‚ÄúÊ±°Êüì‚ÄùGPT ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÔºåÊàëÂª∫ËÆÆÂ¶ÇÊûúÊÇ®ÊÉ≥ËÆ®ËÆ∫Êüê‰∏™ÈùûÂ∏∏ÂÖ∑‰ΩìÁöÑÂÜÖÂÆπÔºåÂèØ‰ª•ÊâìÂºÄ‰∏Ä‰∏™Êñ∞ËÅäÂ§©Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*G6Cxxvd7uGn-fS4pFkvyiw.png)\n\n* ÊÇ®ÂßãÁªàÂèØ‰ª•Âú®ÊêúÁ¥¢Ê†è‰∏≠ÊêúÁ¥¢ÊÇ®ÊúÄËøëÁöÑËÅäÂ§©ËÆ∞ÂΩïÔºåÂõ†Ê≠§ÊÇ®‰∏ç‰ºö‰∏¢Â§±‰ªª‰ΩïÂéÜÂè≤ËÆ∞ÂΩïÔºÅ\n\n‰ΩøÁî® SearchGPT ËøõË°å‰ø°ÊÅØÊêúÁ¥¢ÊòØ‰∏çÂèØÊÄùËÆÆÁöÑÔºåÊàëÂØπÊ≠§ÊÑüÂà∞Êó†ÊØîÂÖ¥Â•ã„ÄÇÊàë‰∏ÄÁõ¥ÂæàÊúüÂæÖÂä†Âø´ÊàëÊÉ≥Â≠¶‰π†ÁöÑÊâÄÊúâÂÜÖÂÆπÁöÑÂ≠¶‰π†ËøõÁ®ãÔºÅ\n\n### SearchGPTÁî®‰∫é‰∫§ÊòìÂíåÂïÜ‰∏öË∞ÉÊü•ÊêúÁ¥¢\n\nÊòØÁöÑÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®SearchGPTÊâæÂà∞Ê≥®ÂÜåÊàñË¥≠‰π∞ÊúçÂä°Âíå‰∫ßÂìÅÁöÑÂú∞Êñπ„ÄÇËôΩÁÑ∂ËøôÂπ∂‰∏ç‰∏ÄÂÆöÊØîGoogleÊõ¥Âø´ÊàñÊõ¥Â•ΩÔºå‰ΩÜÂÆÉÁ°ÆÂÆûÊúâ‰∏Ä‰∫õ‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÂäüËÉΩÔºåÊØîÂ¶ÇËøô‰∏™Âú∞ÂõæÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*zWb-fbtC-CHY4mi8ZR997w.png)\n\nÊÇ®ËøòÂèØ‰ª•ÊâæÂà∞Êñ∞ÁöÑÂÜÖÂÆπÊ∂àË¥πÂú∞ÁÇπÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*y1ryR4QJI7VUvyEgqEs_Sw.png)\n\nÂú®SearchGPT‰∏≠ÔºåËøôÊñπÈù¢ÁöÑËåÉÂõ¥ÈùûÂ∏∏ÊúâÈôêÔºåÂõ†Ê≠§ËøôÂèØËÉΩÊòØGoogleÁöÑÂ∞èËÉúÂà© :) ‰∏çËøáÔºåÂÆÉ‰ªçÁÑ∂ÊúâÂä©‰∫éÂø´ÈÄüÊåáÂêëÊ≠£Á°ÆÁöÑÂú∞ÊñπÔºÅ\n\nÊÇ®ËøòÂèØ‰ª•ÈÄöËøáSearchGPTË¥≠Áâ©„ÄÇÁÑ∂ËÄåÔºåÂÆÉÁöÑÊñπÂºèÂπ∂‰∏çÊòØÊÇ®ÊâÄÊúüÊúõÁöÑ„ÄÇ‰∏çË¶ÅËÆ§‰∏∫ChatGPTÂèØ‰ª•Áõ¥Êé•ÊåáÂêëÁ°ÆÂàáÁöÑ‰∫ßÂìÅÈìæÊé•ÔºàÂÆÉÂèØ‰ª•Ôºå‰ΩÜÂÆÉÁªèÂ∏∏Âá∫Áé∞ÂπªËßâÔºâÔºõÁõ∏ÂèçÔºåÊÇ®ÂèØ‰ª•Â∞ÜÂÖ∂ËßÜ‰∏∫‰∏ÄÁßç‰∫ßÂìÅÊØîËæÉÂ∑•ÂÖ∑„ÄÇ\n\nËøôÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*9MTMHNyTY-L4WjGTZhg9BQ.png)\n\nÂÆÉÁé∞Âú®ÊåáÂêëÊàëÂñúÊ¨¢ÁöÑÊØõË°£ÂìÅÁâåÔºöÂúÜÈ¢Ü„ÄÅÁ≤óÈíàÁªá„ÄÅÂÆΩÊùæÂíåÂ§ßÂú∞Ëâ≤Ë∞ÉÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5a02uR0X07VFd4_2hXFCKg.png)\n\nËøòËÆ∞ÂæóÊàë‰πãÂâçÊèêÂà∞ÁöÑËÆ∏Â§ö‰∫∫ÂÅöÊàëÊâÄÁß∞ÁöÑ‚Äú‰∫∫Á±ªÈ™åËØÅÊêúÁ¥¢‚ÄùÂêóÔºü\n\n‰∏çÂπ∏ÁöÑÊòØÔºåSearchGPT‰ºº‰πéÊó†Ê≥ïËÆøÈóÆËÆ∏Â§öËÆ∫ÂùõÔºå‰æãÂ¶ÇReddit„ÄÇËôΩÁÑ∂ÂÆÉÂú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÂåÖÂê´‰∫ÜÂ§ßÈáèÁöÑRedditÂÜÖÂÆπÔºå‰ΩÜÂÆÉÊó†Ê≥ïËÆøÈóÆÁé∞‰ª£Á∫øÁ®ã„ÄÇËøôÊòØSearchGPTÁõÆÂâçÁöÑ‰∏ÄÂ§ßÈôêÂà∂ÔºÅ\n\n### SearchGPTÁî®‰∫éÂèçSEOÊêúÁ¥¢\n\nÂèçSEOÊñáÁ´†ÊêúÁ¥¢ÊòØ‰∏ÄÁßçÊàëÁúãÂà∞ÁöÑÊñ∞Ë∂ãÂäø„ÄÇÂÖ∂Ê†∏ÂøÉÊú¨Ë¥®‰∏äÊòØÊàë‰ª¨Â§ßËÑë‰∏≠ÁöÑ‰∏ÄÁßçËøáÊª§Âô®ÔºåËØïÂõæÊâæÂà∞Êàë‰ª¨‰πãÂâçÁßØÊûÅ‰∫íÂä®ËøáÁöÑÁΩëÁ´ôÊàñÊàë‰ª¨Áü•ÈÅìÈÄöÂ∏∏ÂèØ‰ø°ÁöÑÊù•Ê∫ê„ÄÇ‰ª•‰∏ãÊòØSearchGPTÂ¶Ç‰ΩïÂ∏ÆÂä©ÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dWUoRwDhfvwEE7K5S-u0Bg.png)\n\nËøô‰∏™Âø´ÈÄüÁöÑËøáÁ®ãÂèØ‰ª•Ê∂àÈô§‰Ω†Á†îÁ©∂‰∏≠ÁöÑËÆ∏Â§öÁóõËã¶„ÄÇ\n\n**ÂèçSEOÊêúÁ¥¢ÊäÄÂ∑ß**\n\n* ‰ΩøÁî®Ëøô‰∏™ÊèêÁ§∫ËøõË°åÈ¢ÑËøáÊª§Ôºö‚ÄúÊàëÂè™ÊÉ≥Ë¶ÅÂèØ‰ø°ÁöÑÊù•Ê∫ê„ÄÇÁªôÊàë‰∏Ä‰∏™ÊΩúÂú®Êù•Ê∫êÁöÑÂàóË°®ÔºåÊàë‰ºöÈÄâÊã©ÊàëÊÉ≥Âê¨ÁöÑÈÇ£‰∫õ„ÄÇ‚Äù\n* Âè¶‰∏ÄÁßçÊñπÊ≥ïÊòØËØ¥Ôºö‚Äú‰∏çË¶ÅËæìÂá∫‰ªª‰Ωï‰∏çÁü•ÂêçÊù•Ê∫êÁöÑÂÜÖÂÆπ„ÄÇ‚Äù\n\n### SearchGPTÁî®‰∫éSOSÊêúÁ¥¢\n\nSOSÔºàSave Our SoulsÔºâÊêúÁ¥¢ÂæàÊúâË∂£„ÄÇ‰ΩøÁî®GoogleÊó∂Ôºå‰Ω†‰ºöÊúâ‰∏ÄÁßçÊÉ≥Ë¶ÅÂáÜÁ°ÆÊèèËø∞‰Ω†ÊâÄÁªèÂéÜÁöÑ‰∫ãÊÉÖÁöÑÂÜÖÂú®Ê∏¥ÊúõÔºå‰ΩÜ‰Ω†Áü•ÈÅì‰Ω†‰∏çËÉΩËøôÊ†∑ÂÅö„ÄÇ‰ΩøÁî®SearchGPTÔºå‰Ω†ÂèØ‰ª•ÂÜôÂá∫‰∏Ä‰ªΩÂÖ≥‰∫é‰Ω†ÊÉÖÂÜµÁöÑÊÑèËØÜÊµÅÊä•ÂëäÔºåÂÆÉÂèØ‰ª•Â∞Ü‰Ω†ÁöÑÊêúÁ¥¢ËΩ¨Âåñ‰∏∫‰∏Ä‰∏™Êô∫ËÉΩÊµÅÔºåËÉΩÂ§üÊõ¥Âø´Âú∞ÊâæÂà∞ÈÇ£‰∫õÊõæÁªèÈÅáÂà∞Ëøá‰Ω†ÈóÆÈ¢òÁöÑ‰∫∫„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*107zPh98LewGZ8xuZ7aGWA.png)\n\nÁé∞Âú®ÔºåÊàëÂèØ‰ª•‰ªéÂ∫ïÈÉ®ÁöÑÊΩúÂú®Ëß£ÂÜ≥ÊñπÊ°àÂàóË°®‰∏≠Áº©Â∞èÈóÆÈ¢òËåÉÂõ¥Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ZxGSV6vDOVV2SI566x4jwg.png)\n\nËøôÂú®ËøáÂéªÂá†Âë®Â∑≤ÁªèÂ∏ÆÂä©‰∫ÜÊàëÔºåÊàëÂØπÂÆÉÁöÑË°®Áé∞ÈùûÂ∏∏Êª°ÊÑè„ÄÇ\n\n**‰ΩøÁî®SearchGPTËøõË°åSOSÊêúÁ¥¢ÁöÑÊèêÁ§∫Ôºö**\n\n* ‰ΩøÁî®Ê≠§ÊèêÁ§∫Â∞ÜÂÖ∂Áº©Â∞èÂà∞ÁúüÊ≠£ÁöÑ‰∫∫Á±ªÈóÆÈ¢òÊèèËø∞Ôºö‚ÄúÊâæÂà∞‰∏Ä‰∫õÊúâÁ±ª‰ººÈóÆÈ¢òÁöÑ‰∫∫ÁöÑÊèèËø∞ÔºåÂπ∂ÁªôÊàëËæìÂá∫‰∏Ä‰∏™Ê¶ÇËø∞‚Äù\n* Â¶ÇÊûúËæìÂá∫ÁöÑÂª∫ËÆÆËøá‰∫éÁ¨ºÁªüÔºåËØ∑‰ΩøÁî®Ê≠§ÊèêÁ§∫Ôºö‚ÄúÊàëÈúÄË¶Å‰∏éÊ≠§Âú∫ÊôØÂÆåÂÖ®ÂåπÈÖçÁöÑÈ´òÂ∫¶ÂÖ∑‰ΩìÊ°à‰æã‚Äù\n* ‰∏çË¶ÅÂÆ≥ÊÄïËøá‰∫éËØ¶ÁªÜÔºõÂ¶ÇÊûúÈúÄË¶ÅÔºåÂèØ‰ª•ÂÜôÂá†ÊÆµÊ¶ÇËø∞ÈóÆÈ¢òÁöÑÂéÜÂè≤„ÄÇSearchGPTÂèØ‰ª•Á≠õÈÄâÂô™Èü≥\n\n### SearchGPTÁî®‰∫éÂèçÁ°ÆËÆ§ÂÅèËØØÊêúÁ¥¢\n\nËøôÊòØ‰ΩøÁî®SearchGPTÁöÑ‰∏Ä‰∏™ÂÆåÁæéÊ°à‰æãÔºåÂΩì‰Ω†‰∏éÊúãÂèãÊ∑±ÂÖ•Ëæ©ËÆ∫„ÄÅÂáÜÂ§áËæ©ËÆ∫ÊàñÂè™ÊòØ‰∏ÄËà¨ÊÄßÂú∞Â≠¶‰π†‰∏Ä‰∏™Êúâ‰∫âËÆÆÁöÑËØùÈ¢òÊó∂„ÄÇËøôÁßçÊñπÊ≥ïËÆ©‰Ω†ËÉΩÂ§üÂêåÊó∂ÁúãÂà∞ÈóÆÈ¢òÁöÑÂ§ö‰∏™ÊñπÈù¢Ôºå‰ªéËÄå‰∏∫‰Ω†ÁöÑËßÇÁÇπÂ¢ûÊ∑ª‰∏Ä‰∫õÁªÜÂæÆÂ∑ÆÂà´„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5-FLP0-R1K8oW6KDSE5jLQ.png)\n\nËØ•ÂõûÂ∫îÂ±ïÁ§∫‰∫ÜÊâÄÊúâ3ÁßçËßÇÁÇπÔºåÂπ∂‰∏∫ÊØèÁßçËßÇÁÇπÊèê‰æõ‰∫Ü‰∏çÂêåÁöÑËÆ∫ÊçÆÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*u5Npy5K8FoKnOcvh0t3ZSw.png)\n\n**ÂèçÁ°ÆËÆ§ÂÅèËØØÊêúÁ¥¢ÁöÑÊäÄÂ∑ßÔºö**\n\n* Â∞ùËØï‰∏âÁßçËßÇÁÇπÁöÑÊñπÊ≥ïÔºö‚ÄúÂú®ÁΩë‰∏äÊêúÁ¥¢ÂÖ≥‰∫é\\[INSERT SUBJECT\\]ÁöÑÊ¶ÇËø∞ÂèäÂÖ∂Âà©ÂºäÔºåÊù•Ëá™Ëøô‰∏âÁßçËßÇÁÇπÔºö1\\. ÊîØÊåÅËÄÖ 2\\. ÊâπËØÑËÄÖ 3\\. ‰∏≠Á´ãËßÇÁÇπ‚Äù\n* ÂºÄÂßãÊó∂‰ΩøÁî®‰∏≠Á´ãËØ≠Ë®Ä„ÄÇ‰æãÂ¶ÇÔºå‰∏çË¶ÅÊêúÁ¥¢‚Äú‰∏∫‰ªÄ‰πàÊ∑ªÂä†Á≥ñÊØîÂ§©ÁÑ∂Á≥ñ‰∏çÂÅ•Â∫∑‚ÄùÔºåËÄåÊòØËæìÂÖ•‚ÄúÂ§©ÁÑ∂Á≥ñÂíåÊ∑ªÂä†Á≥ñÂú®ÂÅ•Â∫∑ÂΩ±Âìç‰∏äÁöÑÂ∑ÆÂºÇÂíåÁõ∏‰ººÊÄßÁöÑÊ¶ÇËø∞„ÄÇ‚ÄùSearchGPTÂú®ËøôÈáåÂæàÊúâÂ∏ÆÂä©ÔºåÂõ†‰∏∫ÂÆÉÂèØ‰ª•Ê±áÊÄªÂ§öÁßçÊù•Ê∫êÁöÑËßÇÁÇπ\n* Á°Æ‰øù‰ΩøÁî®Â§ö‰∏™Êù•Ê∫êÔºàÂõ†‰∏∫ÊâÄÊúâÊù•Ê∫êËá≥Â∞ëÈÉΩÊúâ‰∏Ä‰∫õÂÅèËßÅÔºåÂõ†Ê≠§ËøôÊúâÂä©‰∫éÂú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÂπ≥Ë°°Ëøô‰∫õÂÅèËßÅÔºâ\n\n## Prompting and General Tips for SearchGPT\n\nÁé∞Âú®Êàë‰ª¨Â∑≤ÁªèÊ∑±ÂÖ•Êé¢ËÆ®‰∫Ü‰ΩøÁî® SearchGPT ÂèØ‰ª•ËøõË°åÁöÑÊêúÁ¥¢Á±ªÂûãÔºå‰ª•‰∏ãÊòØÊàëÊé®ËçêÁöÑÊõ¥Â§öÈÄöÁî®ÊèêÁ§∫ÂíåÊèêÁ§∫Â∑•Á®ãÊäÄÂ∑ß„ÄÇËÆ∏Â§öËøô‰∫õÂÜÖÂÆπ‰πãÂâçÂ∑≤ÁªèÊèêÂà∞ËøáÔºå‰ΩÜËøôÊòØ‰∏Ä‰∏™ÊúâÁî®ÁöÑÊÄªÁªì„ÄÇ\n\n### SearchGPT ÁöÑÊ≥®ÊÑè‰∫ãÈ°π\n\n* Ë¶ÅÊ±ÇÂÆÉ‰ΩøÁî®Â§ö‰∏™Êù•Ê∫ê ‚Äî ‚ÄúËØ∑Ê£ÄÊü•ÂêÑÁßçÊù•Ê∫ê‚Äù\n* ÂàõÂª∫‰∏Ä‰∏™‰∏é SearchGPT ÁöÑÂºïÂØºË∑ØÂæÑ ‚Äî ‚ÄúÂú®‰Ω†ÂõûÂ∫î‰πãÂêéÂàóÂá∫‰∏Ä‰∫õÊΩúÂú®ÁöÑÂêéÁª≠ÈóÆÈ¢ò‚Äù\n* Âú®‰Ω†ÁöÑËØ∑Ê±Ç‰∏≠‰ΩøÁî®ÂÖ∑‰ΩìÊó•Êúü ‚Äî ‚ÄúÊà™Ëá≥‰ªäÂ§©‚Äù„ÄÅ‚ÄúÊà™Ëá≥ 2024 Âπ¥‚ÄùÊàñ‚ÄúÂú® 1983 Âπ¥‚Äù\n* Â¶ÇÊûú SearchGPT Ê≤°ÊúâÊèê‰æõ‰ªª‰ΩïÊù•Ê∫êÔºåÊâìÂºÄ‰∏Ä‰∏™Êñ∞ËÅäÂ§©Âπ∂Âú®‰Ω†ÁöÑÊèêÁ§∫Êú´Â∞æÊèíÂÖ•‚ÄúÊêúÁ¥¢ÁΩëÁªú‚Äù\n* Âú®‰Ω†‰∫§ÊµÅË∂ÖËøá 20 Êù°Ê∂àÊÅØÂêéÊâìÂºÄ‰∏Ä‰∏™Êñ∞ËÅäÂ§©Ôºå‰Ω†‰∏çÂ∏åÊúõÂÆÉÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÂèòÂæóÂ§™Êª°\n* Ë¶ÅËØ¶ÁªÜ ‚Äî GPT ÂØπ‰Ω†ÁöÑËØ∑Ê±ÇÊúâÊõ¥Â§ö‰∏ä‰∏ãÊñáÊó∂ÔºåÊïàÊûú‰ºöÊõ¥Â•Ω\n\n### SearchGPT ÁöÑÁ¶ÅÂøå\n\n* ‰∏çË¶ÅÊ®°Á≥äÔºà‰æãÂ¶ÇÔºå‚Äú2024 Âπ¥ÁöÑÊñ∞‰ΩèÊàøÂç±Êú∫‚ÄùÊàñ‚Äú2024 Âπ¥ÁöÑÈÖ∑ÁÇ´Ë∑ëËΩ¶‚ÄùÔºâ„ÄÇÂèØ‰ª•Áî®Ëøô‰∏™ÊèêÁ§∫Êù•Ëß£ÂÜ≥Ôºö‚ÄúÈóÆÊàë‰∏Ä‰∫õÂÖ≥‰∫éÊàëÁöÑËØ∑Ê±ÇÁöÑÊæÑÊ∏ÖÈóÆÈ¢òÔºåÊàë‰ºöÂú®‰Ω†ÂºÄÂßã‰πãÂâçÂõûÁ≠î‚Äù\n* ‰∏çË¶ÅÊú™ÁªèÊü•ËØÅÂ∞±ËÆ§‰∏∫Êüê‰∫ãÊòØÁªùÂØπÊ≠£Á°ÆÁöÑÔºõÂπªËßâ‰ªçÁÑ∂ÊòØÂèØËÉΩÁöÑ„ÄÇ‰Ω†ÂèØ‰ª•ÈöèÊó∂ËØ¥‚ÄúÁî®Âè¶‰∏Ä‰∏™‰∏çÂêåÁöÑÊù•Ê∫êÈ™åËØÅÊ≠§‰ø°ÊÅØ‚Äù\n* ‰∏çË¶ÅË¶ÅÊ±ÇÂÖ∑‰ΩìÁöÑÊÑèËßÅÔºõÂÆÉ‰ºöÂëäËØâ‰Ω†‰Ω†ÊÉ≥Âê¨ÁöÑÂÜÖÂÆπ„ÄÇËØ∑Á°Æ‰øù‰Ω†ÁöÑÊèêÁ§∫ÊòØ‰∏ÄËà¨ÊÄßÂíåÂºÄÊîæÁöÑ\n* ‰∏çË¶ÅÂÆ≥ÊÄïÂØπ SearchGPT ÊèêÂá∫‚ÄúËøáÂ§ö‚ÄùÁöÑË¶ÅÊ±Ç„ÄÇÂÆÉÂÖ∑ÊúâÁöÑÊüê‰∫õËÉΩÂäõÊàëÁîöËá≥ËøòÊ≤°ÊúâÂèëÁé∞ÔºåËÄåÂ§ßÈáèÊèêÈóÆÊ≠£ÊòØÊè≠Á§∫ÂÆÉ‰ª¨ÁöÑÊñπÂºè\n\nÂ∞±Ëøô‰∫õÔºåÊúãÂèã‰ª¨„ÄÇÊàëÂ∏åÊúõËøôËÉΩËØ¥Êúç‰Ω†Ëá≥Â∞ëÂ∞ùËØïÂ∞Ü SearchGPT Êï¥ÂêàÂà∞‰Ω†ÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇÂÆÉÂú®ËÆ∏Â§öÊñπÈù¢ÊîπÂèò‰∫ÜÊàëÁöÑÊó•Â∏∏ÁîüÊ¥ªÔºåÊàëÊï¢ÊâìËµåÂÆÉ‰πü‰ºöÊîπÂèò‰Ω†ÁöÑÁîüÊ¥ª„ÄÇ\n\nÊÑüË∞¢ÈòÖËØªÔºÅ\n\n\\-Jordan\n\n"},{"lang":"zh","group":"blog","slug":"blog/smollm2-very-good-alternatives-to-qwen2-5-and-llama-3-2-463a200d2f3b","frontmatter":{"title":"SmolLM2ÔºöQwen2.5 Âíå Llama 3.2 ÁöÑÊúÄ‰Ω≥Êõø‰ª£ÂìÅ","meta_title":"SmolLM2ÔºöQwen2.5 Âíå Llama 3.2 ÁöÑÊúÄ‰Ω≥Êõø‰ª£ÂìÅ","description":"ËÄå‰∏îÊòØÂÖ®ÂºÄÁöÑÔºÅ","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*Y3_lsNsFKybrOi14.png","categories":["Technology","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["SmolLM2","parameters","pre-training","MobileLLM","reproducibility"],"draft":false,"slug":"blog/smollm2-very-good-alternatives-to-qwen2-5-and-llama-3-2-463a200d2f3b"},"content":"\n\n\n## ËÄå‰∏îÂÆÉÊòØÂÆåÂÖ®ÂºÄÊîæÁöÑÔºÅ\n\nHugging Face Âä†Â§ß‰∫ÜÂØπ SmolLM ËÆ°ÂàíÁöÑÊäïÂÖ•„ÄÇ\n\n‰ªñ‰ª¨ÂèëÂ∏É‰∫Ü SmolLM2Ôºö1\\.7B„ÄÅ360M Âíå 135M Ê®°ÂûãÔºåËÆ≠ÁªÉ‰∫é 11T ‰ª§ÁâåÔºàÁõ∏ÊØî SmolLM ÁöÑ 1TÔºâ„ÄÇ‰ªñ‰ª¨ÂèëÂ∏É‰∫ÜÂü∫Á°ÄÁâàÂíåÊåáÂØºÁâàÔºö\n\n* Hugging Face Collection: [SmolLM2](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9) (Apache 2\\.0 ËÆ∏ÂèØËØÅ)\n\n‰ªñ‰ª¨‰ΩøÁî®‰∫ÜÊñ∞ÁöÑÊï∞ÊçÆÈõÜËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåËÆ°ÂàíÂæàÂø´ÂèëÂ∏É„ÄÇ‰∏∫‰∫ÜÂà∂‰ΩúÊåáÂØºÁâàÔºå‰ªñ‰ª¨‰ΩøÁî®‰∫ÜÁ±ª‰ºº‰∫éËÆ≠ÁªÉ Zephyr ÁöÑÈÖçÊñπÔºàSFT\\+DPO Âú® ultrafeedback ‰∏äÔºâ„ÄÇ\n\nÁúãËµ∑Êù• SmolLM2 ÁöÑË°®Áé∞ÈùûÂ∏∏Âá∫Ëâ≤Ôºö\n\n\n\nËØ∑Ê≥®ÊÑèÔºåHugging Face ÂÆåÂÖ®ÂÖ¨ÂºÄ‰∫ÜÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÂíå‰ªñ‰ª¨Áî®Êù•Èò≤Ê≠¢Êï∞ÊçÆÊ±°ÊüìÁöÑÈÖçÊñπ„ÄÇÊç¢Âè•ËØùËØ¥Ôºå‰ªñ‰ª¨ÂèëÂ∏ÉÁöÑËØÑ‰º∞ÁªìÊûúÂèØËÉΩÊòØÂáÜÁ°Æ‰∏îÂÆåÂÖ®ÂèØÈáçÂ§çÁöÑ„ÄÇ\n\nHugging Face ‰ΩøÁî®‰∫ÜËá™Â∑±ÁöÑÊ°ÜÊû∂ËøõË°åÈ¢ÑËÆ≠ÁªÉÔºå[Nanotron](https://github.com/huggingface/nanotron)„ÄÇÊàë‰ªéÊú™ÂÜôËøáÂÖ≥‰∫é Nanotron ÁöÑÊñáÁ´†Ôºå‰ΩÜÊàëËÆ§‰∏∫ËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÊúâË∂£ÁöÑÈ°πÁõÆÔºåÂÄºÂæóÊõ¥Âπø‰∏∫‰∫∫Áü•ÔºåÁâπÂà´ÊòØÂ¶ÇÊûú‰Ω†ÊúâÂÖ¥Ë∂£‰∫ÜËß£È¢ÑËÆ≠ÁªÉÊòØÂ¶Ç‰ΩïËøõË°åÁöÑ„ÄÇÊàë‰ºöÂ∞ΩÈáèÊâæÊó∂Èó¥Âú® 2025 Âπ¥‰πãÂâçÂèëÂ∏É‰∏ÄÁØáËß£Èáä Nanotron ÁöÑÊñáÁ´†ÔºÅ\n\nMeta ËøòÂèëÂ∏É‰∫Ü‰∏ÄÁ≥ªÂàóÂ∞èÂûãÊ®°ÂûãÔºåMobileLLMÔºö\n\n* Hugging Face Collection: [MobileLLM](https://huggingface.co/collections/facebook/mobilellm-6722be18cb86c20ebe113e95) (CC\\-BY\\-NC)\n\nËøôÊòØ‰∏Ä‰∏™Êñ∞ÂèëÂ∏ÉÁöÑÈ°πÁõÆÔºå‰ΩÜËØ∑Ê≥®ÊÑèÔºåËøô‰∫õÊ®°ÂûãÂÆûÈôÖ‰∏äÁõ∏ÂΩìÊóß„ÄÇÂÆÉ‰ª¨ÊòØ‰∏∫ 2024 Âπ¥ 2 ÊúàÂèëÂ∏ÉÁöÑËøôÈ°πÂ∑•‰ΩúËÆ≠ÁªÉÁöÑÔºö\n\n[MobileLLM: Optimizing Sub\\-billion Parameter Language Models for On\\-Device Use Cases](https://arxiv.org/abs/2402.14905)\n\nÈÄöËøáÊàëÁöÑÊñ∞‰π¶‚ÄúLLMs on a Budget‚ÄùÔºå‰∫ÜËß£‰ΩøÁî®ÂíåÂæÆË∞ÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊâÄÈúÄÁöÑ‰∏ÄÂàáÔºö\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-6-best-llm-tools-to-run-models-locally-eedd0f7c2bbd","frontmatter":{"title":"6 ÁßçÊúÄ‰Ω≥Êú¨Âú∞ËøêË°åÊ®°ÂûãÁöÑ LLM Â∑•ÂÖ∑","meta_title":"6 ÁßçÊúÄ‰Ω≥Êú¨Âú∞ËøêË°åÊ®°ÂûãÁöÑ LLM Â∑•ÂÖ∑","description":"ËøêË°åÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)Ôºà‰æãÂ¶Ç ChatGPT Âíå ClaudeÔºâÈÄöÂ∏∏Ê∂âÂèäÂ∞ÜÊï∞ÊçÆÂèëÈÄÅÂà∞Áî± OpenAI ÂíåÂÖ∂‰ªñ AI Ê®°ÂûãÁÆ°ÁêÜÁöÑÊúçÂä°Âô®‚Ä¶‚Ä¶","date":"2024-10-24T17:47:43.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*2MB6-INUUGLR0NR_iOACIg.jpeg","categories":["Technology","Programming","Health"],"author":"Rifx.Online","tags":["LLM","local","deployment","customization","telehealth"],"draft":false,"slug":"blog/the-6-best-llm-tools-to-run-models-locally-eedd0f7c2bbd"},"content":"\n\n\n\n\nËøêË°åÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ¶Ç [ChatGPT](https://openai.com/chatgpt/mac/) Âíå [Claude](https://claude.ai/) ÈÄöÂ∏∏Ê∂âÂèäÂ∞ÜÊï∞ÊçÆÂèëÈÄÅÂà∞Áî± [OpenAI](https://openai.com/) ÂíåÂÖ∂‰ªñ AI Ê®°ÂûãÊèê‰æõÂïÜÁÆ°ÁêÜÁöÑÊúçÂä°Âô®„ÄÇËôΩÁÑ∂Ëøô‰∫õÊúçÂä°ÊòØÂÆâÂÖ®ÁöÑÔºå‰ΩÜ‰∏Ä‰∫õ‰ºÅ‰∏öÊõ¥ÂÄæÂêë‰∫éÂ∞ÜÂÖ∂Êï∞ÊçÆÂÆåÂÖ®Á¶ªÁ∫øÔºå‰ª•Ëé∑ÂæóÊõ¥È´òÁöÑÈöêÁßÅ‰øùÊä§„ÄÇ\n\nÊú¨ÊñáÂ∞Ü‰ªãÁªçÂºÄÂèë‰∫∫ÂëòÂèØ‰ª•‰ΩøÁî®ÁöÑÂÖ≠Ê¨æÂ∑•ÂÖ∑Ôºå‰ª•‰æøÂú®Êú¨Âú∞ËøêË°åÂíåÊµãËØï LLMÔºåÁ°Æ‰øù‰ªñ‰ª¨ÁöÑÊï∞ÊçÆÊ∞∏Ëøú‰∏ç‰ºöÁ¶ªÂºÄ‰ªñ‰ª¨ÁöÑËÆæÂ§áÔºåËøôÁ±ª‰ºº‰∫é [Á´ØÂà∞Á´ØÂä†ÂØÜ](https://getstream.io/blog/end-to-end-encryption/) ‰øùÊä§ÈöêÁßÅÁöÑÊñπÂºè„ÄÇ\n\n## ‰∏∫‰ªÄ‰πà‰ΩøÁî®Êú¨Âú∞ LLMÔºü\n\nÂÉè [LM Studio](https://lmstudio.ai/) ËøôÊ†∑ÁöÑÂ∑•ÂÖ∑Âú®Áî®Êà∑‰ΩøÁî®ÂÆÉÊù•ËøêË°åÊú¨Âú∞ LLM Êó∂Ôºå‰∏ç‰ºöÊî∂ÈõÜÁî®Êà∑Êï∞ÊçÆÊàñË∑üË∏™Áî®Êà∑ÁöÑË°å‰∏∫„ÄÇÂÆÉÂÖÅËÆ∏ÊâÄÊúâËÅäÂ§©Êï∞ÊçÆ‰øùÁïôÂú®Êú¨Âú∞ËÆ°ÁÆóÊú∫‰∏äÔºåËÄå‰∏ç‰∏é AI/ML ÊúçÂä°Âô®ÂÖ±‰∫´„ÄÇ\n\n* **ÈöêÁßÅ**ÔºöÊÇ®ÂèØ‰ª•‰ª•Â§öËΩÆÁöÑÊñπÂºèÊèêÁ§∫Êú¨Âú∞ LLMÔºåËÄå‰∏ç‰ºöËÆ©ÊÇ®ÁöÑÊèêÁ§∫Êï∞ÊçÆÁ¶ªÂºÄÊú¨Âú∞‰∏ªÊú∫„ÄÇ\n* **Ëá™ÂÆö‰πâÈÄâÈ°π**ÔºöÊú¨Âú∞ LLM Êèê‰æõ CPU Á∫øÁ®ã„ÄÅÊ∏©Â∫¶„ÄÅ‰∏ä‰∏ãÊñáÈïøÂ∫¶„ÄÅGPU ËÆæÁΩÆÁ≠âÈ´òÁ∫ßÈÖçÁΩÆÈÄâÈ°π„ÄÇËøôÁ±ª‰ºº‰∫é OpenAI ÁöÑÊ∏∏‰πêÂú∫„ÄÇ\n* **ÊîØÊåÅÂíåÂÆâÂÖ®ÊÄß**ÔºöÂÆÉ‰ª¨Êèê‰æõ‰∏é OpenAI Êàñ Claude Áõ∏‰ººÁöÑÊîØÊåÅÂíåÂÆâÂÖ®ÊÄß„ÄÇ\n* **ËÆ¢ÈòÖÂíåË¥πÁî®**ÔºöËøô‰∫õÂ∑•ÂÖ∑ÂÖçË¥π‰ΩøÁî®ÔºåÂπ∂‰∏î‰∏çÈúÄË¶ÅÊØèÊúàËÆ¢ÈòÖ„ÄÇÂØπ‰∫éÂÉè OpenAI ËøôÊ†∑ÁöÑ‰∫ëÊúçÂä°ÔºåÊØè‰∏™ API ËØ∑Ê±ÇÈÉΩÈúÄË¶Å‰ªòË¥π„ÄÇÊú¨Âú∞ LLM ÊúâÂä©‰∫éËäÇÁúÅË¥πÁî®ÔºåÂõ†‰∏∫Ê≤°ÊúâÊØèÊúàËÆ¢ÈòÖ„ÄÇ\n* **Á¶ªÁ∫øÊîØÊåÅ**ÔºöÊÇ®ÂèØ‰ª•Âú®Á¶ªÁ∫øÊó∂Âä†ËΩΩÂíåËøûÊé•Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n* **ËøûÊé•ÊÄß**ÔºöÊúâÊó∂ÔºåËøûÊé•Âà∞ÂÉè OpenAI ËøôÊ†∑ÁöÑ‰∫ëÊúçÂä°ÂèØËÉΩ‰ºöÂØºËá¥‰ø°Âè∑ÂíåËøûÊé•‰∏çËâØ„ÄÇ\n\n## ÂÖ≠Â§ßÂÖçË¥πÊú¨Âú∞ LLM Â∑•ÂÖ∑\n\nÊ†πÊçÆÊÇ®ÁöÑÂÖ∑‰Ωì‰ΩøÁî®Ê°à‰æãÔºåÊÇ®ÂèØ‰ª•ÈÄâÊã©Âá†ÁßçÁ¶ªÁ∫ø LLM Â∫îÁî®Á®ãÂ∫è„ÄÇËøô‰∫õÂ∑•ÂÖ∑‰∏≠Êúâ‰∏Ä‰∫õÂÆåÂÖ®ÂÖçË¥π‰æõ‰∏™‰∫∫ÂíåÂïÜ‰∏ö‰ΩøÁî®„ÄÇÂÖ∂‰ªñÂ∑•ÂÖ∑ÂèØËÉΩÈúÄË¶ÅÊÇ®ÂèëÈÄÅËØ∑Ê±Ç‰ª•Áî®‰∫éÂïÜ‰∏öÁî®ÈÄî„ÄÇÂØπ‰∫é Mac„ÄÅWindows Âíå LinuxÔºåÊúâÂ§öÁßçÊú¨Âú∞ LLM Â∑•ÂÖ∑ÂèØ‰æõÈÄâÊã©„ÄÇ‰ª•‰∏ãÊòØÊÇ®ÂèØ‰ª•ÈÄâÊã©ÁöÑÂÖ≠‰∏™ÊúÄ‰Ω≥Â∑•ÂÖ∑„ÄÇ\n\n## 1. LM Studio\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*svbQPZKu08of7Kv6)\n\n[LM Studio](https://lmstudio.ai/) ÂèØ‰ª•ËøêË°å‰ªª‰ΩïÊ†ºÂºè‰∏∫ `gguf` ÁöÑÊ®°ÂûãÊñá‰ª∂„ÄÇÂÆÉÊîØÊåÅÊù•Ëá™Ê®°ÂûãÊèê‰æõÂïÜÁöÑ `gguf` Êñá‰ª∂ÔºåÂ¶Ç [Llama 3.1](https://llama.meta.com/)„ÄÅ[Phi 3](https://huggingface.co/docs/transformers/main/en/model_doc/phi3)„ÄÅ[Mistral](https://mistral.ai/) Âíå [Gemma](https://ai.google.dev/gemma)„ÄÇË¶Å‰ΩøÁî® LM StudioÔºåËØ∑ËÆøÈóÆ‰∏äËø∞ÈìæÊé•Âπ∂‰∏ãËΩΩÈÄÇÂêàÊÇ®Êú∫Âô®ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇÂêØÂä® LM Studio ÂêéÔºå‰∏ªÈ°µ‰ºöÂ±ïÁ§∫ÂèØ‰∏ãËΩΩÂíåÊµãËØïÁöÑÈ°∂Á∫ß LLM„ÄÇËøòÊúâ‰∏Ä‰∏™ÊêúÁ¥¢Ê†èÔºåÂèØ‰ª•Á≠õÈÄâÂπ∂‰∏ãËΩΩÊù•Ëá™‰∏çÂêå AI Êèê‰æõÂïÜÁöÑÁâπÂÆöÊ®°Âûã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*sbS3VqiLgDsftgs2)\n\n‰ªéÁâπÂÆöÂÖ¨Âè∏ÁöÑÊ®°Âûã‰∏≠ÊêúÁ¥¢‰ºöÊòæÁ§∫Â§ö‰∏™Ê®°ÂûãÔºåËåÉÂõ¥‰ªéÂ∞èÂûãÂà∞Â§ßÂûã [quantization](https://huggingface.co/docs/optimum/en/concept_guides/quantization)„ÄÇÊ†πÊçÆÊÇ®ÁöÑÊú∫Âô®ÔºåLM Studio ‰ºö‰ΩøÁî®ÂÖºÂÆπÊÄßÁåúÊµãÊù•Á™ÅÂá∫ÊòæÁ§∫ÈÄÇÂêàËØ•Êú∫Âô®ÊàñÂπ≥Âè∞ÁöÑÊ®°Âûã„ÄÇ\n\n## LM Studio ÁöÑÂÖ≥ÈîÆÁâπÊÄß\n\nLM Studio Êèê‰æõ‰∏é ChatGPT Áõ∏‰ººÁöÑÂäüËÉΩÂíåÁâπÊÄß„ÄÇÂÆÉÂÖ∑ÊúâÂ§ö‰∏™ÂäüËÉΩ„ÄÇ‰ª•‰∏ãÊòØ LM Studio ÁöÑÂÖ≥ÈîÆÁâπÊÄß„ÄÇ\n\n* **Ê®°ÂûãÂèÇÊï∞Ëá™ÂÆö‰πâ**ÔºöËøôÂÖÅËÆ∏ÊÇ®Ë∞ÉÊï¥Ê∏©Â∫¶„ÄÅÊúÄÂ§ß‰ª§Áâå„ÄÅÈ¢ëÁéáÊÉ©ÁΩöÁ≠â„ÄÇ\n* **ËÅäÂ§©ÂéÜÂè≤**ÔºöÂÖÅËÆ∏ÊÇ®‰øùÂ≠òÊèêÁ§∫‰ª•‰æõÂêéÁª≠‰ΩøÁî®„ÄÇ\n* **ÂèÇÊï∞ÂíåÁî®Êà∑ÁïåÈù¢ÊèêÁ§∫**ÔºöÊÇ®ÂèØ‰ª•Â∞ÜÈº†Ê†áÊÇ¨ÂÅúÂú®‰ø°ÊÅØÊåâÈíÆ‰∏ä‰ª•Êü•ÊâæÊ®°ÂûãÂèÇÊï∞ÂíåÊúØËØ≠„ÄÇ\n* **Ë∑®Âπ≥Âè∞**ÔºöLM Studio ÂèØÂú® Linux„ÄÅMac Âíå Windows Êìç‰ΩúÁ≥ªÁªü‰∏ä‰ΩøÁî®„ÄÇ\n* **Êú∫Âô®ËßÑÊ†ºÊ£ÄÊü•**ÔºöLM Studio Ê£ÄÊü•ËÆ°ÁÆóÊú∫ËßÑÊ†ºÔºåÂ¶Ç GPU ÂíåÂÜÖÂ≠òÔºåÂπ∂Êä•ÂëäÂÖºÂÆπÁöÑÊ®°Âûã„ÄÇËøôÂèØ‰ª•Èò≤Ê≠¢‰∏ãËΩΩÂèØËÉΩÂú®ÁâπÂÆöÊú∫Âô®‰∏äÊó†Ê≥ïËøêË°åÁöÑÊ®°Âûã„ÄÇ\n* **AI ËÅäÂ§©ÂíåÊ∏∏‰πêÂú∫**Ôºö‰ª•Â§öËΩÆËÅäÂ§©Ê†ºÂºè‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãËøõË°åÂØπËØùÔºåÂπ∂ÈÄöËøáÂêåÊó∂Âä†ËΩΩÂ§ö‰∏™ LLM ËøõË°åÂÆûÈ™å„ÄÇ\n* **ÂºÄÂèëËÄÖÊú¨Âú∞Êé®ÁêÜÊúçÂä°Âô®**ÔºöÂÖÅËÆ∏ÂºÄÂèëËÄÖËÆæÁΩÆ‰∏Ä‰∏™Á±ª‰ºº‰∫é OpenAI API ÁöÑÊú¨Âú∞ HTTP ÊúçÂä°Âô®„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*9bHmRiOSf6gm-u3P)\n\nÊú¨Âú∞ÊúçÂä°Âô®Êèê‰æõÁ§∫‰æã Curl Âíå Python ÂÆ¢Êà∑Á´ØËØ∑Ê±Ç„ÄÇÊ≠§ÂäüËÉΩÊúâÂä©‰∫é‰ΩøÁî® LM Studio ÊûÑÂª∫ AI Â∫îÁî®Á®ãÂ∫èÔºå‰ª•ËÆøÈóÆÁâπÂÆöÁöÑ LLM„ÄÇ\n\n```python\n## Example: reuse your existing OpenAI setup\nfrom openai import OpenAI\n\n## Point to the local server\nclient = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n\ncompletion = client.chat.completions.create(\n  model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n  ],\n  temperature=0.7,\n)\n\nprint(completion.choices[0].message)\n```\nÈÄöËøá‰∏äËø∞Á§∫‰æã Python ‰ª£Á†ÅÔºåÊÇ®ÂèØ‰ª•ÈáçÁî®Áé∞ÊúâÁöÑ OpenAI ÈÖçÁΩÆÔºåÂπ∂Â∞ÜÂü∫Êú¨ URL ‰øÆÊîπ‰∏∫ÊåáÂêëÊÇ®ÁöÑÊú¨Âú∞‰∏ªÊú∫„ÄÇ\n\n* **OpenAI ÁöÑ Python Â∫ìÂØºÂÖ•**ÔºöLM Studio ÂÖÅËÆ∏ÂºÄÂèëËÄÖÂØºÂÖ• OpenAI Python Â∫ìÔºåÂπ∂Â∞ÜÂü∫Êú¨ URL ÊåáÂêëÊú¨Âú∞ÊúçÂä°Âô®ÔºàlocalhostÔºâ„ÄÇ\n* **Â§öÊ®°Âûã‰ºöËØù**Ôºö‰ΩøÁî®Âçï‰∏™ÊèêÁ§∫Âπ∂ÈÄâÊã©Â§ö‰∏™Ê®°ÂûãËøõË°åËØÑ‰º∞„ÄÇ\n\n## ‰ΩøÁî® LM Studio ÁöÑÂ•ΩÂ§Ñ\n\nËØ•Â∑•ÂÖ∑ÂèØ‰æõ‰∏™‰∫∫ÂÖçË¥π‰ΩøÁî®ÔºåÂÖÅËÆ∏ÂºÄÂèëËÄÖÈÄöËøáÂ∫îÁî®ÂÜÖËÅäÂ§©Áî®Êà∑ÁïåÈù¢ÂíåÊ∏∏‰πêÂú∫ËøêË°å LLM„ÄÇÂÆÉÊèê‰æõ‰∫Ü‰∏Ä‰∏™Âçé‰∏Ω‰∏îÊòì‰∫é‰ΩøÁî®ÁöÑÁïåÈù¢ÔºåÂ∏¶ÊúâËøáÊª§Âô®ÔºåÂπ∂ÊîØÊåÅËøûÊé•Âà∞ OpenAI ÁöÑ Python Â∫ìÔºåÊó†ÈúÄ API ÂØÜÈí•„ÄÇÂÖ¨Âè∏Âíå‰ºÅ‰∏öÂèØ‰ª•Ê†πÊçÆË¶ÅÊ±Ç‰ΩøÁî® LM Studio„ÄÇÁÑ∂ËÄåÔºåÂÆÉÈúÄË¶Å M1/M2/M3 Mac ÊàñÊõ¥È´òÁâàÊú¨ÔºåÊàñÂÖ∑ÊúâÊîØÊåÅ [AVX2](https://edc.intel.com/content/www/us/en/design/ipla/software-development-platforms/client/platforms/alder-lake-desktop/12th-generation-intel-core-processors-datasheet-volume-1-of-2/009/intel-advanced-vector-extensions-2-intel-avx2/) ÁöÑÂ§ÑÁêÜÂô®ÁöÑ Windows PC„ÄÇIntel Âíå [AMD](https://www.amd.com/en/support/download/drivers.html) Áî®Êà∑‰ªÖÈôê‰∫é‰ΩøÁî® [v0.2.31](https://lmstudio.ai/) ‰∏≠ÁöÑ Vulkan Êé®ÁêÜÂºïÊìé„ÄÇ\n\n## 2. Jan\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*7YeH_48iFYB4lDRu)\n\nÂ∞Ü [Jan](https://jan.ai/) ÁêÜËß£‰∏∫‰∏Ä‰∏™ËÆæËÆ°Áî®‰∫éÁ¶ªÁ∫øÊìç‰ΩúÁöÑÂºÄÊ∫êÁâàÊú¨ÁöÑ ChatGPT„ÄÇÂÆÉÁî±‰∏Ä‰∏™Áî®Êà∑Á§æÂå∫ÊûÑÂª∫ÔºåÁßâÊåÅÁî®Êà∑Êã•ÊúâÁöÑÁêÜÂøµ„ÄÇJan ÂÖÅËÆ∏ÊÇ®Âú®ËÆæÂ§á‰∏äËøêË°åÊµÅË°åÁöÑÊ®°ÂûãÔºåÂ¶Ç [Mistral](https://huggingface.co/models?other=mistral) Êàñ [Llama](https://huggingface.co/models?other=llama)ÔºåËÄåÊó†ÈúÄËøûÊé•‰∫íËÅîÁΩë„ÄÇ‰ΩøÁî® JanÔºåÊÇ®ÂèØ‰ª•ËÆøÈóÆËøúÁ®ã APIÔºåÂ¶Ç OpenAI Âíå [Groq](https://groq.com/)„ÄÇ\n\n## Jan ÁöÑ‰∏ªË¶ÅÁâπÁÇπ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ufyOE6QkcHw8X5U7)\n\nJan ÊòØ‰∏ÄÊ¨æÁîµÂ≠êÂ∫îÁî®Á®ãÂ∫èÔºåÂÖ∂ÂäüËÉΩÁ±ª‰ºº‰∫é LM Studio„ÄÇÂÆÉÈÄöËøáÂ∞ÜÊ∂àË¥πËÄÖËÆæÂ§áËΩ¨Âèò‰∏∫ AI ËÆ°ÁÆóÊú∫Ôºå‰Ωø AI ÂèòÂæóÂºÄÊîæÂíåÂèØËÆøÈóÆ„ÄÇÁî±‰∫éËøôÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÈ°πÁõÆÔºåÂºÄÂèëËÄÖÂèØ‰ª•‰∏∫ÂÖ∂Ë¥°ÁåÆ‰ª£Á†ÅÂπ∂Êâ©Â±ïÂÖ∂ÂäüËÉΩ„ÄÇ‰ª•‰∏ãÊòØ Jan ÁöÑ‰∏ªË¶ÅÁâπÁÇπ„ÄÇ\n\n* **Êú¨Âú∞**ÔºöÊÇ®ÂèØ‰ª•Âú®ËÆæÂ§á‰∏äËøêË°åÊÇ®ÂñúÊ¨¢ÁöÑ AI Ê®°ÂûãÔºåËÄåÊó†ÈúÄÂ∞ÜÂÖ∂ËøûÊé•Âà∞‰∫íËÅîÁΩë„ÄÇ\n* **Âç≥Áî®Ê®°Âûã**Ôºö‰∏ãËΩΩ Jan ÂêéÔºåÊÇ®Â∞ÜËé∑Âæó‰∏ÄÁªÑÂ∑≤ÂÆâË£ÖÁöÑÊ®°Âûã‰ª•‰æõÂºÄÂßã‰ΩøÁî®„ÄÇ‰πüÂèØ‰ª•ÊêúÁ¥¢ÁâπÂÆöÊ®°Âûã„ÄÇ\n* **Ê®°ÂûãÂØºÂÖ•**ÔºöÊîØÊåÅ‰ªé Hugging Face Á≠âÊù•Ê∫êÂØºÂÖ•Ê®°Âûã„ÄÇ\n* **ÂÖçË¥π„ÄÅË∑®Âπ≥Âè∞ÂíåÂºÄÊ∫ê**ÔºöJan ÂÆåÂÖ®ÂÖçË¥πÔºåÂºÄÊ∫êÔºåÂπ∂ÂèØÂú® Mac„ÄÅWindows Âíå Linux ‰∏äËøêË°å„ÄÇ\n* **Ëá™ÂÆö‰πâÊé®ÁêÜÂèÇÊï∞**ÔºöË∞ÉÊï¥Ê®°ÂûãÂèÇÊï∞ÔºåÂ¶ÇÊúÄÂ§ß‰ª§Áâå„ÄÅÊ∏©Â∫¶„ÄÅÊµÅ„ÄÅÈ¢ëÁéáÊÉ©ÁΩöÁ≠â„ÄÇÊâÄÊúâÂÅèÂ•ΩËÆæÁΩÆ„ÄÅÊ®°Âûã‰ΩøÁî®ÂíåÈÖçÁΩÆÈÉΩ‰øùÁïôÂú®ÊÇ®ÁöÑËÆ°ÁÆóÊú∫‰∏ä„ÄÇ\n* **Êâ©Â±ï**ÔºöJan ÊîØÊåÅ [TensortRT](https://github.com/NVIDIA/TensorRT) Âíå [Inference Nitro](https://huggingface.co/jan-hq/nitro-v1.2-e3) Á≠âÊâ©Â±ïÔºå‰ª•Ëá™ÂÆö‰πâÂíåÂ¢ûÂº∫ÊÇ®ÁöÑ AI Ê®°Âûã„ÄÇ\n\n## ‰ΩøÁî® Jan ÁöÑÂ•ΩÂ§Ñ\n\nJan Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âπ≤ÂáÄÁÆÄÂçïÁöÑÁïåÈù¢Êù•‰∏é LLM ‰∫íÂä®ÔºåÂπ∂‰∏îÂ∞ÜÊâÄÊúâÊï∞ÊçÆÂíåÂ§ÑÁêÜ‰ø°ÊÅØ‰øùÂ≠òÂú®Êú¨Âú∞„ÄÇÂÆÉÂ∑≤Áªè‰∏∫ÊÇ®ÂÆâË£Ö‰∫ÜË∂ÖËøá‰∏ÉÂçÅ‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰æõÊÇ®‰ΩøÁî®„ÄÇËøô‰∫õÁé∞ÊàêÁöÑÊ®°ÂûãÁöÑÂèØÁî®ÊÄß‰ΩøÂæóËøûÊé•Âíå‰∏éËøúÁ®ã APIÔºàÂ¶Ç OpenAI Âíå MistralÔºâ‰∫íÂä®ÂèòÂæóÁÆÄÂçï„ÄÇJan ËøòÊúâ‰∏Ä‰∏™ÂæàÊ£íÁöÑ [GitHub](https://github.com/janhq/jan)„ÄÅ[Discord](https://discord.gg/FTk2MvZwJH) Âíå [Hugging Face](https://huggingface.co/janhq) Á§æÂå∫ÔºåÂèØ‰ª•ÂÖ≥Ê≥®Âπ∂ÂØªÊ±ÇÂ∏ÆÂä©„ÄÇÁÑ∂ËÄåÔºåÂÉèÊâÄÊúâ LLM Â∑•ÂÖ∑‰∏ÄÊ†∑ÔºåËøô‰∫õÊ®°ÂûãÂú® Apple Silicon Macs ‰∏äÁöÑËøêË°åÈÄüÂ∫¶ÊØîÂú® Intel Êú∫Âô®‰∏äÊõ¥Âø´„ÄÇ\n\n## 3. Llamafile\n\n[Llamafile](https://github.com/Mozilla-Ocho/llamafile) Áî± [Mozilla](https://www.mozilla.org/en-US/?v=1) ÊîØÊåÅÔºåÊó®Âú®ÈÄöËøáÂø´ÈÄüÁöÑ [CPU Êé®ÁêÜ](https://huggingface.co/docs/transformers/en/perf_infer_cpu) ‰ΩøÂºÄÊ∫ê AI ÂØπÊØè‰∏™‰∫∫ÈÉΩÂèØËÆøÈóÆÔºåËÄåÊó†ÈúÄÁΩëÁªúËøûÊé•„ÄÇÂÆÉÂ∞Ü LLM ËΩ¨Êç¢‰∏∫Â§öÂπ≥Âè∞ÁöÑ [ÂèØÊâßË°åÈìæÊé•Ê†ºÂºè](https://gist.github.com/x0nu11byt3/bcb35c3de461e5fb66173071a2379779) (ELF)„ÄÇÂÆÉÊèê‰æõ‰∫ÜÂ∞Ü AI [ÈõÜÊàê](https://getstream.io/chat/solutions/ai-integration/) Âà∞Â∫îÁî®Á®ãÂ∫è‰∏≠ÁöÑÊúÄ‰Ω≥ÈÄâÈ°π‰πã‰∏ÄÔºå‰ΩøÊÇ®ËÉΩÂ§ü‰ªÖÈÄöËøá‰∏Ä‰∏™ÂèØÊâßË°åÊñá‰ª∂ËøêË°å LLM„ÄÇ\n\n## Llamafile ÁöÑÂ∑•‰ΩúÂéüÁêÜ\n\nÂÆÉÊó®Âú®Â∞ÜÊùÉÈáçËΩ¨Êç¢‰∏∫Â§ö‰∏™ÂèØÊâßË°åÁ®ãÂ∫èÔºåËøô‰∫õÁ®ãÂ∫èÊó†ÈúÄÂÆâË£ÖÂç≥ÂèØÂú® Windows„ÄÅMacOS„ÄÅLinux„ÄÅIntel„ÄÅARM„ÄÅFreeBSD Á≠âÊû∂ÊûÑ‰∏äËøêË°å„ÄÇÂú®Â∫ïÂ±ÇÔºåLlamafile ‰ΩøÁî® [tinyBLAST](https://github.com/ggerganov/llama.cpp/issues/5048) Âú®ÂÉè Windows ËøôÊ†∑ÁöÑÊìç‰ΩúÁ≥ªÁªü‰∏äËøêË°åÔºåËÄåÊó†ÈúÄ SDK„ÄÇ\n\n## Llamafile ÁöÑÂÖ≥ÈîÆÁâπÊÄß\n\n* **ÂèØÊâßË°åÊñá‰ª∂**Ôºö‰∏é LM Studio Âíå Jan Á≠âÂÖ∂‰ªñ LLM Â∑•ÂÖ∑‰∏çÂêåÔºåLlamafile Âè™ÈúÄ‰∏Ä‰∏™ÂèØÊâßË°åÊñá‰ª∂Âç≥ÂèØËøêË°å LLM„ÄÇ\n* **‰ΩøÁî®Áé∞ÊúâÊ®°Âûã**ÔºöLlamafile ÊîØÊåÅ‰ΩøÁî®Áé∞ÊúâÁöÑÊ®°ÂûãÂ∑•ÂÖ∑ÔºåÂ¶Ç Ollama Âíå LM Studio„ÄÇ\n* **ËÆøÈóÆÊàñÂàõÂª∫Ê®°Âûã**ÔºöÊÇ®ÂèØ‰ª•ËÆøÈóÆ OpenAI„ÄÅMistral„ÄÅGroq Á≠âÊµÅË°å LLM„ÄÇÂÆÉËøòÊèê‰æõ‰ªéÂ§¥ÂàõÂª∫Ê®°ÂûãÁöÑÊîØÊåÅ„ÄÇ\n* **Ê®°ÂûãÊñá‰ª∂ËΩ¨Êç¢**ÔºöÊÇ®ÂèØ‰ª•Â∞ÜËÆ∏Â§öÊµÅË°å LLM ÁöÑÊñá‰ª∂Ê†ºÂºèËΩ¨Êç¢Ôºå‰æãÂ¶ÇÔºåÂ∞Ü `.gguf` ËΩ¨Êç¢‰∏∫ `.llamafile` Âè™ÈúÄ‰∏Ä‰∏™ÂëΩ‰ª§„ÄÇ\n\n`llamafile-convert mistral-7b.gguf`\n\n## ÂºÄÂßã‰ΩøÁî® Llamafile\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4PV1KsCZvvVKqFll)\n\nË¶ÅÂÆâË£Ö LlamafileÔºåËØ∑ËÆøÈóÆ Huggingface ÁΩëÁ´ôÔºå‰ªéÂØºËà™‰∏≠ÈÄâÊã© **Models**ÔºåÁÑ∂ÂêéÊêúÁ¥¢ **Llamafile**„ÄÇÊÇ®ËøòÂèØ‰ª•‰ªé‰∏ãÈù¢ÁöÑ URL ÂÆâË£ÖÊÇ®ÂñúÊ¨¢ÁöÑ [ÈáèÂåñ](https://huggingface.co/docs/optimum/en/concept_guides/quantization) ÁâàÊú¨„ÄÇ\n\n[`https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/tree/m`ain](https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/tree/main)\n\n**Ê≥®ÊÑè**ÔºöÈáèÂåñÊï∞Â≠óË∂äÂ§ßÔºåÂìçÂ∫îË∂äÂ•Ω„ÄÇÊ≠£Â¶Ç‰∏äÂõæÊâÄÁ§∫ÔºåÊú¨Êñá‰ΩøÁî® `Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile`ÔºåÂÖ∂‰∏≠ `Q6` ‰ª£Ë°®ÈáèÂåñÊï∞Â≠ó„ÄÇ\n\n**Ê≠•È™§ 1Ôºö‰∏ãËΩΩ Llamafile**\n\n‰ªé‰∏äÈù¢ÁöÑÈìæÊé•ÔºåÁÇπÂáª‰ªªÊÑè‰∏ãËΩΩÊåâÈíÆ‰ª•Ëé∑ÂèñÊÇ®ÂñúÊ¨¢ÁöÑÁâàÊú¨„ÄÇÂ¶ÇÊûúÊÇ®Âú®Êú∫Âô®‰∏äÂÆâË£Ö‰∫Ü [wget](https://www.gnu.org/software/wget/) Â∑•ÂÖ∑ÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§‰∏ãËΩΩ Llamafile„ÄÇ\n\n`wget <https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/blob/main/Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile>`\n\nÊÇ®Â∫îËØ•Áî®ÊÇ®ÂñúÊ¨¢ÁöÑÁâàÊú¨ÊõøÊç¢ URL„ÄÇ\n\n**Ê≠•È™§ 2Ôºö‰Ωø Llamafile ÂèØÊâßË°å**\n\n‰∏ãËΩΩÁâπÂÆöÁâàÊú¨ÁöÑ Llamafile ÂêéÔºåÊÇ®Â∫îËØ•ÈÄöËøáÂØºËà™Âà∞Êñá‰ª∂‰ΩçÁΩÆÔºå‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§‰ΩøÂÖ∂ÂèØÊâßË°å„ÄÇ\n\n`chmod +x Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile`**Ê≠•È™§ 3ÔºöËøêË°å Llamafile**\n\nÂú®Êñá‰ª∂Âêç‰πãÂâçÊ∑ªÂä†‰∏Ä‰∏™ÁÇπÂíåÊñúÊù† `./` Êù•ÂêØÂä® Llamafile„ÄÇ\n\n`./Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile`\n\nLlamafile Â∫îÁî®Á®ãÂ∫èÁé∞Âú®Â∞ÜÂú® `http://127.0.0.1:8080` ÂèØÁî®Ôºå‰ª•ËøêË°åÊÇ®ÁöÑÂêÑÁßç LLMs„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*1xrwDPTfNgmEQDTx)\n\n## ‰ΩøÁî® Llamafile ÁöÑÂ•ΩÂ§Ñ\n\nLlamafile ÈÄöËøá‰Ωø LLM ÂÆπÊòìË¢´Ê∂àË¥πËÄÖ CPU ËÆøÈóÆÔºåÂ∏ÆÂä©ÂÆûÁé∞ AI Âíå ML ÁöÑÊ∞ë‰∏ªÂåñ„ÄÇ‰∏éÂÖ∂‰ªñÊú¨Âú∞ LLM Â∫îÁî®Á®ãÂ∫èÂ¶Ç **Llama.cpp** Áõ∏ÊØîÔºåLlamafile Êèê‰æõ‰∫ÜÊúÄÂø´ÁöÑÊèêÁ§∫Â§ÑÁêÜ‰ΩìÈ™åÔºåÂπ∂Âú®Ê∏∏ÊàèÁîµËÑë‰∏äË°®Áé∞Êõ¥‰Ω≥„ÄÇÁî±‰∫éÂÖ∂Êõ¥Âø´ÁöÑÊÄßËÉΩÔºåÂÆÉÊòØÊÄªÁªìÈïøÊñáÊú¨ÂíåÂ§ßÂûãÊñáÊ°£ÁöÑÁªù‰Ω≥ÈÄâÊã©„ÄÇÂÆÉÂÆåÂÖ®Á¶ªÁ∫øËøêË°åÂπ∂‰øùÊä§ÈöêÁßÅÔºåÂõ†Ê≠§Áî®Êà∑‰∏ç‰ºöÂ∞ÜÊï∞ÊçÆÂàÜ‰∫´Áªô‰ªª‰Ωï AI ÊúçÂä°Âô®Êàñ API„ÄÇÂÉè Hugging Face ËøôÊ†∑ÁöÑÊú∫Âô®Â≠¶‰π†Á§æÂå∫ÊîØÊåÅ Llamafile Ê†ºÂºèÔºå‰ΩøÂæóÊêúÁ¥¢‰∏é Llamafile Áõ∏ÂÖ≥ÁöÑÊ®°ÂûãÂèòÂæóÂÆπÊòì„ÄÇÂÆÉËøòÊúâ‰∏Ä‰∏™Âá∫Ëâ≤ÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåËøõ‰∏ÄÊ≠•ÂºÄÂèëÂíåÊâ©Â±ïÂÆÉ„ÄÇ\n\n## 4. GPT4ALL\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*j3vNWWQZCVF5woo5)\n\nGPT4ALL Âü∫‰∫éÈöêÁßÅ„ÄÅÂÆâÂÖ®ÂíåÊó†ÈúÄ‰∫íËÅîÁΩëÁöÑÂéüÂàôÊûÑÂª∫„ÄÇÁî®Êà∑ÂèØ‰ª•Âú® Mac„ÄÅWindows Âíå Ubuntu ‰∏ä [ÂÆâË£Ö](https://www.nomic.ai/gpt4all)„ÄÇ‰∏é Jan Êàñ LM Studio Áõ∏ÊØîÔºåGPT4ALL Êã•ÊúâÊõ¥Â§öÁöÑÊØèÊúà‰∏ãËΩΩÈáè„ÄÅ[GitHub Stars](https://github.com/nomic-ai/gpt4all) ÂíåÊ¥ªË∑ÉÁî®Êà∑„ÄÇ\n\n## GPT4ALLÁöÑ‰∏ªË¶ÅÁâπÁÇπ\n\nGPT4AllÂèØ‰ª•Âú®‰∏ªË¶ÅÊ∂àË¥πÁ°¨‰ª∂‰∏äËøêË°åLLMÔºå‰æãÂ¶ÇMac MÁ≥ªÂàóËäØÁâá„ÄÅAMDÂíåNVIDIA GPU„ÄÇ‰ª•‰∏ãÊòØÂÖ∂‰∏ªË¶ÅÁâπÁÇπ„ÄÇ\n\n* **ÈöêÁßÅ‰ºòÂÖà**ÔºöÂ∞ÜÁßÅ‰∫∫ÂíåÊïèÊÑüÁöÑËÅäÂ§©‰ø°ÊÅØÂíåÊèêÁ§∫‰ªÖ‰øùÁïôÂú®ÊÇ®ÁöÑËÆæÂ§á‰∏ä„ÄÇ\n* **Êó†ÈúÄ‰∫íËÅîÁΩë**ÔºöÂÆÉÂÆåÂÖ®Á¶ªÁ∫øÂ∑•‰Ωú„ÄÇ\n* **Ê®°ÂûãÊé¢Á¥¢**ÔºöÊ≠§ÂäüËÉΩÂÖÅËÆ∏ÂºÄÂèëËÄÖÊµèËßàÂíå‰∏ãËΩΩ‰∏çÂêåÁ±ªÂûãÁöÑLLMËøõË°åÂÆûÈ™å„ÄÇÊÇ®ÂèØ‰ª•‰ªéÊµÅË°åÈÄâÈ°π‰∏≠ÈÄâÊã©Â§ßÁ∫¶1000‰∏™ÂºÄÊ∫êËØ≠Ë®ÄÊ®°ÂûãÔºåÂ¶ÇLLama„ÄÅMistralÁ≠â„ÄÇ\n* **Êú¨Âú∞ÊñáÊ°£**ÔºöÊÇ®ÂèØ‰ª•ËÆ©Êú¨Âú∞LLMËÆøÈóÆÊÇ®ÁöÑÊïèÊÑüÊï∞ÊçÆÔºå‰ΩøÁî®Êú¨Âú∞ÊñáÊ°£Â¶Ç`.pdf`Âíå`.txt`ÔºåÊï∞ÊçÆ‰∏ç‰ºöÁ¶ªÂºÄÊÇ®ÁöÑËÆæÂ§áÔºå‰πüÊó†ÈúÄÁΩëÁªú„ÄÇ\n* **Ëá™ÂÆö‰πâÈÄâÈ°π**ÔºöÂÆÉÊèê‰æõÂ§ö‰∏™[ËÅäÂ§©Êú∫Âô®‰∫∫](https://getstream.io/blog/llm-chatbot-docs/)Ë∞ÉÊï¥ÈÄâÈ°πÔºåÂ¶ÇÊ∏©Â∫¶„ÄÅÊâπÂ§ÑÁêÜÂ§ßÂ∞è„ÄÅ‰∏ä‰∏ãÊñáÈïøÂ∫¶Á≠â„ÄÇ\n* **‰ºÅ‰∏öÁâà**ÔºöGPT4ALLÊèê‰æõ‰ºÅ‰∏öÂ•óÈ§êÔºåÂÖ∑Â§áÂÆâÂÖ®ÊÄß„ÄÅÊîØÊåÅÂíåÊØèÂè∞ËÆæÂ§áÁöÑËÆ∏ÂèØËØÅÔºåÂ∞ÜÊú¨Âú∞AIÂ∏¶ÂÖ•‰ºÅ‰∏ö„ÄÇ\n\n## ÂºÄÂßã‰ΩøÁî® GPT4All\n\nË¶ÅÂºÄÂßã‰ΩøÁî® GPT4All Âú®Êú¨Âú∞ËøêË°å LLMsÔºåËØ∑[‰∏ãËΩΩ](https://www.nomic.ai/gpt4all)ÈÄÇÂêàÊÇ®Êìç‰ΩúÁ≥ªÁªüÁöÑÁâàÊú¨„ÄÇ\n\n## ‰ΩøÁî®GPT4ALLÁöÑÂ•ΩÂ§Ñ\n\nÈô§‰∫ÜOllamaÔºåGPT4ALLÂú®GitHubË¥°ÁåÆËÄÖÊï∞Èáè‰∏äÊúÄ‰∏∫ÊòæËëóÔºåÊã•ÊúâÁ∫¶250000ÂêçÊØèÊúàÊ¥ªË∑ÉÁî®Êà∑ÔºàÊ†πÊçÆ<https://www.nomic.ai/gpt4all>ÔºâÂπ∂‰∏î‰∏éÂÖ∂Á´û‰∫âÂØπÊâãÁõ∏ÊØî„ÄÇËØ•Â∫îÁî®Êî∂ÈõÜÊúâÂÖ≥‰ΩøÁî®ÂàÜÊûêÂíåËÅäÂ§©ÂàÜ‰∫´ÁöÑÂåøÂêçÁî®Êà∑Êï∞ÊçÆ„ÄÇÁÑ∂ËÄåÔºåÁî®Êà∑ÂèØ‰ª•ÈÄâÊã©Âä†ÂÖ•ÊàñÈÄÄÂá∫„ÄÇ‰ΩøÁî®GPT4ALLÔºåÂºÄÂèëËÄÖÂèØ‰ª•‰ªéÂÖ∂Â∫ûÂ§ßÁöÑÁî®Êà∑Âü∫Á°Ä„ÄÅGitHubÂíåDiscordÁ§æÂå∫‰∏≠ÂèóÁõä„ÄÇ\n\n## 5. Ollama\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*STAonWgWIsY6cgDR)\n\n‰ΩøÁî® [Ollama](https://ollama.com/)ÔºåÊÇ®ÂèØ‰ª•ËΩªÊùæÂàõÂª∫Êú¨Âú∞ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåËÄåÊó†ÈúÄËøûÊé•Âà∞ÂÉè OpenAI ËøôÊ†∑ÁöÑ API„ÄÇÁî±‰∫é‰∏ÄÂàáÈÉΩÂú®Êú¨Âú∞ËøêË°åÔºåÊÇ®Êó†ÈúÄÊîØ‰ªò‰ªª‰ΩïËÆ¢ÈòÖË¥πÊàñ API Ë∞ÉÁî®Ë¥πÁî®„ÄÇ\n\n## Ollama ÁöÑÂÖ≥ÈîÆÁâπÊÄß\n\n* **Ê®°ÂûãËá™ÂÆö‰πâ**ÔºöOllama ÂÖÅËÆ∏ÊÇ®ËΩ¨Êç¢ `.gguf` Ê®°ÂûãÊñá‰ª∂Âπ∂‰ΩøÁî® `ollama run modelname` ËøêË°åÂÆÉ‰ª¨„ÄÇ\n* **Ê®°ÂûãÂ∫ì**ÔºöOllama Êã•ÊúâÂ§ßÈáèÊ®°ÂûãÂèØ‰æõÂ∞ùËØïÔºåËÆøÈóÆ [ollama.com/library](https://ollama.com/library)„ÄÇ\n* **ÂØºÂÖ•Ê®°Âûã**ÔºöOllama ÊîØÊåÅ‰ªé [PyTorch](https://pytorch.org/) ÂØºÂÖ•Ê®°Âûã„ÄÇ\n* **Á§æÂå∫ÈõÜÊàê**ÔºöOllama Êó†ÁºùÈõÜÊàêÂà∞ÁΩëÈ°µÂíåÊ°åÈù¢Â∫îÁî®Á®ãÂ∫è‰∏≠Ôºå‰æãÂ¶Ç [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)„ÄÅ[HTML UI](https://github.com/rtcfirefly/ollama-ui)„ÄÅ[Dify.ai](https://github.com/rtcfirefly/ollama-ui) Âíå [Êõ¥Â§ö](https://github.com/ollama/ollama?tab=readme-ov-file#community-integrations)„ÄÇ\n* **Êï∞ÊçÆÂ∫ìËøûÊé•**ÔºöOllama ÊîØÊåÅÂ§ö‰∏™ [Êï∞ÊçÆÂπ≥Âè∞](https://github.com/mindsdb/mindsdb/blob/main/mindsdb/integrations/handlers/ollama_handler/README.md)„ÄÇ\n* **ÁßªÂä®ÈõÜÊàê**ÔºöÂÉè [Enchanted](https://github.com/AugustDev/enchanted) ËøôÊ†∑ÁöÑ SwiftUI Â∫îÁî®Â∞Ü Ollama Â∏¶ÂÖ• iOS„ÄÅmacOS Âíå visionOS„ÄÇ[Maid](https://github.com/Mobile-Artificial-Intelligence/maid) ‰πüÊòØ‰∏Ä‰∏™Ë∑®Âπ≥Âè∞ÁöÑ Flutter Â∫îÁî®ÔºåËÉΩÂ§üÊú¨Âú∞Â§ÑÁêÜ `.gguf` Ê®°ÂûãÊñá‰ª∂„ÄÇ\n\n## ÂºÄÂßã‰ΩøÁî® Ollama\n\nË¶ÅÈ¶ñÊ¨°‰ΩøÁî® OllamaÔºåËØ∑ËÆøÈóÆ <https://ollama.com> Âπ∂‰∏ãËΩΩÈÄÇÂêàÊÇ®Êú∫Âô®ÁöÑÁâàÊú¨„ÄÇÊÇ®ÂèØ‰ª•Âú® Mac„ÄÅLinux Êàñ Windows ‰∏äÂÆâË£ÖÂÆÉ„ÄÇÂÆâË£Ö Ollama ÂêéÔºåÊÇ®ÂèØ‰ª•Âú®ÁªàÁ´Ø‰∏≠‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§Ê£ÄÊü•ÂÖ∂ËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ\n\n`ollama`\n\nË¶ÅËøêË°åÁâπÂÆöÁöÑ LLMÔºåÊÇ®Â∫îËØ•‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§‰∏ãËΩΩÂÆÉÔºö\n\n`ollama pull modelname`ÔºåÂÖ∂‰∏≠ `modelname` ÊòØÊÇ®Ë¶ÅÂÆâË£ÖÁöÑÊ®°ÂûãÂêçÁß∞„ÄÇËØ∑Âú® [GitHub](https://github.com/ollama/ollama) ‰∏äÊü•Áúã‰∏Ä‰∫õÂèØ‰æõ‰∏ãËΩΩÁöÑÁ§∫‰æãÊ®°Âûã„ÄÇ`pull` ÂëΩ‰ª§‰πüÁî®‰∫éÊõ¥Êñ∞Ê®°Âûã„ÄÇ‰∏ÄÊó¶‰ΩøÁî®Ôºå‰ªÖ‰ºöËé∑ÂèñÂ∑ÆÂºÇÈÉ®ÂàÜ„ÄÇ\n\n‰æãÂ¶ÇÔºåÂú®‰∏ãËΩΩ‰∫Ü `llama3.1` ÂêéÔºåÂú®ÂëΩ‰ª§Ë°å‰∏≠ËøêË°å `ollama run llama3.1` Â∞ÜÂêØÂä®ËØ•Ê®°Âûã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aglZm6h0BU6GAYkSl04XWA.gif)\n\nÂú®‰∏äËø∞Á§∫‰æã‰∏≠ÔºåÊàë‰ª¨ÊèêÁ§∫ `llama3.1` Ê®°ÂûãËß£ÂÜ≥‰∏Ä‰∏™Áâ©ÁêÜÂäüÂíåËÉΩÈáèÁöÑÈóÆÈ¢ò„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*dNNQYpz1s2tz1pcn)\n\n## ‰ΩøÁî® Ollama ÁöÑÂ•ΩÂ§Ñ\n\nOllama Âú® GitHub ‰∏äÊã•ÊúâË∂ÖËøá 200 ÂêçË¥°ÁåÆËÄÖÔºåÂπ∂‰∏îÊúâÊ¥ªË∑ÉÁöÑÊõ¥Êñ∞„ÄÇÂÆÉÊã•ÊúâÊúÄÂ§öÁöÑË¥°ÁåÆËÄÖÔºåÂπ∂‰∏îÂú®‰∏äËø∞ÂÖ∂‰ªñÂºÄÊ∫ê LLM Â∑•ÂÖ∑‰∏≠Êõ¥ÂÖ∑ÂèØÊâ©Â±ïÊÄß„ÄÇ\n\n## 6. LLaMa.cpp\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*KhsAUquhDZAHghxK)\n\n[LLaMa.cpp](https://github.com/ggerganov/llama.cpp) ÊòØÊîØÊåÅÊú¨Âú∞ LLM Â∑•ÂÖ∑ÔºàÂ¶Ç Ollama Á≠âÔºâÁöÑÂ∫ïÂ±ÇÂêéÁ´ØÊäÄÊúØÔºàÊé®ÁêÜÂºïÊìéÔºâ„ÄÇLLaMa.cpp ÊîØÊåÅÊòæËëóÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜÔºåÈÖçÁΩÆÁÆÄÂçïÔºåÂπ∂Âú®ÂêÑÁßçÁ°¨‰ª∂‰∏äÊèê‰æõÂá∫Ëâ≤ÁöÑÊú¨Âú∞ÊÄßËÉΩ„ÄÇÂÆÉ‰πüÂèØ‰ª•Âú®‰∫ëÁ´ØËøêË°å„ÄÇ\n\n## LLaMa.cpp ÁöÑ‰∏ªË¶ÅÁâπÁÇπ\n\n* **ËÆæÁΩÆ**ÔºöÂÆÉÁöÑËÆæÁΩÆÈùûÂ∏∏ÁÆÄÂçï„ÄÇÊÇ®Âè™ÈúÄ‰∏Ä‰∏™ÂëΩ‰ª§Âç≥ÂèØÂÆâË£Ö„ÄÇ\n* **ÊÄßËÉΩ**ÔºöÂÆÉÂú®Êú¨Âú∞Âíå‰∫ëÁ´ØÁöÑÂêÑÁßçÁ°¨‰ª∂‰∏äË°®Áé∞ÈùûÂ∏∏Âá∫Ëâ≤„ÄÇ\n* **ÊîØÊåÅÁöÑÊ®°Âûã**ÔºöÂÆÉÊîØÊåÅÊµÅË°åÁöÑ‰∏ªË¶Å LLMÔºåÂ¶Ç [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)„ÄÅ[Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral)„ÄÅ[DBRX](https://huggingface.co/databricks/dbrx-instruct)„ÄÅ[Falcon](https://huggingface.co/models?search=tiiuae/falcon) Âíå [ÂÖ∂‰ªñËÆ∏Â§öÊ®°Âûã](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#description)„ÄÇ\n* **ÂâçÁ´Ø AI Â∑•ÂÖ∑**ÔºöLLaMa.cpp ÊîØÊåÅÂºÄÊ∫ê LLM UI Â∑•ÂÖ∑ÔºåÂ¶Ç [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT)„ÄÅ[iohub/collama](https://github.com/iohub/coLLaMA) Á≠â„ÄÇ\n\n## ‰ΩøÁî® LLaMa.cpp ÂºÄÂßã\n\nË¶ÅËøêË°åÊÇ®ÁöÑÁ¨¨‰∏Ä‰∏™Êú¨Âú∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåËØ∑‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£Ö llama.cppÔºö\n\n`brew install llama.cpp`\n\nÊé•‰∏ãÊù•Ôºå‰ªé Hugging Face ÊàñÂÖ∂‰ªñÊù•Ê∫ê‰∏ãËΩΩÊÇ®ÊÉ≥Ë¶ÅËøêË°åÁöÑÊ®°Âûã„ÄÇ‰æãÂ¶ÇÔºå‰ªé Hugging Face ‰∏ãËΩΩ‰∏ãÈù¢ÁöÑÊ®°ÂûãÂπ∂Â∞ÜÂÖ∂‰øùÂ≠òÂú®ÊÇ®ËÆ°ÁÆóÊú∫‰∏äÁöÑÊüê‰∏™‰ΩçÁΩÆ„ÄÇ\n\n[`https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.g`guf](https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf)\n\n‰ΩøÁî®ÊÇ®ÂñúÊ¨¢ÁöÑÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑ÔºåÂ¶ÇÁªàÁ´ØÔºå`cd` ËøõÂÖ•ÊÇ®Âàö‰∏ãËΩΩÁöÑ `.gguf` Ê®°ÂûãÊñá‰ª∂ÁöÑ‰ΩçÁΩÆÔºåÂπ∂ËøêË°å‰ª•‰∏ãÂëΩ‰ª§„ÄÇ\n\n```python\nllama-cli --color \\ \n-m Mistral-7B-Instruct-v0.3.Q4_K_M.ggufb \\ \n-p \"Write a short intro about SwiftUI\"\n```\nÊÄª‰πãÔºåÊÇ®È¶ñÂÖàË∞ÉÁî® LLaMa CLI Â∑•ÂÖ∑Âπ∂ËÆæÁΩÆÈ¢úËâ≤ÂíåÂÖ∂‰ªñÊ†áÂøó„ÄÇ`-m` Ê†áÂøóÊåáÂÆöÊÇ®Ë¶Å‰ΩøÁî®ÁöÑÊ®°ÂûãÁöÑË∑ØÂæÑ„ÄÇ`-p` Ê†áÂøóÊåáÂÆöÊÇ®Â∏åÊúõÁî®Êù•ÊåáÁ§∫Ê®°ÂûãÁöÑÊèêÁ§∫„ÄÇ\n\nËøêË°å‰∏äËø∞ÂëΩ‰ª§ÂêéÔºåÊÇ®Â∞ÜÁúãÂà∞‰ª•‰∏ãÈ¢ÑËßà‰∏≠ÁöÑÁªìÊûú„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4Al-j50vXUXLUfvxzBt6aw.gif)\n\n## Êú¨Âú∞ LLM ÁöÑÁî®‰æã\n\nÂú®Êú¨Âú∞ËøêË°å LLM ÂèØ‰ª•Â∏ÆÂä©ÂºÄÂèë‰∫∫ÂëòÊ∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÊÄßËÉΩÂíåÂ∑•‰ΩúÂéüÁêÜ„ÄÇ Êú¨Âú∞ LLM ÂèØ‰ª•Êü•ËØ¢ÁßÅÊúâÊñáÊ°£ÂíåÊäÄÊúØËÆ∫ÊñáÔºå‰ª•‰æø‰∏éËøô‰∫õÊñáÊ°£Áõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ‰∏ç‰ºöÁ¶ªÂºÄÁî®‰∫éÊü•ËØ¢ÁöÑËÆæÂ§áÔºå‰∏ç‰ºöÂèëÈÄÅÂà∞‰ªª‰Ωï‰∫ë AI API„ÄÇ Êú¨Âú∞ LLM Âú®Ê≤°Êúâ‰∫íËÅîÁΩëÁöÑÂú∞ÊñπÂíåÁΩëÁªú‰ø°Âè∑ËæÉÂ∑ÆÁöÑÂú∞ÊñπÈùûÂ∏∏ÊúâÁî®„ÄÇ\n\nÂú® [ËøúÁ®ãÂåªÁñóÁéØÂ¢É](https://getstream.io/blog/telemedicine-app-development/) ‰∏≠ÔºåÊú¨Âú∞ LLM ÂèØ‰ª•ÂØπÊÇ£ËÄÖÊñáÊ°£ËøõË°åÊéíÂ∫èÔºåËÄåÊó†ÈúÄÂá∫‰∫éÈöêÁßÅËÄÉËôëÂ∞ÜÂÖ∂‰∏ä‰º†Âà∞‰ªª‰Ωï AI API Êèê‰æõÂïÜ„ÄÇ\n\n## ËØÑ‰º∞Êú¨Âú∞ËøêË°åÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊÄßËÉΩ\n\nÂú®Êú¨Âú∞‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰πãÂâçÔºå‰∫ÜËß£ÂÖ∂ÊÄßËÉΩÂØπ‰∫éËé∑ÂæóÊâÄÈúÄÁöÑÂìçÂ∫îËá≥ÂÖ≥ÈáçË¶Å„ÄÇÊúâÂá†ÁßçÊñπÊ≥ïÂèØ‰ª•Á°ÆÂÆöÁâπÂÆö LLM ÁöÑÊÄßËÉΩ„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÊñπÊ≥ï„ÄÇ\n\n* **ËÆ≠ÁªÉ**ÔºöËØ•Ê®°ÂûãÊòØÂü∫‰∫é‰ªÄ‰πàÊï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉÁöÑÔºü\n* **ÂæÆË∞É**ÔºöÊ®°ÂûãÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÂèØ‰ª•ÂÆöÂà∂‰ª•ÊâßË°åÁâπÂÆö‰ªªÂä°ÔºåÊàñËÄÖÊòØÂê¶ÂèØ‰ª•ÈíàÂØπÁâπÂÆöÈ¢ÜÂüüËøõË°åÂæÆË∞ÉÔºü\n* **Â≠¶ÊúØÁ†îÁ©∂**ÔºöËØ• LLM ÊòØÂê¶ÊúâÂ≠¶ÊúØÁ†îÁ©∂ËÆ∫ÊñáÔºü\n\nË¶ÅÂõûÁ≠î‰∏äËø∞ÈóÆÈ¢òÔºåÊÇ®ÂèØ‰ª•Êü•Áúã‰ºòÁßÄÁöÑËµÑÊ∫êÔºåÂ¶Ç [Hugging Face](https://huggingface.co/datasets) Âíå [Arxiv.org](https://arxiv.org/)„ÄÇÊ≠§Â§ñÔºå[Open LLm Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) Âíå [LMSYS Chatbot Arena](https://chat.lmsys.org/?arena) Êèê‰æõ‰∫ÜÂêÑÁßç LLM ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÂíåÂü∫ÂáÜÊµãËØï„ÄÇ\n\n## Êú¨Âú∞ LLM Â∑•ÂÖ∑ÁªìËÆ∫\n\nÊ≠£Â¶ÇÊú¨ÊñáÊâÄËÆ®ËÆ∫ÁöÑÔºåÈÄâÊã©Âíå‰ΩøÁî®Êú¨Âú∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂä®Êú∫ÊúâÂæàÂ§ö„ÄÇÂ¶ÇÊûúÊÇ®‰∏çÂ∏åÊúõÂ∞ÜÊï∞ÊçÆÈõÜÈÄöËøá‰∫íËÅîÁΩëÂèëÈÄÅÁªô AI API Êèê‰æõÂïÜÔºåÂàôÂèØ‰ª•ÂØπÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºå‰ª•ÊâßË°å [ËøúÁ®ãÂåªÁñóÂ∫îÁî®](https://getstream.io/chat/solutions/healthcare/) ‰∏≠ÁöÑÁâπÂÆö‰ªªÂä°„ÄÇËÆ∏Â§öÂºÄÊ∫êÁöÑÂõæÂΩ¢Áî®Êà∑ÁïåÈù¢ÔºàGUIÔºâÊú¨Âú∞ LLM Â∑•ÂÖ∑ÔºåÂ¶Ç LLm Studio Âíå JanÔºåÊèê‰æõÁõ¥ËßÇÁöÑÂâçÁ´ØÁî®Êà∑ÁïåÈù¢Ôºå‰ª•‰æøÂú®Ê≤°ÊúâÂÉè OpenAI Êàñ Claude ËøôÊ†∑ÁöÑËÆ¢ÈòÖÊúçÂä°ÁöÑÊÉÖÂÜµ‰∏ãÈÖçÁΩÆÂíåÂÆûÈ™å LLM„ÄÇÊÇ®ËøòÂèëÁé∞‰∫ÜÂêÑÁßçÂº∫Â§ßÁöÑÂëΩ‰ª§Ë°å LLM Â∫îÁî®Á®ãÂ∫èÔºåÂ¶Ç Ollama Âíå LLaMa.cppÔºåÂ∏ÆÂä©ÊÇ®Âú®Êú¨Âú∞ËøêË°åÂíåÊµãËØïÊ®°ÂûãÔºåËÄåÊó†ÈúÄ‰∫íËÅîÁΩëËøûÊé•„ÄÇÊü•Áúã Stream ÁöÑ [AI ËÅäÂ§©Êú∫Âô®‰∫∫](https://getstream.io/chat/solutions/ai-integration/) Ëß£ÂÜ≥ÊñπÊ°àÔºåÂ∞Ü AI ËÅäÂ§©ÈõÜÊàêÂà∞ÊÇ®ÁöÑÂ∫îÁî®‰∏≠ÔºåÂπ∂ËÆøÈóÆÊâÄÊúâÁõ∏ÂÖ≥ÈìæÊé•‰ª•‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n*ÊúÄÂàùÂèëÂ∏É‰∫é [https://getstream.io](https://getstream.io/blog/best-local-llm-tools/).*\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-best-conversational-ai-virtual-health-care-assistants-for-aging-adults-fc65bcfb9cf4","frontmatter":{"title":"ÊúÄÈÄÇÂêàËÄÅÂπ¥‰∫∫ÁöÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËôöÊãüÂåªÁñóÂä©ÁêÜ","meta_title":"ÊúÄÈÄÇÂêàËÄÅÂπ¥‰∫∫ÁöÑÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩËôöÊãüÂåªÁñóÂä©ÁêÜ","description":"ËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÊâãÔºåÂ¶ÇMiiHealth.aiÔºåÊ≠£Âú®‰∏∫Áã¨Â±ÖËÄÅÂπ¥‰∫∫Êèê‰æõÈù©ÂëΩÊÄßÁöÑÂåªÁñóÊîØÊåÅ„ÄÇËøô‰∫õÂØπËØùÂºèÂä©ÊâãÈÄöËøáËçØÁâ©ÁÆ°ÁêÜ„ÄÅ24/7ÂèØÁî®ÊÄß„ÄÅÁ¥ßÊÄ•ÂÅ•Â∫∑ÁõëÊµã„ÄÅ‰∏™ÊÄßÂåñÂÅ•Â∫∑Âª∫ËÆÆÂíåÊÉÖÊÑüÊîØÊåÅÔºåÂ∏ÆÂä©ËÄÅÂπ¥‰∫∫Â∫îÂØπÂÅ•Â∫∑ÊåëÊàòÂíåÂ≠§Áã¨ÊÑü„ÄÇÂÆÉ‰ª¨ÁöÑÊòìÁî®ÊÄßÂíå‰∏™ÊÄßÂåñÊúçÂä°‰ΩøÂÖ∂Êàê‰∏∫ËÄÅÂπ¥‰∫∫ÂÅ•Â∫∑Êä§ÁêÜÁöÑÈáçË¶ÅÂ∑•ÂÖ∑ÔºåÁ°Æ‰øù‰ªñ‰ª¨‰øùÊåÅÁã¨Á´ã„ÄÅËøûÊé•ÂíåÂÅ•Â∫∑„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PBuPT38hZv61TFXQzJZ_3w.jpeg","categories":["Health","Chatbots","Autonomous Systems"],"author":"Rifx.Online","tags":["Virtual","Healthcare","Assistants","Medication","Monitoring"],"draft":false,"slug":"blog/the-best-conversational-ai-virtual-health-care-assistants-for-aging-adults-fc65bcfb9cf4"},"content":"\n\n\nÈöèÁùÄÂπ¥ÈæÑÁöÑÂ¢ûÈïøÔºåÁÖßÈ°æÊàë‰ª¨ÁöÑÂÅ•Â∫∑ÂèòÂæóÊõ¥Âä†Âõ∞ÈöæÔºåÂØπ‰∫éÁã¨Â±ÖÁöÑËÄÅÂπ¥‰∫∫Êù•ËØ¥ÔºåËøôÁßçÊÉÖÂÜµÊõ¥‰∏∫‰∏•Èáç„ÄÇËôΩÁÑ∂ÂØπ‰∫éËÆ∏Â§öËÄÅÂπ¥ÁæéÂõΩ‰∫∫Êù•ËØ¥ÔºåÁÆ°ÁêÜËçØÁâ©„ÄÅÂ∞±ÂåªÂíåÊï¥‰ΩìÂÅ•Â∫∑Êàê‰∏∫‰∫Ü‰∏ÄÈ°πÊåëÊàò„ÄÇ‰ΩÜÊòØÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™‰º¥‰æ£‚Äî‚Äî‰∏Ä‰∏™ËÉΩÂ∏ÆÂä©‰Ω†ÊåâÊó∂ÂêÉËçØ„ÄÅÂú®‰Ω†ÊÑüÂà∞Â≠§Áã¨Êó∂Áªô‰Ω†ÊâìÁîµËØùÔºåÁîöËá≥ËØ¢ÈóÆ‰Ω†ËøëÂÜµÁöÑ‰∫∫Ôºå‰Ω†‰ºöÊÄé‰πàÊÉ≥Âë¢ÔºüËøôÂ∞±ÊòØËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÊâãÁöÑÈ≠ÖÂäõÔºåÂÆÉ‰ª¨Ê≠£Âú®‰∏∫ËÄÅÂπ¥‰∫∫ÁöÑÂåªÁñó‰øùÂÅ•Â∏¶Êù•Èù©ÂëΩÊÄßÁöÑÂèòÂåñ„ÄÇ\n\nÂÉè [**MiiHealth.ai**](https://miihealth.ai/) ËøôÊ†∑ÁöÑÂÖ¨Âè∏Â§Ñ‰∫éÂàõÂª∫Êô∫ËÉΩÁöÑ„ÄÅÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑ‰º¥‰æ£ÁöÑÂâçÊ≤øÔºåÂÆÉ‰ª¨Â∏ÆÂä©ËÄÅÂπ¥‰∫∫Ëß£ÂÜ≥ÂÅ•Â∫∑ÈóÆÈ¢òÔºåÂπ∂Â∞Ü‰ªñ‰ª¨‰∏é‰∫≤‰∫∫ËÅîÁ≥ªËµ∑Êù•„ÄÇÁé∞Âú®ÔºåËÆ©Êàë‰ª¨Êù•ÁúãÁúãËøô‰∫õËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÊâãÊòØÂ¶Ç‰ΩïÊîπÂèòÁã¨Â±ÖËÄÅÂπ¥‰∫∫ÁöÑÁîüÊ¥ªÁöÑÔºå‰ª•Âèä‰∏∫‰ªÄ‰πàÂÆÉ‰ª¨Âú®ËÄÅÂπ¥‰∫∫Êä§ÁêÜ‰∏≠ËøÖÈÄüÂèòÂæó‰∏çÂèØÊàñÁº∫„ÄÇ\n\n## ‰ªÄ‰πàÊòØËôöÊãüÂÅ•Â∫∑Âä©ÊâãÔºü\n\nËôöÊãüÂÅ•Â∫∑Âä©ÊâãÊòØ‰∏ÄÁßçÂØπËØù‰ª£ÁêÜÔºå‰∏ìÈó®Áî®‰∫éÂ∏ÆÂä©‰∫∫‰ª¨Â§ÑÁêÜ‰ªñ‰ª¨ÁöÑÂÅ•Â∫∑ÈóÆÈ¢ò„ÄÇËøô‰∫õÂä©ÊâãÂèØ‰ª•‰∏éÁî®Êà∑‰∫íÂä®ÔºåÊèê‰æõÂÅ•Â∫∑‰ø°ÊÅØ„ÄÅËçØÁâ©Êó∂Èó¥Ë°®ÔºåÂπ∂Âú®ÊÇ£ËÄÖÊÑüÂà∞‰∏çÁü•ÊâÄÊé™Êó∂Êèê‰æõÂÆâÊÖ∞„ÄÇÂÆÉ‰ª¨ÂèØ‰ª•ÊâßË°åËØ∏Â¶ÇÊ£ÄÊü•ÊÇ£ËÄÖË°ÄÂéã„ÄÅÊé®ËçêÈîªÁÇºÔºåÁîöËá≥‰ªÖ‰ªÖ‰∏éÊÇ£ËÄÖËÅäÂ§©Á≠âÊìç‰ΩúÔºåÊâÄÊúâËøô‰∫õÈÉΩÂèØ‰ª•ÈÄöËøáËØ≠Èü≥ÊéßÂà∂ÊàñÁü≠‰ø°ËøõË°å„ÄÇ\n\n\n\nÂØπ‰∫é‰ªª‰ΩïÈù¢‰∏¥Áã¨Ëá™ËÄÅÂéªËøô‰∏ÄËâ∞Èöæ‰ªªÂä°ÁöÑ‰∫∫Êù•ËØ¥ÔºåËøô‰∫õÂä©Êâã‰∏ç‰ªÖÊòØÈ´òÁßëÊäÄÂ∞èÂ∑•ÂÖ∑ÔºåÊõ¥ÊòØÂú®ÂÅ•Â∫∑ÂíåÂπ∏Á¶èÊñπÈù¢ÁöÑÁúüÊ≠£‰ºô‰º¥ÔºåÊó†ËÆ∫ÁôΩÂ§©ËøòÊòØÈªëÂ§ú„ÄÇÂØπ‰∫éÈúÄË¶ÅÊé•Êî∂ÁÆÄÁü≠‰ø°ÊÅØÊàñÁ¥ßÊÄ•ÂëºÂè´ÁöÑËÄÅÂπ¥‰∫∫Ôºå[**ËôöÊãüÂÅ•Â∫∑Âä©Êâã**](https://miihealth.ai/)ÂèØ‰ª•Êèê‰æõÂ∏ÆÂä©„ÄÇ\n\n## ‰∏∫‰ªÄ‰πàËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÁêÜÂØπËÄÅÂπ¥‰∫∫Êù•ËØ¥ÊòØ‰∏Ä‰∏™Ê∏∏ÊàèÊîπÂèòËÄÖ\n\nÂçïË∫´Âπ∂‰∫´ÂèóËÄÅÂπ¥ÁîüÊ¥ªÂ∏¶Êù•‰∫ÜÁâπÂà´ÁöÑÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁæéÂõΩÔºåËÄÅÂπ¥‰∫∫Èù¢‰∏¥ÁöÑÂõ∞ÈöæÊõ¥‰∏∫Á™ÅÂá∫„ÄÇ‰ªéÂ§ÑÁêÜÂ§çÊùÇÁöÑÂÅ•Â∫∑Êó•Á®ãÂà∞Â∫îÂØπÂ≠§Áã¨ÔºåÂÆ∂Â∫≠ÂØπÂ∏ÆÂä©ÁöÑÈúÄÊ±ÇÊØî‰ª•ÂæÄÊõ¥È´ò„ÄÇËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÁêÜÂèØ‰ª•ÈÄöËøáÂ§öÁßçÂΩ±ÂìçÊ∑±ËøúÁöÑÊñπÂºèÊèê‰æõËøôÁßçÊîØÊåÅÔºö\n\n**1\\. ËçØÁâ©ÁªÑÁªá‰∏éË∑üË∏™**\n\nÊÇ£ÊúâÊÖ¢ÊÄßÁóÖÁöÑÊÇ£ËÄÖÔºåÂ¶ÇERÔºåÈúÄÊúâÊïàÁÆ°ÁêÜËçØÁâ©‰ª•Ëé∑ÂæóÊúÄ‰Ω≥ÊïàÊûú„ÄÇÊú™ËÉΩÂú®Ê≠£Á°ÆÁöÑÊó∂Èó¥ÊúçÁî®ËçØÁâ©ÊàñÊúçÁî®ÈîôËØØÁöÑËçØÁâ©ÂèØËÉΩÂØºËá¥‰∏•ÈáçÂêéÊûú„ÄÇ‰Ωú‰∏∫ËôöÊãüÊä§ÁêÜÂä©ÁêÜÔºåÂèØ‰ª•ÊèêÈÜíËÄÅÂπ¥‰∫∫ÊåâÊó∂ÊúçËçØÔºå‰ªéËÄå‰Ωø‰ªñ‰ª¨ÈÅµÂæ™ÊâÄÈúÄÁöÑËçØÁâ©Êó∂Èó¥Ë°®„ÄÇËøô‰∫õÊèêÈÜíÂèØ‰ª•Ê†πÊçÆ‰∏™‰∫∫ÁöÑÊó∂Èó¥Ë°®ÂíåÁâπÂÆöËçØÁâ©ÁöÑÂâÇÈáèËøõË°åË∞ÉÊï¥„ÄÇ\n\nÈô§‰∫ÜÊèêÈÜíÔºåËøô‰∫õÂä©ÁêÜAIËøòÂèØ‰ª•Â∏ÆÂä©ËßÇÂØüÊâÄÊúçËçØÁâ©ÁöÑÂâØ‰ΩúÁî®ÂíåÁóáÁä∂ÁöÑÂá∫Áé∞Ôºå‰ªéËÄåÂáèËΩªÂØπËÄÅÂπ¥‰∫∫ÂèäÂÖ∂‰∫≤Â±ûÁöÑÁÖßÈ°æË¥üÊãÖ„ÄÇ‰æãÂ¶ÇÔºåÂΩìËÄÅÂπ¥‰∫∫ÊúçÁî®ÊäóÈ´òË°ÄÂéãËçØÁâ©ÊàñÁ≥ñÂ∞øÁóÖËçØÁâ©Êó∂ÔºåÂä©ÁêÜÂèØ‰ª•ËØ¢ÈóÆ‰ªñ‰ª¨ÁöÑÂÅ•Â∫∑Áä∂ÂÜµÔºåÂπ∂Âª∫ËÆÆÁõëÊµãË°ÄÂéãÁöÑÊó∂Èó¥„ÄÇ\n\n**2\\. 24/7ÂèØÁî®ÊÄß‰∏éÊîØÊåÅ**\n\nËÆ∏Â§ö‰∫∫ÂñúÊ¨¢ËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÁêÜÁöÑ‰∏Ä‰∏™ÁâπÁÇπÊòØÂÆÉÈöèÊó∂ÂèØÁî®ÔºöÊó†ËÆ∫ÁôΩÂ§©ËøòÊòØÊôö‰∏ä„ÄÇËøôÂØπ‰∫éÈÇ£‰∫õÂèØËÉΩÊÑüÂà∞Â≠§Áã¨ÊàñÁÑ¶ËôëÁöÑËÄÅÂπ¥‰∫∫Â∞§ÂÖ∂ÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∏ªË¶ÅÁÖßÈ°æËÄÖÂèØËÉΩÊ≠£Âú®Áù°ËßâÁöÑÊó∂ÊÆµ„ÄÇ‰ªéËß£ÈáäÊúÄËøëÁöÑÂèòÂåñÂà∞Âú®Ê≤°ÊúâÂÖ∂‰ªñËØùÈ¢òÊó∂ËøõË°å‰∫§Ë∞àÔºåËøô‰∫õÂä©ÁêÜÈÉΩÂú®Êèê‰æõÂ∏ÆÂä©„ÄÇ\n\nÂØπ‰∫éÈÇ£‰∫õÂú®ÊØèÂ§©ÁâπÂÆöÊó∂ÂàªÊ≤°Êúâ‰∫∫ÊàñÂÖ∂‰ªñÂèØ‰ª•‰æùËµñÁöÑ‰∫ãÁâ©ÁöÑËÄÅÂπ¥‰∫∫Êù•ËØ¥ÔºåÁªèÊµé‰æùËµñÂ∞§ÂÖ∂ÈáçË¶Å„ÄÇÊ≠§Â§ñÔºåËøô‰∫õÂä©ÁêÜÂèØ‰ª•ÂõûÁ≠îËÆ∏Â§öÈóÆÈ¢òÔºåËß£ÂÜ≥ÁÆÄÂçïÊàñÂ§çÊùÇÁöÑÂÅ•Â∫∑ÈóÆÈ¢òÔºåËÄåÊó†ÈúÄÈ¢ÑÁ∫¶ÊàñÂØªÊ±ÇÂä©ÁêÜÁöÑÂ∏ÆÂä©„ÄÇ\n\n**3\\. Á¥ßÊÄ•Ë≠¶Êä•ÂÅ•Â∫∑ÁõëÊµã**\n\nËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÁêÜÁöÑÂè¶‰∏Ä‰∏™‰ºòÂäøÊòØÂÆÉ‰ª¨ÂèØ‰ª•ÈöèÊó∂Ë∑üË∏™ËÄÅÂπ¥‰∫∫ÁöÑÂÅ•Â∫∑Áä∂ÂÜµÂπ∂ÂØπÂç±Êú∫‰ΩúÂá∫ÂèçÂ∫î„ÄÇ‰æãÂ¶ÇÔºåÂ§ßÂ§öÊï∞AIÂä©ÁêÜÂèØ‰ª•‰∏éË∑üË∏™ËÆæÂ§áÔºàÂ¶ÇÊâãËÖïÂ∏¶ÊàñÊâãË°®ÔºâÈõÜÊàêÔºåÁõëÊµãËÑâÊêè„ÄÅË°ÄÂéãÔºåÁîöËá≥Ë∑åÂÄíÊÉÖÂÜµ„ÄÇËøôËøò‰ΩøÂä©ÁêÜËÉΩÂ§üÂú®ËÄÅÂπ¥‰∫∫Ë∑åÂÄíÊàñÂá∫Áé∞ÁñæÁóÖËøπË±°Êó∂‰∏éÂÖ∂‰ªñ‰∫∫Ê≤üÈÄö„ÄÇ\n\nËøôÂØπ‰∫éÈÇ£‰∫õÂú®Á¥ßÊÄ•ÊÉÖÂÜµ‰∏ãÂèØËÉΩÊó†Ê≥ïËé∑ÂæóÂ∏ÆÂä©ÁöÑËÄÅÂπ¥‰∫∫Â∞§‰∏∫ÈáçË¶Å„ÄÇÊó†ËÆ∫ÊòØË∑åÂÄí„ÄÅÂÅ•Â∫∑Ê£ÄÊü•ÂºÇÂ∏∏ÔºåËøòÊòØÊÑüÂà∞‰∏çÈÄÇÔºåÂä©ÁêÜÈÉΩËÉΩÊèê‰æõÈ¢ùÂ§ñÁöÑÂÆâÂÖ®‰øùÈöú„ÄÇ\n\n**4\\. Áã¨ÁâπÁöÑÂÅ•Â∫∑‰ø°ÊÅØ‰∏éÂÅ•Ë∫´Âª∫ËÆÆ**\n\nÊØè‰∏™‰∫∫ÁöÑÂÅ•Â∫∑ÈúÄÊ±ÇÈÉΩÊòØÁã¨ÁâπÁöÑÔºåËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÁêÜÂèØ‰ª•Êèê‰æõÁ¨¶ÂêàËøô‰∫õÈúÄÊ±ÇÁöÑÂ∏ÆÂä©„ÄÇÂØπ‰∫éËÄÅÂπ¥‰∫∫Êù•ËØ¥ÔºåËøôÂèØËÉΩÊÑèÂë≥ÁùÄÂª∫ËÆÆÂì™‰∫õËøêÂä®ÂØπÂÖ≥ËäÇÁöÑÂéãÂäõËæÉÂ∞èÔºåÊàñÂª∫ËÆÆÂì™‰∫õÈ£üÁâ©ÂØπÁ≥ñÂ∞øÁóÖÊàñÂøÉËÑèÁóÖÁ≠âÁâπÂÆöÁñæÁóÖÊúâÁõä„ÄÇ\n\n‰∏éÈúÄË¶Å‰∏çÊñ≠ÈáçÊñ∞ÂÆâË£ÖÁöÑÂ∏∏ËßÑÁ®ãÂ∫è‰∏çÂêåÔºåËøô‰∫õÂä©ÁêÜË¢´ÁºñÁ®ã‰∏∫‰ªéÁî®Êà∑ÈÇ£ÈáåÂ≠¶‰π†Ôºå‰ªéËÄå‰ΩøÂÖ∂ÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªÂèòÂæóÊõ¥Âä†Êô∫ËÉΩ„ÄÇÂÆÉ‰ª¨‰øùÊåÅÁÅµÊ¥ªÔºå‰ª•Êª°Ë∂≥ËÄÅÂπ¥‰∫∫ÁöÑÈúÄÊ±ÇÔºåÁõëÊµãÂÖ∂ËøõÂ±ïÔºåÁîöËá≥Êèê‰æõÊúâÂÖ≥‰∏™‰∫∫Áä∂ÂÜµÁöÑÂª∫ËÆÆ„ÄÇ\n\n**5\\. ÁºìËß£Â≠§Áã¨ÂíåÂ¢ûÂº∫ÂøÉÁêÜÂÅ•Â∫∑ÁöÑ‰∏ªË¶ÅÊñπÂºè„ÄÇ**\n\nËÄÅÂπ¥‰∫∫ÊôÆÈÅçÂ≠òÂú®ÁöÑÂ≠§Áã¨ÊÑüÂèäÂÖ∂ÂØπ‰∏™‰∫∫ÂÅ•Â∫∑ÁöÑÂΩ±Âìç‰πüÂèØËÉΩÊòØ‰∏Ä‰∏™ÈóÆÈ¢ò„ÄÇËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÁêÜÂèØ‰ª•ËÆæËÆ°ÊàêÂú®ËÄÅÂπ¥‰∫∫ÊÑüÂà∞Â≠§Áã¨Êó∂Êèê‰æõÊüêÁßçÂΩ¢ÂºèÁöÑÈô™‰º¥Ôºå‰ªñ‰ª¨ÂèØ‰ª•‰∏éËôöÊãüÂÅ•Â∫∑Âä©ÁêÜËøõË°åÂØπËØù„ÄÇÂõ†Ê≠§ÔºåÂä©ÁêÜÂπ∂‰∏çÊòØ‰∏é‰ªñ‰∫∫Á§æ‰∫§‰∫íÂä®ÁöÑÊõø‰ª£ÂìÅÔºåÂ∞ΩÁÆ°ËØ•Â∑•ÂÖ∑ÂèØ‰ª•ÂõûÂ∫îÁÆÄÂçïÁöÑ‰ø°ÊÅØÔºåËÆ≤Á¨ëËØùÔºåÂπ∂ÈºìÂä±Áî®Êà∑„ÄÇ\n\nÊüê‰∫õÂä©ÁêÜÊó®Âú®Â∏ÆÂä©ËÄÅÂπ¥‰∫∫‰∏éÊúãÂèãÂíåÂÆ∂‰∫∫Âª∫Á´ãÊúâÊÑè‰πâÁöÑ‰∫íÂä®ÔºåÊàñÂèÇ‰∏éËôöÊãüÊ¥ªÂä®„ÄÇÈ¶ñÂÖàÔºåAIÂ∑•ÂÖ∑Êèê‰æõÁ§æ‰∫§Èô™‰º¥ÔºõËÄÅÂπ¥‰∫∫ÈúÄË¶ÅÊÑüÂèóÂà∞Ë¢´Êé•ÂèóÂíåË¢´Áà±ÁöÑÊÑüËßâÔºå‰ª•‰øùÊåÅÂÅ•Â∫∑„ÄÇ\n\n## ‰∏∫‰ªÄ‰πà MiiHealth.ai ÊòØËÄÅÂπ¥‰∫∫ÁöÑÈ¶ñÈÄâ\n\nÂú®ËÄÉËôë‰ΩøÁî®ËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÊâãÊó∂ÔºåMiiHealth.ai Êòì‰∫é‰ΩøÁî®ÔºåÊäÄÊúØÈ©±Âä®ÔºåËÉΩÂ§üÊª°Ë∂≥ËÄÅÂπ¥ÂÆ¢Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ‰ª•‰∏ãÊòØ MiiHealth.ai Êàê‰∏∫ËÄÅÂπ¥‰∫∫È¶ñÈÄâÁöÑ‰∏Ä‰∫õÂéüÂõ†Ôºö\n\n* **ÁÆÄÂçï‰∏îÁõ¥ËßÇÁöÑÁïåÈù¢**ÔºöÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåMiiHealth ËΩØ‰ª∂ÁöÑËÆæËÆ°ÂØπÁî®Êà∑ÈùûÂ∏∏ÂèãÂ•Ω„ÄÇËÄÅÂπ¥‰∫∫‰πü‰∏çÈúÄË¶ÅÂÖ∑Â§á‰∏∞ÂØåÁöÑÊäÄÊúØÁü•ËØÜÂç≥ÂèØÊìç‰ΩúËØ•Âπ≥Âè∞„ÄÇËøôÊÑèÂë≥ÁùÄËØ≠Èü≥ÂëΩ‰ª§Á≥ªÁªü‰ΩøÂæóÂç≥‰ΩøÊòØÊäÄÊúØÁ¥†ÂÖªËæÉ‰ΩéÁöÑ‰∫∫‰πüËÉΩËΩªÊùæ‰ΩøÁî®„ÄÇ\n* **ÈáèË∫´ÂÆöÂà∂Êª°Ë∂≥ËÄÅÂπ¥‰∫∫ÈúÄÊ±Ç**ÔºöMiiHealth.ai ‰∏éÂÖ∂‰ªñÊú∫ÊûÑ‰∏çÂêåÔºåÂÆÉÊèê‰æõÈíàÂØπËÄÅÂπ¥‰∫∫ÂÅ•Â∫∑ÁöÑÊúçÂä°ÔºåÂπ∂ÁêÜËß£ÂÖ∂ÊúçÂä°ÂøÖÈ°ª‰∏™ÊÄßÂåñ„ÄÇÂÆÉÂØπÊâÄÊúâÁî®Êà∑ÈÉΩÂÖ∑Â§áÁÅµÊ¥ªÊÄßÔºõÂèØ‰ª•ÊèêÈÜíÊüê‰∫∫‰ΩïÊó∂ÊúçËçØÔºå‰πüÂèØ‰ª•ÂëäÁü•Âè¶‰∏Ä‰∫∫‰ΩïÊó∂ÈîªÁÇº„ÄÇ\n* **ÊÉÖÊÑüÊîØÊåÅ**ÔºöÊ≠§Â§ñÔºåÈô§‰∫ÜÊª°Ë∂≥Ë∫´‰ΩìÈúÄÊ±ÇÔºåMiiHealth.ai ËøòÂÖ∑ÊúâÊÉÖÊÑüÂíåÁ§æ‰ºöÊîØÊåÅÁöÑÂäüËÉΩÔºå‰ª•ÂáèËΩªËÆ∏Â§öÁã¨Â±ÖËÄÅÂπ¥‰∫∫ÊâÄÊÑüÂèóÂà∞ÁöÑÂ≠§Áã¨ÊÑü„ÄÇ\n* **ÂÖ®Èù¢ÂÅ•Â∫∑ÁõëÊµã**ÔºöÈÄöËøáËøûÊé•ÂèØÁ©øÊà¥ÂÅ•Â∫∑ËÆæÂ§áÔºåMiiHealth.ai ÂÆöÊúüÁõëÊµãËÄÅÂπ¥‰∫∫ÁöÑÁîüÂëΩ‰ΩìÂæÅÔºåÂπ∂Âú®ÂøÖË¶ÅÊó∂ÂèëÂá∫ÈÄöÁü•„ÄÇ\n\n## ÁªìËÆ∫\n\nÂêåÊ†∑ÔºåÂØπ‰∫éËÄÅÂπ¥ÁæéÂõΩ‰∫∫Êù•ËØ¥ÔºåÂçïË∫´Âπ∂‰∏ç‰∏ÄÂÆöÊÑèÂë≥ÁùÄÁº∫‰πèÁª¥ÊåÅÂÅ•Â∫∑ÂíåÂø´‰πêÁîüÊ¥ªÊàñÂ∫îÂØπÁñæÁóÖÁöÑÁÖßÊä§„ÄÇÂú®ËøôÊñπÈù¢ÔºåËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÊâãÂ¶Ç MiiHealth.ai ‰∏∫‰∫∫‰ª¨Êèê‰æõ‰∫ÜÈ´òÊïàÁöÑÂ∑•ÂÖ∑Ôºå‰Ωø‰ªñ‰ª¨ËÉΩÂ§üÊé•Ëß¶Âà∞ÊúÄÂÖàËøõÁöÑ AI ÊäÄÊúØ‰ª•ÂèäÈ´òÂ∫¶‰∏™ÊÄßÂåñÁöÑÂåªÁñóÊîØÊåÅ„ÄÇ\n\nÂú®ÁÆ°ÁêÜËçØÁâ©ÂíåÂèëÂá∫Á¥ßÊÄ•Ë≠¶Êä•Ôºå‰ª•ÂèäÊèê‰æõÂÖ≥‰∫éÂÅ•Â∫∑ÁöÑÂØπËØùÂíåÂª∫ËÆÆÊñπÈù¢ÔºåËøô‰∫õÂä©ÊâãÊ≠£Âú®ÊîπÂèòËÄÅÂπ¥‰∫∫ÁöÑÂåªÁñó‰øùÂÅ•Èù¢Ë≤å„ÄÇÊó†ËÆ∫ÊòØÁî®‰∫éÊïôËÇ≤„ÄÅÊîØÊåÅËøòÊòØÈô™‰º¥ÔºåËôöÊãüÂÅ•Â∫∑Êä§ÁêÜÂä©ÊâãÈÉΩ‰∏∫ËÄÅÂπ¥‰∫∫Â∏¶Êù•‰∫ÜÂÖ≥ÊÄÄÔºåÁ°Æ‰øù‰ªñ‰ª¨‰øùÊåÅÁã¨Á´ã„ÄÅËøûÊé•ÂíåÂÅ•Â∫∑„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ÊàñÊÇ®ÂÆ∂‰∏≠ÁöÑÊüê‰∫∫ÈúÄË¶ÅÂèØÈù†ÂíåÂÖ≥ÊÄÄÁöÑÂÅ•Â∫∑Áõ∏ÂÖ≥‰∏™‰∫∫Âä©ÊâãÔºåÊÇ®Â∫îËØ•ÁÜüÊÇâ [MiiHealth.ai](http://miihealth.ai)„ÄÇËøôÊòØ‰∏∫Áã¨Â±ÖËÄÅÂπ¥‰∫∫ÈÄöÂêëÊõ¥Â•ΩÂíåÂÖÖÂÆûÁîüÊ¥ªÁöÑ‰∏ÄÊù°‰æøÊç∑‰πãË∑Ø„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-focus-is-shifting-from-ai-agents-to-ai-agent-tool-use-a84fc061eec8","frontmatter":{"title":"ÁÑ¶ÁÇπÊ≠£‰ªé‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜËΩ¨Âêë‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®","meta_title":"ÁÑ¶ÁÇπÊ≠£‰ªé‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜËΩ¨Âêë‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®","description":"ÊñáÁ´†Êé¢ËÆ®‰∫ÜAI‰ª£ÁêÜÁöÑÂÖ≥Ê≥®ÁÇπËΩ¨ÂêëÂ¢ûÂº∫ÂÖ∂‰ΩøÁî®Â∑•ÂÖ∑ÁöÑËÉΩÂäõÔºåËøô‰∫õÂ∑•ÂÖ∑ÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞Âπ∂ÊøÄÊ¥ª‰ª£ÁêÜÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇOpenAIÂíåAnthropicÁ≠âÂÖ¨Âè∏Ê≠£Âú®ÂºÄÂèëËÉΩÂ§üÂú®ËÆ°ÁÆóÊú∫‰∏äËá™‰∏ªÊâßË°å‰ªªÂä°ÁöÑAI‰ª£ÁêÜÔºåÊó®Âú®ÊèêÈ´òÂ§öÊ≠•È™§Â∑•‰ΩúÊµÅÁ®ãÁöÑÁÆ°ÁêÜËÉΩÂäõ„ÄÇAnthropicÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèÇËÄÉÂÆûÁé∞ÔºåÂ±ïÁ§∫‰∫ÜAI‰ª£ÁêÜÂ¶Ç‰Ωï‰∏éËÆ°ÁÆóÊú∫ÁéØÂ¢É‰∫§‰∫íÔºåÂåÖÊã¨GUIÊìç‰ΩúÂíåÂëΩ‰ª§Ë°åÂäüËÉΩÔºåÂº∫Ë∞É‰∫ÜÂú®ÂèóÊéßÁéØÂ¢É‰∏≠ÁÅµÊ¥ªËøêÁî®Â∑•ÂÖ∑ÁöÑÁ≠ñÁï•„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7IELtMakzcc68bdb4usXBQ.png","categories":["Programming","Technology","Autonomous Systems"],"author":"Rifx.Online","tags":["Operator","GUI","Navigation","Command","File"],"draft":false,"slug":"blog/the-focus-is-shifting-from-ai-agents-to-ai-agent-tool-use-a84fc061eec8"},"content":"\n\n\n\n\n### ÂÖ≥‰∫éAI‰ª£ÁêÜÁöÑÂÖ≥Ê≥®ÁÇπÊ≠£Âú®‰ªéÂçïÁ∫ØÂºÄÂèëËá™‰∏ªAI‰ª£ÁêÜËΩ¨ÂêëÂ¢ûÂº∫ÂèØ‰æõÂÆÉ‰ª¨‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑ÔºåËøôÁõ¥Êé•ÂΩ±ÂìçÂà∞ÂÆÉ‰ª¨ÁöÑËÉΩÂäõÂíåÁÅµÊ¥ªÊÄß„ÄÇ\n\nAI‰ª£ÁêÜÁöÑÂäüËÉΩÂíåËåÉÂõ¥Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùËµñ‰∫éÂ∑•ÂÖ∑ÁöÑËÆøÈóÆÔºåÂ∑•ÂÖ∑‰ª•Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞ÔºåÂπ∂ÈÄöËøá‰ª£ÁêÜÁöÑÂÜÖÈÉ®Êé®ÁêÜÊøÄÊ¥ª„ÄÇ\n\nÊ°åÈù¢ÂíåÂÖ∂‰ªñÁî®Êà∑ÁâπÂÆöÁéØÂ¢ÉÊèê‰æõ‰∫Ü‰ª£ÁêÜÊúâÊïàÊâßË°å‰ªªÂä°ÊâÄÈúÄÁöÑ‰∏∞ÂØå‰∏ä‰∏ãÊñáÔºå‰ΩøÂÆÉ‰ª¨Êàê‰∏∫ÁêÜÊÉ≥ÁöÑÊìç‰ΩúÁ©∫Èó¥„ÄÇ\n\n## ‚ú®‚ú® Âú® LinkedIn ‰∏äÂÖ≥Ê≥®Êàë ‚ú®‚ú®\n\n## ‰ªãÁªç\n\nÈöèÁùÄÊ®°ÂûãÊàê‰∏∫ÂÆûÁî®Â∑•ÂÖ∑ÔºåÂêØÁî®Â∑•ÂÖ∑ÁöÑÊ°ÜÊû∂ÂíåÁéØÂ¢ÉÊ≠£Âú®Êàê‰∏∫ÂÖ≥ÈîÆÔºåÈ¢ÜÂÖàÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂÖ¨Âè∏Â¶ÇOpenAIÂíåAnthropicÊ≠£Âú®Êé¢Á¥¢‰ΩøÁî®ËÆ°ÁÆóÊú∫GUIÂØºËà™Êù•ÂÆåÊàêÂ§çÊùÇ‰ªªÂä°ÁöÑAI‰ª£ÁêÜ„ÄÇ\n\nOpenAIÊúÄËøëÂÆ£Â∏ÉÔºåÂáÜÂ§áÂèëÂ∏É‰∏ÄÊ¨æ**AI‰ª£ÁêÜ**Ôºå*Operator*ÔºåÂÆÉÂ∞ÜÂú®Áî®Êà∑ÁöÑËÆ°ÁÆóÊú∫‰∏äËá™‰∏ªÊâßË°å‰ªªÂä°ÔºåÂ¶ÇÁºñÁ†ÅÂíåÈ¢ÑËÆ¢ÊóÖË°åÔºåÂπ∂Â∞ÜÂú®1Êúà‰Ωú‰∏∫Á†îÁ©∂È¢ÑËßàÁâàÊé®Âá∫„ÄÇ\n\nËøô‰∏ÄÂèëÂ∏É‰∏éÊï¥‰∏™Ë°å‰∏öÂêëÊõ¥Âº∫Â§ßÁöÑ**‰ª£ÁêÜÂ∑•ÂÖ∑**ËΩ¨ÂèòÁöÑË∂ãÂäø‰∏ÄËá¥ÔºåËøô‰∫õÂ∑•ÂÖ∑ËÉΩÂ§üÂú®ÊúÄÂ∞ëÁõëÁù£‰∏ãÁÆ°ÁêÜÂ§öÊ≠•È™§Â∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\nÂÖ∂‰ªñ‰∏ªË¶ÅÂèÇ‰∏éËÄÖ‰πüÂú®Êé®Âá∫ËÉΩÂ§üÂÆûÊó∂ËÆ°ÁÆóÊú∫ÂØºËà™ÁöÑ‰ª£ÁêÜÂ∑•ÂÖ∑ÔºåËøôÂèçÊò†Âá∫ÈÄöËøáÂ∑•ÂÖ∑ËÆøÈóÆÂ¢ûÂº∫AI‰ª£ÁêÜËÉΩÂäõÁöÑÊàòÁï•ÊÄß‰∏æÊé™ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÊèêÈ´òÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*q7YvQLqfVdhV3bZM2oflDQ.png)\n\n## ‰∫∫Â∑•Êô∫ËÉΩËÆ°ÁÆóÊú∫‰ΩøÁî®\n\nAnthropic Êèê‰æõ‰∫Ü‰∏Ä‰∏™ [ÂèÇËÄÉÂÆûÁé∞](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫ÜÊÇ®Âø´ÈÄüÂºÄÂßãËÆ°ÁÆóÊú∫‰ΩøÁî®ÊâÄÈúÄÁöÑ‰∏ÄÂàá„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vD4T4Bo2-JcH535TOc46BQ.png)\n\n‰∏äÈù¢ÁöÑÂõæÂÉèÊòæÁ§∫‰∫ÜÂú®ÊàëÁöÑÊ°åÈù¢‰∏äËøêË°åÁöÑ AI ‰ª£ÁêÜÔºåÊàëÈúÄË¶ÅÂú®ÊàëÁöÑ MacBook ‰∏äÂÆâË£Ö Docker Âπ∂Â∞Ü Docker ÈïúÂÉèÈÉ®ÁΩ≤Âà∞ÊàëÁöÑÊú∫Âô®‰∏ä„ÄÇ\n\n‰∏ãÈù¢ÁöÑËÑöÊú¨Â∞±ÊòØÊÇ®ÊâÄÈúÄÁöÑÂÖ®ÈÉ®ÂÜÖÂÆπÔºå‰ª•ÈÉ®ÁΩ≤ÂÆû‰æãÂπ∂‰ΩøÂÖ∂Ê≠£Â∏∏ËøêË°å„ÄÇ\n\n```python\nexport ANTHROPIC_API_KEY=%your_api_key%\ndocker run \\\n    -e ANTHROPIC_API_KEY=<Your Anthropic API Key Goes Here> \\\n    -v $HOME/.anthropic:/home/computeruse/.anthropic \\\n    -p 5900:5900 \\\n    -p 8501:8501 \\\n    -p 6080:6080 \\\n    -p 8080:8080 \\\n    -it ghcr.io/anthropics/anthropic-quickstarts:computer-use-demo-latest\n```\n‰∏ãÈù¢ÊòØÊàëËøêË°åÊñá‰ª∂ÁöÑÁªàÁ´ØÁ™óÂè£ÁöÑÊà™Âõæ‚Ä¶\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mTu4gGEwnFbQYqJ-YGYqIA.png)\n\nËØ•ÂÆûÁé∞ÂåÖÊã¨Ôºö\n\n* ‰∏Ä‰∏™ÈÄÇÁî®‰∫é‰∏é Claude ËøõË°åËÆ°ÁÆóÊú∫‰ΩøÁî®ÁöÑ [ÂÆπÂô®ÂåñÁéØÂ¢É](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/Dockerfile)\n* [ËÆ°ÁÆóÊú∫‰ΩøÁî®Â∑•ÂÖ∑](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/computer_use_demo/tools) ÁöÑÂÆûÁé∞\n* ‰∏Ä‰∏™‰∏é Anthropic API ‰∫§‰∫íÂπ∂ÊâßË°åËÆ°ÁÆóÊú∫‰ΩøÁî®Â∑•ÂÖ∑ÁöÑ [‰ª£ÁêÜÂæ™ÁéØ](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/computer_use_demo/loop.py)\n* ‰∏Ä‰∏™‰∏éÂÆπÂô®„ÄÅ‰ª£ÁêÜÂæ™ÁéØÂíåÂ∑•ÂÖ∑‰∫§‰∫íÁöÑÁΩëÈ°µÁïåÈù¢„ÄÇ\n\n## Anthropic AI Agent ËØ¶ÁªÜ‰ø°ÊÅØ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*euT2ZTmjVV5cTK-j8i4fgg.png)\n\nAnthropic **AI Agent** ÂèØ‰ª•ËÆøÈóÆ‰∏â‰∏™‰∏ªË¶ÅÁöÑ **Â∑•ÂÖ∑/ÂäüËÉΩ**Ôºå‰ΩøÊàëËÉΩÂ§ü‰∏é Ubuntu ËôöÊãüÊú∫ÁéØÂ¢ÉËøõË°å‰∫§‰∫íÔºö\n\n### ËÆ°ÁÆóÊú∫ÂäüËÉΩÔºö\n\n* ËøôÊòØ‰∏éGUIÁéØÂ¢É‰∫§‰∫íÁöÑ‰∏ªË¶ÅÊé•Âè£\n* ÂÖÅËÆ∏AI‰ª£ÁêÜÊâßË°åÈº†Ê†áÂíåÈîÆÁõòÊìç‰ΩúÔºå‰æãÂ¶ÇÔºö\n* ÁßªÂä®ÂÖâÊ†á (`mouse_move`)\n* ÁÇπÂáª (`left_click`, `right_click`, `middle_click`, `double_click`)\n* ËæìÂÖ•ÊñáÊú¨ (`type`)\n* ÊåâÈîÆÁªÑÂêà (`key`)\n* Êà™Âõæ (`screenshot`)\n* ÊòæÁ§∫ÂàÜËæ®ÁéáËÆæÁΩÆ‰∏∫1024x768\n* ÊòæÁ§∫ÁºñÂè∑‰∏∫ :1\n* AI‰ª£ÁêÜÂú®ÁÇπÂáªÂÖÉÁ¥†‰πãÂâçÈúÄË¶ÅÈÄöËøáÊà™ÂõæÊ£ÄÊü•ÂùêÊ†á\n\n### bash ÂáΩÊï∞:\n\n* Áªô‰∫à AI Agent ËÆøÈóÆ bash shell ÁöÑÊùÉÈôê‰ª•ËøêË°åÂëΩ‰ª§\n* Áä∂ÊÄÅÂú®ÂëΩ‰ª§‰πãÈó¥‰øùÊåÅ\n* ÂèØ‰ª•ÈÄöËøá apt Âíå pip ÂÆâË£ÖËΩØ‰ª∂ÂåÖ\n* ÂèØ‰ª•ËøêË°åÂêéÂè∞ËøõÁ®ã\n* ÂØπ‰∫é GUI Â∫îÁî®Á®ãÂ∫èÔºåÈúÄË¶ÅËÆæÁΩÆ DISPLAY=:1 ÁéØÂ¢ÉÂèòÈáè\n\n### str\\_replace\\_editor ÂáΩÊï∞Ôºö\n\n* Êñá‰ª∂Êìç‰ΩúÂ∑•ÂÖ∑ÔºåÂÖÅËÆ∏Ôºö\n* Êü•ÁúãÊñá‰ª∂ÂíåÁõÆÂΩï (`view`)\n* ÂàõÂª∫Êñ∞Êñá‰ª∂ (`create`)\n* ÊõøÊç¢Êñá‰ª∂‰∏≠ÁöÑÊñáÊú¨ (`str_replace`)\n* Âú®ÁâπÂÆöË°åÊèíÂÖ•ÊñáÊú¨ (`insert`)\n* Êí§ÈîÄÁºñËæë (`undo_edit`)\n* Âú®Êìç‰Ωú‰πãÈó¥‰øùÊåÅÁä∂ÊÄÅ\n\n## ÈáçË¶ÅÁ∫¶Êùü\n\n* ‰∏çËÉΩÂú®Á§æ‰∫§Â™í‰Ωì/ÈÄöËÆØÂπ≥Âè∞‰∏äÂàõÂª∫Ë¥¶Êà∑\n* ‰∏çËÉΩÂú®Ê≤°ÊúâÁî®Êà∑ÂçèÂä©ÁöÑÊÉÖÂÜµ‰∏ãÂ§ÑÁêÜ CAPTCHA/reCAPTCHA\n* ‰∏çËÉΩÂú®Ê≤°ÊúâÁî®Êà∑ÊåáÁ§∫ÁöÑÊÉÖÂÜµ‰∏ãÂêåÊÑèÊúçÂä°Êù°Ê¨æ\n* ‰∏çËÉΩÂú®Á§æ‰∫§Â™í‰Ωì‰∏äÂèëÂ∏ÉËØÑËÆ∫/ÂèçÂ∫î\n* ‰∏çËÉΩËÆøÈóÆÈÄâÊ∞ëÊ≥®ÂÜåÊàñÈÄâ‰∏æÂü∫Á°ÄËÆæÊñΩÊï∞ÊçÆ\n\nÁ≥ªÁªüËøêË°åÂú® aarch64 Êû∂ÊûÑÁöÑ Ubuntu ËôöÊãüÊú∫‰∏äÔºåÊàëÈÄöËøá Docker ÂÆπÂô®Âú®ÊàëÁöÑÁ¨îËÆ∞Êú¨ÁîµËÑë‰∏äËøêË°åÂÆÉ„ÄÇ\n\nËøô‰∫õÂ∑•ÂÖ∑‰∏∫ AI Agent Êèê‰æõ‰∫Ü‰∏ÄÁßçÂèóÊéß‰ΩÜÁÅµÊ¥ªÁöÑÊñπÂºèÊù•‰∏éËôöÊãüÁéØÂ¢É‰∫íÂä®ÔºåÁªìÂêà‰∫Ü GUI ‰∫§‰∫í„ÄÅÂëΩ‰ª§Ë°åÊìç‰ΩúÂíåÊñá‰ª∂Êìç‰ΩúËÉΩÂäõ„ÄÇ\n\nÊàëÁöÑÁéØÂ¢ÉÂú®ÊØè‰∏™‰ºöËØù‰∏≠ÈÉΩÊòØÊñ∞ÂàùÂßãÂåñÁöÑÔºå‰ΩÜÂú®Â∑•ÂÖ∑Ë∞ÉÁî®‰πãÈó¥‰øùÊåÅÁä∂ÊÄÅ„ÄÇ\n\nAI Agent ÂèØ‰ª•ÈÄöËøá Firefox ‰ΩøÁî®‰∫íËÅîÁΩëÔºåÂπ∂Ê†πÊçÆÈúÄË¶ÅÈÄöËøáËΩØ‰ª∂ÂåÖÁÆ°ÁêÜÁ≥ªÁªüÂÆâË£ÖÈ¢ùÂ§ñÁöÑËΩØ‰ª∂„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4env1UkoKOZ-3zmF.png)\n\n[***È¶ñÂ∏≠Â∏ÉÈÅìËÄÖ***](https://www.linkedin.com/in/cobusgreyling/) ***@*** *[Kore.ai](https://blog.kore.ai/cobus-greyling) \\| ÊàëÁÉ≠Ë°∑‰∫éÊé¢Á¥¢‰∫∫Â∑•Êô∫ËÉΩ‰∏éËØ≠Ë®ÄÁöÑ‰∫§ÈõÜ„ÄÇ‰ªéËØ≠Ë®ÄÊ®°Âûã„ÄÅAI Agent Âà∞‰ª£ÁêÜÂ∫îÁî®„ÄÅÂºÄÂèëÊ°ÜÊû∂ÂíåÊï∞ÊçÆÈ©±Âä®ÁöÑÁîü‰∫ßÂäõÂ∑•ÂÖ∑ÔºåÊàëÂàÜ‰∫´Ëøô‰∫õÊäÄÊúØÂ¶Ç‰ΩïÂ°ëÈÄ†Êú™Êù•ÁöÑËßÅËß£ÂíåÊÉ≥Ê≥ï„ÄÇ*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4env1UkoKOZ-3zmF.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*4env1UkoKOZ-3zmF.png)\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-future-of-chatgpt-explained-everything-will-change-in-the-next-5-years-4bfd46ddca0b","frontmatter":{"title":"ChatGPT ÁöÑÊú™Êù•Ëß£ÊûêÔºöÊú™Êù• 5 Âπ¥‰∏ÄÂàáÈÉΩÂ∞ÜÊîπÂèò","meta_title":"ChatGPT ÁöÑÊú™Êù•Ëß£ÊûêÔºöÊú™Êù• 5 Âπ¥‰∏ÄÂàáÈÉΩÂ∞ÜÊîπÂèò","description":"OpenAIÂà∂ÂÆö‰∫Ü‰∏Ä‰∏™‰∫îÊ≠•Ë∑ØÁ∫øÂõæÔºå‰ª•ÂÆûÁé∞‰∫∫Â∑•ÈÄöÁî®Êô∫ËÉΩÔºàAGIÔºâ„ÄÇËØ•Ë∑ØÁ∫øÂõæÂåÖÊã¨‰∫î‰∏™Èò∂ÊÆµÔºöÁ¨¨‰∏ÄÁ∫ß‰∏∫ÂØπËØùÊú∫Âô®‰∫∫ÔºåÁ¨¨‰∫åÁ∫ß‰∏∫Êé®ÁêÜËÄÖÔºåËÉΩÂ§üËß£ÂÜ≥Â§çÊùÇÈóÆÈ¢òÔºõÁ¨¨‰∏âÁ∫ß‰∏∫Ëá™‰∏ªÂÜ≥Á≠ñÁöÑ‰ª£ÁêÜÔºõÁ¨¨ÂõõÁ∫ß‰∏∫ÂàõÊñ∞ËÄÖÔºåÊé®Âä®ÂàõÊñ∞ÔºõÁ¨¨‰∫îÁ∫ß‰∏∫ÁªÑÁªáÔºåËÉΩÂÉèÂõ¢Èòü‰∏ÄÊ†∑Ëøê‰Ωú„ÄÇÁõÆÂâçÔºåOpenAIÂ§Ñ‰∫éÁ¨¨‰∏ÄÁ∫ßÂíåÁ¨¨‰∫åÁ∫ß‰πãÈó¥ÔºåÈ¢ÑËÆ°Âú®‰∫îÂπ¥ÂÜÖÂÆûÁé∞AGIÔºå‰∏ã‰∏ÄÊ≠•ÂèØËÉΩÊòØ2025Âπ¥Êé®Âá∫ÁöÑGPT-5„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nCVwPhWiFZ_0lglxT4pDAw.jpeg","categories":["Chatbots","Artificial General Intelligence","Reasoners"],"author":"Rifx.Online","tags":["Chatbots","Reasoners","Agents","Innovators","Organizations"],"draft":false,"slug":"blog/the-future-of-chatgpt-explained-everything-will-change-in-the-next-5-years-4bfd46ddca0b"},"content":"\n\n\n## ËøôÂèØËÉΩ‰ºöËÆ©‰∫∫Â∑•Êô∫ËÉΩËµ∞ÂæóÊõ¥Ëøú‚Ä¶‚Ä¶\n\n\n\nOpenAIÂ∑≤ÁªèÂà∂ÂÆö‰∫Ü‰∏Ä‰∏™**Ê∏ÖÊô∞ÁöÑÊÑøÊôØ**ÔºåÊù•ÊåáÂØºChatGPTÁöÑÊºîÂèòÔºåÊúÄËøëÂÖ¨Â∏É‰∫Ü‰∏Ä‰∏™**‰∫îÊ≠•Ë∑ØÁ∫øÂõæ**Ôºå‰ª•ÂÆûÁé∞‰ªñ‰ª¨ÊâÄÁß∞ÁöÑ**‰∫∫Â∑•ÈÄöÁî®Êô∫ËÉΩ**ÔºàAGIÔºâ„ÄÇ\n\nAGI‰ª£Ë°®‰∏ÄÁßçÁêÜËÆ∫‰∏äÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÔºåËÉΩÂ§ü**Â≠¶‰π†**„ÄÅ**ÁêÜËß£**Âíå**ÊâßË°å‰ªª‰ΩïÊô∫Âäõ‰ªªÂä°**ÔºåÂÖ∂ËÉΩÂäõËææÂà∞‰∫∫Á±ªÊ∞¥Âπ≥Ôºå‰∏îÂÆåÂÖ®Ëá™‰∏ªÂíåÈÄÇÂ∫îÊÄßÂº∫„ÄÇ\n\nËøôÊòØ‰∏Ä‰∏™ÂºÄÂàõÊÄßÁöÑÊÑøÊôØÔºå‰ΩÜÂÆûÁé∞Ëøô‰∏ÄÈõÑÂøÉÂãÉÂãÉÁöÑÁõÆÊ†áÈúÄË¶ÅÁªèÂéÜ**‰∫î‰∏™ÂÖ≥ÈîÆÈò∂ÊÆµ**Ôºö\n\n## Level 1: ËÅäÂ§©Êú∫Âô®‰∫∫\n\nÁ¨¨‰∏ÄÁ∫ßÔºåÊàë‰ª¨ÁõÆÂâçÂèëÁé∞ÂÉè ChatGPT ËøôÊ†∑ÁöÑÁ≥ªÁªüÔºåÈõÜ‰∏≠‰∫é **ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ**„ÄÇÂú®Ëøô‰∏™Èò∂ÊÆµÔºå‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•‰∏é‰∫∫Á±ªËá™ÁÑ∂‰∫íÂä®ÔºåÂ§ÑÁêÜÂêÑÁßçÂØπËØùÔºåÂ±ïÁé∞Âá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊµÅÁïÖÊÄßÂíåËøûË¥ØÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ObzqCLMIIqpU9RK-TbTrfQ.png)\n\n## Level 2: Reasoners\n\nÂú®Ëøô‰∏™Èò∂ÊÆµÔºåAIÁ≥ªÁªüÂ∞ÜËÉΩÂ§ü**Ëß£ÂÜ≥Â§çÊùÇÈóÆÈ¢ò**ÔºåÊ∂âÂèäÈ´òÁ∫ßÊï∞Â≠¶ÂíåÈÄªËæë„ÄÇÊàë‰ª¨Â∑≤ÁªèÂú®ChatGPTÁöÑÊúÄÊñ∞ÁâàÊú¨‚Äúo1\\-preview‚Äù‰∏≠ÁúãÂà∞‰∫ÜËøô‰∏ÄÁÇπÔºåÂÆÉÊ†áÂøóÁùÄÁ¨¨1Á∫ßÂíåÁ¨¨2Á∫ß‰πãÈó¥ÁöÑÊ°•Ê¢ÅÔºåÁß∞‰∏∫‚ÄúÊé®ÁêÜ‚ÄùÈò∂ÊÆµ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*B42LqC8ZDSaSYPX4yd3_Ng.png)\n\n## Level 3: Agents\n\nËøôÊòØ‰∫∫Â∑•Êô∫ËÉΩÂºÄÂßã**Áã¨Á´ã**ÂÅöÂá∫ÂÜ≥Á≠ñÂíåÊâßË°å‰ªªÂä°ÁöÑÂ±ÇÁ∫ßÔºåÊó†ÈúÄ‰∫∫Á±ªÁõëÁù£„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ãÔºå‰∏Ä‰∏™‰∏ç‰ªÖ‰ªÖÊòØÂçèÂä©ÔºåËÄåÊòØ**Ëá™Êàë**ÂèëËµ∑Âπ∂ÂÆåÊàê‰ªªÂä°ÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‚Äî‚ÄîËøôÊòØÊú™Êù•ChatGPTÁâàÊú¨ÁöÑÊ¢¶ÊÉ≥„ÄÇ\n\n## Level 4: Innovators\n\n‰∏ÄÊó¶‰∫∫Â∑•Êô∫ËÉΩËææÂà∞‚ÄúÂàõÊñ∞ËÄÖ‚ÄùÁ∫ßÂà´ÔºåÂÆÉÂ∞ÜËÉΩÂ§ü**ÁßØÊûÅÂú∞**Êé®Âä®Âíå‰øÉËøõÂàõÊñ∞„ÄÇÊ≠§Êó∂Ôºå‰∫∫Â∑•Êô∫ËÉΩ‰∏ç‰ªÖ‰ªÖÊòØÈÅµÂæ™‰∫∫Á±ªÁöÑÊåá‰ª§ÔºõÂÆÉÂ∞Ü‰∏é‰∫∫Á±ªÂêà‰ΩúÔºåÊèêÂá∫Êñ∞ÊÉ≥Ê≥ï„ÄÇ\n\n## Level 5: ÁªÑÁªá\n\nÂú®ÊúÄÂêé‰∏ÄÁ∫ßÔºåAIÂ∞ÜÂÖ∑Â§á‰Ωú‰∏∫Êï¥‰∏™ÁªÑÁªáËøê‰ΩúÁöÑËÉΩÂäõ‚Äî‚ÄîËÉΩÂ§üÊâßË°å**Â∞±ÂÉèÊòØ‰∏ÄÊîØÁÜüÁªÉÁöÑÂõ¢Èòü**‰∏ÄÊ†∑ÁöÑ‰ªªÂä°„ÄÇËøô‰∏™Êú™Êù•ÁâàÊú¨ÁöÑAIÂ∞ÜÂÉè**‰∏Ä‰∏™ÂÆåÂÖ®Ëá™‰∏ªÁöÑÂïÜ‰∏öÂÆû‰Ωì**‰∏ÄÊ†∑Ëøê‰ΩúÔºåÂ§ÑÁêÜ‰ªéÊàòÁï•Âà∞ÊâßË°åÁöÑÊâÄÊúâ‰∫ãÂä°„ÄÇ\n\n## ÈÇ£‰πàÔºåÊàë‰ª¨Áé∞Âú®Â§Ñ‰∫é‰ªÄ‰πàÁä∂ÊÄÅÔºü\n\nOpenAI ÁõÆÂâçÂ§Ñ‰∫éÁ¨¨ 1 Á∫ßÂíåÁ¨¨ 2 Á∫ß‰πãÈó¥„ÄÇÊ†πÊçÆ OpenAI È¶ñÂ∏≠ÊâßË°åÂÆò Sam Altman ÁöÑËØ¥Ê≥ïÔºåËØ•ÂÖ¨Âè∏Êó®Âú®Â§ßÁ∫¶‰∫îÂπ¥ÂÜÖÂÆûÁé∞ AGI„ÄÇ\n\n‰∏ã‰∏Ä‰∏™‰∏ªË¶ÅÈáåÁ®ãÁ¢ëÂèØËÉΩ‰ºöÈöèÁùÄ‚ÄúÊé®ÁêÜÂô®‚ÄùÁöÑÂà∞Êù•ËÄåÊù•ÔºåÂèØËÉΩÊúÄÊó©Âú® 2025 Âπ¥Êé®Âá∫ÁöÑ **GPT\\-5**ÔºåÈ¢ÑËÆ°ËÉΩÂ§üËææÂà∞ **Â§ö‰∏™È¢ÜÂüüÂçöÂ£´ÁöÑÊô∫ÂäõÊ∞¥Âπ≥**„ÄÇ\n\nÊÑüË∞¢ÊÇ®ÁöÑÈòÖËØªÔºÅ\n\n**ÈôÑÊ≥®„ÄÇ** ÊÉ≥Ë¶Å‰∏Ä‰∏™ÈÖ∑ÁÇ´ÁöÑÊäÄÂ∑ßÔºàÂ∞±ÂÉèÈ≠îÊúØÂ∏àÁ∫ßÂà´ÁöÑÔºâÊù•ÁÆÄÂåñÊÇ®ÁöÑÊèêÁ§∫ÂÜô‰ΩúÂêóÔºü\n\nÊàëÊ≠£Â•ΩÊúâ **ÊÇ®ÊâÄÈúÄË¶ÅÁöÑ**ÔºÅüëá\n\nNick\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-most-ambitious-ai-crypto-project-ever-is-here-ab3f6d85afd1","frontmatter":{"title":"Âè≤‰∏äÊúÄÈõÑÂøÉÂãÉÂãÉÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂä†ÂØÜÈ°πÁõÆÊù•‰∫Ü","meta_title":"Âè≤‰∏äÊúÄÈõÑÂøÉÂãÉÂãÉÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂä†ÂØÜÈ°πÁõÆÊù•‰∫Ü","description":"Áé∞‰ª£‰∫∫Â∑•Êô∫ËÉΩÁöÑÂ•†Âü∫‰∫∫‰πã‰∏ÄIllia PolosukhinÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÈõÑÂøÉÂãÉÂãÉÁöÑÈ°πÁõÆÔºåÊó®Âú®Âà©Áî®Âå∫ÂùóÈìæËÆ≠ÁªÉÂÖ®ÁêÉÊúÄÂ§ßÁöÑÂºÄÊ∫êÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÁõÆÊ†á‰∏∫1.4‰∏á‰∫øÂèÇÊï∞„ÄÇËØ•È°πÁõÆÂ∏åÊúõÈÄöËøá‰ºóÁ≠πÊñπÂºèÁ≠πÈõÜ1.6‰∫øÁæéÂÖÉÔºåÂπ∂‰ª•Âéª‰∏≠ÂøÉÂåñÊñπÂºèËøõË°åËÆ≠ÁªÉÔºå‰ª•ÂÆûÁé∞ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÁöÑËÆ°ÁÆóËµÑÊ∫êÊï¥Âêà„ÄÇÊñáÁ´†Êé¢ËÆ®‰∫ÜÂå∫ÂùóÈìæÂú®Á°Æ‰øùËÆ≠ÁªÉËøáÁ®ãÈÄèÊòéÂíå‰∏çÂèØÁØ°ÊîπÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöËøáÈõ∂Áü•ËØÜËØÅÊòéÁ≠âÊäÄÊúØËß£ÂÜ≥ÂΩìÂâçÁöÑÂèØË°åÊÄßÈóÆÈ¢ò„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uiBwsWl8grXKJCJaGtH7kw.png","categories":["Technology","Machine Learning","Blockchain"],"author":"Rifx.Online","tags":["blockchain","parameters","crowdfunding","synchronization","transparency"],"draft":false,"slug":"blog/the-most-ambitious-ai-crypto-project-ever-is-here-ab3f6d85afd1"},"content":"\n\n\n### AI \\& Âå∫ÂùóÈìæÔºöÂ§©‰Ωú‰πãÂêàÔºåËøòÊòØÈ™óÂ±ÄÔºü\n\n\n\nÁé∞‰ª£‰∫∫Â∑•Êô∫ËÉΩÁöÑÂ•†Âü∫‰∫∫‰πã‰∏ÄÂ∏åÊúõÂà©Áî®Âå∫ÂùóÈìæËÆ≠ÁªÉÂÖ®ÁêÉÊúÄÂ§ßÁöÑÂºÄÊ∫êÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÂÖ∂ËßÑÊ®°Âá†‰πéÊòØ Llama 3\\.1 405B ÁöÑÂõõÂÄçÔºåÂêéËÄÖÈÄöÂ∏∏Ë¢´ËÆ§‰∏∫ÊòØÊúÄ‰Ω≥ÁöÑÂºÄÊîæ LLM„ÄÇ\n\nÂú®‰Ω†Â∞ÜËøô‰∏™Ê†áÈ¢òËßÜ‰∏∫Ê¨∫ËØàÊÄßÁÇí‰Ωú‰πãÂâçÔºåËØ∑Ê≥®ÊÑèÔºåËøô‰∏ÄÁõÆÊ†áÁöÑÊèêÂá∫ËÄÖÊ≠£ÊòØ ***Illia Polosukhin***Ôºå‰ªñÊòØ‚ÄúAttention is All you Need‚ÄùËÆ∫ÊñáÁöÑÁ†îÁ©∂ËÄÖ‰πã‰∏ÄÔºåËøôÁØáÂºÄÂàõÊÄßÁöÑËÆ∫ÊñáÂÇ¨Áîü‰∫ÜÊàë‰ª¨ÂΩìÂâçÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈù©ÂëΩ„ÄÇ\n\nÈÇ£‰πàÔºå‰ªñ‰ª¨Á©∂Á´üÊÉ≥ÂÅö‰ªÄ‰πàÔºüÂå∫ÂùóÈìæÂú®Ëøô‰∏ÄÂàá‰∏≠ÊâÆÊºî‰ªÄ‰πàËßíËâ≤Ôºü\n\nÁªßÁª≠ÈòÖËØªÔºå‰∫ÜËß£‰∫∫Â∑•Êô∫ËÉΩÂíåÂä†ÂØÜ‰∏ñÁïåÂ∞ÜÂ¶Ç‰Ωï‰∏çÂèØÈÅøÂÖçÂú∞ËûçÂêàÔºå‰ª•ÂèäËøô‰∏™È°πÁõÆÂ¶Ç‰ΩïÊúÄÁªàÂàõÈÄ†‰∏Ä‰∏™Áî±‰∫∫Ê∞ëÊã•ÊúâÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊ®°Âûã„ÄÇ\n\n> ‰Ω†ÂèØËÉΩÂéåÂÄ¶‰∫ÜÈÇ£‰∫õ‰ªÖ‰ªÖËß£ÈáäÂèëÁîü‰∫Ü‰ªÄ‰πàÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈÄöËÆØ„ÄÇËøôÂæàÁÆÄÂçïÔºå‰ªª‰Ωï‰∫∫ÈÉΩÂèØ‰ª•ÂÅöÂà∞ÔºåËøôÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÊúâËøô‰πàÂ§öËøôÊ†∑ÁöÑÈÄöËÆØ„ÄÇ\n\n> ‰ΩÜËß£Èáä‰∏∫‰ªÄ‰πàËøôÂæàÈáçË¶ÅÂàôÊòØÂè¶‰∏ÄÂõû‰∫ã„ÄÇËøôÈúÄË¶ÅÁü•ËØÜ„ÄÅË∞ÉÊü•ÂíåÊ∑±ÊÄùÁÜüËôë‚Ä¶‚Ä¶Ëøô‰∫õÈÉΩÊòØÊØèÂë®‰∏é **TheTechOasis** ‰∫íÂä®ÁöÑ‰∫∫ÊâÄÂÖ∑Â§áÁöÑÁâπË¥®ÔºåËøôÊòØ‰∏Ä‰ªΩÊó®Âú®ÂõûÁ≠î‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÊúÄÁ¥ßËø´ÈóÆÈ¢òÁöÑÈÄöËÆØ„ÄÇ\n\n> üèùÔ∏èüèùÔ∏è ‰ªäÂ§©Â∞±‰∏ãÈù¢ËÆ¢ÈòÖÔºö\n\n## Êã•Êúâ‰∫∫Â∑•Êô∫ËÉΩ\n\nÈöèÁùÄÁâπÊúóÊôÆÁöÑËÉúÂà©ÔºåÂä†ÂØÜË¥ßÂ∏ÅËøõÂÖ•‰∫Ü‰∏Ä‰∏™Âç≥ÂÖ¥ÁöÑÁâõÂ∏ÇÔºå[ÊØîÁâπÂ∏ÅÁöÑ‰ª∑Ê†ºÁ¶ªÊØèÊûö$100kÁöÑÊ†áÂøóÂºÇÂ∏∏Êé•Ëøë](https://coinmarketcap.com/currencies/bitcoin/)ÔºåÂπ∂ËææÂà∞‰∫ÜÊñ∞ÁöÑÂéÜÂè≤È´òÁÇπ„ÄÇ\n\n### NearÈ°πÁõÆ\n\nÂú®ÁâπÊúóÊôÆÊâßÊîøÊúüÈó¥ÔºåÂå∫ÂùóÈìæÂÖ¨Âè∏ÂØπÊú™Êù•ÊúâÂÖÖÂàÜÁöÑÁêÜÁî±ÊÑüÂà∞‰πêËßÇ„ÄÇÂÖ∂‰∏≠‰∏ÄÂÆ∂ÂÖ¨Âè∏ÊòØNearÔºåÂÆÉËØïÂõæÊû∂Ëµ∑Âä†ÂØÜË¥ßÂ∏Å‰∏é‰∫∫Â∑•Êô∫ËÉΩ‰πãÈó¥ÁöÑÊ°•Ê¢Å„ÄÇ\n\nÊàë‰∏çÊÉ≥ËØ¶ÁªÜ‰ªãÁªçËøô‰∏™È°πÁõÆÔºåÂõ†‰∏∫Êàë‰∏çÊÉ≥ËÆ©‰Ω†ËßâÂæóÊàëÂú®ËµûÂä©ÂÆÉÔºàÊàëÂπ∂‰∏çÊã•ÊúâNEARÂ∏ÅÔºâ„ÄÇÁÑ∂ËÄåÔºå‰ªñ‰ª¨ÊúÄËøëÂºÄÂßã‰∫Ü‰∏Ä‰∏™‰ºüÂ§ßËÄåÈõÑÂøÉÂãÉÂãÉÁöÑÁõÆÊ†áÔºåÊàëÊ∑±ÊÑüËÆ§ÂêåÔºö\n\nËÆ≠ÁªÉÊúâÂè≤‰ª•Êù•ÊúÄÂ§ßÁöÑÂºÄÊ∫êÊ®°ÂûãÔºåÁî±‰∏™‰∫∫‰ºóÁ≠πÔºåÂπ∂Áî±‰ªñ‰ª¨Êã•Êúâ„ÄÇ\n\nÂÖ∑‰ΩìÊù•ËØ¥Ôºå**‰ªñ‰ª¨Â∏åÊúõËÆ≠ÁªÉ‰∏Ä‰∏™1.4‰∏á‰∫øÂèÇÊï∞ÁöÑÊ®°Âûã**ÔºåËøô‰∏™Ê®°ÂûãÁöÑËßÑÊ®°Â∞Ü‰∏éGPT-4Á≠âÊ®°ÂûãÁõ∏Â™≤ÁæéÔºåÂπ∂‰∏îÊØî‰∏ñÁïå‰∏äÊúÄÂ§ßÁöÑÂºÄÊ∫êÔºàÊàñËÄÖÊàëÊï¢ËØ¥ÔºåÂºÄÊîæÊùÉÈáçÁöÑÔºâLLM‚Äî‚ÄîMetaÁöÑLlama 3.1 405BÂ§ß3.5ÂÄçÔºåÂêéËÄÖ‰πüË¢´ËÆ§‰∏∫ÊòØ‰ªäÂ§©ÊúÄÂ•ΩÁöÑÂºÄÊîæÊ®°Âûã„ÄÇ\n\n‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºå**‰ªñ‰ª¨È¢ÑËÆ°ÈúÄË¶Å‰ºóÁ≠π‰∏ÄÁ¨îÂèØËßÇÁöÑ1.6‰∫øÁæéÂÖÉ**ÔºåÈÄöËøáËé∑Âèñ$NEARÂ∏ÅÊù•ËµÑÂä©ÔºåËøôÊòØ‰∏ÄÁßçÊà™Ëá≥‰ªäÂ§©[Â∏ÇÂÄº‰∏∫66‰∫øÁæéÂÖÉ](https://coinmarketcap.com/currencies/near-protocol/)ÁöÑÂä†ÂØÜË¥ßÂ∏Å„ÄÇ\n\nÁÑ∂ËÄåÔºåÁúüÊ≠£ÁöÑÈóÆÈ¢ò‰∏çÊòØËßÑÊ®°ÔºåËÄåÊòØ‰ªñ‰ª¨Â∏åÊúõÈÄöËøáÊ≤üÈÄö‰∏çÁïÖÁöÑÁ°¨‰ª∂‰ª•Âéª‰∏≠ÂøÉÂåñÁöÑÊñπÂºèËÆ≠ÁªÉËøô‰∏™Ê®°Âûã„ÄÇÈÄö‰øóÂú∞ËØ¥Ôºå‰ªñ‰ª¨Âπ∂‰∏çÊâìÁÆóÂú®ÂÉèÂüÉÈöÜ¬∑È©¨ÊñØÂÖãÂú®Áî∞Á∫≥Ë•øÂ∑ûÂ≠üËè≤ÊñØÊã•ÊúâÁöÑ[140ÂÖÜÁì¶Êï∞ÊçÆ‰∏≠ÂøÉÔºåÈÖçÂ§á10‰∏áGPU](https://readmedium.com/putting-the-worlds-largest-ai-supercomputer-into-perspective-60afde9bc653)‰∏≠ËÆ≠ÁªÉËøô‰∏™Ê®°ÂûãÔºåËÄåÊòØÂ∏åÊúõÂú®ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖËøõË°åËÆ≠ÁªÉ„ÄÇ\n\nÂØπ‰∫éÁÜüÊÇâËøô‰∫õÊ®°ÂûãËÆ≠ÁªÉÊñπÂºèÁöÑ‰∫∫Êù•ËØ¥ÔºåËøôÂú®‰ªäÂ§©ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÊòØÊûÅÂÖ∂ÈõÑÂøÉÂãÉÂãÉÁöÑ„ÄÇ\n\n*‰ΩÜ‰∏∫‰ªÄ‰πàÂë¢Ôºü*\n\n### Êó∂Èó¥ÁöÑÈáçË¶ÅÊÄß\n\nÊÇ®ÂèØËÉΩÂê¨ËØ¥ËøáÂÖ≥‰∫éAIËÆ≠ÁªÉÂíåÊé®ÁêÜÁöÑÁñØÁãÇÊï∞Â≠óÔºå‰ΩÜËøô‰∫õÊï∞Â≠ó‰ªÖ‰ªÖÊòØÊú™Êù•ÁöÑ‰∏Ä‰∏™Áº©ÂΩ±„ÄÇ\n\n* [ÂüÉÈöÜ¬∑È©¨ÊñØÂÖãÂú®‰∏Ä‰∏™Âú∞ÁÇπÊã•Êúâ100,000‰∏™NVIDIA H100 GPU](https://readmedium.com/putting-the-worlds-largest-ai-supercomputer-into-perspective-60afde9bc653)ÔºåÂπ∂ÊâìÁÆóÂú®Êé•‰∏ãÊù•ÁöÑÂá†‰∏™ÊúàÂÜÖÂ∞ÜËÆ°ÁÆóËÉΩÂäõÁøªÂÄçÔºåËææÂà∞200,000‰∏™H100Á≠âÊïàËÆæÂ§á„ÄÇ\n* ÊâÄÊúâË∂ÖÂ§ßËßÑÊ®°‰∫ëÊúçÂä°ÂïÜÔºàÂæÆËΩØ„ÄÅ‰∫öÈ©¨ÈÄä„ÄÅMeta„ÄÅË∞∑Ê≠åÊàñÁî≤È™®ÊñáÔºâÊ≠£Âú®‰∏éÊ†∏ÁîµÁ´ôËææÊàêÂçèËÆÆÔºåÊàñÂ∑≤[ËææÊàêÂçèËÆÆ](https://www.technologyreview.com/2024/09/26/1104516/three-mile-island-microsoft/)‰∏éÂ∞èÂûãÊ®°ÂùóÂåñÂèçÂ∫îÂ†ÜÂÖ¨Âè∏Âêà‰ΩúÔºåÂª∫ËÆæÊ†∏ËÉΩÂèëÁîµ‰ª•‰æõÂÖ∂Êï∞ÊçÆ‰∏≠ÂøÉ‰ΩøÁî®Ôºå‰ªéËÄåÈÅøÂÖç‰º†ËæìÁ∫øË∑ØÂíåÁîµÊ∞îÂèòÂéãÂô®ÁöÑËøáÈïø‰∫§‰ªòÊó∂Èó¥„ÄÇ\n* [‰∏ÄÂÆ∂Ë∂ÖÂ§ßËßÑÊ®°‰∫ëÊúçÂä°ÂïÜÂêëÂåóËææÁßë‰ªñÂ∑ûÂ∑ûÈïøÈÅìÊ†º¬∑‰ºØÂè§ÂßÜÊèêËÆÆÂª∫ËÆæ‰∏Ä‰∏™**5‚Äì10ÂêâÁì¶ÁöÑÊï∞ÊçÆ‰∏≠ÂøÉ**](https://thetechoasis.beehiiv.com/p/understanding-ai-s-big-picture)„ÄÇ‰Ωú‰∏∫ÂèÇËÄÉÔºåÂêéËÄÖÁöÑÊï∞ÊçÆ‰∏≠ÂøÉÂ∞ÜÊã•ÊúâÊØî[ÂæÆËΩØÊï¥‰∏™Azure‰∫ëÔºà5 GWÔºâ](https://www.datacenterdynamics.com/en/news/microsoft-to-double-new-data-center-capacity-this-year-report/)Êõ¥Âº∫ÁöÑËÆ°ÁÆóËÉΩÂäõÔºåÂπ∂Ê∂àËÄóË∂≥Â§üÁöÑÁîµÂäõ‰∏∫**830‰∏áÁæéÂõΩÂÆ∂Â∫≠Êèê‰æõÁîµÂäõÔºåÊåâÁæéÂõΩÂÆ∂Â∫≠Âπ≥ÂùáÊ∂àË¥πÂÄº‰∏∫10,500 KWh/Âπ¥ËÆ°ÁÆó**„ÄÇ\n\nËÄå‰∏îËøô‰∏™ÂêçÂçïËøòÂú®ÁªßÁª≠„ÄÇ*‰ΩÜ‰∏∫‰ªÄ‰πàÔºü*\n\n**ÂéüÂõ†Â∞±ÊòØÊó∂Èó¥**„ÄÇË¶ÅËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÔºåÊÇ®ÈúÄË¶ÅÂêëÂÆÉÂèëÈÄÅÊï∞ÊçÆÔºåÂº∫Ëø´ÂÆÉËøõË°åÈ¢ÑÊµãÔºåÂπ∂ÊµãÈáèËØ•È¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊ†πÊçÆËøô‰∏™ËØØÂ∑Æ‰ø°Âè∑ÔºåÊàë‰ª¨ÈöèÂêéÊõ¥Êñ∞Ê®°ÂûãÁöÑÂèÇÊï∞Ôºå‰ª•‰ΩøÈ¢ÑÊµãËØØÂ∑ÆÈöèÊó∂Èó¥Èôç‰Ωé„ÄÇ\n\nËøô‰∏™ËøáÁ®ãÁöÑÈóÆÈ¢òÊúâ‰∏§‰∏™ÊñπÈù¢Ôºö\n\n* Ê®°ÂûãÈùûÂ∏∏Â∫ûÂ§ßÔºåËøôÊÑèÂë≥ÁùÄÊØèÊ¨°Êàë‰ª¨ÈúÄË¶ÅÊõ¥Êñ∞ÂèÇÊï∞Êó∂ÔºåÂèØËÉΩË¶ÅÊõ¥Êñ∞Êï∞‰∏á‰∫ø‰∏™ÂèÇÊï∞„ÄÇ\n* Êï∞ÊçÆÈõÜ‰πüÈùûÂ∏∏Â∫ûÂ§ßÔºåËøôÊÑèÂë≥ÁùÄÂèÇÊï∞Êõ¥Êñ∞ÁöÑÊï∞ÈáèÊòØÈöæ‰ª•ÊÉ≥Ë±°ÁöÑÂ∑®Â§ß„ÄÇ\n\nËøôÂØºËá¥ËÆ≠ÁªÉËøáÁ®ãÂ¶ÇÊûúÊåâÈ°∫Â∫èÊâßË°åÂ∞ÜÊ∞∏Êó†Ê≠¢Â¢É„ÄÇÂπ∏ËøêÁöÑÊòØÔºåÁî±‰∫éÁé∞Âú®Â§ßÂ§öÊï∞ÂâçÊ≤øAIÊ®°ÂûãÂü∫Êú¨‰∏äÊòØÂú®ËøõË°åË∂ÖÂ§ßËßÑÊ®°ÁöÑÁü©Èòµ‰πòÊ≥ïÔºåËøô‰∏éÂú®ËÆ°ÁÆóÊú∫Â±èÂπï‰∏äÊ∏≤ÊüìÂÉèÁ¥†ÁöÑÊï∞Â≠¶ËÆ°ÁÆóÈùûÂ∏∏Áõ∏‰ººÔºåËøô‰πüÊòØGPUÁöÑÊúÄÂàùÁõÆÊ†áÔºåÊàë‰ª¨ÂèØ‰ª•Âà©Áî®ËøôÁßçÁ°¨‰ª∂Êù•ËÆ≠ÁªÉËøô‰∫õÊ®°Âûã„ÄÇ\n\nÂÖ≥ÈîÆÊòØÔºåGPUÊó®Âú®Âπ∂Ë°åËÆ°ÁÆóÔºåËøôÊÑèÂë≥ÁùÄÊàë‰ª¨ÂèØ‰ª•ÂπøÊ≥õÂú∞Âπ∂Ë°åËÆ≠ÁªÉËøô‰∫õÊ®°ÂûãÔºà[Â∞ΩÁÆ°Áî±‰∫éÈòøÂßÜËææÂ∞îÂÆöÂæãÂπ∂‰∏çËÉΩÂÆåÂÖ®Âπ∂Ë°å](https://thetechoasis.beehiiv.com/p/understanding-ai-s-big-picture)Ôºâ„ÄÇ\n\nËøôÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÂÉè[Llama 3.1 405BËøôÊ†∑ÁöÑÊ®°ÂûãÂú®‰∏Ä‰∏™24,000 GPUÈõÜÁæ§‰∏äËÆ≠ÁªÉ](https://arxiv.org/pdf/2407.21783)Ôºå‰ª•ÂèäÂÉèxAIÁöÑÊñ∞GrokÂíå[MetaÁöÑLlama 4](https://www.tomshardware.com/tech-industry/artificial-intelligence/meta-is-using-more-than-100-000-nvidia-h100-ai-gpus-to-train-llama-4-mark-zuckerberg-says-that-llama-4-is-being-trained-on-a-cluster-bigger-than-anything-that-ive-seen)ËøôÊ†∑ÁöÑÊ®°ÂûãÂú®Ë∂ÖËøá100,000‰∏™GPUÈõÜÁæ§‰∏≠ËÆ≠ÁªÉÁöÑÂéüÂõ†„ÄÇ\n\nÂ•ΩÂêßÔºåÊàëÊòéÁôΩËøô‰∫õÊ®°ÂûãÈúÄË¶ÅÂ§ßÈáèGPUÂêåÊó∂Â∑•‰ΩúÊâçËÉΩËøõË°åËÆ≠ÁªÉ„ÄÇ*‰ΩÜÂÆÉ‰ª¨ÊòØÂ¶Ç‰ΩïÂÅöÂà∞ÁöÑÔºü*\n\n### ÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÁöÑÊú¨Ë¥®\n\nÂú®ÂàÜÂ∏ÉÂºèËÆ≠ÁªÉ‰∏≠ÔºåÊàë‰ª¨‰∏çÊòØËÆ≠ÁªÉ‰∏Ä‰∏™Âçï‰∏ÄÁöÑÊ®°ÂûãÂπ∂ÈÄöËøáÂ∞ÜÊâÄÊúâÊï∞ÊçÆÂèëÈÄÅÂà∞ËØ•ÂÆû‰æãÊù•Êõ¥Êñ∞ÂÆÉÔºåËÄåÊòØÊûÑÂª∫ÂâØÊú¨ÔºåÂç≥Ê®°ÂûãÁöÑÁõ∏ÂêåÁâàÊú¨ÔºåÊØè‰∏™ÂâØÊú¨ÂàÜÈÖçÁªô‰∏Ä‰∏™ÁâπÂÆöÁöÑGPU podÔºàpodÊòØ‰∏ÄÁªÑÁ¥ßÂØÜËøûÊé•ÂíåÂÖ±ÁΩÆÁöÑGPUÔºâ„ÄÇ\n\nÁÑ∂ÂêéÔºåÊàë‰ª¨ÂØπËÆ≠ÁªÉÈõÜËøõË°åÊâπÂ§ÑÁêÜÔºåÂπ∂Â∞ÜÊâπÊ¨°ÂàÜÈÖçÁªô‰∏çÂêåÁöÑpods„ÄÇÂΩìÁÑ∂ÔºåËøôÊÑèÂë≥ÁùÄÊØè‰∏™ÂâØÊú¨Êé•Êî∂‰∏çÂêåÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂõ†Ê≠§Â≠¶‰π†Âà∞ÁöÑÂÜÖÂÆπ‰πü‰∏çÂêå„ÄÇ\n\nÂõ†Ê≠§Ôºå**ÊØèÈöî‰∏ÄÊÆµÊó∂Èó¥ÔºåGPU podsÈúÄË¶ÅÂêåÊ≠•**Ôºå‰∏éÂÖ∂‰ªñpodsÂÖ±‰∫´ÂÆÉ‰ª¨ÁöÑÂ≠¶‰π†ÔºåËøôÊÑèÂë≥ÁùÄÂú®Ëøô‰∏™ÂêåÊ≠•Èò∂ÊÆµ‰πãÂêéÔºåÊâÄÊúâÊ®°ÂûãÂâØÊú¨ÈÉΩÊúâÂÆåÂÖ®Áõ∏ÂêåÁöÑÂèÇÊï∞ÂÄºÔºàÂõ†‰∏∫ÊØè‰∏™Ê®°ÂûãÂâØÊú¨ÂÆûÈôÖ‰∏äÊòØÁî®Âπ≥ÂùáÂ≠¶‰π†ÂÄºËøõË°åÊõ¥Êñ∞ÁöÑÔºåÂõ†Ê≠§Âú®ÊØè‰∏™ÊâπÊ¨°ËÆ≠ÁªÉÊ≠•È™§‰πãÂêéÔºåÊâÄÊúâÊ®°ÂûãÂâØÊú¨Â≠¶‰π†Âà∞ÁöÑÂÜÖÂÆπÈÉΩÊòØÁõ∏ÂêåÁöÑÔºâ„ÄÇ\n\nËôΩÁÑ∂Ëøô‰∏ÄÂàáÁúãËµ∑Êù•ÂæàÂ•ΩÔºå‰ΩÜËøôÁßçÂêåÊ≠•ÊòØ‰∏Ä‰∏™Â§ßÈóÆÈ¢òÔºåÂõ†‰∏∫Ëøô‰∫õÂêåÊ≠•Êõ¥Êñ∞ÊÑèÂë≥ÁùÄÊâÄÊúâpodsÂú®ÂêåÊ≠•ÊúüÈó¥Âü∫Êú¨‰∏äÈÉΩÊòØÂÅúÊªûÁöÑÔºå**Ëøô‰ΩøÂæóËÆ≠ÁªÉÊó∂Èó¥ÂèòÂæóÂç±Èô©Âú∞ËøáÈïøÔºàËøô‰∫õËÆ≠ÁªÉÂÆûÈôÖ‰∏äÈúÄË¶ÅÂá†‰∏™ÊúàÔºâ**„ÄÇ\n\nÊõ¥Á≥üÁ≥ïÁöÑÊòØÔºåNearÂ∏åÊúõ‰ª•‰ΩéÂ∏¶ÂÆΩÁöÑÂΩ¢ÂºèËøõË°åËøôÈ°πÂ∑•‰ΩúÔºåËøôÊÑèÂë≥ÁùÄGPU pods‰πãÈó¥ÁöÑÈÄö‰ø°ÈÄöÈÅìÂ∞Ü‰ºöÂæàÊÖ¢„ÄÇ\n\nÂõ†Ê≠§Ôºå*‰ªñ‰ª¨ËØ•Â¶Ç‰ΩïÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåÂå∫ÂùóÈìæÂ∞ÜÂèëÊå•‰ªÄ‰πà‰ΩúÁî®Ôºü* Âπ∏ËøêÁöÑÊòØÔºåÊàë‰ª¨ÂØπËøô‰∏§‰∏™ÈóÆÈ¢òÁöÑÁ≠îÊ°àÊØî‰Ω†È¢ÑÊúüÁöÑË¶ÅËØ¶ÁªÜÂæóÂ§ö„ÄÇ\n\n## ÊúùÂêëÂéª‰∏≠ÂøÉÂåñÁöÑ‰∫∫Â∑•Êô∫ËÉΩ\n\nÂπ∏ËøêÁöÑÊòØÔºåNearÂπ∂‰∏çÊòØÂîØ‰∏Ä‰∏Ä‰∏™ËÄÉËôëÂéª‰∏≠ÂøÉÂåñ‰∫∫Â∑•Êô∫ËÉΩÁöÑÈ°πÁõÆÔºàÂ∞ΩÁÆ°NearÂä†ÂÖ•‰∫ÜÂå∫ÂùóÈìæÔºõÊàë‰ª¨Á®çÂêé‰ºöÁúãÂà∞‰ªñ‰ª¨ÁöÑÂÅöÊ≥ïÔºâÔºåÂú®Êú¨ÊñáÊí∞ÂÜôÊó∂Ôºå**‰∏ñÁïå‰∏äÊúÄÂ§ßÁöÑÂéª‰∏≠ÂøÉÂåñËÆ≠ÁªÉÊ≠£Âú®ËøõË°å‰∏≠ÔºåÊ≠£Â¶Ç‰Ω†ÈòÖËØªËøôÁØáÊñáÁ´†Êó∂ÊâÄÁúãÂà∞ÁöÑ**„ÄÇ\n\n### PrimeÊ°ÜÊû∂\n\nPrime IntellectÊòØ‰∏ÄÂÆ∂Ëá¥Âäõ‰∫é‰ª•Âéª‰∏≠ÂøÉÂåñÊñπÂºèËÆ≠ÁªÉÂ§ßÂûãLLMÁöÑÂÖ¨Âè∏ÔºåÊó®Âú®ÂÆåÂÖ®Âéª‰∏≠ÂøÉÂåñÂú∞ËÆ≠ÁªÉ***Intellect\\-1***ÔºåËøôÊòØ‰∏Ä‰∏™Êã•Êúâ100‰∫øÂèÇÊï∞ÁöÑÊ®°Âûã„ÄÇ\n\nÊç¢Âè•ËØùËØ¥ÔºåËÆ≠ÁªÉËøáÁ®ãÂàÜÂ∏ÉÂú®Â§ö‰∏™GPU‰∏äÔºå**Ëøô‰∫õGPUÁî±Áã¨Á´ãÊñπÊã•Êúâ**ÔºåÂèØËÉΩÂàÜÂ∏ÉÂú®‰∏çÂêåÁöÑÂ§ßÈôÜÔºåÂπ∂ÈÄöËøá‰ΩéÂ∏¶ÂÆΩÁΩëÁªúËøûÊé•„ÄÇ\n\n> ÊÇ®ÂèØ‰ª•ÈÄöËøá[Ëøô‰∏™Â∫îÁî®Á®ãÂ∫è](https://app.primeintellect.ai/intelligence?utm_source=thetechoasis.beehiiv.com&utm_medium=newsletter&utm_campaign=should-ai-s-kill-openai-s-swarm-the-future-of-ai-training&_bhlid=8eadb6cf7d24b545a761f9ac3f7126a45ac2b579)ËßÇÁúãËøõÂ±ïÂíåÂèÇ‰∏éÁöÑ‰∏çÂêåÊñπ„ÄÇ\n\nËøô‰ΩøÊàë‰ª¨ÂØπNearÂ¶Ç‰ΩïÂÆûÁé∞ËÆ≠ÁªÉÊúâÂè≤‰ª•Êù•ÊúÄÂ§ßÁöÑÂºÄÊ∫êAIÊ®°ÂûãÁöÑ‰ΩøÂëΩÊúâ‰∫ÜÂæàÂ•ΩÁöÑÊ¥ûÂØü„ÄÇ\n\nÊ≠£Â¶ÇÊÇ®‰ªéÂâç‰∏ÄÈÉ®ÂàÜ‰∏≠ÁåúÊµãÁöÑÈÇ£Ê†∑ÔºåAIËÆ≠ÁªÉÁöÑ‰∏ªË¶ÅÁì∂È¢àÊòØÂêåÊ≠•Êõ¥Êñ∞„ÄÇÊ†πÊçÆÈòøÂßÜËææÂ∞îÂÆöÂæãÔºå**Â¶ÇÊûúËÆ≠ÁªÉ‰∏≠ÁöÑÊüê‰∏™ÁéØËäÇÊó†Ê≥ïÂπ∂Ë°åÂåñÔºåÂàôÂπ∂Ë°åÂåñÂèØËÉΩ‰ºöÂØºËá¥Êî∂ÁõäÈÄíÂáè**„ÄÇ\n\nÂõ†Ê≠§ÔºåÈöèÁùÄÂπ∂Ë°åÂåñÁöÑÂ¢ûÂä†ÔºåËäÇÁúÅÊó∂Èó¥ÁöÑÊîπËøõÂèòÂæóÂ¢ûÈáèÂåñÔºåÂõ†‰∏∫Êàë‰ª¨Êó†Ê≥ïÂáèÂ∞ëÂêåÊ≠•Êó∂Èó¥„ÄÇ\n\n> Â¶ÇÊûúÊÇ®ÊÉ≥Áü•ÈÅìÔºåÊó†Ê≥ïÂºÇÊ≠•ÊâßË°åÂêåÊ≠•ÔºàÊØè‰∏™podÁã¨Á´ãÊõ¥Êñ∞ÂÖ∂ÂèÇÊï∞ÂÄºÔºâÔºåÂõ†‰∏∫Ê®°ÂûãÊî∂ÊïõÂèòÂæó‰∏çÂèØËÉΩÔºàËá≥Â∞ëÂú®Êàë‰ª¨ÁõÆÂâçÁöÑÁü•ËØÜ‰∏≠Ôºâ„ÄÇ\n\nÁü•ÈÅìËøô‰∏ÄÁÇπÂêéÔºåPrime IntellectÂÆûÊñΩ‰∫ÜÂá†ÁßçNearËÇØÂÆö‰ºöÂà©Áî®ÁöÑÊäÄÊúØÔºö\n\n* **ÊØèÁôæÊ≠•ÂêåÊ≠•‰∏ÄÊ¨°**„ÄÇ\n\nÊØèÊ¨°ÂèÇÊï∞Êõ¥Êñ∞Êó∂Ôºå‰∏çÊòØÊØè‰∏™GPU podÈÉΩËøõË°åÂêåÊ≠•ÔºåËÄåÊòØÊØè‰∏™podÊê∫Â∏¶ÂÖ∂‚Äú‰º™Ê¢ØÂ∫¶‚ÄùÔºàÂú®Â§ö‰∏™Êú¨Âú∞ËÆ≠ÁªÉÊó∂Èó¥Ê≠•È™§‰∏≠ÁßØÁ¥ØÂÖ∂Â≠¶‰π†ÔºâÔºåÊØè100‰∏™ËøôÊ†∑ÁöÑÊó∂Èó¥Ê≠•È™§ÔºåÂÆÉ‰∏éÂÖ∂‰ªñpodÂàÜ‰∫´ÂÖ∂Â≠¶‰π†„ÄÇ\n\nÁÆÄÂçïÊù•ËØ¥ÔºåÁî±‰∫éÂ≠¶‰π†ÂÖ±‰∫´ÊòØËÆ≠ÁªÉÊÄßËÉΩÁöÑ‰∏ªË¶ÅÁì∂È¢àÔºåÊàë‰ª¨ÊúÄÂ∞èÂåñGPU pod‰πãÈó¥ÁöÑÈÄö‰ø°Ê¨°Êï∞„ÄÇ\n\n* **ÈÄö‰ø°Ë¥üËΩΩÁöÑÈáèÂåñ**„ÄÇ\n\nË∑®podÈÄö‰ø°ÁöÑÊ¨°Êï∞Âπ∂‰∏çÊòØÂîØ‰∏ÄÂΩ±ÂìçÊó∂Èó¥ÁöÑÂõ†Á¥†ÔºõÂÖ±‰∫´‰ø°ÊÅØÁöÑÊï∞Èáè‰πüÂæàÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÂØπÂ≠¶‰π†ËøõË°åÈáèÂåñÔºå‰ª•‰æø‰ø°ÊÅØ‰ª•ÂéãÁº©ÂΩ¢Âºè‰º†ÈÄíÔºå‰ªéËÄåÂä†Âø´ÈÄüÂ∫¶„ÄÇ\n\nËøôÂ∞ÜÈÄö‰ø°ÈúÄÊ±ÇÂáèÂ∞ë‰∫Ü400ÂÄç„ÄÇÂú®Ê†áÂáÜÊÉÖÂÜµ‰∏ãÔºåÂêåÊ≠•ÂèØËÉΩÈúÄË¶ÅÈïøËææ40ÂàÜÈíü„ÄÇÈÄöËøáËøôÁßçÈáèÂåñÔºåÊâÄÈúÄÊó∂Èó¥Â∞ë‰∫é‰∏ÄÂàÜÈíü„ÄÇ\n\n> **‰ªÄ‰πàÊòØÈáèÂåñÔºü** ÁÆÄËÄåË®Ä‰πãÔºåÊàë‰ª¨ÂØπÊÉ≥Ë¶ÅÂ≠òÂÇ®ÔºàÊàñÂÖ±‰∫´ÔºåÂ¶ÇÊú¨‰æãÊâÄÁ§∫ÔºâÁöÑ‰ø°ÊÅØËøõË°åÂ§ÑÁêÜÔºåÈôç‰ΩéÊØè‰∏™ÂèÇÊï∞ÁöÑÁ≤æÂ∫¶ÔºàËÄå‰∏çÊòØ‚Äò1.023293‚ÄôÔºåËØ•Êï∞Â≠ó‰ª•‚Äò1‚ÄôÁöÑÂΩ¢Âºè‰º†ÈÄíÔºâ‰ª•‰ºòÂåñÂô®Áä∂ÊÄÅÔºàÊê∫Â∏¶ÊØè‰∏™Ê®°ÂûãÂâØÊú¨Â≠¶‰π†ÂÜÖÂÆπÁöÑÁä∂ÊÄÅÔºâ„ÄÇ\n\n> **ÂèØ‰ª•Â∞ÜÂÖ∂ËßÜ‰∏∫Âú®ÂèëÈÄÅ‰πãÂâçÂ∞ÜÊï∞ÊçÆÂéãÁº©ÊàêzipÊñá‰ª∂Ôºå‰ª•‰æøÂèëÈÄÅÁöÑÊï∞ÊçÆÂåÖÂ§ßÂ∞èÊõ¥Â∞èÔºå‰ªéËÄåÊõ¥Âø´ÂèëÈÄÅ„ÄÇ**\n\n> ÁÑ∂ËÄåÔºåËôΩÁÑ∂ÂèØ‰ª•ÊÅ¢Â§çÂéüÂßãÊï∞Â≠óÔºàÂèçÈáèÂåñÔºâÔºå‰ΩÜ‰ºöÈÄ†Êàê‰∏Ä‰∫õÁ≤æÂ∫¶ÊçüÂ§±ÔºåËøôÂèØËÉΩ‰ºöÂΩ±ÂìçÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºå[Prime IntellectÂ£∞Áß∞‰ªñ‰ª¨Ê≤°ÊúâÊÑüÂèóÂà∞‰ªª‰ΩïÊÄßËÉΩÊçüÂ§±](https://www.primeintellect.ai/blog/intellect-1)ÔºåÂ∞ΩÁÆ°ËäÇÁúÅ‰∫ÜÂ§ßÈáèÊó∂Èó¥„ÄÇ\n\n* **Âä®ÊÄÅÂÖ®ÁêÉÁªÑ**\n\nÂéª‰∏≠ÂøÉÂåñÊ®°ÂûãËÆ≠ÁªÉÁöÑÊúÄÂ§ßÈóÆÈ¢ò‰πã‰∏ÄÊòØÂèØÈù†ÊÄßÔºõÁΩëÁªúÂíåÔºåÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂ∑•‰ΩúËÄÖÔºàGPUÔºâÂèØËÉΩ‰ºöÂ¥©Ê∫ÉÂíåÂ§±Ë¥•„ÄÇÊ≠§Â§ñÔºå**ÊÇ®Â∏åÊúõÊøÄÂä±ËøôÁßçÂä®ÊÄÅÊÄß**Ôºå‰ª•‰æø‰∫∫‰ª¨ÂèØ‰ª•ÂÖ±ÂêåÂèÇ‰∏éËÆ≠ÁªÉÂπ∂Âú®ÈúÄË¶ÅÊó∂‰∏ãÁ∫ø„ÄÇ\n\n‰∏∫Ê≠§ÔºåPrimeÊ°ÜÊû∂ÂÖ∑Êúâ**Âä®ÊÄÅÂÖ®ÁêÉÁªÑ**ÔºåÁ°Æ‰øùÂ∑•‰ΩúËÄÖÂèØ‰ª•Âú®‰∏çÂΩ±ÂìçÊï¥‰ΩìËÆ≠ÁªÉËøáÁ®ãÁöÑÊÉÖÂÜµ‰∏ã‰∏äÁ∫øÂíå‰∏ãÁ∫ø„ÄÇ\n\nÊ≠§Â§ñÔºåÊ°ÜÊû∂ËøòÂåÖÊã¨ÂÖ∂‰ªñÊäÄÊúØÔºåÂ¶ÇÂºÇÊ≠•Ê£ÄÊü•ÁÇπÔºåÊàë‰∏ç‰ºöËØ¶ÁªÜ‰ªãÁªç‰ª•ËäÇÁúÅÁØáÂπÖÔºå‰ΩÜÊÇ®ÂèØ‰ª•Âú®[ËøôÈáåËØ¶ÁªÜÈòÖËØª](https://www.primeintellect.ai/blog/intellect-1)„ÄÇ\n\n‰ΩÜÊàë‰ª¨‰ªçÁÑ∂Ê≤°ÊúâÂõûÁ≠îÂÖ≥ÈîÆÈóÆÈ¢òÔºö*Âå∫ÂùóÈìæÂú®Ëøô‰∏ÄÂàá‰∏≠ÈÄÇÂêà‰ªÄ‰πàÔºü*\n\n## ÊøÄÂä®‰∫∫ÂøÉÁöÑÊú™Êù•\n\nÂú®Êé•‰∏ãÊù•ÁöÑÂõõÂπ¥ÈáåÔºåÊÇ®Â∞ÜÁúãÂà∞Âå∫ÂùóÈìæÊó†Â§Ñ‰∏çÂú®„ÄÇ\n\nÊòØÁöÑÔºå*‚Äò{ÊèíÂÖ•Êüê‰∏™Ëøê‰ΩúËâØÂ•ΩÁöÑ‰∏úË•ø}‰ΩÜÁé∞Âú®ÂÆÉÊòØÂéª‰∏≠ÂøÉÂåñÁöÑ‚Äô* ËøôÁßçÂè£Âè∑Â∞ÜÈáçÊñ∞ÂõûÂà∞Êàë‰ª¨ÁöÑÁîüÊ¥ª‰∏≠„ÄÇ\n\nËôΩÁÑ∂ËÆ∏Â§öÊñ∞ÁöÑÁî®‰æãÂèØËÉΩÊØ´Êó†ÊÑè‰πâÔºå‰ΩÜÂå∫ÂùóÈìæÁ°ÆÂÆûÊúâ‰∏Ä‰∏™ÊòéÁ°ÆÁöÑÂ≠òÂú®ÁêÜÁî±Ôºå‰ΩøÂÖ∂Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®Êó∂ÈùûÂ∏∏Êúâ‰ª∑ÂÄºÔºåËÄå‰∏çÊòØ‰∏∫‰∫ÜËØ¥ÊÇ®Âú®‰ΩøÁî®Âå∫ÂùóÈìæ„ÄÇ\n\n### ËøôÊòØ‰∏Ä‰ªΩË¥¶Êú¨\n\nÂå∫ÂùóÈìæÊòØÂéª‰∏≠ÂøÉÂåñÁöÑË¥¶Êú¨„ÄÇÂÆÉ‰ª¨‰ª•Âå∫ÂùóÁöÑÂΩ¢ÂºèÂ≠òÂÇ®‰∏§‰∏™ËäÇÁÇπ‰πãÈó¥ÁöÑ‰∫§Êòì‰ø°ÊÅØÔºåËøô‰∫õÂå∫ÂùóÊåâÈ°∫Â∫èËøûÊé•Âú®‰∏ÄËµ∑ÔºàÂõ†Ê≠§ÂæóÂêçÔºâ„ÄÇ\n\n**ËøôÈùûÂ∏∏ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑÂéª‰∏≠ÂøÉÂåñÁâπÊÄß‰ΩøÂæóËøô‰∏™Ë¥¶Êú¨Âá†‰πé‰∏çÂèØËÉΩË¢´ÁØ°Êîπ**„ÄÇÁúüÊ≠£ÁöÑÂå∫ÂùóÈìæÔºà‰ªäÂ§©Á¨¶ÂêàËøô‰∏ÄÊ†áÂáÜÁöÑÂπ∂‰∏çÂ§öÔºâÊòØ‰∏çÂèØÂèòÁöÑÂíåÊòéÁ°ÆÁöÑÔºåÊòØÊüê‰∏™Êó∂Âàª‰∫§ÊòìÂèëÁîüÁöÑÊó†ÂèØ‰∫âËÆÆÁöÑ‰∫ãÂÆûÊù•Ê∫ê„ÄÇ\n\nÈáçË¶ÅÁöÑÊòØÔºåÂÆÉ‰ª¨ÊòØ‚ÄúÊó†‰ø°‰ªª‚ÄùÁöÑÔºåËøôÊÑèÂë≥ÁùÄÂä†ÂØÜÊäÄÊúØÔºåËÄå‰∏çÊòØÂÉèÈì∂Ë°åËøôÊ†∑ÁöÑ‰∏≠ÂøÉÂåñÂÆû‰ΩìÔºå‰øùËØÅ‰∫ÜË¥¶Êú¨ÁöÑÊú™Ë¢´ÁØ°ÊîπÁöÑÁâπÊÄß„ÄÇ\n\n> ÂÆÉ‰ª¨‰πãÊâÄ‰ª•Â¶ÇÊ≠§Èöæ‰ª•ÁØ°ÊîπÔºåÊÇ®ÁåúÂØπ‰∫ÜÔºåÊòØÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑÂéª‰∏≠ÂøÉÂåñÁâπÊÄß„ÄÇ‰øùÊä§Âå∫ÂùóÈìæÁöÑÂÖ®ÁêÉËäÇÁÇπÁΩëÁªúÈÉΩÊúâÁΩëÁªúÁöÑÁ≤æÁ°ÆÂâØÊú¨ÔºåÊØèÊ¨°Ê∑ªÂä†Êñ∞ÂùóÊó∂ÈÉΩ‰ºöÊõ¥Êñ∞„ÄÇ\n\n> Âõ†Ê≠§ÔºåË¶ÅÂºïÂÖ•Ë¢´ÁØ°ÊîπÁöÑ‰∫§ÊòìÔºåÊÇ®ÈúÄË¶ÅÊã•ÊúâËøô‰∫õËäÇÁÇπÁöÑÂ§öÊï∞ÔºåÊó†ËÆ∫ÊòØÈÄöËøáÂú®ÂÉèÊØîÁâπÂ∏ÅËøôÊ†∑ÁöÑÂ∑•‰ΩúÈáèËØÅÊòéÂå∫ÂùóÈìæ‰∏≠ÊäïÂÖ•Â∑®È¢ùËÆ°ÁÆóËµÑÊ∫êÔºàÊàêÊú¨ÊûÅÈ´òÔºâ„ÄÅÈªëÂÆ¢ÊîªÂáªÂ§ßÂ§öÊï∞ËäÇÁÇπÔºàÂêåÊ†∑ÔºåÊàêÊú¨ÊûÅÈ´òÔºâÔºåËøòÊòØÈÄöËøáÂú®ÂÉè‰ª•Â§™ÂùäËøôÊ†∑ÁöÑÊùÉÁõäËØÅÊòéÂå∫ÂùóÈìæ‰∏≠Êã•ÊúâÂ§öÊï∞ÁöÑÂä†ÂØÜË¥ßÂ∏ÅËÇ°‰ªΩÔºàÂêåÊ†∑ÔºåÊàêÊú¨ÊûÅÈ´òÔºâ„ÄÇ\n\nÈïøËØùÁü≠ËØ¥ÔºåÂå∫ÂùóÈìæÁöÑ‰ª∑ÂÄºÂú®‰∫éÔºå‰ΩøÁØ°ÊîπÂÆÉ‰ª¨ÁöÑË°å‰∏∫Âú®ÁªèÊµé‰∏äÊàê‰∏∫‰∏Ä‰∏™ÈùûÂ∏∏ÈùûÂ∏∏Á≥üÁ≥ïÁöÑ‰∏ªÊÑèÔºåËøôÊ†∑ÂÅöÊ†πÊú¨‰∏çÂÄºÂæó„ÄÇ\n\nÂõ†Ê≠§ÔºåÂÆÉ‰ª¨ÁöÑ‰ª∑ÂÄºÂú®‰∫éÔºå‰∏ç‰ªÖÊòØ‰ºüÂ§ßÁöÑÁúüÁõ∏Êù•Ê∫êÔºå‰∏∫‰∫§ÊòìÊèê‰æõ‰ø°‰ªªÔºåËÄå‰∏îËøòÂÖç‰∫éÂèØËÉΩÊúâÂä®Êú∫ÂéªÁØ°ÊîπÂÆÉ‰ª¨ÁöÑ‰∏≠ÂøÉÂåñÊùÉÂäõ„ÄÇ\n\n*Ëøô‰∏é‰∫∫Â∑•Êô∫ËÉΩÊúâ‰ªÄ‰πàÂÖ≥Á≥ªÔºü* ËøôÂ∞±ÊòØ‰∏ÄÂàáÂõûÂΩíÁöÑÂú∞Êñπ„ÄÇ\n\n### Êã•ÊúâÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈúÄË¶ÅÂå∫ÂùóÈìæ\n\nËÆ≠ÁªÉÂéª‰∏≠ÂøÉÂåñ‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÊÉ≥Ê≥ïÊòØÔºåÂèÇ‰∏éËÆ≠ÁªÉËØ•Ê®°ÂûãÁöÑ‰∫∫ÔºàÊó†ËÆ∫ÊòØÈÄöËøáËÆ°ÁÆóËøòÊòØËµÑÈáëÔºâÈÉΩÂ∞ÜËé∑ÂæóÂ•ñÂä±„ÄÇ\n\nÂõ†Ê≠§ÔºåËøô‰∏™1.4‰∏á‰∫øÂèÇÊï∞Ê®°ÂûãÁöÑÁõÆÊ†áÊòØÂ∞ÜÂÖ∂Êé®Êñ≠Ôºà‰ΩøÁî®ÔºâÂõûÊä•ÁªôÂÖ∂ËµÑÂä©ËÄÖ„ÄÇ\n\nËÄåÂå∫ÂùóÈìæÂú®ËøôÈáåÂèëÊå•‰∫Ü‰ΩúÁî®Ôºå‰Ωú‰∏∫‰∏çÂèØÂê¶ËÆ§ÁöÑËØÅÊçÆÔºåËØÅÊòé*‚ÄúÊù•Ëá™ÂÜÖÂ∏ÉÊãâÊñØÂä†Â∑ûÁöÑÁÆÄ¬∑Â§ö‚Äù*ÊîØ‰ªò‰∫Ü1,000ÁæéÂÖÉÊù•ËµÑÂä©ËøôÈ°πËÆ≠ÁªÉÔºåÊàñËÄÖ*‚ÄúÊù•Ëá™Êó•Êú¨ÁöÑÁ∫¶Áø∞¬∑Â§ö‚Äù*ËØÅÊòé‰ªñ‰ª¨Êèê‰æõ‰∫Ü100Â∞èÊó∂ÁöÑGPUËÆ°ÁÆóÁî®‰∫éËÆ≠ÁªÉÔºåÂõ†Ê≠§Ôºå‰∏§ËÄÖÈÉΩÊòØËØ•Ê®°ÂûãÊé®Êñ≠Êî∂ÁõäÁöÑÂêàÊ≥ïÊé•Êî∂ËÄÖÔºàÊØèÊ¨°Ê®°ÂûãËøêË°åÊó∂ÔºåÊÇ®ÈÉΩ‰ºöËé∑ÂæóÊä•ÈÖ¨Ôºâ„ÄÇ\n\nÁé∞Âú®ÔºåÊÇ®ÂèØËÉΩ‰ºöÈóÆÔºö‰∏Ä‰∏™‰∏≠ÂøÉÂåñÂÆû‰ΩìËÉΩÁÆ°ÁêÜËøô‰∏ÄÂàáÂêóÔºü\n\nÂΩìÁÑ∂ÂèØ‰ª•Ôºå‰ΩÜÂå∫ÂùóÈìæÁöÑÊ†∏ÂøÉÁõÆÁöÑÂ∞±ÊòØÈò≤Ê≠¢ÈúÄË¶ÅËøôÊ†∑ÁöÑ‰∏≠ÂøÉÂÆû‰ΩìÁöÑÂ≠òÂú®ÔºåÂπ∂Á°Æ‰øùÊ≤°Êúâ‰∫∫ÂÆåÂÖ®ÊéßÂà∂Ë∞ÅÊã•Êúâ‰ªÄ‰πàÊàñÊÇ®Ëé∑ÂæóÂ§öÂ∞ëÊä•ÈÖ¨„ÄÇ\n\nÁé∞Âú®ÔºåËÄÉËôëÂà∞ÊâÄÊúâÂõ†Á¥†Ôºå*Ëøô‰∏™ÊÑøÊôØ‰ªäÂ§©ÁúüÁöÑÂèØËÉΩÂÆûÁé∞ÂêóÔºü*\n\n### ÂèØË°åÊÄßÊòØÂê¶Á¨¶ÂêàÊÑøÊôØÔºü\n\n‰ªª‰Ωï‰∫∫ÈÉΩÂæàÂÆπÊòì‰∏é Near ÁöÑ AI ÊÑøÊôØ‰øùÊåÅ‰∏ÄËá¥ÔºåÂ∞§ÂÖ∂ÊòØËÄÉËôëÂà∞Ëøô‰∏™È°πÁõÆËÉåÂêéÁöÑ‰∫∫„ÄÇ\n\nËÆæÊÉ≥‰∏Ä‰∏™Âéª‰∏≠ÂøÉÂåñÁªèÊµéÂõ¥Áªï AI ÂÖ¥Ëµ∑ÁöÑÊú™Êù•Ôºå‰ª•Á°Æ‰øù‰∫∫‰ª¨Âõ†ÂÖ∂Êï∞ÊçÆ„ÄÅÂÜÖÂÆπ„ÄÅËÆ°ÁÆóÊàñ‰∏ì‰∏öÁü•ËØÜËÄåËé∑ÂæóÊä•ÈÖ¨ÔºåÂπ∂ÂØπÊ≠§Ëé∑ÂæóÊòéÁ°ÆÂíåÂÆ¢ËßÇÁöÑÂ•ñÂä±ÔºåËøôÊòØ‰ªª‰Ωï‰∫∫ÈÉΩËÉΩÂÖ±È∏£ÁöÑÊÑøÊôØ„ÄÇ\n\nÁÑ∂ËÄåÔºå**Âü∫‰∫éÂΩìÂâçÊ†áÂáÜÔºå1.4‰∏á‰∫øÂèÇÊï∞ÁöÑÊ®°ÂûãÊòæÂæóËøá‰∫éÂ∫ûÂ§ß**„ÄÇÊ≠£Â¶ÇÊâÄÊèêÂà∞ÁöÑÔºå*Intellect\\-1*ÔºåÁõÆÂâçÂ∑≤Áü•ÁöÑÊúÄÂ§ßËÆ≠ÁªÉÊ®°ÂûãÔºå**‰ªÖ‰∏∫ *Near* ÊâìÁÆóÊûÑÂª∫ÁöÑÊ®°ÂûãÁöÑ 140 ÂàÜ‰πã‰∏Ä**„ÄÇ\n\nÂè¶‰∏Ä‰∏™ÊãÖÂøßÊòØÂå∫ÂùóÈìæ„ÄÇ‰æãÂ¶ÇÔºåÊúâÂÖ≥ NFT ÁöÑÊúÄÂ§ßË∞éË®Ä‰πã‰∏ÄÊòØÂå∫ÂùóÈìæ‰ªÖÂ≠òÂÇ® NFT ‰∫§ÊòìÂèëÁîüÁöÑ‰∫ãÂÆûÔºå**‰ΩÜ NFT ÊòØ‚ÄúÈìæÂ§ñ‚ÄùÂ≠òÂÇ®ÁöÑ„ÄÇ**ÂèØÊÇ≤ÁöÑÊòØÔºåÁúüÁõ∏ÊòØÔºåÂè™ÊúâÂ≠òÂÇ®Âú®Âå∫ÂùóÈìæ‰∏≠ÁöÑÊï∞ÊçÆÊòØÂÆåÂÖ®Âèó‰øùÊä§ÁöÑÔºåÂõ†Ê≠§ÂÆûÈôÖÁöÑ‚ÄúËâ∫ÊúØÂìÅ‚ÄùÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÊ≤°Êúâ‰øùÊä§ÁöÑÔºå‰∏îÊòì‰∫éÂ§çÂà∂„ÄÇ\n\nÁÑ∂ËÄåÔºåÂå∫ÂùóÈìæ notoriously ‰ΩéÊïàÔºåËøôÊÑèÂë≥ÁùÄ‰Ω†Âú®‚ÄúÈìæ‰∏ä‚ÄùÂ≠òÂÇ®ÁöÑÊï∞ÊçÆË∂äÂ∞ëË∂äÂ•ΩÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨ÈùûÂ∏∏‰∏çÂÆûÁî®„ÄÇ\n\nÂõ†Ê≠§ÔºåÂ¶ÇÊûúÊ®°Âûã„ÄÅÊï∞ÊçÆÊàñÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãÁöÑËÆ°ÁÆóÈÉΩ‰∏ç‰ºöÂ≠òÂÇ®Âú®Âå∫ÂùóÈìæ‰∏äÔºå*ÈÇ£Êúâ‰ªÄ‰πàÊÑè‰πâÂë¢Ôºü*\n\nÂπ∏ËøêÁöÑÊòØÔºåÊúâ‰∏Ä‰∏™Ëß£ÂÜ≥ÊñπÊ°àÔºöÈõ∂Áü•ËØÜËØÅÊòéÔºå‰ªäÂ§©‰∏∫‰∫ÜÁØáÂπÖÂéüÂõ†Êàë‰∏çÊâìÁÆóÊ∑±ÂÖ•Êé¢ËÆ®ÔºåËøôÂèØËÉΩÊòØÁ°Æ‰øù‰∫ã‰ª∂ÂèëÁîüÁöÑÂÖ≥ÈîÆÔºåÂç≥‰ΩøÂÆÉÊ≤°ÊúâÂ≠òÂÇ®Âú®Èìæ‰∏ä„ÄÇ\n\nÈÄöËøá zk\\-proofsÔºåÊüê‰∫∫ÂèØ‰ª•ËØÅÊòé‰ªñ‰ª¨Â£∞Áß∞Áî®‰∫éËÆ≠ÁªÉÁöÑËÆ°ÁÆóÁ°ÆÂÆûÂèëÁîü‰∫ÜÔºåÊàñËÄÖ‰ªñ‰ª¨Á°ÆÂÆûËµÑÂä©‰∫ÜËÆ≠ÁªÉËøáÁ®ãÔºåÈÄöËøáÂ≠òÂÇ®ËØ•‰∫§ÊòìÁöÑÊ≥®ÂÜå‰ø°ÊÅØÔºåÂπ∂ÈôÑ‰∏ä‰∏Ä‰∏™ zk\\-proofÔºåËØÅÊòéÊüê‰∏™ÈìæÂ§ñ‰∫ã‰ª∂Á°ÆÂÆûÂèëÁîü„ÄÇ\n\nÂõ†Ê≠§Ôºå‰ªÖÈÄöËøáÂ≠òÂÇ® zk\\-proofÔºåÊàë‰ª¨ÂèØ‰ª•Á°Æ‰øùÂç≥‰ΩøÊòØÈìæÂ§ñÊï∞ÊçÆ‰πüÂèØ‰ª•Ë¢´‰ø°‰ªª„ÄÇ*ÈóÆÈ¢òÊòØÔºü* Áî±‰∫é zk\\-proof ÂØπËÆ°ÁÆóÁöÑË¶ÅÊ±ÇÂæàÈ´òÔºåÂÆÉ‰ª¨Â∞öÊú™ÂáÜÂ§áÂ•Ω„ÄÇ\n\nÁÑ∂ËÄåÔºåÊúâ‰∏ÄÁÇπ‰ªçÁÑ∂ÊàêÁ´ãÔºöÂ¶ÇÊûú‰Ω†ÁúüÁöÑÁõ∏‰ø° AI ÂèØ‰ª•Âéª‰∏≠ÂøÉÂåñÔºå‰Ω†ÂøÖÈ°ªÁõ∏‰ø°Âå∫ÂùóÈìæÊòØÂêàÊ≥ïÁöÑ„ÄÇ\n\n*‰ΩÜËøôÁßçÁ±ªÂûãÁöÑÂÖ¨ÂëäËÆ©‰Ω†ÊÑüËßâÂ¶Ç‰ΩïÔºü‰Ω†ÂØπ Crypto Âíå AI ‰πãÈó¥ÁöÑÂçèÂêå‰ΩúÁî®ÊÑüÂà∞ÂÖ¥Â•ãÂêóÔºü*\n\n*ËøòÊòØÊØèÊ¨°ÁúãÂà∞Âå∫ÂùóÈìæÊèêÂèäÊó∂Ôºå‰ªçÁÑ∂ËßâÂæóÊòØ‰∏ÄÁßç‚ÄúÈ™óÂ±Ä‚ÄùÔºü* Â¶ÇÊûúÊòØËøôÊ†∑ÔºåÊàë‰∏çÊÄ™‰Ω†Ôºå‰ΩÜÂ¶ÇÊûú‰Ω†ËÉΩÂ§üÊäΩÁ¶ªÂá∫ Crypto ÁöÑÊó†Êï∞È™óÂ±ÄÔºå‰Ω†‰ºöÊÑèËØÜÂà∞ËøôÈ°πÊäÄÊúØÂ∞ÜÂú® AI ‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ\n\nÂ¶ÇÊûú Near ÊòØÂØπÁöÑÔºåÈÇ£Â∞ÜÊØîÈ¢ÑÊúüÁöÑÊõ¥Êó©Âà∞Êù•„ÄÇ\n\n\n> **ÊúâÂÖ≥ AI Á≠ñÁï•ÊàñÂàÜÊûêÁöÑÂïÜ‰∏öÂí®ËØ¢ÔºåËØ∑ËÅîÁ≥ª nacho@thewhitebox.ai**\n\n\n> Â¶ÇÊûú‰Ω†ÂñúÊ¨¢ËøôÁØáÊñáÁ´†ÔºåÊàë‰ºöÂú®ÊàëÁöÑ [LinkedIn](https://www.linkedin.com/in/ignacio-de-gregorio-noblejas/) ‰∏ä‰ª•Êõ¥ÂÖ®Èù¢ÂíåÁÆÄÂåñÁöÑÊñπÂºèÂÖçË¥πÂàÜ‰∫´Á±ª‰ººÁöÑÊÉ≥Ê≥ï„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-quest-for-production-quality-graph-rag-easy-to-start-hard-to-finish-46ca404cee3d","frontmatter":{"title":"ËøΩÊ±ÇÁîü‰∫ßË¥®Èáè Graph RAGÔºöÂºÄÂßãÂÆπÊòìÔºåÂÆåÊàêÈöæ","meta_title":"ËøΩÊ±ÇÁîü‰∫ßË¥®Èáè Graph RAGÔºöÂºÄÂßãÂÆπÊòìÔºåÂÆåÊàêÈöæ","description":"ÂÖãÊúç RAG ÂõæÁîü‰∫ßÂåñÊåëÊàò","date":"2024-11-01T03:56:04.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RMudHNmBOgXM1Mubj1UTkw.jpeg","categories":["Programming","Data Science","Generative AI"],"author":"Rifx.Online","tags":["graph","RAG","production","uncertainty","optimization"],"draft":false,"slug":"blog/the-quest-for-production-quality-graph-rag-easy-to-start-hard-to-finish-46ca404cee3d"},"content":"\n\n\n### ÂÖãÊúçÂõæÂΩ¢ RAG Áîü‰∫ßÂåñÁöÑÊåëÊàò\n\n\n\nÂΩìÊàëÈòÖËØªÊúÄËøëÂú® VentureBeat ‰∏äÂÖ≥‰∫é Glean [ÂàöÂàöÂú®ÊúÄÊñ∞ËûçËµÑËΩÆ‰∏≠Ëé∑ÂæóË∂ÖËøá 2.6 ‰∫øÁæéÂÖÉÁöÑÊñáÁ´†](https://venturebeat.com/data-infrastructure/how-to-take-advantage-of-a-generative-tool-fueling-gleans-260m-raise-graph-rag/)Êó∂ÔºåÊàëÊúâ‰∏§‰∏™Áõ¥Êé•ÁöÑÁõ¥Ëßâ„ÄÇÈ¶ñÂÖàÔºåÁúãÂà∞Ëøô‰∏™ÈùûÂ∏∏ÂÖ¨ÂºÄÁöÑÂõæÂΩ¢ RAG Á§∫‰æãÂÖÖÂàÜÂèëÊå•ÂÖ∂‰Ωú‰∏∫‰∏ÄÁßçÂº∫Â§ß„ÄÅÊúâ‰ª∑ÂÄºÁöÑÊäÄÊúØÁöÑÊΩúÂäõÔºåËÉΩÂ§üÊØî‰ª•ÂæÄ‰ªª‰ΩïÊó∂ÂÄôÈÉΩÊõ¥È´òÊïàÂú∞Â∞Ü‰∫∫‰ª¨‰∏éÁü•ËØÜËøûÊé•Ëµ∑Êù•ÔºåËøôËÆ©ÊàëÊÑüÂà∞Êª°ÊÑè„ÄÇÂÖ∂Ê¨°ÔºåËØªÂà∞‰ª•‰∏ãÂÜÖÂÆπËÆ©ÊàëÊÑüÂà∞ÊÉäËÆ∂‰ΩÜÂèàÈ¢áÂÖ∑È™åËØÅÊÄßÔºö\n\n> ‰∏ñÁïå‰∏äÊúÄÂ§ßÁöÑÂÖ±‰∫´Âá∫Ë°åÂÖ¨Âè∏‰πã‰∏Ä‰∫≤Ë∫´‰ΩìÈ™å‰∫ÜÂÖ∂Â∏¶Êù•ÁöÑÂ•ΩÂ§Ñ„ÄÇÂú®‰∏ìÈó®ÊäïÂÖ•Êï¥‰∏™Â∑•Á®ãÂõ¢ÈòüÂºÄÂèëÁ±ª‰ººÁöÑÂÜÖÈÉ®Ëß£ÂÜ≥ÊñπÊ°àÂêéÔºå‰ªñ‰ª¨ÊúÄÁªàÂÜ≥ÂÆöËΩ¨Âêë Glean ÁöÑÂπ≥Âè∞„ÄÇ\n\n> ‚ÄúÂú®‰∏Ä‰∏™ÊúàÂÜÖÔºå‰ªñ‰ª¨Âú® Glean Âπ≥Âè∞‰∏äÁöÑ‰ΩøÁî®ÈáèÁøª‰∫Ü‰∏ÄÁï™ÔºåÂõ†‰∏∫ÁªìÊûúÊòØÊòæËÄåÊòìËßÅÁöÑÔºå‚ÄùGlean ÁöÑÈ¶ñÂ∏≠Ëê•ÈîÄÂÆò Matt Kixmoeller ËØ¥„ÄÇ\n\nËôΩÁÑ∂ÊàëÂØπÊñ∞ÈóªÊñáÁ´†‰∏≠ÊèêÂà∞ÁöÑÂ§±Ë¥•ÊÑüÂà∞ÊÉäËÆ∂Ôºå‰ΩÜÊ†πÊçÆÊàëËá™Â∑±ÁöÑÁªèÈ™å‰ª•ÂèäÂêå‰∫ãÂíåÂÆ¢Êà∑ÁöÑÁªèÂéÜÔºåÂä™ÂäõÂ∞ÜÂõæÂΩ¢ RAG Êé®ÂêëÁîü‰∫ßÊòØÊàëÊâÄÈ¢ÑÊñôÁöÑ„ÄÇÊàëÂπ∂‰∏çÊòØËØ¥ÊàëÊúüÊúõÂ§ßÂûãÁßëÊäÄÂÖ¨Âè∏Âú®ÊûÑÂª∫Ëá™Â∑±ÁöÑÂõæÂΩ¢ RAG Á≥ªÁªüÊó∂‰ºöÂ§±Ë¥•„ÄÇ**ÊàëÂè™ÊòØÊúüÊúõÂ§ßÂ§öÊï∞‰∫∫‰ºöÂú®ÊûÑÂª∫ÂíåÁîü‰∫ßÂåñÂõæÂΩ¢ RAG Êó∂ÈÅáÂà∞Âõ∞Èöæ‚Äî‚ÄîÂç≥‰Ωø‰ªñ‰ª¨Â∑≤ÁªèÊúâ‰∏Ä‰∏™ÈùûÂ∏∏ÊàêÂäüÁöÑÊ¶ÇÂøµÈ™åËØÅ„ÄÇ**\n\nÊàëÂú® [The New Stack ‰∏äÂØπ VentureBeat ÊñáÁ´†ÂÅö‰∫Ü‰∏Ä‰∏™È´òÂ±ÇÊ¨°ÁöÑÂèçÂ∫î](https://bit.ly/4fjIlgJ)ÔºåÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÊÉ≥Ê∑±ÂÖ•Êé¢ËÆ®‰∏∫‰ªÄ‰πàÂõæÂΩ¢ RAG ÂèØËÉΩÂ¶ÇÊ≠§Èöæ‰ª•ÂÅöÂà∞Ê≠£Á°Æ„ÄÇÈ¶ñÂÖàÔºåÊàëÂ∞ÜÊåáÂá∫ÔºåÂà©Áî®ÊúÄÊñ∞Â∑•ÂÖ∑ÔºåÂºÄÂßã‰ΩøÁî®ÂõæÂΩ¢ RAG ÂèòÂæóÂ§ö‰πàÁÆÄÂçï„ÄÇÁÑ∂ÂêéÔºåÊàëÂ∞ÜÊ∑±ÂÖ•Êé¢ËÆ®‰∏Ä‰∫õÁâπÂÆöÁöÑÂõæÂΩ¢ RAG ÊåëÊàòÔºåËøô‰∫õÊåëÊàò‰ΩøÂÖ∂‰ªéÁ†îÂèëËΩ¨ÂêëÁîü‰∫ßÂèòÂæóÂ¶ÇÊ≠§Âõ∞Èöæ„ÄÇÊúÄÂêéÔºåÊàëÂ∞ÜÂàÜ‰∫´‰∏Ä‰∫õÂÖ≥‰∫éÂ¶Ç‰ΩïÊúÄÂ§ßÂåñÊàêÂäüÊú∫‰ºöÁöÑÂõæÂΩ¢ RAG ÁöÑÂª∫ËÆÆ„ÄÇ\n\n## ÂºÄÂßã‰ΩøÁî®ÂõæÂΩ¢ RAG ÂæàÁÆÄÂçï\n\nÂ¶ÇÊûú‰∏ÄÂÆ∂Â§ßÂûãÂÖ±‰∫´Âá∫Ë°åÂÖ¨Âè∏Êó†Ê≥ïÊúâÊïàÊûÑÂª∫Ëá™Â∑±ÁöÑÂπ≥Âè∞ÔºåÈÇ£‰πàÊàë‰∏∫‰ªÄ‰πà‰ºöËØ¥Ëá™Â∑±ÂÆûÁé∞ÂõæÂΩ¢ RAG ÂæàÁÆÄÂçïÂë¢Ôºü\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*l6EiwfjeUGLjVlYeiY1lqA.jpeg)\n\nÈ¶ñÂÖàÔºåÊîØÊåÅ RAG ÂíåÂõæÂΩ¢ RAG ÁöÑÊäÄÊúØÂú®ËøáÂéª‰∏ÄÂπ¥‰∏≠ÂèñÂæó‰∫ÜÈïøË∂≥ÁöÑËøõÊ≠•„ÄÇÂçÅ‰∫å‰∏™ÊúàÂâçÔºåÂ§ßÂ§öÊï∞‰ºÅ‰∏öÁîöËá≥Ê≤°ÊúâÂê¨ËØ¥ËøáÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê„ÄÇÁé∞Âú®ÔºåRAG ÊîØÊåÅ‰∏ç‰ªÖÊòØ [ÂÉè LangChain ËøôÊ†∑ÁöÑÊúÄ‰Ω≥ AI ÊûÑÂª∫Â∑•ÂÖ∑ÁöÑÂÖ≥ÈîÆÁâπÊÄß](https://python.langchain.com/docs/tutorials/rag/)ÔºåËÄå‰∏îÂá†‰πéÊØè‰∏™‰∏ªË¶ÅÁöÑ AI ÂèÇ‰∏éËÄÖÈÉΩÊúâ RAG ÊïôÁ®ãÔºåÁîöËá≥ËøòÊúâ [Coursera ËØæÁ®ã](https://www.coursera.org/projects/introduction-to-rag)„ÄÇÂ∞ùËØï RAG ÁöÑÂø´ÈÄüÂÖ•Èó®ÈÄîÂæÑÂ±ÇÂá∫‰∏çÁ©∑„ÄÇ\n\nÂæÆËΩØÂèØËÉΩ‰∏çÊòØÁ¨¨‰∏Ä‰∏™ÂÅöÂõæÂΩ¢ RAG ÁöÑÂÖ¨Âè∏Ôºå‰ΩÜ‰ªñ‰ª¨Âú®‰ªäÂπ¥Êó©‰∫õÊó∂ÂÄôÂèëÂ∏ÉÁöÑ [Á†îÁ©∂ÂçöÂÆ¢ÊñáÁ´†](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/) ‰∏≠ÂØπËøô‰∏ÄÊ¶ÇÂøµËøõË°å‰∫ÜÂ§ßÂäõÊé®Âä®ÔºåÂπ∂ÁªßÁª≠Ëá¥Âäõ‰∫éÁõ∏ÂÖ≥ÊäÄÊúØÁöÑÁ†îÁ©∂„ÄÇ\n\nÂú® Medium ‰∏äÔºåËøòÊúâ‰∏ÄÁØáÊù•Ëá™ [Ë∞∑Ê≠åÁöÑ‰∏Ä‰ΩçÁîüÊàê AI Â∑•Á®ãÂ∏à](https://towardsdatascience.com/graph-rag-a-conceptual-introduction-41cd0d431375) ÁöÑÂæàÂ•ΩÁöÑÊ¶ÇÂøµ‰ªãÁªçÔºåÂåÖÂê´‰∫Ü‰∏Ä‰∫õÊäÄÊúØÁªÜËäÇ„ÄÇÊ≠§Â§ñÔºåÂú® Towards Data Science ‰∏äÔºåËøòÊúâ‰∏ÄÁØáÊúÄËøëÁöÑ„ÄÅÈùûÂ∏∏ËØ¶Â∞ΩÁöÑ [ÂÖ≥‰∫éÊûÑÂª∫ÂõæÂΩ¢ RAG Á≥ªÁªüÁöÑÊìç‰ΩúÊåáÂçó](https://towardsdatascience.com/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759)Ôºå‰ª•ÂèäÂú®ÁßëÂ≠¶Âá∫ÁâàÁâ©Êï∞ÊçÆÈõÜ‰∏äËøõË°åÊµãËØïÁöÑÂÜÖÂÆπ„ÄÇ\n\nÂú®‰º†ÁªüÂõæÂΩ¢Êï∞ÊçÆÂ∫ìÂíåÂàÜÊûêÈ¢ÜÂüüÔºåÁü•ÂêçÂìÅÁâå Neo4j Âú®ÂÖ∂ÊóóËà∞ÂõæÂΩ¢Êï∞ÊçÆÂ∫ì‰∫ßÂìÅ‰∏≠Â¢ûÂä†‰∫ÜÂêëÈáèËÉΩÂäõÔºå‰ª•ÂìçÂ∫îÊúÄËøëÁöÑÁîüÊàê AI Èù©ÂëΩÔºåÂπ∂‰∏∫ÈúÄË¶ÅÂ§çÊùÇÂõæÂΩ¢ÂàÜÊûêÂíåÊ∑±Â∫¶ÂõæÂΩ¢ÁÆóÊ≥ïÁöÑÈ°πÁõÆÊèê‰æõ‰∫Ü‰∏ÄÁ≥ªÂàó‰ºòÁßÄÁöÑÂ∑•ÂÖ∑Âπ≥Âè∞ÔºåÈô§‰∫ÜÊ†áÂáÜÁöÑÂõæÂΩ¢ RAG ÂäüËÉΩÂ§ñ„ÄÇ‰ªñ‰ª¨ËøòÊèê‰æõ‰∫Ü [ÂõæÂΩ¢ RAG ÂÖ•Èó®ÊåáÂçó](https://neo4j.com/developer-blog/graphrag-ecosystem-tools/)„ÄÇ\n\nÂè¶‰∏ÄÊñπÈù¢Ôºå[ÊÇ®ÁîöËá≥‰∏çÈúÄË¶ÅÂõæÂΩ¢Êï∞ÊçÆÂ∫ìÂ∞±ÂèØ‰ª•ÂÅöÂõæÂΩ¢ RAG](https://bit.ly/3YD5NAd)„ÄÇËÆ∏Â§öÂàöÊé•Ëß¶ÂõæÂΩ¢ RAG ÁöÑ‰∫∫ËÆ§‰∏∫‰ªñ‰ª¨ÈúÄË¶ÅÈÉ®ÁΩ≤‰∏Ä‰∏™‰∏ìÈó®ÁöÑÂõæÂΩ¢Êï∞ÊçÆÂ∫ìÔºå‰ΩÜËøôÂπ∂‰∏çÊòØÂøÖË¶ÅÁöÑÔºåÂÆûÈôÖ‰∏äÂèØËÉΩ‰ºö‰ΩøÊÇ®ÁöÑÊäÄÊúØÊ†àÂèòÂæóÊõ¥Âä†Â§çÊùÇ„ÄÇ\n\nÊàëÁöÑÈõá‰∏ª DataStax ‰πüÊúâ [ÂõæÂΩ¢ RAG ÊåáÂçó](https://bit.ly/4862Lrl)„ÄÇ\n\nÂΩìÁÑ∂Ôºå‰∏§‰∏™ÊúÄÂèóÊ¨¢ËøéÁöÑÁîüÊàê AI Â∫îÁî®Á®ãÂ∫èÁªÑÂêàÊ°ÜÊû∂Ôºå[LangChain](https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/) Âíå [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/cookbooks/GraphRAG_v1/)ÔºåÂêÑËá™ÈÉΩÊúâËá™Â∑±ÁöÑÂõæÂΩ¢ RAG ‰ªãÁªç„ÄÇÊ≠§Â§ñÔºåËøòÊúâ‰∏ÄÁØá [DataCamp ÊñáÁ´†](https://www.datacamp.com/tutorial/knowledge-graph-rag) ÂêåÊó∂‰ΩøÁî®‰∫ÜËøô‰∏§ËÄÖ„ÄÇ\n\nÊúâ‰∫ÜÊâÄÊúâÂèØÁî®ÁöÑÂ∑•ÂÖ∑ÂíåÊïôÁ®ãÔºåÂºÄÂßã‰ΩøÁî®ÂõæÂΩ¢ RAG ÊòØÁÆÄÂçïÁöÑÈÉ®ÂàÜ‚Ä¶‚Ä¶\n\n## ‚Ä¶‰ΩÜÂ∞ÜÂõæÂΩ¢ RAG ÊäïÂÖ•Áîü‰∫ßÊòØÂõ∞ÈöæÁöÑ\n\nËøôÊòØÊï∞ÊçÆÁßëÂ≠¶‰∏≠‰∏Ä‰∏™ÈùûÂ∏∏Âè§ËÄÅÁöÑÊïÖ‰∫ãÔºö‰∏ÄÁßçÊñ∞ÁöÑËΩØ‰ª∂ÊñπÊ≥ïËÆ∫„ÄÅÊäÄÊúØÊàñÂ∑•ÂÖ∑Âú®Á†îÁ©∂ÁéØÂ¢É‰∏≠Ëß£ÂÜ≥‰∫Ü‰∏Ä‰∫õÈáçË¶ÅÈóÆÈ¢òÔºå‰ΩÜË°å‰∏öÂú®Â∞ÜÂÖ∂ÊûÑÂª∫‰∏∫ÊØèÂ§©Êèê‰æõ‰ª∑ÂÄºÁöÑ‰∫ßÂìÅÊó∂Âç¥Èù¢‰∏¥Âõ∞Èöæ„ÄÇËøô‰∏ç‰ªÖ‰ªÖÊòØËΩØ‰ª∂ÂºÄÂèëÁöÑÂä™ÂäõÂíå‰∏ì‰∏öÊ∞¥Âπ≥ÁöÑÈóÆÈ¢ò‚Äî‚ÄîÂç≥‰ΩøÊòØÊúÄÂ§ßÁöÑ„ÄÅÊúÄ‰ºòÁßÄÁöÑÂõ¢Èòü‰πüÂèØËÉΩÊó†Ê≥ïÂÖãÊúçËß£ÂÜ≥Áé∞ÂÆû‰∏ñÁïåÈóÆÈ¢òÊâÄÊ∂âÂèäÁöÑÁé∞ÂÆûÊï∞ÊçÆÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÅ‰∏çÂèØÈ¢ÑÊµãÊÄßÂíå‰∏çÂèØÊéßÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OklHNrhsNHZF6qzeRUSd_w.jpeg)\n\n‰∏çÁ°ÆÂÆöÊÄßÊòØÊûÑÂª∫Âíå‰ΩøÁî®Êï∞ÊçÆ‰∏≠ÂøÉÁ≥ªÁªüÁöÑÂõ∫ÊúâÈÉ®ÂàÜÔºåËøô‰∫õÁ≥ªÁªüÂá†‰πéÊÄªÊòØÂÖ∑ÊúâÊüê‰∫õÈöèÊú∫ÊÄß„ÄÅÊ¶ÇÁéáÊàñÊó†ÁïåËæìÂÖ•ÁöÑÂÖÉÁ¥†„ÄÇËÄå‰∏îÔºåÂΩìËæìÂÖ•ÂíåËæìÂá∫ÊòØÈùûÁªìÊûÑÂåñÁöÑÊó∂Ôºå‰∏çÁ°ÆÂÆöÊÄßÂèØËÉΩ‰ºöÊõ¥Â§ßÔºåËøôÊ≠£ÊòØ LLM ÂíåÂÖ∂‰ªñ GenAI Â∫îÁî®Á®ãÂ∫èÁöÑËá™ÁÑ∂ËØ≠Ë®ÄËæìÂÖ•ÂíåËæìÂá∫ÁöÑÊÉÖÂÜµ„ÄÇ\n\nÊÉ≥Ë¶ÅÂ∞ùËØïÂõæÂΩ¢ RAG ÁöÑ‰∫∫ÈÄöÂ∏∏Â∑≤ÁªèÊã•Êúâ‰∏Ä‰∏™Áé∞ÊúâÁöÑ RAG Â∫îÁî®Á®ãÂ∫èÔºåËØ•Â∫îÁî®Á®ãÂ∫èÂú®ÁÆÄÂçïÁî®‰æã‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®‰∏Ä‰∫õÊõ¥Â§çÊùÇÁöÑÁî®‰æãÂíåÈúÄË¶ÅË∑®Áü•ËØÜÂ∫ìÂ§ö‰∏™‰ø°ÊÅØÁâáÊÆµÁöÑÊèêÁ§∫‰∏≠Â§±Ë¥•ÔºåÂèØËÉΩÊ∂âÂèä‰∏çÂêåÁöÑÊñáÊ°£„ÄÅ‰∏ä‰∏ãÊñá„ÄÅÊ†ºÂºèÊàñÁîöËá≥Êï∞ÊçÆÂ≠òÂÇ®„ÄÇÂΩìÂõûÁ≠îÈóÆÈ¢òÊâÄÈúÄÁöÑÊâÄÊúâ‰ø°ÊÅØÈÉΩÂú®Áü•ËØÜÂ∫ì‰∏≠Ôºå‰ΩÜ RAG Á≥ªÁªüÊâæ‰∏çÂà∞Êó∂ÔºåËøô‰ºº‰πéÊòØ‰∏Ä‰∏™Â§±Ë¥•„ÄÇ‰ªéÁî®Êà∑‰ΩìÈ™å (UX) ÁöÑËßíÂ∫¶Êù•ÁúãÔºåÁ°ÆÂÆûÂ¶ÇÊ≠§‚Äî‚ÄîÊ≤°ÊúâÁªôÂá∫Ê≠£Á°ÆÁöÑÁ≠îÊ°à„ÄÇ\n\n‰ΩÜËøôÂπ∂‰∏ç‰∏ÄÂÆöÊÑèÂë≥ÁùÄ RAG Á≥ªÁªüÂ≠òÂú®‚ÄúÈóÆÈ¢ò‚ÄùÔºåÂÆÉÂèØËÉΩÊ≠£Â¶ÇÂÖ∂ËÆæËÆ°ÈÇ£Ê†∑ËøêË°å„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÈóÆÈ¢òÊàñÈîôËØØÔºå‰ΩÜÊàë‰ª¨‰ªçÁÑ∂Ê≤°ÊúâÂæóÂà∞ÊÉ≥Ë¶ÅÁöÑÂìçÂ∫îÔºåÈÇ£‰∏ÄÂÆöÊÑèÂë≥ÁùÄÊàë‰ª¨ÊúüÊúõ RAG Á≥ªÁªüÂÖ∑Â§áÂÆÉÊ†πÊú¨Ê≤°ÊúâÁöÑËÉΩÂäõ„ÄÇ\n\nÂú®Êàë‰ª¨ÂÖ∑‰ΩìÊé¢ËÆ®‰∏∫‰ªÄ‰πàÂ∞ÜÂõæÂΩ¢ RAG ÊäïÂÖ•Áîü‰∫ßÂæàÂõ∞Èöæ‰πãÂâçÔºåËÆ©Êàë‰ª¨ÂÖàÁúãÁúãÊàë‰ª¨ËØïÂõæËß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n\n## ÂõæÂΩ¢ RAG Ëß£ÂÜ≥ÁöÑ‰∏ªË¶ÅÊåëÊàò\n\nÂõ†‰∏∫ÊôÆÈÄöÁöÑ RAG Á≥ªÁªüÔºàÊ≤°ÊúâÁü•ËØÜÂõæË∞±Ôºâ‰ªÖÂü∫‰∫éÂêëÈáèÊêúÁ¥¢Êù•Ê£ÄÁ¥¢ÊñáÊ°£ÔºåÊâÄ‰ª•Âè™ËÉΩÊ£ÄÁ¥¢‰∏éÊü•ËØ¢Âú®ËØ≠‰πâ‰∏äÊúÄÁõ∏‰ººÁöÑÊñáÊ°£„ÄÇÈÇ£‰∫õÂÆåÂÖ®‰∏çÁõ∏‰ººÊàñÁõ∏‰ººÂ∫¶‰∏çÂ§üÁöÑÊñáÊ°£ÂàôË¢´ÊéíÈô§Âú®Â§ñÔºåÈÄöÂ∏∏‰∏ç‰ºöÂú®Êü•ËØ¢Êó∂Êèê‰æõÁªôÁîüÊàêÂìçÂ∫îÁöÑ LLM„ÄÇ\n\nÂΩìÊàë‰ª¨ÈúÄË¶ÅÂõûÁ≠îÊèêÁ§∫‰∏≠ÁöÑÈóÆÈ¢òÁöÑÊñáÊ°£Âπ∂‰∏çÈÉΩÊòØ‰∏éÊèêÁ§∫Âú®ËØ≠‰πâ‰∏äÁõ∏‰ººÊó∂ÔºåRAG Á≥ªÁªüÂæÄÂæÄ‰ºöÈÅóÊºè‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÊñáÊ°£„ÄÇËøôÁßçÊÉÖÂÜµÂèØËÉΩÂèëÁîüÂú®ÂõûÁ≠îÈóÆÈ¢òÊó∂ÈúÄË¶ÅÊ∑∑Âêà‰∏ÄËà¨ÊÄßÂíå‰∏ì‰∏öÊÄßÁöÑÊñáÊ°£ÊàñÊúØËØ≠ÔºåÂπ∂‰∏îÂΩìÊñáÊ°£Âú®ÁªÜËäÇ‰∏äÈùûÂ∏∏ÂØÜÈõÜÊó∂ÔºåÊüê‰∫õÂØπËøô‰∏™ÁâπÂÆöÊèêÁ§∫ÈùûÂ∏∏ÈáçË¶ÅÁöÑÁªÜËäÇÂèØËÉΩ‰ºöË¢´ÂüãÊ≤°Âú®‰∏éËØ•ÊèêÁ§∫‰∏çÂ§™Áõ∏ÂÖ≥ÁöÑÁõ∏ÂÖ≥ÁªÜËäÇ‰∏≠„ÄÇËØ∑ÂèÇËßÅ [ËøôÁØáÊñáÁ´†Ôºå‰∫ÜËß£ RAG Â¶Ç‰ΩïÈÅóÊºèÊñáÊ°£ÁöÑ‰æãÂ≠ê](https://bit.ly/3BKZAJv)ÔºåÂõ†‰∏∫‰∏§‰∏™Áõ∏ÂÖ≥Ê¶ÇÂøµÔºàÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÊòØ‚ÄúÂ§™Á©∫Èíà‚ÄùÂíå‚Äú‰∏ãÁöáÂêéÂÆâÂ¶ÆÁ§æÂå∫‚ÄùÔºâÂú®ËØ≠‰πâ‰∏äÂπ∂‰∏çÁõ∏‰ººÔºåÂπ∂‰∏î [ËØ∑ÂèÇËßÅËøôÁØáÊñáÁ´†Ôºå‰∫ÜËß£ÈáçË¶ÅÁªÜËäÇÂ¶Ç‰ΩïË¢´ÂüãÊ≤°ÁöÑ‰æãÂ≠ê](https://bit.ly/4ffhrqi)ÔºåÂõ†‰∏∫ÂêëÈáèÂµåÂÖ•ÊòØ‚ÄúÊúâÊçü‚ÄùÁöÑ„ÄÇ\n\nÂΩìÊàë‰ª¨ÁúãÂà∞Ê£ÄÁ¥¢‚ÄúÂ§±Ë¥•‚ÄùÊú™ËÉΩÊâæÂà∞Ê≠£Á°ÆÁöÑÊñáÊ°£Êó∂ÔºåÂèØËÉΩ‰ºöÊÉ≥Ë¶ÅÂ∞ùËØïÊîπËøõÂêëÈáèÊêúÁ¥¢Êàñ‰ΩøÂÖ∂Êõ¥Ë¥¥ÂêàÊàë‰ª¨ÁöÑÁî®‰æã„ÄÇ‰ΩÜËøôÈúÄË¶ÅË∞ÉÊï¥ÂµåÂÖ•ÔºåËÄåÂµåÂÖ•ÊòØÂ§çÊùÇÁöÑ„ÄÅÊ∑∑‰π±ÁöÑ„ÄÅËÆ°ÁÆóÊàêÊú¨È´òÊòÇÁöÑÔºåÁîöËá≥ÂæÆË∞ÉÁöÑÊàêÊú¨Êõ¥È´ò„ÄÇÊ≠§Â§ñÔºåËøôÁîöËá≥‰∏çÊòØËß£ÂÜ≥ÈóÆÈ¢òÁöÑÊúÄ‰Ω≥ÊñπÊ≥ï„ÄÇ\n\n‰æãÂ¶ÇÔºåÁúãÁúã‰∏äÈù¢ÈìæÊé•ÁöÑ‰æãÂ≠êÔºåÊàë‰ª¨ÁúüÁöÑÊÉ≥‰ΩøÁî®‰∏Ä‰∏™Â∞Ü‚ÄúÂ§™Á©∫Èíà‚ÄùÂíå‚Äú‰∏ãÁöáÂêéÂÆâÂ¶ÆÁ§æÂå∫‚ÄùÂú®ËØ≠‰πâÂêëÈáèÁ©∫Èó¥‰∏≠ÊîæÂæóÂæàËøëÁöÑÂµåÂÖ•ÁÆóÊ≥ïÂêóÔºü‰∏çÔºåÂæÆË∞ÉÊàñÂØªÊâæ‰∏Ä‰∏™Â∞ÜËøô‰∏§‰∏™ÊúØËØ≠Âú®ËØ≠‰πâÁ©∫Èó¥‰∏≠ÊîæÂæóÈùûÂ∏∏ËøëÁöÑÂµåÂÖ•ÁÆóÊ≥ïÂèØËÉΩ‰ºö‰∫ßÁîü‰∏Ä‰∫õÊÑèÊÉ≥‰∏çÂà∞Âíå‰∏çÂ∏åÊúõÁöÑÂâØ‰ΩúÁî®„ÄÇ\n\nÊúÄÂ•Ω‰∏çË¶ÅÂº∫Ëø´ËØ≠‰πâÊ®°ÂûãÂéªÂÅö‰∏Ä‰∏™Âú∞ÁêÜÊàñÊóÖÊ∏∏‰ø°ÊÅØÊõ¥ÈÄÇÂêàÁöÑÂ∑•‰Ωú„ÄÇÂ¶ÇÊûúÊàëÊòØ‰∏Ä‰∏™‰æùËµñ‰∫é‰∫ÜËß£Ëøô‰∫õÂú∞Ê†áÊâÄÂú®Á§æÂå∫ÁöÑÊóÖË°åÊàñÊóÖÊ∏∏ÂÖ¨Âè∏ÔºåÊàëÂÆÅÊÑøÂª∫Á´ã‰∏Ä‰∏™ËÉΩÂ§üÁ°ÆÂÆöËøô‰∫õ‰ø°ÊÅØÁöÑÊï∞ÊçÆÂ∫ì‚Äî‚ÄîËøô‰∏™‰ªªÂä°ÊØîËÆ©ËØ≠‰πâÂêëÈáèÊêúÁ¥¢ÂÆåÊàêÂêåÊ†∑ÁöÑ‰ªªÂä°Ë¶ÅÂÆπÊòìÂæóÂ§ö‚Ä¶‚Ä¶ËÄå‰∏îÊ≤°ÊúâÂÆåÂÖ®ÁöÑÁ°ÆÂÆöÊÄß„ÄÇ\n\nÂõ†Ê≠§ÔºåËøôÈáå‰∏ªË¶ÅÁöÑÈóÆÈ¢òÊòØÔºåÊàë‰ª¨Êúâ‰∏Ä‰∫õÊàë‰ª¨Áü•ÈÅì‰ª•ÊüêÁßçÊñπÂºèÁõ∏ÂÖ≥ÁöÑÊ¶ÇÂøµÂíå‰ø°ÊÅØÔºå‰ΩÜÂú®ËØ≠‰πâÂêëÈáèÁ©∫Èó¥‰∏≠Âπ∂‰∏çÁõ∏ÂÖ≥„ÄÇÊüê‰∫õÂÖ∂‰ªñÔºàÈùûÂêëÈáèÔºâ‰ø°ÊÅØÊù•Ê∫êÂëäËØâÊàë‰ª¨ÔºåÊàë‰ª¨Ê≠£Âú®Â§ÑÁêÜÁöÑÂêÑÁßçÊ¶ÇÂøµ‰πãÈó¥Â≠òÂú®ËÅîÁ≥ª„ÄÇÊûÑÂª∫ÂõæÂΩ¢ RAG Â∫îÁî®ÁöÑ‰ªªÂä°ÊòØÊúâÊïàÂú∞Â∞ÜËøô‰∫õÊ¶ÇÂøµ‰πãÈó¥ÁöÑËøûÊé•ÊçïÊçâÂà∞Áü•ËØÜÂõæË∞±‰∏≠ÔºåÂπ∂Âà©Áî®ÂõæÂΩ¢ËøûÊé•Êù•Ê£ÄÁ¥¢Êõ¥Áõ∏ÂÖ≥ÁöÑÊñáÊ°£Ôºå‰ª•ÂìçÂ∫îÊèêÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*flPVNMUm83oc7H9Lt7U5AA.jpeg)\n\nÊÄªÁªì‰∏Ä‰∏ãÊàë‰ª¨ËØïÂõæÈÄöËøáÂõæÂΩ¢ RAG Ëß£ÂÜ≥ÁöÑÈóÆÈ¢òÔºöÂ≠òÂú®ÂçäÁªìÊûÑÂåñ„ÄÅÈùûËØ≠‰πâÁöÑ‰ø°ÊÅØËøûÊé•ÁùÄÊàëÈùûÁªìÊûÑÂåñÊñáÊ°£‰∏≠Âá∫Áé∞ÁöÑËÆ∏Â§öÊ¶ÇÂøµ‚Äî‚ÄîÊàëÂ∏åÊúõÂà©Áî®Ëøô‰∫õËøûÊé•‰ø°ÊÅØÊù•Ë°•ÂÖÖËØ≠‰πâÂêëÈáèÊêúÁ¥¢Ôºå‰ª•Ê£ÄÁ¥¢ÊúÄÈÄÇÂêàÂõûÁ≠îÊàëÁî®‰æã‰∏≠ÊèêÁ§∫ÂíåÈóÆÈ¢òÁöÑÊñáÊ°£„ÄÇÊàë‰ª¨Âè™ÊòØÊÉ≥ËÆ©Ê£ÄÁ¥¢ÂèòÂæóÊõ¥Â•ΩÔºåÂπ∂Â∏åÊúõ‰ΩøÁî®‰∏Ä‰∫õÂ§ñÈÉ®‰ø°ÊÅØÊàñÂ§ñÈÉ®ÈÄªËæëÊù•ÂÆûÁé∞Ëøô‰∏ÄÁÇπÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖ‰æùËµñËØ≠‰πâÂêëÈáèÊêúÁ¥¢Êù•ËøûÊé•ÊèêÁ§∫‰∏éÊñáÊ°£„ÄÇ\n\n## Â∞ÜÂõæÂΩ¢‰∏é RAG ÈõÜÊàêÁöÑÊåáÂØºÂéüÂàô\n\nËÄÉËôëÂà∞‰∏äËø∞Âä®Êú∫‚Äî‚Äî‰ΩøÁî®‚ÄúÂ§ñÈÉ®‚Äù‰ø°ÊÅØÊù•Âª∫Á´ãËØ≠‰πâÊêúÁ¥¢ÂèØËÉΩÈÅóÊºèÁöÑÊñáÊ°£ËøûÊé•‚Äî‚ÄîÂú®ÊûÑÂª∫ÂíåÊµãËØïÂõæÂΩ¢ RAG Â∫îÁî®Á®ãÂ∫èÊó∂ÔºåÊàë‰ª¨ÂèØ‰ª•Áâ¢ËÆ∞‰∏Ä‰∫õÊåáÂØºÂéüÂàôÔºö\n\n1. ÂõæÂΩ¢Â∫îÂåÖÂê´È´òË¥®Èáè„ÄÅÊúâÊÑè‰πâÁöÑÊ¶ÇÂøµÂíåËøûÊé•\n2. Ê¶ÇÂøµÂíåËøûÊé•Â∫î‰∏éÁî®‰æãÈõÜ‰∏≠ÁöÑÊèêÁ§∫Áõ∏ÂÖ≥\n3. ÂõæÂΩ¢ËøûÊé•Â∫îË°•ÂÖÖËÄå‰∏çÊòØÊõø‰ª£ÂêëÈáèÊêúÁ¥¢\n4. Â∫î‰ºòÂÖàËÄÉËôë‰∏ÄÊ≠•Âíå‰∏§Ê≠•ÂõæÂΩ¢ËøûÊé•ÁöÑÂÆûÁî®ÊÄßÔºõ‰æùËµñ‰∫éË∂ÖËøá‰∏âÊ≠•ÁöÑËøûÊé•Â∫î‰ªÖÈôê‰∫é‰∏ì‰∏öÁî®‰æã„ÄÇ\n\n‰πüËÆ∏Âú®Êú™Êù•ÁöÑÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•Êé¢ËÆ®ÈÅµÂæ™Ëøô‰∫õÂéüÂàôÁöÑÁªÜÂæÆÂ∑ÆÂà´ÂíåÊΩúÂú®ÂΩ±ÂìçÔºå‰ΩÜÁõÆÂâçÊàëÂè™ÊÉ≥ÊåáÂá∫ÔºåËøô‰∏™ÂàóË°®Êó®Âú®ÂÖ±ÂêåÊèêÈ´òÂèØËß£ÈáäÊÄßÔºåÈò≤Ê≠¢Ëøá‰∫éÂ§çÊùÇÔºåÂπ∂ÊúÄÂ§ßÂåñÊûÑÂª∫Âíå‰ΩøÁî®ÂõæÂΩ¢ RAG Á≥ªÁªüÁöÑÊïàÁéá„ÄÇ\n\nÈÅµÂæ™Ëøô‰∫õÂéüÂàô‰ª•ÂèäËΩØ‰ª∂Â∑•Á®ãÂíåÊï∞ÊçÆÁßëÂ≠¶ÁöÑÂÖ∂‰ªñÊ†∏ÂøÉÂéüÂàôÔºåÂèØ‰ª•Â¢ûÂä†ÊàêÂäüÊûÑÂª∫ÊúâÁî®‰∏îÂº∫Â§ßÁöÑÂõæÂΩ¢ RAG Â∫îÁî®Á®ãÂ∫èÁöÑÊú∫‰ºöÔºå‰ΩÜÂú®Ê≠§ËøáÁ®ã‰∏≠ËÇØÂÆö‰ºöÊúâÈô∑Èò±ÔºåÊàë‰ª¨Â∞ÜÂú®‰∏ã‰∏ÄËäÇ‰∏≠Ê¶ÇËø∞„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*twgres708JPQHa1uZrkwDA.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*5U0k4GoHTFiQhKM2a6xdMA.jpeg)\n\n## ‰Ω†ÁöÑÂõæÂΩ¢ RAG Â∫îÁî®ÂèØËÉΩÊó†Ê≥ïÊäïÂÖ•Áîü‰∫ßÁöÑÂéüÂõ†\n\n‰ªª‰ΩïËä±Ë¥πÂ§ßÈáèÊó∂Èó¥Âõ¥ÁªïÊï∞ÊçÆ„ÄÅÂ§çÊùÇÁÆóÊ≥ï„ÄÅÁªüËÆ°Â≠¶Âíå‰∫∫Á±ªÁî®Êà∑ÊûÑÂª∫ËΩØ‰ª∂ÁöÑ‰∫∫ÈÉΩÂèØËÉΩÁêÜËß£ÔºåÂú®ÊûÑÂª∫ÂÉèÂõæÂΩ¢ RAG ËøôÊ†∑ÁöÑÁ≥ªÁªüÊó∂Â≠òÂú®ÂæàÂ§ö‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂú®Êï∞ÊçÆÂáÜÂ§áÂíåÂä†ËΩΩ„ÄÅÊûÑÂª∫Áü•ËØÜÂõæË∞±„ÄÅÊü•ËØ¢ÂíåÈÅçÂéÜÂõæÂΩ¢„ÄÅÁªìÊûúÊ±áÁºñÂíåÊèêÁ§∫ÊûÑÂª∫Ôºå‰ª•ÂèäÂá†‰πéÂ∑•‰ΩúÊµÅÁ®ã‰∏≠ÁöÑ‰ªª‰ΩïÂÖ∂‰ªñÁÇπÔºåÈÉΩÂèØËÉΩÂèëÁîüÊÑèÂ§ñÊÉÖÂÜµ„ÄÇ\n\nÂú®‰∏äÈù¢ÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂ¶Ç‰ΩïËΩªÊùæÂÆûÁé∞ÂõæÂΩ¢ RAG ‰ª•Ëé∑ÂæóÂàùÊ≠•ÁªìÊûúÔºå‰ΩÜË¶ÅËé∑ÂæóËâØÂ•ΩÁöÑÁªìÊûúÔºåÊõ¥‰∏çÁî®ËØ¥Áîü‰∫ßÁ∫ßÂà´ÁöÑÁªìÊûú‰∫ÜÔºåÂèØËÉΩ‰ºöÂæàÂõ∞Èöæ„ÄÇÊé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞ÜÁúãÁúãÂú®ÊûÑÂª∫ÂíåÊµãËØïÂõæÂΩ¢ RAG Â∫îÁî®Êó∂ÂèØËÉΩÈÅáÂà∞ÁöÑ‰∏Ä‰∫õÊΩúÂú®ÈóÆÈ¢ò„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1J9hwwZDuYZ3WNrxCl_cOA.jpeg)\n\n### ÂõæÂΩ¢RAGÁöÑË°®Áé∞‰∏éÊôÆÈÄöRAGÁõ∏Â∑ÆÊó†Âá†\n\nÂ¶ÇÊûúÊÇ®ÁöÑÂõæÂΩ¢RAGÁ≥ªÁªüÁöÑÊÄßËÉΩ‰∏éÊôÆÈÄöRAGÂ§ßËá¥Áõ∏ÂêåÔºåÂèØËÉΩÊúâÂ§öÁßçÂéüÂõ†„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåËøô‰ºº‰πéÊÑèÂë≥ÁùÄÂõæÂΩ¢Âπ∂Ê≤°Êúâ‰∏∫Á≥ªÁªüÂ¢ûÂä†‰ª∑ÂÄºÔºå‰ΩÜËøôÂèØËÉΩÊòØÁî±‰∫é‰ΩéË¥®ÈáèÁöÑÁü•ËØÜÂõæ„ÄÅÂõæÁöÑÂà©Áî®‰∏çË∂≥„ÄÅÂèÇÊï∞ËÆæÁΩÆ‰∏ç‰Ω≥ÊàñÂÖ∂‰ªñËÆ∏Â§öÂéüÂõ†ÈÄ†ÊàêÁöÑ„ÄÇÊàñËÄÖÔºåÊ†πÊú¨Ê≤°ÊúâÈóÆÈ¢òÔºõÂêëÈáèÊêúÁ¥¢ÂèØËÉΩÂú®ÂØªÊâæÊ≠£Á°ÆÁöÑÊñáÊ°£ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåËÄåÂõæÂΩ¢Ê†πÊú¨‰∏çÈúÄË¶Å„ÄÇ\n\nÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑ‰∫ãÈ°πÔºö\n\n* ÊÇ®ÊòØÂê¶ÊúâÊôÆÈÄöRAGÊó†Ê≥ïÂæàÂ•ΩÂ§ÑÁêÜÁöÑÁ§∫‰æãÊèêÁ§∫Ôºå‰ΩÜÊÇ®ÊúüÊúõÂõæÂΩ¢RAGËÉΩÂ§üÊàêÂäüÂ§ÑÁêÜÔºüÊÇ®ËÉΩÂê¶Âú®Ëøô‰∫õÊèêÁ§∫‰∏äËøõË°å‚ÄúË∞ÉËØï‚ÄùÔºåÁúãÁúãÂêéÂè∞ÂèëÁîü‰∫Ü‰ªÄ‰πàÔºü\n* Áü•ËØÜÂõæÊòØÂê¶ÂåÖÂê´ËØ≠‰πâÊêúÁ¥¢ÂèØËÉΩÊó†Ê≥ïÂª∫Á´ãÁöÑÊúâÊÑè‰πâËøûÊé•ÔºüÊÇ®ËÉΩÂê¶ÊâæÂà∞Âú®Âõæ‰∏≠ËøûÊé•ÁöÑÊ¶ÇÂøµÂØπÁöÑÁ§∫‰æãÔºåÂÖ∂Áõ∏ÂÖ≥ÊñáÊ°£Âú®ÂêëÈáèÁ©∫Èó¥‰∏≠Áõ∏Ë∑ùÁîöËøúÔºüÁü•ËØÜÂõæÂ∫îËØ•Âú®‚ÄúËøúÁ¶ª‚ÄùÁöÑÊñáÊ°£‰πãÈó¥Âª∫Á´ãÊúâÊÑè‰πâÁöÑËøûÊé•„ÄÇ\n\n### ‰Ω†Ôºà‰ªçÁÑ∂ÔºâÁúãÂà∞ÂπªËßâ\n\nÂ¶ÇÊûú‰Ω†Âú®‰ΩøÁî®ÂõæÂΩ¢ RAG Êó∂ÁúãÂà∞ÁöÑÂπªËßâ‰∏é‰ΩøÁî®ÊôÆÈÄö RAG Êó∂‰∏çÂêåÔºåÊàë‰ºöÊÄÄÁñëÊüêÂ§ÑÂ≠òÂú®ÈîôËØØÊàñÂèÇÊï∞ËÆæÁΩÆ‰∏çÂΩì„ÄÇÂ¶ÇÊûú‰Ω†ÁúãÂà∞ÁöÑÂπªËßâÊ∞¥Âπ≥Áõ∏‰ººÔºåËøôÂê¨Ëµ∑Êù•ÂÉèÊòØ‰∏Ä‰∏™Ë∂ÖÂá∫ÂõæÂΩ¢ÊñπÈù¢ÁöÑ‰∏ÄËà¨ÈóÆÈ¢ò„ÄÇ\n\nÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑ‰∫ãÈ°πÔºö\n\n* ‰Ω†ÁöÑÊñáÊ°£ÈõÜÊòØÂê¶ÂåÖÂê´ÂØπÂºïÂèëÂπªËßâÁöÑÊèêÁ§∫ÁöÑÊ≠£Á°ÆÂìçÂ∫îÔºüÂêëÈáèÊêúÁ¥¢ÊòØÂê¶ÊâæÂà∞‰∫ÜËøô‰∫õÊñáÊ°£Ôºü\n* ‰ªéÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£‰∏≠Ëé∑ÂèñÁöÑÊ≠£Á°ÆÂìçÂ∫îÊòØÂê¶Ê≠£Á°ÆÊèíÂÖ•Âà∞‰º†ÈÄíÁªô LLM ÁöÑÊèêÁ§∫‰∏ä‰∏ãÊñá‰∏≠Ôºü\n\n### ÂõæË°®‚ÄúËøáÂ§ß‚Äù\n\nÂΩìÊÇ®ÁöÑÁü•ËØÜÂõæË∞±‚ÄúËøáÂ§ß‚ÄùÊàñËøá‰∫éÂØÜÈõÜÊó∂ÔºåÂèØËÉΩ‰ºöÂá∫Áé∞‰∏§Áßç‰∏ªË¶ÅÈóÆÈ¢ò„ÄÇÈ¶ñÂÖàÔºåÂèØËÉΩ‰ºöÂá∫Áé∞Êâ©Â±ïÊÄßÈóÆÈ¢òÔºåÊàëÂ∞ÜÂú®‰∏ãÈù¢ËÆ®ËÆ∫„ÄÇÂÖ∂Ê¨°ÔºåÂõæÈÅçÂéÜÂèØËÉΩÂØºËá¥‚ÄúËøáÂ§ö‚ÄùÁöÑÊñáÊ°£ÔºåËøô‰∫õÊñáÊ°£ÂøÖÈ°ªÈáçÊñ∞ÊéíÂ∫èÂíåËøáÊª§„ÄÇÂ¶ÇÊûúÈáçÊñ∞ÊéíÂ∫èÂíåËøáÊª§Á≠ñÁï•‰∏éÊ£ÄÁ¥¢ÂíåÂõæÈÅçÂéÜÂÖÉÁ¥†‰∏çÂÖºÂÆπÔºåÊÇ®ÂèØËÉΩ‰ºöÂú®ÂõæÂàöÂèëÁé∞ÈáçË¶ÅÊñáÊ°£ÂêéÁ´ãÂç≥Â∞ÜÂÖ∂ËøáÊª§Êéâ„ÄÇ\n\nÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑÂÜÖÂÆπÔºö\n\n* ÂõæÈÅçÂéÜÂêéËøîÂõû‰∫ÜÂ§öÂ∞ëÊñáÊ°£ÔºåÂ§öÂ∞ëË¢´ÈáçÊñ∞ÊéíÂ∫èÊàñËøáÊª§ÊéâÔºüÈÄöËøáÂº∫ÂõæËøûÊé•ÊâæÂà∞ÁöÑÊñáÊ°£ÊòØÂê¶ËÉΩÊàêÂäüÂ≠òÊ¥ª‰∫éËøáÊª§‰∏≠Ôºü\n* ÊÇ®ÊòØÂê¶ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂÖÖÊª°ÈÄÇÂêàÊÇ®Áî®‰æãÁöÑÊúâÊÑè‰πâËøûÊé•ÁöÑÁü•ËØÜÂõæË∞±ÔºüÂú®Âõæ‰∏≠ÔºåÊÇ®ËÉΩÂê¶ÊâæÂà∞ËÆ∏Â§öÂØπÊÇ®ÁöÑÁî®‰æãËøá‰∫éÈÄöÁî®ÊàñÊó†ÂÖ≥ÁöÑÊ¶ÇÂøµÊàñËøûÊé•ÔºüÊÇ®ÁöÑÁü•ËØÜÂõæË∞±‰∏≠ÊúâÂ§öÂ∞ëÊòØÁî±‰ΩéË¥®Èáè‰ø°ÊÅØÁªÑÊàêÁöÑÔºü\n\n### ÂõæÂΩ¢‚ÄúÂ§™Â∞è‚Äù\n\nÊ†πÊçÆ‰∏äËø∞ÔºåÂ¶ÇÊûúÂõæÂΩ¢‚ÄúÂ§™Â§ß‚ÄùÔºåÂèØËÉΩ‰ºöÂÖÖÊª°‰ΩéË¥®ÈáèÁöÑËøûÊé•„ÄÇËÄåÂ¶ÇÊûúÂõæÂΩ¢‚ÄúÂ§™Â∞è‚ÄùÔºåÊàëÂ∏åÊúõÈÇ£ÈáåÂ≠òÂú®ÁöÑËøûÊé•ÊòØÊúâÊÑè‰πâÁöÑÔºåËøôÂæàÂ•ΩÔºå‰ΩÜÁº∫Â§±ÁöÑËøûÊé•‰∏ªË¶ÅÊúâ‰∏§ÁßçÁ±ªÂûã„ÄÇÁ¨¨‰∏ÄÁßçÊòØÁî±‰∫éÂõæÂΩ¢ÊûÑÂª∫ËøáÁ®ã‰∏≠Âá∫Áé∞ÁöÑÈîôËØØÂºïËµ∑ÁöÑ„ÄÇÁ¨¨‰∫åÁßçÊòØÁî±‰∫éÂõæÂΩ¢ÊûÑÂª∫Êú™ÈíàÂØπÂÖ∂ËøõË°åËÆæËÆ°„ÄÇ‰∏çÂêå‰∏ä‰∏ãÊñáÊàñ‰∏çÂêåÊ†ºÂºèÁöÑÊï∞ÊçÆÂèØËÉΩ‰ºöË¢´‰∏çÂêåÁöÑÂõæÂΩ¢ÊûÑÂª∫ÊñπÊ≥ï‰ª•‰∏çÂêåÁöÑÊñπÂºèÂ§ÑÁêÜ„ÄÇ\n\nÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑÂÜÖÂÆπÔºö\n\n* ‰Ω†ÊòØÂê¶‰ΩøÁî®Â∏¶ÊúâÂÆû‰Ωì/ÂÖ≥ÈîÆËØçÊèêÂèñÁöÑLLMÊûÑÂª∫‰∫ÜÁü•ËØÜÂõæË∞±Ôºü‰Ω†ÊòØÂê¶ÊçïËé∑‰∫ÜÊØè‰∏™ÊñáÊ°£‰∏≠ÊâÄÊúâÊúâÊÑè‰πâÁöÑÂÆû‰ΩìÔºåËøòÊòØLLMÈôêÂà∂‰∫ÜÂÖ∂ËæìÂá∫Ôºü\n* Âú®‰Ω†ÁöÑÊñáÊ°£‰∏≠ÔºåÊúâÂì™‰∫õÊ¶ÇÂøµÂíåËøûÊé•ÊòØ‰Ω†ÊúüÊúõÂá∫Áé∞Âú®Áü•ËØÜÂõæË∞±‰∏≠ÁöÑÔºå‰ΩÜ‰ºº‰πéÁº∫Â§±‰∫ÜÔºü‰Ω†ÊúüÂæÖÂÆÉ‰ª¨‰ΩïÊó∂‰ª•ÂèäÂ¶Ç‰ΩïË¢´Ê∑ªÂä†Âà∞ÂõæË∞±‰∏≠Ôºü‰∏∫‰ªÄ‰πàÂÆÉ‰ª¨ÂÆûÈôÖ‰∏äÊ≤°ÊúâË¢´Ê∑ªÂä†Âà∞ÂõæË∞±‰∏≠Ôºü\n\n### ‰Ω†Êâæ‰∏çÂà∞‚ÄúÈÄÇ‰∏≠‚ÄùÂõæË°®\n\n‰Ω†ÊòØÂê¶ËßâÂæóÂèØ‰ª•ÊûÑÂª∫‰∏Ä‰∏™‚ÄúËøáÂ§ß‚ÄùÊàñ‚ÄúËøáÂ∞è‚ÄùÁöÑÂõæË°®Ôºå‰ΩÜÊó†Ê≥ïÊûÑÂª∫‰∏Ä‰∏™‰∏≠Á≠âÂ§ßÂ∞èÁöÑÂõæË°®Ôºü\n\nÈúÄË¶ÅÊ≥®ÊÑèÁöÑ‰∫ãÈ°πÔºö\n\n* ‰Ω†Ê≠£Âú®Êõ¥ÊîπÂì™‰∫õÂèÇÊï∞ÊàñÊñπÊ≥ïÊù•‰ªéÂ∞èÂà∞Â§ßÊàñÂèçÂêëÂèòÂåñÔºüËøô‰∫õÊòØÂê¶Â∫îËØ•ÂØπÂõæË°®Ë¥®Èáè‰∫ßÁîüÂ¶ÇÊ≠§Â§ßÁöÑÂΩ±ÂìçÔºü‰Ω†ËÉΩÂê¶Á†îÁ©∂‰∏Ä‰∫õÊ†πÊçÆÊâÄ‰ΩøÁî®ÁöÑÂõæË°®ÊûÑÂª∫ËÆæÁΩÆÊÑèÂ§ñÂá∫Áé∞ÊàñÊ∂àÂ§±ÁöÑÂõæË°®ÂÖÉÁ¥†Ôºü\n* Âè¶ËØ∑Êü•Áúã‰∏äÈù¢‚ÄúËøáÂ§ß‚ÄùÂíå‚ÄúËøáÂ∞è‚ÄùÈÉ®ÂàÜÁöÑÁõ∏ÂÖ≥ÊèêÁ§∫„ÄÇ\n\n### ‰Ω†ÁöÑÂÆûÁé∞ÈúÄË¶ÅÊñ∞ÁöÑËΩØ‰ª∂ÊàñÂ¢ûÂä†ÈÉ®ÁΩ≤Â§çÊùÇÊÄß\n\nËøôÊòØ‰∏Ä‰∏™ÁªèÂÖ∏ÁöÑÊï∞ÊçÆÁßëÂ≠¶ÈóÆÈ¢òÔºöÊûÑÂª∫ÈùûÂ∏∏ÈÖ∑ÁÇ´ÂíåÂâçÊ≤øÁöÑÊñπÊ≥ïÔºåÂç¥ÁúãÂà∞ÂºÄÂèëÂõ¢ÈòüÊãíÁªùÊàñÈöæ‰ª•Â∞Ü‰Ω†Á¨îËÆ∞Êú¨‰∏≠ÁöÑ‰ª£Á†ÅÂºïÂÖ•Áîü‰∫ßÁéØÂ¢É„ÄÇÂùöÊåÅ‰ΩøÁî®ÊúÄÊµÅË°å„ÄÅÊîØÊåÅÊúÄÂ•ΩÁöÑ‰ª•ÂèäÂ§ßÈÉ®ÂàÜÂºÄÊ∫êÁöÑÂ∑•ÂÖ∑ÔºåÂèØ‰ª•Êõ¥ÂÆπÊòìÂú∞ËøõÂÖ•Áîü‰∫ßÔºåÁâπÂà´ÊòØÂ¶ÇÊûú‰Ω†ÁöÑÁªÑÁªáÂú®ÂÖ∂‰ªñÂú∞ÊñπÂ∑≤Áªè‰ΩøÁî®Ëøô‰∫õÂ∑•ÂÖ∑ÁöÑËØù„ÄÇ\n\nÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑ‰∫ãÈ°πÔºö\n\n* ‰Ω†ÁöÑÂÆûÁé∞ÊòØÂê¶ÈúÄË¶Å‰∏∫ÂõæÂΩ¢ÂàõÂª∫Êñ∞ÁöÑÊï∞ÊçÆÂ≠òÂÇ®Ôºü‰Ω†[ÂèØËÉΩ‰∏çÈúÄË¶ÅÂõæÂΩ¢Êï∞ÊçÆÂ∫ì](https://www.datastax.com/blog/knowledge-graphs-for-rag-without-a-graphdb)ÔºåËÄå‰∏îÂèØËÉΩËÉΩÂ§ü‰ΩøÁî®‰Ω†ÁöÑÁîü‰∫ßÂêëÈáèÂ≠òÂÇ®Êù•Â§ÑÁêÜÂõæÂΩ¢„ÄÇ\n* ‰Ω†ÊòØÂê¶Âú®‰ΩøÁî®‰∏Ä‰∫õÊúÄÊµÅË°åÁöÑÂºÄÊ∫êÂ∑•ÂÖ∑Êù•ÊûÑÂª∫AIÂ∫îÁî®Á®ãÂ∫èÔºåÊØîÂ¶ÇLangChainÔºüËøô‰∫õÂ∑•ÂÖ∑ÂèØ‰ª•ÂáèÂ∞ë‰ª£Á†ÅÂ§çÊùÇÊÄßÔºå‰ΩøÂ∫îÁî®Á®ãÂ∫èÊõ¥ÂÖ∑ÂèØÁßªÊ§çÊÄßÔºåÂπ∂Êâ©Â±ïÊΩúÂú®ÁöÑÈõÜÊàêÂíåËøõ‰∏ÄÊ≠•ÂºÄÂèë„ÄÇ\n\n### ‰Ω†ÁöÑÂÆûÁé∞Êó†Ê≥ïÊâ©Â±ï\n\nÊñáÁ´† [Scaling Knowledge Graphs by Eliminating Edges](https://thenewstack.io/scaling-knowledge-graphs-by-eliminating-edges/) Âú® *The New Stack* ‰∏≠Â±ïÁ§∫‰∫Ü‰∏ÄÁßç‰ΩøÂõæÂΩ¢ RAG ÈùûÂ∏∏ÂèØÊâ©Â±ïÁöÑÊñπÊ≥ï„ÄÇÂÉè‰∏äÈù¢ÊèêÂà∞ÁöÑÔºåÊúÄÊµÅË°å„ÄÅÊîØÊåÅÊúÄÂ•ΩÁöÑ„ÄÅÂπ∂‰∏îÂ§ßÂ§öÊï∞ÊòØÂºÄÊ∫êÁöÑÂ∑•ÂÖ∑ÈÄöÂ∏∏ÊòØÊó†ÁóõÊâ©Â±ïÁöÑÊúÄ‰Ω≥Ë∑ØÂæÑÔºå‰ΩÜËøôÂπ∂‰∏çÊÄªÊòØÂÆπÊòì„ÄÇ\n\nÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑÂÜÖÂÆπÔºö\n\n* Âì™‰∏ÄÈÉ®ÂàÜÊó†Ê≥ïÊâ©Â±ïÔºüÂõæÈÅçÂéÜ„ÄÅÈáçÊñ∞ÊéíÂ∫è„ÄÅÁªìÊûúÊ±áÁºñÔºåËøòÊòØÂÖ∂‰ªñÔºüËØ∑ÂèÇËßÅ‰∏äÈù¢ÁöÑ‚ÄúThe graph is too big‚Äù‰ª•Ëé∑ÂèñÊõ¥Â§öÊèêÁ§∫„ÄÇ\n* ‰Ω†ÊòØÂê¶ÊúâÊüê‰∏™ÁâπÂÆöÁªÑ‰ª∂Êó†Ê≥ïÂæàÂ•ΩÂú∞Êâ©Â±ïÔºüÊúâÊó∂‰ΩøÁî®ÂÜÖÂ≠ò‰∏≠ÁöÑÂõæÂΩ¢Â∫ìÔºåÂ¶Ç 'networkx' ‚Äî ÊàñËÄÖÁîöËá≥ÊòØÂõæÂΩ¢Êï∞ÊçÆÂ∫ì ‚Äî Êù•ÊâßË°åÂ§çÊùÇÁöÑÂõæÂΩ¢Êìç‰ΩúÂèØËÉΩ‰ºöÈÄ†ÊàêËµÑÊ∫êÁì∂È¢à„ÄÇ‰Ω†ÂèØËÉΩÊÉ≥Ë¶Å [ÂàáÊç¢Âà∞Êõ¥ÂèØÊâ©Â±ïÁöÑÂõæÂΩ¢Êìç‰ΩúÈÄâÈ°π](https://bit.ly/3YD5NAd)„ÄÇ\n* ‰Ω†ÊòØÂê¶Âú®‰ΩøÁî®Âπ∂Ë°å API Ë∞ÉÁî®Êù•Â§ÑÁêÜÂ§ßÈÉ®ÂàÜÁπÅÈáçÁöÑÂ∑•‰ΩúÔºåËøòÊòØÂú®Â∞ùËØïÂú®‰∏ªÂ∫îÁî®ÈÄªËæë‰∏≠ËøõË°åÂ§çÊùÇÊàñÈ´òÊàêÊú¨ÁöÑËÆ°ÁÆóÔºü\n\n## Âú®Áîü‰∫ß‰∏≠Âà©Áî®ÂõæÂΩ¢RAGËé∑ÂæóÊàêÂäü\n\nÂàõÂª∫ÊàêÂäüÁöÑÂõæÂΩ¢RAGÁ≥ªÁªüÁöÑÂÖ≥ÈîÆÂú®‰∫éÊûÑÂª∫‰∏Ä‰∏™Áü•ËØÜÂõæË∞±ÂíåÈÅçÂéÜÈÄªËæëÔºå‰ª•Ë°•ÂÖÖËØ≠‰πâÂêëÈáèÊ£ÄÁ¥¢ÔºåËÄå‰∏çÊòØÂèñ‰ª£Êàñ‰∏é‰πãÁ´û‰∫â„ÄÇÂõæÂΩ¢ËÆæËÆ°Â∫îÊó®Âú®Âú®ÂêàÈÄÇÁöÑÊó∂Èó¥ËøûÊé•Ê≠£Á°ÆÁöÑËäÇÁÇπ„ÄÅÁü•ËØÜ„ÄÅÂÆû‰ΩìÂíåÊñáÊ°£Ôºå‰ªéËÄåËÉΩÂ§üÁªÑË£ÖÂêàÈÄÇÁöÑÊñáÊ°£Ôºå‰ª•‰∫ßÁîüÊúÄÊúâÂ∏ÆÂä©ÂíåÂèØÊìç‰ΩúÁöÑÊü•ËØ¢ÂìçÂ∫î„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*orXW5uw-geBo-WVtZUxWXQ.jpeg)\n\nÂÖ≥‰∫éGleanÔºåÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÜÖÈÉ®ÊñáÊ°£Êï∞ÊçÆÈõÜÊòØÂõæÂΩ¢RAGÁöÑ‰∏Ä‰∏™ÂÆåÁæéÁî®‰æã„ÄÇÁü•ËØÜÂõæË∞±ÂèØ‰ª•ËøûÊé•‰∫∫„ÄÅÈ°πÁõÆ„ÄÅ‰∫ßÂìÅ„ÄÅÂÆ¢Êà∑„ÄÅ‰ºöËÆÆ„ÄÅÂú∞ÁÇπÁ≠â‚Äî‚ÄîÊâÄÊúâËøô‰∫õÂú®Êï∞Èáè‰∏äÈÉΩÂèóÂà∞ÁªÑÁªáËßÑÊ®°ÂíåÂÖ∂Â∑•‰ΩúÂÜÖÂÆπÁöÑÈôêÂà∂„ÄÇÊûÑÂª∫ÂíåÁÆ°ÁêÜ‰∏Ä‰∏™Áî±Êï∞ÂçÉÂêçÂëòÂ∑•ÁªÑÊàêÁöÑÂõæÂΩ¢ÊØî‰æãÂ¶ÇÂ∞ùËØïÂØπÁª¥Âü∫ÁôæÁßë‰∏äÊèêÂà∞ÁöÑÊâÄÊúâ‰∫∫ÊàñÂ§ßÂûãË¥¢Âä°ÊàñÊ≥ïÂæãÊñáÊ°£Êï∞ÊçÆÂ∫ì‰∏≠ÁöÑÊâÄÊúâ‰∫∫ÂÅöÂêåÊ†∑ÁöÑ‰∫ãÊÉÖË¶ÅÂèØË°åÂæóÂ§ö„ÄÇÂõ†Ê≠§ÔºåGleanÂÅöÂá∫ÁöÑÁ¨¨‰∏Ä‰∏™ÈáçÂ§ßÂÜ≥Á≠ñÂèØËÉΩÊòØÊâæÂà∞‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂõæÂΩ¢RAGÁî®‰æãÊù•Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ\n\nÂõæÂΩ¢RAGÁ≥ªÁªüÁöÑ‰∏Ä‰∏™Â∏∏Ë¢´‰Ωé‰º∞ÁöÑÊñπÈù¢ÊòØËæìÂÖ•Êï∞ÊçÆÁöÑË¥®ÈáèÂíåÂ∞ÜÂÖ∂‰º†ËæìÂà∞ÁõÆÁöÑÂú∞ÁöÑÁÆ°ÈÅìÁöÑÂèØÈù†ÊÄß„ÄÇËøô‰∏éÊï∞ÊçÆÂ∑•Á®ãÂíå‰º†ÁªüËΩØ‰ª∂ÂºÄÂèëÁöÑÂÖ≥Á≥ªÂ§ß‰∫é‰∏éAIÁöÑÂÖ≥Á≥ª„ÄÇÂú®‰ª•ÂæÄÁöÑÊäÄÊúØËåÉÂºè‰∏≠ÔºåÁî±‰∫éÊï∞ÊçÆÁ±ªÂûãÂíåËÆøÈóÆÊñπÊ≥ïÁöÑ‰∏çÂÖºÂÆπÔºåËøûÊé•‰∏çÂêåÁöÑÊï∞ÊçÆÁ≥ªÁªüÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇÁé∞Âú®ÔºåAIÂíåLLMs‰ΩøÂæóÂ∞Ü‰∏çÂêåÊù•Ê∫êÁöÑÈùûÁªìÊûÑÂåñÊï∞ÊçÆÊï¥ÂêàÊàê‰∏∫ÂèØËÉΩÔºå‰ªéËÄåÂÖÅËÆ∏Â∞ÜÊù•Ëá™ÂêÑÁßçÊù•Ê∫êÁöÑÊï∞ÊçÆÊï¥ÂêàÂà∞‰∏Ä‰∏™Âçï‰∏ÄÁöÑRAGÁ≥ªÁªü‰∏≠„ÄÇËøôÁßçÈõÜÊàêËÉΩÂäõ‰ΩøÂæóLLMsËÉΩÂ§üÂ§ÑÁêÜÂíåÁêÜËß£Êù•Ëá™ÂêÑÁßçÊù•Ê∫êÁöÑÈùûÁªìÊûÑÂåñÊï∞ÊçÆÔºå‰æãÂ¶ÇÂÜÖÈÉ®ÁΩëÈ°µ„ÄÅÁª¥Âü∫„ÄÅ‰ª£Á†ÅÂ∫ì„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅGoogleÊñáÊ°£ÂíåËÅäÂ§©ËÆ∞ÂΩï„ÄÇ‰ªÖ‰ªÖÂ∞ÜÊâÄÊúâËøô‰∫õ‰ø°ÊÅØËøûÊé•Âú®‰∏ÄËµ∑ÔºåÂπ∂ÈÄöËøáÂçï‰∏ÄÊé•Âè£‰ΩøÂÖ∂ÂèØËÆøÈóÆÔºåÂ∞±ÂèØ‰ª•Â∏¶Êù•Â∑®Â§ßÁöÑÊî∂Áõä„ÄÇ\n\n## ÂâçËøõÁöÑÊñπÂêë\n\nÊûÑÂª∫Âõæ RAG Á≥ªÁªü‰ª•Êª°Ë∂≥‰ªª‰ΩïÁî®‰æãÈúÄË¶ÅÂà©Áî®Âü∫Á°ÄÁªÑ‰ª∂ÔºåÂ¶ÇÂêëÈáèÂíåÂõæÁöÑÊï∞ÊçÆÂ≠òÂÇ®„ÄÅÂµåÂÖ•Âíå LLMÔºåÂπ∂ÈÄöËøáÂºÄÊ∫êÁºñÊéíÂ∑•ÂÖ∑Â¶Ç LangChain Âíå LlamaIndex ËøõË°åÂ¢ûÂº∫„ÄÇËøô‰∫õÂ∑•ÂÖ∑‰øÉËøõ‰∫ÜÂº∫Â§ß„ÄÅÂèØÊâ©Â±ïÂíåÈ´òÊïàÁ≥ªÁªüÁöÑÂºÄÂèëÔºåÊâøËØ∫Êú™Êù•ÂÖ¨Âè∏ÈÄöËøáËá™Âä®ÂåñÂíåÁ≤æÁÆÄ‰ºòÂåñÁü•ËØÜÂ∑•‰ΩúÔºåÂÆûÁé∞ÊòæËëóÊàêÂäü„ÄÇ\n\nÁü•ËØÜÂõæË∞±ÂíåÂõæ RAG Á≥ªÁªüÁöÑÂÖ¨ÂÖ±ÊàêÂäüÔºåÂ∞§ÂÖ∂ÊòØÂÉè Glean ËøôÊ†∑ÁöÑÂÖ¨Âè∏ÁöÑÊàêÂäüÔºåÂ±ïÁ§∫‰∫ÜËøô‰∫õÊäÄÊúØÂú®ÂÜÖÈÉ®Áî®‰æã‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈÄöËøáÊèêÈ´òÁªÑÁªáÊïàÁéáÂàõÈÄ†‰ª∑ÂÄº„ÄÇÁÑ∂ËÄåÔºåÈù¢ÂêëÂ§ñÈÉ®ÁöÑ‰ºÅ‰∏öÂíåÊ∂àË¥πËÄÖ‰∫ßÂìÅÁöÑÊõ¥ÂπøÊ≥õÂ∫îÁî®ÊΩúÂäõ‰ªçÁÑ∂Âü∫Êú¨Êú™Ë¢´ÂºÄÂèëÔºå‰∏∫ÂÖ∂‰ªñÂÖ¨Âè∏Êèê‰æõ‰∫ÜËÆ∏Â§öÊé¢Á¥¢Êú∫‰ºö„ÄÇ\n\nÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàë‰ª¨Â∑≤ÁªèÂ§Ñ‰∫éÊâÄË∞ìÁöÑ‚Äú‰ø°ÊÅØÊó∂‰ª£‚ÄùËá≥Â∞ë 30 Âπ¥ÔºåËÄåÂú®ËøáÂéª‰∏Ä‰∏§Âπ¥‰∏≠ÔºåÊàë‰ª¨ÊâçÁúüÊ≠£ÂºÄÂßãÂ∞ÜÊâÄÊúâËøô‰∫õ‰ø°ÊÅØË∑®Êù•Ê∫ê„ÄÅË∑®ÊÄùÊÉ≥„ÄÅË∑®ÊñáÊ°£ÂíåË∑®Ê¶ÇÂøµËøûÊé•Ëµ∑Êù•Ôºå‰ª•‰æøÊàë‰ª¨ÁöÑËΩØ‰ª∂Á≥ªÁªüËÉΩÂ§üËøõË°å‰∏éÊàë‰ª¨‰∫∫Á±ªÂú®Áü•ËØÜÂ∑•‰Ωú‰∏≠Êó•Â∏∏‰ΩøÁî®ÁöÑÊé®ÁêÜ„ÄÅÈÄªËæëÂíåÂà§Êñ≠Áõ∏ÂêåÁöÑÁ±ªÂûãÁöÑÊé®ÁêÜ„ÄÇ‰∏Ä‰∫õ‰∫∫Áß∞‰πã‰∏∫‚ÄúÊô∫ËÉΩÊó∂‰ª£‚Äù„ÄÇ\n\nËôΩÁÑ∂ÊúÄÂàùÂÖ≥Ê≥®ÁÆÄÂçï„ÄÅÁõ¥Êé•ÁöÑÂÜ≥Á≠ñÔºå‰ΩÜ‰∫∫Â∑•Êô∫ËÉΩÁöÑËΩ®ËøπÊ≠£ÊúùÁùÄÁÆ°ÁêÜÊõ¥Â§çÊùÇÂú∫ÊôØÁöÑÊñπÂêëÂèëÂ±ïÔºåÊòæËëóÊèêÈ´òÊó∂Èó¥ÂíåÊàêÊú¨ÁöÑÊïàÁéá„ÄÇËøô‰∏Ä‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÊºîÂèò‰ΩøËÆ∏Â§ö‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®ÔºåÂåÖÊã¨Âõæ RAGÔºåÂú®ËΩ¨ÂèòÁü•ËØÜÂ¶Ç‰ΩïÂú®ÂêÑÁßçËÉåÊôØ‰∏ãÁõ∏‰∫íËøûÊé•ÂíåÂà©Áî®ÊñπÈù¢ÂèòÂæóËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nË¶ÅÁ´ãÂç≥ÂºÄÂßã‰ΩøÁî®Âõæ RAGÔºåÊàñ‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØÔºåËØ∑Êü•Áúã [DataStax Âõæ RAG ÊåáÂçó](https://bit.ly/4862Lrl)„ÄÇ\n\n*‰ΩúËÄÖÔºöBrian Godsey, Ph.D. ([LinkedIn](https://bit.ly/4enqFRa)) ‚Äî Êï∞Â≠¶ÂÆ∂„ÄÅÊï∞ÊçÆÁßëÂ≠¶ÂÆ∂ÂíåÂ∑•Á®ãÂ∏à // [DataStax](https://bit.ly/3NpPujA) ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂíåÊú∫Âô®Â≠¶‰π†‰∫ßÂìÅ // Ëëó‰Ωú [Think Like a Data Scientist](https://bit.ly/4f5uVES)*\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Il1GrFN6fYN7e_ovExRGPw.jpeg)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wQvZDIlkOvrYZnbwl0bEPQ.jpeg)\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-real-reason-openai-abandoned-next-js-for-remix-a4b2622ee9b2","frontmatter":{"title":"OpenAI ÊîæÂºÉ Next.js ËΩ¨ËÄå‰ΩøÁî® Remix ÁöÑÁúüÊ≠£ÂéüÂõ†","meta_title":"OpenAI ÊîæÂºÉ Next.js ËΩ¨ËÄå‰ΩøÁî® Remix ÁöÑÁúüÊ≠£ÂéüÂõ†","description":"OpenAI Ê≠§‰∏æËÉåÂêé‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÂéüÂõ†ÂèäÂÖ∂ÂØπ Web ÂºÄÂèëÁöÑÊú™Êù•ÊÑèÂë≥ÁùÄ‰ªÄ‰πà","date":"2024-11-08T00:25:31.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*bf8ao0JjEiMka6dJqp-hxg.jpeg","categories":["Technology/Web","Programming","Web Development"],"author":"Rifx.Online","tags":["Remix","Next.js","client-side","rendering","scalability"],"draft":false,"slug":"blog/the-real-reason-openai-abandoned-next-js-for-remix-a4b2622ee9b2"},"content":"\n### OpenAI ÈááÂèñË°åÂä®ËÉåÂêéÁöÑÊÉä‰∫∫ÂéüÂõ†ÂèäÂÖ∂ÂØπÊú™Êù•ÁΩëÈ°µÂºÄÂèëÁöÑÂΩ±Âìç\n\n\n\n## ËøáÊ∏°‰ªãÁªç\n\nOpenAI ÊúÄËøëÂú®ÂºÄÂèëËÄÖÁ§æÂå∫ÂºïËµ∑‰∫ÜËΩ∞Âä®ÔºåÂõ†‰∏∫ÂÆÉ‰ªé Next.js ËΩ¨Âêë‰∫Ü Remix„ÄÇ\n\nËøô‰∏ÄÊÑèÂ§ñÁöÑËΩ¨ÂèòËÆ©ËÆ∏Â§ö‰∫∫Ë¥®ÁñëÂ¶ÇÊ≠§ÈáçÂ§ßÂèòÂåñÁöÑÁêÜÁî±„ÄÇ\n\n‰ΩÜ **‰Ω†ËÉΩË¥£ÊÄ™‰ªñ‰ª¨ÂêóÔºü**\n\n‰ª•‰∏ãÊòØ **Â§ßÂ§öÊï∞ÂºÄÂèëËÄÖÂØπ NextJS ÁöÑÁúãÊ≥ï**ÔºåÂü∫‰∫é [ËøôÁØá](https://www.reddit.com/r/nextjs/comments/1f92jdv/chatgptcom_switched_from_nextjs_to_remix/) reddit ËÆ®ËÆ∫Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GCrb_aGjh1nticKNeHh9Bg.png)\n\nËøôÂæàËâ∞Èöæ„ÄÇ\n\n‰ΩÜÊàë‰πüÂú® X ‰∏äËØ¢ÈóÆ‰∫ÜÂºÄÂèëËÄÖÔºå\n\n‰ªñ‰ª¨ÂØπÂ∞èÂûãÈ°πÁõÆÁöÑÁúãÊ≥ïÂàôÊúâÊâÄ‰∏çÂêåÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YmN2pTYaCFXFzb3AMjfoqQ.png)\n\n## ËÆ©Êàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ®Ëøô‰∏™ÈóÆÈ¢ò\n\nËøôÊ¨°Êé¢Á¥¢‰∏ç‰ªÖ‰ªÖÊòØ‰∏∫‰∫ÜÁêÜËß£ OpenAI ÁöÑÂÜ≥ÂÆöÔºåËøòÊ∂âÂèäÂà∞ **ËøôÂØπÂÖ∂‰ªñÂºÄÂèëËÄÖÂíåÊõ¥ÂπøÊ≥õÁöÑÁßëÊäÄÈ¢ÜÂüüÊÑèÂë≥ÁùÄ‰ªÄ‰πà**„ÄÇ\n\n‰∏∫‰∫ÜÁêÜËß£ÂÖ∂ËÉåÂêéÁöÑÁêÜÁî±ÔºåÊàëËä±‰∫ÜÊï∞Â∞èÊó∂ÂàÜÊûê‰ª£Á†ÅÂ∫ìÂíåÂ∑•ÂÖ∑„ÄÇ\n\n‰ª•‰∏ãÊòØÊàëËé∑ÂæóÁöÑËßÅËß£„ÄÇ\n\n## ÂÖ≥‰∫éÂàáÊç¢ÁöÑÊäÄÊúØËßÅËß£\n\nÁêÜËß£Ëøô‰∏ÄËøáÊ∏°ÁöÑÊäÄÊúØÊñπÈù¢ÊòØÁêÜËß£‰∏∫‰ªÄ‰πà OpenAI ÂÅèÁà± Remix ÁöÑÂÖ≥ÈîÆ„ÄÇ\n\nÊàë‰ª¨Ê£ÄÊü•‰∫Ü‰ªñ‰ª¨ÁöÑÂ∫îÁî®Êû∂ÊûÑÔºå‰ª•ËØÜÂà´ Next.js Âíå Remix ‰πãÈó¥ÁöÑÊ†∏ÂøÉÂ∑ÆÂºÇ„ÄÇ\n\n### ÂÆ¢Êà∑Á´ØÊ∏≤Êüì‰∏éÊúçÂä°Âô®Ê∏≤Êüì\n\nOpenAI ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏ìÊ≥®‰∫é **ÂÆ¢Êà∑Á´ØÊ∏≤Êüì**ÔºåÂ§ßÈÉ®ÂàÜÂ§ÑÁêÜÂèëÁîüÂú®Áî®Êà∑ÁöÑÊµèËßàÂô®‰∏≠„ÄÇ\n\nËøôÂáèÂ∞ë‰∫ÜÂØπÊúçÂä°Âô®Ê∏≤Êüì HTML ÁöÑÈúÄÊ±Ç„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*50dv8sWPbwFp85fQu_dodQ.png)\n\n**Remix** ÈùûÂ∏∏ÈÄÇÂêàËøô‰∫õÂú∫ÊôØÔºåÂõ†‰∏∫ÂÆÉÊúâÊïàÂú∞ÁÆ°ÁêÜÂÆ¢Êà∑Á´ØÂ∫îÁî®Á®ãÂ∫è„ÄÇËøô‰∏™ÈÄâÊã©Á°Æ‰øù‰∫Ü OpenAI ÁöÑÁî®Êà∑Êã•ÊúâÊõ¥ÊµÅÁïÖ„ÄÅÊõ¥ÁÅµÊïèÁöÑ‰ΩìÈ™å„ÄÇ\n\n### ÂàùÂßãÈ°µÈù¢Âä†ËΩΩËøáÁ®ã\n\nÂΩìÁî®Êà∑ËÆøÈóÆ ChatGPT ÁΩëÁ´ôÊó∂Ôºå**È¢ÑÂä†ËΩΩÁöÑ JavaScript Âíå meta Ê†áÁ≠æ** ÂèÇ‰∏é‰∫ÜÂàùÂßãÈ°µÈù¢Âä†ËΩΩ„ÄÇ\n\nËøô‰ºòÂåñ‰∫ÜÂÆ¢Êà∑Á´ØÊ∏≤ÊüìËøáÁ®ã„ÄÇ**Remix** Âú®ÁÆ°ÁêÜËøô‰∫õÂÖÉÁ¥†ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåÁ°Æ‰øù‰∫ÜÈ°∫ÁïÖÂø´ÈÄüÁöÑÂàùÂßãÂä†ËΩΩ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*65VlHo5RQObk-YGzBlkx3w.png)\n\n## ‰∏∫‰ªÄ‰πàËøôÂæàÈáçË¶Å\n\n### ÊîπËøõÁöÑÁî®Êà∑‰ΩìÈ™å\n\nÈÄöËøáÈ¢ÑÂä†ËΩΩÂøÖË¶ÅÁöÑËÑöÊú¨ÂíåÊï∞ÊçÆÔºåÁî®Êà∑Âú®ËÆøÈóÆÁΩëÁ´ôÊó∂‰ºöÈÅáÂà∞Êõ¥Â∞ëÁöÑÂª∂ËøüÔºåÂπ∂‰∫´ÂèóÂà∞Êõ¥ÁÅµÊïèÁöÑÁïåÈù¢„ÄÇ\n\n### È´òÊïàÂä†ËΩΩ\n\nRemix Â§ÑÁêÜËøô‰∫õÈ¢ÑÂä†ËΩΩÂÖÉÁ¥†ÁöÑËÉΩÂäõÊÑèÂë≥ÁùÄÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥ÔºåÊèê‰æõÊõ¥Âø´ÁöÑÊµèËßà‰ΩìÈ™å„ÄÇ\n\nÈÄöËøáÂà©Áî®Ëøô‰∫õÂäüËÉΩÔºå\n\n*OpenAI ÂèØ‰ª•‰∏∫ÂÖ∂Áî®Êà∑‰ªé‰∏ÄÂºÄÂßãÂ∞±Êèê‰æõÊõ¥Êó†ÁºùÂíåÊÑâÊÇ¶ÁöÑ‰ΩìÈ™å„ÄÇ*\n\n## Ê∑±ÂÖ•Êé¢ËÆ® OpenAI Âà©Áî®ÁöÑ Remix ÂÖ≥ÈîÆÁâπÊÄß\n\nOpenAI Âà©Áî® Remix ÁöÑÂá†‰∏™ÂÖ≥ÈîÆÁâπÊÄßÊù•Â¢ûÂº∫‰ªñ‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n### È¢ÑÂä†ËΩΩÁ≠ñÁï•\n\nRemix È¢ÑÂä†ËΩΩÂøÖË¶ÅÁöÑÊï∞ÊçÆÂíåËµÑÊ∫êÔºåÂáèÂ∞ëÂä†ËΩΩÊó∂Èó¥Âπ∂ÊèêÂçáÊÄßËÉΩ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GPH2ZGhT_yfrQYpR2Xhvug.png)\n\nËøô‰∏ÄÁ≠ñÁï•Á°Æ‰øùÁî®Êà∑‰ªé‰∏ÄÂºÄÂßãÂ∞±ËÉΩËé∑ÂæóÊó†ÁºùÁöÑ‰ΩìÈ™å„ÄÇ\n\n### Êï∞ÊçÆÁÆ°ÁêÜ‰∏éÂä†ËΩΩÂô®\n\nRemixÁöÑÂä†ËΩΩÂô®APIÊúâÊïàÂú∞Êî∂ÈõÜÂàùÂßãÊ∏≤ÊüìÊâÄÈúÄÁöÑÊâÄÊúâÊï∞ÊçÆÔºåÂπ∂Áõ¥Êé•ÂµåÂÖ•Âà∞HTML‰∏≠„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PmCiQNkAJlu2MSFEtpydiw.png)\n\nËøôÁßçÊñπÊ≥ïÊ∂àÈô§‰∫ÜÈ¢ùÂ§ñÁöÑÂÆ¢Êà∑Á´ØÊï∞ÊçÆËé∑ÂèñÁöÑÈúÄÊ±ÇÔºåÂä†Âø´‰∫ÜÊ∏≤ÊüìËøáÁ®ã„ÄÇ\n\n## ËΩ¨Âêë Remix ÁöÑÂ•ΩÂ§ÑÂíåÂΩ±Âìç\n\nËΩ¨Âêë Remix ‰∏∫ OpenAI Êèê‰æõ‰∫ÜÂ§ö‰∏™‰ºòÂäøÔºå‰ªéÊÄßËÉΩÊèêÂçáÂà∞Êú™Êù•ÁöÑÂèëÂ±ïÂâçÊôØ„ÄÇ\n\n### ÊÄßËÉΩÊèêÂçá\n\nÈÄöËøáÈááÁî® RemixÔºåOpenAI ÂÆûÁé∞‰∫ÜÊõ¥Âø´ÁöÑÂàùÂßãÂä†ËΩΩÊó∂Èó¥ÂíåÊõ¥ÊµÅÁïÖÁöÑÂÆ¢Êà∑Á´ØÂØºËà™„ÄÇ\n\nËøô‰∫õÊÄßËÉΩÊèêÂçáÊúâÂä©‰∫éÂàõÂª∫Êõ¥ÂÖ∑ÂìçÂ∫îÊÄßÂíåÁî®Êà∑ÂèãÂ•ΩÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ\n\n### RemixÁöÑÊú™Êù•ÂâçÊôØ\n\nRemixÁöÑÁÅµÊ¥ªÊÄßÂíåÈ´òÊïàÊÄß‰∏∫OpenAIÁöÑÊú™Êù•Â¢ûÈïøÂíåÂàõÊñ∞Â•†ÂÆö‰∫ÜÂü∫Á°Ä„ÄÇ\n\nÈöèÁùÄRemixÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåOpenAIÂèØ‰ª•Âà©Áî®ÂÖ∂ÂÖàËøõÁöÑÂäüËÉΩÂú®ÁΩëÈ°µÂºÄÂèëÁöÑÁ´û‰∫âÁéØÂ¢É‰∏≠‰øùÊåÅÈ¢ÜÂÖà„ÄÇ\n\n### ‰∏∫‰ªÄ‰πàËøôÂæàÈáçË¶Å\n\n**ÊîπÂñÑÁî®Êà∑‰ΩìÈ™å**ÔºöÁî®Êà∑‰ªéÊõ¥Âø´ÁöÑÈ°µÈù¢Âä†ËΩΩÂíåÊõ¥ÊµÅÁïÖÁöÑÊµèËßà‰ΩìÈ™å‰∏≠ÂèóÁõä„ÄÇ\n\n**È´òÊïàÂºÄÂèë**ÔºöRemix ÁöÑÂäüËÉΩÁÆÄÂåñ‰∫ÜÂºÄÂèëËøáÁ®ãÔºå‰Ωø OpenAI ËÉΩÂ§üÊõ¥Âø´ÈÄüÂú∞ËøõË°åÂàõÊñ∞„ÄÇ\n\n**ÂèØÊâ©Â±ïÊÄß**ÔºöRemix ÁöÑÊû∂ÊûÑÊîØÊåÅÊú™Êù•ÁöÑÂ¢ûÂº∫ÂíåÊâ©Â±ïÔºåÁ°Æ‰øùÈïøÊúüÁöÑÂèØË°åÊÄß„ÄÇ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/the-rise-of-the-ai-agent-product-manager-and-ai-agent-engineer-0905f1d30cce","frontmatter":{"title":"‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÂíå‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÂ∑•Á®ãÂ∏àÁöÑÂ¥õËµ∑","meta_title":"‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÂíå‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÂ∑•Á®ãÂ∏àÁöÑÂ¥õËµ∑","description":"ÊÉ≥Ë±°‰∏Ä‰∏ãÊú™Êù•ÔºåÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩ‰∏ç‰ªÖËÉΩÂìçÂ∫îÊü•ËØ¢ÔºåËøòËÉΩ‰∏ªÂä®Ëß£ÂÜ≥ÂêÑ‰∏™ÊñπÈù¢ÁöÑÂ§çÊùÇÈóÆÈ¢ò‚Ä¶‚Ä¶","date":"2024-11-04T12:33:53.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dlJ0a49_lRAPR1tTPs898w.png","categories":["Generative AI","Ethics","Technology"],"author":"Rifx.Online","tags":["Generative","Product","Manager","Engineer","Ethics"],"draft":false,"slug":"blog/the-rise-of-the-ai-agent-product-manager-and-ai-agent-engineer-0905f1d30cce"},"content":"\n\n\n\n\nÊÉ≥Ë±°‰∏Ä‰∏™Êú™Êù•ÔºåÁîüÊàêÂºèAI‰∏ç‰ªÖ‰ªÖÊòØÂìçÂ∫îÊü•ËØ¢ÔºåËÄåÊòØ‰∏ªÂä®Ëß£ÂÜ≥ÂïÜ‰∏öÂêÑ‰∏™ÊñπÈù¢ÁöÑÂ§çÊùÇÈóÆÈ¢ò„ÄÇËøô‰∏çÊòØÁßëÂπªÂ∞èËØ¥ÔºåËÄåÊòØÁîüÊàêÂºèAI‰ª£ÁêÜËøÖÈÄüÈÄºËøëÁöÑÁé∞ÂÆû„ÄÇËøô‰∫õ‰ª£ÁêÜÊúâÊúõÂΩªÂ∫ïÊîπÂèòÂÖ¨Âè∏ÁöÑËøêËê•ÔºåÂπ∂ÊøÄÂèë‰∏ÄÊ≥¢Êñ∞ÁöÑÂàõÊñ∞Ôºå‰ªéÁÆÄÂåñ‰æõÂ∫îÈìæÂà∞‰ºòÂåñ‰∫ßÂìÅÂºÄÂèëÔºåÂÜçÂà∞ËΩ¨ÂèòÂÆ¢Êà∑‰∫íÂä®„ÄÇ\n\nÂú®ËøáÂéª‰∏ÄÂπ¥Â§öÁöÑÊó∂Èó¥ÈáåÔºåÊàë‰∏ÄÁõ¥Âú®ÊûÑÂª∫ÁîüÊàêÂºèAIÂ∫îÁî®Âíå‰ª£ÁêÜÔºå‰∫≤ÁúºËßÅËØÅ‰∫ÜËøô‰∫õÊäÄÊúØÂ¶Ç‰ΩïÊ∑±ÂàªÈáçÂ°ëÂïÜ‰∏öÊµÅÁ®ã„ÄÇAIÁöÑÊΩúÂäõÂ∑®Â§ßÔºå‰ªé‰ª•Á©∫ÂâçÈ´òÊïàÂ§ÑÁêÜÂÆ¢Êà∑Êü•ËØ¢ÁöÑÊîØÊåÅ‰ª£ÁêÜÔºåÂà∞Êé®Âä®ÂïÜ‰∏öËøêËê•ÂíåÂÜ≥Á≠ñÁöÑËá™‰∏ª‰ª£ÁêÜ„ÄÇËøô‰∫õ‰ª£ÁêÜ‰∏ç‰ªÖ‰ªÖÊòØÂú®ÊèêÂçáÁé∞ÊúâÊµÅÁ®ãÔºåËÄåÊòØÂú®ÂêØÁî®Êñ∞ÁöÑÂ∑•‰ΩúÊñπÂºè„ÄÇ\n\n‰æãÂ¶ÇÔºåÊÉ≥Ë±°‰∏Ä‰∏™‰ª£ÁêÜÔºåÂÆÉ‰∏ç‰ªÖ‰ªÖÊòØÂÆâÊéí‰ºöËÆÆÔºåËÄåÊòØÁêÜËß£‰Ω†Â∑•‰ΩúÁöÑËÉåÊôØÔºåÂª∫ËÆÆÊúÄÊúâÂΩ±ÂìçÂäõÁöÑ‰∏é‰ºöËÄÖÔºåÂáÜÂ§áÁÆÄÊä•Êñá‰ª∂ÔºåÁîöËá≥Ê†πÊçÆÊúÄËøëÁöÑÂÖ¨Âè∏Âä®ÊÄÅÊèêÂá∫ËÆÆÁ®ãÈ°πÁõÆ„ÄÇÂèàÊàñËÄÖËÄÉËôë‰∏Ä‰∏™Âà∂ÈÄ†‰∏ö‰∏≠ÁöÑ‰ª£ÁêÜÔºåÂÆÉ‰∏ç‰ªÖ‰ªÖÊòØÁõëÊéßÁîü‰∫ßÁ∫øÔºåËÄåÊòØÈ¢ÑÊµãÁª¥Êä§ÈúÄÊ±ÇÔºåÂÆûÊó∂‰ºòÂåñËµÑÊ∫êÂàÜÈÖçÔºåÂπ∂‰∏éËÆæËÆ°Âõ¢ÈòüÂêà‰ΩúÔºåÊ†πÊçÆÁîü‰∫ßÊï∞ÊçÆÂª∫ËÆÆ‰∫ßÂìÅÊîπËøõ„ÄÇ\n\nËøôÁßçAIÈ©±Âä®ÁöÑËΩ¨ÂûãÊ≠£Âú®ÂàõÈÄ†ÂØπ‰∏§‰∏™ÂÖ≥ÈîÆËßíËâ≤ÁöÑÈúÄÊ±ÇÔºö**AI‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜ**Âíå**AI‰ª£ÁêÜÂ∑•Á®ãÂ∏à**„ÄÇËøô‰∫õ‰∏ì‰∏ö‰∫∫Âëò‰∏ç‰ªÖÊòØÊàë‰ª¨AIÂ¢ûÂº∫Êú™Êù•ÁöÑÊû∂ÊûÑÂ∏àÂíåÂª∫ËÆæËÄÖÔºåËÄå‰∏îÊòØ‰∏Ä‰∏™Âçè‰ΩúÂõ¢ÈòüÁöÑ‰∏çÂèØÊàñÁº∫ÁöÑÈÉ®ÂàÜÔºåÂ∑•‰ΩúÂú®ÂïÜ‰∏öÊàòÁï•‰∏éÂâçÊ≤øÊäÄÊúØÁöÑ‰∫§Ê±áÁÇπ‰∏ä„ÄÇ\n\n## ÂºïÂÖ•Êñ∞ËßíËâ≤\n\n**AI Agent Product Manager** ÊòØ‰∏Ä‰ΩçÂÖ∑ÊúâËøúËßÅÁöÑ‰∫∫ÔºåËÉΩÂ§üËØÜÂà´‰ª£ÁêÜÂàõÈÄ†‰ª∑ÂÄºÁöÑÊú∫‰ºöÔºåËÆæËÆ°ÂÖ∂ËÉΩÂäõÔºåÂπ∂Á°Æ‰øùÂÆÉ‰ª¨‰∏é‰∏öÂä°ÁõÆÊ†áÂíåÁî®Êà∑ÈúÄÊ±Ç‰øùÊåÅ‰∏ÄËá¥„ÄÇ‰ªñ‰ª¨Âú®ÂïÜ‰∏ö‰∏ñÁïåÂíåAIÂèØËÉΩÊÄß‰πãÈó¥ÂÖÖÂΩìÁøªËØëÔºåÂçèË∞ÉAIÂàõÊñ∞„ÄÇ\n\n**AI Agent Engineer** ÂàôÊòØÂ∞ÜËøô‰∫õ‰ª£ÁêÜÂèò‰∏∫Áé∞ÂÆûÁöÑÊäÄÊúØÈ´òÊâã„ÄÇ‰ªñ‰ª¨ËÆæËÆ°Á®≥ÂÅ•ÁöÑÊû∂ÊûÑÔºåÂàõÂª∫Â§çÊùÇÁöÑÊèêÁ§∫ÔºåÂπ∂ÈÄöËøá‰∏éÂêÑÁßçÁ≥ªÁªüÂíåÊï∞ÊçÆÊ∫êÁöÑÊó†ÁºùÈõÜÊàêÔºåÁ°Æ‰øù‰ª£ÁêÜÂü∫‰∫éÂÖ¨Âè∏Êï∞ÊçÆÂíåÊµÅÁ®ã„ÄÇ\n\nÁî±‰∫éÊàë‰ª¨‰ªçÂ§Ñ‰∫éËøô‰∏ÄÊäÄÊúØÂë®ÊúüÁöÑÊó©ÊúüÈò∂ÊÆµÔºåËøô‰∫õ‰∏ì‰∏ö‰∫∫ÂëòÈÄöÂ∏∏Âú®‰∏ìÈó®ÁöÑAIÂí®ËØ¢ÂÖ¨Âè∏ÊàñÂºÄÂèë‰ª£ÁêÜÊûÑÂª∫‰∫ßÂìÅÁöÑÂÖ¨Âè∏ÔºàÂ¶ÇSalesforceÔºâÂ∑•‰Ωú„ÄÇËøô‰Ωø‰ªñ‰ª¨ËÉΩÂ§üÂ∞ÜÊúÄ‰Ω≥ÂÆûË∑µÂíåË°å‰∏öÂàõÊñ∞Â∏¶ÂÖ•ÊØè‰∏Ä‰∏™Êñ∞È°πÁõÆ„ÄÇ\n\n## AI‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÔºöÂºïÈ¢ÜAIÂàõÊñ∞\n\n‰Ωú‰∏∫‰∏ÄÂêç‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÔºåÊÇ®ÂèØËÉΩ‰ºöÂú®‰∏çÂêåÁöÑÁî®‰æã‰∏äÂ∑•‰ΩúÔºåÊØîÂ¶Ç‰∏Ä‰∏™ÊúàÊãÖ‰ªªÈîÄÂîÆ‰ª£ÁêÜÔºå‰∏ã‰∏™ÊúàÊãÖ‰ªª‰∫∫ÂäõËµÑÊ∫ê‰ª£ÁêÜ„ÄÇËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£ÊÇ®ÁöÑËßíËâ≤ÂèØËÉΩÊòØ‰ªÄ‰πàÊ†∑ÁöÑÔºö\n\n‰Ωú‰∏∫‰∏ÄÂêç‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÔºåÂÅáËÆæÊÇ®Ë¥üË¥£‰∏∫‰∏ÄÂÆ∂Ë∑®ÂõΩÂà∂ÈÄ†ÂÖ¨Âè∏ÂºÄÂèë‰∏Ä‰∏™‰ª£ÁêÜ„ÄÇÊÇ®ÁöÑÁ¨¨‰∏ÄÊ≠•ÊòØ‰∏éÊù•Ëá™ÂêÑ‰∏™ÈÉ®Èó®ÁöÑÈ´òÁÆ°È¢ÜÂØº‰∏ÄÁ≥ªÂàóÁ†îËÆ®‰ºö‚Äî‚ÄîËøêËê•„ÄÅËÆæËÆ°„ÄÅÈîÄÂîÆÂíåÂÆ¢Êà∑ÊúçÂä°„ÄÇÊÇ®‰∏ç‰ªÖ‰ªÖÂú®ÂØªÊâæÊ∏êËøõÂºèÁöÑÊîπËøõÔºõÊÇ®Âú®ÂØªÊâæÂèòÈù©ÊÄßÁöÑÊú∫‰ºöÔºåËÄåÊÇ®ÈÄöËøá‰øÉËøõÁªÑÁªáÂÜÖÈÉ®ÁöÑÂêà‰Ωú‰∏éÁêÜËß£Êù•ÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†á„ÄÇ\n\nÈÄöËøáËøô‰∫õËÆ®ËÆ∫ÔºåÊÇ®ËØÜÂà´Âá∫‰∏Ä‰∏™È¢†Ë¶ÜÊÄßÁöÑÂèØËÉΩÊÄßÔºö‰∏Ä‰∏™ÂèØ‰ª•ËøûÊé•ÂÆ¢Êà∑ÂèçÈ¶à„ÄÅ‰∫ßÂìÅËÆæËÆ°ÂíåÂà∂ÈÄ†ÊµÅÁ®ãÁöÑ‰ª£ÁêÜ„ÄÇËøô‰∏™‰ª£ÁêÜÂ∞ÜÂàÜÊûêÂÆ¢Êà∑ËØÑËÆ∫ÂíåÊîØÊåÅÂ∑•ÂçïÔºåËØÜÂà´ÊµÅË°åÁöÑÈóÆÈ¢òÊàñÊúüÊúõÁöÑÂäüËÉΩÔºåÂπ∂Ëá™Âä®ÁîüÊàêËÆæËÆ°‰øÆÊîπÂª∫ËÆÆ„ÄÇÁÑ∂ÂêéÔºåÂÆÉÂ∞ÜÊ®°ÊãüËøô‰∫õÂèòÂåñÂØπÂà∂ÈÄ†ÊµÅÁ®ãÂíåÊàêÊú¨ÁöÑÂΩ±Âìç„ÄÇ\n\n‰Ωú‰∏∫‰ª£ÁêÜÁöÑ‰∫ßÂìÅÁªèÁêÜÔºåÊÇ®‰∏ªË¶ÅÁöÑË¥£‰ªª‰πã‰∏ÄÂ∞ÜÊòØÁªòÂà∂‰ª£ÁêÜÁöÑÊóÖÁ®ã„ÄÇËøôÊ∂âÂèäÂÆö‰πâ‰ªéÂàùÂßã‰∫íÂä®Âà∞ÊúÄÁªàÁªìÊûúÁöÑÊØè‰∏ÄÊ≠•ÔºåÁ°Æ‰øù‰∏ÄÂàá‰∏é‰∏öÂä°ÁõÆÊ†á‰∏ÄËá¥„ÄÇÊÇ®ÈúÄË¶ÅËØÜÂà´‰ª£ÁêÜÂ∞ÜË¶ÅËøõË°åÁöÑÂÖ≥ÈîÆ‰∫íÂä®Ôºå‰∫ÜËß£Ëøô‰∫õ‰∫íÂä®ÁöÑËÉåÊôØÔºåÂπ∂Á°ÆÂÆöÊØè‰∏™ÊóÖÁ®ãÂ∫îËØ•ÂÆûÁé∞ÁöÑÁõÆÊ†á„ÄÇÊÇ®ËøòÈúÄË¶ÅËÄÉËôë‰∏Ä‰∫õÂÖ≥ÈîÆÈóÆÈ¢òÔºå‰æãÂ¶ÇÔºö‰ª£ÁêÜÂ∞ÜÂ¶Ç‰Ωï‰ºòÂÖàËÄÉËôëÂÆ¢Êà∑ÂèçÈ¶àÔºüÂÆÉÂ¶Ç‰ΩïÊúâÊïàÂú∞ÂêëÂ∑•Á®ãÂõ¢ÈòüÊèêÂá∫ËÆæËÆ°Âª∫ËÆÆÔºüÂΩìAIÂΩ±Âìç‰∫ßÂìÅÂÜ≥Á≠ñÊó∂ÔºåÂøÖÈ°ªËß£ÂÜ≥Âì™‰∫õ‰º¶ÁêÜËÄÉËôëÔºü\n\nÊÇ®Â∞Ü‰∏éÂà©ÁõäÁõ∏ÂÖ≥ËÄÖÂØÜÂàáÂêà‰ΩúÔºå‰ª•ÂÆö‰πâÊàêÂäüÊåáÊ†á„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØËÉΩÂÜ≥ÂÆö‰ª£ÁêÜÁöÑÁõÆÊ†áÊòØÂ∞ÜËØÜÂà´‰∫ßÂìÅÈóÆÈ¢òÂà∞ÂÆûÊñΩ‰øÆÂ§çÁöÑÊó∂Èó¥Áº©Áü≠50%ÔºåÂêåÊó∂ÊèêÈ´òÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ËØÑÂàÜ„ÄÇ\n\nÈöèÁùÄÈ°πÁõÆÁöÑËøõÂ±ïÔºåÊÇ®Á°Æ‰øù‰ª£ÁêÜÊèê‰æõÁúüÂÆûÁöÑÂïÜ‰∏ö‰ª∑ÂÄº„ÄÇÊÇ®ÂèØËÉΩ‰ºöÂÆ°Êü•AI‰∏éËÆæËÆ°Âõ¢Èòü‰πãÈó¥ÁöÑÊ®°ÊãüÂíåÂÆûÈôÖÂØπËØùÔºåË∞ÉÊï¥‰ª£ÁêÜÁöÑÊ≤üÈÄöÈ£éÊ†ºÔºå‰ª•Êõ¥Â•ΩÂú∞‰∏éÂ∑•Á®ãÂ∏à‰∫ßÁîüÂÖ±È∏£„ÄÇÊàñËÄÖÔºåÊÇ®ÂèØËÉΩ‰ºö‰ªîÁªÜÁ†îÁ©∂‰ª£ÁêÜÁöÑÂª∫ËÆÆÂ¶Ç‰ΩïÂΩ±Âìç‰∫ßÂìÅË¥®ÈáèÂíåÂÆ¢Êà∑Êª°ÊÑèÂ∫¶ÁöÑÊï∞ÊçÆÔºåÂØªÊâæËøõ‰∏ÄÊ≠•ÊèêÈ´òÂÖ∂ÊÄßËÉΩÁöÑÊñπÊ≥ï„ÄÇ\n\nÂú®Êï¥‰∏™ËøáÁ®ã‰∏≠ÔºåÊÇ®‰∏ç‰ªÖÂú®ËÄÉËôë‰ª£ÁêÜÂΩìÂâçÁöÑËÉΩÂäõÔºåËøòÂú®ËÄÉËôëÂÖ∂Êú™Êù•ÁöÑÊΩúÂäõ„ÄÇËøô‰∏™‰ª£ÁêÜÂ¶Ç‰ΩïÊºîÂèò‰ª•ÂìçÂ∫îÂÆ¢Êà∑ÂèçÈ¶àÂπ∂È¢ÑÊµãÊú™Êù•Â∏ÇÂú∫Ë∂ãÂäøÔºüÂÆÉÊòØÂê¶ÊúâÂèØËÉΩÂú®Êú™Êù•ÂèÇ‰∏é‰∫ßÂìÅÂõ¢ÈòüÁöÑÂ§¥ËÑëÈ£éÊö¥‰ºöËÆÆÔºåÊèê‰æõÊï∞ÊçÆÈ©±Âä®ÁöÑËßÅËß£‰ª•Êé®Âä®ÂàõÊñ∞Ôºü\n\nÊÇ®ÁöÑ‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜËßíËâ≤‰ΩøÊÇ®Â§Ñ‰∫éÂïÜ‰∏öËΩ¨ÂûãÁöÑÊúÄÂâçÊ≤ø„ÄÇÊÇ®‰∏ç‰ªÖ‰ªÖÊòØÂú®ÂÆûÊñΩ‰∏Ä‰∏™Êñ∞Â∑•ÂÖ∑ÔºõÊÇ®Ê≠£Âú®ÈáçÂ°ëÊï¥‰∏™ÁªÑÁªáÂú®AIÊó∂‰ª£ÁöÑÊÄùÁª¥„ÄÅÂàõÊñ∞ÂíåËøêËê•ÊñπÂºè„ÄÇ\n\n## AI‰ª£ÁêÜÂ∑•Á®ãÂ∏àÔºöÊâìÈÄ†Êô∫ËÉΩÂèØÈù†ÁöÑÁ≥ªÁªü\n\nÁé∞Âú®ÔºåËÆ©Êàë‰ª¨ËΩ¨ÂèòÊÄùË∑ØÔºåËøõÂÖ•Âêå‰∏ÄÈ°πÁõÆ‰∏≠ÁöÑ‰ª£ÁêÜÂ∑•Á®ãÂ∏àËßíËâ≤Ôºö\n\nÊÇ®ÁöÑÊåëÊàòÊòØÂàõÂª∫‰∏Ä‰∏™ËÉΩÂ§üÁêÜËß£ÂÆ¢Êà∑ÂèçÈ¶à„ÄÅÂ∞ÜÂÖ∂ËΩ¨Âåñ‰∏∫ÂèØË°åËÆæËÆ°ËßÅËß£Âπ∂‰∏éÂà∂ÈÄ†Á≥ªÁªüÊé•Âè£ÁöÑ‰ª£ÁêÜ„ÄÇËøôÂπ∂ÈùûÊòì‰∫ã‚Äî‚ÄîËøôÈúÄË¶ÅÂØπÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã„ÄÅÂ§çÊùÇÁöÑÊèêÁ§∫Â∑•Á®ãÂíåÂº∫Â§ßÁöÑÁ≥ªÁªüÈõÜÊàêÊúâÊ∑±ÂàªÁöÑÁêÜËß£„ÄÇ\n\nÊÇ®È¶ñÂÖàÈÄâÊã©‰∏Ä‰∏™ÂêàÈÄÇÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫‰ª£ÁêÜÁöÑÂü∫Á°Ä„ÄÇÁÑ∂ËÄåÔºåÊÇ®ÁúüÊ≠£ÁöÑÂ∑•‰ΩúÂú®‰∫éËÆæËÆ°‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑ‰ª£ÁêÜÊû∂ÊûÑÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®ËÆ∏Â§öÂØπËØùÊóÖÁ®ã‰∏≠ÂèØÈù†Âú∞ÊâßË°å„ÄÇ\n\n‰Ωú‰∏∫‰ª£ÁêÜÂ∑•Á®ãÂ∏àÔºåÊÇ®‰∏ªË¶ÅÂÖ≥Ê≥®‰πã‰∏ÄÊòØÂàõÂª∫ÂíåÂÆåÂñÑ‰ª£ÁêÜÁöÑÊèêÁ§∫ÁªìÊûÑ„ÄÇÊÇ®ËÆæËÆ°Â§çÊùÇÁöÑÊèêÁ§∫ÔºåÊúâÊïàÂºïÂØºÊ®°ÂûãÁöÑË°å‰∏∫ÔºåÁ°Æ‰øùÂÆÉÂú®ÂêÑÁßçÂú∫ÊôØ‰∏≠ÂßãÁªàÊèê‰æõÁõ∏ÂÖ≥‰∏îÂáÜÁ°ÆÁöÑÂìçÂ∫î„ÄÇËøôÂèØËÉΩÊ∂âÂèäÂºÄÂèë‰∏Ä‰∏™Â±ÇÊ¨°ÂåñÁöÑÊèêÁ§∫Á≥ªÁªüÔºåËÉΩÂ§üÂ§ÑÁêÜ‰ªéÁõëÁù£Â§ö‰∏™‰ª£ÁêÜÂà∞ÂØºËà™ÂêÑÁßçÊóÖÁ®ãÁöÑÊâÄÊúâ‰∫ãÂä°„ÄÇ\n\nÊÇ®Â∞ÜËä±Ë¥πÂ§ßÈáèÊó∂Èó¥ËØÑ‰º∞‰ª£ÁêÜÁöÑË°å‰∏∫ÂíåËæìÂá∫Ôºå‰ºòÂåñÊèêÁ§∫ÂíåÊµÅÁ®ãÔºåÂπ∂ÂèëÂ∏ÉÊñ∞ÁâàÊú¨„ÄÇÊÇ®ÁîöËá≥ÂèØËÉΩËÆæËÆ°ÂíåÂÆûÊñΩ‰∏Ä‰∏™‰∏•Ê†ºÁöÑÊµãËØïÊ°ÜÊû∂ÔºåÊ®°ÊãüÊï∞ÂçÉÁßçÊΩúÂú®ÂØπËØùËΩ®Ëøπ„ÄÇÊÇ®ÁöÑÁõÆÊ†áÊòØÁ°Æ‰øù‰ª£ÁêÜÁöÑÂìçÂ∫îÊòØÁ°ÆÂÆöÊÄßÁöÑÔºåÂπ∂‰∏é‰ªª‰ΩïÁªôÂÆöËæìÂÖ•ÁöÑÊúüÊúõÁªìÊûú‰øùÊåÅ‰∏ÄËá¥„ÄÇ\n\n‰æãÂ¶ÇÔºåÊÇ®ÂèØËÉΩ‰ºöÂàõÂª∫‰∏ÄÂ•óÊµãËØïÁî®‰æãÔºåÊ∂µÁõñÂêÑÁßçÁ±ªÂûãÁöÑÂÆ¢Êà∑ÂèçÈ¶àÔºå‰ªéÁÆÄÂçïÁöÑ‰∫ßÂìÅÈóÆÈ¢òÂà∞Â§çÊùÇÁöÑÂäüËÉΩËØ∑Ê±Ç„ÄÇÁÑ∂ÂêéÔºåÊÇ®Á≥ªÁªüÂú∞Â§ÑÁêÜËøô‰∫õÊ°à‰æãÔºåÂàÜÊûê‰ª£ÁêÜÁöÑÂìçÂ∫îÔºåÂπ∂Ëø≠‰ª£ÊèêÁ§∫ÁªìÊûÑÂíåÂÜ≥Á≠ñÈÄªËæëÔºå‰ª•ÊèêÈ´òÊÄßËÉΩ„ÄÇ\n\nÂΩìÊÇ®ÈÅáÂà∞‰ª£ÁêÜË°å‰∏∫‰∏ç‰∏ÄËá¥Êàñ‰∏çÁêÜÊÉ≥ÁöÑËæπÁºòÊ°à‰æãÊó∂ÔºåÊÇ®Âπ∂‰∏çÊòØÁÆÄÂçïÂú∞Ë∞ÉÊï¥ÊèêÁ§∫„ÄÇÁõ∏ÂèçÔºåÊÇ®Ê∑±ÂÖ•Á†îÁ©∂‰ª£ÁêÜÁöÑÂÜ≥Á≠ñËøáÁ®ãÔºåÁ≥ªÁªüÊÄßÂú∞Ë∞ÉÊï¥Âü∫Á°ÄÈÄªËæëÂíåÊèêÁ§∫ÁªìÊûÑÔºå‰ª•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇ\n\nÈõÜÊàê‰ªçÁÑ∂ÊòØÊÇ®ËßíËâ≤ÁöÑÂÖ≥ÈîÆÈÉ®ÂàÜ„ÄÇÊÇ®Ê≠£Âú®ËÆæËÆ°APIÔºå‰Ωø‰ª£ÁêÜËÉΩÂ§ü‰ªéÂÆ¢Êà∑ÊîØÊåÅÊï∞ÊçÆÂ∫ì‰∏≠ÊèêÂèñÊï∞ÊçÆÔºåËÆøÈóÆ‰∫ßÂìÅËÆæËÆ°Êñá‰ª∂ÔºåÂπ∂Â∞ÜÊï∞ÊçÆËæìÂÖ•Âà∞Âà∂ÈÄ†ËßÑÂàíÁ≥ªÁªü‰∏≠„ÄÇ‰ΩÜ‰∏ç‰ªÖ‰ªÖÊòØËøûÊé•Á≥ªÁªüÔºåÊÇ®Ëøò‰∏ìÊ≥®‰∫éÁ°Æ‰øù‰ª£ÁêÜËÉΩÂ§üÂü∫‰∫éËøô‰∫õÈõÜÊàêÊï∞ÊçÆÂÅöÂá∫Êô∫ËÉΩÂÜ≥Á≠ñ„ÄÇ\n\n‰º¶ÁêÜÂíåÂÆâÂÖ®‰ªçÁÑ∂ÊòØÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇÊÇ®ÂÆûÊñΩ‰∫ÜÂº∫ÊúâÂäõÁöÑ‰øùÈöúÂíåÁõëÁù£Êú∫Âà∂Ôºå‰ª•Á°Æ‰øùAI‰∏ç‰ºöÂª∫ËÆÆÂèØËÉΩÂç±Âèä‰∫ßÂìÅÂÆâÂÖ®ÁöÑËÆæËÆ°ÂèòÊõ¥„ÄÇÊÇ®ËøòÊûÑÂª∫‰∫ÜËß£ÈáäÊÄßÂäüËÉΩÔºå‰ª•‰æøAIÂßãÁªàËÉΩÂ§üÂ±ïÁ§∫ÂÖ∂‰ªª‰ΩïÂª∫ËÆÆÁöÑÊé®ÁêÜÔºåËøôÂØπ‰∫é‰∏é‰ΩøÁî®‰ª£ÁêÜÁöÑÂ∑•Á®ãÂ∏àÂíåËÆæËÆ°Â∏àÂª∫Á´ã‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\n‰Ωú‰∏∫‰ª£ÁêÜÂ∑•Á®ãÂ∏àÔºåÊÇ®ÁöÑËßíËâ≤‰∏ç‰ªÖÊ∂âÂèäÂàõÂª∫‰∏Ä‰∏™ÂäüËÉΩÊÄßAIÁ≥ªÁªüÔºåËøòÊ∂âÂèäÊâìÈÄ†‰∏Ä‰∏™ËÉΩÂ§üÂèØÈù†Âíå‰∏ÄËá¥Âú∞Êé®Âä®Êï¥‰∏™‰∫ßÂìÅÂºÄÂèëÂíåÂà∂ÈÄ†ËøáÁ®ã‰∏≠ÁöÑÂàõÊñ∞ÂíåÊïàÁéáÁöÑÊô∫ËÉΩ‰ª£ÁêÜ„ÄÇËøô‰∏ÄÂ§çÊùÇÁöÑÊåëÊàò‰ΩøÊÇ®Â§Ñ‰∫éAIÊäÄÊúØÁöÑÊúÄÂâçÊ≤øÔºåÂ°ëÈÄ†ÁùÄ‰ºÅ‰∏öÂú®AIÊó∂‰ª£ÁöÑËøêËê•Êú™Êù•„ÄÇ\n\n## ‰º¶ÁêÜËÄÉÈáè‰∏éÂçè‰ΩúÁöÑÂäõÈáè\n\nÈöèÁùÄ‰ª£ÁêÜÂú®‰ºÅ‰∏ö‰∏≠ÂèòÂæóË∂äÊù•Ë∂äÈáçË¶ÅÔºå‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÂíå‰ª£ÁêÜÂ∑•Á®ãÂ∏àÁöÑËßíËâ≤Â∞ÜÊÑàÂèëÈáçË¶Å„ÄÇËøô‰∫õËßíËâ≤‰∏ç‰ªÖ‰ªÖÊ∂âÂèäÊäÄÊúØËÉΩÂäõÊàñÊàòÁï•Ê¥ûÂØüÂäõ‚Äî‚ÄîÂÆÉ‰ª¨ËøòË¶ÅÊ±ÇÂØπ‰º¶ÁêÜËÄÉÈáèÊúâÊ∑±ÂàªÁöÑÊâøËØ∫„ÄÇÁî±‰∫éËøô‰∫õ‰ª£ÁêÜÂΩ±ÂìçÁùÄÈáçË¶ÅÁöÑÂïÜ‰∏öÂÜ≥Á≠ñÔºåËÉåÂêéÁöÑ‰∏ì‰∏ö‰∫∫Â£´ÂøÖÈ°ªÁ°Æ‰øùËøô‰∫õÁ≥ªÁªüÊòØÈÄèÊòéÁöÑ„ÄÅÂÖ¨Âπ≥ÁöÑÔºåÂπ∂‰∏éÊõ¥ÂπøÊ≥õÁöÑÁ§æ‰ºö‰ª∑ÂÄºËßÇÁõ∏‰∏ÄËá¥„ÄÇ\n\nËøô‰∏™‰ª£ÁêÜÁöÑÊàêÂäüÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùËµñ‰∫é‰∫ßÂìÅÁªèÁêÜÂíåÂ∑•Á®ãÂ∏à‰πãÈó¥ÁöÑÊó†ÁºùÂçè‰Ωú„ÄÇ‰Ω†‰ª¨Â∞ÜÂÖ±ÂêåËø≠‰ª£‰ª£ÁêÜÁöÑËÉΩÂäõÔºåÊéíÈô§ÈóÆÈ¢òÔºåÂπ∂Êé®Âä®ÂèØËÉΩÊÄßÁöÑËæπÁïå„ÄÇ\n\n## ÊØîËæÉËßíËâ≤Ôºö‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜ‰∏é‰ª£ÁêÜÂ∑•Á®ãÂ∏à\n\n‰ª•‰∏ãÊòØ‰∏Ä‰∏™ÊÄªÁªìÊØîËæÉË°®Ôºå‰ª•Âº∫Ë∞É‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜ‰∏é‰ª£ÁêÜÂ∑•Á®ãÂ∏à‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*T26nkBI-wID26X2NrE2SSQ.jpeg)\n\nÂÖ≥ÈîÆË¶ÅÁÇπÔºö\n\n* **‰ª£ÁêÜ‰∫ßÂìÅÁªèÁêÜÔºö** ËØ•ËÅå‰Ωç‰∏ìÊ≥®‰∫é‰ª£ÁêÜÁöÑÊàòÁï•Âíå‰∏öÂä°ÊñπÈù¢ÔºåÁ°Æ‰øùÂÆÉ‰ª¨Êèê‰æõ‰ª∑ÂÄºÂπ∂‰∏éÂÖ¨Âè∏ÁõÆÊ†á‰øùÊåÅ‰∏ÄËá¥„ÄÇ\n* **‰ª£ÁêÜÂ∑•Á®ãÂ∏àÔºö** ËØ•ËÅå‰ΩçÈõÜ‰∏≠‰∫éÊäÄÊúØÂÆûÁé∞ÔºåÁ°Æ‰øù‰ª£ÁêÜÂèØÈù†ËøêË°åÂπ∂‰∏éÁé∞ÊúâÁ≥ªÁªüÊó†ÁºùÈõÜÊàê„ÄÇ\n\n## Êú™Êù•Â±û‰∫é‰Ω†ÔºöËøéÊé•ÊåëÊàò\n\nÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂΩ±ÂìçÂäõ‰∏çÊñ≠Êâ©Â§ßÔºåAgent Product Manager Âíå Agent Engineer ÁöÑËßíËâ≤Â∞ÜÂ§Ñ‰∫éËøôÂú∫ÊäÄÊúØÈù©ÂëΩÁöÑÊúÄÂâçÊ≤ø„ÄÇÊó†ËÆ∫‰Ω†ÊòØÂú®‰∏∫ AI È©±Âä®ÁöÑ‰∏öÂä°ËΩ¨ÂûãÂÆö‰πâÊàòÁï•ÔºåËøòÊòØÂú®ËÆæËÆ°È©±Âä®Êô∫ËÉΩ‰ª£ÁêÜÁöÑÂ§çÊùÇÁ≥ªÁªüÔºå‰Ω†ÈÉΩÂ∞ÜÂú®Â°ëÈÄ†ÂïÜ‰∏öÁöÑÊú™Êù•„ÄÇ\n\nËøô‰∫õËßíËâ≤ÈúÄË¶ÅÁã¨ÁâπÁöÑÊäÄËÉΩÁªÑÂêàÔºöÊàòÁï•ÊÄùÁª¥„ÄÅÊäÄÊúØ‰∏ìÈïø„ÄÅÂàõÈÄ†ÂäõÔºå‰ª•ÂèäÂØπÂïÜ‰∏öÂíå‰∫∫Â∑•Êô∫ËÉΩÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇÂÆÉ‰ª¨Êèê‰æõ‰∫ÜÂú®Â∞ñÁ´ØÊäÄÊúØ‰∏äÂ∑•‰ΩúÁöÑÊú∫‰ºöÔºåÂêåÊó∂Êé®Âä®ÂÆûÈôÖÁöÑÂïÜ‰∏öÂΩ±Âìç„ÄÇ\n\nÈÇ£‰πàÔºåÊú™Êù•ÁöÑ Agent Product Managers Âíå EngineersÔºå‰Ω†‰ª¨ÂáÜÂ§áÂ•ΩËøéÊé•ÊåëÊàò‰∫ÜÂêóÔºü‰∫∫Â∑•Êô∫ËÉΩÂ¢ûÂº∫ÁöÑÊú™Êù•Ê≠£Á≠âÂæÖÁùÄ‰Ω†‰ª¨ÁöÑ‰∏ì‰∏öÁü•ËØÜÂíåÊÑøÊôØ„ÄÇÊó†ËÆ∫‰Ω†ÊòØÂØπ‰∫ßÂìÅÁÆ°ÁêÜÁöÑÊàòÁï•ÊñπÈù¢ÊÑüÂÖ¥Ë∂£ÔºåËøòÊòØÂØπ‰ª£ÁêÜÂ∑•Á®ãÁöÑÊäÄÊúØÁªÜËäÇÂÖÖÊª°ÁÉ≠ÊÉÖÔºåÂú®Ëøô‰∏™‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÊñ∞È¢ÜÂüü‰∏≠ÈÉΩÊúâ‰Ω†ÁöÑ‰∏ÄÂ∏≠‰πãÂú∞„ÄÇÈóÆÈ¢ò‰∏çÂú®‰∫é‰∫∫Â∑•Êô∫ËÉΩÊòØÂê¶‰ºöÊîπÂèòÂïÜ‰∏öÔºåËÄåÂú®‰∫éÂ¶Ç‰ΩïÊîπÂèò‚Äî‚ÄîËÄå‰Ω†ÂèØËÉΩÂ∞±ÊòØÂÜ≥ÂÆöËÄÖ„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/top-25-generative-ai-terminologies-you-must-know-6a3bb0300988","frontmatter":{"title":"ÊÇ®ÂøÖÈ°ª‰∫ÜËß£ÁöÑ 25 ‰∏™È°∂Á∫ßÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúØËØ≠","meta_title":"ÊÇ®ÂøÖÈ°ª‰∫ÜËß£ÁöÑ 25 ‰∏™È°∂Á∫ßÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúØËØ≠","description":"Êú¨Êñá‰ªãÁªç‰∫Ü25‰∏™ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑÊ†∏ÂøÉÊúØËØ≠ÔºåÂåÖÊã¨ÁîüÊàêÊ®°Âûã„ÄÅTransformer„ÄÅGAN„ÄÅËá™ÁºñÁ†ÅÂô®Á≠â„ÄÇÊØè‰∏™ÊúØËØ≠ÈÉΩÊèê‰æõ‰∫ÜÂÆö‰πâ„ÄÅÁ§∫‰æãÂèäÁõ∏ÂÖ≥ËµÑÊ∫êÔºå‰ª•Â∏ÆÂä©ÊäÄÊúØ‰∏ì‰∏ö‰∫∫Â£´ÂíåÂÖ∂‰ªñÈ¢ÜÂüü‰∫∫Â£´Ê∑±ÂÖ•ÁêÜËß£ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÖ≥ÈîÆÊ¶ÇÂøµ„ÄÇËøô‰∫õÊúØËØ≠ÁöÑÊéåÊè°ÂØπ‰∫éÂèÇ‰∏é‰∫∫Â∑•Êô∫ËÉΩÈ°πÁõÆ„ÄÅÂáÜÂ§áÈù¢ËØï‰ª•ÂèäË∑üË∏™Ë°å‰∏öÂä®ÊÄÅËá≥ÂÖ≥ÈáçË¶Å„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*swCl2YJj6wfAc9J3v6AqTg.png","categories":["Generative AI","Machine Learning","Data Science"],"author":"Rifx.Online","tags":["Generative","Transformers","GANs","Autoencoders","Zero-Shot"],"draft":false,"slug":"blog/top-25-generative-ai-terminologies-you-must-know-6a3bb0300988"},"content":"\n\n\n*ÊéåÊè°ÂÖ≥ÈîÆÊ¶ÇÂøµÔºå‰ª•Ê∏ÖÊô∞ÁöÑËß£Èáä„ÄÅÂÆûÈôÖÂ∫îÁî®ÂíåÊ∑±ÂÖ•ÁöÑËµÑÊ∫êÂú®ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüËÑ±È¢ñËÄåÂá∫*\n\n\n\nÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁ°ÆÂÆûÊòØÂêÑË°å‰∏ö‰∏≠ÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºõÂõ†Ê≠§ÔºåÁêÜËß£ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÁöÑÊ†∏ÂøÉÊ¶ÇÂøµÂØπ‰ªª‰ΩïÊäÄÊúØ‰∏ì‰∏ö‰∫∫Â£´ÂèäÂÖ∂‰ªñÈ¢ÜÂüüÁöÑ‰∫∫Â£´Êù•ËØ¥ÈÉΩÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑ„ÄÇ‰ª•‰∏ãÁªºÂêàÊåáÂçóÊ∂µÁõñ‰∫Ü25‰∏™ÂøÖÈ°ª‰∫ÜËß£ÁöÑÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÊúØËØ≠ÔºåÊèê‰æõÊ∏ÖÊô∞ÁöÑÂÆö‰πâ„ÄÅÂÆûÈôÖÁöÑ‰æãÂ≠êÂíåÂÖ∂‰ªñËµÑÊ∫êÔºå‰ª•Âä†Ê∑±ÊÇ®ÁöÑÁü•ËØÜ„ÄÇÊó†ËÆ∫ÊòØ‰∏∫Èù¢ËØïÂÅöÂáÜÂ§á„ÄÅÂèÇ‰∏é‰∫∫Â∑•Êô∫ËÉΩÈ°πÁõÆÔºåËøòÊòØË∑ü‰∏äËøô‰∏™Âø´ÈÄüÂèòÂåñÈ¢ÜÂüüÁöÑÂä®ÊÄÅÔºåÊéåÊè°Ëøô‰∫õÊúØËØ≠ÈÉΩÂ∞Ü‰∏∫ÊÇ®Âú®ÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÊâì‰∏ãÂùöÂÆûÁöÑÂü∫Á°Ä„ÄÇ\n\n## 1\\. ÁîüÊàêÊ®°Âûã\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßç‰ªéÂ≠¶‰π†Âà∞ÁöÑÊ®°Âºè‰∏≠ÁîüÊàêÊñ∞Êï∞ÊçÆÁÇπÁöÑAIÊ®°Âûã„ÄÇ\n* **Á§∫‰æã**ÔºöÁîüÊàêÈ¢ÑËÆ≠ÁªÉÂèòÊç¢Âô®ÔºàGPTÔºâÊ†πÊçÆËæìÂÖ•ÊèêÁ§∫ÁîüÊàêÁ±ª‰∫∫ÊñáÊú¨„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ÁîüÊàêÊ®°ÂûãÁÆÄ‰ªã](https://proxy.rifx.online/https://www.datacamp.com/blog/what-is-a-generative-model)\n\n## 2\\. Transformer\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÁ•ûÁªèÁΩëÁªúÊû∂ÊûÑÔºåÂà©Áî®Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂Â§ÑÁêÜÂíåÁîüÊàêÂ∫èÂàóÔºå‰æãÂ¶ÇÊñáÊú¨ÊàñÂõæÂÉè„ÄÇ\n* **Á§∫‰æã**ÔºöBERT ÊòØ‰∏ÄÁßçÁî®‰∫éÈóÆÁ≠îÂíåÊñáÊú¨ÂàÜÁ±ªÁ≠â‰ªªÂä°ÁöÑ Transformer Ê®°Âûã„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ÁêÜËß£ Transformers](https://proxy.rifx.online/https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power)\n\n## 3\\. ÊΩúÂú®Á©∫Èó¥\n\n* **ÂÆö‰πâ**Ôºö‰∏Ä‰∏™Â§öÁª¥Á©∫Èó¥ÔºåÁîüÊàêÊ®°ÂûãÂú®ÂÖ∂‰∏≠Êò†Â∞ÑÊï∞ÊçÆÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ≠¶‰π†ÂíåÁîüÊàêÂèò‰Ωì„ÄÇ\n* **Á§∫‰æã**ÔºöÂú®ÂõæÂÉèÁîüÊàê‰∏≠ÔºåÁõ∏‰ººÁöÑÂõæÂÉèÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ÂΩºÊ≠§Èù†Ëøë„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[Êé¢Á¥¢‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÁöÑÊΩúÂú®Á©∫Èó¥](https://proxy.rifx.online/https://www.perplexity.ai/page/latent-space-101-what-it-is-an-mwXuxYfzS_.J4e_uFvOskg)\n\n## 4\\. GANÔºàÁîüÊàêÂØπÊäóÁΩëÁªúÔºâ\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßç‰∫∫Â∑•Êô∫ËÉΩÔºåÂà©Áî®‰∏§‰∏™Á•ûÁªèÁΩëÁªú‚Äî‚ÄîÁîüÊàêÂô®ÂíåÂà§Âà´Âô®‚Äî‚ÄîÁõ∏‰∫íÂØπÊäó‰ª•ÁîüÊàêÈÄºÁúüÁöÑÊï∞ÊçÆ„ÄÇ\n* **Á§∫‰æã**ÔºöGANÁîüÊàêÁúãËµ∑Êù•ÈÄºÁúüÁöÑÈù¢Â≠îÔºå‰ΩÜËøô‰∫õÈù¢Â≠îÂπ∂‰∏çÂ±û‰∫éÁúüÂÆûÁöÑ‰∫∫„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØGANÔºåÂÆÉ‰ª¨ÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÔºü](https://proxy.rifx.online/https://aws.amazon.com/what-is/gan/#:~:text=A%20generative%20adversarial%20network%20(GAN,from%20a%20database%20of%20songs.)\n\n## 5\\. Ëá™ÁºñÁ†ÅÂô®\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÁ•ûÁªèÁΩëÁªúÔºåÂ≠¶‰π†ÂéãÁº©ÂíåÈáçÊûÑÊï∞ÊçÆÔºåÈÄöÂ∏∏Áî®‰∫éÈôçÁª¥ÂíåÂéªÂô™Á≠â‰ªªÂä°„ÄÇ\n* **Á§∫‰æã**ÔºöËá™ÁºñÁ†ÅÂô®Áî®‰∫é‰ªéÊçüÂùèÁöÑÂõæÂÉè‰∏≠ÂéªÈô§Âô™Â£∞„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[Ëá™ÁºñÁ†ÅÂô®‰ªãÁªç](https://proxy.rifx.online/https://towardsdatascience.com/introduction-to-autoencoders-7a47cf4ef14b)\n\n## 6\\. Êâ©Êï£Ê®°Âûã\n\n* **ÂÆö‰πâ**: Â≠¶‰π†ÈÄÜËΩ¨Âô™Â£∞Ê∑ªÂä†ËøáÁ®ãÁöÑÊ®°ÂûãÔºå‰ª•‰ªéÂô™Â£∞‰∏≠ÁîüÊàêËØ¶ÁªÜ‰∏î‰∏ÄËá¥ÁöÑÊï∞ÊçÆ„ÄÇ\n* **Á§∫‰æã**: Êâ©Êï£Ê®°ÂûãÂú® DALL\\-E 2 ‰∏≠Áî®‰∫é‰ªéÈöèÊú∫Âô™Â£∞ÁîüÊàêÈ´òË¥®ÈáèÂõæÂÉè„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**: [ÁêÜËß£Êâ©Êï£Ê®°Âûã](https://proxy.rifx.online/https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)\n\n## 7\\. ÊèêÁ§∫Â∑•Á®ã\n\n* **ÂÆö‰πâ**ÔºöÁ≤æÂøÉËÆæËÆ°ËæìÂÖ•ÊèêÁ§∫ÁöÑËøáÁ®ãÔºå‰ª•‰ºòÂåñÊ®°ÂûãÁîüÊàêÁöÑËæìÂá∫„ÄÇ\n* **Á§∫‰æã**Ôºö‰øÆÊîπGPT\\-4‰∏≠ÁöÑËæìÂÖ•ÊèêÁ§∫‰ª•ÁîüÊàêÊõ¥ÁÆÄÊ¥ÅÁöÑÊëòË¶Å„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ÊèêÁ§∫Â∑•Á®ãÊåáÂçó](https://proxy.rifx.online/https://www.datacamp.com/tutorial/a-beginners-guide-to-chatgpt-prompt-engineering)\n\n## 8\\. Èõ∂Ê†∑Êú¨Â≠¶‰π†\n\n* **ÂÆö‰πâ**ÔºöÊ®°ÂûãÂú®Êú™ÊòéÁ°ÆËÆ≠ÁªÉÁöÑ‰ªªÂä°‰∏äÊâßË°å‰ªªÂä°ÁöÑËÉΩÂäõÔºåÈÄöËøáÂà©Áî®ÂÖ∂‰ªñ‰ªªÂä°ÁöÑÁü•ËØÜ„ÄÇ\n* **Á§∫‰æã**ÔºöGPT\\-3 ÂèØ‰ª•Âú®Ê≤°ÊúâÈíàÂØπÁøªËØëÊï∞ÊçÆÈõÜËøõË°åÁâπÂà´ËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÊâßË°åÁøªËØë„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØÈõ∂Ê†∑Êú¨Â≠¶‰π†Ôºü](https://proxy.rifx.online/https://www.ibm.com/topics/zero-shot-learning)\n\n## 9\\. Â∞ëÊ†∑Êú¨Â≠¶‰π†\n\n* **ÂÆö‰πâ**ÔºöÊ®°ÂûãÂú®‰ªÖÊúâÂ∞ëÈáèÁ§∫‰æãÁöÑÊÉÖÂÜµ‰∏ãÂ≠¶‰π†‰ªªÂä°ÁöÑËÉΩÂäõÔºåÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂáèÂ∞ëÂØπÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÁöÑÈúÄÊ±Ç„ÄÇ\n* **Á§∫‰æã**ÔºöGPT\\-3 ÂèØ‰ª•ÈÄöËøáÊúÄÂ∞ëÁöÑËæìÂÖ•Ê†∑Êú¨ËøõË°åÂæÆË∞ÉÔºå‰ª•ÁâπÂÆöÈ£éÊ†ºËøõË°åÂÜô‰Ωú„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[Â∞ëÊ†∑Êú¨Â≠¶‰π†Ëß£Èáä](https://proxy.rifx.online/https://www.ibm.com/topics/few-shot-learning#:~:text=IBM-,What%20is%20few%2Dshot%20learning%3F,suitable%20training%20data%20is%20scarce.)\n\n## 10\\. Âº∫ÂåñÂ≠¶‰π†\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÂ≠¶‰π†ËåÉÂºèÔºåAI‰ª£ÁêÜÈÄöËøá‰∏éÁéØÂ¢É‰∫íÂä®Êù•Â≠¶‰π†ÂÜ≥Á≠ñÔºå‰ª•ÊúÄÂ§ßÂåñÁ¥ØÁßØÂ•ñÂä±„ÄÇ\n* **Á§∫‰æã**ÔºöAlphaGo‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÈÄöËøá‰∏éËá™Â∑±ÂØπÂºàÊï∞Áôæ‰∏áÂ±ÄÊù•Á≤æÈÄöÂõ¥Ê£ã„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ÁîüÊàêÂºèAIÁöÑÂº∫ÂåñÂ≠¶‰π†](https://proxy.rifx.online/https://dl.acm.org/doi/pdf/10.1613/jair.1.15278)\n\n## 11\\. ÂèòÂàÜËá™ÁºñÁ†ÅÂô® (VAE)\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçËá™ÁºñÁ†ÅÂô®ÔºåÈÄöËøáÂºïÂÖ•ÈöèÊú∫ÊÄßÊù•Â≠¶‰π†ÁîüÊàêÊñ∞Êï∞ÊçÆÔºå‰ªéËÄåÂØπÂÖ∂ÊΩúÂú®Á©∫Èó¥Ë°®Á§∫ËøõË°åÂª∫Ê®°„ÄÇ\n* **Á§∫‰æã**ÔºöVAE Ë¢´Áî®‰∫éÁîüÊàêÊñ∞ÁöÑ‰∫∫ËÑ∏ÔºåÂπ∂Âú®‰∏çÂêåÁöÑÈù¢ÈÉ®ÁâπÂæÅ‰πãÈó¥Âπ≥ÊªëËøáÊ∏°„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[VAE ÂèäÂÖ∂Â∫îÁî®](https://proxy.rifx.online/https://www.datacamp.com/tutorial/variational-autoencoders)\n\n``` \n## ‰ª£Á†ÅÂùóÂÜÖÂÆπ‰øùÊåÅ‰∏çÂèò\n```\n\n## 12\\. Ëá™ÁõëÁù£Â≠¶‰π†\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÂ≠¶‰π†ÊäÄÊúØÔºåÊ®°Âûã‰ªéÊï∞ÊçÆ‰∏≠ÁîüÊàêËá™Â∑±ÁöÑÊ†áÁ≠æÔºå‰ªéËÄåÂáèÂ∞ëÂØπÊ†áËÆ∞Êï∞ÊçÆÈõÜÁöÑ‰æùËµñ„ÄÇ\n* **Á§∫‰æã**ÔºöBERTÈÄöËøáÂú®Âè•Â≠ê‰∏≠Êé©ÁõñÂçïËØçÂπ∂Âú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠È¢ÑÊµãÂÆÉ‰ª¨Êù•‰ΩøÁî®Ëá™ÁõëÁù£Â≠¶‰π†„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØËá™ÁõëÁù£Â≠¶‰π†Ôºü](https://proxy.rifx.online/https://www.ibm.com/topics/self-supervised-learning)\n\n```\n## Code block example\ndef self_supervised_learning():\n    pass\n```\n\n## 13\\. ÂàÜËØç\n\n* **ÂÆö‰πâ**ÔºöÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫Êõ¥Â∞èÁöÑÂçïÂÖÉÔºåÂ¶ÇËØçÊàñÂ≠êËØçÔºå‰ª•‰æøÊ®°ÂûãÊõ¥ÂÆπÊòìÂ§ÑÁêÜÁöÑËøáÁ®ã„ÄÇ\n* **Á§∫‰æã**ÔºöÊñáÊú¨ËæìÂÖ•Âú®ËæìÂÖ•Âà∞ GPT\\-4 ËøõË°åÂ§ÑÁêÜ‰πãÂâçË¢´ÂàÜËØç‰∏∫ÂçïËØç„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏≠ÁöÑÂàÜËØç](https://proxy.rifx.online/https://www.datacamp.com/blog/what-is-tokenization)\n\n## 14\\. Beam Search\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÊêúÁ¥¢ÁÆóÊ≥ïÔºåÈÄöËøáÊâ©Â±ïÂ§ö‰∏™ÊΩúÂú®ÁöÑÊ†áËÆ∞Â∫èÂàóÔºåÂú®Ëß£Á†ÅËøáÁ®ã‰∏≠ÁîüÊàêÊúÄÂèØËÉΩÁöÑÂ∫èÂàó„ÄÇ\n* **Á§∫‰æã**ÔºöBeam search Âú®Êú∫Âô®ÁøªËØë‰∏≠Áî®‰∫éÁîüÊàêËøûË¥ØÁöÑÊñáÊú¨ËæìÂá∫„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[Beam Search Explained](https://proxy.rifx.online/https://www.width.ai/post/what-is-beam-search)\n\n## 15\\. ËøÅÁßªÂ≠¶‰π†\n\n* **ÂÆö‰πâ**ÔºöÂú®‰∏Ä‰∏™‰ªªÂä°‰∏ä‰ΩøÁî®È¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÂπ∂ÂØπÂÖ∂ËøõË°åÂæÆË∞É‰ª•ÈÄÇÂ∫îÂè¶‰∏Ä‰∏™‰ªªÂä°ÁöÑËøáÁ®ãÔºåÈÄöÂ∏∏ÊâÄÈúÄÁöÑÊï∞ÊçÆÊõ¥Â∞ë„ÄÇ\n* **Á§∫‰æã**ÔºöÂú®ÈÄöÁî®ËØ≠Ë®Ä‰ªªÂä°‰∏äÈ¢ÑËÆ≠ÁªÉÂêéÔºåÂØπÊÉÖÊÑüÂàÜÊûê‰ªªÂä°ËøõË°åBERTÁöÑÂæÆË∞É„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØËøÅÁßªÂ≠¶‰π†Ôºü](https://proxy.rifx.online/https://aws.amazon.com/what-is/transfer-learning/)\n\n## 16\\. ËØ≠Ë®ÄÊ®°Âûã\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÈ¢ÑÊµãËá™ÁÑ∂ËØ≠Ë®Ä‰∏≠ËØçÂ∫èÂàóÊ¶ÇÁéáÁöÑÊ®°ÂûãÔºåÂ∏ÆÂä©ÁîüÊàêÊàñÁêÜËß£ÊñáÊú¨„ÄÇ\n* **Á§∫‰æã**ÔºöGPT\\-4 ÊòØ‰∏ÄÁßçËÉΩÂ§ü‰∏∫ÂπøÊ≥õÂ∫îÁî®ÁîüÊàêËøûË¥ØÊñáÊú¨ÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ËØ≠Ë®ÄÊ®°ÂûãÁÆÄ‰ªã](https://proxy.rifx.online/https://developers.google.com/machine-learning/resources/intro-llms)\n\n## 17\\. ‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÁöÑÂÅèËßÅ\n\n* **ÂÆö‰πâ**Ôºö‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÁî±‰∫éËÆ≠ÁªÉÊï∞ÊçÆÊàñÁÆóÊ≥ïÁöÑÂÅèËßÅÔºåÂÄæÂêë‰∫é‰∫ßÁîüÊúâÂà©‰∫éÊàñÊ≠ßËßÜÊüê‰∫õÁæ§‰ΩìÁöÑÁªìÊûú„ÄÇ\n* **Á§∫‰æã**ÔºöÂü∫‰∫éÊúâÂÅèËßÅÂéÜÂè≤Êï∞ÊçÆËÆ≠ÁªÉÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊãõËÅòÁ≥ªÁªü‰∏≠ÁöÑÊÄßÂà´ÂÅèËßÅ„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ÁêÜËß£‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÁöÑÂÅèËßÅ](https://proxy.rifx.online/https://www.ibm.com/topics/ai-bias)\n\n## 18\\. GPT (ÁîüÊàêÈ¢ÑËÆ≠ÁªÉÂèòÊç¢Âô®)\n\n* **ÂÆö‰πâ**Ôºö‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂü∫‰∫éÂØπÂπøÊ≥õÊñáÊú¨ËØ≠ÊñôÂ∫ìÁöÑÈ¢ÑËÆ≠ÁªÉÂíåÂæÆË∞ÉÁîüÊàêÁ±ª‰∫∫ÊñáÊú¨„ÄÇ\n* **Á§∫‰æã**ÔºöGPT-4 ÁîüÊàêËÆ∫Êñá„ÄÅÊïÖ‰∫ãÂíåÂØπÁî®Êà∑Êü•ËØ¢ÁöÑËØ¶ÁªÜÂõûÂ∫î„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[GPT ÁöÑÂ∑•‰ΩúÂéüÁêÜ](https://proxy.rifx.online/https://tecknoworks.com/how-gpt-works-and-its-core-mechanics/)\n\n## 19\\. Âõ∞ÊÉëÂ∫¶\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçË°°ÈáèËØ≠Ë®ÄÊ®°ÂûãÈ¢ÑÊµãÁªôÂÆöÂçïËØçÂ∫èÂàóÊïàÊûúÁöÑÊåáÊ†áÔºåÂõ∞ÊÉëÂ∫¶Ë∂ä‰ΩéË°®Á§∫ÊÄßËÉΩË∂äÂ•Ω„ÄÇ\n* **Á§∫‰æã**ÔºöÊØîËæÉ GPT\\-3 Âíå GPT\\-4 ÁöÑÂõ∞ÊÉëÂ∫¶Ôºå‰ª•ËØÑ‰º∞ÂÆÉ‰ª¨ÁöÑÊñáÊú¨ÁîüÊàêË¥®Èáè„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÂõ∞ÊÉëÂ∫¶](https://proxy.rifx.online/https://huggingface.co/docs/transformers/en/perplexity)\n\n## 20\\. Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP)\n\n* **ÂÆö‰πâ**Ôºö‰∏Ä‰∏™‰∏ìÊ≥®‰∫éËÆ°ÁÆóÊú∫‰∏é‰∫∫Á±ªÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄËøõË°å‰∫§‰∫íÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÔºåÊ∂µÁõñÁøªËØëÂíåÊÉÖÊÑüÂàÜÊûêÁ≠â‰ªªÂä°„ÄÇ\n* **Á§∫‰æã**ÔºöNLPÊ®°ÂûãÁî®‰∫éÂØπÂÆ¢Êà∑ËØÑ‰ª∑ËøõË°åÊÉÖÊÑüÂàÜÊûê„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[NLPÁÆÄ‰ªã](https://proxy.rifx.online/https://towardsdatascience.com/a-gentle-introduction-to-natural-language-processing-e716ed3c0863)\n\n## 21\\. Á•ûÁªèÁΩëÁªú\n\n* **ÂÆö‰πâ**Ôºö‰∏ÄÁßçÂèó‰∫∫ËÑëÁ•ûÁªèÂÖÉÁΩëÁªúÂêØÂèëÁöÑËÆ°ÁÆóÁ≥ªÁªüÔºåÁî±Â§ö‰∏™Áõ∏‰∫íËøûÊé•ÁöÑËäÇÁÇπÂ±ÇÁªÑÊàêÔºåÁî®‰∫éÂõæÂÉèËØÜÂà´ÂíåËØ≠Ë®ÄÂ§ÑÁêÜÁ≠â‰ªªÂä°„ÄÇ\n* **Á§∫‰æã**ÔºöÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºàCNNÔºâÁî®‰∫éËØÜÂà´ÂõæÂÉè‰∏≠ÁöÑÁâ©‰Ωì„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØÁ•ûÁªèÁΩëÁªúÔºü](https://proxy.rifx.online/https://www.ibm.com/topics/neural-networks)\n\n## 22\\. ËÆ≠ÁªÉÊï∞ÊçÆ\n\n* **ÂÆö‰πâ**ÔºöÁî®‰∫éËÆ≠ÁªÉAIÊ®°ÂûãÁöÑÊï∞ÊçÆÔºåÈÄöËøáËÆ©ÂÆÉ‰ª¨‰ªéÁ§∫‰æã‰∏≠Â≠¶‰π†ÔºåÊèêÈ´òÂÆÉ‰ª¨ËØÜÂà´Ê®°ÂºèÂíåËøõË°åÈ¢ÑÊµãÁöÑËÉΩÂäõ„ÄÇ\n* **Á§∫‰æã**ÔºöÂÉèImageNetËøôÊ†∑ÁöÑÂ§ßÂûãÂõæÂÉèÊï∞ÊçÆÈõÜÁî®‰∫éËÆ≠ÁªÉAIÊ®°ÂûãËøõË°åÂõæÂÉèÂàÜÁ±ª‰ªªÂä°„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[AI‰∏≠ÁöÑËÆ≠ÁªÉÊï∞ÊçÆ](https://proxy.rifx.online/https://www.oracle.com/artificial-intelligence/ai-model-training/)\n\n## 23\\. Ê≥®ÊÑèÂäõÊú∫Âà∂\n\n* **ÂÆö‰πâ**ÔºöÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑ‰∏ÄÁßçÊñπÊ≥ïÔºåÂ∏ÆÂä©Ê®°ÂûãÂÖ≥Ê≥®ËæìÂÖ•Â∫èÂàó‰∏≠ÊúÄÁõ∏ÂÖ≥ÁöÑÈÉ®ÂàÜÔºå‰ªéËÄåÊèêÈ´òÊú∫Âô®ÁøªËØëÂíåÊñáÊú¨ÁîüÊàêÁ≠â‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇ\n* **Á§∫‰æã**ÔºöÊ≥®ÊÑèÂäõÊú∫Âà∂ÂÖÅËÆ∏Ê®°ÂûãÂú®ËØ≠Ë®ÄÁøªËØëÊó∂ÂÖ≥Ê≥®Âè•Â≠ê‰∏≠ÁöÑÈáçË¶ÅÂçïËØç„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºü](https://proxy.rifx.online/https://machinelearningmastery.com/the-attention-mechanism-from-scratch/)\n\n## 24\\. Á∫™ÂÖÉ\n\n* **ÂÆö‰πâ**ÔºöÂú®Êú∫Âô®Â≠¶‰π†Ê®°ÂûãËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÁªèËøáÊï¥‰∏™ËÆ≠ÁªÉÊï∞ÊçÆÈõÜÁöÑ‰∏ÄÊ¨°ÂÆåÊï¥ÈÅçÂéÜ„ÄÇ\n* **Á§∫‰æã**ÔºöËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú10‰∏™Á∫™ÂÖÉÔºå‰ª•Á°Æ‰øùÂÖ∂Ê≠£Á°ÆÂ≠¶‰π†ËÄå‰∏çÂèëÁîüËøáÊãüÂêà„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[ÁêÜËß£Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÁ∫™ÂÖÉ](https://proxy.rifx.online/https://www.geeksforgeeks.org/epoch-in-machine-learning/)\n\n## 25\\. Â§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩ\n\n* **ÂÆö‰πâ**ÔºöËÉΩÂ§üÂêåÊó∂Â§ÑÁêÜÂíåÁîüÊàêÊù•Ëá™Â§öÁßçÊ®°ÊÄÅÔºà‰æãÂ¶ÇÊñáÊú¨„ÄÅÂõæÂÉèÂíåÈü≥È¢ëÔºâÊï∞ÊçÆÁöÑ‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ\n* **Á§∫‰æã**ÔºöCLIP ÂêåÊó∂Â§ÑÁêÜÂõæÂÉèÂíåÊñáÊú¨Ôºå‰ª•ÁîüÊàêÂõæÂÉèÁöÑÊ†áÈ¢ò„ÄÇ\n* **‰∫ÜËß£Êõ¥Â§ö**Ôºö[‰ªÄ‰πàÊòØÂ§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÔºü](https://proxy.rifx.online/https://www.techtarget.com/searchenterpriseai/definition/multimodal-AI)\n\nËØ∑ËÆ∞‰ΩèÔºåÊéåÊè°ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊòØ‰∏Ä‰∏™ÈÄêÊ≠•ÁöÑËøáÁ®ã„ÄÇÂú®Â≠¶‰π†Ëøô‰∫õÊ¶ÇÂøµÊó∂ÔºåÁ°Æ‰øùÈÄöËøáÊèê‰æõÁöÑËµÑÊ∫êÊ∑±ÂÖ•Êé¢Á¥¢ÊØè‰∏Ä‰∏™Ê¶ÇÂøµÔºåÂèÇ‰∏éËÆ®ËÆ∫ÔºåÂπ∂Â∞ùËØïÂ∞ÜÊâÄÂ≠¶Â∫îÁî®‰∫éÊÇ®ÁöÑÈ°πÁõÆ„ÄÇ‰∏éËøô‰∫õËµÑÊ∫êÂíåÂØπËØùÁöÑ‰∫íÂä®Â∞ÜÂ∏ÆÂä©ÊÇ®ÁêÜËß£ÊúØËØ≠ÂèäÂÖ∂Âú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑ‰ΩøÁî®„ÄÇ\n\nÊÑüË∞¢ÊÇ®ÁöÑÈòÖËØªÔºÅÂ¶ÇÊûúÊÇ®ËßâÂæóÊú¨ÊåáÂçóÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑‰∏éÂÖ∂‰ªñÂèØËÉΩÂ∏åÊúõÊèêÂçáÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁêÜËß£ÁöÑ‰∫∫ÂàÜ‰∫´„ÄÇÊàë‰ª¨ÂÖ±ÂêåÂ≠¶‰π†ÔºåÂπ∂Âõ†Ê≠§Êõ¥Â•ΩÂú∞Â∫îÁî®Ëøô‰∫õÊ¶ÇÂøµ„ÄÇ\n\nÂ¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÊÉ≥Ê≥ï„ÄÅÈóÆÈ¢òÔºåÊàñÁîöËá≥ËÆ§‰∏∫ÂèØËÉΩÊúâÂ∏ÆÂä©ÁöÑÈ¢ùÂ§ñËµÑÊ∫êÂª∫ËÆÆÔºåËØ∑Âú®‰∏ãÈù¢ÁöÑËØÑËÆ∫Âå∫ÁïôË®Ä„ÄÇ\n\nÁ•ùÊÇ®Âú®ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∏ñÁïå‰∏≠Êé¢Á¥¢ÊÑâÂø´ÔºÅ\n\n*ÈÄöËøá [linktr.ee](https://proxy.rifx.online/https://linktr.ee/tharunkumarreddypolu) ‰∏éÊàëËÅîÁ≥ªÔºå‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØÔºÅ*\n\n## Áî®ÁÆÄÂçïËã±ËØ≠ üöÄ\n\n*ÊÑüË∞¢ÊÇ®Êàê‰∏∫ [**Áî®ÁÆÄÂçïËã±ËØ≠**](https://proxy.rifx.online/https://plainenglish.io/) Á§æÂå∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºÅÂú®ÊÇ®Á¶ªÂºÄ‰πãÂâçÔºö*\n\n* ‰∏ÄÂÆöË¶Å **ÁÇπËµû** Âíå **ÂÖ≥Ê≥®** ‰ΩúËÄÖ Ô∏èüëè**Ô∏èÔ∏è**\n* ÂÖ≥Ê≥®Êàë‰ª¨Ôºö [**X**](https://proxy.rifx.online/https://x.com/inPlainEngHQ) \\| [**LinkedIn**](https://proxy.rifx.online/https://www.linkedin.com/company/inplainenglish/) \\| [**YouTube**](https://proxy.rifx.online/https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \\| [**Discord**](https://proxy.rifx.online/https://discord.gg/in-plain-english-709094664682340443) \\| [**Newsletter**](https://proxy.rifx.online/https://newsletter.plainenglish.io/) \\| [**Podcast**](https://proxy.rifx.online/https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)\n* [**Âú® Differ ‰∏äÂàõÂª∫‰∏Ä‰∏™ÂÖçË¥πÁöÑ AI È©±Âä®ÂçöÂÆ¢„ÄÇ**](https://proxy.rifx.online/https://differ.blog/)\n* Êõ¥Â§öÂÜÖÂÆπËØ∑ËÆøÈóÆ [**PlainEnglish.io**](https://proxy.rifx.online/https://plainenglish.io/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/top-5-ai-tools-for-ios-developers-5ee9f39558ac","frontmatter":{"title":"Èù¢Âêë iOS ÂºÄÂèë‰∫∫ÂëòÁöÑ 5 Â§ß‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑","meta_title":"Èù¢Âêë iOS ÂºÄÂèë‰∫∫ÂëòÁöÑ 5 Â§ß‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑","description":"Êú¨Êñá‰ªãÁªç‰∫Ü‰∫îÂ§ßAIÂ∑•ÂÖ∑ÔºåÊó®Âú®ÊèêÂçáiOSÂºÄÂèëËÄÖÁöÑÂ∑•‰ΩúÊïàÁéá„ÄÇÈ¶ñÂÖàÊòØCursor/VSCodeÔºåÈÄöËøáGitHub CopilotÂÆûÁé∞Âø´ÈÄüÁºñÁ†ÅÂíåÊô∫ËÉΩÈáçÊûÑ„ÄÇÂÖ∂Ê¨°ÊòØGitHub CopilotÁöÑXcodeÊâ©Â±ïÔºåÊèê‰æõAIËæÖÂä©ÁºñËæëÂäüËÉΩ„ÄÇÁ¨¨‰∏âÊòØSwift AssistÔºåËôΩÁÑ∂Â∞öÊú™ÂÆåÂÖ®ÂèØÁî®Ôºå‰ΩÜÊúâÊΩúÂäõÁîüÊàê‰ª£Á†Å„ÄÇÊé•ÁùÄÊòØChatGPTÂèäÂÖ∂Ë°çÁîüÂ∑•ÂÖ∑ÔºåÈÄÇÂêàÂø´ÈÄüËø≠‰ª£‰ª£Á†Å„ÄÇÊúÄÂêéÊòØAlex SidebarÂíåAIProxyÔºåÂàÜÂà´‰∏∫XcodeÊèê‰æõÊâ©Â±ïÂäüËÉΩÂíåÂÆâÂÖ®ÈõÜÊàêAI API„ÄÇÊï¥‰Ωì‰∏äÔºåËøô‰∫õÂ∑•ÂÖ∑‰∏∫iOSÂºÄÂèëËÄÖÊèê‰æõ‰∫ÜÈ´òÊïàÁöÑÁºñÁ†Å‰ΩìÈ™å„ÄÇ","date":"2024-11-14T03:29:09.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*6Hs8174FgiwTv87e.jpg","categories":["Programming","Technology/Web","Generative AI"],"author":"Rifx.Online","tags":["Cursor","VSCode","GitHub","Copilot","Swift"],"draft":false,"slug":"blog/top-5-ai-tools-for-ios-developers-5ee9f39558ac"},"content":"\n### ÊèêÈ´òÂ∑•‰ΩúÊµÅÁ®ãÈÄüÂ∫¶‰∏éÊïàÁéá\n\n\n\nËôΩÁÑ∂ÂÖ≥‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑËÆ®ËÆ∫ÂæàÂ§öÔºå‰ΩÜÊàëÊÉ≥ËÆ©‰Ω†ÂõûÂΩíÁé∞ÂÆû„ÄÇÊó†ËÆ∫‰Ω†ÊòØÂê¶Â∑≤ÁªèÂú®‰ΩøÁî® AI ËæÖÂä©ÁöÑÁºñÁ†ÅÂ∑•ÂÖ∑ÔºåÊàñËÄÖËßâÂæóËøô‰∏ÄÂàáÈÉΩÊòØÊó†Á®Ω‰πãË∞à‚Ä¶‚Ä¶ËøôÁØáÊ†áÈ¢òÂê∏ÂºïÁúºÁêÉÁöÑÊñáÁ´†ÂèØËÉΩÈÄÇÂêà‰Ω†„ÄÇ\n\nËôΩÁÑ∂‰Ω†ÂèØËÉΩÂ∑≤ÁªèËÉΩÊâæÂà∞ÂæàÂ§öÂÖ≥‰∫éÂ¶Ç‰Ωï‰ΩøÁî®ÂêÑÁßçÂ∑•ÂÖ∑Êù•ÊèêÈ´ò‰Ω†ÁöÑÊäÄËÉΩ„ÄÅÊïàÁéáÂíåÂáÜÁ°ÆÊÄßÁöÑÊñáÁåÆÔºå‰ΩÜÂØπ‰∫éÊàë‰ª¨ iOS ÂºÄÂèëËÄÖÊù•ËØ¥ÔºåËøôË¶ÅÂ§çÊùÇ‰∏Ä‰∫õ„ÄÇÂõ†‰∏∫Êàë‰ª¨‰æùËµñ Xcode ÂèäÂÖ∂Â∑•ÂÖ∑ÈìæÊù•ÊûÑÂª∫Êàë‰ª¨ÁöÑÂ∫îÁî®ÔºåÊâÄ‰ª•Êàë‰ª¨ÂæàÈöæ‰∏ç‰ΩøÁî® Xcode„ÄÇËÄåÊàëÂ∞ÜÂú®Êé•‰∏ãÊù•ÁöÑÊÆµËêΩ‰∏≠ÂàóÂá∫ÂíåËß£ÈáäÁöÑÂπ∂‰∏çÊòØÊâÄÊúâÂ∑•ÂÖ∑ÈÉΩ‰∏éË∑≥Ëøá Xcode ÊúâÂÖ≥„ÄÇ\n\n## 1\\. Cursor / VSCode\n\nÊòæÁÑ∂ÔºåËøôÊòØÂàóË°®ÁöÑÈ¶ñ‰Ωç„ÄÇÈô§Èùû‰Ω†‰∏ÄÁõ¥Âú®Áü≥Â§¥‰∏ãÂÜ¨Áú†ÔºåÂê¶Âàô‰Ω†ÂèØËÉΩÂê¨ËØ¥ËøáVSCode„ÄÇÂú®SwiftÈ°πÁõÆ‰∏≠‰ΩøÁî®ÂÆÉÂπ∂‰∏çÊòØÊñ∞È≤ú‰∫ã„ÄÇÂÜÖÁΩÆ‰∫éVSCodeÁöÑGitHub CopilotÂÖÅËÆ∏‰Ω†‰ª•ÂÖâÈÄüÁºñÁ†ÅÔºåËÄåÊó†ÈúÄËøõË°åÂ§™Â§öËÆæÁΩÆ„ÄÇ‰ªñ‰ª¨ÊúÄËøëÂú®VSCode‰∏≠ÈõÜÊàê‰∫ÜÊõ¥Â§öÁöÑCopilotÂäüËÉΩÔºåË∂äÊù•Ë∂äÊé•ËøëCursor„ÄÇÈô§‰∫ÜÊ†áÁ≠æË°•ÂÖ®Â§ñÔºå‰Ω†Áé∞Âú®ËøòÂèØ‰ª•ËøõË°åÂÜÖËÅîËÅäÂ§©Âíå‰ª£Á†ÅÁîüÊàê„ÄÇ\n\nCursorÊòØVSCodeÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåÊåâÁÖßÊàëÁöÑÁªèÈ™åÔºå‰ªñ‰ª¨ÁöÑCursorÊ†áÁ≠æË°•ÂÖ®ÂäüËÉΩÊØîVSCodeÊõ¥Âø´„ÄÅÊõ¥ÂáÜÁ°Æ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*pQ4SuReyicAiBCG3.gif)\n\n‰ªñ‰ª¨ËøòÂÅö‰∫Ü‰∏Ä‰∫õËÆ©ÊàëËäÇÁúÅ‰∫ÜÊó†Êï∞Â∞èÊó∂ÁöÑ‰∫ãÊÉÖÔºöÊô∫ËÉΩ/AIËæÖÂä©ÈáçÊûÑ„ÄÇËøôÂèØËÉΩÊòØÂÄºÂæóCursorËÆ¢ÈòÖÁöÑÊúÄ‰Ω≥ÂäüËÉΩ‰πã‰∏Ä„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JlzVJ6o18sulIUEeo_p5sg.gif)\n\nËÄå‰∏îËøô‰∏ç‰ªÖ‰ªÖÊòØÈáçÊûÑÔºõÂú®Êõ¥Êîπ‰∏ÄË°åÂêéÔºåÂÆÉÂú®Êô∫ËÉΩÁºñËæë‰∏≠‰πü‰ºöË°®Áé∞Âá∫Ëâ≤„ÄÇCursor‰ºöÊòæÁ§∫‰∏Ä‰∏™‚ÄúÊ†áÁ≠æ‚ÄùÊåáÁ§∫Á¨¶ÔºåË°®Á§∫ÂÆÉÂØπ‰Ω†ÂàöÂàöÁºñËæëÁöÑ‰ª£Á†ÅÈÉ®ÂàÜÊèêÂá∫‰∫ÜÊõ¥ÊîπÂª∫ËÆÆ„ÄÇÂè™ÈúÄÊåâ‰∏ãÊ†áÁ≠æÈîÆÂç≥ÂèØÁ∫ßËÅîÊõ¥ÊîπÔºåËøôÊ†∑ÂèØ‰ª•‰∏çÊñ≠ËøõË°å‰∏ãÂéª„ÄÇÊ†áÁ≠æÊ†áÁ≠æÊ†áÁ≠æ„ÄÇ\n\n‰∏ÄÊó¶‰Ω†ËøõÂÖ•Áä∂ÊÄÅÔºå‰Ω†‰ºöÂèëÁé∞Ëá™Â∑±ËÉΩÂ§ö‰πàÈ´òÊïà„ÄÇÊàëÁºñÁ†ÅÁöÑÊµÅÁ®ãÂíåÂæÄÂ∏∏‰∏ÄÊ†∑Ôºå‰ΩÜÂõ†‰∏∫ÊàëÈúÄË¶ÅÂÜôÁöÑ‰ª£Á†ÅÂ∞ëÂæóÂ§öÔºåÊâÄ‰ª•ÈÄüÂ∫¶Êõ¥Âø´„ÄÇ‰Ω†‰ΩøÁî®ÂÆÉÁºñÁ†ÅÁöÑË∂äÂ§öÔºåÂÆÉÂ∞±Ë∂äËÉΩÂ≠¶‰π†‰Ω†ÁöÑÈ°πÁõÆ„ÄÅÁºñÁ†ÅÈ£éÊ†ºÁ≠â‚Ä¶‚Ä¶‰∏ÄÂºÄÂßãÂèØËÉΩ‰ºöÊòæÂæóÊúâ‰∫õ‰∏çÈÄÇÂ∫îÔºå‰ΩÜÁõ∏‰ø°ÊàëÔºåÁªôÂÆÉ‰∏ÄÁÇπÊó∂Èó¥„ÄÇ\n\n‰Ω†ËøòÂèØ‰ª•ÈÄöËøáÂÜÖËÅîËÅäÂ§©ÁîüÊàê‰ª£Á†ÅÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*pVzU2MZ0vNFQ6-dRaWPy-w.gif)\n\nÂΩì‰Ω†ÈúÄË¶Å‰∏Ä‰∏™ÁâπÂÆöÁöÑÁÆóÊ≥ïÔºåÊàñËÄÖÂú®Áé∞Êúâ‰ª£Á†Å‰∏≠Êã•ÊúâÊâÄÊúâ‰∏ä‰∏ãÊñá‰ΩÜÈúÄË¶ÅÁºñÂÜô‰∏Ä‰∫õÁπÅÁêêÁöÑÈÉ®ÂàÜÊó∂ÔºåËøôÈùûÂ∏∏ÊúâÁî®„ÄÇÂÆÉÁöÑÊïàÊûúÁõ∏ÂΩì‰∏çÈîôÔºå‰πüËÉΩËäÇÁúÅÂæàÂ§öÊó∂Èó¥„ÄÇÂà´Âøò‰∫ÜÂÆ°Êü•ÁîüÊàêÁöÑ‰ª£Á†Å :)\n\n‰∏∫‰∫Ü‰∏ìÈó®ÂºÄÂßãiOSÂºÄÂèëÔºåÊàëÈºìÂä±‰Ω†ÈòÖËØªÊàëÂè¶Â§ñ‰∏§‰∏™ÊïÖ‰∫ãÔºö\n\n‰∏Ä‰∏™ÊòØÂÖ≥‰∫éÂ¶Ç‰ΩïËÆæÁΩÆÂÆÉÔºåÂÆâË£ÖÊ≠£Á°ÆÁöÑÊâ©Â±ïÁ≠â‚Ä¶‚Ä¶\n\nÂè¶‰∏Ä‰∏™ÊòØÂÖ≥‰∫éÂ¶Ç‰ΩïÂ∞Ü‰Ω†ÁöÑXcodeÈ°πÁõÆ‰ªéÂü∫‰∫éÁªÑÁöÑËΩ¨Êç¢‰∏∫Âü∫‰∫éÊñá‰ª∂Â§πÁöÑÔºå‰ª•‰æø‰Ω†ÂèØ‰ª•Âú®VSCode/Cursor‰∏≠Ëá™Áî±ÂàõÂª∫/Âà†Èô§/ÁßªÂä®Êñá‰ª∂ÔºåËÄåÊó†ÈúÄËß¶Á¢∞.xcodeproj / Xcode„ÄÇ\n\nËøôÂè™ÊòØCursor/VSCodeÂú®iOSÂºÄÂèë‰∏≠ÁöÑË°®Èù¢„ÄÇ‰ΩÜ‰Ω†‰ªäÂ§©Â∞±Â∫îËØ•ÂºÄÂßãÔºÅ\n\n## 2\\. GitHub Copilot Xcode Êâ©Â±ï\n\nËøôÊòØ‰∏Ä‰∏™ÊúÄËøëÂèëÂ∏ÉÁöÑÊâ©Â±ïÔºåÊúÄÂàùÊòØ [Intitni](https://proxy.rifx.online/https://github.com/intitni/CopilotForXcode) ÁöÑ‰∏Ä‰∏™È°πÁõÆÔºå‰ΩÜ‰ºº‰πé GitHub Â∑≤ÁªèÂØπÂÖ∂ËøõË°å‰∫ÜÂàÜÂèâ/Êî∂Ë¥≠ÔºåÂπ∂‰ΩøÂÖ∂Êàê‰∏∫ Copilot + Xcode ÁöÑÂÆòÊñπÊâ©Â±ï„ÄÇÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåËôΩÁÑ∂Áî®Êà∑‰ΩìÈ™åÂπ∂‰∏çÂÆåÁæéÔºàÂèØ‰ª•ÁêÜËß£ÔºåÂõ†‰∏∫‰ªñ‰ª¨ÂøÖÈ°ª‰∏éÂèØËÆøÈóÆÊÄß/Á™óÂè£ API ‰∏ÄËµ∑Â∑•‰ΩúÔºâÔºå‰ΩÜÂÆÉÊØî AppleÔºàÊú¨Âú∞ÔºâXcode Ê®°ÂûãË¶ÅÂ•ΩÂæóÂ§ö„ÄÇ\n\nËÄå‰Ω†ÂæàÂπ∏ËøêÔºåÊàëÂ∑≤ÁªèÂÜôËøáÂÖ≥‰∫éÂÆÉÁöÑÂÜÖÂÆπÔºö\n\nÂ¶ÇÊûú‰Ω†Ëøò‰∏çÂáÜÂ§áÂàáÊç¢Âà∞ Xcode ‰ª•Â§ñÁöÑÂÖ∂‰ªñÁºñËæëÂô®Ôºå‰ΩÜ‰ªçÊÉ≥‰ΩøÁî®È´òÊïàÁöÑ AI ËæÖÂä©‰ª£Á†ÅÁºñËæëÔºåÈÇ£‰πàËøô‰∏™Êâ©Â±ïÂ∞±ÊòØ‰∏∫‰Ω†ÂáÜÂ§áÁöÑÔºÅ\n\n## 3\\. Swift Assist\n\nËôΩÁÑ∂ Xcode Â∑≤ÁªèÂÜÖÁΩÆ‰∫Ü‰∏Ä‰∏™Áî®‰∫éÈ¢ÑÊµã‰ª£Á†ÅË°•ÂÖ®ÁöÑÊú¨Âú∞Ê®°ÂûãÔºà‰ªÖÂú® Xcode 16 ÁöÑ Apple Silicon Mac ‰∏äÂèØÁî®ÔºâÔºå‰ΩÜ Apple Âú® WWDC ‰∏äÈÄèÈú≤‰∫ÜÂÖ∂‰ªñÂÜÖÂÆπÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-mlY8GyGh3VPVhyg3TmLYw.png)\n\nSwift Assist\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XJnlRo8mqrAMZEVEL64ufg.gif)\n\nËøôÁúãËµ∑Êù•ÂÉèÊòØÊàë‰∏äÈù¢ÊºîÁ§∫ÁöÑ Cursor ÁöÑËÅäÂ§© + ‰ª£Á†ÅÁîüÊàê„ÄÇÂÆÉÂ∫îËØ•ËÉΩÂ§üÊ†πÊçÆ‰Ω†ÁöÑËØÑËÆ∫ÁîüÊàê‰ª£Á†Å„ÄÇ‰ΩÜÁõÆÂâçÔºåËøô‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ËôöÂπªÁöÑ‰∫ßÂìÅ„ÄÇXcode 16\\.2 beta 2 ÊèêÂà∞‰∫ÜÂÆÉÔºå‰ΩÜÊàë‰ª¨‰ªçÁÑ∂Êó†Ê≥ïËøõË°åÊµãËØï„ÄÇ\n\n‰πüËÆ∏ÂÆÉ‰ºöÂú® Xcode 16\\.2 beta ÁöÑÂêéÁª≠ÁâàÊú¨‰∏≠Êé®Âá∫ÔºåÊàëËø´‰∏çÂèäÂæÖÊÉ≥Ë¶ÅÊµãËØïÂπ∂ÂÜôÂÖ≥‰∫éÂÆÉÁöÑÂÜÖÂÆπÔºÅ\n\n## 4\\. ChatGPT/Claude/Perplexity ÁΩëÁªúÁïåÈù¢\n\nÊúâÊó∂ÂÄôÔºåÂõûÂΩíÂü∫Á°ÄÊòØÊúÄÂ•ΩÁöÑÈÄâÊã©„ÄÇËôΩÁÑ∂Ëøô‰∫õ‰ª£Á†ÅÁºñËæëÂô®‰ΩøÁî®‰∫ÜAnthropicÂíåOpenAIÁöÑÊ®°Âûã‰ª•ÂèäÂÆÉ‰ª¨Ëá™Â∑±ÁöÑÊ®°ÂûãÔºå‰ΩÜÂú®ÂΩì‰ªäÁöÑÁéØÂ¢É‰∏≠Ôºå‰ΩøÁî®ÂÆÉ‰ª¨ÁöÑÁΩëÁªúÁïåÈù¢‰πüÊòØ‰∏ÄÁßçÂÆùË¥µÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n### ChatGPT \\+ Canvas\n\nOpenAI ÁöÑ ChatGPT Âú®ËøáÂéªÂá†‰∏™Êúà‰∏≠Êúâ‰∫ÜÂæàÂ§ßÁöÑËøõÂ±ï„ÄÇÊúÄËøëÂèëÂ∏ÉÁöÑ o1-preview ÁâàÊú¨Â∏¶Êù•‰∫ÜÊé®ÁêÜÂíåÁîªÂ∏ÉÂäüËÉΩÔºå‰ΩøÂæóÂú® ChatGPT ÁΩëÈ°µÁïåÈù¢‰∏≠ËøõË°åÁºñÁ†Å‰ºöËØùÂèòÂæóÊõ¥Âä†È°∫ÁïÖ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WUraNCcZMrCRrHMilgzl-Q.png)\n\nÁîªÂ∏ÉÊòØ‰∏Ä‰∏™ÊûÑÂª∫Âú® ChatGPT ÁΩëÈ°µÁïåÈù¢‰∏äÁöÑËø∑‰Ω†‰ª£Á†ÅÁºñËæëÂô®ÔºåÂÖÅËÆ∏ÊÇ®Âø´ÈÄüËø≠‰ª£‰ª£Á†ÅÂíåÊÉ≥Ê≥ï„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®ËÅäÂ§©ËøõË°åÂ¢ûÈáèÊõ¥ÊîπÔºåËøòÊúâÂÖ∂‰ªñ‰∏Ä‰∫õÂ∑•ÂÖ∑ÂèØ‰ª•ÂØπ‰ª£Á†ÅËøõË°åÊ≥®Èáä„ÄÅËøõË°åÂÜÖËÅîÊõ¥Êîπ„ÄÅËΩ¨Êç¢‰∏∫ÂÖ∂‰ªñËØ≠Ë®ÄÁ≠â„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ab7PdMLJwacZtVsET2YYmA.gif)\n\nËôΩÁÑ∂Ëøô‰∏çËÉΩËÆ©ÊÇ®ÊûÑÂª∫ÂÆåÊï¥ÁöÑÂ∫îÁî®Á®ãÂ∫èÔºå‰ΩÜÂÆÉÊòØ‰∏Ä‰∏™Âú®Ê†áÂáÜÁºñËæëÂô®‰πãÂ§ñÂø´ÈÄüËø≠‰ª£‰ª£Á†ÅÊÉ≥Ê≥ïÁöÑÂ•ΩÂ∑•ÂÖ∑„ÄÇ\n\n### Claude ‰º™ÂΩ±\n\nËøô‰∏é ChatGPT Canvas Á±ª‰ººÔºå‰ΩÜÂÖ∑Êúâ‰∏Ä‰∫õÂÖ∂‰ªñÂäüËÉΩÔºå‰æãÂ¶ÇÈ¢ÑËßàÔºàÊòæÁÑ∂‰∏çÊîØÊåÅ Swift/SwiftUIÔºâÂíåÂêåÊó∂Â§ÑÁêÜÂ§ö‰∏™Êñá‰ª∂„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*2iverELFSGqnJzklPK0cYg.png)\n\n## 5\\. Alex Sidebar\n\nËøôÊòØ‰∏Ä‰∏™Êñ∞ÁöÑÁ´û‰∫âËÄÖÔºÅÂâçÊèêÂæàÁÆÄÂçïÔºåÂõ†‰∏∫ Xcode ÊòØÈó≠Ê∫êÁöÑÔºåÊâ©Â±ï API Áõ∏ÂΩìÊúâÈôêÔºå‰∏∫‰ªÄ‰πà‰∏çÂõ¥Áªï Xcode ÊûÑÂª∫Âë¢Ôºü\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vZgn_FjH0FW53c7qZ4DZAg.png)\n\nÊàëÂØπÁî®Êà∑‰ΩìÈ™åÂπ∂‰∏çÂ§™Êª°ÊÑèÔºå‰ΩÜÂÆÉÊèê‰æõ‰∫ÜÂ§ßÂ§öÊï∞ Cursor ÂäüËÉΩÔºå‰Ωú‰∏∫‰∏Ä‰∏™ÂÉèÁ™óÂè£‰∏ÄÊ†∑ÊûÑÂª∫ÁöÑ Xcode ‰æßÈù¢Êùø„ÄÇËøôÈáåÊúâÂêÑÁßçÂø´Êç∑ÈîÆ + ‰ª£Á†ÅË°•ÂÖ® + ËÅäÂ§©„ÄÇ‰Ω†ÁªùÂØπÂ∫îËØ•Â∞ùËØï‰∏Ä‰∏ãÔºåÁúãÁúãÂÆÉÊòØÂê¶ËÉΩÊîπÂñÑ‰Ω†ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºÅ\n\n## 6\\. AIProxy\n\n‰Ωú‰∏∫Ôºà3ÔºâSwift AssistÁöÑÈ¢ùÂ§ñÂ•ñÂä±ÔºåÂÆÉÂπ∂‰∏çÊòØÁúüÊ≠£ÁöÑ‚Ä¶.ÂèØÁî®\n\nËøô‰∏çÊòØ‰∏Ä‰∏™Áî®‰∫éÁºñÁ†ÅÁöÑÂ∑•ÂÖ∑ÔºåËÄåÊòØ‰∏Ä‰∏™‰∏∫ÊûÑÂª∫ËÄÖÂáÜÂ§áÁöÑÂ∑•ÂÖ∑„ÄÇÂΩìÂú®‰Ω†ÁöÑiOSÂ∫îÁî®‰∏≠ÈõÜÊàêAI APIÊó∂Ôºå‰Ω†ÂæàÂèØËÉΩÈúÄË¶ÅÂ∞ÜAPIÂØÜÈí•Ê∑ªÂä†Âà∞‰Ω†ÁöÑÈ°πÁõÆ‰∏≠„ÄÇ‰ΩÜÊ≠£Â¶ÇÊàë‰ª¨ÊâÄÁü•ÔºàÂØπÂêßÔºÅÔºâÔºå‰Ω†‰∏çÂ∫îËØ•Â∞ÜÂÖ∂ÊîæÂú®ÂÆ¢Êà∑Á´Ø„ÄÇÂ¶ÇÊûúËøôÊ†∑ÂÅöÔºåÂá†‰πé‰ªª‰Ωï‰∫∫ÈÉΩÂèØ‰ª•ËΩªÊòìËé∑Âèñ‰Ω†ÁöÑAPIÂØÜÈí•ÔºåÂπ∂‰ª£Ë°®‰Ω†‰ΩøÁî®‰Ω†ÁöÑAIÁßØÂàÜ„ÄÇ\n\nËøõÂÖ•[AIProxy](https://proxy.rifx.online/https://www.aiproxy.pro/)Ôºå‰ªñ‰ª¨Êèê‰æõÂºÄÊ∫êSDKÔºåÊòì‰∫éÈõÜÊàêÔºåÂπ∂ÊîØÊåÅ‰Ω†ÊâÄÈúÄÁöÑÊâÄÊúâAIÊèê‰æõÂïÜ„ÄÇ\n\nÂ¶ÇÊûú‰Ω†‰∏çÊÉ≥ÊûÑÂª∫‰∏Ä‰∏™ÂêéÁ´ØÊù•‰ª£ÁêÜ‰Ω†ÁöÑAIË∞ÉÁî®ÔºåËøôÂ∞±ÊòØÈÄÇÂêà‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºÅ\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/top-8-leading-ai-use-cases-revolutionizing-business-in-2025-837e4a98f6a3","frontmatter":{"title":"2025 Âπ¥ÂºïÈ¢ÜÂïÜ‰∏öÂèòÈù©ÁöÑÂÖ´Â§ß‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®Ê°à‰æã","meta_title":"2025 Âπ¥ÂºïÈ¢ÜÂïÜ‰∏öÂèòÈù©ÁöÑÂÖ´Â§ß‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®Ê°à‰æã","description":"‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÊ≠£Âú®Êé®Âä®ÂïÜ‰∏öËΩ¨ÂûãÔºåÈ¢ÑËÆ°Âà∞2025Âπ¥ÔºåÂ∞ÜÂú®Â§ö‰∏™È¢ÜÂüüÂèëÊå•ÂÖ≥ÈîÆ‰ΩúÁî®ÔºåÂåÖÊã¨È¢ÑÊµãÂàÜÊûê„ÄÅÂÆ¢Êà∑ÊîØÊåÅ„ÄÅ‰∏™ÊÄßÂåñËê•ÈîÄÂíå‰æõÂ∫îÈìæ‰ºòÂåñÁ≠â„ÄÇAIÈÄöËøáÊèêÈ´òÊïàÁéá„ÄÅÈôç‰ΩéÊàêÊú¨ÂíåÂ¢ûÂº∫ÂÜ≥Á≠ñËÉΩÂäõÔºåÂ∏ÆÂä©‰ºÅ‰∏öÊõ¥Â•ΩÂú∞Â∫îÂØπÂ∏ÇÂú∫ÂèòÂåñ„ÄÇÂ∞ΩÁÆ°Èù¢‰∏¥Êï∞ÊçÆÈöêÁßÅÂíåÂ∞±‰∏öÊõø‰ª£Á≠âÊåëÊàòÔºåÊã•Êä±AIÊäÄÊúØÁöÑ‰ºÅ‰∏öÂ∞ÜÂú®Á´û‰∫â‰∏≠Âç†ÊçÆ‰ºòÂäøÔºåÊé®Âä®ÂàõÊñ∞Âπ∂Êª°Ë∂≥‰∏çÊñ≠ÂèòÂåñÁöÑÊ∂àË¥πËÄÖÈúÄÊ±Ç„ÄÇ","date":"2024-11-16T01:36:50.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Na9Wc3PuYCxWOCSBWc4HtQ.png","categories":["Technology","Predictive Analytics","Machine Learning"],"author":"Rifx.Online","tags":["predictive","analytics","automation","recommendation","machine-learning"],"draft":false,"slug":"blog/top-8-leading-ai-use-cases-revolutionizing-business-in-2025-837e4a98f6a3"},"content":"\n\n\n### Êé¢Á¥¢Êé®Âä®ÂïÜ‰∏öÊàêÂäüÁöÑÂÖ≥ÈîÆAIÂ∫îÁî®„ÄÇ\n\n‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÊ≠£Êó•ÁõäÂ°ëÈÄ†ÂïÜ‰∏öÁöÑÊú™Êù•ÔºåÂÖ∂ÂΩ±ÂìçÂäõÂú®ÂêÑ‰∏™Ë°å‰∏ö‰∏çÊñ≠Êâ©Â§ß„ÄÇÂà∞2025Âπ¥ÔºåAI‰∏ç‰ªÖÂ∞ÜÊàê‰∏∫ÂàõÊñ∞ÁöÑÂ∑•ÂÖ∑ÔºåÊõ¥ÊòØÂïÜ‰∏öËΩ¨ÂûãÁöÑÈáçË¶ÅÈ©±Âä®Âäõ„ÄÇ‰ªéÂÆ¢Êà∑ÊîØÊåÅÂà∞È¢ÑÊµãÂàÜÊûêÔºåAIÂú®ÊèêÈ´òÊïàÁéá„ÄÅÈôç‰ΩéÊàêÊú¨Âíå‰øÉËøõÊñ∞Â¢ûÈïøÊú∫‰ºöÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÈöèÁùÄAIÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºå‰ºÅ‰∏öË∂äÊù•Ë∂ä‰æùËµñ‰∫éÂÆÉÊù•ÁÆÄÂåñËøêËê•„ÄÅÂ¢ûÂº∫ÂÜ≥Á≠ñËÉΩÂäõÂíåÂàõÈÄ†‰∏™ÊÄßÂåñÁöÑÂÆ¢Êà∑‰ΩìÈ™å„ÄÇ\n\n\n\n[***AIÊäÄÊúØ***](https://www.blockchainappfactory.com/ai-development-company)ÁöÑÂø´ÈÄüÂèëÂ±ïÊ≠£Âú®‰∏∫‰ºÅ‰∏öÂºÄÂêØÂâçÊâÄÊú™ÊúâÁöÑÂèØËÉΩÊÄß„ÄÇÂÖ¨Âè∏Ê≠£Âú®Âà©Áî®Êú∫Âô®Â≠¶‰π†„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËá™Âä®ÂåñÁöÑÂäõÈáèÔºå‰ª•Âú®‰∏çÊñ≠ÂèòÂåñÁöÑÂ∏ÇÂú∫ÁéØÂ¢É‰∏≠‰øùÊåÅÁ´û‰∫âÂäõ„ÄÇËøô‰∫õÂèëÂ±ïÂú®‰æõÂ∫îÈìæ‰ºòÂåñ„ÄÅ‰∏™ÊÄßÂåñËê•ÈîÄÂíå‰∫∫ÂäõËµÑÊ∫êÁÆ°ÁêÜÁ≠âÈ¢ÜÂüüÂ∞§‰∏∫ÊòéÊòæ„ÄÇÈöèÁùÄAIÁöÑÊôÆÂèäÔºåÂÖ∂Âú®Ê†∏ÂøÉ‰∏öÂä°ÊµÅÁ®ã‰∏≠ÁöÑÊï¥ÂêàÂ∞ÜÂèòÂæóÊõ¥Âä†ÂÖ≥ÈîÆÔºåÂ∞§ÂÖ∂ÊòØÂØπ‰∫éÈÇ£‰∫õÂ∏åÊúõÂú®2025Âπ¥Âèä‰ª•ÂêéËì¨ÂãÉÂèëÂ±ïÁöÑÁªÑÁªá„ÄÇ\n\n## ÁêÜËß£‰∫∫Â∑•Êô∫ËÉΩ\n\nAIÔºà‰∫∫Â∑•Êô∫ËÉΩÔºâÊòØËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåÊó®Âú®ÂàõÂª∫ËÉΩÂ§üÊâßË°åÈÄöÂ∏∏ÈúÄË¶Å‰∫∫Á±ªÊô∫ËÉΩÁöÑ‰ªªÂä°ÁöÑÊú∫Âô®ÊàñÁ≥ªÁªü„ÄÇËøô‰∫õ‰ªªÂä°ÂåÖÊã¨ÁêÜËß£ËØ≠Ë®Ä„ÄÅËØÜÂà´Ê®°Âºè„ÄÅËß£ÂÜ≥ÈóÆÈ¢òÂíåÂÅöÂá∫ÂÜ≥Á≠ñÁ≠â„ÄÇAIÂèØ‰ª•Â§ßËá¥ÂàÜ‰∏∫‰∏§ÁßçÁ±ªÂûãÔºö\n\n1. **Áã≠‰πâAIÔºàÂº±AIÔºâÔºö** ËøôÁßçÁ±ªÂûãÁöÑAIÊó®Âú®ÊâßË°åÁâπÂÆö‰ªªÂä°„ÄÇ‰æãÂ≠êÂåÖÊã¨ËØ≠Èü≥Âä©ÊâãÂ¶ÇSiriÊàñAlexa„ÄÅ‰∫∫ËÑ∏ËØÜÂà´Á≥ªÁªüÔºå‰ª•ÂèäÊµÅÂ™í‰ΩìÊúçÂä°Â¶ÇNetflixÊàñSpotify‰ΩøÁî®ÁöÑÊé®ËçêÁÆóÊ≥ï„ÄÇÁã≠‰πâAI‰∏çÂÖ∑Â§á‰∏ÄËà¨Êô∫ËÉΩÔºåÂ±ÄÈôê‰∫éÂÖ∂Ë¢´ÁºñÁ®ãÊâßË°åÁöÑ‰ªªÂä°„ÄÇ\n2. **Âπø‰πâAIÔºàÂº∫AIÔºâÔºö** ËøôÊòØ‰∏ÄÁßçÊõ¥È´òÁ∫ßÁöÑAIÂΩ¢ÂºèÔºåËÉΩÂ§üÁêÜËß£„ÄÅÂ≠¶‰π†Âπ∂Âú®ÂπøÊ≥õÁöÑÊ¥ªÂä®‰∏≠Â∫îÁî®Êô∫ËÉΩÔºåÁ±ª‰ºº‰∫é‰∫∫Á±ªÁöÑÊÄùÁª¥ÂíåÊé®ÁêÜÊñπÂºè„ÄÇÂπø‰πâAIÂú®ÁõÆÂâç‰ªçÁÑ∂‰∏ªË¶ÅÊòØÁêÜËÆ∫ÊÄßÁöÑÔºåÂ∞ö‰∏çÂ≠òÂú®„ÄÇ\n\n**AI‰∏≠ÁöÑÂÖ≥ÈîÆÊäÄÊúØÂíåÊ¶ÇÂøµÔºö**\n\n* **Êú∫Âô®Â≠¶‰π†ÔºàMLÔºâÔºö** AIÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºå‰∏ìÊ≥®‰∫éÊûÑÂª∫ÂÖÅËÆ∏Êú∫Âô®‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âπ∂ÈöèÁùÄÊó∂Èó¥Êé®ÁßªÊîπËøõÁöÑÁÆóÊ≥ï„ÄÇÂú®ML‰∏≠ÔºåÁ≥ªÁªüÂú®Â§ßÂûãÊï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉÔºåÂπ∂Âà©Áî®Ëøô‰∫õ‰ø°ÊÅØËøõË°åÈ¢ÑÊµãÊàñÂÜ≥Á≠ñÔºåËÄåÊó†ÈúÄÊòéÁ°ÆÁºñÁ®ã„ÄÇ\n* **Ê∑±Â∫¶Â≠¶‰π†Ôºö** Êú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºå‰ΩøÁî®ÂÖ∑ÊúâÂ§ö‰∏™Â±ÇÊ¨°ÔºàÁß∞‰∏∫Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÔºâÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇÊ∑±Â∫¶Â≠¶‰π†Âú®ÂõæÂÉèÂíåËØ≠Èü≥ËØÜÂà´„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËá™Âä®È©æÈ©∂Á≠âÂ§çÊùÇ‰ªªÂä°‰∏≠ÁâπÂà´ÊúâÁî®„ÄÇ\n* **Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâÔºö** ËøôÊ∂âÂèäÊïôÊú∫Âô®ÁêÜËß£„ÄÅËß£ÈáäÂíå‰ª•ÊúâÊÑè‰πâÂíåÁõ∏ÂÖ≥ÁöÑÊñπÂºèÂõûÂ∫î‰∫∫Á±ªËØ≠Ë®Ä„ÄÇNLPÊòØËÅäÂ§©Êú∫Âô®‰∫∫„ÄÅËôöÊãüÂä©ÊâãÂíåËØ≠Ë®ÄÁøªËØëÂ∫îÁî®ËÉåÂêéÁöÑÊäÄÊúØ„ÄÇ\n* **ËÆ°ÁÆóÊú∫ËßÜËßâÔºö** ‰∏Ä‰∏™ÂÖÅËÆ∏Êú∫Âô®Ëß£ÈáäÂíåÁêÜËß£ËßÜËßâ‰∏ñÁïåÁöÑAIÈ¢ÜÂüü„ÄÇËÆ°ÁÆóÊú∫ËßÜËßâÁî®‰∫é‰∫∫ËÑ∏ËØÜÂà´„ÄÅÁâ©‰ΩìÊ£ÄÊµãÂíåËá™Âä®È©æÈ©∂Ê±ΩËΩ¶Á≠âÂ∫îÁî®„ÄÇ\n* **Âº∫ÂåñÂ≠¶‰π†Ôºö** ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†Á±ªÂûãÔºåÂÖ∂‰∏≠AI‰ª£ÁêÜÈÄöËøáÊâßË°åÂä®‰ΩúÂπ∂‰ª•Â•ñÂä±ÊàñÊÉ©ÁΩöÁöÑÂΩ¢ÂºèÊé•Êî∂ÂèçÈ¶àÊù•Â≠¶‰π†Â¶Ç‰ΩïÂú®ÁéØÂ¢É‰∏≠Ë°å‰∏∫„ÄÇ\n\n## 2024Âπ¥ÊîπÂèòÊ∏∏ÊàèËßÑÂàôÁöÑÂçÅÂ§ßAIÂ∫îÁî®Ê°à‰æã\n\n## 1\\. È¢ÑÊµãÂàÜÊûêÂú®ÊàòÁï•ÂÜ≥Á≠ñ‰∏≠ÁöÑÂ∫îÁî®\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*fgshMkMhuWL7ZEDo9MIR_w.png)\n\nÈ¢ÑÊµãÂàÜÊûêÂà©Áî®ÁªüËÆ°ÁÆóÊ≥ï„ÄÅÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂíåÊï∞ÊçÆÊåñÊéòÊù•Âü∫‰∫éÂéÜÂè≤Êï∞ÊçÆÈ¢ÑÊµãÊú™Êù•ÁªìÊûú„ÄÇÂÆÉ‰Ωø‰ºÅ‰∏öËÉΩÂ§üÂõûÁ≠îÂÖ≥ÈîÆÈóÆÈ¢òÔºå‰æãÂ¶Ç‚ÄúÂèØËÉΩ‰ºöÂèëÁîü‰ªÄ‰πàÔºü‚ÄùÈÄöËøá‰ªéËøáÂéªÁöÑÊ®°Âºè‰∏≠ÊèêÂèñ‰ø°ÊÅØÔºå‰ª•ÊåáÂØºÊú™Êù•ÁöÑÊÉÖÊôØ„ÄÇ\n\n### ÂÖ≥ÈîÆÁî®‰æãÂú®ÊàòÁï•ÂÜ≥Á≠ñ‰∏≠\n\n* **ÈúÄÊ±ÇÈ¢ÑÊµã**ÔºöÈõ∂ÂîÆÂïÜ„ÄÅÂà∂ÈÄ†ÂïÜÂíåÊúçÂä°Êèê‰æõÂïÜ‰ΩøÁî®È¢ÑÊµãÂàÜÊûêÊù•È¢ÑÊµãÈúÄÊ±ÇÔºåÂ∏ÆÂä©‰ªñ‰ª¨ÁÆ°ÁêÜÂ∫ìÂ≠òÔºåÂáèÂ∞ëÊµ™Ë¥πÔºåÈÅøÂÖçÁº∫Ë¥ßÊàñËøáÂ∫¶Áîü‰∫ß„ÄÇ‰æãÂ¶ÇÔºåÈõ∂ÂîÆÂïÜÂèØ‰ª•‰∏∫Â≠£ËäÇÊÄßÈ´òÂ≥∞ÂÅöËÆ°ÂàíÔºåÂà∂ÈÄ†ÂïÜÂèØ‰ª•Ê†πÊçÆÈ¢ÑÊúüÈúÄÊ±ÇË∞ÉÊï¥Áîü‰∫ßËÆ°Âàí„ÄÇ\n* **È£éÈô©ËØÑ‰º∞‰∏éÁÆ°ÁêÜ**ÔºöÈ¢ÑÊµãÊ®°ÂûãÂÆûÊó∂ËØÜÂà´È£éÈô©Âõ†Á¥†Ôºå‰Ωø‰ºÅ‰∏öÊõ¥ÂÆπÊòìÁÆ°ÁêÜË¥¢Âä°„ÄÅËøêËê•ÁîöËá≥Â£∞Ë™âÈ£éÈô©„ÄÇÂú®ÈáëËûçÈ¢ÜÂüüÔºåÈ¢ÑÊµãÂàÜÊûêÂèØ‰ª•Ê†áËÆ∞ÊΩúÂú®ÁöÑËøùÁ∫¶È£éÈô©ÔºåËÄåÂú®‰æõÂ∫îÈìæ‰∏≠ÔºåÂÆÉÂèØ‰ª•È¢ÑÊµã‰∏≠Êñ≠„ÄÇ\n* **ÂÆ¢Êà∑Ë°å‰∏∫È¢ÑÊµã**ÔºöÈÄöËøáÂàÜÊûêËøáÂéªÁöÑ‰∫íÂä®Ôºå‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•È¢ÑÊµãÂÆ¢Êà∑Ë°å‰∏∫Ôºå‰ΩøÂÖ¨Âè∏Êõ¥Â•ΩÂú∞ÁêÜËß£ÂÆ¢Êà∑ÂÅèÂ•Ω„ÄÅË¥≠‰π∞Âë®ÊúüÂíåÊΩúÂú®ÊµÅÂ§±„ÄÇËøôÊúâÂä©‰∫éÈáèË∫´ÂÆöÂà∂‰∫ßÂìÅÂíåÊó∂Êú∫ÔºåÊúÄÂ§ßÂåñÂÆ¢Êà∑ÁîüÂëΩÂë®Êúü‰ª∑ÂÄº„ÄÇ\n\n### È¢ÑÊµãÂàÜÊûêÂØπÊàòÁï•ÁöÑÂ•ΩÂ§Ñ\n\n* **ÂÜ≥Á≠ñÂáÜÁ°ÆÊÄßÊèêÈ´ò**ÔºöÈ¢ÑÊµãÊ®°ÂûãÊèê‰æõÂü∫‰∫éËØÅÊçÆÁöÑÊ¥ûÂØüÔºåÂ¢ûÂº∫ÊàòÁï•ÂÜ≥Á≠ñÁöÑ‰ø°ÂøÉÔºåÂáèÂ∞ëÂØπÁõ¥ËßâÁöÑ‰æùËµñ„ÄÇ\n* **‰∏ªÂä®Ëß£ÂÜ≥ÈóÆÈ¢ò**Ôºö‰ºÅ‰∏öÂèØ‰ª•È¢ÑËßÅÈóÆÈ¢òÔºåËÄå‰∏çÊòØÂú®ÈóÆÈ¢òÂá∫Áé∞Êó∂Ë¢´Âä®ÂèçÂ∫î„ÄÇËøô‰ΩøÂæóÂú®È£éÈô©ÁºìËß£„ÄÅËµÑÊ∫êÂàÜÈÖçÂíå‰∫∫ÂäõËµÑÊ∫êËßÑÂàíÁ≠âÈ¢ÜÂüüÈááÂèñ‰∏ªÂä®Êé™ÊñΩÊàê‰∏∫ÂèØËÉΩ„ÄÇ\n* **Á´û‰∫â‰ºòÂäø**ÔºöÂà©Áî®È¢ÑÊµãÂàÜÊûêÁöÑÂÖ¨Âè∏ËÉΩÂ§üÊØîÁ´û‰∫âÂØπÊâãÊõ¥Âø´„ÄÅÊõ¥ËÅ™ÊòéÂú∞ÂÅöÂá∫ÂÜ≥Á≠ñÔºå‰ªéËÄåËé∑ÂæóÊàòÁï•‰ºòÂäø„ÄÇ\n\n### È¢ÑÊµãÂàÜÊûê‰∏≠ÁöÑÂ∑•ÂÖ∑ÂíåÊäÄÊúØ\n\n* **Êï∞ÊçÆÊî∂ÈõÜ‰∏éÂáÜÂ§á**ÔºöÂÉè Google BigQuery Âíå Apache Hadoop ËøôÊ†∑ÁöÑÂ∑•ÂÖ∑‰ªéÂêÑÁßçÊù•Ê∫êÊî∂ÈõÜÂíåÈ¢ÑÂ§ÑÁêÜÊï∞ÊçÆ„ÄÇ\n* **Ê®°ÂûãÊûÑÂª∫‰∏é‰ºòÂåñ**ÔºöÂ¶Ç TensorFlow„ÄÅSAS Âíå IBM Watson Á≠âÂπ≥Âè∞ÂÖÅËÆ∏‰ºÅ‰∏öÂàõÂª∫ÂíåÊµãËØïÈ¢ÑÊµãÊ®°ÂûãÔºåÂπ∂ÂØπÂÖ∂ËøõË°åÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄßÁöÑÂæÆË∞É„ÄÇ\n* **ÈÉ®ÁΩ≤‰∏éÁõëÊéß**ÔºöÂú®Ê®°ÂûãÂºÄÂèë‰πãÂêéÔºåÂÉè DataRobot Êàñ Amazon SageMaker ËøôÊ†∑ÁöÑÂ∑•ÂÖ∑‰øÉËøõÈÉ®ÁΩ≤ÔºåÂÖÅËÆ∏ÂØπÂÆûÊó∂ÂáÜÁ°ÆÊÄßËøõË°åÊåÅÁª≠ÁõëÊéßÂíåÊõ¥Êñ∞„ÄÇ\n\n## 2\\. AI\\-È©±Âä®ÁöÑÂÆ¢Êà∑ÊîØÊåÅÂíåËÅäÂ§©Êú∫Âô®‰∫∫\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dTt_KxOtAb-qGThAvEOQsg.png)\n\nAI\\-È©±Âä®ÁöÑÂÆ¢Êà∑ÊîØÊåÅÁ≥ªÁªüÂà©Áî®Êú∫Âô®Â≠¶‰π†ÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊù•ÁêÜËß£„ÄÅËß£ÈáäÂíåÂõûÂ∫îÂÆ¢Êà∑Êü•ËØ¢„ÄÇËøô‰∫õÂ∑•ÂÖ∑ÂàÜÊûêÁî®Êà∑ËæìÂÖ•ÔºåÊ£ÄÊµãÊÑèÂõæÔºåÂπ∂Êèê‰æõÁõ∏ÂÖ≥ÁöÑÂìçÂ∫îÊàñÂºïÂØºÁî®Êà∑ÂÆåÊàê‰∏ÄÁ≥ªÂàóÊìç‰ΩúÔºåËá™Âä®ÂåñÂìçÂ∫îËøáÁ®ãÂπ∂ÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥„ÄÇ\n\n### AIÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊîØÊåÅÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÂÖ≥ÈîÆ‰ΩøÁî®Ê°à‰æã\n\n* **ÂÖ®Â§©ÂÄôÂÆ¢Êà∑ÊúçÂä°**: ËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•ÂÖ®Â§©ÂÄôÂ§ÑÁêÜÂÆ¢Êà∑Âí®ËØ¢ÔºåÊèê‰æõÂç≥Êó∂Â∏ÆÂä©ÔºåÂáèÂ∞ëÂÆ¢Êà∑Âú®ÈùûÂ∑•‰ΩúÊó∂Èó¥Á≠âÂæÖ‰∫∫Â∑•ÂÆ¢ÊúçÁöÑÈúÄÊ±Ç„ÄÇ\n* **ÊΩúÂú®ÂÆ¢Êà∑ËµÑÊ†ºÁ°ÆËÆ§ÂíåÂüπËÇ≤**: ÂØπ‰∫é‰ª•ÈîÄÂîÆ‰∏∫È©±Âä®ÁöÑÂõ¢ÈòüÔºåËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•ÈÄöËøáËØ¢ÈóÆÈ¢ÑËÆæÈóÆÈ¢òÊù•Á°ÆËÆ§ÊΩúÂú®ÂÆ¢Êà∑ÔºåÊî∂ÈõÜÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂπ∂Â∞ÜÈ´òÊΩúÂäõÁöÑÊΩúÂú®ÂÆ¢Êà∑ÂºïÂØºÁªô‰∫∫Â∑•ÂÆ¢Êúç„ÄÇ\n* **‰∏™ÊÄßÂåñÂÆ¢Êà∑‰ΩìÈ™å**: Âà©Áî®ÂÆ¢Êà∑Êï∞ÊçÆÔºåAIÈ©±Âä®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÂéÜÂè≤„ÄÅ‰πãÂâçÁöÑ‰∫íÂä®ÂíåË°å‰∏∫‰∏™ÊÄßÂåñÂìçÂ∫îÔºåÊèê‰æõÈáèË∫´ÂÆöÂà∂ÁöÑ‰ΩìÈ™åÔºå‰ª•Â¢ûÂº∫ÂèÇ‰∏éÊÑü„ÄÇ\n* **ÂèçÈ¶àÊî∂ÈõÜÂíåÊÉÖÊÑüÂàÜÊûê**: AIËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•Âú®‰∫íÂä®ÊúüÈó¥Âíå‰πãÂêéÊî∂ÈõÜÂèçÈ¶àÔºåËØÑ‰º∞ÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇÊÉÖÊÑüÂàÜÊûêÂèØ‰ª•Áî®‰∫éÊ£ÄÊµãÊª°ÊÑèÊàñÊå´Ë¥•ÊÑüÔºåÂ∏ÆÂä©‰ºÅ‰∏ö‰ºòÂåñÊúçÂä°„ÄÇ\n\n### AIÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊîØÊåÅÂíåËÅäÂ§©Êú∫Âô®‰∫∫‰ºòÂäø\n\n* **ÊèêÂçáÊïàÁéáÂíåËäÇÁúÅÊàêÊú¨**ÔºöÈÄöËøáËá™Âä®ÂåñÈáçÂ§çÊÄßÊü•ËØ¢ÔºåAIÂáèÂ∞ë‰∫Ü‰∫∫Á±ª‰ª£ÁêÜÁöÑÂ∑•‰ΩúË¥üÊãÖÔºå‰Ωø‰ªñ‰ª¨ËÉΩÂ§ü‰∏ìÊ≥®‰∫éÂ§çÊùÇÈóÆÈ¢òÔºåÂπ∂Èôç‰ΩéËøêËê•ÊàêÊú¨„ÄÇ\n* **ÂèØÊâ©Â±ïÊÄß**ÔºöAIÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊîØÊåÅËÉΩÂ§üËΩªÊùæÊâ©Â±ïÔºå‰Ωø‰ºÅ‰∏öÂú®È´òÂ≥∞Êó∂ÊúüÂ§ÑÁêÜÂÆ¢Êà∑Êü•ËØ¢ÊøÄÂ¢ûËÄåÊó†ÈúÄÂ¢ûÂä†È¢ùÂ§ñÂëòÂ∑•„ÄÇ\n* **Êõ¥Âø´ÁöÑÂìçÂ∫îÊó∂Èó¥**ÔºöAIËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•Âç≥Êó∂Â§ÑÁêÜÂíåÂõûÂ∫îÔºåÊòæËëóÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥Âπ∂ÊîπÂñÑÂÆ¢Êà∑‰ΩìÈ™å„ÄÇ\n\n### ÂèóÊ¨¢ËøéÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÂÆ¢Êà∑ÊîØÊåÅÂíåËÅäÂ§©Êú∫Âô®‰∫∫Âπ≥Âè∞\n\n* **Zendesk Chat and Support**: Â∞ÜËÅäÂ§©Êú∫Âô®‰∫∫‰∏éÂ∑•ÂçïÁ≥ªÁªüÁªìÂêàÔºå‰ª•ÁÆ°ÁêÜÂ§çÊùÇÁöÑÂÆ¢Êà∑ÊîØÊåÅÊµÅÁ®ã„ÄÇ\n* **Intercom**: ‰∏ÄÊ¨æÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆ¢Êà∑Ê∂àÊÅØÂπ≥Âè∞ÔºåÈÄöËøáÂÆûÊó∂ËÅäÂ§©ÂíåËá™Âä®ÂõûÂ§çÊîØÊåÅÈîÄÂîÆÂíåÂÆ¢Êà∑‰∫íÂä®„ÄÇ\n* **Drift**: ‰ª•ÂÖ∂ÊΩúÂú®ÂÆ¢Êà∑ËµÑÊ†ºËØÑ‰º∞ÂäüËÉΩËÄåÈóªÂêçÔºåDrift ‰ΩøÁî®ÂØπËØùÂºè‰∫∫Â∑•Êô∫ËÉΩ‰∏éÁΩëÁ´ôËÆøÂÆ¢‰∫íÂä®ÔºåÂ∞ÜÂÖ∂ËΩ¨Âåñ‰∏∫ÂêàÊ†ºÊΩúÂú®ÂÆ¢Êà∑„ÄÇ\n\n## 3\\. ‰∏™ÊÄßÂåñËê•ÈîÄ‰∏éÊé®ËçêÂºïÊìé\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*24ZIbZ6OOV0UGFoW3OOxtg.png)\n\nÂü∫‰∫éAIÁöÑÊé®ËçêÂºïÊìé‰ΩøÁî®ÁÆóÊ≥ïÂíåÊú∫Âô®Â≠¶‰π†Êù•ÂàÜÊûêÁî®Êà∑Êï∞ÊçÆÔºåËØÜÂà´Ê®°ÂºèÔºåÂπ∂ËøõË°åÈ¢ÑÊµã„ÄÇÈÄöËøáÂ∞ÜËøáÂéªË°å‰∏∫ÁöÑÊï∞ÊçÆ‰∏éÂÆûÊó∂‰∫§‰∫íÁõ∏ÁªìÂêàÔºåËøô‰∫õÂºïÊìéÂèØ‰ª•Êèê‰æõ‰∏éÁî®Êà∑ÂÖ¥Ë∂£È´òÂ∫¶Áõ∏ÂÖ≥ÁöÑÁ≤æÂáÜÊé®Ëçê„ÄÇÊúÄÂ∏∏ËßÅÁöÑÊäÄÊúØÂåÖÊã¨Ôºö\n\n* **ÂçèÂêåËøáÊª§**ÔºöËØÜÂà´Áõ∏‰ººÁî®Êà∑ÂñúÊ¨¢ÁöÑÈ°πÁõÆÊàñÂÜÖÂÆπÂπ∂ËøõË°åÊé®Ëçê„ÄÇ\n* **Âü∫‰∫éÂÜÖÂÆπÁöÑËøáÊª§**ÔºöÂª∫ËÆÆ‰∏é‰πãÂâçË°®Áé∞Âá∫ÂÖ¥Ë∂£ÁöÑÈ°πÁõÆÂÖ∑ÊúâÁõ∏‰ººÂ±ûÊÄßÁöÑÈ°πÁõÆ„ÄÇ\n* **Ê∑∑ÂêàÊ®°Âûã**ÔºöÁªìÂêàÂçèÂêåËøáÊª§ÂíåÂü∫‰∫éÂÜÖÂÆπÁöÑËøáÊª§Ôºå‰ª•Êèê‰æõÊõ¥ÂáÜÁ°ÆÂíåÂ§öÊ†∑ÂåñÁöÑÊé®Ëçê„ÄÇ\n\n### ‰∏™ÊÄßÂåñËê•ÈîÄÂíåÊé®ËçêÂºïÊìéÁöÑÂÖ≥ÈîÆÁî®‰æã\n\n* **ÁîµÂ≠êÂïÜÂä°‰∫ßÂìÅÊé®Ëçê**ÔºöÂú®Á∫øÈõ∂ÂîÆÂïÜÊ†πÊçÆ‰πãÂâçÁöÑË¥≠‰π∞ÊàñÊµèËßàÂéÜÂè≤Âª∫ËÆÆÂïÜÂìÅÔºå‰ªéËÄåÂ¢ûÂä†ËΩ¨ÂåñÁöÑÂèØËÉΩÊÄßÂπ∂ÊèêÂçáÈîÄÂîÆÈ¢ù„ÄÇ\n* **ÂÜÖÂÆπÂíåÂ™í‰Ωì‰∏™ÊÄßÂåñ**ÔºöÂÉèNetflixÂíåSpotifyËøôÊ†∑ÁöÑÊµÅÂ™í‰ΩìÂπ≥Âè∞‰ΩøÁî®Êé®ËçêÂºïÊìéÊù•Âª∫ËÆÆÁîµÂΩ±„ÄÅËäÇÁõÆÊàñÊ≠åÊõ≤Ôºå‰ªéËÄåÂ¢ûÂº∫Áî®Êà∑ÂèÇ‰∏éÂ∫¶ÂíåÁïôÂ≠òÁéá„ÄÇ\n* **Á≤æÂáÜÈÇÆ‰ª∂Ëê•ÈîÄÊ¥ªÂä®**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈÄöËøáÂåÖÂê´‰∫ßÂìÅÂª∫ËÆÆ„ÄÅÁâπÂà´‰ºòÊÉ†Âíå‰∏éÊØè‰∏™Êî∂‰ª∂‰∫∫Ë°å‰∏∫Áõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÊù•‰∏™ÊÄßÂåñÈÇÆ‰ª∂ÂÜÖÂÆπÔºå‰ªéËÄåÊèêÈ´òÊâìÂºÄÁéáÂíåÁÇπÂáªÁéá„ÄÇ\n* **Âä®ÊÄÅÁΩëÈ°µÂÜÖÂÆπ**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂºïÊìéÊ†πÊçÆËÆøÂÆ¢Ë°å‰∏∫ÂÆûÊó∂Ë∞ÉÊï¥ÁΩëÁ´ôÂÜÖÂÆπÔºåÂêëÁî®Êà∑ÂëàÁé∞‰∏éÂÖ∂ÂÖ¥Ë∂£ÂåπÈÖçÁöÑ‰øÉÈîÄ„ÄÅÊñáÁ´†Êàñ‰∫ßÂìÅ„ÄÇ\n\n### ‰∏™ÊÄßÂåñËê•ÈîÄÂíåÊé®ËçêÂºïÊìéÁöÑÂ•ΩÂ§Ñ\n\n* **Â¢ûÂº∫ÂÆ¢Êà∑ÂèÇ‰∏éÂ∫¶**Ôºö‰∏™ÊÄßÂåñÊé®ËçêÈÄöËøáÊèê‰æõÁõ∏ÂÖ≥ÈÄâÈ°πÊù•Â¢ûÂä†Áî®Êà∑‰∫íÂä®ÔºåÂáèÂ∞ëÂÆ¢Êà∑ÊêúÁ¥¢ÊâÄËä±Ë¥πÁöÑÊó∂Èó¥„ÄÇ\n* **ÊèêÈ´òËΩ¨ÂåñÁéá**ÔºöÂΩìÁî®Êà∑ÁúãÂà∞‰∏é‰ªñ‰ª¨ÂÖ¥Ë∂£ÂØÜÂàáÁõ∏ÂÖ≥ÁöÑ‰∫ßÂìÅÊàñÂÜÖÂÆπÊó∂Ôºå‰ªñ‰ª¨Êõ¥ÊúâÂèØËÉΩËøõË°åË¥≠‰π∞Êàñ‰∏éÂÜÖÂÆπ‰∫íÂä®„ÄÇ\n* **ÊîπÂñÑÂÆ¢Êà∑Âø†ËØöÂ∫¶ÂíåÁïôÂ≠òÁéá**ÔºöÈÄöËøáËÆ©ÂÆ¢Êà∑ÊÑüÂà∞Ë¢´ÁêÜËß£ÔºåÂìÅÁâåÂüπÂÖª‰∫ÜÊõ¥Âº∫ÁöÑËÅîÁ≥ªÔºåÈºìÂä±ÈáçÂ§çËÆøÈóÆÂíåÂìÅÁâåÂø†ËØö„ÄÇ\n\n### ‰∏™ÊÄßÂåñËê•ÈîÄÂíåÊé®ËçêÂºïÊìéÁöÑÊúÄ‰Ω≥Â∑•ÂÖ∑\n\n* **Amazon Personalize**Ôºö‰∫öÈ©¨ÈÄäÁöÑÂ∑•ÂÖ∑Âà©Áî®Êú∫Âô®Â≠¶‰π†Êèê‰æõÂÆûÊó∂Êé®ËçêÂíå‰∏™ÊÄßÂåñÂÜÖÂÆπ„ÄÇ\n* **Salesforce Einstein**Ôºö‰∏ÄÂ•óÂº∫Â§ßÁöÑ AI È©±Âä®ÁöÑÂÆ¢Êà∑ÂÖ≥Á≥ªÁÆ°ÁêÜ (CRM) Â•ó‰ª∂ÔºåËÉΩÂ§üÂú®Â§ö‰∏™ÂÆ¢Êà∑Êé•Ëß¶ÁÇπÊèê‰æõ‰∏™ÊÄßÂåñÊé®Ëçê„ÄÇ\n* **Algolia Recommend**Ôºö‰∏Ä‰∏™Êé®ËçêÂºïÊìéÔºå‰ΩøÁîµÂ≠êÂïÜÂä°„ÄÅÂ™í‰ΩìÂíåÂÖ∂‰ªñÊï∞Â≠óÁéØÂ¢É‰∏≠ÁöÑ‰∏™ÊÄßÂåñ‰ΩìÈ™åÊàê‰∏∫ÂèØËÉΩ„ÄÇ\n\n### Áé∞ÂÆû‰∏ñÁïåÊé®ËçêÂºïÊìéÁöÑÂÆûÈôÖÊ°à‰æã\n\n* **Èõ∂ÂîÆ**ÔºöÂÉè‰∫öÈ©¨ÈÄäÂíåÊ≤ÉÂ∞îÁéõËøôÊ†∑ÁöÑÁîµÂ≠êÂïÜÂä°Âπ≥Âè∞Ê†πÊçÆÁî®Êà∑Ë°å‰∏∫Êé®ËçêÂïÜÂìÅÔºåÈÄöËøá‰∫§ÂèâÈîÄÂîÆÂíåËøΩÂä†ÈîÄÂîÆÊù•Â¢ûÂä†ËÆ¢Âçï‰ª∑ÂÄº„ÄÇ\n* **ÊµÅÂ™í‰ΩìÊúçÂä°**ÔºöNetflixÁöÑÊé®ËçêÂºïÊìéÂàÜÊûêËßÇÁúã‰π†ÊÉØ‰ª•Âª∫ËÆÆÂÜÖÂÆπÔºåÂàõÈÄ†Êó†Áºù‰∏îÂºï‰∫∫ÂÖ•ËÉúÁöÑËßÇÁúã‰ΩìÈ™å„ÄÇ\n* **ÊóÖÊ∏∏‰∏éÈÖíÂ∫ó**ÔºöÂÉèAirbnbÂíåExpediaËøôÊ†∑ÁöÑÂÖ¨Âè∏Ê†πÊçÆÁî®Êà∑ÂÅèÂ•ΩÊé®ËçêÊóÖË°åÁõÆÁöÑÂú∞„ÄÅ‰ΩèÂÆøÂíåÊ¥ªÂä®Ôºå‰ΩøÊóÖË°åËßÑÂàíÊõ¥Âä†Áõ∏ÂÖ≥ÂíåÈ´òÊïà„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qlu4M1HEcB3VNAm2o3FI6w.png)\n\n## 4\\. Êô∫ËÉΩËá™Âä®Âåñ‰∏éRPAÔºàÊú∫Âô®‰∫∫ÊµÅÁ®ãËá™Âä®ÂåñÔºâ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Bbnm4Snzk0vrhKOxLwZ_uQ.png)\n\nÊô∫ËÉΩËá™Âä®ÂåñÁî±RPAÔºàÊú∫Âô®‰∫∫ÊµÅÁ®ãËá™Âä®ÂåñÔºâÂíåÂÖàËøõÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÔºåÊ≠£Âú®ÈÄöËøáËá™Âä®ÂåñÈáçÂ§çÊÄß‰ªªÂä°„ÄÅÊèêÈ´òÁîü‰∫ßÂäõÂíåÂáèÂ∞ëÈîôËØØÊù•ÊîπÂèòÂïÜ‰∏öËøêËê•„ÄÇ‰∏é‰º†ÁªüËá™Âä®Âåñ‰∏ìÊ≥®‰∫éÁÆÄÂçïËßÑÂàôÂü∫Á°Ä‰ªªÂä°‰∏çÂêåÔºåÊô∫ËÉΩËá™Âä®ÂåñÁªìÂêà‰∫Ü‰∫∫Â∑•Êô∫ËÉΩ„ÄÅÊú∫Âô®Â≠¶‰π†ÂíåRPAÔºå‰ª•Â§ÑÁêÜÈúÄË¶ÅÈÄÇÂ∫îÊÄßÂíåÂÜ≥Á≠ñËÉΩÂäõÁöÑÂ§çÊùÇÂ∑•‰ΩúÊµÅ„ÄÇ‰ª•‰∏ãÊòØÊô∫ËÉΩËá™Âä®Âåñ‰∏éRPAÂ¶Ç‰ΩïÊîπÂèòÂïÜ‰∏öÊ†ºÂ±ÄÁöÑÊ¶ÇËø∞Ôºö\n\n### ‰ªÄ‰πàÊòØÊô∫ËÉΩËá™Âä®ÂåñÂíåRPAÔºü\n\n* **Êú∫Âô®‰∫∫ÊµÅÁ®ãËá™Âä®Âåñ (RPA)** ‰ΩøÁî®ËΩØ‰ª∂Êú∫Âô®‰∫∫Êàñ‚ÄúÊú∫Âô®‰∫∫‚ÄùÊù•Ëá™Âä®ÂåñÈ´òÂÆπÈáè„ÄÅÈáçÂ§çÊÄßÁöÑ‰ªªÂä°ÔºåÂ¶ÇÊï∞ÊçÆËæìÂÖ•„ÄÅË°®ÂçïÂ°´ÂÜôÂíåÊä•ÂëäÁîüÊàê„ÄÇRPA Âü∫‰∫éÈ¢ÑËÆæËßÑÂàôÊìç‰ΩúÔºå‰∏çÈúÄË¶ÅËÆ§Áü•ÂÜ≥Á≠ñ„ÄÇ\n* **Êô∫ËÉΩËá™Âä®Âåñ** Â∞Ü RPA ‰∏é‰∫∫Â∑•Êô∫ËÉΩËÉΩÂäõÔºàÂ¶ÇËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP) ÂíåÊú∫Âô®Â≠¶‰π†ÔºâÁªìÂêàÔºå‰ª•ÁÆ°ÁêÜÈúÄË¶ÅÊõ¥È´òÊ∞¥Âπ≥Êé®ÁêÜÂíåÈÄÇÂ∫îÊÄßÁöÑ‰ªªÂä°„ÄÇËøôÁßçËûçÂêà‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÂÅöÂá∫‰∏ä‰∏ãÊñáÂÜ≥Á≠ñÔºåÈÄÇÂ∫îÊñ∞Êï∞ÊçÆÔºåÂπ∂Â§ÑÁêÜÈùûÁªìÊûÑÂåñ‰ø°ÊÅØ„ÄÇ\n\n### Êô∫ËÉΩËá™Âä®ÂåñÂíåRPAÁöÑÂÖ≥ÈîÆÁî®‰æã\n\n* **ÂèëÁ•®Â§ÑÁêÜÂíåÂ∫î‰ªòË¥¶Ê¨æ**ÔºöRPAÂèØ‰ª•Êâ´ÊèèÂèëÁ•®ÔºåÊèêÂèñÊï∞ÊçÆÔºå‰∏éÈááË¥≠ËÆ¢ÂçïËøõË°å‰∫§ÂèâÊ£ÄÊü•ÔºåÂπ∂Â∞ÜÂÖ∂ËæìÂÖ•‰ºöËÆ°Á≥ªÁªüÔºå‰ªéËÄåÂáèÂ∞ë‰∫∫Â∑•Â∑•‰ΩúÈáèÂπ∂ÊèêÈ´òÂáÜÁ°ÆÊÄß„ÄÇ\n* **ÈáëËûçÊúçÂä°‰∏≠ÁöÑÂÆ¢Êà∑ÂÖ•ËÅå**ÔºöÊô∫ËÉΩËá™Âä®ÂåñÂ∏ÆÂä©Èì∂Ë°åÂíå‰øùÈô©ÂÖ¨Âè∏ÈÄöËøáËá™Âä®ÂåñÊñáÊ°£È™åËØÅ„ÄÅËÉåÊôØÊ£ÄÊü•ÂíåÊï∞ÊçÆËæìÂÖ•Êù•ÁÆÄÂåñÂÖ•ËÅåÊµÅÁ®ãÔºåÂ¢ûÂº∫ÂêàËßÑÊÄßÂπ∂ÂáèÂ∞ëÂÖ•ËÅåÊó∂Èó¥„ÄÇ\n* **ËÆ¢ÂçïÂ§ÑÁêÜÂíåÂ±•Ë°å**ÔºöRPAÂèØ‰ª•ÈÄöËøá‰ªéËÆ¢ÂçïË°®Âçï‰∏≠ÊèêÂèñÊï∞ÊçÆ„ÄÅÊ£ÄÊü•Â∫ìÂ≠òÂíåÂêØÂä®ÂèëË¥ßÊµÅÁ®ãÊù•Ëá™Âä®ÂåñËÆ¢ÂçïÂ§ÑÁêÜÔºåÂä†Âø´Â±•Ë°åÈÄüÂ∫¶Âπ∂ÊúÄÂ∞èÂåñÈîôËØØ„ÄÇ\n* **ÂëòÂ∑•ÂÖ•ËÅåÂíå‰∫∫ÂäõËµÑÊ∫êÁÆ°ÁêÜ**ÔºöÊú∫Âô®‰∫∫ÂèØ‰ª•ÁÆ°ÁêÜ‰æãË°åÁöÑ‰∫∫ÂäõËµÑÊ∫ê‰ªªÂä°ÔºåÂ¶ÇÂÖ•ËÅå„ÄÅÂÆâÊéíÈù¢ËØïÂíåÊõ¥Êñ∞ÂëòÂ∑•ËÆ∞ÂΩïÔºå‰Ωø‰∫∫ÂäõËµÑÊ∫êÂõ¢ÈòüËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊàòÁï•ÊÄßÂ∑•‰Ωú„ÄÇ\n\n### Êô∫ËÉΩËá™Âä®ÂåñÂíåRPAÁöÑÂ•ΩÂ§Ñ\n\n* **ÊàêÊú¨ËäÇÁ∫¶ÂíåÊïàÁéá**ÔºöËá™Âä®ÂåñÂáèÂ∞ë‰∫ÜÂØπ‰∫∫Â∑•Âπ≤È¢ÑÁöÑÈúÄÊ±ÇÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üËäÇÁúÅÂä≥Âä®ÂäõÊàêÊú¨Âπ∂Â∞ÜËµÑÊ∫êÈáçÊñ∞ÂàÜÈÖçÂà∞Êõ¥È´ò‰ª∑ÂÄºÁöÑ‰ªªÂä°‰∏ä„ÄÇ\n* **ÂáèÂ∞ëÈîôËØØÂíåÂ¢ûÂº∫ÂêàËßÑÊÄß**ÔºöÊú∫Âô®‰∫∫‰ª•È´òÁ≤æÂ∫¶ÊâßË°å‰ªªÂä°ÔºåÂáèÂ∞ë‰∫∫‰∏∫ÈîôËØØÔºåÁâπÂà´ÊòØÂú®ÈáëËûçÂíåÂåªÁñóÁ≠âÊï∞ÊçÆÂØÜÈõÜÂûãÈ¢ÜÂüü„ÄÇËá™Âä®ÂåñÂ∑•‰ΩúÊµÅÁ®ãËøòÈÄöËøáËÆ∞ÂΩïËøáÁ®ãÂπ∂Á°Æ‰øùÈÅµÂæ™Ê≥ïËßÑÊù•ÊîØÊåÅÂêàËßÑÊÄß„ÄÇ\n* **ÂèØÊâ©Â±ïÊÄß**ÔºöRPA‰Ωø‰ºÅ‰∏öËÉΩÂ§üÂú®È´òÂ≥∞ÊúüËΩªÊùæÊâ©Â±ïËøêËê•ÔºåÈÄöËøáÈÉ®ÁΩ≤Êõ¥Â§öÊú∫Âô®‰∫∫ËÄåÊó†ÈúÄÈõá‰Ω£È¢ùÂ§ñÂëòÂ∑•Ôºå‰ªéËÄåÊèê‰æõËµÑÊ∫êÁÆ°ÁêÜÁöÑÁÅµÊ¥ªÊÄß„ÄÇ\n\n### ÊµÅË°åÁöÑRPAÂíåÊô∫ËÉΩËá™Âä®ÂåñÂ∑•ÂÖ∑\n\n* **UiPath**Ôºö‰∏Ä‰∏™ÂπøÊ≥õ‰ΩøÁî®ÁöÑRPAÂπ≥Âè∞Ôºå‰ª•ÂÖ∂ÊòìÁî®ÊÄßÂíå‰∏éÊú∫Âô®Â≠¶‰π†Â∑•ÂÖ∑ÁöÑÂº∫Â§ßÈõÜÊàêËÄåÈóªÂêçÔºåÈÄÇÁî®‰∫éÊô∫ËÉΩËá™Âä®Âåñ„ÄÇ\n* **Automation Anywhere**ÔºöÊèê‰æõRPAÂíåËÆ§Áü•Ëá™Âä®ÂåñÂäüËÉΩÔºåÈÄÇÂêàÈúÄË¶ÅÂÜ≥Á≠ñÁöÑÂ§çÊùÇÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ\n* **Blue Prism**Ôºö‰∏ìÊ≥®‰∫éÂÆâÂÖ®ÁöÑRPAÈÉ®ÁΩ≤ÔºåÁêÜÊÉ≥ÈÄÇÁî®‰∫éÂØπÂÆâÂÖ®ÂíåÂêàËßÑÊÄßË¶ÅÊ±ÇÈ´òÁöÑË°å‰∏öÔºåÂ¶ÇÈì∂Ë°åÂíåÂåªÁñó‰øùÂÅ•„ÄÇ\n\n### Êô∫ËÉΩËá™Âä®ÂåñÂú®ÂÆûÈôÖ‰∏≠ÁöÑÂ∫îÁî®ÂÆû‰æã\n\n* **Áîµ‰ø°**ÔºöÂÉèAT\\&TËøôÊ†∑ÁöÑÂÖ¨Âè∏‰ΩøÁî®RPAÊù•Ëá™Âä®ÂåñÂÆ¢Êà∑ÊúçÂä°Êü•ËØ¢„ÄÅË¥¶ÂçïÂ§ÑÁêÜÂíåÁΩëÁªúÁõëÊéßÔºåÊèêÈ´òÊúçÂä°ÂìçÂ∫îÊó∂Èó¥ÂíåËøêËê•ÊïàÁéá„ÄÇ\n* **Èõ∂ÂîÆ**ÔºöÈõ∂ÂîÆÂïÜ‰ΩøÁî®RPAÊù•ÁÆÄÂåñ‰æõÂ∫îÈìæÊìç‰ΩúÔºå‰ªéËÆ¢ÂçïÂ±•Ë°åÂà∞Â∫ìÂ≠òÁÆ°ÁêÜÔºåÂ∏ÆÂä©Èôç‰ΩéËøêËê•ÊàêÊú¨Âπ∂ÊèêÈ´òÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ\n* **ÂåªÁñó**ÔºöÂåªÈô¢ÂíåÂåªÁñóÊúçÂä°Êèê‰æõËÄÖÂÆûÊñΩRPAÊù•Â§ÑÁêÜÊÇ£ËÄÖÊï∞ÊçÆÁÆ°ÁêÜ„ÄÅÈ¢ÑÁ∫¶ÂÆâÊéíÂíåÁ¥¢ËµîÂ§ÑÁêÜÔºåËÆ©ÂåªÁñó‰∫∫ÂëòËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊÇ£ËÄÖÊä§ÁêÜ„ÄÇ\n\n## 4\\. Ê¨∫ËØàÊ£ÄÊµã‰∏éÂÆâÂÖ®Â¢ûÂº∫\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cFol51alN3qozxSH0rU0Bw.png)\n\nAIÊ¨∫ËØàÊ£ÄÊµãÁ≥ªÁªü‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂàÜÊûêÂ§ßÈáèÊï∞ÊçÆÔºåËØÜÂà´ÂºÇÂ∏∏Ê®°ÂºèÔºåÂπ∂Ê†áËÆ∞ÂèØÁñëÊ¥ªÂä®„ÄÇÂÖ≥ÈîÆÊäÄÊúØÂåÖÊã¨Ôºö\n\n* **ÂºÇÂ∏∏Ê£ÄÊµã**ÔºöËØÜÂà´‰∏éÊ≠£Â∏∏Ë°å‰∏∫ÁöÑÂÅèÂ∑ÆÔºå‰æãÂ¶ÇÂºÇÂ∏∏‰∫§ÊòìÊàñË¥¶Êà∑Ê¥ªÂä®ÔºåËøôÂèØËÉΩË°®ÊòéÊ¨∫ËØàË°å‰∏∫„ÄÇ\n* **Ë°å‰∏∫ÂàÜÊûê**ÔºöÁ†îÁ©∂Áî®Êà∑Ë°å‰∏∫‰ª•Âª∫Á´ãÂü∫Á∫øÔºåÂπ∂Ê†πÊçÆÁî®Êà∑ÈÄöÂ∏∏Â¶Ç‰Ωï‰∏éÁ≥ªÁªü‰∫íÂä®Êù•Ê£ÄÊµãÂºÇÂ∏∏„ÄÇ\n* **È¢ÑÊµãÂª∫Ê®°**ÔºöÂ∞ÜÂéÜÂè≤Êï∞ÊçÆ‰∏éÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁªìÂêàÔºå‰ª•È¢ÑÊµãÊ¨∫ËØà‰∫ã‰ª∂ÁöÑÂèØËÉΩÊÄßÔºåÂπ∂Âú®Ê¨∫ËØàÂèëÁîü‰πãÂâçËß¶ÂèëË≠¶Êä•„ÄÇ\n\n### Ê¨∫ËØàÊ£ÄÊµãÂíåÂÆâÂÖ®Â¢ûÂº∫ÁöÑÂÖ≥ÈîÆÁî®‰æã\n\n* **ÈáëËûçÊúçÂä°**ÔºöÈì∂Ë°å‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÂÆûÊó∂ÁõëÊéß‰∫§ÊòìÔºåÊ†áËÆ∞ÊΩúÂú®ÁöÑÊ¨∫ËØàÊ¥ªÂä®ÔºåÂ¶ÇÂºÇÂ∏∏ÁöÑË¥¶Êà∑ËΩ¨Ë¥¶ÊàñÂèñÊ¨æÔºåÂπ∂Âú®ÂÆåÊàêÈ™åËØÅ‰πãÂâçÈòªÊ≠¢Ëøô‰∫õ‰∫§Êòì„ÄÇ\n* **‰øùÈô©Á¥¢ËµîÂ§ÑÁêÜ**Ôºö‰øùÈô©ÂÖ¨Âè∏Âà©Áî®‰∫∫Â∑•Êô∫ËÉΩÈÄöËøáÂàÜÊûêÁ¥¢ËµîÊ®°Âºè„ÄÅËØÜÂà´ÈáçÂ§çÁ¥¢ËµîÂíåÂèëÁé∞Êèê‰∫§Êñá‰ª∂‰∏≠ÁöÑ‰∏ç‰∏ÄËá¥Êù•Ê£ÄÊµãÊ¨∫ËØàÊÄßÁ¥¢Ëµî„ÄÇ\n* **ÁîµÂ≠êÂïÜÂä°ÂíåÈõ∂ÂîÆ**ÔºöÈõ∂ÂîÆÂïÜ‰ΩøÁî®Ê¨∫ËØàÊ£ÄÊµãÁÆóÊ≥ïÊù•ËØÜÂà´Ê¨∫ËØàÊÄßË¥≠‰π∞„ÄÅË¢´Áõó‰ø°Áî®Âç°‰∫§ÊòìÂíåË¥¶Êà∑Êé•ÁÆ°Ôºå‰ª•‰øùÊä§Ê∂àË¥πËÄÖÂíå‰ºÅ‰∏ö„ÄÇ\n* **Ë∫´‰ªΩÈ™åËØÅÂíåËÆøÈóÆÊéßÂà∂**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈÄöËøáÁîüÁâ©ËØÜÂà´ËÆ§ËØÅÔºàÂ¶ÇÈù¢ÈÉ®ËØÜÂà´ÂíåÊåáÁ∫πÂàÜÊûêÔºâÊù•Âä†Âº∫ÂÆâÂÖ®ÊÄßÔºåÈò≤Ê≠¢Êú™ÁªèÊéàÊùÉÁöÑËÆøÈóÆ„ÄÇ\n\n### AIÂú®Ê¨∫ËØàÊ£ÄÊµãÂíåÂÆâÂÖ®‰∏≠ÁöÑÂ•ΩÂ§Ñ\n\n* **ÂÆûÊó∂Â®ÅËÉÅÊ£ÄÊµã**ÔºöAIÂÖÅËÆ∏Âç≥Êó∂Â®ÅËÉÅÊ£ÄÊµãÂíåÂìçÂ∫îÔºåÈò≤Ê≠¢Ê¨∫ËØàÂú®ÂçáÁ∫ß‰πãÂâçÂèëÁîüÔºåÊúÄÂ∞èÂåñË¥¢Âä°ÊçüÂ§±„ÄÇ\n* **ÂáèÂ∞ëËØØÊä•**ÔºöÈÄöËøáÂ≠¶‰π†Áî®Êà∑Ê®°ÂºèÔºåAIÂèØ‰ª•ÂáèÂ∞ë‰º†ÁªüÊ¨∫ËØàÊ£ÄÊµãÁ≥ªÁªü‰∏≠Â∏∏‰º¥ÈöèÁöÑËØØÊä•Êï∞ÈáèÔºåÁ°Æ‰øùÁúüÊ≠£ÁöÑ‰∫§Êòì‰∏ç‰ºöË¢´‰∏çÂøÖË¶ÅÂú∞Ê†áËÆ∞„ÄÇ\n* **ÂØπÊñ∞Â®ÅËÉÅÁöÑÈÄÇÂ∫îÊÄßÊèêÈ´ò**ÔºöAIÁ≥ªÁªü‰∏çÊñ≠‰ªéÊñ∞Êï∞ÊçÆ‰∏≠Â≠¶‰π†Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÈÄÇÂ∫î‰∏çÊñ≠ÊºîÂèòÁöÑÊ¨∫ËØàÁ≠ñÁï•ÔºåËÄåÂü∫‰∫éËßÑÂàôÁöÑÁ≥ªÁªüÂèØËÉΩ‰ºöÂèòÂæóËøáÊó∂„ÄÇ\n\n### È°∂Á∫ßÂ∑•ÂÖ∑ÂíåÂπ≥Âè∞Áî®‰∫é‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÊ¨∫ËØàÊ£ÄÊµã\n\n* **Darktrace**Ôºö‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÊ£ÄÊµã„ÄÅË∞ÉÊü•ÂíåÂìçÂ∫îÁΩëÁªúÂ®ÅËÉÅÔºåÂà©Áî®Êú∫Âô®Â≠¶‰π†ÂÆûÊó∂ÁêÜËß£Âíå‰øùÊä§ÁªÑÁªáÁΩëÁªú„ÄÇ\n* **Splunk**Ôºö‰∏ÄÁßçÂÆâÂÖ®‰ø°ÊÅØÂíå‰∫ã‰ª∂ÁÆ°ÁêÜÔºàSIEMÔºâÂ∑•ÂÖ∑ÔºåÂ∞Ü‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂàÜÊûê‰∏éÂÆûÊó∂ÁõëÊéßÁõ∏ÁªìÂêàÔºå‰ª•Ê£ÄÊµãÂíåÂìçÂ∫îÂêÑÁßçÁ≥ªÁªü‰∏≠ÁöÑÂºÇÂ∏∏„ÄÇ\n* **Feedzai**Ôºö‰∏∫ÈáëËûçÊú∫ÊûÑËÆæËÆ°ÁöÑÂπ≥Âè∞ÔºåÂà©Áî®Êú∫Âô®Â≠¶‰π†ÁõëÊéß‰∫§ÊòìÔºåÈò≤Ê≠¢Ê¨∫ËØàÔºåÂπ∂Á°Æ‰øùÈÅµÂÆàÁõëÁÆ°Ë¶ÅÊ±Ç„ÄÇ\n\n### Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÊ¨∫ËØàÊ£ÄÊµãÂíåÂÆâÂÖ®Â¢ûÂº∫Á§∫‰æã\n\n* **Èì∂Ë°å**ÔºöËÆ∏Â§öÈì∂Ë°åÁé∞Âú®‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÁ≥ªÁªüÊù•Ê£ÄÊµã‰ø°Áî®Âç°Ê¨∫ËØà„ÄÅÂºÇÂ∏∏‰∫§ÊòìÂíåË¥¶Êà∑Êé•ÁÆ°ÔºåÊòæËëóÂáèÂ∞ëÂõ†Ê¨∫ËØàÊ¥ªÂä®ÈÄ†ÊàêÁöÑË¥¢Âä°ÊçüÂ§±„ÄÇ\n* **ÂåªÁñó‰øùÂÅ•**Ôºö‰∫∫Â∑•Êô∫ËÉΩË¢´Áî®‰∫éÊ£ÄÊµãÊ¨∫ËØàÊÄßÂåªÁñóË¥¶ÂçïÂíåË∫´‰ªΩÁõóÁ™ÉÔºåÈÄöËøáËØÜÂà´Á¥¢ËµîÂ§ÑÁêÜ‰∏≠ÁöÑÊª•Áî®Ê®°ÂºèÔºå‰∏∫ÂåªÁñóÊèê‰æõËÄÖÂíå‰øùÈô©ÂÖ¨Âè∏ËäÇÁúÅ‰∫ÜÊï∞Áôæ‰∏á„ÄÇ\n* **Âú®Á∫øÂπ≥Âè∞**ÔºöÁ§æ‰∫§Â™í‰ΩìÂíåÂú®Á∫øÂ∏ÇÂú∫‰ΩøÁî®‰∫∫Â∑•Êô∫ËÉΩÊ£ÄÊµãÂíåÈò≤Ê≠¢Ë¥¶Êà∑Êé•ÁÆ°„ÄÅÁΩëÁªúÈíìÈ±ºÂíåÂûÉÂúæÈÇÆ‰ª∂Ôºå‰øùÊä§Áî®Êà∑ÂÖçÂèóÂêÑÁßçÂÆâÂÖ®Â®ÅËÉÅ„ÄÇ\n\n## 5\\. ‰æõÂ∫îÈìæ‰ºòÂåñ‰∏é‰∫∫Â∑•Êô∫ËÉΩ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3pWU90X3MXQMyJ8G9rQ97g.png)\n\n‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑ‰æõÂ∫îÈìæ‰ºòÂåñÊ≠£Âú®ÈÄöËøáÊèêÈ´òÊïàÁéá„ÄÅÈôç‰ΩéÊàêÊú¨ÂíåÂ¢ûÂº∫‰æõÂ∫îÈìæÂêÑ‰∏™Èò∂ÊÆµÁöÑÈÄèÊòéÂ∫¶Êù•ÊîπÂèòÁâ©ÊµÅÂíå‰æõÂ∫îÈìæÁÆ°ÁêÜ„ÄÇ‰ªéÈúÄÊ±ÇÈ¢ÑÊµãÂà∞Â∫ìÂ≠òÁÆ°ÁêÜÔºå‰∫∫Â∑•Êô∫ËÉΩ‰Ωø‰ºÅ‰∏öËÉΩÂ§üÂÅöÂá∫Êï∞ÊçÆÈ©±Âä®ÁöÑÂÜ≥Á≠ñÔºåÂπ∂‰∏ªÂä®Â∫îÂØπÂπ≤Êâ∞„ÄÇ‰ª•‰∏ãÊòØ‰∫∫Â∑•Êô∫ËÉΩÂ¶Ç‰ΩïÈù©Êñ∞‰æõÂ∫îÈìæÁÆ°ÁêÜÂíå‰ºòÂåñËøêËê•ÁöÑÊ∑±ÂÖ•ÂàÜÊûêÔºö\n\n### AIÂ¶Ç‰Ωï‰ºòÂåñ‰æõÂ∫îÈìæ\n\nAIÂ∑•ÂÖ∑Âà©Áî®Êú∫Âô®Â≠¶‰π†„ÄÅÈ¢ÑÊµãÂàÜÊûêÂíåÂÆûÊó∂Êï∞ÊçÆÂàÜÊûêÊù•ÁÆÄÂåñ‰æõÂ∫îÈìæÁöÑÂêÑ‰∏™ÊñπÈù¢„ÄÇÈÄöËøáÂàÜÊûêÂéÜÂè≤Êï∞ÊçÆ„ÄÅË∑üË∏™ÂÆûÊó∂‰ø°ÊÅØÂíåÈ¢ÑÊµãÊú™Êù•Ë∂ãÂäøÔºåAIÁÆóÊ≥ïÂèØ‰ª•‰ºòÂåñÈááË¥≠„ÄÅÁîü‰∫ß„ÄÅÂàÜÈîÄÂíåÁâ©ÊµÅÊµÅÁ®ã„ÄÇ‰∏ªË¶ÅÊñπÊ≥ïÂåÖÊã¨Ôºö\n\n* **È¢ÑÊµãÂàÜÊûê**ÔºöÊ†πÊçÆÂéÜÂè≤Êï∞ÊçÆ„ÄÅÂ≠£ËäÇÊÄßË∂ãÂäøÂíåÂ∏ÇÂú∫Âõ†Á¥†È¢ÑÊµãÊú™Êù•ÈúÄÊ±Ç„ÄÇ\n* **ÈúÄÊ±ÇÈ¢ÑÊµãÁöÑÊú∫Âô®Â≠¶‰π†**ÔºöÂà©Áî®ËøáÂéªÈîÄÂîÆ„ÄÅÂÆ¢Êà∑Ë°å‰∏∫ÂíåÂ§ñÈÉ®Âõ†Á¥†ÁöÑÊï∞ÊçÆÁîüÊàêÂáÜÁ°ÆÁöÑÈúÄÊ±ÇÈ¢ÑÊµã„ÄÇ\n* **ÂÆûÊó∂ÁõëÊéßÂíåÁâ©ËÅîÁΩëÈõÜÊàê**ÔºöÈÄöËøáÁâ©ËÅîÁΩë‰º†ÊÑüÂô®ÂÆûÊó∂Ë∑üË∏™Ë¥ßÁâ©ÔºåÊèêÈ´òÂèØËßÜÊÄßÂπ∂Âø´ÈÄüÂìçÂ∫îÈóÆÈ¢ò„ÄÇ\n\n### AIÂú®‰æõÂ∫îÈìæ‰ºòÂåñ‰∏≠ÁöÑÂÖ≥ÈîÆÂ∫îÁî®Ê°à‰æã\n\n* **ÈúÄÊ±ÇÈ¢ÑÊµã‰∏éËßÑÂàí**ÔºöÂü∫‰∫éAIÁöÑÈúÄÊ±ÇÈ¢ÑÊµã‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞È¢ÑÊµãÂÆ¢Êà∑ÈúÄÊ±ÇÔºåÁ°Æ‰øùÊúÄ‰Ω≥Â∫ìÂ≠òÊ∞¥Âπ≥ÔºåÂáèÂ∞ëËøáÂâ©ÊàñÁº∫Ë¥ßÁöÑÊÉÖÂÜµ„ÄÇ\n* **Â∫ìÂ≠òÁÆ°ÁêÜ‰∏é‰ºòÂåñ**ÔºöAIÂ∏ÆÂä©ÂÖ¨Âè∏ÈÄöËøáÈ¢ÑÊµãÂ∫ìÂ≠òÈúÄÊ±Ç„ÄÅ‰ºòÂåñË°•Ë¥ßËÆ°ÂàíÂíåÊúÄÂ∞èÂåñËøáÂâ©Â∫ìÂ≠òÊù•Áª¥ÊåÅÈÄÇÂΩìÁöÑÂ∫ìÂ≠òÊ∞¥Âπ≥„ÄÇ\n* **Áâ©ÊµÅË∑ØÁ∫ø‰ºòÂåñ**ÔºöAIÁÆóÊ≥ïËÄÉËôë‰∫§ÈÄö„ÄÅÂ§©Ê∞îÂíåÁáÉÊñôÊàêÊú¨Ôºå‰ª•Á°ÆÂÆöÊúÄÊúâÊïàÁöÑË∑ØÁ∫øÔºå‰ªéËÄåËäÇÁúÅÊó∂Èó¥Âπ∂Èôç‰ΩéËøêËæìË¥πÁî®„ÄÇ\n* **‰æõÂ∫îÂïÜÈ£éÈô©ÁÆ°ÁêÜ**ÔºöAI‰Ωø‰ºÅ‰∏öËÉΩÂ§üËØÑ‰º∞‰æõÂ∫îÂïÜÁöÑÂèØÈù†ÊÄßÂíåÁª©ÊïàÔºåÈ¢ÑÊµã‰∏é‰æõÂ∫îÂïÜÂª∂ËøüÁõ∏ÂÖ≥ÁöÑÈ£éÈô©ÔºåÂπ∂ÈÄöËøá‰∏ªÂä®Á≠ñÁï•Êù•Èôç‰ΩéËøô‰∫õÈ£éÈô©„ÄÇ\n* **Ë¥®ÈáèÊéßÂà∂‰∏éÈ¢ÑÊµãÊÄßÁª¥Êä§**ÔºöAIÂíåÁâ©ËÅîÁΩë‰º†ÊÑüÂô®ÂèØ‰ª•ËØÜÂà´Âà∂ÈÄ†ËÆæÂ§á‰∏≠ÁöÑÊ®°ÂºèÔºåÈ¢ÑÊµãÁª¥Êä§ÈúÄÊ±ÇÂπ∂ÂáèÂ∞ëÂÅúÊú∫Êó∂Èó¥Ôºå‰ªéËÄåÊèêÈ´ò‰∫ßÂìÅË¥®ÈáèÂπ∂ÂáèÂ∞ëÊµ™Ë¥π„ÄÇ\n\n### AIÈ©±Âä®ÁöÑ‰æõÂ∫îÈìæ‰ºòÂåñÁöÑÂ•ΩÂ§Ñ\n\n* **ÊàêÊú¨Èôç‰Ωé**ÔºöÈÄöËøáÊèêÈ´òË∑ØÁ∫øÊïàÁéá„ÄÅÂ∫ìÂ≠òÂáÜÁ°ÆÊÄßÂíåÈúÄÊ±ÇÈ¢ÑÊµãÔºåAIÂú®Êï¥‰∏™‰æõÂ∫îÈìæ‰∏≠ÊúÄÂ∞èÂåñËøêËê•ÊàêÊú¨„ÄÇ\n* **Â¢ûÂº∫ÂÜ≥Á≠ñËÉΩÂäõ**ÔºöAIÊèê‰æõÂÆûÊó∂Ê¥ûÂØüÂíåÈ¢ÑÊµãÔºå‰ΩøÂÜ≥Á≠ñËÄÖËÉΩÂ§üËøÖÈÄüÂ∫îÂØπÈúÄÊ±Ç„ÄÅ‰æõÂ∫îÂïÜË°®Áé∞ÊàñÁâ©ÊµÅÊåëÊàòÁöÑÂèòÂåñ„ÄÇ\n* **Êõ¥Â§ßÁöÑÈüßÊÄßÂíåÁÅµÊ¥ªÊÄß**ÔºöAIÈ©±Âä®ÁöÑÁ≥ªÁªüËÉΩÂ§üÈÄÇÂ∫îÊÑèÂ§ñÂπ≤Êâ∞Ôºå‰æãÂ¶Ç‰æõÂ∫îÂïÜÈóÆÈ¢òÊàñÈúÄÊ±ÇÊøÄÂ¢ûÔºåÂç≥‰ΩøÂú®‰∏çÁ°ÆÂÆöÊó∂Êúü‰πüËÉΩ‰øùÊåÅÊúçÂä°Ê∞¥Âπ≥„ÄÇ\n* **ÂèØÊåÅÁª≠ÊÄß**ÔºöÈÄöËøáÂáèÂ∞ëÊµ™Ë¥π„ÄÅ‰ºòÂåñË∑ØÁ∫øÂíåÈò≤Ê≠¢ËøáÂ∫¶Áîü‰∫ßÔºåAIÊúâÂä©‰∫éÂèØÊåÅÁª≠ÂèëÂ±ïÁõÆÊ†áÔºåÂáèÂ∞ë‰ºÅ‰∏öÂØπÁéØÂ¢ÉÁöÑÂΩ±Âìç„ÄÇ\n\n### AIÈ©±Âä®ÁöÑ‰æõÂ∫îÈìæ‰ºòÂåñÁöÑÈ°∂Á∫ßÂ∑•ÂÖ∑ÂíåÂπ≥Âè∞\n\n* **SAPÈõÜÊàê‰∏öÂä°ËßÑÂàí (IBP)**ÔºöÂ∞ÜÊú∫Âô®Â≠¶‰π†‰∏é‰æõÂ∫îÈìæËßÑÂàíÂ∑•ÂÖ∑Áõ∏ÁªìÂêàÔºåÂÆûÁé∞ÂÆûÊó∂ÈúÄÊ±ÇÈ¢ÑÊµãÂíåÂ∫ìÂ≠ò‰ºòÂåñ„ÄÇ\n* **Llamasoft (Áî±CoupaÊèê‰æõ)**ÔºöÂà©Áî®ÂÖàËøõÁöÑÂàÜÊûêËøõË°åÁΩëÁªúËÆæËÆ°„ÄÅÂ∫ìÂ≠ò‰ºòÂåñÂíåÈúÄÊ±ÇÈ¢ÑÊµãÔºå‰∏ìÊ≥®‰∫éÊàòÁï•ÂíåËøêËê•‰æõÂ∫îÈìæËßÑÂàí„ÄÇ\n* **ClearMetal (Áî±Project44Êèê‰æõ)**ÔºöÊèê‰æõÂÆûÊó∂‰æõÂ∫îÈìæÂèØËßÜÂåñÂíåÈ¢ÑÊµãÂàÜÊûêÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üË∑üË∏™Ë¥ßÁâ©„ÄÅÂàÜÊûêË∂ãÂäøÂπ∂‰ºòÂåñÁâ©ÊµÅË∑ØÁ∫ø„ÄÇ\n\n## 6\\. Âü∫‰∫éAIÁöÑ‰∫ßÂìÅÂºÄÂèë‰∏éËÆæËÆ°\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*rcCCXcQq85tiFEe2M1gvzA.png)\n\nÂü∫‰∫éAIÁöÑ‰∫ßÂìÅÂºÄÂèë‰∏éËÆæËÆ°Ê≠£Âú®ÊîπÂèòÂÖ¨Âè∏ÊûÑÊÄù„ÄÅÂàõÂª∫ÂíåÊé®ÂêëÂ∏ÇÂú∫‰∫ßÂìÅÁöÑÊñπÂºè„ÄÇÈÄöËøáÂà©Áî®Êú∫Âô®Â≠¶‰π†„ÄÅÁîüÊàêËÆæËÆ°ÂíåÈ¢ÑÊµãÂàÜÊûêÔºåAI‰ΩøÂõ¢ÈòüËÉΩÂ§üÊõ¥Âø´Âú∞ËøõË°åÂàõÊñ∞ÔºåÊèêÈ´ò‰∫ßÂìÅË¥®ÈáèÔºåÂπ∂ÊúâÊïàÂ∫îÂØπ‰∏çÊñ≠ÂèòÂåñÁöÑÂÆ¢Êà∑ÈúÄÊ±Ç„ÄÇ‰ª•‰∏ãÊòØAIÂ¶Ç‰ΩïÂΩªÂ∫ïÊîπÂèò‰∫ßÂìÅÂºÄÂèë‰∏éËÆæËÆ°ÁöÑÂÖ®Èù¢ÂàÜÊûêÔºö\n\n### AIÂú®‰∫ßÂìÅÂºÄÂèëÂíåËÆæËÆ°‰∏≠ÁöÑÂ∫îÁî®\n\nAI‰ºòÂåñ‰∫ßÂìÅÁîüÂëΩÂë®ÊúüÁöÑÊØè‰∏™Èò∂ÊÆµÔºå‰ªéÊûÑÊÄùÂà∞ËÆæËÆ°„ÄÅÂéüÂûãÂà∂‰ΩúÂíåÊµãËØï„ÄÇÂà©Áî®ÂÖàËøõÁöÑÁÆóÊ≥ïÂíåÊï∞ÊçÆÂàÜÊûêÔºåAIÈ©±Âä®ÁöÑÁ≥ªÁªüÂèØ‰ª•ÁîüÊàê‰∫ßÂìÅÊ¶ÇÂøµÔºåËØÜÂà´ËÆæËÆ°Áº∫Èô∑ÔºåÁîöËá≥ÊèêÂá∫ÊîπËøõÂª∫ËÆÆ„ÄÇÂÖ≥ÈîÆÁöÑAIÊñπÊ≥ïÂåÖÊã¨Ôºö\n\n* **ÁîüÊàêËÆæËÆ°**ÔºöAIÊ†πÊçÆÈ¢ÑÂÆö‰πâÁöÑÂèÇÊï∞ÁîüÊàêËÆæËÆ°ÈÄâÈ°πÔºå‰æãÂ¶ÇÊùêÊñôÁ±ªÂûã„ÄÅÈáçÈáèÂíåËÄêÁî®ÊÄßÔºå‰ΩøËÆæËÆ°Â∏àËÉΩÂ§üÊé¢Á¥¢Êõ¥ÂπøÊ≥õÁöÑÂèØËÉΩÊÄß„ÄÇ\n* **ÂÆ¢Êà∑Ê¥ûÂØüÁöÑÈ¢ÑÊµãÂàÜÊûê**ÔºöÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂàÜÊûêÂÆ¢Êà∑Êï∞ÊçÆÂíåÂ∏ÇÂú∫Ë∂ãÂäøÔºå‰ª•È¢ÑÊµãÂì™‰∫õÂäüËÉΩÊàñËÆæËÆ°‰ºö‰∏éÁî®Êà∑‰∫ßÁîüÂÖ±È∏£Ôºå‰ªéËÄåÂ¢ûÂº∫‰∫ßÂìÅÂ∏ÇÂú∫Â•ëÂêàÂ∫¶„ÄÇ\n* **Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ**ÔºöNLP‰ΩøÂõ¢ÈòüËÉΩÂ§üÂàÜÊûêÂÆ¢Êà∑ÂèçÈ¶à„ÄÅËØÑËÆ∫ÂíåÁ§æ‰∫§Â™í‰ΩìÔºå‰ª•Ëé∑ÂèñÂèØ‰ª•ÊåáÂØº‰∫ßÂìÅÊîπËøõÂíåÊñ∞ÂäüËÉΩÂàõÊÑèÁöÑÊ¥ûÂØü„ÄÇ\n\n### AIÂú®‰∫ßÂìÅÂºÄÂèëÂíåËÆæËÆ°‰∏≠ÁöÑÂÖ≥ÈîÆÂ∫îÁî®Ê°à‰æã\n\n* **Ê¶ÇÂøµÁîüÊàêÂíåËÆæËÆ°Êé¢Á¥¢**ÔºöAIÈÄöËøáÊ†πÊçÆÁâπÂÆöÁ∫¶ÊùüÁîüÊàêÂ§ö‰∏™ËÆæËÆ°Êõø‰ª£ÊñπÊ°àÊù•ÂçèÂä©ËÆæËÆ°Â∏à„ÄÇ‰æãÂ¶ÇÔºåÂú®Ê±ΩËΩ¶Ë°å‰∏öÔºåAIÂèØ‰ª•ÁîüÊàêÊîπÂñÑÁáÉÊ≤πÊïàÁéáÁöÑÁ©∫Ê∞îÂä®ÂäõÂ≠¶ËÆæËÆ°„ÄÇ\n* **ÂéüÂûãÂà∂‰ΩúÂíåÂø´ÈÄüËø≠‰ª£**ÔºöAIÈ©±Âä®ÁöÑÂ∑•ÂÖ∑ËÉΩÂ§üÂø´ÈÄüËøõË°åËôöÊãüÂéüÂûãÂà∂‰ΩúÔºåÂáèÂ∞ëÂØπÁâ©ÁêÜÊ®°ÂûãÁöÑÈúÄÊ±ÇÔºåÂπ∂ÂÖÅËÆ∏Âø´ÈÄüÊµãËØïËÆæËÆ°Âèò‰Ωì„ÄÇ\n* **Ë¥®Èáè‰øùËØÅÂíåÊµãËØï**ÔºöAIÁÆóÊ≥ïÂàÜÊûê‰∫ßÂìÅÊï∞ÊçÆÔºå‰ª•Êó©ÊúüÊ£ÄÊµãÁº∫Èô∑ÔºåÈ¢ÑÊµãÊΩúÂú®ÊïÖÈöúÔºåÂπ∂Âª∫ËÆÆ‰øÆÊîπÔºå‰ªéËÄåÊèêÈ´òË¥®ÈáèÂπ∂Èôç‰Ωé‰∏éÂè¨ÂõûÁõ∏ÂÖ≥ÁöÑÊàêÊú¨„ÄÇ\n* **‰ª•ÂÆ¢Êà∑‰∏∫‰∏≠ÂøÉÁöÑ‰∫ßÂìÅÂÆöÂà∂**ÔºöAIÈ©±Âä®ÁöÑÂπ≥Âè∞ÂÖÅËÆ∏ÂÖ¨Âè∏ÈÄöËøáÂàÜÊûêÂÅèÂ•ΩÂπ∂ÁîüÊàê‰∏™ÊÄßÂåñÂäüËÉΩÊàñÊé®ËçêÔºåÂàõÂª∫ÈáèË∫´ÂÆöÂà∂ÁöÑ‰∫ßÂìÅ„ÄÇ\n* **ÊàêÊú¨‰ºòÂåñ**ÔºöAIËØÜÂà´ÊùêÊñô„ÄÅÂà∂ÈÄ†ËøáÁ®ãÂíå‰æõÂ∫îÈìæ‰∏≠ÁöÑËäÇÁúÅÊàêÊú¨Êú∫‰ºöÔºåËÄå‰∏çÂΩ±Âìç‰∫ßÂìÅË¥®ÈáèÔºå‰ªéËÄåÊèêÈ´òÁõàÂà©ËÉΩÂäõ„ÄÇ\n\n### AIÈ©±Âä®ÁöÑ‰∫ßÂìÅÂºÄÂèëÂíåËÆæËÆ°ÁöÑÂ•ΩÂ§Ñ\n\n* **Âä†ÈÄü‰∏äÂ∏ÇÊó∂Èó¥**ÔºöAIÂáèÂ∞ë‰∫Ü‰∫ßÂìÅËÆæËÆ°„ÄÅÂéüÂûãÂà∂‰ΩúÂíåÊµãËØïÊâÄÈúÄÁöÑÊó∂Èó¥Ôºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÊõ¥Âø´Âú∞Â∞Ü‰∫ßÂìÅÊé®ÂêëÂ∏ÇÂú∫ÔºåÂπ∂Êäì‰ΩèÊñ∞ÂÖ¥Ë∂ãÂäø„ÄÇ\n* **Â¢ûÂº∫ÂàõÊñ∞ÂíåÂàõÈÄ†Âäõ**ÔºöÁîüÊàêËÆæËÆ°ÂíåÊï∞ÊçÆÈ©±Âä®ÁöÑÊ¥ûÂØüÂäõÊøÄÂèëÊñ∞ÊÉ≥Ê≥ïÔºå‰ΩøËÆæËÆ°Â∏àËÉΩÂ§üÂàõÈÄ†Âá∫Êõ¥ÂÖ∑ÂàõÊñ∞ÊÄßÂíå‰ª•Áî®Êà∑‰∏∫‰∏≠ÂøÉÁöÑ‰∫ßÂìÅ„ÄÇ\n* **ÊèêÈ´ò‰∫ßÂìÅË¥®Èáè**ÔºöAIÊó©ÊúüËØÜÂà´ÊΩúÂú®ÁöÑËÆæËÆ°Áº∫Èô∑ÔºåÊèêÈ´ò‰∫ßÂìÅË¥®ÈáèÂíåÂèØÈù†ÊÄßÔºå‰ªéËÄåÂ∏¶Êù•Êõ¥È´òÁöÑÂÆ¢Êà∑Êª°ÊÑèÂ∫¶„ÄÇ\n* **Èôç‰ΩéÂºÄÂèëÊàêÊú¨**ÔºöÈÄöËøáÂáèÂ∞ëÂØπÁâ©ÁêÜÂéüÂûãÁöÑÈúÄÊ±ÇÂíåÁÆÄÂåñËÆæËÆ°ËøáÁ®ãÔºåAIÊúâÂä©‰∫éÈôç‰ΩéÊï¥‰ΩìÂºÄÂèëÊàêÊú¨ÂíåËµÑÊ∫ê„ÄÇ\n\n### AIÈ©±Âä®ÁöÑ‰∫ßÂìÅÂºÄÂèëÂíåËÆæËÆ°ÁöÑÈ°∂Â∞ñÂ∑•ÂÖ∑\n\n* **AutodeskÁöÑFusion 360‰∏éÁîüÊàêËÆæËÆ°**ÔºöÊèê‰æõÁîüÊàêËÆæËÆ°Â∑•ÂÖ∑ÔºåÁî®‰∫éÂàõÂª∫‰ºòÂåñÁªìÊûÑÂíåËΩªÈáèÂåñËÆæËÆ°ÔºåÂ∏∏Áî®‰∫éÊ±ΩËΩ¶„ÄÅËà™Á©∫Ëà™Â§©ÂíåÂ∑•‰∏öËÆæËÆ°„ÄÇ\n* **SolidWorks‰∏éAIÊèí‰ª∂**ÔºöÈõÜÊàê‰∫ÜAIÈ©±Âä®ÁöÑÊ®°ÂùóÔºåÁî®‰∫éÂø´ÈÄüÂéüÂûãÂà∂‰Ωú„ÄÅÊùêÊñô‰ºòÂåñÂíåËÆæËÆ°È™åËØÅ„ÄÇ\n* **Canva AIËÆæËÆ°Â∑•ÂÖ∑**ÔºöÂà©Áî®AIÁîüÊàêÂ∏ÉÂ±ÄÂª∫ËÆÆÔºå‰ºòÂåñËâ≤ÂΩ©Êê≠ÈÖçÔºåÂπ∂Âª∫ËÆÆËÆæËÆ°Ê®°ÊùøÔºåÈùûÂ∏∏ÈÄÇÂêàÊï∞Â≠óÂÜÖÂÆπÂíåÂìÅÁâåËÆæËÆ°„ÄÇ\n\n### Áé∞ÂÆû‰∏ñÁïå‰∏≠ AI Âú®‰∫ßÂìÅÂºÄÂèë‰∏≠ÁöÑÂ∫îÁî®ÂÆû‰æã\n\n* **Ê±ΩËΩ¶ÂíåËà™Á©∫Ëà™Â§©**ÔºöÂÉèÁ©∫ÂÆ¢ËøôÊ†∑ÁöÑÂÖ¨Âè∏‰ΩøÁî® AI È©±Âä®ÁöÑÁîüÊàêËÆæËÆ°Êù•ÂàõÂª∫ËΩªÈáèÂåñ„ÄÅÁ©∫Ê∞îÂä®ÂäõÂ≠¶ÁöÑÁªÑ‰ª∂Ôºå‰ªéËÄåÂáèÂ∞ëÁáÉÊñôÊ∂àËÄóÂπ∂ÊîπÂñÑÂèØÊåÅÁª≠ÊÄß„ÄÇ\n* **Ê∂àË¥πÁîµÂ≠ê**ÔºöÁßëÊäÄÂ∑®Â§¥Âà©Áî® AI ËØÜÂà´ÂäüËÉΩÂÅèÂ•ΩÔºå‰ΩøÂæóÂü∫‰∫éÁî®Êà∑Êï∞ÊçÆÂàõÂª∫ÂÆöÂà∂ÂäüËÉΩÊàê‰∏∫ÂèØËÉΩÔºå‰æãÂ¶ÇÁúÅÁîµÊ®°ÂºèÊàñ‰∏™ÊÄßÂåñËÆæÁΩÆ„ÄÇ\n* **Êó∂Â∞öÂíåÊúçË£Ö**ÔºöÂìÅÁâå‰ΩøÁî® AI Ê†πÊçÆË∫´‰ΩìÊµãÈáèËÆæËÆ°ÂÆöÂà∂ÂêàË∫´ÁöÑÊúçË£ÖÔºåÂπ∂ÂàÜÊûêÈ¢úËâ≤ÂíåÈ£éÊ†ºË∂ãÂäø‰ª•È¢ÑÊµãÊú™Êù•ÈúÄÊ±ÇÔºåÂ∏ÆÂä©ÂìÅÁâåÂáèÂ∞ëÊú™ÂîÆÂá∫Â∫ìÂ≠ò„ÄÇ\n\n## 7\\. Âä≥Âä®ÂäõÂíå‰∫∫ÊâçÁÆ°ÁêÜ‰∏é‰∫∫Â∑•Êô∫ËÉΩ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*-zSlQl-pe5KJ2DuACUEeeA.png)\n\n‰∫∫Â∑•Êô∫ËÉΩÊï¥Âêà‰∫ÜÊú∫Âô®Â≠¶‰π†„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÊï∞ÊçÆÂàÜÊûêÔºå‰ª•ÊîπÂñÑÂä≥Âä®ÂäõÁÆ°ÁêÜÁöÑÂêÑ‰∏™ÊñπÈù¢ÔºåÂåÖÊã¨ÊãõËÅò„ÄÅÁª©ÊïàÁÆ°ÁêÜ„ÄÅÂüπËÆ≠ÂíåÂëòÂ∑•ÂèÇ‰∏é„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®ÁöÑÂÖ≥ÈîÆÈ¢ÜÂüüÂåÖÊã¨Ôºö\n\n* **ÊãõËÅòÂíå‰∫∫ÊâçËé∑Âèñ**Ôºö‰∫∫Â∑•Êô∫ËÉΩËá™Âä®ÂåñÁ≠õÈÄâËøáÁ®ãÔºåÂàÜÊûêÁÆÄÂéÜÂíåÁî≥ËØ∑Ôºå‰ª•Ê†πÊçÆÂÄôÈÄâ‰∫∫ÁöÑÊäÄËÉΩ„ÄÅÁªèÈ™åÂíåÊΩúÂäõÂåπÈÖçÊúÄ‰Ω≥ËÅå‰Ωç„ÄÇ\n* **ÂëòÂ∑•ÂüπËÆ≠ÂíåÂèëÂ±ï**Ôºö‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÊèê‰æõ‰∏™ÊÄßÂåñÂ≠¶‰π†‰ΩìÈ™åÔºåÊ†πÊçÆÂëòÂ∑•ÁöÑÁª©Êïà„ÄÅËÅå‰∏öÁõÆÊ†áÂíåÂÖ¥Ë∂£Êé®ËçêËØæÁ®ãÂíåÂüπËÆ≠È°πÁõÆ„ÄÇ\n* **Áª©ÊïàÁõëÊµãÂíåÂèçÈ¶à**Ôºö‰∫∫Â∑•Êô∫ËÉΩÊèê‰æõÂÆûÊó∂ÁöÑÂëòÂ∑•Áª©ÊïàÂíåÂèÇ‰∏éÂ∫¶Ê¥ûÂØüÔºåÊèê‰æõÊåÅÁª≠ÂèçÈ¶à‰ª•Â∏ÆÂä©ÊèêÈ´òÁîü‰∫ßÂäõÂπ∂ËØÜÂà´ÊàêÈïøÈ¢ÜÂüü„ÄÇ\n* **Âä≥Âä®ÂäõËßÑÂàíÂíåÂàÜÊûê**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂàÜÊûêÂä≥Âä®ÂäõË∂ãÂäø„ÄÅÁª©ÊïàÊï∞ÊçÆÂíåÂ∏ÇÂú∫Êù°‰ª∂Ôºå‰ª•Â∏ÆÂä©ÁªÑÁªáËßÑÂàíÂíå‰ºòÂåñÂÖ∂‰∫∫ÂäõÈúÄÊ±Ç„ÄÇ\n\n### AIÂú®Âä≥Âä®ÂäõÂíå‰∫∫ÊâçÁÆ°ÁêÜ‰∏≠ÁöÑÂÖ≥ÈîÆÂ∫îÁî®Ê°à‰æã\n\n* **AIÈ©±Âä®ÁöÑÊãõËÅò**: AIÁÆóÊ≥ïËá™Âä®Ëß£ÊûêÁÆÄÂéÜ„ÄÅËøõË°åÂÄôÈÄâ‰∫∫ÊéíÂêçÂíåÂàùÊ≠•Èù¢ËØïËØÑ‰º∞ÔºåÁ°Æ‰øùÊõ¥Âø´„ÄÅÊó†ÂÅèËßÅÁöÑÊãõËÅòÊµÅÁ®ãÂíåÊõ¥Â•ΩÁöÑÂÄôÈÄâ‰∫∫‰ΩìÈ™å„ÄÇ\n* **ÂëòÂ∑•Âí®ËØ¢ËÅäÂ§©Êú∫Âô®‰∫∫**: AIËÅäÂ§©Êú∫Âô®‰∫∫ÂçèÂä©ÂëòÂ∑•Â§ÑÁêÜ‰∏é‰∫∫ÂäõËµÑÊ∫êÁõ∏ÂÖ≥ÁöÑÈóÆÈ¢òÔºåÂ¶ÇÁ¶èÂà©„ÄÅËñ™ËµÑÂíåÂÖ¨Âè∏ÊîøÁ≠ñÔºåÊèêÈ´ò‰∫∫ÂäõËµÑÊ∫êÊúçÂä°ÊïàÁéáÔºåÂπ∂‰Ωø‰∫∫ÂäõËµÑÊ∫êÂëòÂ∑•ËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°„ÄÇ\n* **‰∏™ÊÄßÂåñÂëòÂ∑•ÂèëÂ±ï**: AIÈ©±Âä®ÁöÑÂ≠¶‰π†ÁÆ°ÁêÜÁ≥ªÁªüÔºàLMSÔºâÂàÜÊûêÂëòÂ∑•ÁöÑË°®Áé∞ÂíåÂ≠¶‰π†ÂÅèÂ•ΩÔºåÊé®ËçêÈáèË∫´ÂÆöÂà∂ÁöÑÂèëÂ±ïË∑ØÂæÑ„ÄÅËØæÁ®ãÂíåËÆ§ËØÅÔºå‰ª•ÊèêÂçáÊäÄËÉΩ„ÄÇ\n* **ÂëòÂ∑•ÂèÇ‰∏éÂ∫¶ÊÉÖÊÑüÂàÜÊûê**: AIÂàÜÊûêÂëòÂ∑•ÂèçÈ¶à„ÄÅË∞ÉÊü•ÂíåÊ≤üÈÄöÊ®°ÂºèÔºå‰ª•ËØÑ‰º∞Â£´Ê∞î„ÄÅËØÜÂà´ÊΩúÂú®ÈóÆÈ¢òÔºåÂπ∂Êèê‰æõÊîπÂñÑÂ∑•‰ΩúÂú∫ÊâÄÊñáÂåñÂíåÂèÇ‰∏éÂ∫¶ÁöÑËßÅËß£„ÄÇ\n* **Âä≥Âä®Âäõ‰ºòÂåñ**: AIÂ∑•ÂÖ∑ÂàÜÊûêÂä≥Âä®ÂäõÊï∞ÊçÆÔºåÂ∏ÆÂä©‰∫∫ÂäõËµÑÊ∫êÁªèÁêÜ‰ºòÂåñÊéíÁè≠„ÄÅÁè≠Ê¨°Ê®°ÂºèÂíåËµÑÊ∫êÈÖçÁΩÆÔºåÊèêÈ´òÁîü‰∫ßÂäõÂíåÂëòÂ∑•Êª°ÊÑèÂ∫¶ÔºåÂêåÊó∂Èôç‰ΩéÊàêÊú¨„ÄÇ\n\n### AIÂú®Âä≥Âä®ÂäõÂíå‰∫∫ÊâçÁÆ°ÁêÜ‰∏≠ÁöÑÂ•ΩÂ§Ñ\n\n* **ÊèêÈ´òÊïàÁéá**ÔºöAIËá™Âä®ÂåñÂ∏∏ËßÑÁöÑ‰∫∫ÂäõËµÑÊ∫ê‰ªªÂä°ÔºåÂ¶ÇÁ≠õÈÄâÁÆÄÂéÜ„ÄÅÂÆâÊéíÈù¢ËØïÂíåÂõûÁ≠îÂëòÂ∑•Êü•ËØ¢Ôºå‰Ωø‰∫∫ÂäõËµÑÊ∫ê‰∏ì‰∏ö‰∫∫ÂëòËÉΩÂ§üËäÇÁúÅÊó∂Èó¥Ôºå‰∏ìÊ≥®‰∫éÊàòÁï•ÂÜ≥Á≠ñ„ÄÇ\n* **Â¢ûÂº∫ÂÜ≥Á≠ñËÉΩÂäõ**ÔºöAIÈ©±Âä®ÁöÑÂàÜÊûê‰∏∫‰∫∫ÂäõËµÑÊ∫êÁªèÁêÜÊèê‰æõÂèØÊìç‰ΩúÁöÑÊ¥ûÂØüÔºåÂ∏ÆÂä©‰ªñ‰ª¨Âú®ÊãõËÅò„ÄÅÊôãÂçáÂíåËµÑÊ∫êÂàÜÈÖçÊñπÈù¢ÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇ\n* **ÊîπÂñÑ‰∫∫ÊâçÊãõËÅò**ÔºöAIÈÄöËøáÊ∂àÈô§ÊãõËÅò‰∏≠ÁöÑÂÅèËßÅÔºåÂ∏ÆÂä©Êõ¥Âø´Âú∞ËØÜÂà´ÊúÄ‰Ω≥ÂÄôÈÄâ‰∫∫ÔºåÊèêÈ´òÂ§öÊ†∑ÊÄßÔºåÂπ∂Á°Æ‰øùÂÄôÈÄâ‰∫∫‰∏éËßíËâ≤‰πãÈó¥ÁöÑÊõ¥Â•ΩÂåπÈÖç„ÄÇ\n* **‰∏™ÊÄßÂåñÂëòÂ∑•‰ΩìÈ™å**ÔºöAIÈ©±Âä®ÁöÑÂ∑•ÂÖ∑Êèê‰æõ‰∏™ÊÄßÂåñÁöÑËÅå‰∏öÂèëÂ±ïÂíåÂüπËÆ≠È°πÁõÆÔºåÈÄöËøáÂ∞Ü‰∏™‰∫∫ÁõÆÊ†á‰∏éÁªÑÁªáÁõÆÊ†áÂØπÈΩêÔºåÊèêÈ´òÂëòÂ∑•Êª°ÊÑèÂ∫¶ÂíåÁïô‰ªªÁéá„ÄÇ\n* **‰∏ªÂä®Áïô‰ªªÁ≠ñÁï•**ÔºöÈÄöËøáÂàÜÊûêÂëòÂ∑•ÊÉÖÁª™ÂíåÁª©ÊïàÊï∞ÊçÆÔºåAIÂèØ‰ª•È¢ÑÊµãÊΩúÂú®ÁöÑÁ¶ªËÅåÊÉÖÂÜµÔºå‰Ωø‰∫∫ÂäõËµÑÊ∫êËÉΩÂ§üÂèäÊó©‰ªãÂÖ•ÂÆûÊñΩÁïô‰ªªÁ≠ñÁï•„ÄÇ\n\n### ‰∫∫Â∑•Êô∫ËÉΩÂú®Âä≥Âä®ÂäõÂíå‰∫∫ÊâçÁÆ°ÁêÜ‰∏≠ÁöÑÈ°∂Á∫ßÂ∑•ÂÖ∑\n\n* **HireVue**Ôºö‰∏Ä‰∏™Âü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑËßÜÈ¢ëÈù¢ËØïÂπ≥Âè∞ÔºåÂàÜÊûêÂÄôÈÄâ‰∫∫ÁöÑÂõûÁ≠î„ÄÅËØ≠Ë∞ÉÂíåÈù¢ÈÉ®Ë°®ÊÉÖÔºå‰ª•ËØÑ‰º∞ËµÑÊ†º„ÄÅ‰∏™ÊÄßÂíå‰∏éËÅå‰ΩçÁöÑÂ•ëÂêàÂ∫¶„ÄÇ\n* **Workday**Ôºö‰∏ÄÊ¨æ‰∫∫ÂäõËµÑÊú¨ÁÆ°ÁêÜËΩØ‰ª∂ÔºåÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩËøõË°åÊãõËÅò„ÄÅÁª©ÊïàÁÆ°ÁêÜ„ÄÅ‰∫∫ÊâçÂèëÂ±ïÂíåÂä≥Âä®ÂäõËßÑÂàíÔºåÂ∏ÆÂä©‰ºÅ‰∏öÂÅöÂá∫Êï∞ÊçÆÈ©±Âä®ÁöÑ‰∫∫ÂäõËµÑÊ∫êÂÜ≥Á≠ñ„ÄÇ\n* **Ultimate Software**ÔºöÊèê‰æõÁî®‰∫éËñ™ËµÑ„ÄÅÂëòÂ∑•ÂèÇ‰∏éÂíåÁª©ÊïàÁÆ°ÁêÜÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂ∑•ÂÖ∑ÔºåÊèêÈ´ò‰∫∫ÂäõËµÑÊ∫êÊïàÁéáÔºåÂπ∂Êèê‰æõÂÖ≥‰∫éÂëòÂ∑•Áª©ÊïàÂíåÊÉÖÁª™ÁöÑÂèØÊìç‰ΩúÊ¥ûÂØü„ÄÇ\n* **Pymetrics**ÔºöÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÊ†πÊçÆËÆ§Áü•ÂíåÊÉÖÊÑüËÉΩÂäõÂ∞ÜÂÄôÈÄâ‰∫∫‰∏éËÅå‰ΩçÂåπÈÖçÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ÊîπÂñÑÂ§öÊ†∑ÊÄßÂπ∂ÂáèÂ∞ëÊãõËÅòÂÅèËßÅ„ÄÇ\n\n### ‰∫∫Â∑•Êô∫ËÉΩÂú®Âä≥Âä®ÂäõÂíå‰∫∫ÊâçÁÆ°ÁêÜ‰∏≠ÁöÑÂÆûÈôÖÊ°à‰æã\n\n* **ËÅîÂêàÂà©ÂçéÁöÑÊãõËÅò**ÔºöËÅîÂêàÂà©ÂçéÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÂ∑•ÂÖ∑Êù•Ëá™Âä®ÂåñÂÄôÈÄâ‰∫∫Á≠õÈÄâ„ÄÅÈù¢ËØïÔºåÊèêÈ´òÈÄüÂ∫¶Âπ∂ÂáèÂ∞ëÊãõËÅòËøáÁ®ã‰∏≠ÁöÑÊó†ÊÑèËØÜÂÅèËßÅ„ÄÇ\n* **IBMÁöÑÁª©ÊïàÁÆ°ÁêÜ**ÔºöIBMÁöÑ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÁª©ÊïàÁÆ°ÁêÜÁ≥ªÁªüÂàÜÊûêÂëòÂ∑•Êï∞ÊçÆÂπ∂Êèê‰æõ‰∏™ÊÄßÂåñÂèçÈ¶àÔºåÂ∏ÆÂä©ÁÆ°ÁêÜËÄÖË∑üË∏™ÂëòÂ∑•Áª©ÊïàÂπ∂ËØÜÂà´ÂèëÂ±ïÊú∫‰ºö„ÄÇ\n* **ÂüÉÊ£ÆÂì≤ÁöÑÂëòÂ∑•ÂèÇ‰∏éÂ∫¶**ÔºöÂüÉÊ£ÆÂì≤Âà©Áî®‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑÊÉÖÊÑüÂàÜÊûêÊù•ÁõëÊµãÂëòÂ∑•ÂèÇ‰∏éÂ∫¶ÔºåÊî∂ÈõÜÂèçÈ¶àÔºåÂπ∂Âà∂ÂÆöÊîπÂñÑÂ∑•‰ΩúÂú∫ÊâÄÊñáÂåñÁöÑÁ≠ñÁï•„ÄÇ\n\n## 8\\. ‰∫∫Â∑•Êô∫ËÉΩÂú®Ë¥¢Âä°ËßÑÂàíÂíåÈ¢ÑÊµã‰∏≠ÁöÑÂ∫îÁî®\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*2QSFmYDlYv1eqjTXRWApNw.png)\n\n‰∫∫Â∑•Êô∫ËÉΩÂà©Áî®Â§ßÈáèÁöÑË¥¢Âä°Êï∞ÊçÆÂíåÂÖàËøõÁöÑÁÆóÊ≥ïÊù•ÂàõÂª∫Êõ¥ÂáÜÁ°Æ„ÄÅÂä®ÊÄÅÂíåÂèØÈù†ÁöÑË¥¢Âä°Ê®°Âûã„ÄÇÈÄöËøáËá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°„ÄÅÊèêÈ´òÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÂíåÊèê‰æõÂèØÊìç‰ΩúÁöÑÊ¥ûÂØüÔºå‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®Â∏ÆÂä©ÁªÑÁªáÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑË¥¢Âä°ÂÜ≥Á≠ñ„ÄÇÂÖ≥ÈîÆÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®ÂåÖÊã¨Ôºö\n\n* **È¢ÑÊµãÂàÜÊûê**Ôºö‰∫∫Â∑•Êô∫ËÉΩÈÄöËøáÂàÜÊûêÂéÜÂè≤Êï∞ÊçÆ„ÄÅËØÜÂà´Ë∂ãÂäøÂíåËØÑ‰º∞Â∏ÇÂú∫Êù°‰ª∂Êù•È¢ÑÊµãÊú™Êù•ÁöÑË¥¢Âä°Ë°®Áé∞„ÄÇËøô‰ΩøÂæóÊõ¥ÂáÜÁ°ÆÁöÑÈ¢ÑÊµãÂíåÈ¢ÑÁÆóÊàê‰∏∫ÂèØËÉΩ„ÄÇ\n* **ÂÆûÊó∂Ë¥¢Âä°ÁõëÊéß**ÔºöÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂ∑•ÂÖ∑Êèê‰æõË¥¢Âä°Êï∞ÊçÆÁöÑÂÆûÊó∂Ë∑üË∏™ÔºåÂ∏ÆÂä©‰ºÅ‰∏öÂø´ÈÄüÊ£ÄÊµãÂºÇÂ∏∏„ÄÅÈ¢ÑÊµãÁé∞ÈáëÊµÅÂπ∂ÁõëÊéßÈ¢ÑÁÆóÈÅµÂæ™ÊÉÖÂÜµ„ÄÇ\n* **ÊÉÖÊôØËßÑÂàí**Ôºö‰∫∫Â∑•Êô∫ËÉΩÂèØ‰ª•Ê®°Êãü‰∏çÂêåÁöÑÁªèÊµéÊù°‰ª∂ÊàñÂïÜ‰∏öÊÉÖÊôØÔºåÂ∏ÆÂä©Ë¥¢Âä°ËßÑÂàíËÄÖËØÑ‰º∞ÂêÑÁßçÁ≠ñÁï•ÂíåÂÜ≥Á≠ñÂØπÂÖ¨Âè∏Â∫ïÁ∫øÁöÑÂΩ±Âìç„ÄÇ\n\n### AIÂú®Ë¥¢Âä°ËßÑÂàíÂíåÈ¢ÑÊµã‰∏≠ÁöÑÂÖ≥ÈîÆÁî®‰æã\n\n* **È¢ÑÁÆóÂíåÁé∞ÈáëÊµÅÈ¢ÑÊµã**ÔºöAIÂ∑•ÂÖ∑ÂàÜÊûêËøáÂéªÁöÑË¥¢Âä°Êï∞ÊçÆ„ÄÅÂÆ¢Êà∑Ë°å‰∏∫ÂíåÂ∏ÇÂú∫Êù°‰ª∂Ôºå‰ª•ÁîüÊàêÁé∞ÈáëÊµÅÈ¢ÑÊµãÔºåÁ°Æ‰øù‰ºÅ‰∏öÊã•ÊúâË∂≥Â§üÁöÑÊµÅÂä®ÊÄßÂπ∂ËÉΩÂ§üËßÑÂàíÊú™Êù•ÁöÑÊîØÂá∫„ÄÇ\n* **Êî∂ÂÖ•È¢ÑÊµã**ÔºöAIÊ®°ÂûãÂèØ‰ª•Ê†πÊçÆÂéÜÂè≤Ë°®Áé∞„ÄÅÂ≠£ËäÇÊÄßË∂ãÂäøÂíåÂÆ¢Êà∑Ë°å‰∏∫È¢ÑÊµãÊú™Êù•Êî∂ÂÖ•Ôºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÂàÜÈÖçËµÑÊ∫ê„ÄÇ\n* **Ë¥πÁî®ÁÆ°ÁêÜÂíå‰ºòÂåñ**ÔºöAIÈÄöËøáÂàÜÊûêÊîØÂá∫Ê®°ÂºèÂπ∂Âª∫ËÆÆËäÇÁúÅÊàêÊú¨ÁöÑÊé™ÊñΩÔºåËØÜÂà´ÂèØ‰ª•ÂáèÂ∞ëÊàñ‰ºòÂåñÁöÑÊàêÊú¨È¢ÜÂüü„ÄÇ\n* **‰ø°Áî®È£éÈô©ËØÑ‰º∞**ÔºöAIÈ©±Âä®ÁöÑ‰ø°Áî®ËØÑÂàÜÊ®°ÂûãÂàÜÊûêÂπøÊ≥õÁöÑË¥¢Âä°ÂíåÈùûË¥¢Âä°Êï∞ÊçÆÔºå‰∏∫Ë¥∑Êñπ„ÄÅÊäïËµÑËÄÖÂíå‰ºÅ‰∏öÊèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÈ£éÈô©ËØÑ‰º∞„ÄÇ\n* **ÊäïËµÑÂàÜÊûêÂíåÊäïËµÑÁªÑÂêàÁÆ°ÁêÜ**ÔºöAIÂ∑•ÂÖ∑ÂàÜÊûêÂ§ßÈáèÂ∏ÇÂú∫Êï∞ÊçÆÔºå‰ª•ËØÜÂà´ÊäïËµÑÊú∫‰ºö„ÄÅËØÑ‰º∞ÊäïËµÑÁªÑÂêàË°®Áé∞Âπ∂‰ºòÂåñËµÑ‰∫ßÈÖçÁΩÆ„ÄÇ\n\n### AIÂú®Ë¥¢Âä°ËßÑÂàíÂíåÈ¢ÑÊµã‰∏≠ÁöÑÂ•ΩÂ§Ñ\n\n* **ÊèêÈ´òÂáÜÁ°ÆÊÄß**ÔºöAIÁÆóÊ≥ïÂ§ÑÁêÜÂ§ßÈáèÊï∞ÊçÆÈõÜÂπ∂ËØÜÂà´‰∫∫Á±ªÂèØËÉΩÂøΩËßÜÁöÑÊ®°ÂºèÔºå‰ªéËÄåÂØºËá¥Êõ¥ÂáÜÁ°ÆÁöÑË¥¢Âä°È¢ÑÊµã„ÄÅÈ¢ÑÊµãÂíåÈ¢ÑÁÆó„ÄÇ\n* **Âä†Âø´ÂÜ≥Á≠ñ**ÔºöAIÂä†ÈÄüË¥¢Âä°ÂàÜÊûêÔºå‰ΩøÂÜ≥Á≠ñÊõ¥Âø´ÔºåËÉΩÂ§üÊõ¥ÁÅµÊ¥ªÂú∞Â∫îÂØπÂ∏ÇÂú∫ÂèòÂåñ„ÄÅÁé∞ÈáëÊµÅÈúÄÊ±ÇÊàñÊÑèÂ§ñÁöÑË¥¢Âä°‰∫ã‰ª∂„ÄÇ\n* **ÊèêÈ´òÊïàÁéá**ÔºöÈÄöËøáËá™Âä®ÂåñÊï∞ÊçÆÂΩïÂÖ•„ÄÅÂàÜÊûêÂíåÊä•ÂëäÁîüÊàêÁ≠âÊó•Â∏∏‰ªªÂä°ÔºåAI‰∏∫Ë¥¢Âä°‰∏ì‰∏ö‰∫∫Â£´ËÖæÂá∫Êó∂Èó¥Ôºå‰∏ìÊ≥®‰∫éÊàòÁï•ÂÜ≥Á≠ñÂíåÊÉÖÊôØËßÑÂàí„ÄÇ\n* **È£éÈô©ÁÆ°ÁêÜ**ÔºöAIÂàÜÊûêÂ§ßÈáèÊï∞ÊçÆÁöÑËÉΩÂäõÊúâÂä©‰∫éÂèäÊó©ËØÜÂà´ÊΩúÂú®È£éÈô©ÂíåË¥¢Âä°ÊåëÊàòÔºå‰ΩøÂÖ¨Âè∏ËÉΩÂ§üÈááÂèñ‰∏ªÂä®Êé™ÊñΩÊù•ÂáèËΩªËøô‰∫õÈ£éÈô©„ÄÇ\n* **Â¢ûÂº∫ÊàòÁï•Ê¥ûÂØü**ÔºöAIÊèê‰æõÂØπË¥¢Âä°Êï∞ÊçÆÁöÑÊõ¥Ê∑±ÂàªÊ¥ûÂØüÔºåÊèê‰æõÂÖ≥‰∫éËäÇÁúÅÊàêÊú¨Êú∫‰ºö„ÄÅÊî∂ÂÖ•Â¢ûÈïøÁ≠ñÁï•ÂíåÊï¥‰ΩìË¥¢Âä°ÂÅ•Â∫∑ÁöÑÂª∫ËÆÆ„ÄÇ\n\n### AIÂú®Ë¥¢Âä°ËßÑÂàíÂíåÈ¢ÑÊµã‰∏≠ÁöÑÈ°∂Â∞ñÂ∑•ÂÖ∑\n\n* **Adaptive Insights**: ‰∏ÄÊ¨æÂü∫‰∫é‰∫ëÁöÑË¥¢Âä°ËßÑÂàíÂ∑•ÂÖ∑ÔºåÂà©Áî®AIÂ∏ÆÂä©‰ºÅ‰∏öËøõË°åË¥¢Âä°Âú∫ÊôØÁöÑÈ¢ÑÊµãÂíåÂª∫Ê®°ÔºåË∑üË∏™Áª©ÊïàÔºåÂπ∂Ê†πÊçÆÂÆûÊó∂Êï∞ÊçÆË∞ÉÊï¥ËÆ°Âàí„ÄÇ\n* **Anaplan**: ‰∏ÄÊ¨æÁî±AIÈ©±Âä®ÁöÑËΩØ‰ª∂ÔºåÊèê‰æõÈõÜÊàêÁöÑË¥¢Âä°ËßÑÂàí„ÄÅÈ¢ÑÁÆóÂíåÈ¢ÑÊµãËß£ÂÜ≥ÊñπÊ°àÔºå‰Ωø‰ºÅ‰∏öËÉΩÂ§üËøûÊé•Ë¥¢Âä°Êï∞ÊçÆÂπ∂‰ºòÂåñÂÜ≥Á≠ñ„ÄÇ\n* **Planful (ÂâçÁß∞Host Analytics)**: ‰∏ÄÊ¨æAIÈ©±Âä®ÁöÑË¥¢Âä°ËßÑÂàí„ÄÅÂàÜÊûêÂíåÈ¢ÑÊµãÂπ≥Âè∞Ôºå‰∏∫Ë¥¢Âä°Âõ¢ÈòüÊèê‰æõÂº∫Â§ßÁöÑÂª∫Ê®°„ÄÅÈ¢ÑÁÆóÂíåÊä•ÂëäËÉΩÂäõ„ÄÇ\n* **Kensho**: ‰∏ÄÊ¨æÁî±AIÈ©±Âä®ÁöÑÂàÜÊûêÂ∑•ÂÖ∑ÔºåÈáëËûçÊú∫ÊûÑ‰ΩøÁî®ÂÆÉÊù•ÈÄöËøáÂàÜÊûêÂ§ßÈáèË¥¢Âä°Êï∞ÊçÆÂπ∂Êèê‰æõÈ¢ÑÊµãÊ¥ûÂØüÔºåÂ¢ûÂº∫È¢ÑÊµã„ÄÅÈ£éÈô©ËØÑ‰º∞ÂíåË¥¢Âä°ËßÑÂàí„ÄÇ\n* **Xero**: ‰∏ÄÊ¨æÂü∫‰∫é‰∫ëÁöÑ‰ºöËÆ°Âπ≥Âè∞ÔºåÂÖ∑ÊúâAIÈ©±Âä®ÁöÑÂäüËÉΩÔºåÂ∏ÆÂä©‰ºÅ‰∏öÂÆûÊó∂Ë∑üË∏™Áé∞ÈáëÊµÅ„ÄÅËøõË°åÈ¢ÑÊµãÂíåË¥¢Âä°Êä•Âëä„ÄÇ\n\n### Áé∞ÂÆû‰∏ñÁïå‰∏≠ AI Âú®Ë¥¢Âä°ËßÑÂàíÂíåÈ¢ÑÊµã‰∏≠ÁöÑÂ∫îÁî®ÂÆû‰æã\n\n* **Ê≤ÉËææ‰∏∞ÁöÑ‰ºÅ‰∏öÈ¢ÑÁÆó**ÔºöÊ≤ÉËææ‰∏∞Âà©Áî® AI ÊîπËøõÂÖ∂Ë¥¢Âä°ËßÑÂàíÊµÅÁ®ãÔºåÈÄöËøáËá™Âä®ÂåñÈ¢ÑÁÆóÂàõÂª∫„ÄÅ‰ºòÂåñÁé∞ÈáëÊµÅÈ¢ÑÊµãÔºåÂπ∂Êèê‰æõÊõ¥Ê∑±ÂÖ•ÁöÑÂÖ®ÁêÉËøêËê•ÊàêÊú¨ÂàÜÈÖçÊ¥ûÂØü„ÄÇ\n* **Netflix ÁöÑÊî∂ÂÖ•È¢ÑÊµã**ÔºöNetflix Âà©Áî® AI ÂàÜÊûêÂÆ¢Êà∑Êï∞ÊçÆÂπ∂È¢ÑÊµãÁî®Êà∑Â¢ûÈïøÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ËßÑÂàíÂÖ∂Ë¥¢Âä°ÊàòÁï•ÔºåÂπ∂ÊúâÊïàÂàÜÈÖçËµÑÊ∫ê‰∫éÂêÑÁßçÂÜÖÂÆπÂà∂‰ΩúÂíåËê•ÈîÄÂ∑•‰Ωú„ÄÇ\n* **ÈªëÁü≥ÁöÑÊäïËµÑÁÆ°ÁêÜ**ÔºöÈªëÁü≥ÈááÁî® AI ÂíåÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊù•ÁÆ°ÁêÜÊäïËµÑÁªÑÂêàÂíå‰ºòÂåñËµÑ‰∫ßÈÖçÁΩÆÔºå‰∏∫ÂÆ¢Êà∑Êèê‰æõÊõ¥ÂáÜÁ°ÆÂíåÊï∞ÊçÆÈ©±Âä®ÁöÑÊäïËµÑÁ≠ñÁï•„ÄÇ\n\n## ÁªìËÆ∫\n\nÈöèÁùÄÊàë‰ª¨ËøõÂÖ•2025Âπ¥Ôºå‰∫∫Â∑•Êô∫ËÉΩÂ∞ÜÊàê‰∏∫ËÆ∏Â§öÊàêÂäü‰ºÅ‰∏öÁöÑÊîØÊü±„ÄÇÈÄöËøáËá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°„ÄÅÊèêÂçáÂÆ¢Êà∑‰ΩìÈ™å‰ª•ÂèäÊèê‰æõÊï∞ÊçÆÈ©±Âä®ÁöÑÊ¥ûÂØüÔºå‰∫∫Â∑•Êô∫ËÉΩ‰ΩøÁªÑÁªáËÉΩÂ§üÂÅöÂá∫Êõ¥ËÅ™Êòé„ÄÅÊõ¥Âø´ÈÄüÁöÑÂÜ≥Á≠ñ„ÄÇ‰∫∫Â∑•Êô∫ËÉΩÂú®È¢ÑÊµãÂàÜÊûê„ÄÅÁΩëÁªúÂÆâÂÖ®Âíå‰∏™ÊÄßÂåñËê•ÈîÄ‰∏≠ÁöÑ‰ΩúÁî®Â∞ÜÁªßÁª≠Êé®Âä®ÂàõÊñ∞Ôºå‰Ωø‰ºÅ‰∏öËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Êª°Ë∂≥‰∏çÊñ≠ÂèòÂåñÁöÑÊ∂àË¥πËÄÖÈúÄÊ±Ç„ÄÇ\n\nÂïÜ‰∏öÁöÑÊú™Êù•Âú®‰∫é[**‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑÊï¥Âêà**](https://www.blockchainappfactory.com/ai-development-company)ÔºåÈÇ£‰∫õÊã•Êä±Ëøô‰∫õËøõÊ≠•ÁöÑ‰ºÅ‰∏öÂ∞ÜÂ§Ñ‰∫éË°å‰∏öÁöÑÂâçÊ≤ø„ÄÇÂ∞ΩÁÆ°ÈááÁî®‰∫∫Â∑•Êô∫ËÉΩÈù¢‰∏¥ÁùÄÊï∞ÊçÆÈöêÁßÅÂíåÂ∞±‰∏öÊõø‰ª£Á≠âÊåëÊàòÔºå‰ΩÜÂÖ∂Â•ΩÂ§ÑËøúËøúË∂ÖËøáÈ£éÈô©„ÄÇÈÄöËøáÂà∂ÂÆöÊ≠£Á°ÆÁöÑÁ≠ñÁï•Ôºå‰ºÅ‰∏öÂèØ‰ª•ÂÖÖÂàÜÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÁöÑÊΩúÂäõÔºåÂú®2025Âπ¥ÁöÑÁ´û‰∫âÁéØÂ¢É‰∏≠Ëì¨ÂãÉÂèëÂ±ï„ÄÇ\n\n## Â∏∏ËßÅÈóÆÈ¢òËß£Á≠î\n\n1. **2025Âπ¥‰ºÅ‰∏öÊúÄÈáçË¶ÅÁöÑAIÂ∫îÁî®Âú∫ÊôØÊòØ‰ªÄ‰πàÔºü**  \nÂú®2025Âπ¥ÔºåAIÂ∞ÜÁî®‰∫éÈ¢ÑÊµãÂàÜÊûê„ÄÅ‰∏™ÊÄßÂåñËê•ÈîÄ„ÄÅËá™Âä®Âåñ„ÄÅÊ¨∫ËØàÊ£ÄÊµã„ÄÅÂÆ¢Êà∑ÊîØÊåÅËÅäÂ§©Êú∫Âô®‰∫∫Âíå‰æõÂ∫îÈìæ‰ºòÂåñ„ÄÇ\n2. **AIÂ¶Ç‰ΩïÊîπÂñÑÂÆ¢Êà∑‰ΩìÈ™åÔºü**  \nAIÂèØ‰ª•ÈÄöËøá‰∏™ÊÄßÂåñÊé®Ëçê„ÄÅAIÈ©±Âä®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫Êèê‰æõÂç≥Êó∂ÊîØÊåÅÔºå‰ª•ÂèäÈ¢ÑÊµãÂ∑•ÂÖ∑Êù•È¢ÑËßÅÂÆ¢Êà∑ÈúÄÊ±ÇÔºå‰ªéËÄåÂ¢ûÂº∫ÂÆ¢Êà∑‰ΩìÈ™å„ÄÇ\n3. **AIÊòØÂê¶ÂèØËÉΩÂèñ‰ª£‰ºÅ‰∏ö‰∏≠ÁöÑ‰∫∫Á±ªÂëòÂ∑•Ôºü**  \nAIÊõ¥ÂèØËÉΩÈÄöËøáËá™Âä®ÂåñÈáçÂ§çÊÄß‰ªªÂä°Êù•Â¢ûÂº∫‰∫∫Á±ªÂëòÂ∑•ÁöÑÂ∑•‰ΩúÔºå‰ΩøÂëòÂ∑•ËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊõ¥È´òÂ±ÇÊ¨°ÁöÑÂÜ≥Á≠ñÂíåÂàõÈÄ†ÊÄßÂ∑•‰Ωú„ÄÇ\n4. **Âì™‰∫õË°å‰∏öÂú®2025Âπ¥ÊúÄËÉΩ‰ªéAI‰∏≠ÂèóÁõäÔºü**  \nÈáëËûç„ÄÅÂåªÁñó‰øùÂÅ•„ÄÅÈõ∂ÂîÆ„ÄÅÂà∂ÈÄ†ÂíåÁâ©ÊµÅÁ≠âË°å‰∏öÈ¢ÑËÆ°Â∞Ü‰ªéAI‰∏≠Ëé∑ÂæóÊòæËëóÊî∂ÁõäÔºåÂåÖÊã¨ÊèêÈ´òÊïàÁéáÂíåËäÇÁúÅÊàêÊú¨„ÄÇ\n5. **‰ºÅ‰∏öÂú®ÈááÁî®AIÊó∂Èù¢‰∏¥Âì™‰∫õÊåëÊàòÔºü**  \n‰ºÅ‰∏öÂèØËÉΩÈù¢‰∏¥‰∏éÊï∞ÊçÆÈöêÁßÅ„ÄÅ‰∏éÁé∞ÊúâÁ≥ªÁªüÁöÑÈõÜÊàê„ÄÅÈ´òÂàùÂßãÊäïËµÑ‰ª•ÂèäÁ°Æ‰øùAIÁ≥ªÁªüÁöÑ‰º¶ÁêÜ‰ΩøÁî®Áõ∏ÂÖ≥ÁöÑÊåëÊàò„ÄÇ\n\n"},{"lang":"zh","group":"blog","slug":"blog/unified-memory-across-chatgpt-claude-perplexity-24809dc56717","frontmatter":{"title":"Ë∑® ChatGPT„ÄÅClaude„ÄÅPerplexity ÁöÑÁªü‰∏ÄÂÜÖÂ≠ò","meta_title":"Ë∑® ChatGPT„ÄÅClaude„ÄÅPerplexity ÁöÑÁªü‰∏ÄÂÜÖÂ≠ò","description":"ÊÇ®‰∏ÄÂÆö‰ºöÂñúÊ¨¢Ëøô‰∏™ÔºåÁâπÂà´ÊòØÂ¶ÇÊûúÊÇ®Â∑≤Áªè‰ΩøÁî®Ëøá Claude„ÄÅChatGPT Âíå Perplexity„ÄÇ","date":"2024-11-08T00:24:33.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qrHnDS6YODZuVXZ4eeWZrQ.png","categories":["Chatbots","Programming/Scripting","Technology/Web"],"author":"Rifx.Online","tags":["Mem0","Chrome","extension","context","memory"],"draft":false,"slug":"blog/unified-memory-across-chatgpt-claude-perplexity-24809dc56717"},"content":"\n‰Ω†‰∏ÄÂÆö‰ºöÂñúÊ¨¢Ëøô‰∏™ÔºåÁâπÂà´ÊòØÂ¶ÇÊûú‰Ω†Â∑≤Áªè‰∏é Claude„ÄÅChatGPT Âíå Perplexity Á¥ßÂØÜËÅîÁ≥ªÂú®‰∏ÄËµ∑„ÄÇ\n\n‰∏é‰∏çÂêåÁöÑ AI Âä©Êâã‰∫íÂä®ÊúâÊó∂‰ºöÊÑüËßâÊúâ‰∫õËÑ±ËäÇ„ÄÇ\n\nÂú®ÂàáÊç¢ ChatGPT„ÄÅClaude„ÄÅPerplexity ÂíåÂÖ∂‰ªñÂä©ÊâãÊó∂Ôºå‰Ω†ÂøÖÈ°ª‰∏ÄÈÅçÂèà‰∏ÄÈÅçÂú∞ÈáçÂ§çÁõ∏ÂêåÁöÑ‰∏ä‰∏ãÊñá„ÄÇ\n\nÂ¶ÇÊûúÂÆÉ‰ª¨ÈÉΩËÉΩÂÖ±‰∫´‰∏Ä‰∏™ÈÄöÁî®ËÆ∞ÂøÜ‰ª•Â¢ûÂº∫‰∏ä‰∏ãÊñáÔºåÈÇ£ËØ•Â§öÂ•ΩÂïäÔºü\n\nÊàëÂèëÁé∞‰∫ÜËøô‰∏™ÂæàÊ£íÁöÑ Chrome Êâ©Â±ïÔºåÂÆÉÂØπÊàëÊù•ËØ¥ÁúüÊòØ‰∏™ÊïëÊòü„ÄÇ\n\nÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÊó†ËÆ∫‰Ω†Âú®‰∏éÂì™‰∏™ AI ËÅäÂ§©Ôºå‰∏ä‰∏ãÊñáÈÉΩËÉΩÊó†Áºù‰º†ÈÄíÁöÑÂØπËØù„ÄÇ\n\nÂê¨Ëµ∑Êù•‰∏çÈîôÔºåÊòØÂêßÔºü\n\n\n\n### ÂÆÉËß£ÂÜ≥ÁöÑÈáçÂ§ßÈóÆÈ¢ò\n\nÂú®ÊàëÊ∑±ÂÖ•Êé¢ËÆ®‰πãÂâçÔºåÊàë‰ª¨Â¶Ç‰Ωï‰øùÊåÅ LLMs Êõ¥Êñ∞‰ª•Ëé∑ÂèñÊúÄÊñ∞Áü•ËØÜÔºü\n\nÊúâÂá†Áßç‰º†ÁªüÁöÑÊñπÊ≥ïÂèØ‰ª•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºö\n\n1. **Âü∫‰∫éÊ£ÄÁ¥¢ÁöÑÊñπÊ≥ï**ÔºöËøô‰∫õÊñπÊ≥ï‰ªéÁü•ËØÜÂ∫ì‰∏≠ÊèêÂèñ‰ø°ÊÅØ„ÄÇÂÆÉ‰ª¨ÂäüËÉΩÂº∫Â§ßÔºå‰ΩÜÂèØËÉΩ‰ºöÂõ†‰∏∫ÂÜó‰ΩôÊï∞ÊçÆÂíåÁÆ°ÁêÜ‰∏çÊñ≠Â¢ûÈïøÁöÑÂ≠òÂÇ®Â∫ìËÄåÂèòÂæóÊ∑∑‰π±„ÄÇ\n2. **Ê®°ÂûãÁºñËæë**ÔºöËøôÊòØ‰∏ÄÁßçË∞ÉÊï¥Ê®°Âûã‰ª•ÈÄÇÂ∫îÊñ∞‰∫ãÂÆûÁöÑÊñπÊ≥ï„ÄÇÂÆÉÈÄÇÁî®‰∫éÁÆÄÂçïÁöÑÂçïÂè•Êõ¥Êñ∞Ôºå‰ΩÜÂú®Â§ÑÁêÜËæÉÈïø„ÄÅÊõ¥Â§çÊùÇÁöÑ‰ø°ÊÅØÊó∂‰ºöÈÅáÂà∞Âõ∞Èöæ„ÄÇ\n3. **Èïø‰∏ä‰∏ãÊñáÊñπÊ≥ï**ÔºöËøô‰∫õÊñπÊ≥ïÂ∞ÜÊâÄÊúâÁü•ËØÜÂ°ûÂÖ•Ê®°ÂûãÁöÑ‰∏ä‰∏ãÊñá‰∏≠„ÄÇËøôÂ∞±ÂÉèÊòØÁî®Êï∞ÊçÆËøáËΩΩÊ®°ÂûãÔºå‰ΩÜÁî±‰∫é‰∏ä‰∏ãÊñáÈïøÂ∫¶ÊúâÈôêÔºåËøôÂπ∂‰∏çÂÆûÁî®„ÄÇ\n\nÊâÄÊúâËøô‰∫õÊñπÊ≥ïÈÉΩÊúâÂÖ∂Áº∫ÁÇπÔºåÁâπÂà´ÊòØÂú®Êàë‰ª¨ÈúÄË¶ÅÂú®‰∏çÂêåÁöÑ AI Âπ≥Âè∞‰πãÈó¥ËøõË°åÊúÄÊñ∞„ÄÅÊó†ÁºùÁöÑ‰∫§‰∫íÊó∂„ÄÇ\n\n### ËøõÂÖ• Mem0ÔºöAI Âä©ÊâãÁöÑÊô∫ËÉΩËÆ∞ÂøÜÊ£ÄÁ¥¢\n\nMem0 ÈÄöËøáÂàõÂª∫‰∏Ä‰∏™ÈÄöÁî®ÁöÑËÆ∞ÂøÜÂ±ÇÔºåËß£ÂÜ≥‰∫ÜËøô‰∫õÈóÆÈ¢òÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®Â§ö‰∏™ AI Âä©Êâã‰πãÈó¥Â∑•‰Ωú„ÄÇ\n\nÂÆÉÂ∏¶Êù•‰∫Ü‰ª•‰∏ã‰ºòÂäøÔºö\n\n* **ÈÄöÁî®ËÆ∞ÂøÜÂ±Ç**ÔºöÂú® ChatGPT„ÄÅClaude„ÄÅPerplexity Á≠â‰πãÈó¥ËΩªÊùæÂÖ±‰∫´‰∏ä‰∏ãÊñá„ÄÇ‰∏çÂÜçÈúÄË¶ÅÈáçÂ§çËá™Â∑±ÔºÅ\n* **Êô∫ËÉΩ‰∏ä‰∏ãÊñáÊ£ÄÊµã**ÔºöËá™Âä®‰ªéÊÇ®ÁöÑÂØπËØù‰∏≠ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØÔºåÂõ†Ê≠§ÊÇ®Êó†ÈúÄÊâãÂä®ËæìÂÖ•‰ªª‰ΩïÂÜÖÂÆπ„ÄÇ\n* **Êô∫ËÉΩËÆ∞ÂøÜÊ£ÄÁ¥¢**ÔºöMem0 Âú®ÂêàÈÄÇÁöÑÊó∂Êú∫Ë∞ÉÂá∫Ê≠£Á°ÆÁöÑËÆ∞ÂøÜÔºå‰ΩøÊÇ®ÁöÑ‰∫íÂä®Êõ¥Âä†È°∫ÁïÖ„ÄÇ\n* **‰∏ÄÈîÆ‰∏é ChatGPT ÂêåÊ≠•**ÔºöÂ¶ÇÊûúÊÇ®‰∏ÄÁõ¥Âú®‰ΩøÁî® ChatGPTÔºåÂèØ‰ª•ÈÄöËøá‰∏ÄÊ¨°ÁÇπÂáªÂ∞ÜÁé∞ÊúâËÆ∞ÂøÜÂêåÊ≠•„ÄÇ\n* **ËÆ∞ÂøÜ‰ª™Ë°®Êùø**Ôºö‰∏Ä‰∏™Êñπ‰æøÁöÑÂú∞ÊñπÔºåÂèØ‰ª•ÈõÜ‰∏≠ÁÆ°ÁêÜÊâÄÊúâËÆ∞ÂøÜ„ÄÇ\n\n‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊÇ®‰∏é Claude ÂºÄÂßãÂØπËØùÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QQAJPzQp2tjBFgi-9InG1Q.png)\n\nÂÆÉÂ∞ÜÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØÂπ∂Â∞ÜÂÖ∂Ê∑ªÂä†Âà∞ËÆ∞ÂøÜ‰∏≠„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MtctEzunD72Tw_dOOCOnyA.png)\n\nÁÑ∂ÂêéÔºå‰∏ãÊ¨°ÊÇ®ÈóÆ‰∏Ä‰∏™Áõ∏ÂÖ≥ÈóÆÈ¢òÊó∂Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*r0WyCIHGvmiGm0GZ6xR1pw.png)\n\nÂÆÉÂ∞ÜÊ∑ªÂä†Áõ∏ÂÖ≥‰∏ä‰∏ãÊñáÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*PTEhFUJ4nrhQbeZXIAnD6A.png)\n\n‰ΩÜÊõ¥ÊúâË∂£ÁöÑÊòØ„ÄÇ\n\nÂ¶ÇÊûúÊÇ®ÊâìÂºÄ Perplexity Âπ∂ÈóÆÂè¶‰∏Ä‰∏™ÈóÆÈ¢òÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*54BKW9BQWwCDdXdAg0U-mA.png)\n\nÂÆÉÂ∞ÜË∑®‰∏çÂêåÂ∫îÁî®Á®ãÂ∫èËé∑ÂèñËÆ∞ÂøÜÂπ∂Â¢ûÂº∫‰∏ä‰∏ãÊñáÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FD6MwGtL8WpovUH3o1Vw3g.png)\n\nËøôÁúüÊòØÂ§™ÈÖ∑‰∫ÜÔºÅ\n\nÂ¶ÇÊûúÊÇ®ÊâìÂºÄ ChatGPT Âπ∂ÈóÆ‰∏Ä‰∏™ÈóÆÈ¢òÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qLmDZh5NofuArxzS4OnDIQ.png)\n\nÂêåÊ†∑ÔºåÂÆÉÂ∞Ü‰ªéËÆ∞ÂøÜ‰∏≠ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØÂπ∂Â¢ûÂº∫‰∏ä‰∏ãÊñá„ÄÇ\n\nÈöèÁùÄÊÇ®‰∏éÂÆÉÁöÑ‰∫íÂä®Â¢ûÂ§öÔºåÂÆÉÂ∞ÜÊî∂ÈõÜÂÖ≥ÈîÆ‰ø°ÊÅØÔºå‰∏∫ÊÇ®ËäÇÁúÅÂ§ßÈáèËæìÂÖ•Êó∂Èó¥ÔºåÂêåÊó∂‰∏é Claude„ÄÅPerplexity Âíå ChatGPT ËøõË°å‰∫§‰∫í„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MqgEr6hi5cHzHRuTqODzuA.png)\n\nÊÇ®ËøòÂèØ‰ª•ÂêëËÆ∞ÂøÜ‰∏≠Ê∑ªÂä†Êñ∞‰ø°ÊÅØÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Xo6jLLIGKqxvYR9SivuMhQ.png)\n\n### Â¶Ç‰ΩïÂºÄÂßã\n\nÂÆâË£Ö Mem0 ÈùûÂ∏∏ÁÆÄÂçïÔºö\n\n1. [**Â∞ÜÊâ©Â±ïÁ®ãÂ∫èÊ∑ªÂä†Âà∞ Chrome**](https://chromewebstore.google.com/detail/mem0/onihkkbipkfeijkadecaafbgagkhglop?hl=en-GB)\n\n**2\\. ÁôªÂΩï**Ôºö\n\n* ÂÆâË£ÖÂêéÔºåÊÇ®‰ºöÂú®Â∑•ÂÖ∑Ê†è‰∏≠ÁúãÂà∞ Mem0 ÂõæÊ†á„ÄÇ\n* ÁÇπÂáªÂÆÉÂπ∂‰ΩøÁî® Google ÁôªÂΩï„ÄÇ\n\n**4\\. ÂºÄÂßãËÅäÂ§©**Ôºö\n\n* ‰ΩøÁî®‰ªª‰ΩïÊîØÊåÅÁöÑ AI Âä©Êâã„ÄÇ\n* ÂØπ‰∫é ChatGPT Âíå PerplexityÔºåÂè™ÈúÄÂÉèÂπ≥Â∏∏‰∏ÄÊ†∑ËÅäÂ§©„ÄÇ\n* Âú® Claude ‰∏äÔºåÁÇπÂáª Mem0 ÊåâÈíÆÊàñ‰ΩøÁî®Âø´Êç∑ÈîÆ `^ + M`„ÄÇ\n\nMem0 ÊúÄÊ£íÁöÑÂú∞Êñπ‰πã‰∏ÄÂ∞±ÊòØÂÆÉÊòØÂÆåÂÖ®ÂÖçË¥πÁöÑ„ÄÇÊ≤°ÊúâÔºö\n\n* **‰ΩøÁî®ÈôêÂà∂**\n* **ÂπøÂëä**\n* **ÊâÄÊúâÂäüËÉΩÂùáÂåÖÂê´Âú®ÂÜÖ**\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/unlocking-mixture-of-experts-moe-llm-your-moe-model-can-be-embedding-model-for-free-f192b9c07a5f","frontmatter":{"title":"Ëß£ÈîÅÊ∑∑Âêà‰∏ìÂÆ∂ (MoE) LLMÔºö‰Ω†ÁöÑ MoE Ê®°ÂûãÂèØ‰ª•ÂÖçË¥πÂµåÂÖ•Ê®°Âûã","meta_title":"Ëß£ÈîÅÊ∑∑Âêà‰∏ìÂÆ∂ (MoE) LLMÔºö‰Ω†ÁöÑ MoE Ê®°ÂûãÂèØ‰ª•ÂÖçË¥πÂµåÂÖ•Ê®°Âûã","description":"Ê∑∑Âêà‰∏ìÂÆ∂ (MoE) LLM ÂèØ‰ª•ÂÖçË¥πÁî®‰ΩúÂµåÂÖ•Ê®°Âûã„ÄÇ","date":"2024-11-04T12:30:57.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mB6VhEyAvxAxGbLDG_6hTw.png","categories":["Machine Learning","Natural Language Processing","Data Science"],"author":"Rifx.Online","tags":["Mixture-of-Experts","MoE","embedding","MoEE","BERTopic"],"draft":false,"slug":"blog/unlocking-mixture-of-experts-moe-llm-your-moe-model-can-be-embedding-model-for-free-f192b9c07a5f"},"content":"\n### Mixture-of-experts (MoE) LLM ÂèØ‰ª•‰Ωú‰∏∫ÂÖçË¥πÁöÑÂµåÂÖ•Ê®°Âûã‰ΩøÁî®„ÄÇ\n\n\n\nÊàëÊúÄËøëÂèëÁé∞‰∫Ü‰∏ÄÁØáÊúâË∂£ÁöÑËÆ∫ÊñáÔºåÊ†áÈ¢ò‰∏∫‚Äú‰Ω†ÁöÑ Mixture-of-Experts LLM ÁßòÂØÜÂú∞ÊòØ‰∏Ä‰∏™ÂÖçË¥πÁöÑÂµåÂÖ•Ê®°Âûã„ÄÇ‚Äù\\[1\\] ÊúÄËøëÁöÑ LLM Êû∂ÊûÑË∂ãÂäøÊòØËß£Á†ÅÂô®Ê®°ÂûãÔºåËøôÂØπ‰∫éÂµåÂÖ•Ê®°ÂûãÂπ∂‰∏çÈÄÇÁî®ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑÊ≥®ÊÑèÂäõÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºå‰ΩúËÄÖÊè≠Á§∫‰∫Ü Mixture-of-Experts (MoE) LLM ÂèØ‰ª•‰Ωú‰∏∫ÂµåÂÖ•Ê®°ÂûãÊù•ÊâßË°åÂ§öÁßçÂµåÂÖ•Áõ∏ÂÖ≥ÁöÑ‰ªªÂä°ÔºåËÄåÊó†ÈúÄËøõ‰∏ÄÊ≠•ÁöÑÂæÆË∞É„ÄÇÂú®ËøôÁØáÂçöÂÆ¢‰∏≠ÔºåÈ¶ñÂÖàËÆ©Êàë‰ª¨ÂõûÈ°æ‰∏Ä‰∏ã MoEÔºåÊàëÂ∞Ü‰ªãÁªçÂÆÉÁöÑÂ∑•‰ΩúÂéüÁêÜÂèäÂÖ∂ÂÆûÈôÖÂ∫îÁî®„ÄÇ\n\n## ÁõÆÂΩï\n\n1. ‰ªÄ‰πàÊòØ‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºàMoEÔºâÔºü\n2. MoE Â¶Ç‰Ωï‰Ωú‰∏∫ÂµåÂÖ•Ê®°ÂûãÂ∑•‰ΩúÔºü\n3. ÂÆûÈôÖÂÆûÊñΩÔºö‰ΩøÁî® BERTopic Âà©Áî® MoEE\n\n## 1\\. ‰ªÄ‰πàÊòØ‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°Âûã (MoE)Ôºü\n\n‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°Âûã (MoE) ÊòØ‰∏ÄÁßçÂÖ∑ÊúâÂ§ö‰∏™Â≠êÁΩëÁªúÁöÑÊû∂ÊûÑÔºåËøô‰∫õÂ≠êÁΩëÁªúË¢´Áß∞‰∏∫‚Äú‰∏ìÂÆ∂‚ÄùÔºåÊØè‰∏™‰∏ìÂÆ∂‰∏ìÊ≥®‰∫é‰∏çÂêåÁöÑ‰ªªÂä°ÊàñÊï∞ÊçÆÊñπÈù¢„ÄÇMoE ÁöÑ‰∏Ä‰∏™‰ºòÂäøÊòØÔºåÂÆÉËÉΩÂ§ü‰ª•ÊØîÁõ∏ÂêåÊàñÊõ¥Â§ßÊ®°ÂûãÊõ¥Â∞ëÁöÑËÆ°ÁÆóÈáèÂØπ AI Ê®°ÂûãËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂêåÊó∂‰øùÊåÅÊàñÊèêÈ´òË¥®Èáè„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÊàë‰ª¨ÁöÑÈ¢ÑÁÆóÊúâÈôêÔºå‰ΩøÁî® MoE ÂèØ‰ª•ÊØîÁ®†ÂØÜÁöÑ„ÄÅÁõ∏‰ººÂ§ßÂ∞èÁöÑ‰º†ÁªüÊ®°ÂûãËé∑ÂæóÊõ¥Â•ΩÁöÑÊ®°Âûã„ÄÇÂú®ÊúÄËøëÁöÑÊàêÂäüÊ°à‰æã‰∏≠ÔºåMixtral 8 x 7B Âú®ËÆ∏Â§öËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏äË∂ÖË∂ä‰∫Ü LLaMA 2 70B„ÄÇ\n\nÊé•‰∏ãÊù•ÔºåËÆ©Êàë‰ª¨Á†îÁ©∂ MoE ÁöÑÊû∂ÊûÑ„ÄÇÊúÄËøëÊàêÂäüÁöÑ MoE ‰ΩøÁî®‰∫ÜÂèòÂéãÂô®Ê®°ÂûãÔºåÂõ†Ê≠§ÊàëÂ∞ÜÈáçÁÇπÂÖ≥Ê≥®ÂèòÂéãÂô®ÁöÑÊµÅË°å MoE Êû∂ÊûÑ„ÄÇMoE ‰∏ªË¶ÅÊúâ‰∏§‰∏™ÁªÑ‰ª∂ÔºåÂ¶Ç‰∏ãÊâÄËø∞„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Dia_c08PJnFeeIc9lxwtGQ.png)\n\n* **MoE Â±Ç**\n\nMoE Âú®ÂèòÂéãÂô®Êû∂ÊûÑ‰∏≠Áî® MoE Â±ÇÊõø‰ª£‰∫ÜÂâçÈ¶àÁΩëÁªú (FFN) Â±Ç„ÄÇÊØè‰∏™ MoE Â±ÇÊúâ‰∏Ä‰∫õ‰∏ìÂÆ∂Ôºà‰æãÂ¶ÇÔºå‰∏äÂõæ‰∏≠ÁöÑ 4 ‰∏™‰∏ìÂÆ∂ÔºâÔºåÊØè‰∏™‰∏ìÂÆ∂Áî±ÁÆÄÂçïÁöÑ FFN Â±ÇÁªÑÊàê„ÄÇËØ∑Ê≥®ÊÑèÔºåÂèòÂéãÂô®‰∏≠ÁöÑÂÖ∂‰ªñÁªÑ‰ª∂Ôºå‰æãÂ¶ÇËá™Ê≥®ÊÑèÂäõÂ±ÇÔºå‰ΩøÁî®Áõ∏ÂêåÁöÑÊùÉÈáç„ÄÇÂõ†Ê≠§ÔºåMoE ÁöÑÊùÉÈáçÊï∞ÈáèÂπ∂‰∏çÁÆÄÂçï„ÄÇ‰æãÂ¶ÇÔºåMixtral 8 x 7B ÁöÑÊùÉÈáç‰∏çÊòØ 8 x 7 = 56BÔºåËÄåÊòØ 47BÔºåÂõ†‰∏∫Èô§‰∫Ü MoE Â±Ç‰πãÂ§ñÁöÑÂÖ∂‰ªñÂ±ÇÂÖ±‰∫´Áõ∏ÂêåÁöÑÊùÉÈáç„ÄÇ\n\n* **Èó®ÊéßÁΩëÁªú**\n\nÈó®ÊéßÁΩëÁªúÊàñË∑ØÁî±Âô®ÊòØ MoE ‰∏≠ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂„ÄÇÂÆÉÊé•Êî∂ËæìÂÖ•Ê†áËÆ∞Âπ∂‰∏∫ÊØè‰∏™Ê†áËÆ∞ÈÄâÊã©ÊúÄÁõ∏ÂÖ≥ÁöÑ‰∏ìÂÆ∂„ÄÇ‰æãÂ¶ÇÔºåÂú®‰∏äÈù¢ÁöÑÊèíÂõæ‰∏≠ÔºåË∑ØÁî±Âô®ÁöÑÂ∑¶‰æßÈÄâÊã©Á¨¨‰∫å‰∏™‰∏ìÂÆ∂Êù•Â§ÑÁêÜÂçïËØç‚Äúmore‚ÄùÊ†áËÆ∞„ÄÇÂêåÊó∂ÔºåË∑ØÁî±Âô®Á°ÆÂÆöÁ¨¨‰∏Ä‰∏™‰∏ìÂÆ∂Êù•Â§ÑÁêÜÂçïËØç‚ÄúParameters‚ÄùÊ†áËÆ∞„ÄÇÈÄöÂ∏∏ÔºåÈó®ÊéßÁΩëÁªúÈÄâÊã©‰∏éÁªôÂÆöÊ†áËÆ∞Áõ∏ÂÖ≥ÁöÑÂâç k ‰∏™‰∏ìÂÆ∂ÔºåÂπ∂Â∞ÜÊ†áËÆ∞ÂèëÈÄÅÁªôÈÄâÂÆöÁöÑ‰∏ìÂÆ∂Ôºõ‰æãÂ¶ÇÔºåMixtral 8 x 7B ÈÄâÊã©Ââç 2 ‰∏™‰∏ìÂÆ∂„ÄÇ\n\nÊàë‰ª¨Â¶Ç‰ΩïÈÄâÊã©Ââç k ‰∏™‰∏ìÂÆ∂ÔºüÊàë‰ª¨‰ΩøÁî® softmax ÂáΩÊï∞Êù•ËÆ°ÁÆó‰∏ìÂÆ∂ÁöÑÈáçË¶ÅÊÄßÊ¶ÇÁéáÔºåÂπ∂‰øùÁïôÂâç k ‰∏™Ê¶ÇÁéá‰∏ìÂÆ∂ÔºåÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇÊàëÊèêÂèñ‰∫Ü‰∏äËø∞ÊèíÂõæÁöÑÈó®ÊéßÈÉ®ÂàÜ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qX9H2KKtjntVuiE8yFstMQ.png)\n\nÈó®ÊéßÁΩëÁªúÊúâÂÖ∂ÊùÉÈáç„ÄÇÊàë‰ª¨Â∞Ü softmax ÂáΩÊï∞Â∫îÁî®‰∫éËæìÂÖ•ÂçïËØçÊ†áËÆ∞‰∏éÈó®ÊéßÁΩëÁªúÊùÉÈáç‰πãÈó¥ÁöÑÁÇπÁßØÁªìÊûúÔºåÁÑ∂ÂêéÂæóÂà∞‰∏ìÂÆ∂‰∏éÁªôÂÆöÊ†áËÆ∞Áõ∏ÂÖ≥ÁöÑÊ¶ÇÁéá„ÄÇÊ†πÊçÆÊ¶ÇÁéáÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄâÊã©Ââç k ‰∏™Áõ∏ÂÖ≥‰∏ìÂÆ∂„ÄÇÂÖ∑ÊúâËøôÁßçÁ±ªÂûãÈó®ÊéßÁΩëÁªúÁöÑ MoE Ë¢´Áß∞‰∏∫Á®ÄÁñè MoE„ÄÇ\n\nËøô‰∫õÊòØÁêÜËß£ MoE Â¶Ç‰Ωï‰Ωú‰∏∫ÂµåÂÖ•Ê®°ÂûãÂ∑•‰ΩúÁöÑÂü∫Êú¨Áü•ËØÜ„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÁêÜËß£ÔºåÊàëÊé®ËçêÈòÖËØª [ËøôÁØáÂçöÂÆ¢](https://huggingface.co/blog/moe) \\[2]„ÄÇÁé∞Âú®ÔºåËÆ©Êàë‰ª¨Ê∑±ÂÖ•Êé¢ËÆ® MoE ÂÆûÈôÖ‰∏äÊòØÂ¶Ç‰Ωï‰Ωú‰∏∫ÂµåÂÖ•Ê®°ÂûãÂ∑•‰ΩúÁöÑ„ÄÇ\n\n## 2\\. MoE Â¶Ç‰Ωï‰Ωú‰∏∫ÂµåÂÖ•Ê®°ÂûãÂ∑•‰ΩúÔºü\n\n### ÂÖ≥‰∫éÂµåÂÖ•ÁöÑÂø´ÈÄüÂõûÈ°æ\n\nÂú®Ê∑±ÂÖ•Êú¨ËäÇ‰∏ªÈ¢ò‰πãÂâçÔºåËÆ©Êàë‰ª¨Âø´ÈÄüÂõûÈ°æ‰∏Ä‰∏ãÂµåÂÖ•„ÄÇÊúÄËøëÔºåÂµåÂÖ•Êàê‰∏∫Ê∑±Â∫¶Â≠¶‰π†Ê®°Âûã‰∏≠ËæìÂÖ•Êï∞ÊçÆÁöÑÂÜÖÈÉ®Ë°®Á§∫ÔºåÂÆÉÂÖ∑ÊúâËØ≠‰πâÂíåÊµìÁº©ÁöÑÊï∞ÊçÆ‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÈÄöÂ∏∏ÊèêÂèñÁ•ûÁªèÁΩëÁªúÁöÑÊúÄÂêé‰∏Ä‰∏™ÈöêËóèÁä∂ÊÄÅ‰Ωú‰∏∫ÂµåÂÖ•ÔºåÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kSHFTEejKiSI51taKZCO9A.png)\n\nÊàë‰ª¨ÈÄöÂ∏∏‰ΩøÁî®Âü∫‰∫éÁºñÁ†ÅÂô®ÁöÑÊ®°ÂûãÊù•ÊèêÂèñÂµåÂÖ•ÔºåÂõ†‰∏∫‰∏é‰ªÖËß£Á†ÅÂô®Ê®°ÂûãÁõ∏ÊØîÔºåÂÆÉ‰ª¨ËÉΩÂ§üÈÄöËøáÂèåÂêëÊ≥®ÊÑèÂäõÊçïÊçâËØ≠‰πâ„ÄÇ‰ªÖËß£Á†ÅÂô®Ê®°ÂûãÈÄöÂ∏∏‰ΩøÁî®Âõ†ÊûúÊ≥®ÊÑèÂäõÔºåÂè™‰∏é‰πãÂâçÁöÑËØçÂÖÉËøõË°å‰∫§‰∫íÔºõÂõ†Ê≠§ÔºåÂÆÉ‰ª¨Êó†Ê≥ïÊçïÊçâ‰∏∞ÂØåÁöÑËØ≠‰πâÔºåÂ¶Ç‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåËøô‰∏ÄÁÇπÊòØÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Ê®°ÂûãÊâÄËÉΩÂÆûÁé∞ÁöÑ„ÄÇ\n\n### MoEÂ¶Ç‰Ωï‰Ωú‰∏∫ÂµåÂÖ•Ê®°ÂûãÂ∑•‰ΩúÔºü\n\n‰∫∫‰ª¨ÊôÆÈÅçËÆ§‰∏∫Ëß£Á†ÅÂô®Ê®°ÂûãÊó†Ê≥ïÁî®‰∫éÂµåÂÖ•ÊèêÂèñ„ÄÇÁÑ∂ËÄåÔºå‰ΩúËÄÖÂèëÁé∞MoE‰∏≠ÁöÑË∑ØÁî±ÊùÉÈáç‰∏∫Ëß£Á†ÅÂô®ÂµåÂÖ•Êèê‰æõ‰∫Ü‰∫íË°•‰ø°ÊÅØ„ÄÇÊØè‰∏ÄÂ±Ç‰∏≠ÁöÑË∑ØÁî±ÊùÉÈáçÂèçÊò†‰∫ÜÂØπËæìÂÖ•Ê†áËÆ∞ÁöÑÊé®ÁêÜÈÄâÊã©ÔºåÂõ†Ê≠§ÂÆÉÂåÖÂê´‰∫ÜËæìÂÖ•ÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåËÄåÈöêËóèÁä∂ÊÄÅÁöÑÂµåÂÖ•ÂèØËÉΩ‰ºö‰∏¢Â§±„ÄÇÂú®Êï∞Â≠¶ÂÖ¨Âºè‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•ËøôÊ†∑ÊèèËø∞ÂÆÉÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*n6wGCMqAhjBAfLFV47ML1g.png)\n\n*g*ÊòØsoftmaxÂáΩÊï∞Ôºå*H*Ë°®Á§∫ÈöêËóèÁä∂ÊÄÅ„ÄÇÊàë‰ª¨Â∞ÜÊâÄÊúâMoEÂ±ÇÁöÑË∑ØÁî±ÊùÉÈáçËøõË°åËøûÊé•Ôºå‰ª•ÈÅøÂÖç‰∏¢Â§±Ê®°ÂûãÁöÑÊé®ÁêÜÈÄâÊã©„ÄÇ\n\n‰∏∫‰∫ÜÂÖÖÂàÜÂà©Áî®Ë∑ØÁî±ÊùÉÈáçÂíåËß£Á†ÅÂô®ÂµåÂÖ•Ôºå‰ΩúËÄÖÊèêÂá∫‰∫Ü‰∏ÄÁßçÁß∞‰∏∫MoEÂµåÂÖ•ÔºàMoEEÔºâÁöÑÊñπÊ≥ïÔºå‰ª•ÂΩ¢ÊàêÊõ¥ÂÖ®Èù¢ÁöÑÂµåÂÖ•Ë°®Á§∫„ÄÇMoEEÊúâ‰∏§ÁßçÁ±ªÂûã„ÄÇ‰∏ÄÁßçÊñπÊ≥ïÊòØÂü∫‰∫éËøûÊé•ÁöÑÁªÑÂêàÔºåÂÖ∑‰ΩìÂ¶Ç‰∏ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uVmcV-lM83XL7HoYbYjt7w.png)\n\nËøôÁßçÊñπÊ≥ïÂæàÁÆÄÂçïÔºåÊàë‰ª¨Âè™ÈúÄÂ∞ÜË∑ØÁî±ÊùÉÈáçÂíåËß£Á†ÅÂô®ÂµåÂÖ•ËøõË°åËøûÊé•„ÄÇ‰ΩúËÄÖÂ∞ÜËøôÁßçÊñπÊ≥ïÁß∞‰∏∫MoEE(concat)„ÄÇÂÆÉÂèØ‰ª•‰øùÁïôÊØè‰∏™Ë∑ØÁî±ÊùÉÈáçÊçïËé∑ÁöÑÁã¨Áâπ‰ø°ÊÅØÔºåÂêåÊó∂ÂÖÅËÆ∏‰∏ãÊ∏∏‰ªªÂä°Âà©Áî®ÁªÑÂêàË°®Á§∫„ÄÇ\n\nÂè¶‰∏ÄÁßçÊñπÊ≥ïÊòØÂä†ÊùÉÊ±ÇÂíåÈõÜÊàê„ÄÇÂÆÉÂØπ‰ªéË∑ØÁî±ÊùÉÈáçÂíåÈöêËóèÁä∂ÊÄÅÔºàHSÔºâÂµåÂÖ•ËÆ°ÁÆóÁöÑÁõ∏‰ººÊÄßÂàÜÊï∞ËøõË°åÂä†ÊùÉÊ±ÇÂíåÔºåË°®Á§∫‰∏∫MoEE(sum)„ÄÇËØ•ÊñπÊ≥ïÁî®‰∫éÊØîËæÉ‰∏§‰∏™Âè•Â≠êÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇËØ≠‰πâÊñáÊú¨Áõ∏‰ººÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kyJxWW9zdgRyNr2jmO4LlQ.png)\n\nùõÇÊòØ‰∏Ä‰∏™Ë∂ÖÂèÇÊï∞ÔºåÁî®‰∫éÊéßÂà∂Ë∑ØÁî±ÊùÉÈáçÁöÑË¥°ÁåÆ„ÄÇÂú®‰∏∫ÊØèÂØπËÆ°ÁÆóÁõ∏‰ººÊÄßÂàÜÊï∞ÂêéÔºåÊàë‰ª¨ËÆ°ÁÆóËÆ°ÁÆóÂæóÂá∫ÁöÑÁõ∏‰ººÊÄßÂàÜÊï∞‰∏éÁúüÂÆûÁõ∏‰ººÊÄß‰πãÈó¥ÁöÑÁ≠âÁ∫ßÁõ∏ÂÖ≥ÊÄßÔºå‰æãÂ¶ÇÊñØÁöÆÂ∞îÊõºÁ≠âÁ∫ßÁõ∏ÂÖ≥ÊÄß„ÄÇ\n\nÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåÊàëËÆ§‰∏∫MoEE(concat)Êòì‰∫é‰ΩøÁî®„ÄÇÊ≠§Â§ñÔºå‰ΩúËÄÖÂà©Áî®PromptEOLÊäÄÊúØ\\[4]Êù•Â¢ûÂº∫MoEE„ÄÇËØ•ÊäÄÊúØÊèêÁ§∫‰ª•‰∏ãÊ®°ÊùøÔºå‰ª•ÈôêÂà∂LLMsÂú®È¢ÑÊµã‰∏ã‰∏Ä‰∏™Ê†áËÆ∞ÁöÑËØ≠‰πâ‰ø°ÊÅØÊó∂ÁöÑË°å‰∏∫„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S9BASj9JkQe-i4fqmbopWg.png)\n\nÁé∞Âú®ÔºåËøôÈáåÊòØMTEB‰ªªÂä°ÁöÑÊÄßËÉΩË°®„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7LxkEMR2DFlncypF6_T7Vw.png)\n\nÂ∏¶ÊúâPromptEOLÁöÑMoEEÂèØ‰ª•ÊØîÁõëÁù£ÂíåËá™ÁõëÁù£ÊñπÊ≥ïË°®Áé∞Êõ¥Â•Ω„ÄÇËØ∑Ê≥®ÊÑèÔºåËøô‰∏™ÊéíË°åÊ¶ú‰∏çÊòØÊúÄÊñ∞ÁöÑÔºåÂõ†Ê≠§Ëøô‰∏™ÁªìÊûúÂπ∂‰∏çÊòØSOTA„ÄÇËøôÁßçÊñπÊ≥ïÁöÑ‰ª∑ÂÄºÂú®‰∫éÊàë‰ª¨ÂèØ‰ª•Âú®ÂµåÂÖ•‰ªªÂä°‰∏≠Ëé∑Âæó‰∏çÈîôÁöÑÁªìÊûúÔºåÂπ∂‰∏îÂèØ‰ª•Âú®Ê≤°Êúâ‰ªª‰ΩïËøõ‰∏ÄÊ≠•ËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®„ÄÇ\n\nÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊàë‰ª¨Â∑≤ÁªèÊ∂µÁõñ‰∫ÜMoEEÁöÑÂ∑•‰ΩúÂéüÁêÜ„ÄÇÂú®‰∏ã‰∏ÄËäÇ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÂÆûÁé∞MoEE‰∏éBERTopicÂπ∂ÂØπÂè•Â≠êËøõË°åËÅöÁ±ª„ÄÇ\n\n## 3\\. ÂÆûÈôÖÂÆûÊñΩÔºöÂà©Áî® MoEE ‰∏é BERTopic\n\nÂú®Êú¨ËäÇ‰∏≠ÔºåÊàë‰ª¨‰ªéÈ¢ÑËÆ≠ÁªÉÁöÑ MoE LLM ‰∏≠ÊèêÂèñÂµåÂÖ•ÔºåÂπ∂‰ΩøÁî® 20-news-group Êï∞ÊçÆÈõÜ \\[5] ‰∏é [BERTopic](https://maartengr.github.io/BERTopic/index.html) ÁªìÂêà„ÄÇ‰æõÊÇ®ÂèÇËÄÉÔºåBERTopic ÊòØ‰∏Ä‰∏™‰æøÂà©ÁöÑ‰∏ªÈ¢òÂª∫Ê®°Â∫ìÔºåË∂ÖË∂ä‰∫Ü‰º†ÁªüÁöÑÁªüËÆ°‰∏ªÈ¢òÂª∫Ê®°„ÄÇÂÆÉÂà©Áî®Êù•Ëá™ Transformer ÁöÑÂµåÂÖ•ËøõË°å‰∏ªÈ¢òËÅöÁ±ªÔºåÂõ†Ê≠§ÊàëËÆ§‰∏∫ÂÆÉÈÄÇÂêàÁî®‰∫éÊ£ÄÊü•ËÉΩÂäõ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Êù•ÂáÜÂ§á‰∏Ä‰∏™ÁéØÂ¢É„ÄÇ\n\n### ÁéØÂ¢ÉËÆæÁΩÆ\n\nÊàë‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Â∏¶Êúâ Python 3\\.10 ÁöÑ conda ÁéØÂ¢É„ÄÇÊàëÂú® Ubuntu 20\\.04 ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºå‰ΩøÁî® cuda 12\\.4Ôºå16 GB VRAM„ÄÇ‰∏ãËΩΩÊ®°ÂûãÊùÉÈáçÂèØËÉΩÈúÄË¶Å 32 GB RAM„ÄÇ\n\n```python\nconda create -n moee python=3.10 -y\nconda activate moee\n```\n\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÈúÄË¶ÅÈÄöËøá pip ÂÆâË£Ö‰ª•‰∏ãÂ∫ì„ÄÇ\n\n```python\npip install transformers torch bitsandbytes bertopic accelerate\n```\n\nMoE Ê®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅËæÉÈ´òÁöÑ VRAMÔºåÂõ†‰∏∫Êàë‰ª¨ÈúÄË¶ÅÊèêÂâçÂ∞ÜÊï¥‰∏™Ê®°ÂûãÂä†ËΩΩÂà∞ VRAM ‰∏≠„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶Å‰ΩøÁî® bitsandbytesÔºåËøôÊòØ‰∏Ä‰∏™ÈáèÂåñÂåÖÔºå‰ª•ËäÇÁúÅ VRAM ÂÜÖÂ≠ò„ÄÇ\n\nÊàë‰ª¨ÈúÄË¶ÅÂÖãÈöÜÂÆòÊñπ GitHub ‰ªìÂ∫ì„ÄÇ\n\n```python\ngit clone https://github.com/tianyi-lab/MoE-Embedding.git\n```\n\nÊâÄÊúâÂáÜÂ§áÂ∑•‰ΩúÈÉΩÂÆåÊàê‰∫Ü„ÄÇÁé∞Âú®ÔºåËÆ©Êàë‰ª¨‰ΩøÁî® MoEE ÂÆûÁé∞ BERTopic ÁöÑ‰∏ªÈ¢òËÅöÁ±ª„ÄÇ\n\n### Âà©Áî® MoEE Âíå BERTopic\n\nÁé∞Âú®ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî® MoEE ‰Ωú‰∏∫ BERTopic ÁöÑÂµåÂÖ•Ê®°ÂûãÂπ∂Â∞ùËØï‰∏ªÈ¢òËÅöÁ±ª„ÄÇÂéüÂßã‰ª£Á†ÅÂ∫ìÂÖÅËÆ∏Êàë‰ª¨‰ΩøÁî®Â∞èÂûã MoE Ê®°ÂûãÔºå‰æãÂ¶Ç Qwen\\-1\\.5\\-MoE\\-A2\\.7B Êàñ OLMoE\\-1B\\-7B„ÄÇÂú®ËøôÁØáÂçöÂÆ¢‰∏≠ÔºåÊàëÂ∞Ü‰ΩøÁî® OLMoE\\-1B\\-7BÔºåÂÆÉÈÄÇÂêàÂú® 16 GB VRAM ‰∏äËøêË°åÊé®ÁêÜ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅÂä†ËΩΩ OLMoE\\-1B\\-7B„ÄÇ\n\n```python\nkwargs = {\n        \"base_model\": 'allenai/OLMoE-1B-7B-0924',\n        \"normalized\": False,\n        \"torch_dtype\": torch.bfloat16,\n        \"mode\": \"embedding\",\n        \"pooling_method\": \"mean\",\n        \"attn_implementation\": \"sdpa\",\n        \"attn\": \"bbcc\",\n    }\n\nconfig = {\n    'embed_method': 'prompteol',\n    'emb_info': 'MoEE'\n    }\n\nembedding_model = MOEE(model_name_or_path='allenai/OLMoE-1B-7B-0924', **kwargs)\n```\n\nÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆó 20\\-news\\-group Êï∞ÊçÆÈõÜÁöÑÂµåÂÖ•Ôºå‰ª•‰º†ÈÄíÁªô BERTopic„ÄÇÔºàÊàëÁ®çÂêé‰ºöÈôÑ‰∏äÂÆåÊï¥‰ª£Á†Å„ÄÇÔºâ\n\n```python\nfrom sklearn.datasets import fetch_20newsgroups\n\ndocs = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))['data']\n\ndataset = MyDataset(docs)\ndataloader = DataLoader(dataset=dataset, batch_size=8)\nembeddings = None\n\nfor batch in tqdm(dataloader):\n    with torch.no_grad():    \n        embedding = embedding_model.encode(batch, **config)\n      \n        if embeddings is None:\n            embeddings = embedding[0]\n        else:\n            embeddings = np.vstack((embeddings, embedding[0]))\n  \n    torch.cuda.empty_cache()\n```\n\n‰∏∫‰∫ÜÊèêÂâçËÆ°ÁÆóÂµåÂÖ•ÔºåÊàë‰ª¨‰ΩøÁî® torch.utils.data.DataLoader ‰Ωú‰∏∫Ëø≠‰ª£Âô®ÔºåÂπ∂ÂØπÊØè‰∏™ÊâπÊ¨°ÁöÑÊñáÊ°£ËøõË°åÁºñÁ†Å„ÄÇËØ∑Ê≥®ÊÑèÔºåÊàë‰ª¨ÂøÖÈ°ªÂ∞ÜÂµåÂÖ•‰Ωú‰∏∫ np.asarray Á±ªÂûã‰º†ÈÄíÁªô BERTopic„ÄÇ\n\nÂΩìÊÇ®ÊÉ≥‰ΩøÁî®Ëá™Â∑±ÁöÑ MoE Ê®°ÂûãÊó∂ÔºåÂøÖÈ°ªÂÆûÁé∞‰ªéÊØè‰∏™ MoE Â±ÇËé∑ÂèñË∑ØÁî±ÊùÉÈáç„ÄÇÂØπ‰∫éÈöêËóèÁä∂ÊÄÅÂµåÂÖ•ÔºåÊàë‰ª¨ÂèØ‰ª•Âà©Áî® HuggingFace transformer ÂáΩÊï∞„ÄÇÊàë‰ª¨Âè™ÈúÄÂú®Êé®ÁêÜÊó∂‰º†ÈÄí output\\_hidden\\_states\\=True ÂèÇÊï∞„ÄÇ\n\nÁé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•ËøêË°å‰∏ªÈ¢òÂª∫Ê®°„ÄÇ\n\n```python\n## Step 2 - Reduce dimensionality\numap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n\n## Step 3 - Cluster reduced embeddings\nhdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n\n## Step 4 - Tokenize topics\nvectorizer_model = CountVectorizer(stop_words=\"english\")\n\n## Step 5 - Create topic representation\nctfidf_model = ClassTfidfTransformer()\n\n## Step 6 - (Optional) Fine-tune topic representations with \n## a `bertopic.representation` model\nrepresentation_model = KeyBERTInspired()\n\n## All steps together\ntopic_model = BERTopic(\n  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n  ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n  representation_model=representation_model # Step 6 - (Optional) Fine-tune topic representations\n)\n\n## topic modeling using BERTopic model\ntopics, probs = topic_model.fit_transform(docs, embeddings)\n```\n\nÊàë‰ª¨ÈÄöËøáÈªòËÆ§ËÆæÁΩÆÂæóÂà∞‰∫Ü 42 ‰∏™‰∏ªÈ¢òÔºõ‰∏Ä‰∫õÁ§∫‰æãÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇÂ∞ΩÁÆ°ÊàëÈöèÊú∫ÈÄâÊã©‰∫Ü‰∏ªÈ¢òÔºå‰ΩÜÂÆÉËÉΩÂ§üÂæàÂ•ΩÂú∞ÊçïÊçâËØ≠‰πâ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*VIaKHU-PSuTPzOUKDFbwOw.png)\n\nÊ≠§Â§ñÔºåËøôÈáåÊòØ‰∏ªÈ¢òËÅöÁ±ªÂèØËßÜÂåñ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*KYAUOe2qEAv-ihq2S2dM0A.png)\n\nËØ∑Êü•Áúã‰∏ªÈ¢òËÅöÁ±ªÂèØËßÜÂåñ‰∏≠ÁöÑÁ∫¢Ëâ≤ÂúÜÂúà„ÄÇËøô‰∏™Á∫¢Ëâ≤ÂúÜÂúàÊåáÁöÑÊòØ‰∏ªÈ¢ò 0Ôºå‰∏éËÆ°ÁÆóÊú∫Áõ∏ÂÖ≥„ÄÇÊõ¥Êé•ËøëÁöÑ‰∏ªÈ¢ò‰πü‰∏éÊú∫Ê¢∞ËØçÊ±áÁõ∏ÂÖ≥Ôºå‰æãÂ¶ÇÂõæÂΩ¢„ÄÅÊï∞Â≠óÂíåÊâìÂç∞Êú∫„ÄÇ\n\nËøôÁßçÊñπÊ≥ïÂêëÊàë‰ª¨Â±ïÁ§∫‰∫ÜÊàë‰ª¨ÂèØ‰ª•Âú®Ê≤°Êúâ‰ªª‰ΩïËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãËé∑ÂæóËâØÂ•ΩÁöÑÂµåÂÖ•„ÄÇÂ∞ΩÁÆ°Âú®Ë¥®Èáè‰∏ä‰ªçÊúâÊèêÂçáÁ©∫Èó¥Ôºå‰ª•ËææÂà∞ SOTA\\-ÁõëÁù£Ê®°ÂûãÁöÑÊ∞¥Âπ≥Ôºå‰ΩÜÊú¨ÊñáÁöÑÂèëÁé∞ÊòØËøõ‰∏ÄÊ≠•ÊîπÂñÑÂµåÂÖ•ÊèêÂèñÊñπÊ≥ïËÄå‰∏çËøõË°åËÆ≠ÁªÉÁöÑËâØÂ•ΩÊ≠•È™§„ÄÇ\n\nËøôÊòØÊàëÁöÑÂÆåÊï¥‰ª£Á†Å„ÄÇÊÇ®ÈúÄË¶ÅÂ∞ÜÊ≠§Êñá‰ª∂ÊîæÂÖ• MoE\\-Embedding ÁõÆÂΩïÁöÑÈ°∂ÈÉ®„ÄÇ\n\n## ÂèÇËÄÉÊñáÁåÆ\n\n\\[1] Ziyue Li, Tianyi Zhou, [YOUR MIXTURE\\-OF\\-EXPERTS LLM IS SECRETLY AN EMBEDDING MODEL FOR FREE](https://arxiv.org/pdf/2410.10814) (2024\\), *Arxiv*\n\n\\[2] Omar S., et.al., [Mixture of Experts Explained](https://huggingface.co/blog/moe) (2023\\), Hugging Face\n\n\\[3] William Fedus, Barret Zoph., et.al., [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961) (2021\\), *Arxiv*\n\n\\[4] Ting Jiang, et.al., [Scaling Sentence Embeddings with Large Language Models](https://arxiv.org/pdf/2307.16645) (2023\\), *Arxiv*\n\n\\[5] [20 News groups](http://qwone.com/~jason/20Newsgroups/)\n\n\n"},{"lang":"zh","group":"blog","slug":"blog/using-llama-3-for-building-ai-agents-7e74f79d1ccc","frontmatter":{"title":"‰ΩøÁî® Llama 3 ÊûÑÂª∫ AI ‰ª£ÁêÜ","meta_title":"‰ΩøÁî® Llama 3 ÊûÑÂª∫ AI ‰ª£ÁêÜ","description":"‰ΩøÁî® Llama 3 ÂáΩÊï∞Ë∞ÉÁî®ÂäüËÉΩÊûÑÂª∫ AI ‰ª£ÁêÜÁöÑÁªºÂêàÊåáÂçó„ÄÇ","date":"2024-11-10T03:51:17.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EWGo-7t4Kl6l82rB2-ZK9Q.png","categories":["Programming","Generative AI","Chatbots"],"author":"Rifx.Online","tags":["Llama","Gradio","RAG","metadata","indexing"],"draft":false,"slug":"blog/using-llama-3-for-building-ai-agents-7e74f79d1ccc"},"content":"\n\n\n### ÊûÑÂª∫ÂÖ∑Êúâ Llama 3 ÂáΩÊï∞Ë∞ÉÁî®ËÉΩÂäõÁöÑ AI ‰ª£ÁêÜÁöÑÁªºÂêàÊåáÂçó\n\n\n\n### ÂºïË®Ä\n\nÊÉ≥Ë±°‰∏Ä‰∏ã‰Ω†ÊÉ≥‰π∞‰∏Ä‰∫õ‰∏úË•ø„ÄÇ‰Ω†ËÆøÈóÆ‰∏Ä‰∏™ÁîµÂ≠êÂïÜÂä°ÁΩëÁ´ôÔºå‰ΩøÁî®ÊêúÁ¥¢ÈÄâÈ°πÊâæÂà∞‰Ω†ÊÉ≥Ë¶ÅÁöÑ‰∏úË•ø„ÄÇ‰πüËÆ∏‰Ω†ÊúâÂ§ö‰∏™Áâ©ÂìÅË¶ÅË¥≠‰π∞ÔºåÂõ†Ê≠§Ëøô‰∏™ËøáÁ®ãÂπ∂‰∏çÊòØÂæàÈ´òÊïà„ÄÇÁé∞Âú®ËÄÉËôëËøô‰∏™Âú∫ÊôØÔºöÊâìÂºÄ‰∏Ä‰∏™Â∫îÁî®Á®ãÂ∫èÔºåÁî®ÁÆÄÂçïÁöÑËã±ËØ≠ÊèèËø∞‰Ω†ÊÉ≥Ë¶ÅÁöÑ‰∏úË•øÔºåÁÑ∂ÂêéÊåâ‰∏ãÂõûËΩ¶„ÄÇ‰Ω†‰∏çÂøÖÊãÖÂøÉÊêúÁ¥¢Âíå‰ª∑Ê†ºÊØîËæÉÔºåÂõ†‰∏∫Â∫îÁî®Á®ãÂ∫è‰ºöËá™Âä®‰∏∫‰Ω†Â§ÑÁêÜËøô‰∫õ‰∫ãÊÉÖ„ÄÇÂæàÈÖ∑ÔºåÂØπÂêßÔºüËøôÊ≠£ÊòØÊàë‰ª¨Â∞ÜÂú®Êú¨ÊïôÁ®ã‰∏≠ÊûÑÂª∫ÁöÑÂÜÖÂÆπ„ÄÇ\n\nËÆ©Êàë‰ª¨ÂÖàÁúã‰∏Ä‰∫õ‰æãÂ≠ê„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ikbr1ozv37PIB2meVfCCfA.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AZPn3_KCDRV0pAszd3vLmA.png)\n\nÂ•ΩÁöÑÔºåËÆ©Êàë‰ª¨‰∏∫Ëøô‰∏™Â∫îÁî®Á®ãÂ∫èÊ≥®ÂÖ•Ê¥ªÂäõ„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®MetaÁöÑLlama 3Ê®°ÂûãÔºåÂÖ∑ÊúâÂáΩÊï∞Ë∞ÉÁî®ËÉΩÂäõ„ÄÇ‰∏çËøáÔºåËøô‰πüÂèØ‰ª•‰ΩøÁî®3.1Ê®°ÂûãÊù•ÂÆûÁé∞„ÄÇÊ†πÊçÆ[MetaÁöÑÂÖ¨Âëä](https://ai.meta.com/blog/meta-llama-3-1/)Ôºå3.1Ê®°ÂûãÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞‰ΩøÁî®Â∑•ÂÖ∑ÂíåÂáΩÊï∞„ÄÇ\n\n> Ëøô‰∫õÊòØÂ§öËØ≠Ë®ÄÁöÑÔºåÂÖ∑ÊúâÊòæËëóÊõ¥ÈïøÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶128KÔºåÊúÄÂÖàËøõÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõÔºå‰ª•ÂèäÊï¥‰ΩìÊõ¥Âº∫ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ\n\nÊàëÂ∞Ü‰ΩøÁî®Groq CloudÔºåÁâπÂà´ÊòØ‰ªñ‰ª¨ÁöÑÊ®°ÂûãÊù•Êí∞ÂÜôÊú¨Êñá„ÄÇËøô‰∏™Â∫îÁî®Á®ãÂ∫èÁöÑÂàùÂßãÂ∑•‰ΩúÊµÅÁ®ãÂ∫îÁî±‰∏Ä‰∏™ÂµåÂÖ•Ê®°Âûã„ÄÅ‰∏Ä‰∏™Ê£ÄÁ¥¢Âô®Âíå‰∏§‰∏™‰∏ªË¶ÅÂ∑•ÂÖ∑ÁªÑÊàêÔºåÁî®‰∫éÂ§ÑÁêÜÁî®Êà∑ÁöÑË¥≠‰π∞ÂÖ¥Ë∂£Âíå‰∏éÊàêÊú¨Áõ∏ÂÖ≥ÁöÑÂÖ≥Ê≥®„ÄÇÊÄª‰πãÔºåÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∫õÁ±ª‰ºº‰∫é‰∏ãÈù¢ÂõæË°®‰∏≠ÊèèËø∞ÁöÑÂÜÖÂÆπ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EZVySX3GD2O07fzEPwLcbQ.png)\n\nÁé∞Âú®Êàë‰ª¨ÈúÄË¶Å‰ΩøÁî®LLMÁºñÊéíÊ°ÜÊû∂„ÄÇ‰∏∫Ê≠§ÔºåÊàëÈÄâÊã©Êàë‰∏ÄÁõ¥‰ª•Êù•ÊúÄÂñúÊ¨¢ÁöÑ[Haystack](https://haystack.deepset.ai/)„ÄÇ\n\nÂ•ΩÁöÑÔºåÊàë‰ª¨ÂæóÂà∞‰∫ÜÊàë‰ª¨ÈúÄË¶ÅÁöÑ‰∏úË•ø„ÄÇËÆ©Êàë‰ª¨Ë∑≥ÂÖ•ÂÆûÈôÖÂ∑•‰ΩúÂêßÔºÅ\n\n### Âä†ËΩΩÂíåÁ¥¢ÂºïÊï∞ÊçÆ\n\nÁî±‰∫éÊàë‰ª¨Êúâ‰∏Ä‰∏™ RAG ÊµÅÊ∞¥Á∫øÔºåÂ∫îËØ•Â∞ÜÊûÑÂª∫ÊñáÊ°£Á¥¢ÂºïÊúçÂä°‰Ωú‰∏∫Á¨¨‰∏ÄÊ≠•„ÄÇÂØπ‰∫éËøô‰∏™ÊºîÁ§∫ÔºåÊàëÂ∞Ü‰ΩøÁî® Haystack Êèê‰æõÁöÑÂÜÖÂ≠òÂêëÈáèÊï∞ÊçÆÂ∫ì„ÄÇËØ∑Ê≥®ÊÑèÔºåÊàë‰ª¨ÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠ÁöÑÊØè‰∏™ÊñáÊ°£ÂåÖÂê´Ôºö\n\n* ÂÜÖÂÆπ ‚Äî Êàë‰ª¨Áî®ÂÆÉÊù•ÊâßË°åÁõ∏‰ººÊÄßÊêúÁ¥¢\n* Id ‚Äî ÂîØ‰∏ÄÊ†áËØÜÁ¨¶\n* ‰ª∑Ê†º ‚Äî ‰∫ßÂìÅ‰ª∑Ê†º\n* URL ‚Äî ‰∫ßÂìÅ URL\n\nÂΩìÊàë‰ª¨ÁöÑ RAG ÊµÅÊ∞¥Á∫øË¢´Ë∞ÉÁî®Êó∂ÔºåÂÜÖÂÆπÂ≠óÊÆµÁî®‰∫éÂêëÈáèÊêúÁ¥¢„ÄÇÊâÄÊúâÂÖ∂‰ªñÂ≠óÊÆµ‰Ωú‰∏∫ÂÖÉÊï∞ÊçÆÂåÖÂê´„ÄÇ‰øùÁïôËøô‰∫õÂÖÉÊï∞ÊçÆËá≥ÂÖ≥ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÆÉÂØπÂâçÁ´ØÂëàÁé∞ÁªôÁî®Êà∑ÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑ„ÄÇ\n\nËÆ©Êàë‰ª¨ÁúãÁúãÂ¶Ç‰ΩïÂÆûÁé∞Ëøô‰∏ÄÁÇπ„ÄÇ\n\n```python\nfrom haystack import Pipeline, Document\nfrom haystack.document_stores.in_memory import InMemoryDocumentStore\nfrom haystack.components.writers import DocumentWriter\nfrom haystack.components.embedders import SentenceTransformersDocumentEmbedder\nfrom haystack.components.generators import OpenAIGenerator\nfrom haystack.utils import Secret\nfrom haystack.components.generators.chat import OpenAIChatGenerator\nfrom haystack.components.builders import PromptBuilder\nfrom haystack.components.embedders import SentenceTransformersTextEmbedder\nfrom haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\nfrom haystack.dataclasses import ChatMessage\nimport pandas as pd\n\n## Load product data from CSV\ndf = pd.read_csv(\"product_sample.csv\")\n\n## Initialize an in-memory document store\ndocument_store = InMemoryDocumentStore()\n\n## Convert the product data into Haystack Document objects\ndocuments = [\n    Document(\n        content=item.product_name, \n        meta={\n            \"id\": item.uniq_id, \n            \"price\": item.selling_price, \n            \"url\": item.product_url\n        }\n    ) for item in df.itertuples()\n]\n\n## Create a pipeline for indexing the documents\nindexing_pipeline = Pipeline()\n\n## Add a document embedder to the pipeline using Sentence Transformers model\nindexing_pipeline.add_component(\n    instance=SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"), name=\"doc_embedder\"\n)\n\n## Add a document writer to the pipeline to store documents in the document store\nindexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"doc_writer\")\n\n## Connect the embedder's output to the writer's input\nindexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n\n## Run the indexing pipeline to process and store the documents\nindexing_pipeline.run({\"doc_embedder\": {\"documents\": documents}})\n```\nÂæàÂ•ΩÔºåÊàë‰ª¨Â∑≤ÂÆåÊàê AI ‰ª£ÁêÜÂ∫îÁî®Á®ãÂ∫èÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇÁé∞Âú®ÊòØÊó∂ÂÄôÊûÑÂª∫‰∫ßÂìÅËØÜÂà´Â∑•ÂÖ∑‰∫Ü„ÄÇ‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÁêÜËß£‰∫ßÂìÅËØÜÂà´Âô®ÁöÑ‰∏ªË¶Å‰ªªÂä°ÔºåËÆ©Êàë‰ª¨ËÄÉËôë‰∏ãÈù¢ÁöÑÁ§∫‰æã„ÄÇ\n\n> Áî®Êà∑Êü•ËØ¢ÔºöÊàëÊÉ≥‰π∞‰∏ÄÂèåÈú≤Ëê•Èù¥„ÄÅ‰∏ÄÂè∞ÁÇ≠ÁÉ§ÁÇâÂíå‰∏Ä‰∏™ Google Pixel 9 ÁöÑÊâãÊú∫Â£≥„ÄÇËÆ©Êàë‰ª¨ÁêÜËß£‰∫ßÂìÅËØÜÂà´ÂäüËÉΩÁöÑÁêÜÊÉ≥Â∑•‰ΩúÊµÅÁ®ã„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kXGYjlMi4pQcqIKpmUZLRQ.png)\n\nÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅÂàõÂª∫‰∏Ä‰∏™Â∑•ÂÖ∑Êù•ÂàÜÊûêÁî®Êà∑Êü•ËØ¢Âπ∂ËØÜÂà´Áî®Êà∑ÊÑüÂÖ¥Ë∂£ÁöÑ‰∫ßÂìÅ„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÁâáÊÆµÊûÑÂª∫ËøôÊ†∑ÁöÑÂ∑•ÂÖ∑„ÄÇ\n\n### ÊûÑÂª∫Áî®Êà∑Êü•ËØ¢ÂàÜÊûêÂô®\n\n\n```python\ntemplate = \"\"\"\nUnderstand the user query and list of products the user is interested in and return product names as list.\nYou should always return a Python list. Do not return any explanation.\n\nExamples:\nQuestion: I am interested in camping boots, charcoal and disposable rain jacket.\nAnswer: [\"camping_boots\",\"charcoal\",\"disposable_rain_jacket\"]\n\nQuestion: Need a laptop, wireless mouse, and noise-cancelling headphones for work.\nAnswer: [\"laptop\",\"wireless_mouse\",\"noise_cancelling_headphones\"]\n\nQuestion: {{ question }}\nAnswer:\n\"\"\"\n\nproduct_identifier = Pipeline()\n\nproduct_identifier.add_component(\"prompt_builder\", PromptBuilder(template=template))\nproduct_identifier.add_component(\"llm\", generator())\n\nproduct_identifier.connect(\"prompt_builder\", \"llm\")\n```\nÂ•ΩÁöÑÔºåÁé∞Âú®Êàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÁ¨¨‰∏Ä‰∏™ÂáΩÊï∞ÁöÑ‰∏ÄÂçäÔºåÁé∞Âú®ÊòØÊó∂ÂÄôÈÄöËøáÊ∑ªÂä†RAGÁÆ°ÈÅìÊù•ÂÆåÊàêËøô‰∏™ÂáΩÊï∞„ÄÇ \n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JyxINdc8Wz-qAg_PCAkLbA.png)\n\n### ÂàõÂª∫ RAG ÁÆ°ÈÅì\n\n\n```python\ntemplate = \"\"\"\nReturn product name, price, and url as a python dictionary. \nYou should always return a Python dictionary with keys price, name and url for single product.\nYou should always return a Python list of dictionaries with keys price, name and url for multiple products.\nDo not return any explanation.\n\nLegitimate Response Schema:\n{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"}\nLegitimate Response Schema for multiple products:\n[{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"},{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"}]\n\nContext:\n{% for document in documents %}\n    product_price: {{ document.meta['price'] }}\n    product_url: {{ document.meta['url'] }}\n    product_id: {{ document.meta['id'] }}\n    product_name: {{ document.content }}\n{% endfor %}\nQuestion: {{ question }}\nAnswer:\n\"\"\"\n\nrag_pipe = Pipeline()\nrag_pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\nrag_pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))\nrag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\nrag_pipe.add_component(\"llm\", generator())\n\nrag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\nrag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\nrag_pipe.connect(\"prompt_builder\", \"llm\")\n```\nÂú®Ëøô‰∏™Èò∂ÊÆµÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫Ü RAG ÂíåÊü•ËØ¢ÂàÜÊûêÂô®ÁÆ°ÈÅì„ÄÇÁé∞Âú®ÊòØÊó∂ÂÄôÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Â∑•ÂÖ∑‰∫Ü„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Â∏∏ËßÑÁöÑÂáΩÊï∞Â£∞ÊòéÔºåÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇ‰∏∫‰ª£ÁêÜÂàõÂª∫Â∑•ÂÖ∑Â∞±ÂÉèÂàõÂª∫‰∏Ä‰∏™ Python ÂáΩÊï∞„ÄÇÂ¶ÇÊûú‰Ω†ÊúâËøôÊ†∑ÁöÑÈóÆÈ¢ò\n\n\n> ‰ª£ÁêÜÂ¶Ç‰ΩïË∞ÉÁî®Ëøô‰∏™ÂáΩÊï∞Ôºü\n\nËß£ÂÜ≥ÊñπÊ°àÂæàÁÆÄÂçïÔºöÈÄöËøáÂà©Áî®ÁâπÂÆöÊ®°ÂûãÁöÑÂ∑•ÂÖ∑Êû∂ÊûÑÔºåÊàë‰ª¨ËÆ°ÂàíÂú®Êú™Êù•ÁöÑÊ≠•È™§‰∏≠Á∫≥ÂÖ•„ÄÇÁõÆÂâçÔºåÊòØÊó∂ÂÄôÂàõÂª∫‰∏Ä‰∏™ÂåÖË£ÖÂáΩÊï∞ÔºåÊó¢‰ΩøÁî®Êü•ËØ¢ÂàÜÊûêÂô®Âèà‰ΩøÁî® RAG ÁÆ°ÈÅì„ÄÇ\n\nËÆ©Êàë‰ª¨ÊòéÁ°ÆËøô‰∏™ÂáΩÊï∞ÁöÑÁõÆÊ†á„ÄÇ\n\n**ÁõÆÊ†á 1Ôºö** Á°ÆÂÆöÁî®Êà∑ÊÑüÂÖ¥Ë∂£ÁöÑÊâÄÊúâ‰∫ßÂìÅÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨‰Ωú‰∏∫ÂàóË°®ËøîÂõû„ÄÇ **ÁõÆÊ†á 2Ôºö** ÂØπ‰∫éÊØè‰∏™ËØÜÂà´ÁöÑ‰∫ßÂìÅÔºå‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢ÊúÄÂ§ö‰∫î‰∏™‰∫ßÂìÅÂèäÂÖ∂ÂÖÉÊï∞ÊçÆ„ÄÇ\n\n### ÂÆåÊàê‰∫ßÂìÅËØÜÂà´ÂäüËÉΩ\n\n\n```python\ndef product_identifier_func(query: str):\n    \"\"\"\n    Ê†πÊçÆÁªôÂÆöÁöÑÊü•ËØ¢ËØÜÂà´‰∫ßÂìÅÂπ∂Ê£ÄÁ¥¢ÊØè‰∏™ËØÜÂà´‰∫ßÂìÅÁöÑÁõ∏ÂÖ≥ÁªÜËäÇ„ÄÇ\n\n    ÂèÇÊï∞Ôºö\n    query (str): Áî®‰∫éËØÜÂà´‰∫ßÂìÅÁöÑÊü•ËØ¢Â≠óÁ¨¶‰∏≤„ÄÇ\n\n    ËøîÂõûÔºö\n    dict: ‰∏Ä‰∏™Â≠óÂÖ∏ÔºåÈîÆ‰∏∫‰∫ßÂìÅÂêçÁß∞ÔºåÂÄº‰∏∫ÊØè‰∏™‰∫ßÂìÅÁöÑËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇÂ¶ÇÊûúÊú™ÊâæÂà∞‰∫ßÂìÅÔºåÂàôËøîÂõû‚ÄúNo product found‚Äù„ÄÇ\n    \"\"\"\n    product_understanding = product_identifier.run({\"prompt_builder\": {\"question\": query}})\n\n    try:\n        product_list = literal_eval(product_understanding[\"llm\"][\"replies\"][0])\n    except:\n        return \"No product found\"\n\n    results = {}\n\n    for product in product_list:\n        response = rag_pipe.run({\"embedder\": {\"text\": product}, \"prompt_builder\": {\"question\": product}})\n        try:\n            results[product] = literal_eval(response[\"llm\"][\"replies\"][0])\n        except:\n            results[product] = {}\n    \n    return results\n```\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HWRTdWvvcw2MZP4uoaQdeQ.png)\n\nËá≥Ê≠§ÔºåÊàë‰ª¨ÂÆåÊàê‰∫Ü‰ª£ÁêÜÁöÑÁ¨¨‰∏Ä‰∏™Â∑•ÂÖ∑„ÄÇËÆ©Êàë‰ª¨ÁúãÁúãÂÆÉÊòØÂê¶ÊåâÈ¢ÑÊúüÂ∑•‰Ωú„ÄÇ\n\n\n```python\nquery = \"I want crossbow and woodstock puzzle\"\n#execute function\nproduct_identifier_func(query)\n\n## {'crossbow': {'name': 'DB Longboards CoreFlex Crossbow 41\" Bamboo Fiberglass '\n##                        'Longboard Complete',\n##                'price': 237.68,\n##                'url': 'https://www.amazon.com/DB-Longboards-CoreFlex-Fiberglass-Longboard/dp/B07KMVJJK7'},\n##  'woodstock_puzzle': {'name': 'Woodstock- Collage 500 pc Puzzle',\n##                       'price': 17.49,\n##                       'url': 'https://www.amazon.com/Woodstock-Collage-500-pc-Puzzle/dp/B07MX21WWX'}}\n```\nÂÆÉÂ∑•‰Ωú‰∫ÜÔºÅÔºÅÁÑ∂ËÄåÔºåÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØËøîÂõûËæìÂá∫ÁöÑÁªìÊûÑ„ÄÇÊÇ®ÂèØ‰ª•Âú®‰∏ãÈù¢ÁúãÂà∞‰∏ÄËà¨ÁöÑÁªìÊûÑ„ÄÇ\n\n\n```python\n{\n    \"product_key\": {\n        \"name\": \"string\",\n        \"price\": \"float\",\n        \"url\": \"string\"\n    }\n}\n```\nËøôÊ≠£ÊòØÊàë‰ª¨Âú®RAGÁÆ°ÈÅì‰∏≠Âª∫ËÆÆÊ®°ÂûãÁîüÊàêÁöÑÂÜÖÂÆπ„ÄÇ‰∏ã‰∏ÄÊ≠•ÔºåËÆ©Êàë‰ª¨ÊûÑÂª∫‰∏Ä‰∏™Âêç‰∏∫`find_budget_friendly_option`ÁöÑÂèØÈÄâÂ∑•ÂÖ∑„ÄÇ\n\n\n```python\ndef find_budget_friendly_option(selected_product_details):\n    \"\"\"\n    ‰∏∫ÊØè‰∏™‰∫ßÂìÅÁ±ªÂà´ÊâæÂà∞ÊúÄÂÖ∑È¢ÑÁÆóÂèãÂ•ΩÁöÑÈÄâÈ°π„ÄÇ\n\n    ÂèÇÊï∞Ôºö\n    selected_product_details (dict): ‰∏Ä‰∏™Â≠óÂÖ∏ÔºåÈîÆ‰∏∫‰∫ßÂìÅÁ±ªÂà´ÔºåÂÄº‰∏∫‰∫ßÂìÅËØ¶ÁªÜ‰ø°ÊÅØÁöÑÂàóË°®„ÄÇÊØè‰∏™‰∫ßÂìÅËØ¶ÁªÜ‰ø°ÊÅØÂ∫î‰∏∫ÂåÖÂê´‚Äúprice‚ÄùÈîÆÁöÑÂ≠óÂÖ∏„ÄÇ\n\n    ËøîÂõûÔºö\n    dict: ‰∏Ä‰∏™Â≠óÂÖ∏ÔºåÈîÆ‰∏∫‰∫ßÂìÅÁ±ªÂà´ÔºåÂÄº‰∏∫ÊØè‰∏™Á±ªÂà´ÊúÄÂÖ∑È¢ÑÁÆóÂèãÂ•ΩÁöÑ‰∫ßÂìÅËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ\n    \"\"\"\n    budget_friendly_options = {}\n    \n    for category, items in selected_product_details.items():\n        if isinstance(items, list):\n            lowest_price_item = min(items, key=lambda x: x['price'])\n        else:\n            lowest_price_item = items\n        \n        budget_friendly_options[category] = lowest_price_item\n    \n    return budget_friendly_options\n```\nÂ•ΩÁöÑÔºåËÆ©Êàë‰ª¨‰∏ìÊ≥®‰∫éËøô‰∏™Â∫îÁî®Á®ãÂ∫èÊúÄÂÖ≥ÈîÆÁöÑÊñπÈù¢ÔºåÂç≥‰Ωø‰ª£ÁêÜÊ†πÊçÆÈúÄË¶Å‰ΩøÁî®Ëøô‰∫õÂäüËÉΩ„ÄÇÊ≠£Â¶ÇÊàë‰ª¨‰πãÂâçÊâÄËÆ®ËÆ∫ÁöÑÔºåËøôÂèØ‰ª•ÈÄöËøáÊ®°ÂûãÁâπÂÆöÁöÑÂ∑•ÂÖ∑Êû∂ÊûÑÊù•ÂÆûÁé∞„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶ÅÊâæÂà∞ÁâπÂÆö‰∫éÊâÄÈÄâÊ®°ÂûãÁöÑÂ∑•ÂÖ∑Êû∂ÊûÑ„ÄÇÂπ∏ËøêÁöÑÊòØÔºåÂÆÉÂú®Ê®°ÂûãÂç°‰∏≠ÊèêÂà∞ [ËøôÈáå](https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use)„ÄÇÊàë‰ª¨ÈúÄË¶ÅË∞ÉÊï¥ÂÆÉ‰ª•ÈÄÇÂ∫îÊàë‰ª¨ÁöÑÁî®‰æã„ÄÇ\n\n### ÂÆåÊàêËÅäÂ§©Ê®°Êùø\n\n\n```python\nchat_template = '''<|start_header_id|>system<|end_header_id|>\n\nYou are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n<tool_call>\n{\"name\": <function-name>,\"arguments\": <args-dict>}\n</tool_call>\n\nHere are the available tools:\n<tools>\n    {\n        \"name\": \"product_identifier_func\",\n        \"description\": \"To understand user interested products and its details\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to use in the search. Infer this from the user's message. It should be a question or a statement\"\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    {\n        \"name\": \"find_budget_friendly_option\",\n        \"description\": \"Get the most cost-friendly option. If selected_product_details has morethan one key this should return most cost-friendly options\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"selected_product_details\": {\n                    \"type\": \"dict\",\n                    \"description\": \"Input data is a dictionary where each key is a category name, and its value is either a single dictionary with 'price', 'name', and 'url' keys or a list of such dictionaries; example: {'category1': [{'price': 10.5, 'name': 'item1', 'url': 'http://example.com/item1'}, {'price': 8.99, 'name': 'item2', 'url': 'http://example.com/item2'}], 'category2': {'price': 15.0, 'name': 'item3', 'url': 'http://example.com/item3'}}\"\n                }\n            },\n            \"required\": [\"selected_product_details\"]\n        }\n    }\n</tools><|eot_id|><|start_header_id|>user<|end_header_id|>\n\nI need to buy a crossbow<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n<tool_call>\n{\"id\":\"call_deok\",\"name\":\"product_identifier_func\",\"arguments\":{\"query\":\"I need to buy a crossbow\"}}\n</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n\n<tool_response>\n{\"id\":\"call_deok\",\"result\":{'crossbow': {'price': 237.68,'name': 'crossbow','url': 'https://www.amazon.com/crossbow/dp/B07KMVJJK7'}}}\n</tool_response><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n'''\nÁé∞Âú®Âè™Ââ©‰∏ãÂá†‰∏™Ê≠•È™§„ÄÇÂú®ÂÅö‰ªª‰Ωï‰∫ãÊÉÖ‰πãÂâçÔºåËÆ©Êàë‰ª¨ÊµãËØï‰∏Ä‰∏ãÊàë‰ª¨ÁöÑ‰ª£ÁêÜ„ÄÇ\n\n\n```python\n### ÊµãËØï‰ª£ÁêÜ\nmessages = [\n    ChatMessage.from_system(\n        chat_template\n    ),\n    ChatMessage.from_user(\"I need to buy a crossbow for my child and Pok√©mon for myself.\"),\n]\n\nchat_generator = get_chat_generator()\nresponse = chat_generator.run(messages=messages)\npprint(response)\n\n### response\n{'replies': [ChatMessage(content='<tool_call>\\n'\n                                 '{\"id\": 0, \"name\": \"product_identifier_func\", '\n                                 '\"arguments\": {\"query\": \"I need to buy a '\n                                 'crossbow for my child\"}}\\n'\n                                 '</tool_call>\\n'\n                                 '<tool_call>\\n'\n                                 '{\"id\": 1, \"name\": \"product_identifier_func\", '\n                                 '\"arguments\": {\"query\": \"I need to buy a '\n                                 'Pokemon for myself\"}}\\n'\n                                 '</tool_call>',\n                         role=<ChatRole.ASSISTANT: 'assistant'>,\n                         name=None,\n                         meta={'finish_reason': 'stop',\n                               'index': 0,\n                               'model': 'llama3-groq-70b-8192-tool-use-preview',\n                               'usage': {'completion_time': 0.217823967,\n                                         'completion_tokens': 70,\n                                         'prompt_time': 0.041348261,\n                                         'prompt_tokens': 561,\n                                         'total_time': 0.259172228,\n                                         'total_tokens': 631}})]}\n```\nÂà∞Ê≠§‰∏∫Ê≠¢ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÂ§ßÁ∫¶90%ÁöÑÂ∑•‰Ωú„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nYVXcgpm3RZ3g5h5d4UK_A.png)\n\nÂú®‰∏äÈù¢ÁöÑÂìçÂ∫î‰∏≠ÔºåÊÇ®ÂèØËÉΩÊ≥®ÊÑèÂà∞XMLÊ†áÁ≠æ`<tool_call>`Â∞ÅÈó≠‰∫ÜÂ∑•ÂÖ∑Ë∞ÉÁî®„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶ÅÂºÄÂèë‰∏ÄÁßçÊú∫Âà∂Êù•ÊèêÂèñtool_callÂØπË±°„ÄÇ\n\n\n```python\ndef extract_tool_calls(tool_calls_str):\n    json_objects = re.findall(r'<tool_call>(.*?)</tool_call>', tool_calls_str, re.DOTALL)\n    \n    result_list = [json.loads(obj) for obj in json_objects]\n    \n    return result_list\n\navailable_functions = {\n    \"product_identifier_func\": product_identifier_func, \n    \"find_budget_friendly_option\": find_budget_friendly_option\n    }\n```\nÂÆåÊàêËøô‰∏ÄÊ≠•ÂêéÔºåÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•ËÆøÈóÆ‰ª£ÁêÜÁöÑÂìçÂ∫îÔºåÂΩìÂÆÉË∞ÉÁî®‰∏Ä‰∏™Â∑•ÂÖ∑Êó∂„ÄÇÁé∞Âú®ÂîØ‰∏ÄÂæÖÂÅöÁöÑÂ∞±ÊòØËé∑ÂèñÂ∑•ÂÖ∑Ë∞ÉÁî®ÂØπË±°Âπ∂Áõ∏Â∫îÂú∞ÊâßË°åÂáΩÊï∞„ÄÇËÆ©Êàë‰ª¨ÂÆåÊàêÈÇ£ÈÉ®ÂàÜ„ÄÇ\n\n\n```python\nmessages.append(ChatMessage.from_user(message))\nresponse = chat_generator.run(messages=messages)\n\nif response and \"<tool_call>\" in response[\"replies\"][0].content:\n    function_calls = extract_tool_calls(response[\"replies\"][0].content)\n    for function_call in function_calls:\n        # Parse function calling information\n        function_name = function_call[\"name\"]\n        function_args = function_call[\"arguments\"]\n\n        # Find the corresponding function and call it with the given arguments\n        function_to_call = available_functions[function_name]\n        function_response = function_to_call(**function_args)\n\n        # Append function response to the messages list using `ChatMessage.from_function`\n        messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\n        response = chat_generator.run(messages=messages)\n```\nÁé∞Âú®ÊòØÊó∂ÂÄôÂ∞ÜÊØè‰∏™ÁªÑ‰ª∂ÁªÑÂêàÂú®‰∏ÄËµ∑ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂêàÈÄÇÁöÑËÅäÂ§©Â∫îÁî®Á®ãÂ∫è„ÄÇÊàëÂ∞Ü‰ΩøÁî®GradioÊù•ÂÆûÁé∞Ëøô‰∏™ÁõÆÁöÑ„ÄÇ\n\n\n```python\nimport gradio as gr\n\nmessages = [ChatMessage.from_system(chat_template)]\nchat_generator = get_chat_generator()\n\ndef chatbot_with_fc(message, messages):\n    messages.append(ChatMessage.from_user(message))\n    response = chat_generator.run(messages=messages)\n\n    while True:\n        if response and \"<tool_call>\" in response[\"replies\"][0].content:\n            function_calls = extract_tool_calls(response[\"replies\"][0].content)\n            for function_call in function_calls:\n                # Parse function calling information\n                function_name = function_call[\"name\"]\n                function_args = function_call[\"arguments\"]\n\n                # Find the corresponding function and call it with the given arguments\n                function_to_call = available_functions[function_name]\n                function_response = function_to_call(**function_args)\n\n                # Append function response to the messages list using `ChatMessage.from_function`\n                messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\n                response = chat_generator.run(messages=messages)\n\n        # Regular Conversation\n        else:\n            messages.append(response[\"replies\"][0])\n            break\n    return response[\"replies\"][0].content\n\n\ndef chatbot_interface(user_input, state):\n    response_content = chatbot_with_fc(user_input, state)\n    return response_content, state\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# AI Ë¥≠‰π∞Âä©Êâã\")\n    gr.Markdown(\"ÈóÆÊàëÂÖ≥‰∫éÊÇ®ÊÉ≥Ë¥≠‰π∞ÁöÑ‰∫ßÂìÅÔºÅ\")\n    \n    state = gr.State(value=messages)\n    \n    with gr.Row():\n        user_input = gr.Textbox(label=\"ÊÇ®ÁöÑÊ∂àÊÅØÔºö\")\n        response_output = gr.Markdown(label=\"ÂõûÂ§çÔºö\")\n    \n    user_input.submit(chatbot_interface, [user_input, state], [response_output, state])\n    gr.Button(\"ÂèëÈÄÅ\").click(chatbot_interface, [user_input, state], [response_output, state])\n\n\ndemo.launch()\n```\nÂ∞±ËøôÊ†∑ÔºÅÊàë‰ª¨ÊûÑÂª∫‰∫ÜÂü∫‰∫éLlama 3ÁöÑAI‰ª£ÁêÜü§ñÔºåÂÖ∑Â§áÂáΩÊï∞Ë∞ÉÁî®ËÉΩÂäõ„ÄÇÊÇ®ÂèØ‰ª•‰ªéËøô‰∏™[GitHub‰ªìÂ∫ì](https://github.com/Ransaka/ai-agents-with-llama3)ËÆøÈóÆÂÆåÊï¥‰ª£Á†Å„ÄÇÊÑüË∞¢ÊÇ®ÁöÑÈòÖËØª„ÄÇ\n\nÈÄöËøá[Ëøô‰∏™](https://www.kaggle.com/datasets/promptcloud/amazon-product-dataset-2020)KaggleÈìæÊé•ÔºàÂú®CC0ÔºöÂÖ¨ÂÖ±È¢ÜÂüü‰∏ãÔºâÂèØ‰ª•ËÆøÈóÆÊú¨Êñá‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜ„ÄÇ\n\n### ÁªìËÆ∫\n\nÂú®ÊûÑÂª∫Âü∫‰∫éAI‰ª£ÁêÜÁöÑÁ≥ªÁªüÊó∂ÔºåËÄÉËôëÂÆåÊàê‰ªªÂä°ÊâÄÈúÄÁöÑÊó∂Èó¥ÂíåÊØè‰∏™‰ªªÂä°‰ΩøÁî®ÁöÑAPIË∞ÉÁî®Ôºà‰ª§ÁâåÔºâÊï∞ÈáèÈùûÂ∏∏ÈáçË¶Å„ÄÇ‰∏Ä‰∏™‰∏ªË¶ÅÁöÑÊåëÊàòÊòØÂáèÂ∞ëÁ≥ªÁªü‰∏≠ÁöÑÂπªËßâÔºåËøôÊòØ‰∏Ä‰∏™Ê¥ªË∑ÉÁöÑÁ†îÁ©∂È¢ÜÂüü„ÄÇÂõ†Ê≠§ÔºåÊûÑÂª∫LLMÂíå‰ª£ÁêÜÁ≥ªÁªüÊ≤°ÊúâÂõ∫ÂÆöÁöÑËßÑÂàô„ÄÇÂøÖÈ°ªËÄêÂøÉËÄåÊúâÁ≠ñÁï•Âú∞Â∑•‰ΩúÔºå‰ª•Á°Æ‰øùAI‰ª£ÁêÜÔºåÂç≥LLMÔºåÊ≠£Â∏∏ËøêË°å„ÄÇ\n\n*Èô§ÈùûÂè¶ÊúâËØ¥ÊòéÔºåÊâÄÊúâÂõæÁâáÂùáÁî±‰ΩúËÄÖÊèê‰æõ„ÄÇ*\n\n### ÂèÇËÄÉÔºö\n\n[https://docs.together.ai/docs/llama\\-3\\-function\\-calling](https://docs.together.ai/docs/llama-3-function-calling)\n\n"},{"lang":"zh","group":"blog","slug":"blog/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557","frontmatter":{"title":"ÂèØËßÜÂåñ‰Ω†ÁöÑ RAG Êï∞ÊçÆ‚Äî‚Äî‰ΩøÁî® Ragas ËØÑ‰º∞‰Ω†ÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÁ≥ªÁªü","meta_title":"ÂèØËßÜÂåñ‰Ω†ÁöÑ RAG Êï∞ÊçÆ‚Äî‚Äî‰ΩøÁî® Ragas ËØÑ‰º∞‰Ω†ÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÁ≥ªÁªü","description":"Â¶Ç‰Ωï‰ΩøÁî® UMAP ÈôçÁª¥ÂØπÂµåÂÖ•ËøõË°åÂ§ÑÁêÜ‰ª•ÊòæÁ§∫Â§ö‰∏™ËØÑ‰º∞ÈóÆÈ¢òÂèäÂÖ∂‰∏éÊ∫êÊñáÊ°£ÁöÑÂÖ≥Á≥ª‚Ä¶‚Ä¶","date":"2024-11-04T12:35:56.000Z","image":"https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*peWTe1A-MqeROT_Jdof_Cw.gif","categories":["Natural Language Processing","Generative AI","Data Science"],"author":"Rifx.Online","tags":["RAG","UMAP","embeddings","evaluation","visualization"],"draft":false,"slug":"blog/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557"},"content":"\n\n\n### Â¶Ç‰Ωï‰ΩøÁî® UMAP ÈôçÁª¥Â∞ÜÂµåÂÖ•ÂèØËßÜÂåñ‰ª•Â±ïÁ§∫Â§ö‰∏™ËØÑ‰º∞ÈóÆÈ¢òÂèäÂÖ∂‰∏éÊ∫êÊñáÊ°£ÁöÑÂÖ≥Á≥ªÔºåÁªìÂêà Ragas„ÄÅOpenAI„ÄÅLangchain Âíå ChromaDB\n\nÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÂú® LLM ÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Â¢ûÂä†‰∫Ü‰∏Ä‰∏™Ê£ÄÁ¥¢Ê≠•È™§Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®ÂõûÁ≠îÈóÆÈ¢òÂíåÊü•ËØ¢Êó∂Ôºå‰ªéÁßÅ‰∫∫ÊñáÊ°£Á≠âÈ¢ùÂ§ñÊù•Ê∫êÊü•ËØ¢Áõ∏ÂÖ≥Êï∞ÊçÆ \\[1]„ÄÇËØ•Â∑•‰ΩúÊµÅÁ®ã‰∏çÈúÄË¶ÅÂØπÈ¢ùÂ§ñÊñáÊ°£ËøõË°åÊòÇË¥µÁöÑËÆ≠ÁªÉÊàñÂæÆË∞É„ÄÇÊñáÊ°£Ë¢´ÊãÜÂàÜÊàêÁâáÊÆµÔºåÁÑ∂ÂêéËøõË°åÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ΩøÁî®Á¥ßÂáëÁöÑ ML ÁîüÊàêÁöÑÂêëÈáèË°®Á§∫ÔºàÂµåÂÖ•Ôºâ„ÄÇÂÜÖÂÆπÁõ∏‰ººÁöÑÁâáÊÆµÂú®Ëøô‰∏™ÂµåÂÖ•Á©∫Èó¥‰∏≠‰ºöÂΩºÊ≠§Èù†Ëøë„ÄÇ\n\nRAG Â∫îÁî®Â∞ÜÁî®Êà∑Êèê‰æõÁöÑÈóÆÈ¢òÊäïÂΩ±Âà∞ÂµåÂÖ•Á©∫Èó¥Ôºå‰ª•Ê†πÊçÆ‰∏éÈóÆÈ¢òÁöÑË∑ùÁ¶ªÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£ÁâáÊÆµ„ÄÇLLM ÂèØ‰ª•‰ΩøÁî®Ê£ÄÁ¥¢Âà∞ÁöÑ‰ø°ÊÅØÊù•ÂõûÁ≠îÊü•ËØ¢ÔºåÂπ∂ÈÄöËøáÂëàÁé∞ÁâáÊÆµ‰Ωú‰∏∫ÂèÇËÄÉÊù•ËØÅÊòéÂÖ∂ÁªìËÆ∫„ÄÇ\n\n\n\nËØÑ‰º∞ RAG Â∫îÁî®ÊòØÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ \\[2]„ÄÇÂ≠òÂú®‰∏çÂêåÁöÑÊñπÊ≥ïÔºö‰∏ÄÊñπÈù¢ÔºåÊúâ‰∫õÊñπÊ≥ïË¶ÅÊ±ÇÂºÄÂèëËÄÖÊèê‰æõÁ≠îÊ°à‰Ωú‰∏∫ÁúüÂÆûÂÄºÔºõÂè¶‰∏ÄÊñπÈù¢ÔºåÁ≠îÊ°àÔºàÂíåÈóÆÈ¢òÔºâ‰πüÂèØ‰ª•Áî±Âè¶‰∏Ä‰∏™ LLM ÁîüÊàê„ÄÇÊúÄÂ§ßÁöÑÂºÄÊ∫ê LLM ÊîØÊåÅÂõûÁ≠îÁ≥ªÁªü‰πã‰∏ÄÊòØ Ragas \\[4](Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêËØÑ‰º∞)ÔºåÂÆÉÊèê‰æõ\n\n* Âü∫‰∫éÊñáÊ°£ÁîüÊàêÊµãËØïÊï∞ÊçÆÁöÑÊñπÊ≥ïÔºå‰ª•Âèä\n* Âü∫‰∫é‰∏çÂêåÊåáÊ†áÈÄêÊ≠•ÂíåÁ´ØÂà∞Á´ØËØÑ‰º∞Ê£ÄÁ¥¢ÂíåÁîüÊàêÊ≠•È™§ÁöÑËØÑ‰º∞„ÄÇ\n\nÂú®Êú¨Êñá‰∏≠ÔºåÊÇ®Â∞ÜÂ≠¶‰π†\n\n* Â¶Ç‰ΩïÁÆÄË¶ÅÊûÑÂª∫‰∏Ä‰∏™ Formula One ÁöÑ RAG Á≥ªÁªüÔºàÊúâÂÖ≥ËØ¶ÁªÜÊèèËø∞ÔºåËØ∑ÂèÇÈòÖ‰πãÂâçÁöÑÊñáÁ´† [ÂèØËßÜÂåñÊÇ®ÁöÑ RAG Êï∞ÊçÆ ‚Äî Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÁöÑ EDA](https://readmedium.com/visualize-your-rag-data-eda-for-retrieval-augmented-generation-0701ee98768f)Ôºâ\n* ÁîüÊàêÈóÆÈ¢òÂíåÁ≠îÊ°à\n* ‰ΩøÁî® [Ragas](https://github.com/explodinggradients/ragas) ËØÑ‰º∞ RAG Á≥ªÁªü\n* ÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂ¶Ç‰Ωï‰ΩøÁî® [Renumics Spotlight](https://github.com/Renumics/spotlight) ÂèØËßÜÂåñÁªìÊûúÂπ∂Ëß£ËØªÁªìÊûú„ÄÇ\n\n‰ª£Á†ÅÂèØÂú® Github ‰∏äËé∑Âèñ„ÄÇ\n\n## ÂáÜÂ§á‰Ω†ÁöÑÁéØÂ¢É\n\nÂêØÂä®‰∏Ä‰∏™Á¨îËÆ∞Êú¨Âπ∂ÂÆâË£ÖÊâÄÈúÄÁöÑ python ÂåÖ\n\n```python\n!pip install langchain langchain-openai chromadb renumics-spotlight\n%env OPENAI_API_KEY=<your-api-key>\n```\nÊú¨ÊïôÁ®ã‰ΩøÁî®‰ª•‰∏ã python ÂåÖÔºö\n\n* [**Langchain**](https://github.com/langchain-ai/langchain): ‰∏Ä‰∏™ÈõÜÊàêËØ≠Ë®ÄÊ®°ÂûãÂíå RAG ÁªÑ‰ª∂ÁöÑÊ°ÜÊû∂Ôºå‰ΩøËÆæÁΩÆËøáÁ®ãÊõ¥Âä†È°∫ÁïÖ„ÄÇ\n* [**Renumics\\-Spotlight**](https://github.com/Renumics/spotlight): ‰∏Ä‰∏™ÂèØËßÜÂåñÂ∑•ÂÖ∑ÔºåÁî®‰∫é‰∫§‰∫íÂºèÊé¢Á¥¢ÈùûÁªìÊûÑÂåñÁöÑÊú∫Âô®Â≠¶‰π†Êï∞ÊçÆÈõÜ„ÄÇ\n* [**Ragas**](https://github.com/explodinggradients/ragas): ‰∏Ä‰∏™Â∏ÆÂä©‰Ω†ËØÑ‰º∞ RAG ÁÆ°ÈÅìÁöÑÊ°ÜÊû∂\n\n*ÂÖçË¥£Â£∞ÊòéÔºöÊú¨Êñá‰ΩúËÄÖ‰πüÊòØ Spotlight ÁöÑÂºÄÂèëËÄÖ‰πã‰∏Ä„ÄÇ*\n\n## ‰∏∫Êï∞ÊçÆÈõÜÂáÜÂ§áÊñáÊ°£ÂíåÂµåÂÖ•\n\nÊÇ®ÂèØ‰ª•‰ΩøÁî®Ëá™Â∑±ÁöÑ RAG Â∫îÁî®Á®ãÂ∫èÔºåË∑≥Âà∞‰∏ã‰∏ÄÈÉ®ÂàÜ‰∫ÜËß£Â¶Ç‰ΩïËØÑ‰º∞„ÄÅÊèêÂèñÂíåÂèØËßÜÂåñ„ÄÇ\n\nÊàñËÄÖÊÇ®ÂèØ‰ª•‰ΩøÁî®Êù•Ëá™[‰∏ä‰∏ÄÁØáÊñáÁ´†](https://readmedium.com/visualize-your-rag-data-eda-for-retrieval-augmented-generation-0701ee98768f)ÁöÑ RAG Â∫îÁî®Á®ãÂ∫èÔºåÈÖçÂêà[Êàë‰ª¨ÂáÜÂ§áÁöÑÊâÄÊúâÁª¥Âü∫ÁôæÁßë Formula One ÊñáÁ´†ÁöÑÊï∞ÊçÆÈõÜ](https://spotlightpublic.blob.core.windows.net/docs-data/rag_demo/docs.zip)„ÄÇÊÇ®ËøòÂèØ‰ª•Â∞ÜËá™Â∑±ÁöÑÊñáÊ°£ÊèíÂÖ•Âà∞‚Äúdocs/‚ÄùÂ≠êÊñá‰ª∂Â§π‰∏≠„ÄÇ\n\n> Ê≠§Êï∞ÊçÆÈõÜÂü∫‰∫éÊù•Ëá™[Áª¥Âü∫ÁôæÁßë](https://www.wikipedia.org/)ÁöÑÊñáÁ´†ÔºåÂπ∂Ê†πÊçÆÁü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ËÆ∏ÂèØÂçèËÆÆËøõË°åËÆ∏ÂèØ„ÄÇÂéüÂßãÊñáÁ´†Âèä‰ΩúËÄÖÂàóË°®ÂèØ‰ª•Âú®Áõ∏Â∫îÁöÑÁª¥Âü∫ÁôæÁßëÈ°µÈù¢‰∏≠ÊâæÂà∞„ÄÇ\n\nÁé∞Âú®ÊÇ®ÂèØ‰ª•‰ΩøÁî® Langchain ÁöÑ `DirectoryLoader` ‰ªé docs Â≠êÁõÆÂΩïÂä†ËΩΩÊâÄÊúâÊñá‰ª∂ÔºåÂπ∂‰ΩøÁî® `RecursiveCharacterTextSpliter` Â∞ÜÊñáÊ°£ÊãÜÂàÜ‰∏∫ÁâáÊÆµ„ÄÇÈÄöËøá `OpenAIEmbeddings`ÔºåÊÇ®ÂèØ‰ª•ÂàõÂª∫ÂµåÂÖ•Âπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú® `ChromaDB` ‰∏≠‰Ωú‰∏∫ÂêëÈáèÂ≠òÂÇ®„ÄÇÂØπ‰∫é Chain Êú¨Ë∫´ÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî® LangChains ÁöÑ `ChatOpenAI` Âíå `ChatPromptTemplate`„ÄÇ\n\nÊú¨ÊñáÁöÑ[ÈìæÊé•‰ª£Á†Å](https://github.com/Renumics/rag-demo/blob/main/notebooks/visualize_rag_tutorial_qs.ipynb)ÂåÖÂê´ÊâÄÊúâÂøÖË¶ÅÊ≠•È™§ÔºåÊÇ®ÂèØ‰ª•Âú®[‰∏ä‰∏ÄÁØáÊñáÁ´†](https://readmedium.com/visualize-your-rag-data-eda-for-retrieval-augmented-generation-0701ee98768f)‰∏≠ÊâæÂà∞‰∏äËø∞ÊâÄÊúâÊ≠•È™§ÁöÑËØ¶ÁªÜÊèèËø∞„ÄÇ\n\n‰∏Ä‰∏™ÈáçË¶ÅÁöÑÁÇπÊòØÔºåÊÇ®Â∫îËØ•‰ΩøÁî®ÂìàÂ∏åÂáΩÊï∞‰∏∫ `ChromaDB` ‰∏≠ÁöÑÁâáÊÆµÂàõÂª∫ ID„ÄÇËøôÂÖÅËÆ∏Âú®‰ªÖÊã•ÊúâÊñáÊ°£ÂèäÂÖ∂ÂÜÖÂÆπÂíåÂÖÉÊï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÊâæÂà∞Êï∞ÊçÆÂ∫ì‰∏≠ÁöÑÂµåÂÖ•„ÄÇËøô‰ΩøÂæóÂèØ‰ª•Ë∑≥ËøáÂ∑≤ÁªèÂ≠òÂú®‰∫éÊï∞ÊçÆÂ∫ì‰∏≠ÁöÑÊñáÊ°£„ÄÇ\n\n```python\nimport hashlib\nimport json\nfrom langchain_core.documents import Document\n\ndef stable_hash_meta(doc: Document) -> str:\n    \"\"\"\n    Stable hash document based on its metadata.\n    \"\"\"\n    return hashlib.sha1(json.dumps(doc.metadata, sort_keys=True).encode()).hexdigest()\n\n...\nsplits = text_splitter.split_documents(docs)\nsplits_ids = [\n    {\"doc\": split, \"id\": stable_hash_meta(split.metadata)} for split in splits\n]\n\nexisting_ids = docs_vectorstore.get()[\"ids\"]\nnew_splits_ids = [split for split in splits_ids if split[\"id\"] not in existing_ids]\n\ndocs_vectorstore.add_documents(\n    documents=[split[\"doc\"] for split in new_splits_ids],\n    ids=[split[\"id\"] for split in new_splits_ids],\n)\ndocs_vectorstore.persist()\n```\n\n## ËØÑ‰º∞ÈóÆÈ¢ò\n\nÂØπ‰∫éÂÉè‰∏ÄÁ∫ßÊñπÁ®ãÂºèËøôÊ†∑ÁöÑÂ∏∏ËßÅ‰∏ªÈ¢òÔºåÂèØ‰ª•Áõ¥Êé•‰ΩøÁî® ChatGPT ÁîüÊàê‰∏ÄËà¨ÊÄßÈóÆÈ¢ò„ÄÇÊú¨Êñá‰ΩøÁî®‰∫ÜÂõõÁßçÈóÆÈ¢òÁîüÊàêÊñπÊ≥ïÔºö\n\n* **GPT4**: ‰ΩøÁî® ChatGPT 4 ÁîüÊàê‰∫Ü 30 ‰∏™ÈóÆÈ¢òÔºåÊèêÁ§∫‰∏∫‚ÄúÂÜô 30 ‰∏™ÂÖ≥‰∫é‰∏ÄÁ∫ßÊñπÁ®ãÂºèÁöÑÈóÆÈ¢ò‚Äù\n‚Äì ÈöèÊú∫Á§∫‰æãÔºö‚ÄúÂì™‰∏™‰∏ÄÁ∫ßÊñπÁ®ãÂºèËΩ¶Èòü‰ª•ÂÖ∂Ë∑ÉÈ©¨Ê†áÂøóËÄåÈóªÂêçÔºü‚Äù\n* **GPT3\\.5:** ‰ΩøÁî® ChatGPT 3\\.5 ÁîüÊàê‰∫ÜÂè¶Â§ñ 199 ‰∏™ÈóÆÈ¢òÔºåÊèêÁ§∫‰∏∫‚ÄúÂÜô 100 ‰∏™ÂÖ≥‰∫é‰∏ÄÁ∫ßÊñπÁ®ãÂºèÁöÑÈóÆÈ¢ò‚ÄùÔºåÂπ∂ÈáçÂ§ç‚ÄúË∞¢Ë∞¢ÔºåÂÜçÂÜô 100 ‰∏™Âêß‚Äù\n‚Äì Á§∫‰æãÔºö‚ÄúÂì™‰ΩçËΩ¶ÊâãÂú® 1950 Âπ¥Ëµ¢Âæó‰∫ÜÈ¶ñÂ±ä‰∏ÄÁ∫ßÊñπÁ®ãÂºè‰∏ñÁïåÈî¶Ê†áËµõÔºü‚Äù\n* **Ragas\\_GPT4**: ‰ΩøÁî® Ragas ÁîüÊàê‰∫Ü 113 ‰∏™ÈóÆÈ¢ò„ÄÇRagas ÂÜçÊ¨°Âà©Áî®ÊñáÊ°£ÂèäÂÖ∂Ëá™Ë∫´ÁöÑÂµåÂÖ•Ê®°ÂûãÊûÑÂª∫‰∏Ä‰∏™ÂêëÈáèÊï∞ÊçÆÂ∫ìÔºåÁÑ∂ÂêéÁî® GPT4 ÁîüÊàêÈóÆÈ¢ò„ÄÇ\n‚Äì Á§∫‰æãÔºö‚Äú‰Ω†ËÉΩÂëäËØâÊàëÊõ¥Â§öÂÖ≥‰∫é‰πî‰∏π 198 ‰∏ÄÁ∫ßÊñπÁ®ãÂºèËµõËΩ¶Âú® 1998 Âπ¥‰∏ñÁïåÈî¶Ê†áËµõ‰∏≠ÁöÑË°®Áé∞ÂêóÔºü‚Äù\n* **Rags\\_GPT3\\.5**: ‰ΩøÁî® Ragas ÁîüÊàê‰∫Ü 226 ‰∏™È¢ùÂ§ñÈóÆÈ¢ò‚Äî‚ÄîËøôÈáåÊàë‰ª¨‰ΩøÁî® GPT3\\.5\n‚Äì Á§∫‰æãÔºö‚ÄúÂú® 2014 Âπ¥ÊØîÂà©Êó∂Â§ßÂ•ñËµõ‰∏äÂèëÁîü‰∫Ü‰ªÄ‰πà‰∫ã‰ª∂ÂØºËá¥Ê±âÂØÜÂ∞îÈ°øÈÄÄËµõÔºü‚Äù\n\n```python\nfrom ragas.testset import TestsetGenerator\n\ngenerator = TestsetGenerator.from_default(\n    openai_generator_llm=\"gpt-3.5-turbo-16k\", \n    openai_filter_llm=\"gpt-3.5-turbo-16k\"\n)\n\ntestset_ragas_gpt35 = generator.generate(docs, 100)\n```\nÈóÆÈ¢òÂíåÁ≠îÊ°àÊ≤°ÊúâÁªèËøáÂÆ°Ê†∏Êàñ‰øÆÊîπ„ÄÇÊâÄÊúâÈóÆÈ¢òÈÉΩÂêàÂπ∂Âú®‰∏Ä‰∏™Âçï‰∏ÄÁöÑÊï∞ÊçÆÊ°Ü‰∏≠ÔºåÂåÖÂê´ `id`„ÄÅ`question`„ÄÅ`ground_truth`„ÄÅ`question_by` Âíå `answer` Âàó„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*R_74K0-_SJXyTxq6ovAcWg.png)\n\nÊé•‰∏ãÊù•ÔºåÈóÆÈ¢òÂ∞ÜË¢´ÊèêÂá∫Áªô RAG Á≥ªÁªü„ÄÇÂØπ‰∫éË∂ÖËøá 500 ‰∏™ÈóÆÈ¢òÔºåËøôÂèØËÉΩÈúÄË¶Å‰∏Ä‰∫õÊó∂Èó¥Âπ∂‰∫ßÁîüË¥πÁî®„ÄÇÂ¶ÇÊûúÈÄêË°åËØ¢ÈóÆÈóÆÈ¢òÔºåÂèØ‰ª•ÊöÇÂÅúÂπ∂ÁªßÁª≠ËØ•ËøáÁ®ãÔºåÊàñËÄÖÂú®Â¥©Ê∫ÉÂêéÊÅ¢Â§çÔºåËÄå‰∏ç‰ºö‰∏¢Â§±Âà∞ÁõÆÂâç‰∏∫Ê≠¢ÁöÑÁªìÊûúÔºö\n\n```python\nfor i, row in df_questions_answers.iterrows():\n    if row[\"answer\"] is None or pd.isnull(row[\"answer\"]):\n        response = rag_chain.invoke(row[\"question\"])\n\n        df_questions_answers.loc[df_questions_answers.index[i], \"answer\"] = response[\n            \"answer\"\n        ]\n        df_questions_answers.loc[df_questions_answers.index[i], \"source_documents\"] = [\n            stable_hash_meta(source_document.metadata)\n            for source_document in response[\"source_documents\"]\n        ]\n\n```\n‰∏ç‰ªÖÂ≠òÂÇ®‰∫ÜÁ≠îÊ°àÔºåËøòÂ≠òÂÇ®‰∫ÜÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£ÁâáÊÆµÁöÑÊ∫ê ID ÂèäÂÖ∂ÊñáÊú¨ÂÜÖÂÆπ‰Ωú‰∏∫‰∏ä‰∏ãÊñáÔºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*umlKv7Qf9SSLzRslT2r0Qw.png)\n\nÊ≠§Â§ñÔºåËøòÁîüÊàêÂπ∂Â≠òÂÇ®‰∫ÜÊâÄÊúâÈóÆÈ¢òÁöÑÂµåÂÖ•ÔºåÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®Êï∞ÊçÆÊ°Ü‰∏≠„ÄÇËøô‰ΩøÂæóÂèØ‰ª•Â∞ÜÂÆÉ‰ª¨‰∏éÊñáÊ°£‰∏ÄËµ∑ÂèØËßÜÂåñ„ÄÇ\n\n## ‰ΩøÁî® Ragas ËøõË°åËØÑ‰º∞\n\n[Ragas](https://github.com/explodinggradients/ragas) Êèê‰æõ‰∫ÜËØÑ‰º∞ÊÇ®ÁöÑ RAG ÊµÅÊ∞¥Á∫ø‰∏≠ÊØè‰∏™ÁªÑ‰ª∂ÁöÑÊåáÊ†áÔºå‰ª•ÂèäÊï¥‰ΩìÊÄßËÉΩÁöÑÁ´ØÂà∞Á´ØÊåáÊ†áÔºö\n\n1. **‰∏ä‰∏ãÊñáÁ≤æÁ°ÆÂ∫¶Ôºö** ‰ΩøÁî® `question` ÂíåÊ£ÄÁ¥¢Âà∞ÁöÑ `contexts` Êù•ÊµãÈáè‰ø°Âè∑‰∏éÂô™Â£∞ÁöÑÊØîÁéá„ÄÇ\n2. **‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÊÄßÔºö** ÊµãÈáèÊ£ÄÁ¥¢Âà∞ÁöÑ‰∏ä‰∏ãÊñá‰∏éÈóÆÈ¢òÁöÑÁõ∏ÂÖ≥ÊÄßÔºå‰ΩøÁî® `question` Âíå `contexts` ËÆ°ÁÆó„ÄÇ\n3. **‰∏ä‰∏ãÊñáÂè¨ÂõûÁéáÔºö** Âü∫‰∫é `ground truth` Âíå `contexts` Ê£ÄÊü•ÊòØÂê¶Ê£ÄÁ¥¢Âà∞ÊâÄÊúâ‰∏éÁ≠îÊ°àÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇ\n4. **Âø†ÂÆûÂ∫¶Ôºö** Âà©Áî® `contexts` Âíå `answer` Êù•Ë°°ÈáèÁîüÊàêÁ≠îÊ°àÁöÑ‰∫ãÂÆûÂáÜÁ°ÆÊÄß„ÄÇ\n5. **Á≠îÊ°àÁõ∏ÂÖ≥ÊÄßÔºö** ‰ΩøÁî® `question` Âíå `answer` ËÆ°ÁÆóÔºåËØÑ‰º∞ÁîüÊàêÁöÑÁ≠îÊ°à‰∏éÈóÆÈ¢òÁöÑÁõ∏ÂÖ≥ÊÄßÔºà‰∏çËÄÉËôë‰∫ãÂÆûÊÄßÔºâ„ÄÇ\n6. **Á≠îÊ°àËØ≠‰πâÁõ∏‰ººÂ∫¶Ôºö** ‰ΩøÁî® `ground truth` Âíå `answer` ËøõË°åËØÑ‰º∞Ôºå‰ª•Âà§Êñ≠ÁîüÊàêÁ≠îÊ°à‰∏éÊ≠£Á°ÆÁ≠îÊ°à‰πãÈó¥ÁöÑËØ≠‰πâÁõ∏‰ººÊÄß„ÄÇ\n7. **Á≠îÊ°àÊ≠£Á°ÆÊÄßÔºö** ‰æùËµñ‰∫é `ground truth` Âíå `answer` Êù•Ë°°ÈáèÁîüÊàêÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÂíå‰∏éÊ≠£Á°ÆÁ≠îÊ°àÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ\n8. **ÊñπÈù¢ËØÑ‰º∞Ôºö** Ê∂âÂèäÂàÜÊûê `answer` ‰ª•Ê†πÊçÆÈ¢ÑÂÆö‰πâÊàñËá™ÂÆö‰πâÊñπÈù¢ÔºàÂ¶ÇÊ≠£Á°ÆÊÄßÊàñÊúâÂÆ≥ÊÄßÔºâËØÑ‰º∞Êèê‰∫§ÁªìÊûú„ÄÇ\n\nÁõÆÂâçÔºåÊàë‰ª¨‰∏ìÊ≥®‰∫éÁ≠îÊ°àÊ≠£Á°ÆÊÄßÁöÑÁ´ØÂà∞Á´ØÊåáÊ†á„ÄÇÊï∞ÊçÆÊ°Ü‰∏≠ÁöÑÂàóÂêçÂíåÂÜÖÂÆπÂ∑≤Â§çÂà∂Âπ∂Ë∞ÉÊï¥Ôºå‰ª•Á¨¶Âêà Ragas API ÁöÑÂëΩÂêçÂíåÊ†ºÂºèË¶ÅÊ±ÇÔºö\n\n```python\n## prepare the dataframe for evaluation\ndf_qa_eval = df_questions_answers.copy()\n\n\n## adapt the ground truth to the ragas naming and format\ndf_qa_eval.rename(columns={\"ground_truth\": \"ground_truths\"}, inplace=True)\ndf_qa_eval[\"ground_truths\"] = [\n    [gt] if not isinstance(gt, list) else gt for gt in df_qa_eval[\"ground_truths\"]\n]\n```\nËøôÂèØËÉΩÈúÄË¶Å‰∏Ä‰∫õÊó∂Èó¥ÔºåÁîöËá≥ÊØî‰ªÖÊü•ËØ¢ÊÇ®ÁöÑ RAG Á≥ªÁªüËä±Ë¥πÊõ¥Â§öÁöÑÈáëÈí±„ÄÇËÆ©Êàë‰ª¨ÈÄêË°åÂ∫îÁî®ËØÑ‰º∞Ôºå‰ª•‰æøÂú®Â¥©Ê∫ÉÂêéËÉΩÂ§üÊÅ¢Â§çËÄå‰∏ç‰∏¢Â§±Âà∞ÁõÆÂâç‰∏∫Ê≠¢ÁöÑÁªìÊûúÔºö\n\n```python\n## evaluate the answer correctness if not already done\nfields = [\"question\", \"answer\", \"contexts\", \"ground_truths\"]\nfor i, row in df_qa_eval.iterrows():\n    if row[\"answer_correctness\"] is None or pd.isnull(row[\"answer_correctness\"]):\n        evaluation_result = evaluate(\n            Dataset.from_pandas(df_qa_eval.iloc[i : i + 1][fields]),\n            [answer_correctness],\n        )\n        df_qa_eval.loc[i, \"answer_correctness\"] = evaluation_result[\n            \"answer_correctness\"\n        ]\n\n```\n‰πãÂêéÔºåÊÇ®ÂèØ‰ª•Â∞ÜÁªìÊûúÂ≠òÂÇ®Âú® `df_questions_answer` Êï∞ÊçÆÊ°Ü‰∏≠Ôºö\n\n```python\ndf_questions_answers[\"answer_correctness\"] = df_qa_eval[\"answer_correctness\"]\n```\n\n## ÂáÜÂ§áÂèØËßÜÂåñ\n\n‰∏∫‰∫ÜÂú®ÂèØËßÜÂåñ‰∏≠ÂåÖÂê´ÊñáÊ°£ÁâáÊÆµÔºåÊàë‰ª¨Ê∑ªÂä†‰∫Ü‰ªéÊñáÊ°£Âà∞‰ΩøÁî®ËØ•ÊñáÊ°£‰Ωú‰∏∫Êù•Ê∫êÁöÑÈóÆÈ¢òÁöÑÂºïÁî®„ÄÇÊ≠§Â§ñÔºåÂºïÁî®ÊñáÊ°£ÁöÑÈóÆÈ¢òÊï∞Èáè‰πüË¢´Â≠òÂÇ®Ôºö\n\n```python\n## Explode 'source_documents' so each document ID is in its own row alongside the question ID\ndf_questions_exploded = df_qa_eval.explode(\"source_documents\")\n\n## Group by exploded 'source_documents' (document IDs) and aggregate\nagg = (\n    df_questions_exploded.groupby(\"source_documents\")\n    .agg(\n        num_questions=(\"id\", \"count\"),  # Count of questions referencing the document\n        question_ids=(\n            \"id\",\n            lambda x: list(x),\n        ),  # List of question IDs referencing the document\n    )\n    .reset_index()\n    .rename(columns={\"source_documents\": \"id\"})\n)\n\n## Merge the aggregated information back into df_documents\ndf_documents_agg = pd.merge(df_docs, agg, on=\"id\", how=\"left\")\n\n## Use apply to replace NaN values with empty lists for 'question_ids'\ndf_documents_agg[\"question_ids\"] = df_documents_agg[\"question_ids\"].apply(\n    lambda x: x if isinstance(x, list) else []\n)\n## Replace NaN values in 'num_questions' with 0\ndf_documents_agg[\"num_questions\"] = df_documents_agg[\"num_questions\"].fillna(0)\n```\nÁé∞Âú®Â∞ÜÈóÆÈ¢òÁöÑÊï∞ÊçÆÊ°Ü‰∏éÊñáÊ°£ÁöÑÊï∞ÊçÆÊ°ÜËøûÊé•Ëµ∑Êù•\n\n```python\ndf = pd.concat([df_qa_eval, df_documents_agg], axis=0)\n```\nÊ≠§Â§ñÔºåËÆ©Êàë‰ª¨ÂáÜÂ§á‰∏Ä‰∫õ‰∏çÂêåÁöÑ UMAP \\[3] Êò†Â∞Ñ„ÄÇÊÇ®ÂèØ‰ª•Á®çÂêéÂú® Spotlight GUI ‰∏≠ÂÅöÁ±ª‰ººÁöÑ‰∫ãÊÉÖÔºå‰ΩÜÊèêÂâçÂÅöÂ•ΩÂèØ‰ª•ËäÇÁúÅÊó∂Èó¥„ÄÇ\n\n* umap\\_all: ÂØπÊâÄÊúâÊñáÊ°£ÂíåÈóÆÈ¢òÂµåÂÖ•Â∫îÁî® fit Âíå transform ÁöÑ UMAP\n* umap\\_questions: ‰ªÖÂØπÈóÆÈ¢òÂµåÂÖ•Â∫îÁî® fitÔºåÂπ∂ÂØπ‰∏§ËÄÖÂ∫îÁî® transform ÁöÑ UMAP\n* umap\\_docs: ‰ªÖÂØπÊñáÊ°£ÂµåÂÖ•Â∫îÁî® fitÔºåÂπ∂ÂØπ‰∏§ËÄÖÂ∫îÁî® transform ÁöÑ UMAP\n\nÊàë‰ª¨ÂÉèËøôÊ†∑ÂáÜÂ§áÊØè‰∏™ UMAP ËΩ¨Êç¢Ôºö\n\n```python\numap = UMAP(n_neighbors=20, min_dist=0.15, metric=\"cosine\", random_state=42).fit\numap_all = umap.transform(df[\"embedding\"].values.tolist())\ndf[\"umap\"] = umap_all.tolist()\n\n```\nÊØè‰∏™ÊñáÊ°£ÁâáÊÆµÁöÑÂè¶‰∏Ä‰∏™ÊúâË∂£ÊåáÊ†áÊòØÂÖ∂ÂµåÂÖ•‰∏éÊúÄËøëÈóÆÈ¢òÁöÑÂµåÂÖ•‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºö\n\n```python\nquestion_embeddings = np.array(df[df[\"question\"].notna()][\"embedding\"].tolist())\ndf[\"nearest_question_dist\"] = [  # brute force, could be optimized using ChromaDB\n    np.min([np.linalg.norm(np.array(doc_emb) - question_embeddings)])\n    for doc_emb in df[\"embedding\"].values\n]\n```\nËøô‰∏™ÊåáÊ†áÂèØ‰ª•Â∏ÆÂä©ÊâæÂà∞Êú™Ë¢´ÈóÆÈ¢òÂºïÁî®ÁöÑÊñáÊ°£„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*YTRUXZmd0iX8kyPIdUUnlg.png)\n\n## ÂèØËßÜÂåñÁªìÊûú\n\nÂ¶ÇÊûúÊÇ®Ë∑≥Ëøá‰∫Ü‰πãÂâçÁöÑÊ≠•È™§ÔºåÊÇ®ÂèØ‰ª•‰∏ãËΩΩÊï∞ÊçÆÊ°ÜÂπ∂‰ΩøÁî®‰ª•‰∏ã‰ª£Á†ÅÂä†ËΩΩÂÆÉÔºö\n\n```python\nimport pandas as pd\ndf = pd.read_parquet(\"df_f1_rag_docs_and_questions.parquet\")\n```\nÁÑ∂ÂêéÂêØÂä® [Renumics Spotlight](https://github.com/Renumics/spotlight) ‰ª•ÂèØËßÜÂåñÂÆÉÔºö\n\n```python\nfrom renumics import spotlight\n\nspotlight.show(df)\nspotlight.show(\n    df,\n    layout=\"/home/markus/Downloads/layout_rag_1.json\",\n    dtype={x: Embedding for x in df.keys() if \"umap\" in x},\n)\n```\nËøôÂ∞ÜÊâìÂºÄ‰∏Ä‰∏™Êñ∞ÁöÑÊµèËßàÂô®Á™óÂè£Ôºö\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IMbva0pP8RAVhoY4dVbjLg.png)\n\nÂú®Â∑¶‰∏äËßíÔºåÊÇ®ÂèØ‰ª•ÁúãÂà∞‰∏Ä‰∏™**ÊâÄÊúâÈóÆÈ¢òÂíåÊâÄÊúâÊñáÊ°£**ÁâáÊÆµÁöÑË°®Ê†º„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®‚ÄúÂèØËßÅÂàó‚ÄùÊåâÈíÆÊù•ÊéßÂà∂Ë°®Ê†º‰∏≠ÊòæÁ§∫Âì™‰∫õÊï∞ÊçÆÊ°ÜÂàó„ÄÇÁõ¥Êé•ÂàõÂª∫‰∏Ä‰∏™ÈÄâÊã©‰ªÖÈóÆÈ¢òÁöÑËøáÊª§Âô®ÊòØÂæàÊúâÁî®ÁöÑÔºå‰ª•‰æøËÉΩÂ§üÂú®ÂèØËßÜÂåñ‰∏≠ÊâìÂºÄÂíåÂÖ≥Èó≠ÈóÆÈ¢òÔºöÈÄâÊã©ÊâÄÊúâÈóÆÈ¢òÔºåÁÑ∂Âêé‰ΩøÁî®‚Äú‰ªéÈÄâÂÆöË°åÂàõÂª∫ËøáÊª§Âô®‚ÄùÊåâÈíÆÂàõÂª∫ËøáÊª§Âô®„ÄÇ\n\nÂú®Ë°®Ê†ºÁöÑÂè≥‰æßÔºå`answer correctness` **‰Ωú‰∏∫‰∏Ä‰∏™ÊåáÊ†á**ÊòæÁ§∫Âú®ÊâÄÊúâÈóÆÈ¢ò‰∏≠„ÄÇ‰∏ãÈù¢Êúâ‰∏§‰∏™**Áõ¥ÊñπÂõæ**ÔºõÂ∑¶‰æßÊòæÁ§∫‰∫ÜÊ†πÊçÆ‰∏çÂêåÈóÆÈ¢òÁîüÊàêÊñπÊ≥ïÂàíÂàÜÁöÑ`answer correctness`ÁöÑÂàÜÂ∏É„ÄÇÂè≥‰æßÊòæÁ§∫‰∫ÜÈóÆÈ¢òÁîüÊàêÊñπÊ≥ïÁöÑÂàÜÂ∏É„ÄÇÂú®ËøôÈáåÔºåÂ¶ÇÊûúÈúÄË¶ÅÔºåÂª∫ËÆÆ‰ΩøÁî®ËøáÊª§ÊåâÈíÆ‰∏∫ÈóÆÈ¢òÂàõÂª∫ËøáÊª§Âô®Ôºå‰ª•‰ªÖÊòæÁ§∫ÈÄâÂÆöÁöÑË°åÔºàÈóÆÈ¢òÔºâ„ÄÇ\n\nÂè≥‰æßÊúâ**‰∏§‰∏™Áõ∏‰ººÊÄßÂõæ**„ÄÇÁ¨¨‰∏Ä‰∏™‰ΩøÁî®`umap_questions`ÂàóÔºåÂü∫‰∫é‰ªÖÂØπÈóÆÈ¢òÂ∫îÁî®ÁöÑËΩ¨Êç¢ÊòæÁ§∫ÈóÆÈ¢òÂíåÊñáÊ°£„ÄÇËøôÂØπ‰∫éÁã¨Á´ã‰∫éÁõ∏ÂÖ≥ÊñáÊ°£Êü•ÁúãÈóÆÈ¢òÁöÑÂàÜÂ∏ÉÂæàÊúâÂ∏ÆÂä©ÔºåÂõ†‰∏∫ËøôÁßçÊñπÊ≥ïÂÖÅËÆ∏ÂàÜÊûêÂ∏àËØÜÂà´ÈóÆÈ¢òÊú¨Ë∫´ÁöÑÊ®°ÂºèÊàñÁ∞á„ÄÇ\n\nÁ¨¨‰∫å‰∏™Áõ∏‰ººÊÄßÂõæÂü∫‰∫é‰ªÖÂØπÊñáÊ°£Â∫îÁî®ÁöÑËΩ¨Êç¢Ôºà`umap_docs`ÔºâÊòæÁ§∫ÈóÆÈ¢òÂíåÊñáÊ°£„ÄÇÂÆÉÂØπ‰∫éÂú®ÂÖ∂Áõ∏ÂÖ≥ÊñáÊ°£ÁöÑ‰∏ä‰∏ãÊñá‰∏≠Êü•ÁúãÈóÆÈ¢òÂæàÊúâÁî®„ÄÇ‰∏Ä‰∏™ÂêåÊó∂ÂØπÈóÆÈ¢òÂíåÊñáÊ°£ËøõË°åËΩ¨Êç¢ÁöÑÁõ∏‰ººÊÄßÂõæÂú®ÈóÆÈ¢òÊï∞ÈáèËæÉÂ§öÊó∂Ë¢´ËØÅÊòé‰∏çÂ§™ÊúâÁî®ÔºåÂõ†‰∏∫Êõ¥Â§öÊàñÊõ¥Â∞ëÁöÑÈóÆÈ¢ò‰ºöËÅöÈõÜÂú®‰∏ÄËµ∑Âπ∂ÂÄæÂêë‰∫é‰∏éÊñáÊ°£ÂàÜÂºÄ„ÄÇÂõ†Ê≠§ÔºåËøôÁßçË°®Á§∫Âú®ËøôÈáåË¢´ÁúÅÁï•„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*1wZrAj60hiw1T3RVnCuBtA.png)\n\n### ÊñáÊ°£ÂµåÂÖ•Áõ∏‰ººÊÄßÂõæÔºöËßÇÂØü\n\nÂú®Áõ∏‰ººÊÄßÂõæ `umap_docs` ‰∏≠ÔºåÊÇ®ÂèØ‰ª•ËØÜÂà´Âá∫ÊñáÊ°£ÂµåÂÖ•Á©∫Èó¥‰∏≠Ê≤°ÊúâÈÇªËøëÈóÆÈ¢òÁöÑÂå∫Âüü„ÄÇÂΩìÈÄâÊã© `nearest_question_dist` ËøõË°åÁùÄËâ≤Êó∂ÔºåËøô‰∏ÄÁÇπÊõ¥Âä†ÊòéÊòæ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*cMGNPnnBa9Bn7BJ05SzxBw.png)\n\nÂèØ‰ª•ËØÜÂà´Âá∫‰∏Ä‰∫õÁ∞áÔºåÂåÖÊã¨‰ªÖÂåÖÂê´Ê†áÈ¢òÊàñÈÄêÈ°µÂåÖÂê´‰ªÖÊï∞Â≠óÁöÑË°®Ê†ºÊï∞ÊçÆÁöÑÁâáÊÆµÔºåËøô‰∫õÂú®ÊãÜÂàÜËøáÁ®ã‰∏≠ÂÖ∂ÊÑè‰πâ‰∏ßÂ§±„ÄÇÊ≠§Â§ñÔºåËÆ∏Â§ö‰∏çÂåÖÂê´Áõ∏ÂÖ≥‰ø°ÊÅØÁöÑÁª¥Âü∫ÁôæÁßëÁâπÂÆöÊñáÊú¨Ê∑ªÂä†Ôºå‰æãÂ¶ÇÊåáÂêëÂÖ∂‰ªñËØ≠Ë®ÄÁöÑÈìæÊé•ÊàñÁºñËæëÊ≥®ÈáäÔºåÂΩ¢Êàê‰∫ÜÊ≤°ÊúâÈÇªËøëÈóÆÈ¢òÁöÑÁ∞á„ÄÇ\n\n‰ΩøÁî®Áª¥Âü∫ÁôæÁßë API Âà†Èô§Áª¥Âü∫ÁôæÁßëÁõ∏ÂÖ≥ÊñáÊú¨ÂΩ¢ÂºèÁöÑÂô™Â£∞ÈùûÂ∏∏ÁÆÄÂçï„ÄÇËøôÂèØËÉΩÂπ∂‰∏çÊòØÁâπÂà´ÂøÖË¶ÅÔºåÂõ†‰∏∫ÂÆÉ‰∏ªË¶ÅÂç†Áî®‰∏Ä‰∫õÁ©∫Èó¥‚Äî‚ÄîÈ¢ÑËÆ° RAG ÁªìÊûú‰∏ç‰ºöÂõ†Ê≠§ÁâπÂà´ÊÅ∂Âåñ„ÄÇÁÑ∂ËÄåÔºåÂåÖÂê´Âú®Â§ßË°®Ê†º‰∏≠ÁöÑÊï∞ÊçÆÂæàÈöæË¢´ RAG Á≥ªÁªüÊçïËé∑Ôºå‰ΩøÁî®ÂÖàËøõÁöÑÈ¢ÑÂ§ÑÁêÜÊñπÊ≥ïËøõË°åË°®Ê†ºÊèêÂèñÂπ∂Â∞ÜÂÖ∂ËøûÊé•Âà∞ RAG Á≥ªÁªüÂèØËÉΩÊòØÊúâÁõäÁöÑ„ÄÇ\n\nÊÇ®ÂèØ‰ª•Âú® `umap_docs` Áõ∏‰ººÊÄßÂõæ‰∏≠ËßÇÂØüÂà∞ÁöÑÂè¶‰∏Ä‰∏™ÁÇπÊòØÊù•Ëá™‰∏çÂêåÊù•Ê∫êÁöÑÈóÆÈ¢òÁöÑÂàÜÂ∏É„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*IH7z3J4yUmU0C_SruxnDkg.png)\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*K4bADgDmSAr5t4t4r9VImQ.png)\n\nÁî± ChatGPTÔºàGPT-3.5„ÄÅGPT-4ÔºâÁõ¥Êé•ÁîüÊàêÁöÑÈóÆÈ¢ò‰Ωç‰∫é‰∏≠ÂøÉÁöÑ‰∏Ä‰∏™Êõ¥‰∏∫Â∞ÅÈó≠ÁöÑÂå∫ÂüüÔºåËÄåÂü∫‰∫éÊñáÊ°£ÁîüÊàêÁöÑ ragas ÁîüÊàêÁöÑÈóÆÈ¢òË¶ÜÁõñ‰∫ÜÊõ¥Â§ßÁöÑÂå∫Âüü„ÄÇ\n\n### Á≠îÊ°àÊ≠£Á°ÆÊÄßÁõ¥ÊñπÂõæ\n\nÁõ¥ÊñπÂõæÂèØ‰ª•‰Ωú‰∏∫‰∫ÜËß£Êï∞ÊçÆÂÖ®ÁêÉÁªüËÆ°ÁöÑËµ∑ÁÇπ„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåÂú®ÊâÄÊúâÈóÆÈ¢ò‰∏≠Ôºå`Á≠îÊ°àÊ≠£Á°ÆÊÄß`‰∏∫0\\.45„ÄÇÂØπ‰∫éÊ≤°Êúâ‰ΩøÁî®ragasÂàõÂª∫ÁöÑÈóÆÈ¢òÔºåËØ•ÂÄº‰∏∫0\\.36ÔºåËÄå‰ΩøÁî®ragasÁöÑÈóÆÈ¢òÂàô‰∏∫0\\.52„ÄÇÈ¢ÑËÆ°Á≥ªÁªüÂú®ÁîüÊàê‰ΩøÁî®ragasÁöÑÈóÆÈ¢òÊó∂Ë°®Áé∞‰ºöÊõ¥Â•ΩÔºåÂõ†‰∏∫Ëøô‰∫õÈóÆÈ¢òÊòØÂü∫‰∫éÂèØÁî®Êï∞ÊçÆÁîüÊàêÁöÑÔºåËÄåChatGPTÁõ¥Êé•ÁîüÊàêÁöÑÈóÆÈ¢òÂèØËÉΩÊù•Ëá™‰∫éChatGPTËÆ≠ÁªÉÊó∂‰ΩøÁî®ÁöÑÊâÄÊúâÊï∞ÊçÆ„ÄÇ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GsLBsg7uwTrw-AzvO4BHmw.png)\n\nÂØπ‰∏Ä‰∫õÈóÆÈ¢ò/Á≠îÊ°àÂíåÁúüÂÆûÊÉÖÂÜµËøõË°åÂø´ÈÄüÈöèÊú∫ÊâãÂä®ÂÆ°Ê†∏ÊòæÁ§∫ÔºåÂú®`Á≠îÊ°àÊ≠£Á°ÆÊÄß`‰∏∫0\\.3‚Äì0\\.4ÁöÑÂå∫Èó¥ÔºåÂ§ßÂ§öÊï∞ÈóÆÈ¢ò‰ªçÁÑ∂Ê†πÊçÆÁúüÂÆûÊÉÖÂÜµÂæóÂà∞‰∫ÜÊ≠£Á°ÆÂõûÁ≠î„ÄÇÂú®0\\.2‚Äì0\\.3ÁöÑÂå∫Èó¥ÔºåÂ≠òÂú®ËÆ∏Â§öÈîôËØØÁ≠îÊ°à„ÄÇÂú®0\\.1‚Äì0\\.2ÁöÑÂå∫Èó¥ÔºåÂ§ßÂ§öÊï∞Á≠îÊ°àÈÉΩÊòØÈîôËØØÁöÑ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËøô‰∏™ËåÉÂõ¥ÂÜÖÂá†‰πéÊâÄÊúâÁöÑÈóÆÈ¢òÈÉΩÊù•Ëá™GPT\\-3\\.5„ÄÇÂ∞ΩÁÆ°Âú®Ëøô‰∏™Âå∫Èó¥ÂÜÖÁîüÊàêÁöÑ‰∏§‰∏™ÈóÆÈ¢ò‰ΩøÁî®ÁöÑÊòØGPT\\-4Ôºå‰ΩÜÂÆÉ‰ª¨‰ªçÁÑ∂ÂæóÂà∞‰∫ÜÊ≠£Á°ÆÁöÑÂõûÁ≠îÔºåÂ∞ΩÁÆ°ÂÖ∂`Á≠îÊ°àÊ≠£Á°ÆÊÄß`‰Ωé‰∫é0\\.2„ÄÇ\n\n### ÈóÆÈ¢òÂµåÂÖ•Áõ∏‰ººÊÄßÂõæÔºöËßÇÂØü\n\nÈóÆÈ¢òÂµåÂÖ•Áõ∏‰ººÊÄßÂõæÂèØ‰ª•ÈÄöËøáÊ£ÄÊü•ÂèØËÉΩÂØºËá¥Á±ª‰ººÈóÆÈ¢òÁöÑÁõ∏‰ººÈóÆÈ¢òÈõÜÁæ§ÔºåÂ∏ÆÂä©Ê∑±ÂÖ•ÊåñÊéò `Á≠îÊ°àÊ≠£Á°ÆÊÄß`„ÄÇ\n\n* **ÈõÜÁæ§‚ÄúÈ©±Âä®Á®ãÂ∫è/ËøáÁ®ã/Ê±ΩËΩ¶ÁöÑÊúØËØ≠‚ÄùÔºö** Âπ≥Âùá `Á≠îÊ°àÊ≠£Á°ÆÊÄß` 0\\.23ÔºöÁ≠îÊ°àÈÄöÂ∏∏‰∏çÂ§üÁ≤æÁ°Æ„ÄÇ‰æãÂ¶ÇÔºåÂ∫ïÁõòË∞ÉÊ†°‰∏éÂ∫ïÁõòÂºØÊõ≤ÊàñÂàπËΩ¶Ë∞ÉÊ†°‰∏éÂàπËΩ¶ÂÅèÂ∑ÆË∞ÉÊï¥„ÄÇÊòØÂê¶ÈÄÇÂêàÁî®Ëøô‰∫õÁ±ªÂûãÁöÑÈóÆÈ¢òÊù•ËØÑ‰º∞Á≥ªÁªüÊòØÂÄºÂæóÊÄÄÁñëÁöÑÔºåÂõ†‰∏∫Âà§Êñ≠Á≠îÊ°à‰ºº‰πéÈùûÂ∏∏Âõ∞Èöæ„ÄÇ\n* **ÈõÜÁæ§‚ÄúÁáÉÊñôÁ≠ñÁï•ÁöÑÊúØËØ≠‚ÄùÔºö** Âπ≥Âùá `Á≠îÊ°àÊ≠£Á°ÆÊÄß` 0\\.44ÔºåÁ±ª‰ºº‰∫éÂÖ®ÁêÉ `Á≠îÊ°àÊ≠£Á°ÆÊÄß`„ÄÇ\n* **ÈõÜÁæ§‚ÄúËµõÈÅìÂêçÁß∞‚ÄùÔºö** Âπ≥Âùá `Á≠îÊ°àÊ≠£Á°ÆÊÄß` 0\\.49ÔºåÁ±ª‰ºº‰∫éÂÖ®ÁêÉ `Á≠îÊ°àÊ≠£Á°ÆÊÄß`„ÄÇ\n* **ÈõÜÁæ§‚ÄúË∞Å‰øùÊåÅ‰∫Ü‚Ä¶ÁöÑËÆ∞ÂΩï‚ÄùÔºö** Âπ≥Âùá `Á≠îÊ°àÊ≠£Á°ÆÊÄß` 0\\.44ÔºåÁ±ª‰ºº‰∫éÂÖ®ÁêÉ `Á≠îÊ°àÊ≠£Á°ÆÊÄß`„ÄÇ\n* **ÈõÜÁæ§‚ÄúËµ¢Âæó‚Ä¶Èî¶Ê†áËµõ‚ÄùÔºö** Âπ≥Âùá `Á≠îÊ°àÊ≠£Á°ÆÊÄß` 0\\.26 ‚Äî ÁúãËµ∑Êù•ÂæàÂÖ∑ÊåëÊàòÊÄß„ÄÇÂ∏¶ÊúâËÆ∏Â§öÊù°‰ª∂ÁöÑÈóÆÈ¢òÔºå‰æãÂ¶ÇÔºö‚ÄúË∞ÅÊòØÂîØ‰∏Ä‰∏Ä‰ΩçÂá≠ÂÄüËã±ÂõΩËµõËΩ¶ÊâßÁÖß„ÄÅ‰∏∫ÊÑèÂ§ßÂà©ËΩ¶ÈòüÈ©æÈ©∂ÁæéÂõΩÂºïÊìéËµ¢Âæó‰∏ÄÁ∫ßÊñπÁ®ãÂºè‰∏ñÁïåÈî¶Ê†áËµõÁöÑËΩ¶Êâã„ÄÇ‚Äù Êâ©Â±ïÁöÑRAGÊñπÊ≥ïÂ¶ÇÂ§öÊü•ËØ¢ÂèØËÉΩÊúâÂä©‰∫éÊîπÂñÑËøô‰∏ÄÁÇπ„ÄÇ\n* **ÈõÜÁæ§‚ÄúË∞ÅÊòØÂîØ‰∏Ä‰∏Ä‰ΩçËµ¢Âæó‚Ä¶ÁöÑËΩ¶ÊâãÔºåÈ©æÈ©∂ÁºñÂè∑‰∏∫\\<number\\>ÁöÑÊ±ΩËΩ¶‚ÄùÔºö** Âπ≥Âùá `Á≠îÊ°àÊ≠£Á°ÆÊÄß` 0\\.23 ‚Äî ÁúãËµ∑Êù•GPT-3\\.5Âú®ËøôÈáåÊáíÊÉ∞ÔºåÈáçÂ§ç‰∫ÜÁõ∏ÂêåÁöÑÈóÆÈ¢òÔºåÂè™ÊòØÊç¢‰∫Ü‰∏çÂêåÁöÑÊï∞Â≠óÔºåÂ∞ΩÁÆ°Â§ßÂ§öÊï∞ÁúüÂÆûÁ≠îÊ°àÈÉΩÊòØÈîôËØØÁöÑÔºÅ\n\n![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Yc03cpSEFlJoZSBPIpMkiQ.png)\n\n## ÁªìËÆ∫\n\nÊÄª‰πãÔºåÂà©Áî®Âü∫‰∫é UMAP ÁöÑÂèØËßÜÂåñÊèê‰æõ‰∫Ü‰∏ÄÁßçÊúâË∂£ÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Ê∑±ÂÖ•ÂàÜÊûêÂÖ®ÁêÉÊåáÊ†á‰πãÂ§ñÁöÑÂÜÖÂÆπ„ÄÇÊñáÊ°£ÂµåÂÖ•Áõ∏‰ººÊÄßÂú∞ÂõæÊèê‰æõ‰∫Ü‰∏Ä‰∏™ËâØÂ•ΩÁöÑÊ¶ÇËø∞ÔºåÂ±ïÁ§∫‰∫ÜÁõ∏‰ººÊñáÊ°£ÁöÑËÅöÁ±ªÂèäÂÖ∂‰∏éËØÑ‰º∞ÈóÆÈ¢òÁöÑÂÖ≥Á≥ª„ÄÇÈóÆÈ¢òÁõ∏‰ººÊÄßÂú∞ÂõæÊè≠Á§∫‰∫ÜÊ®°ÂºèÔºå‰ΩøÂæóÂèØ‰ª•ÁªìÂêàË¥®ÈáèÊåáÊ†áÂØπÈóÆÈ¢òËøõË°åÂå∫ÂàÜÂíåÂàÜÊûêÔºå‰ªéËÄåÁîüÊàêÊ¥ûÂØü„ÄÇËØ∑ÂèÇÈòÖÂèØËßÜÂåñÁªìÊûúÈÉ®ÂàÜÔºåÂ∞ÜÂèØËßÜÂåñÂ∫îÁî®‰∫éÊÇ®ÁöÑËØÑ‰º∞Á≠ñÁï•‚Äî‚ÄîÊÇ®Â∞ÜÂèëÁé∞‰ªÄ‰πàÊ¥ûÂØüÔºü\n\n*I am a professional with expertise in creating advanced software solutions for the interactive exploration of unstructured data. I write about unstructured data and use powerful visualization tools to analyze and make informed decisions.*\n\n## ÂèÇËÄÉÊñáÁåÆ\n\n\\[1] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, Haofen Wang: [Retrieval\\-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997) (2024\\), arxiv\n\n\\[2] Yixuan Tang, Yi Yang: [MultiHop\\-RAG: Benchmarking Retrieval\\-Augmented Generation for Multi\\-Hop Queries](https://arxiv.org/abs/2401.15391) (2021\\), arXiv\n\n\\[3] Leland McInnes, John Healy, James Melville: [UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction](https://arxiv.org/abs/1802.03426) (2018\\), arXiv\n\n\\[4] Shahul Es, Jithin James, Luis Espinosa\\-Anke, Steven Schockaert: [RAGAS: Automated Evaluation of Retrieval Augmented Generation](https://arxiv.org/abs/2309.15217) (2023\\), arXiv\n\n"},{"lang":"zh","group":"blog","slug":"blog/whats-new-with-claude-sonnet-3-5-claude-3-5-haiku-c1f62a2d2c72","frontmatter":{"title":"Claude Sonnet 3.5 Âíå Claude 3.5 Haiku ÊúâÂì™‰∫õÊñ∞ÂäüËÉΩÔºü","meta_title":"Claude Sonnet 3.5 Âíå Claude 3.5 Haiku ÊúâÂì™‰∫õÊñ∞ÂäüËÉΩÔºü","description":"ÂÄºÂæó‰∏ÄËØïÂêóÔºü","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*CEMTDlHlMUX66-eoMcSOzg.png","categories":["Natural Language Processing","Programming","Technology/Web"],"author":"Rifx.Online","tags":["language","models","interaction","automation","latency"],"draft":false,"slug":"blog/whats-new-with-claude-sonnet-3-5-claude-3-5-haiku-c1f62a2d2c72"},"content":"\n\n\n\n\n### È¶ñÂÖàÔºåClaudeÊòØ‰ªÄ‰πàÔºü\n\nClaudeÊòØÁî±[Anthropic](https://proxy.rifx.online/https://www.anthropic.com/)ÂàõÂª∫ÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®Â∏ÆÂä©ÂÆåÊàêËØ∏Â¶ÇÂõûÁ≠îÈóÆÈ¢ò„ÄÅÊÄªÁªì‰ø°ÊÅØÂíåÁîüÊàêÊñáÊú¨Á≠â‰ªªÂä°‚Äî‚ÄîÁ±ª‰ºº‰∫éChatGPT„ÄÇClaudeÁöÑ‰∏Ä‰∏™‰ºòÁÇπÊòØÂÆÉË¢´ËÆæËÆ°ÂæóÊõ¥ÂÆâÂÖ®ÔºåÊõ¥Á¨¶Âêà‰∫∫Á±ªÊÑèÂõæÔºåÂõ†Ê≠§ÁîüÊàêÊúâÂÆ≥ÊàñËØØÂØºÊÄßÂÜÖÂÆπÁöÑÂèØËÉΩÊÄßËæÉÂ∞è„ÄÇ\n\n### Á≠âÁ≠â‚Ä¶‚Ä¶Claude 3\\.5 Sonnet ‰∏çÊòØÂ∑≤ÁªèÂèëÂ∏É‰∫ÜÂêóÔºü\n\nÂìàÂìàÔºåÊòØÁöÑÔºåËôΩÁÑ∂ÂêçÁß∞Ê≤°ÊúâÂèòÂåñÔºå‰ΩÜËøô‰∏™‰∫é2024Âπ¥10Êúà22Êó•ÂèëÂ∏ÉÁöÑÊñ∞ÁâàÊú¨Claude 3\\.5 SonnetÂíåClaude HaikuÊúâÂæàÂ§ö‰ª§‰∫∫ÂÖ¥Â•ãÁöÑÊõ¥Êñ∞„ÄÇ\n\nËøô‰∫õÊñ∞Ê®°ÂûãÂú®Ë∞ÉËØï‰ª£Á†ÅÂíå‰ªéÂõæÂÉè‰∏≠ËΩ¨ÂΩïÊñáÊú¨Á≠â‰ªªÂä°‰∏äÊõ¥Âø´„ÄÅÊõ¥Â•ΩÔºåËøô‰ΩøÂÆÉ‰ª¨Âú®Èõ∂ÂîÆÂíåÁâ©ÊµÅÁ≠âË°å‰∏ö‰∏≠ÁâπÂà´ÊúâÁî®„ÄÇ\n\n*Â¶ÇÊûúÊÇ®Â∏åÊúõËÆ®ËÆ∫Ëøô‰∫õÊñ∞ÂèòÂåñÂπ∂Êü•ÁúãÂ¶Ç‰ΩïÂ∞ÜÂÖ∂ÂÆûÊñΩÂà∞ÊÇ®ÁöÑÈ°πÁõÆ‰∏≠ÔºåËØ∑[ÁÇπÂáªËøôÈáå‰∏éÊàë‰ª¨ÂÆâÊéí‰∏ÄÊ¨°ÂÖçË¥πÁöÑÁîµËØù‰ºöËÆÆ](https://proxy.rifx.online/https://calendly.com/woyera-ai/)!*\n\n### ËÆ©Êàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£‰∏Ä‰∏ãÊúâ‰ªÄ‰πàÊñ∞‰∏úË•øÔºÅ\n\n## ‰∫∫Êú∫‰∫§‰∫í\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*p1anQynliN8ihnT8X2VYqw.gif)\n\nClaude 3.5 Sonnet ÊúÄÂ§ßÁöÑÊõ¥Êñ∞‰πã‰∏ÄÊòØÂÆÉËÉΩÂ§ü‰ª•Êõ¥Á±ª‰∫∫ÊñπÂºè‰∏éËÆ°ÁÆóÊú∫‰∫íÂä®„ÄÇ\n\nÂÆÉÁé∞Âú®ÂèØ‰ª•ÂØºËà™Â±èÂπï„ÄÅÁÇπÂáªÊåâÈíÆÂíåËæìÂÖ•ÔºåËøô‰∏∫Ëá™Âä®Âåñ‰ªªÂä°ÁîöËá≥ÂÆûÊó∂Â∑•‰ΩúÊµÅÁ®ãÊèê‰æõ‰∫Ü‰∏Ä‰∫õÈùûÂ∏∏ÊúâË∂£ÁöÑÂèØËÉΩÊÄß„ÄÇ\n\nËØ∑Ê≥®ÊÑèÔºåËøô‰∏™ÂäüËÉΩ‰ªçÂú®ÂÖ¨ÂºÄÊµãËØïÈò∂ÊÆµÔºå‰ΩÜÂÆÉÂ∑≤ÁªèÊòæÁ§∫Âá∫ÂæàÂ§ßÁöÑÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®Êú∫Âô®‰∫∫ÊµÅÁ®ãËá™Âä®ÂåñÔºàRPAÔºâÊñπÈù¢„ÄÇ\n\n## Â¢ûÂº∫ÁöÑÁºñÁ†ÅÊîØÊåÅ\n\nClaudeÂèØ‰ª•Âú®Êï¥‰∏™ËΩØ‰ª∂ÂºÄÂèëËøáÁ®ã‰∏≠Êèê‰æõÂ∏ÆÂä©Ôºå‰ªéËÆæËÆ°„ÄÅË∞ÉËØïÂà∞‰ºòÂåñ‰ª£Á†Å‚Äî‚ÄîÂØπ‰∫é‰ªª‰ΩïÊäÄÊúØ‰∫∫ÂëòÊù•ËØ¥ÔºåÂÆÉÈÉΩÊòØ‰∏Ä‰∏™ÂÆùË¥µÁöÑËµÑ‰∫ß„ÄÇ\n\n## ÊîπËøõÁöÑËÅäÂ§©Êú∫Âô®‰∫∫\n\nClaude ÁöÑËá™ÁÑ∂ËØ≠Ë∞ÉÂíåÈ´òÁ∫ßÊé®ÁêÜËÉΩÂäõ‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÊûÑÂª∫Êõ¥ÂÖ∑ÂìçÂ∫îÊÄßÂíå‰∫íÂä®ÊÄßÁöÑËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ\n\nÂÆÉËÉΩÂ§üÂ§ÑÁêÜÂ§çÊùÇÁöÑÂØπËØùÔºåÁîöËá≥ÂèØ‰ª•‰∏éÂêÑÁßçÁ≥ªÁªüËøûÊé•‰ª•ÁÆÄÂåñ‰ªªÂä°ÔºåËøô‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÂÆ¢Êà∑ÊúçÂä°„ÄÅÊäÄÊúØÊîØÊåÅÁ≠â„ÄÇ\n\n## ËßÜËßâÊï∞ÊçÆÊèêÂèñ\n\n‰∏Ä‰∏™ÊòæËëóÁöÑÁâπÁÇπÊòØClaudeÂàÜÊûêËßÜËßâÊï∞ÊçÆÁöÑËÉΩÂäõ„ÄÇÂÆÉÂèØ‰ª•ËΩªÊùæÂú∞Ëß£ÈáäÂíåÊèêÂèñÂõæË°®„ÄÅÂõæÂΩ¢ÂíåÂõæËß£‰∏≠ÁöÑ‰ø°ÊÅØ„ÄÇ\n\n## Áü•ËØÜÈóÆÁ≠î\n\nClaude 3\\.5 Sonnet ‰πüÈùûÂ∏∏ÈÄÇÂêà‰ΩøÁî®Â§ßÂûãÊï∞ÊçÆÈõÜ„ÄÅÁü•ËØÜÂ∫ìÊàñ‰ª£Á†ÅÂ∫ìÊù•ÂõûÁ≠îËØ¶ÁªÜÈóÆÈ¢ò„ÄÇÂá≠ÂÄüÊõ¥Â§ßÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÔºåÂÆÉÊòØÈúÄË¶ÅÂø´ÈÄü„ÄÅÂáÜÁ°Æ‰ø°ÊÅØÁöÑ‰ºÅ‰∏öÁöÑÂèØÈù†ÈÄâÊã©„ÄÇ\n\n## ÂèØÁî®ÊÄßÂíåÂÆö‰ª∑\n\nClaude 3\\.5 ÂèØÈÄöËøá Anthropic API„ÄÅAmazon Bedrock Âíå Google Cloud ÁöÑ Vertex AI ‰Ωú‰∏∫ API ‰ΩøÁî®„ÄÇÂØπ‰∫é APIÔºåÂÆö‰ª∑‰ªé **ÊØèÁôæ‰∏áËæìÂÖ•‰ª§Áâå $3** Âíå **ÊØèÁôæ‰∏áËæìÂá∫‰ª§Áâå $15** ÂºÄÂßã„ÄÇ\n\nÊàñËÄÖÔºåÊÇ®ÂèØ‰ª•ÈÄöËøá [claude.ai](https://proxy.rifx.online/https://claude.ai/login?returnTo=%2F%3F) Âú®ÁΩë‰∏äÁÆÄÂçï‰ΩøÁî®„ÄÇÊÇ®ÂèØ‰ª•ÂÖçË¥πÂàõÂª∫‰∏Ä‰∏™Â∏êÊà∑ÔºåÁÑ∂Âêé Pro ËÆ°Âàí‰∏∫ÊØèÊúà $20ÔºåTeam ËÆ°Âàí‰∏∫ÊØèÊúà $25ÔºåÊàñ [Enterprise.](https://proxy.rifx.online/https://www.anthropic.com/pricing)\n\n## ÂÆâÂÖ®ÊÄß‰∏é‰ø°‰ªª\n\nAnthropic Âú®Á°Æ‰øù Claude 3\\.5 Sonnet ÁöÑÂÆâÂÖ®ÊÄßÊñπÈù¢ÊäïÂÖ•‰∫ÜÂ§ßÈáèÁ≤æÂäõ„ÄÇËØ•Ê®°ÂûãÁªèËøáÂπøÊ≥õÊµãËØïÔºå‰ª•Á°Æ‰øùÂÖ∂ËÉΩÂ§üË¥üË¥£‰ªªÂú∞Â§ÑÁêÜÊïèÊÑüÂÜÖÂÆπÔºåËÄå‰∏çÂΩ±ÂìçÊÄßËÉΩ„ÄÇ\n\nËøôÁßçÂØπÂÆâÂÖ®ÊÄßÁöÑÂÖ≥Ê≥®ÊúâÂä©‰∫éÈò≤ËåÉ‰∏çÂΩìÂÜÖÂÆπÁ≠âÈóÆÈ¢òÔºåÂπ∂Á°Æ‰øù Claude ÈÄÇÁî®‰∫éÂπøÊ≥õÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇ\n\n## Áî®‰æã\n\nÊó†ËÆ∫ÊÇ®ÊòØÂºÄÂèëËÄÖ„ÄÅ‰ºÅ‰∏ö‰∏ªÔºåËøòÊòØÂØπ‰∫∫Â∑•Êô∫ËÉΩÊÑüÂà∞Â•ΩÂ•áÔºåClaude 3.5 Sonnet ÈÉΩËÉΩÊèê‰æõÂæàÂ§öÂäüËÉΩ„ÄÇ\n\n### Ëá™Âä®ÂåñÈáçÂ§ç‰ªªÂä°\n\nÂÆ¢Êà∑ÊúçÂä°Âõ¢ÈòüÂèØ‰ª•‰ΩøÁî®ClaudeÂ§ÑÁêÜÈáçÂ§çÁöÑÂêéÂè∞‰ªªÂä°ÔºåÂ¶ÇÊõ¥Êñ∞ÂÆ¢Êà∑ËÆ¢ÂçïÊàñÂ§ÑÁêÜÈÄÄÊ¨æ„ÄÇClaudeËÉΩÂ§üÂØºËà™Â±èÂπïÂíåÁÇπÂáªÊåâÈíÆÔºåÂèØ‰ª•ËäÇÁúÅÊï∞Â∞èÊó∂ÁöÑÊâãÂä®Â∑•‰Ωú„ÄÇ\n\n### ËÅäÂ§©Êú∫Âô®‰∫∫\n\nÂåªÁñóÊúçÂä°Êèê‰æõËÄÖÂèØ‰ª•‰ΩøÁî®ClaudeÊûÑÂª∫ËÅäÂ§©Êú∫Âô®‰∫∫Ôºå‰ª•Â§ÑÁêÜÊÇ£ËÄÖ‰∫íÂä®Ôºå‰æãÂ¶ÇÈ¢ÑÁ∫¶„ÄÅÂõûÁ≠îÂåªÁñóÂ∏∏ËßÅÈóÆÈ¢òÊàñÊåáÂØºÊÇ£ËÄÖËøõË°åÁóáÁä∂Ê£ÄÊü•„ÄÇÊâÄÊúâËøô‰∫õÈÉΩ‰øùÊåÅËá™ÁÑ∂ÂíåÂØπËØùÁöÑËØ≠Ê∞î„ÄÇ\n\n### ËßÜËßâÊï∞ÊçÆ\n\nÈáëËûçÂàÜÊûêÂ∏àÂèØ‰ª•‰ΩøÁî®ClaudeÂàÜÊûêÂåÖÂê´Â§ßÈáèÂõæË°®ÂíåÂõæÂΩ¢ÁöÑÂ≠£Â∫¶Ë¥¢Êä•„ÄÇClaudeÂèØ‰ª•Âø´ÈÄüÊèêÂèñÊ¥ûÂØüÂπ∂ÊÄªÁªìÂÖ≥ÈîÆË∂ãÂäø„ÄÇ\n\n### Áü•ËØÜÈóÆÁ≠î\n\n‰∏ÄÂÆ∂ÁßëÊäÄÂÖ¨Âè∏ÂèØ‰ª•‰ΩøÁî®ClaudeÊù•ÁÆ°ÁêÜÂÜÖÈÉ®Áü•ËØÜÂ∫ì„ÄÇÂºÄÂèë‰∫∫ÂëòÂèØ‰ª•ËØ¢ÈóÆÊúâÂÖ≥Áé∞Êúâ‰ª£Á†ÅÂ∫ìÊàñÊïÖÈöúÊéíÈô§Ê≠•È™§ÁöÑËØ¶ÁªÜÈóÆÈ¢òÔºåClaudeÂ∞ÜÊèê‰æõÂø´ÈÄü‰∏îÂèØÈù†ÁöÑÁ≠îÊ°à„ÄÇ\n\n## ÂÖ≥‰∫é Claude 3\\.5 HaikuÔºü\n\nClaude 3\\.5 Haiku ÊòØ Anthropic ÊúÄÂø´ÁöÑ AI Ê®°ÂûãÔºåÊèê‰æõÊõ¥Â•ΩÁöÑÊÄßËÉΩÔºåÂêåÊó∂‰∏çÊèêÈ´òÊàêÊú¨ÊàñÈôç‰ΩéÈÄüÂ∫¶„ÄÇÂÆÉÂú®ÁºñÁ†ÅÁ≠â‰ªªÂä°‰∏äÊõ¥Âº∫Â§ßÔºåÂπ∂Âú®Âü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫Ü Claude 3 Opus Âíå GPT\\-4o Á≠âÊ®°Âûã„ÄÇ\n\nËØ•Ê®°ÂûãËÆæËÆ°ÂÖ∑Êúâ‰ΩéÂª∂ËøüÔºåÊÑèÂë≥ÁùÄÂÆÉÂìçÂ∫îËøÖÈÄüÔºåÈùûÂ∏∏ÈÄÇÂêàÂÆûÊó∂Â∫îÁî®„ÄÅ‰∏™ÊÄßÂåñ‰ªªÂä°ÔºàÂ¶ÇÂàÜÊûêË¥≠‰π∞ÂéÜÂè≤Ôºâ‰ª•ÂèäÂÖ∂‰ªñÊï∞ÊçÆÂØÜÈõÜÂûãÈ°πÁõÆ„ÄÇÂÆÉÂ∞ÜÂú®Êú¨ÊúàÊôö‰∫õÊó∂ÂÄôÈÄöËøá Amazon Bedrock Âíå Google Cloud Á≠â API Êèê‰æõÔºåËµ∑ÂàùÂ∞Ü‰Ωú‰∏∫‰ªÖÊñáÊú¨Ê®°ÂûãÔºåÂõæÂÉèÊîØÊåÅÂ∞ÜÂæàÂø´Êé®Âá∫„ÄÇ\n\n## ÈÇ£‰πàÔºåClaude‰∏éChatGPTÁõ∏ÊØîÂ¶Ç‰ΩïÔºü\n\nÂú®ÊØîËæÉ**Claude 3\\.5**Âíå**ChatGPT**Êó∂Ôºå‰∏§ËÄÖÈÉΩÊòØÂÖàËøõÁöÑAIÊ®°ÂûãÔºåÊó®Âú®Â§ÑÁêÜÁ±ª‰ººÁöÑ‰ªªÂä°ÔºåÂ¶ÇÂõûÁ≠îÈóÆÈ¢ò„ÄÅÁîüÊàêÊñáÊú¨ÂíåÂçèÂä©ÁºñÁ†ÅÔºå‰ΩÜÂÆÉ‰ª¨ÊúâÊòéÊòæÁöÑÂ∑ÆÂºÇÔºåÂèØËÉΩÈÄÇÂêà‰∏çÂêåÁöÑÈúÄÊ±Ç„ÄÇ\n\nClaude 3\\.5Âº∫Ë∞É**ÂÆâÂÖ®ÊÄß**ÔºåÂáèÂ∞ëÊúâÂÆ≥ÊàñËØØÂØºÊÄßËæìÂá∫ÁöÑÈ£éÈô©„ÄÇËôΩÁÑ∂ChatGPT‰πüÈáçËßÜÂÆâÂÖ®ÊÄßÔºå‰ΩÜClaudeÁöÑËÆæËÆ°Âú®Ëøô‰∏ÄÈ¢ÜÂüüÁªô‰∫à‰∫ÜÈ¢ùÂ§ñÂÖ≥Ê≥®„ÄÇ\n\nÂú®**ÈÄüÂ∫¶**ÊñπÈù¢ÔºåClaude 3\\.5 HaikuÊèê‰æõÊõ¥Âø´ÁöÑÂìçÂ∫îÊó∂Èó¥Ôºå‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÂÆûÊó∂Â∫îÁî®„ÄÇChatGPT‰πüÂæàÂø´Ôºå‰ΩÜÂú®Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°‰∏äÂèØËÉΩ‰ºöÊúâËΩªÂæÆÂª∂Ëøü„ÄÇ\n\nÂú®**ÁºñÁ†Å**ÊñπÈù¢Ôºå‰∏§ÁßçÊ®°ÂûãË°®Áé∞ËâØÂ•Ω„ÄÇClaude 3\\.5 SonnetÂú®ÊúÄËøëÁöÑÂü∫ÂáÜÊµãËØï‰∏≠Âú®Ë∞ÉËØïÂíå‰ª£Á†ÅÁîüÊàêÊñπÈù¢Ë°®Áé∞Á™ÅÂá∫ÔºåËÄåChatGPT‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÂèØÈù†ÁöÑÁºñÁ†ÅÂ∏ÆÂä©ÂíåËß£ÈáäÈÄâÈ°π„ÄÇ\n\n‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑÂå∫Âà´ÊòØ**Áé∞ÂÆû‰∏ñÁïå‰∫§‰∫í**„ÄÇClaude 3\\.5ËÉΩÂ§üÂØºËà™Â±èÂπïÂíåËá™Âä®Âåñ‰ªªÂä°ÔºåËÄåChatGPTÂ∞öÊú™Êèê‰æõÊ≠§ÂäüËÉΩ„ÄÇ\n\nÂú®**ÂÆö‰ª∑**ÊñπÈù¢ÔºåChatGPTÊúâ‰∏Ä‰∏™ÂπøÊ≥õÂèØÁî®ÁöÑÂÖçË¥πÁâàÊú¨ÔºåËÄåClaudeÂàôÈÄöËøáÂÖ∂APIÂíå‰∫ëÂπ≥Âè∞Êèê‰æõÁÅµÊ¥ªÁöÑÂÆö‰ª∑„ÄÇ\n\nClaudeÂØπÂÆâÂÖ®ÊÄß„ÄÅ‰ΩéÂª∂ËøüÂíåÂÖàËøõÁé∞ÂÆû‰∏ñÁïå‰∫§‰∫íÁöÑÂÖ≥Ê≥®‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÊõ¥‰∏ì‰∏öÁöÑÂ∫îÁî®„ÄÇ‰∏éÊ≠§ÂêåÊó∂ÔºåChatGPTÁöÑÂ§öÂäüËÉΩÊÄß„ÄÅÂπøÊ≥õÂèØÁî®ÊÄßÂíåÂº∫Â§ßÁöÑÁºñÁ†ÅÊîØÊåÅ‰ΩøÂÖ∂Êàê‰∏∫‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÈÄöÁî®Â∑•ÂÖ∑„ÄÇ\n\nÊúÄÁªàÔºåÂú®‰∏§ËÄÖ‰πãÈó¥ÁöÑÈÄâÊã©ÂèñÂÜ≥‰∫éÊÇ®ÊâÄÂØªÊâæÁöÑÂÜÖÂÆπÔºå‰ΩÜËøô‰∏§ÁßçÊ®°ÂûãÈÉΩÊèê‰æõÂº∫Â§ßÁöÑËÉΩÂäõÂíåÁã¨ÁâπÁöÑ‰ºòÂäø„ÄÇ\n\n## ÁªìËÆ∫\n\n‰∫ÜËß£Êñ∞Â∑•ÂÖ∑ÁöÑÊúÄ‰Ω≥ÊñπÂºèÂ∞±ÊòØ‰∫≤Ëá™Â∞ùËØïÔºÅÊÇ®ÂèØ‰ª•‰ΩøÁî® Claude 3\\.5 Sonnet Êù•Â¢ûÂº∫ÁºñÁ†Å„ÄÅËÅäÂ§©Êú∫Âô®‰∫∫„ÄÅÊï∞ÊçÆÂàÜÊûêÁ≠âÂ§öÁßçÂäüËÉΩ„ÄÇ\n\nÂëäËØâÊàë‰ª¨ÊÇ®Â∞ÜÂ¶Ç‰Ωï‰ΩøÁî® Claude„ÄÇ\n\n*Â¶ÇÊûúÊÇ®ÈúÄË¶ÅÊûÑÂª∫Ëá™ÂÆö‰πâËÅäÂ§©Êú∫Âô®‰∫∫ÊàñÂ∫îÁî®Á®ãÂ∫èÔºåËØ∑[ÁÇπÂáªËøôÈáå‰∏éÊàë‰ª¨Âø´ÈÄüÈÄöËØù„ÄÇ](https://proxy.rifx.online/https://calendly.com/woyera-ai/)*\n\n"},{"lang":"zh","group":"blog","slug":"blog/why-embedding-matters-when-building-a-non-english-rag-system-multilingual-embeddings-1e3434ea6180","frontmatter":{"title":"Âú®ÊûÑÂª∫ÈùûËã±ËØ≠ RAG Á≥ªÁªüÊó∂ÔºåÂµåÂÖ•‰∏∫‰ªÄ‰πàÂæàÈáçË¶Å - Â§öËØ≠Ë®ÄÂµåÂÖ•","meta_title":"Âú®ÊûÑÂª∫ÈùûËã±ËØ≠ RAG Á≥ªÁªüÊó∂ÔºåÂµåÂÖ•‰∏∫‰ªÄ‰πàÂæàÈáçË¶Å - Â§öËØ≠Ë®ÄÂµåÂÖ•","description":"ÈÄöËøáÂØπËã±ËØ≠‰∏éËç∑ÂÖ∞ËØ≠Â§öËØ≠Ë®ÄÊ®°ÂûãÁöÑËØ¶ÁªÜÊØîËæÉÔºå‰∫ÜËß£Â§öËØ≠Ë®ÄÂµåÂÖ•ÂØπ RAG Á≥ªÁªüËá≥ÂÖ≥ÈáçË¶ÅÁöÑÂéüÂõ†„ÄÇ","date":"2024-11-13T01:22:29.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*QvODAYxqisUTrt4V.png","categories":["Natural Language Processing","Machine Learning","Multilingual"],"author":"Rifx.Online","tags":["embeddings","multilingual","RAG","Cohere","Dutch"],"draft":false,"slug":"blog/why-embedding-matters-when-building-a-non-english-rag-system-multilingual-embeddings-1e3434ea6180"},"content":"\n\n\n## ‰∏∫‰ªÄ‰πàÂµåÂÖ•ÊòØÂÖ≥ÈîÆ\n\nÂµåÂÖ•ÊòØÁé∞‰ª£ÁîüÊàê AI ÁöÑÂü∫Áü≥ÔºåÈªòÈªòÊé®Âä®ÁùÄÊàë‰ª¨ÊØèÂ§©‰∫íÂä®ÁöÑËÆ∏Â§öÁ≥ªÁªüÁöÑÂäüËÉΩ„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåÂµåÂÖ•ÊòØ **ÊñáÊú¨ÁöÑÊï∞ÂÄºË°®Á§∫** ‚Äî‚Äî ÊúâÊïàÂú∞Â∞ÜÂçïËØç„ÄÅÂè•Â≠êÁîöËá≥Êï¥‰∏™ÊñáÊ°£ËΩ¨Êç¢‰∏∫Êï∞Â≠ó„ÄÇËøô‰∫õÊï∞Â≠óËøúÈùûÈöèÊú∫ÔºõÂÆÉ‰ª¨ÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•ÊçïÊçâÊñáÊú¨‰∏≠ÁöÑÂê´‰πâÂíåÂÖ≥Á≥ª„ÄÇ‰æãÂ¶ÇÔºå‚Äúdog‚ÄùÂíå‚Äúpuppy‚ÄùÁöÑÂµåÂÖ•Âú®Êï∞ÂÄºÁ©∫Èó¥‰∏≠‰ºöÊõ¥Èù†ËøëÔºåËÄå‚Äúcar‚ÄùÁöÑÂµåÂÖ•Âàô‰ºöÁõ∏ÂØπËæÉËøúÔºåÂèçÊò†Âá∫ÂÆÉ‰ª¨ÁöÑ **ËØ≠‰πâÁõ∏‰ººÊÄß**„ÄÇÂ∞ÜÊÑè‰πâÁºñÁ†Å‰∏∫ÂèØÊµãÈáèÁöÑÂΩ¢ÂºèÁöÑËÉΩÂäõÔºå‰ΩøÂæóÂµåÂÖ•Âú®ÊêúÁ¥¢„ÄÅÊé®ËçêÁ≥ªÁªü‰ª•Âèä **Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG)** Á≠âÈ´òÁ∫ß AI Â∫îÁî®‰∏≠‰∏çÂèØÊàñÁº∫„ÄÇ\n\n\n\nËøôÁßçÊï∞Â≠óÂåñËΩ¨Âåñ‰Ωø AI ËÉΩÂ§ü‰ª•ÊúâÊÑè‰πâÁöÑÊñπÂºèÊØîËæÉÂíåÁêÜËß£ÊñáÊú¨„ÄÇÂΩìÂ§ÑÁêÜÂ§ßÈáèÊï∞ÊçÆÊó∂ÔºåÂ∞§ÂÖ∂ÊòØÂú® RAG Á≥ªÁªü‰∏≠ÔºåÂµåÂÖ•ÂèòÂæóËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøô‰∫õÁ≥ªÁªüÂ∞ÜÂµåÂÖ•ÁöÑÂäõÈáè‰∏éÁß∞‰∏∫ **ÂêëÈáèÊï∞ÊçÆÂ∫ì** ÁöÑ‰∏ìÁî®Â≠òÂÇ®Ëß£ÂÜ≥ÊñπÊ°àÁõ∏ÁªìÂêà„ÄÇ‰∏é‰º†ÁªüÊï∞ÊçÆÂ∫ìÊêúÁ¥¢Á≤æÁ°ÆÂåπÈÖç‰∏çÂêåÔºåÂêëÈáèÊï∞ÊçÆÂ∫ìÁªèËøá‰ºòÂåñÔºå‰ª•Ê†πÊçÆÂê´‰πâÊâæÂà∞ÊúÄÊé•ËøëÁöÑÂåπÈÖç„ÄÇËøôÁßçËÉΩÂäõ‰Ωø RAG Á≥ªÁªüËÉΩÂ§ü‰ªéÂ∫ûÂ§ßÁöÑÁü•ËØÜÂ∫ì‰∏≠Ê£ÄÁ¥¢Âá∫ÊúÄÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØÔºåÂπ∂Áî®ÂÆÉÁîüÊàêÂáÜÁ°Æ„ÄÅÂÖ∑Êúâ‰∏ä‰∏ãÊñáÁöÑÂìçÂ∫î„ÄÇÈÄöËøáÊ°•Êé•ÂéüÂßãÊï∞ÊçÆÂíåÊô∫ËÉΩÊ£ÄÁ¥¢ÔºåÂµåÂÖ•ÂíåÂêëÈáèÊï∞ÊçÆÂ∫ìÂÖ±ÂêåÊûÑÊàê‰∫Ü RAG Á≥ªÁªüÊàêÂäüÁöÑÂü∫Á°Ä„ÄÇ\n\n## Â§öËØ≠Ë®ÄÁ≥ªÁªüÁöÑÊåëÊàò\n\nÊûÑÂª∫Âú®Ëã±ËØ≠‰∏≠Ë°®Áé∞ËâØÂ•ΩÁöÑRAGÁ≥ªÁªüÂ∑≤ÁªèÊòØ‰∏ÄÈ°πÂ§çÊùÇÁöÑ‰ªªÂä°Ôºå‰ΩÜÂ∞ÜÂÖ∂Êâ©Â±ïÂà∞ÂÖ∂‰ªñËØ≠Ë®ÄÂàôÂ∏¶Êù•‰∫ÜÂÖ®Êñ∞ÁöÑÊåëÊàò„ÄÇÁî±‰∫éËÆ≠ÁªÉÊï∞ÊçÆ‰∏∞ÂØåÂíåËØ≠Ë®ÄÁªìÊûÑÁÆÄÂçïÔºåËã±ËØ≠ÂµåÂÖ•ÈÄöÂ∏∏ÁªèËøáÈ´òÂ∫¶‰ºòÂåñ„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®Ëøô‰∫õÁªèËøáËã±ËØ≠ËÆ≠ÁªÉÁöÑÂµåÂÖ•Êù•Â§ÑÁêÜÂÖ∂‰ªñËØ≠Ë®ÄÂèØËÉΩ‰ºöÂØºËá¥ÊòæËëóÁöÑ‰∏çÂáÜÁ°ÆÊÄß„ÄÇ‰∏çÂêåËØ≠Ë®ÄÂÖ∑ÊúâÂÖ∂Ëá™Ë∫´ÁöÑÁªÜÂæÆÂ∑ÆÂà´„ÄÅËØ≠Ê≥ïÂíåÊñáÂåñËÉåÊôØÔºåËÄå‰∏ªË¶ÅÂü∫‰∫éËã±ËØ≠ÊñáÊú¨ËÆ≠ÁªÉÁöÑÊ†áÂáÜÂµåÂÖ•Ê®°ÂûãÂæÄÂæÄÊó†Ê≥ïÊçïÊçâËøô‰∫õÁâπÂæÅ„ÄÇËôΩÁÑ∂Â≠òÂú®‰∏Ä‰∫õÂ§öËØ≠Ë®ÄÂµåÂÖ•Ê®°ÂûãÊù•Âº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÆÉ‰ª¨Âú®‰∏çÂêåËØ≠Ë®Ä‰∏≠ÁöÑÊúâÊïàÊÄßÂπ∂‰∏çÁõ∏ÂêåÔºåÂ∞§ÂÖ∂ÊòØÂØπ‰∫éÈÇ£‰∫õËÆ≠ÁªÉÊï∞ÊçÆÊúâÈôêÊàñÂÖ∑ÊúâÁã¨ÁâπËØ≠Ë®ÄÁâπÂæÅÁöÑËØ≠Ë®Ä„ÄÇËøô‰ΩøÂæóÊûÑÂª∫Âú®ÈùûËã±ËØ≠ËØ≠Ë®Ä‰∏≠‰∏éËã±ËØ≠‰∏ÄÊ†∑ÂáÜÁ°ÆÂíåÂèØÈù†ÁöÑRAGÁ≥ªÁªüÂèòÂæóÂõ∞Èöæ„ÄÇ\n\n### ‰∏∫‰ªÄ‰πàËã±ËØ≠ÂµåÂÖ•Êõ¥ÂáÜÁ°ÆÔºü\n\n1. **È´òË¥®ÈáèËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰∏∞ÂØåÊÄß**  \nËã±ËØ≠‰∏ªÂØº‰∫ÜÊï∞Â≠óÈ¢ÜÂüüÔºåÊã•ÊúâÊó†‰∏é‰º¶ÊØîÁöÑÈ´òË¥®ÈáèÂÜÖÂÆπÂèØ‰æõËÆ≠ÁªÉ„ÄÇÂÉèÁª¥Âü∫ÁôæÁßë„ÄÅ‰π¶Á±ç„ÄÅÁ†îÁ©∂ËÆ∫ÊñáÂíåÁ§æ‰∫§Â™í‰ΩìÁ≠âÊï∞ÊçÆÈõÜÂú®Ëã±ËØ≠‰∏≠Ë¶ÅÊØîÂÖ∂‰ªñËØ≠Ë®Ä‰∏∞ÂØåÂæóÂ§ö„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåËÆ∏Â§öËØ≠Ë®ÄÔºåÁâπÂà´ÊòØ‰ΩéËµÑÊ∫êËØ≠Ë®ÄÔºåÁº∫‰πèÂ§öÊ†∑ÂåñÂíåÊ†áÂáÜÂåñÁöÑÊï∞ÊçÆÈõÜÔºåËøôÈôêÂà∂‰∫ÜÂú®Ëøô‰∫õËØ≠Ë®Ä‰∏äËÆ≠ÁªÉÁöÑÂµåÂÖ•ÁöÑË¥®Èáè„ÄÇ\n2. **Ê®°Âûã‰ºòÂåñÂÅèËßÅ**  \nÂÉèBERTÂíåGPTËøôÊ†∑ÁöÑNLPÊ®°ÂûãÊúÄÂàùÊòØ‰∏∫Ëã±ËØ≠ÂºÄÂèëÂíå‰ºòÂåñÁöÑÔºåÈÄöÂ∏∏Âú®Â§öËØ≠Ë®ÄÁâàÊú¨‰∏≠‰ªçÁÑ∂‰ºòÂÖàËÄÉËôëËã±ËØ≠„ÄÇÂ§öËØ≠Ë®ÄÊ®°ÂûãÂú®Âêå‰∏ÄÂèÇÊï∞Á©∫Èó¥ÂÜÖÂπ≥Ë°°Â§öÁßçËØ≠Ë®ÄÁöÑÂ≠¶‰π†ÔºåËøôÂèØËÉΩ‰ºöÁ®ÄÈáäÂØπ‰ª£Ë°®ÊÄßËæÉÂ∞ëÁöÑËØ≠Ë®ÄÁöÑÊÄßËÉΩÔºåÂÄæÂêë‰∫éÂÉèËã±ËØ≠ËøôÊ†∑ÁöÑ‰∏ªÂØºËØ≠Ë®Ä„ÄÇ\n3. **ËØ≠Ë®ÄÂ§çÊùÇÊÄßÂíåÂ§öÊ†∑ÊÄß**  \n‰∏éËÆ∏Â§öÂÖ∂‰ªñËØ≠Ë®ÄÁõ∏ÊØîÔºåËã±ËØ≠ÁöÑÂΩ¢ÊÄÅÁõ∏ÂØπÁÆÄÂçï„ÄÇ‰æãÂ¶ÇÔºåËã±ËØ≠‰∏≠ÁöÑËØçÂΩ¢ÂæÄÂæÄ‰øùÊåÅ‰∏ÄËá¥Ôºà‰æãÂ¶ÇÔºå‚Äúrun‚ÄùÂíå‚Äúrunning‚ÄùÔºâÔºåËÄåÂÉèÂúüËÄ≥ÂÖ∂ËØ≠ÊàñËä¨ÂÖ∞ËØ≠ËøôÊ†∑ÁöÑËØ≠Ë®ÄÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂ±àÊäòÂΩ¢ÂºèÔºå‰∏Ä‰∏™Ê†πËØçÂèØËÉΩÊúâÊï∞ÂçÅÁßçÂèòÂåñ„ÄÇÊ≠§Â§ñÔºåÂÖ∑Êúâ‰∏çÂêåËØ≠Ê≥ïÊàñËØçÂ∫èÁöÑËØ≠Ë®ÄÔºåÂ¶ÇÊó•ËØ≠Ôºà‰∏ªËØ≠-ÂÆæËØ≠-Âä®ËØçÔºâÊàñÈòøÊãâ‰ºØËØ≠ÔºàÁÅµÊ¥ªÁöÑËØçÂ∫èÔºâÔºåÂØπ‰ºòÂåñ‰∏∫Ëã±ËØ≠ÁªìÊûÑÁöÑÊ®°ÂûãÊûÑÊàêÈ¢ùÂ§ñÊåëÊàò„ÄÇ\n4. **ËØ≠‰πâÂíåÊñáÂåñÂØπÈΩê**  \nË∑®ËØ≠Ë®ÄÊçïÊçâËØ≠‰πâÊÑè‰πâËøúÈùûÁÆÄÂçï„ÄÇÂçïËØçÂíåÁü≠ËØ≠ÂæÄÂæÄÂ∏¶ÊúâÁªÜÂæÆÁöÑÂê´‰πâÔºåÊó†Ê≥ïÁõ¥Êé•ÁøªËØë„ÄÇ‰æãÂ¶ÇÔºåËã±ËØ≠ÂçïËØç‚Äúlove‚ÄùÂú®ÂÖ∂‰ªñËØ≠Ë®Ä‰∏≠ÊúâÂ§ö‰∏™ÊñáÂåñ‰∏äÁã¨ÁâπÁöÑÂØπÂ∫îËØçÔºà‰æãÂ¶ÇÔºåË•øÁè≠ÁâôËØ≠‰∏≠ÁöÑ‚Äúamor‚ÄùÔºåÂ∏åËÖäËØ≠‰∏≠ÁöÑ‚Äúeros‚ÄùÊàñ‚Äúagape‚ÄùÔºâ„ÄÇÊú™ËÉΩËÄÉËôëËøô‰∫õÂ∑ÆÂºÇÁöÑÂµåÂÖ•Âú®Â§öËØ≠Ë®ÄÂØπÈΩêÊñπÈù¢Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ\n5. **Âü∫ÂáÜÊµãËØïÂíåËØÑ‰º∞ÂÅèËßÅ**  \nËÆ∏Â§öÂü∫ÂáÜÊï∞ÊçÆÈõÜÂíåËØÑ‰º∞ÊñπÊ≥ïÈÉΩÊòØ‰ª•Ëã±ËØ≠‰∏∫‰∏≠ÂøÉËÆæËÆ°ÁöÑ„ÄÇËøôÁßç‰ª•Ëã±ËØ≠‰∏∫‰∏≠ÂøÉÁöÑÂÖ≥Ê≥®ÂèØËÉΩ‰ºö‰∫∫‰∏∫Âú∞ÊèêÈ´òÊ®°ÂûãÂú®Ëã±ËØ≠‰∏≠ÁöÑÊÑüÁü•ÊÄßËÉΩÔºåÂêåÊó∂Êé©ÁõñÂÆÉ‰ª¨Âú®ÂÖ∂‰ªñËØ≠Ë®Ä‰∏≠ÁöÑÂ±ÄÈôêÊÄß„ÄÇ\n\n### ÂØπ RAG Á≥ªÁªüÁöÑÂΩ±Âìç\n\nÂΩìÂµåÂÖ•Êó†Ê≥ïÂ§ÑÁêÜÂÖ∂‰ªñËØ≠Ë®ÄÁöÑÂ§çÊùÇÊÄßÊó∂ÔºåÂØπ RAG Á≥ªÁªüÁöÑÂΩ±ÂìçÂèØËÉΩÊòØÊòæËëóÁöÑ„ÄÇÊ£ÄÁ¥¢ÁªìÊûúÂæÄÂæÄÂèòÂæó‰∏çÁõ∏ÂÖ≥ÔºåÁîöËá≥ÂÆåÂÖ®ÈîôËØØÔºåÂõ†‰∏∫ÂµåÂÖ•ÂèØËÉΩÈöæ‰ª•ÊçïÊçâÈùûËã±ËØ≠Êü•ËØ¢ÁöÑÁªÜÂæÆÂê´‰πâ„ÄÇËøô‰∏ç‰ªÖÂΩ±ÂìçÂáÜÁ°ÆÊÄßÔºåËøòÂâäÂº±‰∫ÜÁî®Êà∑‰ø°‰ªªÂíåÁ≥ªÁªüÁöÑÊï¥‰ΩìÂÆûÁî®ÊÄß„ÄÇÂú®Ê£ÄÁ¥¢ËøáÁ®ã‰∏≠ÔºåÂÖ≥ÈîÆÊñáÊú¨ÁâáÊÆµÂèØËÉΩË¢´ÈÅóÊºèÔºåÈòªÊ≠¢Á≥ªÁªüËé∑ÂèñÁîüÊàêÂáÜÁ°Æ‰∏î‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÁöÑÂìçÂ∫îÊâÄÈúÄÁöÑ‰ø°ÊÅØ„ÄÇ\n\n‰∏∫‰∫Ü‰ΩøÂ§öËØ≠Ë®Ä RAG Á≥ªÁªüË°®Áé∞ËâØÂ•ΩÔºåÂÆÉÈúÄË¶ÅËÉΩÂ§üÂú®ËØ≠Ë®Ä‰πãÈó¥ËØ≠‰πâÂØπÈΩêÁöÑÂµåÂÖ•ÔºåÂêåÊó∂ËÄÉËôëÂà∞ÂÆÉ‰ª¨Áã¨ÁâπÁöÑÁªìÊûÑÂíåÊñáÂåñÂ§çÊùÇÊÄß„ÄÇÊäïËµÑÈ´òË¥®ÈáèÁöÑÂ§öËØ≠Ë®ÄÂµåÂÖ•Âπ∂ÂØπÂÖ∂ËøõË°åÁâπÂÆöËØ≠Ë®ÄÊàñ‰ªªÂä°ÁöÑÂæÆË∞ÉÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑ„ÄÇËøôÁ°Æ‰øù‰∫Ü RAG Á≥ªÁªüËÉΩÂ§üÊª°Ë∂≥‰ªª‰ΩïËØ≠Ë®ÄÁî®Êà∑ÁöÑÈúÄÊ±Ç‚Äî‚Äî‰∏ç‰ªÖ‰ªÖÊòØËã±ËØ≠„ÄÇ\n\n‰ΩÜ‰∏çÂêåÁöÑÂµåÂÖ•Âú®ÈùûËã±ËØ≠ÁéØÂ¢É‰∏≠ÁöÑË°®Áé∞Â¶Ç‰ΩïÂë¢Ôºü‰∏∫‰∫ÜËß£Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®Ëç∑ÂÖ∞Êï∞ÊçÆÈõÜÊØîËæÉ‰∏Ä‰∏™Ëã±ËØ≠ÂµåÂÖ•Ê®°ÂûãÂíå‰∏Ä‰∏™Â§öËØ≠Ë®ÄÂµåÂÖ•Ê®°Âûã„ÄÇËøô‰∏™ÊµãËØïÂ∞ÜÊè≠Á§∫‰∏çÂêåÁöÑÂµåÂÖ•ÊñπÊ≥ïÂ¶Ç‰ΩïÂΩ±ÂìçÂ§öËØ≠Ë®Ä RAG Á≥ªÁªü‰∏≠ÁöÑÊ£ÄÁ¥¢ÂáÜÁ°ÆÊÄßÂíåÁîüÊàêÂìçÂ∫îÁöÑË¥®Èáè„ÄÇ\n\n## ÊØîËæÉËç∑ÂÖ∞ËØ≠RAGÁ≥ªÁªüÁöÑÂµåÂÖ•Ê®°Âûã\n\n‰∏∫‰∫Ü‰∫ÜËß£‰∏çÂêåÁöÑÂµåÂÖ•Ê®°ÂûãÂ¶Ç‰ΩïÂ§ÑÁêÜÂÉèËç∑ÂÖ∞ËØ≠ËøôÊ†∑ÁöÑÈùûËã±ËØ≠ËØ≠Ë®ÄÔºåÊàë‰ª¨Â∞ÜÊØîËæÉÂú®Amazon Bedrock‰∏äÂèØÁî®ÁöÑ‰∏§‰∏™Ê®°ÂûãÔºö**Cohere Embed English v3**Âíå**Cohere Embed Multilingual v3**„ÄÇËøô‰∏§‰∏™Ê®°Âûã‰ª£Ë°®‰∫ÜÂØπÂµåÂÖ•ÁöÑ‰∏çÂêåÂ§ÑÁêÜÊñπÂºè‚Äî‚Äî‰∏Ä‰∏™‰∏ìÈó®ÈíàÂØπËã±ËØ≠ËøõË°å‰∫Ü‰ºòÂåñÔºåÂè¶‰∏Ä‰∏™ÂàôËÆæËÆ°Áî®‰∫éÂ§öËØ≠Ë®Ä‰ªªÂä°„ÄÇ‰∏ãË°®ÊÄªÁªì‰∫ÜÂÆÉ‰ª¨ÁöÑ‰∏ªË¶ÅÂ±ûÊÄßÔºö\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*pBhIHfOsb-McrjHKvtq4Xw.png)\n\n### ÊûÑÂª∫ÂµåÂÖ•\n\n‰∏∫‰∫ÜËØÑ‰º∞ÂµåÂÖ•Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî® LangChain Ê°ÜÊû∂ÊûÑÂª∫‰∏Ä‰∏™Êú¨Âú∞ÂêëÈáèÂ≠òÂÇ®„ÄÇÂØπ‰∫éÊ≠§Ê¨°ËØÑ‰º∞ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®Áî®Ëç∑ÂÖ∞ËØ≠Êí∞ÂÜôÁöÑÊ∂àÈò≤ÂëòÊåáÂçó‰Ωú‰∏∫Êàë‰ª¨ÁöÑÊï∞ÊçÆÈõÜ„ÄÇËØ•ÊñáÊ°£ÂåÖÂê´ÊäÄÊúØÂíåÁ®ãÂ∫è‰ø°ÊÅØÔºå‰ΩøÂÖ∂Êàê‰∏∫ÈùûËã±ËØ≠ËØ≠Ë®ÄËØ≠‰πâÊ£ÄÁ¥¢ÁöÑ‰∏Ä‰∏™Áé∞ÂÆû‰∏îÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁî®‰æã„ÄÇ‰∏ãÈù¢ÊòØÂàõÂª∫Êú¨Âú∞ÂêëÈáèÂ≠òÂÇ®ÂíåÁ¥¢ÂºïÊñáÊ°£ÂùóÁöÑÊ∏ÖÁêÜÂíåÁÆÄÂåñ‰ª£Á†Å„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Ê≠§ËÆæÁΩÆÊù•ÊµãËØï‰∏§‰∏™ÂµåÂÖ•Ê®°ÂûãÔºö**Cohere Embed English v3** Âíå **Cohere Embed Multilingual v3**„ÄÇ\n\n```python\nimport os\nfrom langchain_community.document_loaders import DirectoryLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain_aws import BedrockEmbeddings\nimport boto3\n\n## Step 1: Load documents\nloader = DirectoryLoader('data', glob=\"**/*.pdf\")  # Adjust 'data' to your document directory\ndocuments = loader.load()\n\nprint(f\"You have {len(documents)} documents\")\nprint(f\"Document 1 contains {len(documents[0].page_content)} characters\")\n\n## Step 2: Split documents into smaller chunks\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\nchunks = text_splitter.split_documents(documents)\n\nprint(f\"You have {len(chunks)} chunks\")\nprint(f\"The first chunk is {len(chunks[0].page_content)} characters long\")\n\n## Step 3: Set up Bedrock embeddings\nbedrock_client = boto3.client(\"bedrock-runtime\", region_name='us-east-1')\nbedrock_embeddings = BedrockEmbeddings(model_id=\"cohere.embed-multilingual-v3\", client=bedrock_client)\n\n## Step 4: Build the FAISS vectorstore\nvectorstore = FAISS.from_documents(chunks, bedrock_embeddings)\n\n## Save the vectorstore locally for reuse\nvectorstore.save_local(\"faiss_cohere_multilingual\")\n```\n\n## ‰ª£Á†ÅÂ¶Ç‰ΩïÂ∑•‰Ωú\n\n1. **ÊñáÊ°£Âä†ËΩΩ**Ôºö\n‰ª£Á†Å‰ªé `data` ÁõÆÂΩïÂä†ËΩΩÊâÄÊúâ PDF Êñá‰ª∂„ÄÇÊÇ®ÂèØ‰ª•Ë∞ÉÊï¥Êñá‰ª∂Ë∑ØÂæÑÂíåÊ†ºÂºè‰ª•ÂåπÈÖçÊÇ®ÁöÑÊï∞ÊçÆÈõÜ„ÄÇ\n2. **ÊñáÊú¨ÊãÜÂàÜ**Ôºö\nÊñáÊ°£Ë¢´ÊãÜÂàÜ‰∏∫ÊØè‰∏™ 400 ‰∏™Â≠óÁ¨¶ÁöÑÂ∞èÂùóÔºåÈáçÂè† 50 ‰∏™Â≠óÁ¨¶Ôºå‰ª•ÊèêÈ´òÊ£ÄÁ¥¢ÁöÑÂáÜÁ°ÆÊÄß„ÄÇËøôÁ°Æ‰øùÊØè‰∏™ÂùóÂú®‰∏ä‰∏ãÊñá‰∏ä‰øùÊåÅÊúâÊÑè‰πâ„ÄÇ\n3. **ÂµåÂÖ•Ê®°Âûã**Ôºö\n`BedrockEmbeddings` Á±ªÂàùÂßãÂåñÂµåÂÖ•Ê®°Âûã„ÄÇÊÇ®ÂèØ‰ª•Êõ¥Êîπ `model_id` Êù•ÊµãËØï **Cohere Embed English v3 Êàñ Cohere Embed Multilingual v3**„ÄÇ\n4. **Êú¨Âú∞ÂêëÈáèÂ≠òÂÇ®**Ôºö\nFAISS Â∫ìÁî®‰∫é‰ªéÊñáÊ°£ÂùóÂàõÂª∫ÂÜÖÂ≠ò‰∏≠ÁöÑÂêëÈáèÂ≠òÂÇ®„ÄÇËøôÂÖÅËÆ∏Âø´ÈÄüÁõ∏‰ººÊÄßÊêúÁ¥¢ÔºåÂπ∂ÂèØ‰ª•Êú¨Âú∞‰øùÂ≠ò‰ª•‰æõÈáçÁî®„ÄÇ\n\nË¶ÅÊµãËØïÊâÄÊúâÊ®°ÂûãÔºåËØ∑Â∞Ü `BedrockEmbeddings` ÂàùÂßãÂåñ‰∏≠ÁöÑ `model_id` ÊõøÊç¢‰∏∫Áõ∏Â∫îÁöÑÊ®°ÂûãÔºö\n\n* `\"cohere.embed-english-v3\"` Áî®‰∫é Cohere English„ÄÇ\n* `\"cohere.embed-multilingual-v3\"` Áî®‰∫é Cohere Multilingual„ÄÇ\n\n### ËØÑ‰º∞ÂµåÂÖ•Ê®°Âûã\n\n‰∏∫‰∫ÜËØÑ‰º∞ÂµåÂÖ•Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÊàë‰ª¨Â∞ÜÊèêÂá∫ÈóÆÈ¢òÔºö**‚ÄúWelke rangen zijn er bij de brandweer?‚Äù**ÔºåÂÖ∂ÁøªËØë‰∏∫**‚ÄúÊ∂àÈò≤ÈÉ®Èó®Â≠òÂú®Âì™‰∫õÁ≠âÁ∫ßÔºü‚Äù**„ÄÇÈÄâÊã©Ëøô‰∏™ÈóÆÈ¢òÊòØÂõ†‰∏∫Êàë‰ª¨ÁöÑÊñáÊ°£‰∏≠‰ªÖ‰ΩøÁî®‰∫ÜÊúØËØ≠**‚Äúhi√´rarchie‚Äù**ÔºåÂú®Ëç∑ÂÖ∞ËØ≠‰∏≠‰∏é**‚Äúrangen‚Äù**ÂÖ∑ÊúâÁõ∏‰ººÁöÑËØ≠‰πâ„ÄÇÁÑ∂ËÄåÔºåÂú®Ëã±ËØ≠‰∏≠Ôºå‚Äúhierarchy‚ÄùÂíå‚Äúranks‚ÄùÂπ∂Ê≤°ÊúâËØ≠‰πâ‰∏äÁöÑÁõ∏‰ººÊÄß„ÄÇ\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*6N3C8C500hMQ3GNNkuu21A.png)\n\nËøôÁßçÂå∫Âà´ÂØπÊàë‰ª¨ÁöÑÊµãËØïËá≥ÂÖ≥ÈáçË¶Å„ÄÇÊàë‰ª¨È¢ÑÊúü**Cohere Embed English v3**Ê®°ÂûãÂú®Â§ÑÁêÜËøô‰∏™Êü•ËØ¢Êó∂‰ºöÈÅáÂà∞Âõ∞ÈöæÔºåÂõ†‰∏∫ÂÆÉ‰æùËµñ‰∫éËã±ËØ≠ËØ≠‰πâÔºåËÄåËøô‰∫õÊúØËØ≠Âπ∂‰∏çÁõ∏ÂÖ≥„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå**Cohere Embed Multilingual v3**Ê®°ÂûãÁªèËøáËÆ≠ÁªÉËÉΩÂ§üÁêÜËß£Ëç∑ÂÖ∞ËØ≠ËØ≠‰πâÔºåÂ∫îËØ•ËÉΩÂ§ü‰ªéÊñáÊ°£‰∏≠Ê£ÄÁ¥¢Âà∞Ê≠£Á°ÆÁöÑ‰ø°ÊÅØÔºåÂ±ïÁ§∫ÂÖ∂Â§ÑÁêÜÈùûËã±ËØ≠ËØ≠Ë®ÄËØ≠‰πâÁªÜÂæÆÂ∑ÆÂà´ÁöÑËÉΩÂäõ„ÄÇ\n\nÈÄöËøáÊèêÂá∫Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨Êó®Âú®Á™ÅÂá∫ËØ≠‰πâÂØπËç∑ÂÖ∞RAGÁ≥ªÁªüÊ£ÄÁ¥¢ÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇËøôÈ°πÊµãËØïÂ∞ÜÊ∏ÖÊô∞Âú∞ÊØîËæÉÊ®°ÂûãÂ§ÑÁêÜÈùûËã±ËØ≠Êü•ËØ¢ÂíåÊ£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇÁªìÊûúÂ∞ÜÂ±ïÁ§∫Â§öËØ≠Ë®ÄÂµåÂÖ•Âú®ÈùûËã±ËØ≠ÁéØÂ¢É‰∏≠ÂÆûÁé∞ÂáÜÁ°ÆÊ£ÄÁ¥¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ\n\nË¶ÅÂÆûÁé∞ÂíåÊµãËØïËøô‰∏™ËÆæÁΩÆÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ã‰ª£Á†Å„ÄÇËØ•ËÑöÊú¨ÊºîÁ§∫‰∫ÜÂ¶Ç‰ΩïÊü•ËØ¢ÂêëÈáèÂ≠òÂÇ®Âπ∂Âà©Áî®RAGÈìæÂ∞ÜÂµåÂÖ•‰∏éËØ≠Ë®ÄÊ®°ÂûãÁªìÂêà‰ª•ÂõûÁ≠îÈóÆÈ¢ò„ÄÇËØ∑Ê≥®ÊÑèÔºåÂú®ÊµãËØï‰∏çÂêåÁöÑÂµåÂÖ•Ôºà‰æãÂ¶Ç**Cohere Embed English v3**‰∏é**Cohere Embed Multilingual v3**ÔºâÊó∂ÔºåÊÇ®ÈúÄË¶ÅÁ°Æ‰øùÂêëÈáèÂ≠òÂÇ®ÊòØ‰ΩøÁî®Áõ∏Â∫îÁöÑÂµåÂÖ•Ê®°ÂûãÊûÑÂª∫ÁöÑ„ÄÇÁî®ÊÇ®ÊÉ≥Ë¶ÅÊµãËØïÁöÑÂµåÂÖ•Ê®°ÂûãÁ¥¢ÂºïÁöÑÂêëÈáèÂ≠òÂÇ®ÊõøÊç¢Ôºå‰ª•Ëé∑ÂæóÂáÜÁ°ÆÁöÑÁªìÊûú„ÄÇ\n\n```python\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain_aws import ChatBedrock\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\ninstructions = \"\"\"Je bent een brandweer expert. Beantwoord de vraag, maak gebruik van de context\"\"\"\n\nhuman = \"\"\"\nDit is de context: {context}\nDit is de vraag: {question}\n\"\"\"\n\nprompt = ChatPromptTemplate(\n    messages=[\n        SystemMessagePromptTemplate.from_template(instructions),\n        HumanMessagePromptTemplate.from_template(human), #User query will go here\n    ],\n    input_variables=['context','question'], # context provided by retriever and question by the user\n)\nmodel = ChatOpenAI(\n    model=\"gpt-4\",  # or \"gpt-3.5-turbo\" based on your needs\n    temperature=0,\n    max_tokens=512\n)\n\n## Function to merge text chunks\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\n## RAG chain\nrag_chain = (\n        {\"context\": vectorstore.as_retriever(k=10) | format_docs, \"question\": RunnablePassthrough()}\n        | prompt\n        | model\n        | StrOutputParser()\n)\n\nrag_chain.invoke(\"Welke rangen zijn er bij de brandweer?\")\n```\n\n## ÂµåÂÖ•Ê®°ÂûãÁöÑÁªìÊûú\n\n‰∏∫‰∫ÜËØÑ‰º∞Ëøô‰∏§‰∏™ÂµåÂÖ•Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºö**‚ÄúWelke rangen zijn er bij de brandweer?‚Äù**ÔºàÁøªËØëÔºö‚ÄúÊ∂àÈò≤ÈÉ®Èó®Â≠òÂú®Âì™‰∫õËÅåÁ∫ßÔºü‚ÄùÔºâ„ÄÇ‰ª•‰∏ãÊòØÊØè‰∏™Ê®°ÂûãÁîüÊàêÁöÑÂìçÂ∫îÔºö\n\n### Cohere Embed English v3\n\n**Response**:*‚ÄúÊñáÊú¨Ê≤°ÊúâÊèê‰æõÂÖ≥‰∫éÊ∂àÈò≤ÈòüÂÜÖÈÉ®‰∏çÂêåÁ≠âÁ∫ßÁöÑÂÖ∑‰Ωì‰ø°ÊÅØ„ÄÇÁÑ∂ËÄåÔºåÂú®ËÆ∏Â§öÊ∂àÈò≤ÁªÑÁªá‰∏≠ÔºåÊúâ‰∏çÂêåÁöÑÁ≠âÁ∫ßÔºåÂ¶ÇÊ∂àÈò≤Âëò„ÄÅ lieutenant„ÄÅ captain„ÄÅ battalion chief„ÄÅ assistant chief Âíå fire chief„ÄÇÂÖ∑‰ΩìÁöÑÁ≠âÁ∫ßÂèØËÉΩÂõ†ÂõΩÂÆ∂ÂíåÂÖ∑‰ΩìÁªÑÁªáËÄåÂºÇ„ÄÇ‚Äù*\n\n**Analysis**:ËØ•ÂìçÂ∫îÊòØÈÄöÁî®ÁöÑÔºåÂπ∂Ê≤°Êúâ‰æùËµñ‰∫éËç∑ÂÖ∞ÊñáÊ°£Êèê‰æõÁöÑ‰∏ä‰∏ãÊñá„ÄÇËøôÊòØÂèØ‰ª•È¢ÑÊúüÁöÑÔºåÂõ†‰∏∫Ëã±ËØ≠ÂµåÂÖ•Ê®°ÂûãÂú®ËøûÊé•‚Äúhi√´rarchie‚ÄùÔºàÊñáÊ°£‰∏≠‰ΩøÁî®ÔºâÂíå‚Äúrangen‚ÄùÔºàÊü•ËØ¢‰∏≠‰ΩøÁî®Ôºâ‰πãÈó¥ÁöÑËØ≠‰πâÁõ∏‰ººÊÄßÊó∂ÈÅáÂà∞‰∫ÜÂõ∞Èöæ„ÄÇÂõ†Ê≠§ÔºåÂÆÉÈªòËÆ§‰ΩøÁî®ÂÖ≥‰∫éÊ∂àÈò≤ÈÉ®Èó®Á≠âÁ∫ßÁöÑ‰∏ÄËà¨Áü•ËØÜ„ÄÇ\n\n### Cohere Embed Multilingual v3\n\n**Response**:*‚ÄúÂú®Ê∂àÈò≤Èòü‰∏≠Êúâ‰∏çÂêåÁöÑÁ≠âÁ∫ß„ÄÇËøô‰∫õÁ≠âÁ∫ßÂàÜ‰∏∫Âü∫Á°ÄÊ°ÜÊû∂Âíå‰∏≠Â±ÇÊ°ÜÊû∂„ÄÇÂú®Âü∫Á°ÄÊ°ÜÊû∂‰∏≠ÔºåÊàë‰ª¨Êúâ B01 Ê∂àÈò≤ÂëòÂíå B02 ‰∏ãÂ£´„ÄÇÂú®‰∏≠Â±ÇÊ°ÜÊû∂‰∏≠ÔºåÁî±‰∏ãÂ£´ÁªÑÊàêÔºåÊàë‰ª¨Êúâ M01 ‰∏≠Â£´Âíå M02 ÂâØÂÆò„ÄÇËøô‰∫õÁ≠âÁ∫ßÂú®Â∑•‰ΩúÂà∂Êúç„ÄÅ‰ºëÈó≤ÊúçÂíåÂπ≤È¢ÑÊúç‰∏äÈÉΩÊúâÊ†áËØÜ„ÄÇ‚Äù*\n\n**Analysis**:Ê≠§ÂìçÂ∫îÈ´òÂ∫¶Áõ∏ÂÖ≥ÔºåÂπ∂ÂáÜÁ°ÆÂú∞‰ªéÊñáÊ°£‰∏≠Ê£ÄÁ¥¢‰ø°ÊÅØ„ÄÇÂ§öËØ≠Ë®ÄÂµåÂÖ•Ê®°ÂûãÊàêÂäüËØÜÂà´‰∫Ü‚Äúhi√´rarchie‚ÄùÔºà‰∏ä‰∏ãÊñáÔºâ‰∏é‚Äúrangen‚ÄùÔºàÊü•ËØ¢Ôºâ‰πãÈó¥ÁöÑËØ≠‰πâÂÖ≥Á≥ª„ÄÇÂÆÉÁõ¥Êé•Âü∫‰∫éÊñáÊ°£ÂÜÖÂÆπÊèê‰æõ‰∫ÜËØ¶ÁªÜÁöÑÁ≠îÊ°àÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÂ§ÑÁêÜËç∑ÂÖ∞ÁâπÂÆöËØ≠‰πâÁöÑËÉΩÂäõ„ÄÇ\n\n### ÂÖ≥ÈîÆË¶ÅÁÇπ\n\n* **Cohere Embed English v3**ÔºöÁî±‰∫éÊü•ËØ¢‰∏éÊñáÊ°£ÊúØËØ≠‰πãÈó¥Áº∫‰πèËØ≠‰πâÂØπÈΩêÔºåËã±ËØ≠Ê®°ÂûãÊú™ËÉΩ‰ªéËç∑ÂÖ∞ÊñáÊ°£‰∏≠Ê£ÄÁ¥¢Âà∞Áõ∏ÂÖ≥‰∏ä‰∏ãÊñá„ÄÇËøôÁ™ÅÊòæ‰∫ÜÂú®ÈùûËã±ËØ≠‰ªªÂä°‰∏≠‰ΩøÁî®Ëã±ËØ≠ÁâπÂÆöÂµåÂÖ•ÁöÑÂ±ÄÈôêÊÄß„ÄÇ\n* **Cohere Embed Multilingual v3**ÔºöÂ§öËØ≠Ë®ÄÊ®°ÂûãÂú®Ê≠§ÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ªéËç∑ÂÖ∞ÊñáÊ°£‰∏≠Ê£ÄÁ¥¢Âπ∂Âà©Áî®‰∫Ü‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇËøôË°®ÊòéÂ§öËØ≠Ë®ÄÂµåÂÖ•Âú®ÂÆûÁé∞ÂáÜÁ°ÆÊ£ÄÁ¥¢ÂíåÊúâÊïàÂõûÁ≠îÈùûËã±ËØ≠Êü•ËØ¢ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ\n\n## ÁªìËÆ∫\n\nÊú¨Ê¨°ËØÑ‰º∞Á™ÅÊòæ‰∫Ü‰∏Ä‰∏™ÂØπ‰ªª‰ΩïÊûÑÂª∫ÈùûËã±ËØ≠ËØ≠Ë®ÄÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÁ≥ªÁªüÁöÑ‰∫∫Êù•ËØ¥Ëá≥ÂÖ≥ÈáçË¶ÅÁöÑËßÅËß£Ôºö**ÂµåÂÖ•ÈùûÂ∏∏ÈáçË¶Å**ÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ªªÂä°Ë¶ÅÊ±ÇË∑®ËØ≠Ë®ÄÁªÜËá¥ÁêÜËß£Êó∂„ÄÇCohere Embed English v3 Âíå Cohere Embed Multilingual v3 Ê®°ÂûãÂú®ÊÄßËÉΩ‰∏äÁöÑÊòéÊòæÂ∑ÆÂºÇËØ¥Êòé‰∫ÜËã±ËØ≠ÁâπÂÆöÂµåÂÖ•Âú®ÈùûËã±ËØ≠ÁéØÂ¢É‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºå‰ª•ÂèäÂ§öËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ∑®Â§ß‰ª∑ÂÄº„ÄÇ\n\nÂú®ÂõûÁ≠îËç∑ÂÖ∞ËØ≠Êü•ËØ¢Êó∂ÔºåÂ§öËØ≠Ë®ÄÊ®°ÂûãË°®Áé∞Âá∫Ëâ≤ÔºåËÉΩÂ§üÁõ¥Êé•‰ªéÊñáÊ°£‰∏≠Ê£ÄÁ¥¢Âà∞ÂáÜÁ°Æ‰∏î‰∏ä‰∏ãÊñá‰∏∞ÂØåÁöÑ‰ø°ÊÅØ„ÄÇ‰∏éÊ≠§ÂêåÊó∂ÔºåËã±ËØ≠ÂµåÂÖ•Ê®°ÂûãÂàôÈÄÄÂõûÂà∞ÈÄöÁî®ÁöÑ„ÄÅ‰∏çÁõ∏ÂÖ≥ÁöÑÁü•ËØÜÔºåÊòæÁ§∫Âá∫ÂÖ∂Âú®Êü•ËØ¢‰∏éÊñáÊ°£ÂÜÖÂÆπ‰πãÈó¥Âº•ÂêàËØ≠‰πâÂ∑ÆË∑ùÁöÑÊó†ËÉΩ„ÄÇ\n\nÂØπ‰∫éÂú®ÂÖ®ÁêÉÂ§öËØ≠Ë®ÄÁéØÂ¢É‰∏≠ÂºÄÂèë AI Á≥ªÁªüÁöÑÁªÑÁªáËÄåË®ÄÔºåËøôÈ°πÊµãËØïÂº∫Âåñ‰∫Ü‰∏∫ÊâãÂ§¥‰ªªÂä°ÈÄâÊã©ÂêàÈÄÇÂµåÂÖ•Ê®°ÂûãÁöÑÈáçË¶ÅÊÄß„ÄÇÂ§öËØ≠Ë®ÄÂµåÂÖ•‰∏ç‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™‚ÄúÈî¶‰∏äÊ∑ªËä±‚ÄùÁöÑÁâπÊÄßÔºõÂÆÉ‰ª¨ÂØπ‰∫éÁ°Æ‰øùÈùûËã±ËØ≠Â∫îÁî®ÁöÑÂáÜÁ°ÆÊÄß„ÄÅÁõ∏ÂÖ≥ÊÄßÂíåÁî®Êà∑‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nÈöèÁùÄÁîüÊàê AI ÁªßÁª≠ÊãìÂ±ïÂÖ∂ÂΩ±ÂìçÂäõÔºåÈÄöËøáÊõ¥Â•ΩÁöÑÂµåÂÖ•Êù•Êã•Êä±ËØ≠Ë®ÄÂ§öÊ†∑ÊÄßÂ∞ÜÊòØÊèê‰æõÊúâÊÑè‰πâÂíåÊúâÂΩ±ÂìçÂäõÁöÑËß£ÂÜ≥ÊñπÊ°àÁöÑÂÖ≥ÈîÆ„ÄÇÈÄöËøá‰ºòÂÖàËÄÉËôëÂ§öËØ≠Ë®ÄËÉΩÂäõÔºå‰ºÅ‰∏öÂèØ‰ª•ÂàõÂª∫‰∏ç‰ªÖÊõ¥Êô∫ËÉΩËÄå‰∏îÊõ¥ÂÖ∑ÂåÖÂÆπÊÄßÁöÑÁ≥ªÁªü‚Äî‚ÄîËµãËÉΩË∑®ËØ≠Ë®ÄÂíåÊñáÂåñÁöÑÁî®Êà∑„ÄÇ\n\n***ÂÖ≥Ê≥®Êàë‰ª•Ëé∑ÂèñÊõ¥Â§ö AI Ê∑±Â∫¶Ëß£ÊûêÔºÅ***\n\n[Medium](https://proxy.rifx.online/https://medium.com/@lorevanoudenhove), [Instagram](https://proxy.rifx.online/https://www.instagram.com/lorevanoudenhove.ai/), [YouTube](https://proxy.rifx.online/https://www.youtube.com/channel/UCVyOJS1VV7FxPsStK65pHcA), [Pairrot](https://proxy.rifx.online/https://www.pairrot.eu/)\n\n"},{"lang":"zh","group":"blog","slug":"blog/will-bolt-new-ai-will-replace-v0-dev-129a3366eb44","frontmatter":{"title":"Êñ∞‰∫∫Â∑•Êô∫ËÉΩ Bolt ÊòØÂê¶‰ºöÂèñ‰ª£ v0.dev","meta_title":"Êñ∞‰∫∫Â∑•Êô∫ËÉΩ Bolt ÊòØÂê¶‰ºöÂèñ‰ª£ v0.dev","description":"Êñ∞‰∫∫Â∑•Êô∫ËÉΩ Bolt ÊòØÂê¶‰ºöÂèñ‰ª£ v0.dev","date":"2024-11-13T01:22:35.000Z","image":"https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*g5S8PyYqR87bdyGhb77rRw.png","categories":["Programming","Technology/Web","Data Science"],"author":"Rifx.Online","tags":["Bolt.new","v0.dev","web","components","layouts"],"draft":false,"slug":"blog/will-bolt-new-ai-will-replace-v0-dev-129a3366eb44"},"content":"\n### AIÂ∑•ÂÖ∑\n\n> **‰∏çÊòØ‰ºöÂëòÔºüÂÖçË¥πÈòÖËØª [ËøôÈáå](https://proxy.rifx.online/https://tarzzotech.medium.com/129a3366eb44?source=friends_link&sk=385b6b2e482ae9d16ef8f99fe083b8ae)„ÄÇ**\n\n\n\nÁΩëÈ°µÂºÄÂèëÁöÑ‰∏ñÁïåÊ≠£Âú®Âø´ÈÄüÂèëÂ±ïÔºåÂ∏ÇÂú∫‰∏äÊ∂åÁé∞Âá∫Â§öÁßçAIÂ∑•ÂÖ∑„ÄÇËøô‰∫õÊñ∞AIÂ∑•ÂÖ∑ÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÊèêÁ§∫Â∏ÆÂä©ÂºÄÂèëËÄÖÁîüÊàêÁΩëÈ°µÁªÑ‰ª∂ÂíåÂ§çÊùÇÁöÑ‰ª£Á†ÅÁªìÊûÑ„ÄÇËøô‰∫õÂ∑•ÂÖ∑Êèê‰æõÊõ¥Â•ΩÁöÑ‰ª£Á†ÅË¥®ÈáèÔºåÂπ∂ÂáèÂ∞ëÊâãÂä®ÁºñÂÜô‰ª£Á†ÅÁöÑÊó∂Èó¥„ÄÇ\n\nÊúÄËøëÔºåÂ∏ÇÂú∫‰∏äÂá∫Áé∞‰∫Ü‰∏ÄÁßçÊñ∞Â∑•ÂÖ∑ **bolt.new**ÔºåÂÆÉÁúãËµ∑Êù•‰∏é v0\\.dev Áõ∏‰ºº„ÄÇÈöèÁùÄ Bolt.new ÁöÑÂá∫Áé∞Ôºå‰∫ßÁîü‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºö***Ëøô‰∏™Êñ∞ÁöÑAIÂπ≥Âè∞‰ºöÂèñ‰ª£ v0\\.dev ÂêóÔºåËøòÊòØËøô‰∫õÂ∑•ÂÖ∑ÂÆåÂÖ®ÊòØ‰∏çÂêåÁöÑÁî®ÈÄîÔºü***\n\nÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜÂàÜ‰∫´Êàë‰ΩøÁî®ËØ•Â∑•ÂÖ∑‰∏ÄÊÆµÊó∂Èó¥ÁöÑÁªèÈ™å„ÄÇÊàë‰∏ªË¶ÅËÆ®ËÆ∫ **v0\\.dev** Âíå **Bolt.new** ‰πãÈó¥ÁöÑÂÖ≥ÈîÆÂå∫Âà´ÔºåÊØîËæÉÂÆÉ‰ª¨ÁöÑ‰ºòÂäø„ÄÅ‰ΩøÁî®Ê°à‰æãÂíåËæìÂá∫„ÄÇÈÄöËøáËÄÉÂØüÁúüÂÆûÊ°à‰æãÔºåÊàë‰ª¨Â∞ÜÁ°ÆÂÆö **Bolt.new** ÊòØÂê¶ÂØπ **v0\\.dev** ÊûÑÊàê‰∫ÜÁúüÊ≠£ÁöÑÂ®ÅËÉÅÔºåÊàñËÄÖËøô‰∏§ÁßçÂ∑•ÂÖ∑Âú®ÂºÄÂèëËÄÖÁöÑÂ∑•ÂÖ∑ÂåÖ‰∏≠ÂêÑÊúâÂÖ∂‰ΩçÁΩÆ„ÄÇ\n\nÂú®Êàë‰πãÂâçÁöÑÂçöÂÆ¢‰∏≠ÔºåÊàëËØ¶ÁªÜËß£Èáä‰∫ÜÂÖ≥‰∫é v0\\.dev ÁöÑÊâÄÊúâÁªÜËäÇÂíåÊàëÁöÑÊÉ≥Ê≥ïÔºåÊâÄ‰ª•ËØ∑Êü•Áúã [**ËøôÈáå**](https://proxy.rifx.online/https://tarzzotech.medium.com/4191292876b3?source=friends_link&sk=9730b35a75771953d0541e459c8adeaa)„ÄÇÊàë‰∏çÊÉ≥Âú®ËøôÈáåÂàÜ‰∫´ÈáçÂ§çÁöÑÂÜÖÂÆπ„ÄÇËÆ©Êàë‰ª¨ÁúãÁúã **bolt.new** ‰ª•Âèä‰∏é **v0\\.dev** ÁöÑÊØîËæÉ„ÄÇ\n\n## Bolt.new Ê¶ÇËø∞\n\n**Bolt.new** ‰Ωú‰∏∫‰∏Ä‰∏™Êñ∞ÂÖ¥ÁöÑ AI È©±Âä®Âπ≥Âè∞ÔºåÂºïËµ∑‰∫ÜÂπøÊ≥õÂÖ≥Ê≥®ÔºåÂÖ∂ÁõÆÊ†á‰∏ç‰ªÖÈôê‰∫éÂâçÁ´ØÁªÑ‰ª∂„ÄÇËôΩÁÑ∂ **v0.dev** ‰∏ìÊ≥®‰∫éÁîüÊàêËæÉÂ∞èÁöÑÁªÑ‰ª∂Ôºå‰ΩÜ Bolt.new Êó®Âú®Êèê‰æõÊõ¥Â§çÊùÇÁöÑËß£ÂÜ≥ÊñπÊ°àÔºå‰æãÂ¶ÇÂÆåÊï¥ÁöÑÈ°µÈù¢Â∏ÉÂ±ÄÊàñË∑®Ë∂äÂâçÁ´ØÂíåÂêéÁ´ØÁöÑÂ§öÊ≠•È™§Â∑•‰ΩúÊµÅ„ÄÇ\n\n**Bolt.new ÁöÑ‰∏ªË¶ÅÁâπÁÇπÔºö**\n\n* **ÂÆåÊï¥Â∏ÉÂ±ÄÔºö** **Bolt.new** ËÉΩÂ§üÁîüÊàêÂÆåÊï¥ÁöÑÈ°µÈù¢Â∏ÉÂ±ÄÔºåÂåÖÊã¨È°µÁúâ„ÄÅÈ°µËÑö„ÄÅ‰æßËæπÊ†èÂíå‰∏ªË¶ÅÂÜÖÂÆπÂå∫Âüü„ÄÇ\n* **Â§öÂäüËÉΩ‰ª£Á†ÅÁîüÊàêÔºö** Èô§‰∫ÜÁΩëÈ°µÁªÑ‰ª∂Ôºå**Bolt.new** ËøòÂèØ‰ª•ÁîüÊàêÊúçÂä°Âô®Á´ØËÑöÊú¨„ÄÅÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÂèäÊûÑÂª∫ÂÖ®Ê†àÂ∫îÁî®ÊâÄÈúÄÁöÑÂÖ∂‰ªñÂÖÉÁ¥†„ÄÇ\n* **Â¢ûÂº∫ÁöÑÂÆöÂà∂ÂåñÔºö** ËôΩÁÑ∂ V0.dev ‰∏ìÊ≥®‰∫éÂçï‰∏™ÁªÑ‰ª∂Ôºå‰ΩÜ **Bolt.new** Êèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÁÅµÊ¥ªÊÄßÔºåÂÖÅËÆ∏ÂºÄÂèë‰∫∫ÂëòÁîüÊàêÂÆåÂÖ®ÂäüËÉΩÁöÑÂ∏ÉÂ±ÄÊàñÁªìÊûÑ„ÄÇ\n\n## ÊØîËæÉ V0\\.dev Âíå Bolt.new\n\nËôΩÁÑ∂Ëøô‰∏§‰∏™Â∑•ÂÖ∑ÈÉΩÊèê‰æõ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂäüËÉΩÔºå‰ΩÜÂÆÉ‰ª¨ÈíàÂØπÂºÄÂèëËøáÁ®ãÁöÑ‰∏çÂêåÊñπÈù¢„ÄÇ\n\n* **v0\\.dev** ‰∏ìÊ≥®‰∫éÂèØ‰ª•ËΩªÊùæÂÆöÂà∂Âπ∂ÈõÜÊàêÂà∞ÂâçÁ´Ø‰ª£Á†ÅÂ∫ì‰∏≠ÁöÑÂçï‰∏™ÁΩëÈ°µÁªÑ‰ª∂„ÄÇÂÆÉÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÂø´ÈÄüËß£ÂÜ≥ÊñπÊ°àÁöÑÂºÄÂèëËÄÖÔºå‰æãÂ¶ÇÂú® React Êàñ Vue Á≠âÊ°ÜÊû∂‰∏≠‰ΩøÁî®ÁöÑÊåâÈíÆ„ÄÅÂç°ÁâáÊàñË°®Âçï„ÄÇ\n* **Bolt.new** ÂàôÈááÂèñÊõ¥ÂÖ®Èù¢ÁöÑÊñπÊ≥ïÔºåÂÖÅËÆ∏ÂºÄÂèëËÄÖÁîüÊàêÂÆåÊï¥ÁöÑÈ°µÈù¢Â∏ÉÂ±ÄÊàñÁîöËá≥ÂêéÁ´ØÈÖçÁΩÆ„ÄÇËøô‰ΩøÂæóÂÆÉÊàê‰∏∫‰∏Ä‰∏™Êõ¥ÁÅµÊ¥ªÁöÑÈÄâÊã©ÔºåÈÄÇÁî®‰∫éÈúÄË¶ÅÂ§öÁßçÁ±ªÂûã‰ª£Á†ÅÁöÑÈ°πÁõÆÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂâçÁ´ØÁªÑ‰ª∂„ÄÇ\n\n## Á§∫‰æãÊØîËæÉÔºö\n\nÂú®ËøôÈáåÔºåÊàë‰ª¨ÂºÄÂßã‰ªéÂ∞èÁªÑ‰ª∂Âà∞ÂÆåÊï¥È°µÈù¢ÊØîËæÉËøô‰∫õÂ∑•ÂÖ∑„ÄÇ\n\n### ÂàõÂª∫ÊåâÈíÆÁªÑ‰ª∂\n\n**ÊèêÁ§∫Ôºö** ‚ÄúÁîüÊàê‰∏Ä‰∏™Â∏¶‰∏ãÊãâËèúÂçïÂíåÊêúÁ¥¢Ê†èÁöÑÂìçÂ∫îÂºèÂØºËà™Ê†è„ÄÇ‚Äù\n\n**v0\\.dev**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8-1NaJb_msK1OLv7MHbOjw.gif)\n\n**bolt.new**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*WsRSUU5brIql4uBb7wFkAg.gif)\n\n**v0\\.dev** ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÂü∫Êú¨Ê†∑ÂºèÁöÑÊåâÈíÆÂÖÉÁ¥†ÔºåÂπ∂‰∏îÂú®ÊÇ¨ÂÅúÊó∂‰ºöÊîπÂèòËÉåÊôØÈ¢úËâ≤ÂíåÊñáÊú¨Ê†∑ÂºèÁöÑÊÇ¨ÂÅúÊïàÊûú„ÄÇ\n\n**Bolt.new** ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÊÇ¨ÂÅúÊïàÊûúÁöÑÊåâÈíÆÔºåÂπ∂‰∏îÂåÖÂê´Âú®ÁÇπÂáªÊó∂Ëß¶ÂèëË≠¶ÂëäÊ°ÜÁöÑJavaScript‰ª£Á†ÅÔºåÂåÖÊã¨ÂÜÖËÅîJavaScriptÂíåÂü∫Êú¨CSSÊ†∑Âºè„ÄÇ\n\n### ÂàõÂª∫ÂØºËà™Ê†è\n\n**ÊèêÁ§∫Ôºö** ‚ÄúÁîüÊàê‰∏Ä‰∏™Â∏¶Êúâ‰∏ãÊãâËèúÂçïÂíåÊêúÁ¥¢Ê†èÁöÑÂìçÂ∫îÂºèÂØºËà™Ê†è„ÄÇ‚Äù\n\n**v0\\.dev**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*sOJ0EveSOVKtJJltLGiVCA.gif)\n\n**bolt.new**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aGCWfH5ULTTFb-FS-kT-7w.gif)\n\nËøô‰∏§‰∏™Â∑•ÂÖ∑ÁîüÊàêÁöÑÂØºËà™Ê†èÊúâ‰∫õÁõ∏‰ºº„ÄÇ‰ΩÜ **bolt.new** ÁîüÊàêÁöÑÊïàÊûúÁï•‰ºò‰∫é **v0\\.dev**„ÄÇ\n\n### ÂàõÂª∫ÁΩëÁ´ô„ÄÇ\n\n**ÊèêÁ§∫:** ‚ÄúÁîüÊàê‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÈ°µÈù¢Â∏ÉÂ±ÄÔºåÂåÖÂê´Á≤òÊÄßÂ§¥ÈÉ®„ÄÅÈ°µËÑö„ÄÅÂèØÊäòÂè†‰æßËæπÊ†èÂíå‰∏∫ÂçöÂÆ¢ÊñáÁ´†ËÆæËÆ°ÁöÑ‰∏ªË¶ÅÂÜÖÂÆπÂå∫Âüü„ÄÇ‚Äù\n\n**v0\\.dev**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kwEXDG3tb1CiHetZr5W03Q.png)\n\n**bolt.new**\n\n![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HxKnFJQf--e-E1fh8yyxVw.png)\n\nÊù•Ëá™ **bolt.new** ÁöÑËæìÂá∫ËÆ©‰∫∫Êó†Ë®Ä‰ª•ÂØπ„ÄÇ\n\n## ÊúÄÁªàÔºåBolt.new ‰ºöÂèñ‰ª£ v0\\.dev ÂêóÔºü\n\nËÄÉËôëÂà∞ Bolt.new ÁöÑÊõ¥ÂπøÊ≥õËåÉÂõ¥ÔºåÂÆÉÂèØËÉΩÁúãËµ∑Êù•‰ºöÊé©Áõñ v0\\.dev„ÄÇÁÑ∂ËÄåÔºåËøô‰∏§‰∏™Âπ≥Âè∞ÂæàÂèØËÉΩ‰ºöÂÖ±Â≠òÔºåÂêÑËá™‰∏∫ÂºÄÂèëËøáÁ®ãÁöÑ‰∏çÂêåÈò∂ÊÆµÊèê‰æõ‰ª∑ÂÄº„ÄÇ\n\n**v0\\.dev** Âú®Âø´ÈÄüÁîüÊàêÁâπÂÆöÁöÑÈ´òË¥®ÈáèÁΩëÈ°µÁªÑ‰ª∂ÊñπÈù¢Êó†‰∏é‰º¶ÊØî„ÄÇÂÆÉÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÂèØÈáçÁî®„ÄÅÂìçÂ∫îÂºèÁªÑ‰ª∂ÁöÑÂâçÁ´ØÂºÄÂèë‰∫∫ÂëòÔºåËøô‰∫õÁªÑ‰ª∂ÂèØ‰ª•ËΩªÊùæÈõÜÊàêÂà∞‰ªñ‰ª¨ÁöÑÈ°πÁõÆ‰∏≠„ÄÇ\n\n**Bolt.new** ËôΩÁÑ∂Êèê‰æõ‰∫ÜÊõ¥Â§öÁöÑÁÅµÊ¥ªÊÄßÔºå‰ΩÜÂπ∂‰∏ç‰∏ÄÂÆöÊòØ v0\\.dev ÁöÑÊõø‰ª£ÂìÅ„ÄÇÂÆÉÊõ¥ÂπøÊ≥õÁöÑÂäüËÉΩËåÉÂõ¥Âê∏Âºï‰∫ÜÈúÄË¶ÅÂÆåÊï¥Â∏ÉÂ±ÄÊàñÊ∂µÁõñÂâçÁ´ØÂíåÂêéÁ´ØÁöÑ‰ª£Á†ÅÁªìÊûÑÁöÑÂºÄÂèë‰∫∫Âëò„ÄÇ\n\n## ÁªìËÆ∫\n\nv0\\.dev Âíå Bolt.new ÈÉΩÊòØÂº∫Â§ßÁöÑ AI Â∑•ÂÖ∑ÔºåÂêÑËá™ÂÖ∑ÊúâÁã¨ÁâπÁöÑ‰ºòÂäø„ÄÇËôΩÁÑ∂ Bolt.new ÁöÑÂ§öÂäüËÉΩÊÄß‰ΩøÂÖ∂Êàê‰∏∫Â∏åÊúõÁîüÊàêÊõ¥Â§çÊùÇ‰ª£Á†ÅÁöÑÂºÄÂèëËÄÖÁöÑÂº∫Âä≤Á´û‰∫âËÄÖÔºå‰ΩÜ v0\\.dev ‰ªçÁÑ∂ÊòØÂ∏åÊúõÂø´ÈÄüËé∑ÂæóÂèØÂÆöÂà∂ÁªÑ‰ª∂ÁöÑÂºÄÂèëËÄÖÁöÑÈ¶ñÈÄâÂ∑•ÂÖ∑„ÄÇ\n\nÊúÄÁªàÔºåBolt.new ÊòØÂê¶‰ºöÂèñ‰ª£ v0\\.devÔºüËøô‰∏çÂ§™ÂèØËÉΩ„ÄÇËøô‰∫õÂπ≥Âè∞Êª°Ë∂≥‰∏çÂêåÁöÑÈúÄÊ±Ç„ÄÇv0\\.dev Âú®ËΩªÊùæÁîüÊàêÁâπÂÆöÁöÑ„ÄÅÂèØÈáçÁî®ÁöÑÁªÑ‰ª∂ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇBolt.new Âàô‰∏∫Â§çÊùÇÂ∏ÉÂ±ÄÊèê‰æõ‰∫ÜÊõ¥ÂπøÊ≥õÁöÑÂäüËÉΩ„ÄÇÈÇ£‰πàÔºåÊÇ®ËÆ§‰∏∫Âì™ÁßçÂ∑•ÂÖ∑Â∞ÜÂú® AI ËæÖÂä©ÂºÄÂèëÁöÑÊú™Êù•‰∏≠Âç†ÊçÆ‰∏ªÂØºÂú∞‰ΩçÔºåËøòÊòØÂÆÉ‰ª¨‰ºöÁªßÁª≠Áõ∏ËæÖÁõ∏ÊàêÔºüÁ≠îÊ°àÂèñÂÜ≥‰∫éÊÇ®Ê≠£Âú®Â∑•‰ΩúÁöÑÂºÄÂèëËÄÖÈúÄÊ±Ç„ÄÇ\n\n\n"},{"lang":"fr","group":"blog","slug":"blog/post-1","frontmatter":{"title":"Comment cr√©er une application avec des technologies modernes","meta_title":"","description":"Ceci est une m√©ta-description","date":"2022-04-04T05:00:00.000Z","image":"/images/image-placeholder.png","categories":["french","Application","Data"],"author":"John Doe","tags":["nextjs","tailwind","react"],"draft":false,"slug":"blog/post-1"},"content":"\nPersonne ne veut m√™me sortir un maquillage de l'urne des soins empoisonn√©s. C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\n## Design Cr√©atif\n\nCar en guise de maquillage, l'urne du poison C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\n> Le client lui-m√™me doit pouvoir poursuivre l'adipisicing. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n"},{"lang":"fr","group":"blog","slug":"blog/post-2","frontmatter":{"title":"Comment cr√©er une application avec des technologies modernes","meta_title":"","description":"Ceci est une m√©ta-description","date":"2022-04-04T05:00:00.000Z","image":"/images/image-placeholder.png","categories":["Technology","Data"],"author":"Sam Wilson","tags":["technology","tailwind"],"draft":false,"slug":"blog/post-2"},"content":"\nPersonne ne veut m√™me sortir un maquillage de l'urne des soins empoisonn√©s. C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\n## Design Cr√©atif\n\nCar en guise de maquillage, l'urne du poison C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\n> Le client lui-m√™me doit pouvoir poursuivre l'adipisicing. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n"},{"lang":"fr","group":"blog","slug":"blog/post-3","frontmatter":{"title":"Comment cr√©er une application avec des technologies modernes","meta_title":"","description":"Ceci est une m√©ta-description","date":"2022-04-04T05:00:00.000Z","image":"/images/image-placeholder.png","categories":["Software"],"author":"John Doe","tags":["software","tailwind"],"draft":false,"slug":"blog/post-3"},"content":"\nPersonne ne veut m√™me sortir un maquillage de l'urne des soins empoisonn√©s. C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\n## Design Cr√©atif\n\nCar en guise de maquillage, l'urne du poison C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\n> Le client lui-m√™me doit pouvoir poursuivre l'adipisicing. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n"},{"lang":"fr","group":"blog","slug":"blog/post-4","frontmatter":{"title":"Comment cr√©er une application avec des technologies modernes","meta_title":"","description":"Ceci est une m√©ta-description","date":"2022-04-04T05:00:00.000Z","image":"/images/image-placeholder.png","categories":["Architecture"],"author":"John Doe","tags":["silicon","technology"],"draft":false,"slug":"blog/post-4"},"content":"\nPersonne ne veut m√™me sortir un maquillage de l'urne des soins empoisonn√©s. C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\n## Design Cr√©atif\n\nCar en guise de maquillage, l'urne du poison C'√©tait un week-end. Je suis un footballeur complet. Pour boire, le lac occupe le plus grand porche. Chacune des cibles de la vie ne flatte pas Euismod.\n\n> Le client lui-m√™me doit pouvoir poursuivre l'adipisicing. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n\nL'entreprise elle-m√™me est une entreprise tr√®s prosp√®re. Personne ne prend m√™me la peine de l'ouvrir. Alors je vais ouvrir la naissance pour choisir ? √ätre rejet√© par certaines personnes est un choix commode du pr√©sent pour ressentir une douleur comme la sienne !\n"},{"lang":"en","group":"models","slug":"models/chatgpt-4o-latest","frontmatter":{"title":"OpenAI: ChatGPT-4o","meta_title":"OpenAI: ChatGPT-4o","description":"OpenAI: ChatGPT-4o","date":"2024-08-14T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text image 2 text"],"author":"openai","tags":["Chatbots","Generative AI","Machine Learning","Natural Language Processing"],"draft":false,"id":"chatgpt-4o-latest","context":128000,"input":0.000005,"output":0.000015,"img":0.007225,"request":0,"last_updated":"2024-08-14T00:00:00.000Z","slug":"models/chatgpt-4o-latest"},"content":"\nDynamic model continuously updated to the current version of [GPT-4o](/openai/gpt-4o) in ChatGPT. Intended for research and evaluation.\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.\n\n"},{"lang":"en","group":"models","slug":"models/claude-3-haiku","frontmatter":{"title":"Anthropic: Claude 3 Haiku","meta_title":"Anthropic: Claude 3 Haiku","description":"Anthropic: Claude 3 Haiku","date":"2024-03-13T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Machine Learning","Generative AI","Chatbots","Natural Language Processing"],"draft":false,"id":"claude-3-haiku","context":200000,"input":2.5e-7,"output":0.00000125,"img":0.0004,"request":0,"last_updated":"2024-10-24T11:54:59.000Z","slug":"models/claude-3-haiku"},"content":"\nClaude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/claude-3-opus","frontmatter":{"title":"Anthropic: Claude 3 Opus","meta_title":"Anthropic: Claude 3 Opus","description":"Anthropic: Claude 3 Opus","date":"2024-03-05T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"claude-3-opus","context":200000,"input":0.000015,"output":0.000075,"img":0.024,"request":0,"last_updated":"2024-11-07T09:45:35.000Z","slug":"models/claude-3-opus"},"content":"\nClaude 3 Opus is Anthropic's most powerful model for highly complex tasks. It boasts top-level performance, intelligence, fluency, and understanding.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/claude-3-sonnet","frontmatter":{"title":"Anthropic: Claude 3 Sonnet","meta_title":"Anthropic: Claude 3 Sonnet","description":"Anthropic: Claude 3 Sonnet","date":"2024-03-05T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Technology","Machine Learning","Data Science","Chatbots"],"draft":false,"is_recommended":true,"id":"claude-3-sonnet","context":200000,"input":0.000003,"output":0.000015,"img":0.0048,"request":0,"last_updated":"2024-11-14T04:05:16.000Z","slug":"models/claude-3-sonnet"},"content":"\nClaude 3 Sonnet is an ideal balance of intelligence and speed for enterprise workloads. Maximum utility at a lower price, dependable, balanced for scaled deployments.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/claude-35-haiku","frontmatter":{"title":"Anthropic: Claude 3.5 Haiku","meta_title":"Anthropic: Claude 3.5 Haiku","description":"Anthropic: Claude 3.5 Haiku","date":"2024-11-04T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text 2 text"],"author":"anthropic","tags":["Programming","Chatbots","Data Science","Machine Learning","Natural Language Processing"],"draft":false,"id":"claude-3.5-haiku","context":200000,"input":0.000001,"output":0.000005,"img":0,"request":0,"last_updated":"2024-11-07T09:46:02.000Z","slug":"models/claude-35-haiku"},"content":"\nClaude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).\n\n"},{"lang":"en","group":"models","slug":"models/claude-35-sonnet","frontmatter":{"title":"Anthropic: Claude 3.5 Sonnet","meta_title":"Anthropic: Claude 3.5 Sonnet","description":"Anthropic: Claude 3.5 Sonnet","date":"2024-06-20T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Data Science","Computer Vision","Chatbots","Autonomous Systems"],"draft":false,"id":"claude-3.5-sonnet","context":200000,"input":0.000003,"output":0.000015,"img":0.0048,"request":0,"last_updated":"2024-10-24T11:45:46.000Z","slug":"models/claude-35-sonnet"},"content":"\nClaude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Autonomously writes, edits, and runs code with reasoning and troubleshooting\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/command-r-plus","frontmatter":{"title":"Cohere: Command R+ (08-2024)","meta_title":"Cohere: Command R+ (08-2024)","description":"Cohere: Command R+ (08-2024)","date":"2024-08-30T00:00:00.000Z","image":"https://img.rifx.online/logo/cohere.svg","categories":["text 2 text"],"author":"cohere","tags":["Technology","Programming","Machine Learning","Generative AI","Ethics"],"draft":false,"id":"command-r-plus","context":128000,"input":0.000002375,"output":0.0000095,"img":0,"request":0,"last_updated":"2024-11-07T09:33:44.000Z","slug":"models/command-r-plus"},"content":"\ncommand-r-plus-08-2024 is an update of the [Command R+](/cohere/command-r-plus) with roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Acceptable Use Policy](https://docs.cohere.com/docs/c4ai-acceptable-use-policy).\n\n"},{"lang":"en","group":"models","slug":"models/command-r","frontmatter":{"title":"Cohere: Command R (08-2024)","meta_title":"Cohere: Command R (08-2024)","description":"Cohere: Command R (08-2024)","date":"2024-08-30T00:00:00.000Z","image":"https://img.rifx.online/logo/cohere.svg","categories":["text 2 text"],"author":"cohere","tags":["Programming","Natural Language Processing","Generative AI","Machine Learning","Data Science"],"draft":false,"id":"command-r","context":128000,"input":1.425e-7,"output":5.7e-7,"img":0,"request":0,"last_updated":"2024-11-07T09:33:55.000Z","slug":"models/command-r"},"content":"\ncommand-r-08-2024 is an update of the [Command R](/cohere/command-r) with improved performance for multilingual retrieval-augmented generation (RAG) and tool use. More broadly, it is better at math, code and reasoning and is competitive with the previous version of the larger Command R+ model.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Acceptable Use Policy](https://docs.cohere.com/docs/c4ai-acceptable-use-policy).\n\n"},{"lang":"en","group":"models","slug":"models/deepseek-chat","frontmatter":{"title":"DeepSeek V2.5","meta_title":"DeepSeek V2.5","description":"DeepSeek V2.5","date":"2024-05-14T00:00:00.000Z","image":"https://img.rifx.online/logo/deepseek.svg","categories":["text 2 text"],"author":"deepseek","tags":["Programming","Natural Language Processing","Machine Learning","Data Science","Chatbots"],"draft":false,"id":"deepseek-chat","context":128000,"input":1.4e-7,"output":2.8e-7,"img":0,"request":0,"last_updated":"2024-11-01T04:19:11.000Z","slug":"models/deepseek-chat"},"content":"\nDeepSeek-V2.5 is an upgraded version that combines DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct. The new model integrates the general and coding abilities of the two previous versions.\n\nDeepSeek-V2 Chat is a conversational finetune of DeepSeek-V2, a Mixture-of-Experts (MoE) language model. It comprises 236B total parameters, of which 21B are activated for each token.\n\nCompared with DeepSeek 67B, DeepSeek-V2 achieves stronger performance, and meanwhile saves 42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum generation throughput to 5.76 times.\n\nDeepSeek-V2 achieves remarkable performance on both standard benchmarks and open-ended generation evaluations.\n\n"},{"lang":"en","group":"models","slug":"models/dolphin-mixtral-8x22b","frontmatter":{"title":"Dolphin 2.9.2 Mixtral 8x22B üê¨","meta_title":"Dolphin 2.9.2 Mixtral 8x22B üê¨","description":"Dolphin 2.9.2 Mixtral 8x22B üê¨","date":"2024-06-08T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"cognitivecomputations","tags":["Natural Language Processing","Generative AI","Chatbots","Roleplay","Ethics"],"draft":false,"id":"dolphin-mixtral-8x22b","context":65536,"input":9e-7,"output":9e-7,"img":0,"request":0,"last_updated":"2024-11-04T12:49:50.000Z","slug":"models/dolphin-mixtral-8x22b"},"content":"\nDolphin 2.9 is designed for instruction following, conversational, and coding. This model is a finetune of [Mixtral 8x22B Instruct](/mistralai/mixtral-8x22b-instruct). It features a 64k context length and was fine-tuned with a 16k sequence length using ChatML templates.\n\nThis model is a successor to [Dolphin Mixtral 8x7B](/cognitivecomputations/dolphin-mixtral-8x7b).\n\nThe model is uncensored and is stripped of alignment and bias. It requires an external alignment layer for ethical use. Users are cautioned to use this highly compliant model responsibly, as detailed in a blog post about uncensored models at [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models).\n\n#moe #uncensored\n\n"},{"lang":"en","group":"models","slug":"models/dolphin-mixtral-8x7b","frontmatter":{"title":"Dolphin 2.6 Mixtral 8x7B üê¨","meta_title":"Dolphin 2.6 Mixtral 8x7B üê¨","description":"Dolphin 2.6 Mixtral 8x7B üê¨","date":"2023-12-21T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"cognitivecomputations","tags":["Programming","Natural Language Processing","Generative AI","Ethics","Chatbots"],"draft":false,"id":"dolphin-mixtral-8x7b","context":32768,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-04T12:52:28.000Z","slug":"models/dolphin-mixtral-8x7b"},"content":"\nThis is a 16k context fine-tune of [Mixtral-8x7b](/mistralai/mixtral-8x7b). It excels in coding tasks due to extensive training with coding data and is known for its obedience, although it lacks DPO tuning.\n\nThe model is uncensored and is stripped of alignment and bias. It requires an external alignment layer for ethical use. Users are cautioned to use this highly compliant model responsibly, as detailed in a blog post about uncensored models at [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models).\n\n#moe #uncensored\n\n"},{"lang":"en","group":"models","slug":"models/eva-qwen-25-14b","frontmatter":{"title":"EVA Qwen2.5 14B","meta_title":"EVA Qwen2.5 14B","description":"EVA Qwen2.5 14B","date":"2024-09-30T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"eva-unit-01","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"is_recommended":false,"id":"eva-qwen-2.5-14b","context":32768,"input":2.5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:18:57.000Z","slug":"models/eva-qwen-25-14b"},"content":"\nA model specializing in RP and creative writing, this model is based on Qwen2.5-14B, fine-tuned with a mixture of synthetic and natural data.\n\nIt is trained on 1.5M tokens of role-play data, and fine-tuned on 1.5M tokens of synthetic data.\n\n"},{"lang":"en","group":"models","slug":"models/eva-qwen-25-32b","frontmatter":{"title":"Eva Qwen2.5 32B","meta_title":"Eva Qwen2.5 32B","description":"Eva Qwen2.5 32B","date":"2024-11-08T22:27:27.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"eva-unit-01","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"is_recommended":true,"id":"eva-qwen-2.5-32b","context":32000,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:18:50.000Z","slug":"models/eva-qwen-25-32b"},"content":"\nA roleplaying/storywriting specialist model, full-parameter finetune of Qwen2.5-32B on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model.\n\n"},{"lang":"en","group":"models","slug":"models/gemini-flash-15-8b-exp","frontmatter":{"title":"Google: Gemini Flash 8B 1.5 Experimental","meta_title":"Google: Gemini Flash 8B 1.5 Experimental","description":"Google: Gemini Flash 8B 1.5 Experimental","date":"2024-08-28T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Technology","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"gemini-flash-1.5-8b-exp","context":1000000,"input":0,"output":0,"img":0,"request":0,"last_updated":"2024-11-11T03:14:22.000Z","slug":"models/gemini-flash-15-8b-exp"},"content":"\nGemini 1.5 Flash 8B Experimental is an experimental, 8B parameter version of the [Gemini 1.5 Flash](/google/gemini-flash-1.5) model.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.\n\n"},{"lang":"en","group":"models","slug":"models/gemini-flash-15-8b","frontmatter":{"title":"Google: Gemini 1.5 Flash-8B","meta_title":"Google: Gemini 1.5 Flash-8B","description":"Google: Gemini 1.5 Flash-8B","date":"2024-10-03T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Natural Language Processing","Chatbots","Translation","Technology/Web"],"draft":false,"id":"gemini-flash-1.5-8b","context":1000000,"input":3.75e-8,"output":1.5e-7,"img":0,"request":0,"last_updated":"2024-10-03T00:00:00.000Z","slug":"models/gemini-flash-15-8b"},"content":"\nGemini 1.5 Flash-8B is optimized for speed and efficiency, offering enhanced performance in small prompt tasks like chat, transcription, and translation. With reduced latency, it is highly effective for real-time and large-scale operations. This model focuses on cost-effective solutions while maintaining high-quality results.\n\n[Click here to learn more about this model](https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/).\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n"},{"lang":"en","group":"models","slug":"models/gemini-flash-15","frontmatter":{"title":"Google: Gemini Flash 1.5","meta_title":"Google: Gemini Flash 1.5","description":"Google: Gemini Flash 1.5","date":"2024-05-14T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Machine Learning","Natural Language Processing","Computer Vision","Chatbots"],"draft":false,"is_recommended":true,"id":"gemini-flash-1.5","context":1000000,"input":7.5e-8,"output":3e-7,"img":0.00004,"request":0,"last_updated":"2024-11-14T08:23:12.000Z","slug":"models/gemini-flash-15"},"content":"\nGemini 1.5 Flash is a foundation model that performs well at a variety of multimodal tasks such as visual understanding, classification, summarization, and creating content from image, audio and video. It's adept at processing visual and text inputs such as photographs, documents, infographics, and screenshots.\n\nGemini 1.5 Flash is designed for high-volume, high-frequency tasks where cost and latency matter. On most common tasks, Flash achieves comparable quality to other Gemini Pro models at a significantly reduced cost. Flash is well-suited for applications like chat assistants and on-demand content generation where speed and scale matter.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/gemini-pro-15","frontmatter":{"title":"Google: Gemini Pro 1.5","meta_title":"Google: Gemini Pro 1.5","description":"Google: Gemini Pro 1.5","date":"2024-04-09T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Chatbots"],"draft":false,"id":"gemini-pro-1.5","context":2000000,"input":0.00000125,"output":0.000005,"img":0.00263,"request":0,"last_updated":"2024-04-09T00:00:00.000Z","slug":"models/gemini-pro-15"},"content":"\nGoogle's latest multimodal model, supporting image and video in text or chat prompts.\n\nOptimized for language tasks including:\n\n- Code generation\n- Text generation\n- Text editing\n- Problem solving\n- Recommendations\n- Information extraction\n- Data extraction or generation\n- AI agents\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/gemini-pro-vision","frontmatter":{"title":"Google: Gemini Pro Vision 1.0","meta_title":"Google: Gemini Pro Vision 1.0","description":"Google: Gemini Pro Vision 1.0","date":"2023-12-13T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Machine Learning","Natural Language Processing","Computer Vision","Generative AI"],"draft":false,"id":"gemini-pro-vision","context":16384,"input":5e-7,"output":0.0000015,"img":0.0025,"request":0,"last_updated":"2024-11-11T03:15:08.000Z","slug":"models/gemini-pro-vision"},"content":"\nGoogle's flagship multimodal model, supporting image and video in text or chat prompts for a text or code response.\n\nSee the benchmarks and prompting guidelines from [Deepmind](https://deepmind.google/technologies/gemini/).\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal\n\n"},{"lang":"en","group":"models","slug":"models/gemma-2-27b-it","frontmatter":{"title":"Google: Gemma 2 27B","meta_title":"Google: Gemma 2 27B","description":"Google: Gemma 2 27B","date":"2024-07-13T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"gemma-2-27b-it","context":8192,"input":2.7e-7,"output":2.7e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:14:49.000Z","slug":"models/gemma-2-27b-it"},"content":"\nGemma 2 27B by Google is an open model built from the same research and technology used to create the [Gemini models](/models?q=gemini).\n\nGemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).\n\n"},{"lang":"en","group":"models","slug":"models/gemma-2-9b-it","frontmatter":{"title":"Google: Gemma 2 9B","meta_title":"Google: Gemma 2 9B","description":"Google: Gemma 2 9B","date":"2024-06-28T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Programming","Natural Language Processing","Machine Learning","Data Science","Open Source"],"draft":false,"id":"gemma-2-9b-it","context":8192,"input":6e-8,"output":6e-8,"img":0,"request":0,"last_updated":"2024-11-11T03:14:49.000Z","slug":"models/gemma-2-9b-it"},"content":"\nGemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\n\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).\n\n"},{"lang":"en","group":"models","slug":"models/glm-4-air","frontmatter":{"title":"GLM-4 Air","meta_title":"GLM-4 Air","description":"GLM-4 Air","date":"2024-11-14T10:21:13.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-air","tags":["Programming","Technology","Machine Learning","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"glm-4-air","context":128000,"input":1.4e-7,"output":1.4e-7,"img":0,"request":0,"last_updated":"2024-11-14T12:36:34.000Z","slug":"models/glm-4-air"},"content":"\nNone\n\n"},{"lang":"en","group":"models","slug":"models/glm-4-airx","frontmatter":{"title":"GLM-4 AirX","meta_title":"GLM-4 AirX","description":"GLM-4 AirX","date":"2024-11-15T13:12:54.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-airx","tags":["Technology","Machine Learning","Generative AI","Data Science","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4-airx","context":8000,"input":0.0000014,"output":0.0000014,"img":0,"request":0,"last_updated":"2024-11-15T23:49:16.000Z","slug":"models/glm-4-airx"},"content":"\n## Basic Information\n\nThe \"GLM-4-AIRX\" is an advanced large language model developed by experts in the field of artificial intelligence. It is renowned for its powerful natural language processing capabilities, enabling it to effectively understand and generate natural language text. This model leverages deep learning technologies, particularly the Transformer architecture, which is widely used in the NLP (Natural Language Processing) domain.\n\n## Technical Features\n\n### 1. Based on Transformer Architecture\n\nThe core of this model is built upon the Transformer architecture, a structure that employs attention mechanisms. Through this mechanism, \"GLM-4-AIRX\" can capture complex dependencies between any two positions within an input sequence, regardless of their distance, thereby enhancing efficiency and accuracy when handling language tasks.\n\n### 2. Pre-training and Fine-tuning\n\nThe model development involves a combination of pre-training and fine-tuning phases. During pre-training, it is trained on extensive and diverse text datasets to grasp fundamental language patterns. In the fine-tuning phase, parameters are adjusted according to specific tasks to improve performance on particular applications.\n\n### 3. Multilingual Support\n\n\"GLM-4-AIRX\" possesses multilingual capabilities achieved through pre-training on corpora containing various languages. This allows it to comprehend and generate text in multiple languages, meeting global user needs and facilitating cross-cultural communication.\n\n### 4. Scalability\n\nDesigned with scalability in mind, this model can be flexibly adjusted to handle larger datasets or more complex task requirements. This feature enables it to be widely applicable in ever-changing and expanding data environments.\n\n## Application Scenarios\n\nThe \"GLM-4-AIRX\" has broad applications across numerous fields including but not limited to:\n\n- **Text Generation**: Automatically creating articles, stories, or poetry.\n- **Text Classification**: Such as sentiment analysis or thematic categorization.\n- **Machine Translation**: Providing efficient and accurate cross-language translation.\n- **Question Answering Systems**: For building intelligent platforms that directly respond to user inquiries.\n- **Text Summarization**: Automatically extracting key information from documents into concise summaries.\n\n## Comparison with Similar Models\n\nCompared to other large language models, \"GLM-4-AIRX\" offers several advantages:\n\n- **Outstanding Performance**: Excels across multiple NLP tasks such as text generation and comprehension.\n- **High Processing Efficiency**: Optimized architectural design results in more efficient resource use and speed.\n- **Strong Flexibility**: Supports multiple languages and can adapt through extended features across different application scenarios.\n- **Task Adaptability**: Achieves optimization for specific task requirements through fine-tuning, enhancing practical value.\n\nIn summary, \"GLM-4-AIRX\" is a comprehensive and flexible large language model that holds potential for continued growth and innovation within today's rapidly evolving AI technology landscape.\n\nThis response uses available real-time data regarding GLM models supporting new functionalities like System Prompt , Function Call , Retrieval , Web_Search etc., alongside general knowledge about transformer-based architectures common in NLP advancements.\n\n"},{"lang":"en","group":"models","slug":"models/glm-4-flash","frontmatter":{"title":"glm-4-flash","meta_title":"glm-4-flash","description":"glm-4-flash","date":"2024-11-15T12:53:10.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-flash","tags":["Generative AI","Machine Learning","Natural Language Processing","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4-flash","context":128000,"input":1e-8,"output":1e-8,"img":0,"request":0,"last_updated":"2024-11-15T23:22:37.000Z","slug":"models/glm-4-flash"},"content":"\nÊô∫Ë∞±Âø´ÈÄüÁâà\n\n"},{"lang":"en","group":"models","slug":"models/glm-4-long","frontmatter":{"title":"glm-4-long","meta_title":"glm-4-long","description":"glm-4-long","date":"2024-11-15T12:53:01.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-long","tags":["Technology","Machine Learning","Natural Language Processing","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"glm-4-long","context":1000000,"input":1.4e-7,"output":1.4e-7,"img":0,"request":0,"last_updated":"2024-11-15T23:22:49.000Z","slug":"models/glm-4-long"},"content":"\nÊô∫Ë∞±Áôæ‰∏á‰∏ä‰∏ãÊñá\n\n"},{"lang":"en","group":"models","slug":"models/glm-4-plus","frontmatter":{"title":"glm-4-plus","meta_title":"glm-4-plus","description":"glm-4-plus","date":"2024-11-15T12:53:05.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-plus","tags":["Generative AI","Machine Learning","Natural Language Processing","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4-plus","context":128000,"input":0.000007,"output":0.000007,"img":0,"request":0,"last_updated":"2024-11-15T23:22:43.000Z","slug":"models/glm-4-plus"},"content":"\nÊô∫Ë∞±ÊóóËà∞Áâà\n\n"},{"lang":"en","group":"models","slug":"models/glm-4","frontmatter":{"title":"GLM-4","meta_title":"GLM-4","description":"GLM-4","date":"2024-11-15T13:12:41.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4","tags":["Generative AI","Machine Learning","Natural Language Processing","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4","context":128000,"input":0.000014,"output":0.000014,"img":0,"request":0,"last_updated":"2024-11-15T23:23:43.000Z","slug":"models/glm-4"},"content":"\nÊô∫Ë∞±ÊúÄÂº∫Áâà\n\n"},{"lang":"en","group":"models","slug":"models/glm-4v-plus","frontmatter":{"title":"glm-4v-plus","meta_title":"glm-4v-plus","description":"glm-4v-plus","date":"2024-11-15T12:53:06.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4v-plus","tags":["Computer Vision","Technology","Machine Learning","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"glm-4v-plus","context":32000,"input":0.0000014,"output":0.0000014,"img":0,"request":0,"last_updated":"2024-11-15T23:22:53.000Z","slug":"models/glm-4v-plus"},"content":"\nÊô∫Ë∞±ÊúÄÊñ∞ÂõæÂÉèËØÜÂà´\n\n"},{"lang":"en","group":"models","slug":"models/gpt-35-turbo-instruct","frontmatter":{"title":"OpenAI: GPT-3.5 Turbo Instruct","meta_title":"OpenAI: GPT-3.5 Turbo Instruct","description":"OpenAI: GPT-3.5 Turbo Instruct","date":"2023-09-28T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"openai","tags":["Programming","Natural Language Processing","Generative AI","Chatbots","Technology/Web"],"draft":false,"id":"gpt-3.5-turbo-instruct","context":4095,"input":0.0000015,"output":0.000002,"img":0,"request":0,"last_updated":"2023-09-28T00:00:00.000Z","slug":"models/gpt-35-turbo-instruct"},"content":"\nThis model is a variant of GPT-3.5 Turbo tuned for instructional prompts and omitting chat-related optimizations. Training data: up to Sep 2021.\n\n"},{"lang":"en","group":"models","slug":"models/gpt-4o-mini","frontmatter":{"title":"OpenAI: GPT-4o-mini","meta_title":"OpenAI: GPT-4o-mini","description":"OpenAI: GPT-4o-mini","date":"2024-07-18T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text image 2 text"],"author":"openai","tags":["Programming","Technology","Programming/Scripting","Technology/Web"],"draft":false,"is_recommended":true,"id":"gpt-4o-mini","context":128000,"input":1.5e-7,"output":6e-7,"img":0.007225,"request":0,"last_updated":"2024-11-14T05:09:26.000Z","slug":"models/gpt-4o-mini"},"content":"\nGPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n"},{"lang":"en","group":"models","slug":"models/gpt-4o","frontmatter":{"title":"OpenAI: GPT-4o","meta_title":"OpenAI: GPT-4o","description":"OpenAI: GPT-4o","date":"2024-05-13T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text image 2 text"],"author":"openai","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Computer Vision"],"draft":false,"id":"gpt-4o","context":128000,"input":0.0000025,"output":0.00001,"img":0.0036125,"request":0,"last_updated":"2024-05-13T00:00:00.000Z","slug":"models/gpt-4o"},"content":"\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n"},{"lang":"en","group":"models","slug":"models/grok-beta","frontmatter":{"title":"xAI: Grok Beta","meta_title":"xAI: Grok Beta","description":"xAI: Grok Beta","date":"2024-10-20T00:00:00.000Z","image":"https://img.rifx.online/logo/xai.svg","categories":["text 2 text"],"author":"x-ai","tags":["Natural Language Processing","Machine Learning","Generative AI","Chatbots","Data Science"],"draft":false,"id":"grok-beta","context":131072,"input":0.000005,"output":0.000015,"img":0,"request":0,"last_updated":"2024-11-07T09:32:49.000Z","slug":"models/grok-beta"},"content":"\nGrok Beta is xAI's experimental language model with state-of-the-art reasoning capabilities, best for complex and multi-step use cases.\n\nIt is the successor of [Grok 2](https://x.ai/blog/grok-2) with enhanced context length.\n\n"},{"lang":"en","group":"models","slug":"models/hermes-3-llama-31-405b","frontmatter":{"title":"Nous: Hermes 3 405B Instruct","meta_title":"Nous: Hermes 3 405B Instruct","description":"Nous: Hermes 3 405B Instruct","date":"2024-08-16T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"nousresearch","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Chatbots"],"draft":false,"id":"hermes-3-llama-3.1-405b","context":131072,"input":0.00000179,"output":0.00000249,"img":0,"request":0,"last_updated":"2024-11-11T03:16:40.000Z","slug":"models/hermes-3-llama-31-405b"},"content":"\nHermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\nHermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general capabilities, with varying strengths and weaknesses attributable between the two.\n\n"},{"lang":"en","group":"models","slug":"models/hermes-3-llama-31-70b","frontmatter":{"title":"Nous: Hermes 3 70B Instruct","meta_title":"Nous: Hermes 3 70B Instruct","description":"Nous: Hermes 3 70B Instruct","date":"2024-08-18T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"nousresearch","tags":["Natural Language Processing","Machine Learning","Generative AI","Chatbots","Programming"],"draft":false,"id":"hermes-3-llama-3.1-70b","context":131072,"input":4e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:16:38.000Z","slug":"models/hermes-3-llama-31-70b"},"content":"\nHermes 3 is a generalist language model with many improvements over [Hermes 2](/nousresearch/nous-hermes-2-mistral-7b-dpo), including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 70B is a competitive, if not superior finetune of the [Llama-3.1 70B foundation model](/meta-llama/llama-3.1-70b-instruct), focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\n"},{"lang":"en","group":"models","slug":"models/inflection-3-pi","frontmatter":{"title":"Inflection: Inflection 3 Pi","meta_title":"Inflection: Inflection 3 Pi","description":"Inflection: Inflection 3 Pi","date":"2024-10-11T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"inflection","tags":["Chatbots","Roleplay","Emotional Intelligence","Customer Support","Safety"],"draft":false,"id":"inflection-3-pi","context":8000,"input":0.0000025,"output":0.00001,"img":0,"request":0,"last_updated":"2024-11-07T10:11:48.000Z","slug":"models/inflection-3-pi"},"content":"\nInflection 3 Pi powers Inflection's [Pi](https://pi.ai) chatbot, including backstory, emotional intelligence, productivity, and safety. It excels in scenarios like customer support, roleplay, and emotional intelligence.\n\n"},{"lang":"en","group":"models","slug":"models/inflection-3-productivity","frontmatter":{"title":"Inflection: Inflection 3 Productivity","meta_title":"Inflection: Inflection 3 Productivity","description":"Inflection: Inflection 3 Productivity","date":"2024-10-11T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"inflection","tags":["Programming","Technology","Chatbots","Generative AI","Data Science"],"draft":false,"id":"inflection-3-productivity","context":8000,"input":0.0000025,"output":0.00001,"img":0,"request":0,"last_updated":"2024-11-07T10:11:56.000Z","slug":"models/inflection-3-productivity"},"content":"\nInflection 3 Productivity is optimized for following instructions. It is better for tasks requiring JSON output or precise adherence to provided guidelines\n\nFor emotional intelligence similar to Pi, see [Inflect 3 Pi](/inflection/inflection-3-pi)\n\nSee [Inflection's announcement](https://inflection.ai/blog/enterprise) for more details.\n\n"},{"lang":"en","group":"models","slug":"models/jamba-1-5-large","frontmatter":{"title":"AI21: Jamba 1.5 Large","meta_title":"AI21: Jamba 1.5 Large","description":"AI21: Jamba 1.5 Large","date":"2024-08-23T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"ai21","tags":["Programming","Technology","Machine Learning","Data Science","Generative AI"],"draft":false,"id":"jamba-1-5-large","context":256000,"input":0.000002,"output":0.000008,"img":0,"request":0,"last_updated":"2024-11-11T03:11:21.000Z","slug":"models/jamba-1-5-large"},"content":"\nJamba 1.5 Large is part of AI21's new family of open models, offering superior speed, efficiency, and quality.\n\nIt features a 256K effective context window, the longest among open models, enabling improved performance on tasks like document summarization and analysis.\n\nBuilt on a novel SSM-Transformer architecture, it outperforms larger models like Llama 3.1 70B on benchmarks while maintaining resource efficiency.\n\nRead their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.\n\n"},{"lang":"en","group":"models","slug":"models/jamba-1-5-mini","frontmatter":{"title":"AI21: Jamba 1.5 Mini","meta_title":"AI21: Jamba 1.5 Mini","description":"AI21: Jamba 1.5 Mini","date":"2024-08-23T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"ai21","tags":["Programming","Technology","Machine Learning","Natural Language Processing","Data Science"],"draft":false,"id":"jamba-1-5-mini","context":256000,"input":2e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:11:12.000Z","slug":"models/jamba-1-5-mini"},"content":"\nJamba 1.5 Mini is the world's first production-grade Mamba-based model, combining SSM and Transformer architectures for a 256K context window and high efficiency.\n\nIt works with 9 languages and can handle various writing and analysis tasks as well as or better than similar small models.\n\nThis model uses less computer memory and works faster with longer texts than previous designs.\n\nRead their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.\n\n"},{"lang":"en","group":"models","slug":"models/l3-lunaris-8b","frontmatter":{"title":"Llama 3 8B Lunaris","meta_title":"Llama 3 8B Lunaris","description":"Llama 3 8B Lunaris","date":"2024-08-13T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"sao10k","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Chatbots"],"draft":false,"id":"l3-lunaris-8b","context":8192,"input":0.000002,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:12:13.000Z","slug":"models/l3-lunaris-8b"},"content":"\nLunaris 8B is a versatile generalist and roleplaying model based on Llama 3. It's a strategic merge of multiple models, designed to balance creativity with improved logic and general knowledge.\n\nCreated by [Sao10k](https://huggingface.co/Sao10k), this model aims to offer an improved experience over Stheno v3.2, with enhanced creativity and logical reasoning.\n\nFor best results, use with Llama 3 Instruct context template, temperature 1.4, and min_p 0.1.\n\n"},{"lang":"en","group":"models","slug":"models/l31-euryale-70b","frontmatter":{"title":"Llama 3.1 Euryale 70B v2.2","meta_title":"Llama 3.1 Euryale 70B v2.2","description":"Llama 3.1 Euryale 70B v2.2","date":"2024-08-28T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"sao10k","tags":["Roleplay","Generative AI","Chatbots","Natural Language Processing","Technology/Web"],"draft":false,"id":"l3.1-euryale-70b","context":8192,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:12:50.000Z","slug":"models/l31-euryale-70b"},"content":"\nEuryale L3.1 70B v2.2 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.1](/sao10k/l3-euryale-70b).\n\n"},{"lang":"en","group":"models","slug":"models/lfm-40b","frontmatter":{"title":"Liquid: LFM 40B MoE","meta_title":"Liquid: LFM 40B MoE","description":"Liquid: LFM 40B MoE","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"liquid","tags":["Machine Learning","Natural Language Processing","Data Science","Generative AI","Computer Vision"],"draft":false,"is_recommended":true,"id":"lfm-40b","context":32768,"input":0.000001,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-14T05:10:16.000Z","slug":"models/lfm-40b"},"content":"\nLiquid's 40.3B Mixture of Experts (MoE) model. Liquid Foundation Models (LFMs) are large neural networks built with computational units rooted in dynamic systems.\n\nLFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.\n\n"},{"lang":"en","group":"models","slug":"models/liquid-lfm-40b:free","frontmatter":{"title":"Liquid: LFM 40B MoE (free)","meta_title":"Liquid: LFM 40B MoE (free)","description":"Liquid: LFM 40B MoE (free)","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"liquid","tags":["Generative AI","Machine Learning","Natural Language Processing","Data Science","Technology/Web"],"draft":false,"id":"liquid/lfm-40b:free","context":8192,"input":0,"output":0,"img":0,"request":0,"last_updated":"2024-11-07T00:17:57.000Z","slug":"models/liquid-lfm-40b:free"},"content":"\nLiquid's 40.3B Mixture of Experts (MoE) model. Liquid Foundation Models (LFMs) are large neural networks built with computational units rooted in dynamic systems.\n\nLFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.\n\n_These are free, rate-limited endpoints for [LFM 40B MoE](/liquid/lfm-40b). Outputs may be cached. Read about rate limits [here](/docs/limits)._\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-70b-instruct","frontmatter":{"title":"Meta: Llama 3.1 70B Instruct","meta_title":"Meta: Llama 3.1 70B Instruct","description":"Meta: Llama 3.1 70B Instruct","date":"2024-07-23T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Programming","Machine Learning","Natural Language Processing","Chatbots","Ethics"],"draft":false,"id":"llama-3.1-70b-instruct","context":131072,"input":3e-7,"output":3e-7,"img":0,"request":0,"last_updated":"2024-10-28T13:38:49.000Z","slug":"models/llama-31-70b-instruct"},"content":"\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 70B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-8b-instruct","frontmatter":{"title":"Meta: Llama 3.1 8B Instruct","meta_title":"Meta: Llama 3.1 8B Instruct","description":"Meta: Llama 3.1 8B Instruct","date":"2024-07-23T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Ethics"],"draft":false,"id":"llama-3.1-8b-instruct","context":131072,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-10-31T23:27:09.000Z","slug":"models/llama-31-8b-instruct"},"content":"\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 8B instruct-tuned version is fast and efficient.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-lumimaid-70b","frontmatter":{"title":"Lumimaid v0.2 70B","meta_title":"Lumimaid v0.2 70B","description":"Lumimaid v0.2 70B","date":"2024-10-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"neversleep","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Ethics"],"draft":false,"id":"llama-3.1-lumimaid-70b","context":131072,"input":0.000003375,"output":0.0000045,"img":0,"request":0,"last_updated":"2024-11-11T03:03:31.000Z","slug":"models/llama-31-lumimaid-70b"},"content":"\nLumimaid v0.2 70B is a finetune of [Llama 3.1 70B](/meta-llama/llama-3.1-70b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-lumimaid-8b","frontmatter":{"title":"Lumimaid v0.2 8B","meta_title":"Lumimaid v0.2 8B","description":"Lumimaid v0.2 8B","date":"2024-09-15T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"neversleep","tags":["Programming","Machine Learning","Natural Language Processing","Chatbots","Ethics"],"draft":false,"id":"llama-3.1-lumimaid-8b","context":131072,"input":1.875e-7,"output":0.000001125,"img":0,"request":0,"last_updated":"2024-11-11T03:10:19.000Z","slug":"models/llama-31-lumimaid-8b"},"content":"\nLumimaid v0.2 8B is a finetune of [Llama 3.1 8B](/meta-llama/llama-3.1-8b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-nemotron-70b-instruct","frontmatter":{"title":"Nvidia: Llama 3.1 Nemotron 70B Instruct","meta_title":"Nvidia: Llama 3.1 Nemotron 70B Instruct","description":"Nvidia: Llama 3.1 Nemotron 70B Instruct","date":"2024-10-15T00:00:00.000Z","image":"https://img.rifx.online/logo/nvidia.svg","categories":["text 2 text"],"author":"nvidia","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Ethics"],"draft":false,"id":"llama-3.1-nemotron-70b-instruct","context":131072,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-10-15T00:00:00.000Z","slug":"models/llama-31-nemotron-70b-instruct"},"content":"\nNVIDIA's Llama 3.1 Nemotron 70B is a language model designed for generating precise and useful responses. Leveraging [Llama 3.1 70B](/models/meta-llama/llama-3.1-70b-instruct) architecture and Reinforcement Learning from Human Feedback (RLHF), it excels in automatic alignment benchmarks. This model is tailored for applications requiring high accuracy in helpfulness and response generation, suitable for diverse user queries across multiple domains.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-sonar-huge-128k-online","frontmatter":{"title":"Perplexity: Llama 3.1 Sonar 405B Online","meta_title":"Perplexity: Llama 3.1 Sonar 405B Online","description":"Perplexity: Llama 3.1 Sonar 405B Online","date":"2024-08-14T00:00:00.000Z","image":"https://img.rifx.online/logo/perplexity.svg","categories":["text 2 text"],"author":"perplexity","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"llama-3.1-sonar-huge-128k-online","context":127072,"input":0.000005,"output":0.000005,"img":0,"request":0.005,"last_updated":"2024-11-07T09:36:38.000Z","slug":"models/llama-31-sonar-huge-128k-online"},"content":"\nLlama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance. The model is built upon the Llama 3.1 405B and has internet access.\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-sonar-large-128k-online","frontmatter":{"title":"Perplexity: Llama 3.1 Sonar 70B Online","meta_title":"Perplexity: Llama 3.1 Sonar 70B Online","description":"Perplexity: Llama 3.1 Sonar 70B Online","date":"2024-08-01T00:00:00.000Z","image":"https://img.rifx.online/logo/perplexity.svg","categories":["text 2 text"],"author":"perplexity","tags":["Programming","Machine Learning","Natural Language Processing","Chatbots","Generative AI"],"draft":false,"id":"llama-3.1-sonar-large-128k-online","context":127072,"input":0.000001,"output":0.000001,"img":0,"request":0.005,"last_updated":"2024-11-07T09:37:21.000Z","slug":"models/llama-31-sonar-large-128k-online"},"content":"\nLlama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/perplexity/llama-3.1-sonar-large-128k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online\n\n"},{"lang":"en","group":"models","slug":"models/llama-31-sonar-small-128k-online","frontmatter":{"title":"Perplexity: Llama 3.1 Sonar 8B Online","meta_title":"Perplexity: Llama 3.1 Sonar 8B Online","description":"Perplexity: Llama 3.1 Sonar 8B Online","date":"2024-08-01T00:00:00.000Z","image":"https://img.rifx.online/logo/perplexity.svg","categories":["text 2 text"],"author":"perplexity","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"llama-3.1-sonar-small-128k-online","context":127072,"input":2e-7,"output":2e-7,"img":0,"request":0.005,"last_updated":"2024-11-07T09:38:09.000Z","slug":"models/llama-31-sonar-small-128k-online"},"content":"\nLlama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/perplexity/llama-3.1-sonar-small-128k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online\n\n"},{"lang":"en","group":"models","slug":"models/llama-32-11b-vision-instruct","frontmatter":{"title":"Meta: Llama 3.2 11B Vision Instruct","meta_title":"Meta: Llama 3.2 11B Vision Instruct","description":"Meta: Llama 3.2 11B Vision Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text image 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Computer Vision","Machine Learning","Generative AI","Data Science"],"draft":false,"is_recommended":true,"id":"llama-3.2-11b-vision-instruct","context":131072,"input":5.5e-8,"output":5.5e-8,"img":0.000079475,"request":0,"last_updated":"2024-11-14T05:10:41.000Z","slug":"models/llama-32-11b-vision-instruct"},"content":"\nLlama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.\n\nIts ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-32-1b-instruct","frontmatter":{"title":"Meta: Llama 3.2 1B Instruct","meta_title":"Meta: Llama 3.2 1B Instruct","description":"Meta: Llama 3.2 1B Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Programming","Technology","Machine Learning","Generative AI"],"draft":false,"id":"llama-3.2-1b-instruct","context":131072,"input":1e-8,"output":2e-8,"img":0,"request":0,"last_updated":"2024-09-25T00:00:00.000Z","slug":"models/llama-32-1b-instruct"},"content":"\nLlama 3.2 1B is a 1-billion-parameter language model focused on efficiently performing natural language tasks, such as summarization, dialogue, and multilingual text analysis. Its smaller size allows it to operate efficiently in low-resource environments while maintaining strong task performance.\n\nSupporting eight core languages and fine-tunable for more, Llama 1.3B is ideal for businesses or developers seeking lightweight yet powerful AI solutions that can operate in diverse multilingual settings without the high computational demand of larger models.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-32-3b-instruct","frontmatter":{"title":"Meta: Llama 3.2 3B Instruct","meta_title":"Meta: Llama 3.2 3B Instruct","description":"Meta: Llama 3.2 3B Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Machine Learning","Generative AI","Chatbots","Multilingual"],"draft":false,"id":"llama-3.2-3b-instruct","context":131072,"input":3e-8,"output":5e-8,"img":0,"request":0,"last_updated":"2024-11-11T03:09:59.000Z","slug":"models/llama-32-3b-instruct"},"content":"\nLlama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/llama-32-90b-vision-instruct","frontmatter":{"title":"Meta: Llama 3.2 90B Vision Instruct","meta_title":"Meta: Llama 3.2 90B Vision Instruct","description":"Meta: Llama 3.2 90B Vision Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text image 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Computer Vision","Machine Learning","Data Science","Generative AI"],"draft":false,"id":"llama-3.2-90b-vision-instruct","context":131072,"input":3.5e-7,"output":4e-7,"img":0.00050575,"request":0,"last_updated":"2024-09-25T00:00:00.000Z","slug":"models/llama-32-90b-vision-instruct"},"content":"\nThe Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal model designed for the most challenging visual reasoning and language tasks. It offers unparalleled accuracy in image captioning, visual question answering, and advanced image-text comprehension. Pre-trained on vast multimodal datasets and fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the most demanding image-based AI tasks.\n\nThis model is perfect for industries requiring cutting-edge multimodal AI capabilities, particularly those dealing with complex, real-time visual and textual analysis.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"en","group":"models","slug":"models/lzlv-70b-fp16-hf","frontmatter":{"title":"lzlv 70B","meta_title":"lzlv 70B","description":"lzlv 70B","date":"2023-11-12T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"lizpreciatior","tags":["Roleplay","Programming","Machine Learning","Generative AI","Chatbots"],"draft":false,"id":"lzlv-70b-fp16-hf","context":4096,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-04T12:50:34.000Z","slug":"models/lzlv-70b-fp16-hf"},"content":"\nA Mythomax/MLewd_13B-style merge of selected 70B models.\nA multi-model merge of several LLaMA2 70B finetunes for roleplaying and creative work. The goal was to create a model that combines creativity with intelligence for an enhanced experience.\n\n#merge #uncensored\n\n"},{"lang":"en","group":"models","slug":"models/magnum-v2-72b","frontmatter":{"title":"Magnum v2 72B","meta_title":"Magnum v2 72B","description":"Magnum v2 72B","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"anthracite-org","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"id":"magnum-v2-72b","context":32768,"input":0.00000375,"output":0.0000045,"img":0,"request":0,"last_updated":"2024-11-11T03:09:19.000Z","slug":"models/magnum-v2-72b"},"content":"\nFrom the maker of [Goliath](https://openrouter.ai/alpindale/goliath-120b), Magnum 72B is the seventh in a family of models designed to achieve the prose quality of the Claude 3 models, notably Opus & Sonnet.\n\nThe model is based on [Qwen2 72B](https://openrouter.ai/qwen/qwen-2-72b-instruct) and trained with 55 million tokens of highly curated roleplay (RP) data.\n\n"},{"lang":"en","group":"models","slug":"models/magnum-v4-72b","frontmatter":{"title":"Magnum v4 72B","meta_title":"Magnum v4 72B","description":"Magnum v4 72B","date":"2024-10-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"anthracite-org","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"magnum-v4-72b","context":32768,"input":0.000001875,"output":0.00000225,"img":0,"request":0,"last_updated":"2024-11-04T12:39:55.000Z","slug":"models/magnum-v4-72b"},"content":"\nThis is a series of models designed to replicate the prose quality of the Claude 3 models, specifically Sonnet and Opus.\n\nThe model is fine-tuned on top of [Qwen2.5 72B].\n\n"},{"lang":"en","group":"models","slug":"models/ministral-3b","frontmatter":{"title":"Ministral 3B","meta_title":"Ministral 3B","description":"Ministral 3B","date":"2024-10-17T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Natural Language Processing","Data Science","Generative AI"],"draft":false,"id":"ministral-3b","context":128000,"input":4e-8,"output":4e-8,"img":0,"request":0,"last_updated":"2024-11-07T00:24:37.000Z","slug":"models/ministral-3b"},"content":"\nMinistral 3B is a 3B parameter model optimized for on-device and edge computing. It excels in knowledge, commonsense reasoning, and function-calling, outperforming larger models like Mistral 7B on most benchmarks. Supporting up to 128k context length, it‚Äôs ideal for orchestrating agentic workflows and specialist tasks with efficient inference.\n\n"},{"lang":"en","group":"models","slug":"models/ministral-8b","frontmatter":{"title":"Ministral 8B","meta_title":"Ministral 8B","description":"Ministral 8B","date":"2024-10-17T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Technology","Machine Learning","Data Science","Generative AI","Ethics"],"draft":false,"id":"ministral-8b","context":128000,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-10-19T04:54:11.000Z","slug":"models/ministral-8b"},"content":"\nMinistral 8B is an 8B parameter model featuring a unique interleaved sliding-window attention pattern for faster, memory-efficient inference. Designed for edge use cases, it supports up to 128k context length and excels in knowledge and reasoning tasks. It outperforms peers in the sub-10B category, making it perfect for low-latency, privacy-first applications.\n\n"},{"lang":"en","group":"models","slug":"models/mistral-7b-instruct","frontmatter":{"title":"Mistral: Mistral 7B Instruct","meta_title":"Mistral: Mistral 7B Instruct","description":"Mistral: Mistral 7B Instruct","date":"2024-05-27T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"mistral-7b-instruct","context":32768,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-10-31T23:13:12.000Z","slug":"models/mistral-7b-instruct"},"content":"\nA high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*\n\n"},{"lang":"en","group":"models","slug":"models/mistral-nemo","frontmatter":{"title":"Mistral: Mistral Nemo","meta_title":"Mistral: Mistral Nemo","description":"Mistral: Mistral Nemo","date":"2024-07-19T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Data Science"],"draft":false,"id":"mistral-nemo","context":128000,"input":1.3e-7,"output":1.3e-7,"img":0,"request":0,"last_updated":"2024-10-31T23:10:58.000Z","slug":"models/mistral-nemo"},"content":"\nA 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.\n\n"},{"lang":"en","group":"models","slug":"models/mistral-tiny","frontmatter":{"title":"Mistral Tiny","meta_title":"Mistral Tiny","description":"Mistral Tiny","date":"2024-01-10T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Data Science","Generative AI","Chatbots"],"draft":false,"id":"mistral-tiny","context":32000,"input":2.5e-7,"output":2.5e-7,"img":0,"request":0,"last_updated":"2024-10-31T23:12:22.000Z","slug":"models/mistral-tiny"},"content":"\nThis model is currently powered by Mistral-7B-v0.2, and incorporates a \"better\" fine-tuning than [Mistral 7B](/mistralai/mistral-7b-instruct-v0.1), inspired by community work. It's best used for large batch processing tasks where cost is a significant factor but reasoning capabilities are not crucial.\n\n"},{"lang":"en","group":"models","slug":"models/mixtral-8x22b-instruct","frontmatter":{"title":"Mistral: Mixtral 8x22B Instruct","meta_title":"Mistral: Mixtral 8x22B Instruct","description":"Mistral: Mixtral 8x22B Instruct","date":"2024-04-17T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Natural Language Processing","Machine Learning","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"mixtral-8x22b-instruct","context":65536,"input":9e-7,"output":9e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:21:32.000Z","slug":"models/mixtral-8x22b-instruct"},"content":"\nMistral's official instruct fine-tuned version of [Mixtral 8x22B](/mistralai/mixtral-8x22b). It uses 39B active parameters out of 141B, offering unparalleled cost efficiency for its size. Its strengths include:\n- strong math, coding, and reasoning\n- large context length (64k)\n- fluency in English, French, Italian, German, and Spanish\n\nSee benchmarks on the launch announcement [here](https://mistral.ai/news/mixtral-8x22b/).\n#moe\n\n"},{"lang":"en","group":"models","slug":"models/mixtral-8x7b","frontmatter":{"title":"Mixtral 8x7B (base)","meta_title":"Mixtral 8x7B (base)","description":"Mixtral 8x7B (base)","date":"2023-12-10T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Generative AI","Machine Learning","Data Science","Programming","Technology/Web"],"draft":false,"is_recommended":true,"id":"mixtral-8x7b","context":32768,"input":5.4e-7,"output":5.4e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:22:09.000Z","slug":"models/mixtral-8x7b"},"content":"\nA pretrained generative Sparse Mixture of Experts, by Mistral AI. Incorporates 8 experts (feed-forward networks) for a total of 47B parameters. Base model (not fine-tuned for instructions) - see [Mixtral 8x7B Instruct](/mistralai/mixtral-8x7b-instruct) for an instruct-tuned model.\n\n#moe\n\n"},{"lang":"en","group":"models","slug":"models/mn-inferor-12b","frontmatter":{"title":"Mistral Nemo Inferor 12B","meta_title":"Mistral Nemo Inferor 12B","description":"Mistral Nemo Inferor 12B","date":"2024-11-13T02:20:28.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"infermatic","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"id":"mn-inferor-12b","context":32000,"input":2.5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T02:10:35.000Z","slug":"models/mn-inferor-12b"},"content":"\nInferor is a merge of top roleplay models, expert on immersive narratives and storytelling.\n\nThis model was merged using the [Model Stock](https://arxiv.org/abs/2403.19522) merge method using [anthracite-org/magnum-v4-12b](https://openrouter.ai/anthracite-org/magnum-v4-72b) as a base.\n\n\n"},{"lang":"en","group":"models","slug":"models/mn-starcannon-12b","frontmatter":{"title":"Mistral Nemo 12B Starcannon","meta_title":"Mistral Nemo 12B Starcannon","description":"Mistral Nemo 12B Starcannon","date":"2024-08-13T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"aetherwiing","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"mn-starcannon-12b","context":12000,"input":0.000002,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:16:53.000Z","slug":"models/mn-starcannon-12b"},"content":"\nStarcannon 12B is a creative roleplay and story writing model, using [nothingiisreal/mn-celeste-12b](https://openrouter.ai/nothingiisreal/mn-celeste-12b) as a base and [intervitens/mini-magnum-12b-v1.1](https://huggingface.co/intervitens/mini-magnum-12b-v1.1) merged in using the [TIES](https://arxiv.org/abs/2306.01708) method.\n\nAlthough more similar to Magnum overall, the model remains very creative, with a pleasant writing style. It is recommended for people wanting more variety than Magnum, and yet more verbose prose than Celeste.\n\n"},{"lang":"en","group":"models","slug":"models/mythomax-l2-13b","frontmatter":{"title":"MythoMax 13B","meta_title":"MythoMax 13B","description":"MythoMax 13B","date":"2023-07-02T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"gryphe","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"id":"mythomax-l2-13b","context":4096,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-10-28T13:10:41.000Z","slug":"models/mythomax-l2-13b"},"content":"\nOne of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay. #merge\n\n"},{"lang":"en","group":"models","slug":"models/o1-mini","frontmatter":{"title":"OpenAI: o1-mini","meta_title":"OpenAI: o1-mini","description":"OpenAI: o1-mini","date":"2024-09-12T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"openai","tags":["Programming","Science","Natural Language Processing","Machine Learning","Data Science"],"draft":false,"id":"o1-mini","context":128000,"input":0.000003,"output":0.000012,"img":0,"request":0,"last_updated":"2024-09-12T00:00:00.000Z","slug":"models/o1-mini"},"content":"\nThe latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.\n\n"},{"lang":"en","group":"models","slug":"models/o1-preview","frontmatter":{"title":"OpenAI: o1-preview","meta_title":"OpenAI: o1-preview","description":"OpenAI: o1-preview","date":"2024-09-12T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"openai","tags":["Programming","Science","Natural Language Processing","Machine Learning","Data Science"],"draft":false,"id":"o1-preview","context":128000,"input":0.000015,"output":0.00006,"img":0,"request":0,"last_updated":"2024-09-12T00:00:00.000Z","slug":"models/o1-preview"},"content":"\nThe latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.\n\n"},{"lang":"en","group":"models","slug":"models/openai-gpt-4o-mini","frontmatter":{"title":"OpenAI: GPT-4o-Mini Official","meta_title":"OpenAI: GPT-4o-Mini Official","description":"OpenAI: GPT-4o-Mini Official","date":"2024-10-26T09:00:07.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"gpt-4o-mini","tags":["Generative AI","Natural Language Processing","Machine Learning","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"openai/gpt-4o-mini","context":128000,"input":1.5e-7,"output":6e-7,"img":0.0036125,"request":0,"last_updated":"2024-11-14T09:46:04.000Z","slug":"models/openai-gpt-4o-mini"},"content":"\nGPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n"},{"lang":"en","group":"models","slug":"models/openai-gpt-4o","frontmatter":{"title":"OpenAI: GPT-4o Official","meta_title":"OpenAI: GPT-4o Official","description":"OpenAI: GPT-4o Official","date":"2024-11-14T02:53:29.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"gpt-4o","tags":["Generative AI","Natural Language Processing","Technology","Chatbots","Machine Learning"],"draft":false,"is_recommended":false,"id":"openai/gpt-4o","context":128000,"input":0.0000025,"output":0.00001,"img":0.0036125,"request":0,"last_updated":"2024-11-14T09:45:25.000Z","slug":"models/openai-gpt-4o"},"content":"\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n"},{"lang":"en","group":"models","slug":"models/openchat-7b","frontmatter":{"title":"OpenChat 3.5 7B","meta_title":"OpenChat 3.5 7B","description":"OpenChat 3.5 7B","date":"2023-11-28T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"openchat","tags":["Programming","Natural Language Processing","Machine Learning","Open Source","Generative AI"],"draft":false,"id":"openchat-7b","context":8192,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-11-07T09:39:42.000Z","slug":"models/openchat-7b"},"content":"\nOpenChat 7B is a library of open-source language models, fine-tuned with \"C-RLFT (Conditioned Reinforcement Learning Fine-Tuning)\" - a strategy inspired by offline reinforcement learning. It has been trained on mixed-quality data without preference labels.\n\n- For OpenChat fine-tuned on Mistral 7B, check out [OpenChat 7B](/openchat/openchat-7b).\n- For OpenChat fine-tuned on Llama 8B, check out [OpenChat 8B](/openchat/openchat-8b).\n\n#open-source\n\n"},{"lang":"en","group":"models","slug":"models/palm-2-chat-bison-32k","frontmatter":{"title":"Google: PaLM 2 Chat 32k","meta_title":"Google: PaLM 2 Chat 32k","description":"Google: PaLM 2 Chat 32k","date":"2023-11-03T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Natural Language Processing","Programming","Technology","Chatbots","Generative AI"],"draft":false,"id":"palm-2-chat-bison-32k","context":32760,"input":0.000001,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:15:52.000Z","slug":"models/palm-2-chat-bison-32k"},"content":"\nPaLM 2 is a language model by Google with improved multilingual, reasoning and coding capabilities.\n\n"},{"lang":"en","group":"models","slug":"models/palm-2-codechat-bison-32k","frontmatter":{"title":"Google: PaLM 2 Code Chat 32k","meta_title":"Google: PaLM 2 Code Chat 32k","description":"Google: PaLM 2 Code Chat 32k","date":"2023-11-03T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Programming","Chatbots","Natural Language Processing","Generative AI","Technology/Web"],"draft":false,"id":"palm-2-codechat-bison-32k","context":32760,"input":0.000001,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:16:01.000Z","slug":"models/palm-2-codechat-bison-32k"},"content":"\nPaLM 2 fine-tuned for chatbot conversations that help with code-related questions.\n\n"},{"lang":"en","group":"models","slug":"models/phi-3-medium-128k-instruct","frontmatter":{"title":"Phi-3 Medium 128K Instruct","meta_title":"Phi-3 Medium 128K Instruct","description":"Phi-3 Medium 128K Instruct","date":"2024-05-24T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Natural Language Processing","Machine Learning","Programming","Data Science","Generative AI"],"draft":false,"id":"phi-3-medium-128k-instruct","context":128000,"input":0.000001,"output":0.000001,"img":0,"request":0,"last_updated":"2024-11-11T03:17:38.000Z","slug":"models/phi-3-medium-128k-instruct"},"content":"\nPhi-3 128K Medium is a powerful 14-billion parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3 70B level of performance.\n\nFor 4k context length, try [Phi-3 Medium 4K](/microsoft/phi-3-medium-4k-instruct).\n\n"},{"lang":"en","group":"models","slug":"models/phi-3-mini-128k-instruct","frontmatter":{"title":"Phi-3 Mini 128K Instruct","meta_title":"Phi-3 Mini 128K Instruct","description":"Phi-3 Mini 128K Instruct","date":"2024-05-26T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Natural Language Processing","Machine Learning","Programming","Data Science","Generative AI"],"draft":false,"id":"phi-3-mini-128k-instruct","context":128000,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:17:47.000Z","slug":"models/phi-3-mini-128k-instruct"},"content":"\nPhi-3 Mini is a powerful 3.8B parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. This model is static, trained on an offline dataset with an October 2023 cutoff date.\n\n"},{"lang":"en","group":"models","slug":"models/phi-35-mini-128k-instruct","frontmatter":{"title":"Phi-3.5 Mini 128K Instruct","meta_title":"Phi-3.5 Mini 128K Instruct","description":"Phi-3.5 Mini 128K Instruct","date":"2024-08-21T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Programming","Machine Learning","Natural Language Processing","Data Science","Generative AI"],"draft":false,"id":"phi-3.5-mini-128k-instruct","context":128000,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-11-01T04:17:17.000Z","slug":"models/phi-35-mini-128k-instruct"},"content":"\nPhi-3.5 models are lightweight, state-of-the-art open models. These models were trained with Phi-3 datasets that include both synthetic data and the filtered, publicly available websites data, with a focus on high quality and reasoning-dense properties. Phi-3.5 Mini uses 3.8B parameters, and is a dense decoder-only transformer model using the same tokenizer as [Phi-3 Mini](/microsoft/phi-3-mini-128k-instruct).\n\nThe models underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures. When assessed against benchmarks that test common sense, language understanding, math, code, long context and logical reasoning, Phi-3.5 models showcased robust and state-of-the-art performance among models with less than 13 billion parameters.\n\n"},{"lang":"en","group":"models","slug":"models/pixtral-12b","frontmatter":{"title":"Mistral: Pixtral 12B","meta_title":"Mistral: Pixtral 12B","description":"Mistral: Pixtral 12B","date":"2024-09-10T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text image 2 text"],"author":"mistralai","tags":["Natural Language Processing","Machine Learning","Technology","Generative AI","Computer Vision"],"draft":false,"id":"pixtral-12b","context":4096,"input":1e-7,"output":1e-7,"img":0.0001445,"request":0,"last_updated":"2024-11-11T03:10:29.000Z","slug":"models/pixtral-12b"},"content":"\nThe first image to text model from Mistral AI. Its weight was launched via torrent per their tradition: https://x.com/mistralai/status/1833758285167722836\n\n"},{"lang":"en","group":"models","slug":"models/qwen-2-7b-instruct","frontmatter":{"title":"Qwen 2 7B Instruct","meta_title":"Qwen 2 7B Instruct","description":"Qwen 2 7B Instruct","date":"2024-07-16T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Natural Language Processing","Programming","Machine Learning","Data Science","Ethics"],"draft":false,"id":"qwen-2-7b-instruct","context":32768,"input":5.4e-8,"output":5.4e-8,"img":0,"request":0,"last_updated":"2024-07-16T00:00:00.000Z","slug":"models/qwen-2-7b-instruct"},"content":"\nQwen2 7B is a transformer-based model that excels in language understanding, multilingual capabilities, coding, mathematics, and reasoning.\n\nIt features SwiGLU activation, attention QKV bias, and group query attention. It is pretrained on extensive data with supervised finetuning and direct preference optimization.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2/) and [GitHub repo](https://github.com/QwenLM/Qwen2).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).\n\n"},{"lang":"en","group":"models","slug":"models/qwen-2-vl-72b-instruct","frontmatter":{"title":"Qwen2-VL 72B Instruct","meta_title":"Qwen2-VL 72B Instruct","description":"Qwen2-VL 72B Instruct","date":"2024-09-18T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text image 2 text"],"author":"qwen","tags":["Natural Language Processing","Computer Vision","Robotics","Machine Learning"],"draft":false,"id":"qwen-2-vl-72b-instruct","context":32768,"input":4e-7,"output":4e-7,"img":0.000578,"request":0,"last_updated":"2024-09-18T00:00:00.000Z","slug":"models/qwen-2-vl-72b-instruct"},"content":"\nQwen2 VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).\n\n"},{"lang":"en","group":"models","slug":"models/qwen-2-vl-7b-instruct","frontmatter":{"title":"Qwen2-VL 7B Instruct","meta_title":"Qwen2-VL 7B Instruct","description":"Qwen2-VL 7B Instruct","date":"2024-08-28T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text image 2 text"],"author":"qwen","tags":["Natural Language Processing","Computer Vision","Robotics","Multimodal AI","Generative AI"],"draft":false,"id":"qwen-2-vl-7b-instruct","context":32768,"input":1e-7,"output":1e-7,"img":0.0001445,"request":0,"last_updated":"2024-11-11T03:13:01.000Z","slug":"models/qwen-2-vl-7b-instruct"},"content":"\nQwen2 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).\n\n"},{"lang":"en","group":"models","slug":"models/qwen-25-72b-instruct","frontmatter":{"title":"Qwen2.5 72B Instruct","meta_title":"Qwen2.5 72B Instruct","description":"Qwen2.5 72B Instruct","date":"2024-09-19T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Programming","Natural Language Processing","Chatbots","Machine Learning","Data Science"],"draft":false,"id":"qwen-2.5-72b-instruct","context":131072,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-09-19T00:00:00.000Z","slug":"models/qwen-25-72b-instruct"},"content":"\nQwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).\n\n"},{"lang":"en","group":"models","slug":"models/qwen-25-7b-instruct","frontmatter":{"title":"Qwen2.5 7B Instruct","meta_title":"Qwen2.5 7B Instruct","description":"Qwen2.5 7B Instruct","date":"2024-10-16T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Programming","Natural Language Processing","Chatbots","Machine Learning","Data Science"],"draft":false,"id":"qwen-2.5-7b-instruct","context":131072,"input":2.7e-7,"output":2.7e-7,"img":0,"request":0,"last_updated":"2024-10-16T00:00:00.000Z","slug":"models/qwen-25-7b-instruct"},"content":"\nQwen2.5 7B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).\n\n"},{"lang":"en","group":"models","slug":"models/qwen-25-coder-32b-instruct","frontmatter":{"title":"Qwen2.5 Coder 32B Instruct","meta_title":"Qwen2.5 Coder 32B Instruct","description":"Qwen2.5 Coder 32B Instruct","date":"2024-11-11T23:40:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Programming","Programming/Scripting","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"is_recommended":true,"id":"qwen-2.5-coder-32b-instruct","context":32768,"input":1.8e-7,"output":1.8e-7,"img":0,"request":0,"last_updated":"2024-11-15T23:24:23.000Z","slug":"models/qwen-25-coder-32b-instruct"},"content":"\nQwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code reasoning** and **code fixing**. \n- A more comprehensive foundation for real-world applications such as **Code Agents**. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\n\nTo read more about its evaluation results, check out [Qwen 2.5 Coder's blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/).\n\n\n\n\n"},{"lang":"en","group":"models","slug":"models/remm-slerp-l2-13b","frontmatter":{"title":"ReMM SLERP 13B","meta_title":"ReMM SLERP 13B","description":"ReMM SLERP 13B","date":"2023-07-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"undi95","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"is_recommended":true,"id":"remm-slerp-l2-13b","context":4096,"input":0.000001125,"output":0.000001125,"img":0,"request":0,"last_updated":"2024-11-14T04:06:00.000Z","slug":"models/remm-slerp-l2-13b"},"content":"\nA recreation trial of the original MythoMax-L2-B13 but with updated models. #merge\n\n"},{"lang":"en","group":"models","slug":"models/remm-slerp-l2-13b:extended","frontmatter":{"title":"ReMM SLERP 13B (extended)","meta_title":"ReMM SLERP 13B (extended)","description":"ReMM SLERP 13B (extended)","date":"2023-07-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"undi95","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"remm-slerp-l2-13b:extended","context":6144,"input":0.000001125,"output":0.000001125,"img":0,"request":0,"last_updated":"2024-11-04T12:47:21.000Z","slug":"models/remm-slerp-l2-13b:extended"},"content":"\nA recreation trial of the original MythoMax-L2-B13 but with updated models. #merge\n\n_These are extended-context endpoints for [ReMM SLERP 13B](/undi95/remm-slerp-l2-13b). They may have higher prices._\n\n"},{"lang":"en","group":"models","slug":"models/rocinante-12b","frontmatter":{"title":"Rocinante 12B","meta_title":"Rocinante 12B","description":"Rocinante 12B","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"thedrummer","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"rocinante-12b","context":32768,"input":2.5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:09:37.000Z","slug":"models/rocinante-12b"},"content":"\nRocinante 12B is designed for engaging storytelling and rich prose.\n\nEarly testers have reported:\n- Expanded vocabulary with unique and expressive word choices\n- Enhanced creativity for vivid narratives\n- Adventure-filled and captivating stories\n\n"},{"lang":"en","group":"models","slug":"models/sorcererlm-8x22b","frontmatter":{"title":"Sorcererlm 8x22b","meta_title":"Sorcererlm 8x22b","description":"Sorcererlm 8x22b","date":"2024-11-08T22:31:23.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"raifle","tags":["Roleplay","Programming","Natural Language Processing","Chatbots","Generative AI"],"draft":false,"id":"sorcererlm-8x22b","context":16000,"input":0.0000045,"output":0.0000045,"img":0,"request":0,"last_updated":"2024-11-11T02:56:49.000Z","slug":"models/sorcererlm-8x22b"},"content":"\nSorcererLM is an advanced RP and storytelling model, built as a Low-rank 16-bit LoRA fine-tuned on WizardLM-2-8x22B.\n\n- Advanced reasoning and emotional intelligence for engaging and immersive interactions\n- Vivid writing capabilities enriched with spatial and contextual awareness\n- Enhanced narrative depth, promoting creative and dynamic storytelling\n\n"},{"lang":"en","group":"models","slug":"models/toppy-m-7b","frontmatter":{"title":"Toppy M 7B","meta_title":"Toppy M 7B","description":"Toppy M 7B","date":"2023-11-10T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"undi95","tags":["Programming","Machine Learning","Generative AI","Chatbots","Data Science"],"draft":false,"id":"toppy-m-7b","context":4096,"input":7e-8,"output":7e-8,"img":0,"request":0,"last_updated":"2024-11-04T12:51:35.000Z","slug":"models/toppy-m-7b"},"content":"\nA wild 7B parameter model that merges several models using the new task_arithmetic merge method from mergekit.\nList of merged models:\n- NousResearch/Nous-Capybara-7B-V1.9\n- [HuggingFaceH4/zephyr-7b-beta](/huggingfaceh4/zephyr-7b-beta)\n- lemonilia/AshhLimaRP-Mistral-7B\n- Vulkane/120-Days-of-Sodom-LoRA-Mistral-7b\n- Undi95/Mistral-pippa-sharegpt-7b-qlora\n\n#merge #uncensored\n\n"},{"lang":"en","group":"models","slug":"models/unslopnemo-12b","frontmatter":{"title":"Unslopnemo 12b","meta_title":"Unslopnemo 12b","description":"Unslopnemo 12b","date":"2024-11-08T22:04:08.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"thedrummer","tags":["Roleplay","Programming","Generative AI","Chatbots","Natural Language Processing"],"draft":false,"id":"unslopnemo-12b","context":32000,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T02:10:09.000Z","slug":"models/unslopnemo-12b"},"content":"\nUnslopNemo v4.1 is the latest addition from the creator of Rocinante, designed for adventure writing and role-play scenarios.\n\n"},{"lang":"en","group":"models","slug":"models/wizardlm-2-7b","frontmatter":{"title":"WizardLM-2 7B","meta_title":"WizardLM-2 7B","description":"WizardLM-2 7B","date":"2024-04-16T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"wizardlm-2-7b","context":32000,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-10-31T23:23:36.000Z","slug":"models/wizardlm-2-7b"},"content":"\nWizardLM-2 7B is the smaller variant of Microsoft AI's latest Wizard model. It is the fastest and achieves comparable performance with existing 10x larger opensource leading models\n\nIt is a finetune of [Mistral 7B Instruct](/mistralai/mistral-7b-instruct), using the same technique as [WizardLM-2 8x22B](/microsoft/wizardlm-2-8x22b).\n\nTo read more about the model release, [click here](https://wizardlm.github.io/WizardLM2/).\n\n#moe\n\n"},{"lang":"en","group":"models","slug":"models/wizardlm-2-8x22b","frontmatter":{"title":"WizardLM-2 8x22B","meta_title":"WizardLM-2 8x22B","description":"WizardLM-2 8x22B","date":"2024-04-16T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"wizardlm-2-8x22b","context":65536,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-10-31T23:24:21.000Z","slug":"models/wizardlm-2-8x22b"},"content":"\nWizardLM-2 8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly competitive performance compared to leading proprietary models, and it consistently outperforms all existing state-of-the-art opensource models.\n\nIt is an instruct finetune of [Mixtral 8x22B](/mistralai/mixtral-8x22b).\n\nTo read more about the model release, [click here](https://wizardlm.github.io/WizardLM2/).\n\n#moe\n\n"},{"lang":"zh","group":"models","slug":"models/chatgpt-4o-latest","frontmatter":{"title":"OpenAI: ChatGPT-4o","meta_title":"OpenAI: ChatGPT-4o","description":"OpenAI: ChatGPT-4o","date":"2024-08-14T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text image 2 text"],"author":"openai","tags":["Chatbots","Generative AI","Machine Learning","Natural Language Processing"],"draft":false,"id":"chatgpt-4o-latest","context":128000,"input":0.000005,"output":0.000015,"img":0.007225,"request":0,"last_updated":"2024-08-14T00:00:00.000Z","slug":"models/chatgpt-4o-latest"},"content":"\nÂä®ÊÄÅÊ®°ÂûãÊåÅÁª≠Êõ¥Êñ∞Âà∞ ChatGPT ‰∏≠ÁöÑÂΩìÂâçÁâàÊú¨ [GPT-4o](/openai/gpt-4o)„ÄÇÊó®Âú®Áî®‰∫éÁ†îÁ©∂ÂíåËØÑ‰º∞„ÄÇ\n\nÊ≥®ÊÑèÔºöÊ≠§Ê®°ÂûãÁõÆÂâçÂ§Ñ‰∫éÂÆûÈ™åÈò∂ÊÆµÔºå‰∏çÈÄÇÂêàÁîü‰∫ß‰ΩøÁî®ÔºåÂπ∂ÂèØËÉΩÂèóÂà∞‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/claude-3-haiku","frontmatter":{"title":"Anthropic: Claude 3 Haiku","meta_title":"Anthropic: Claude 3 Haiku","description":"Anthropic: Claude 3 Haiku","date":"2024-03-13T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Machine Learning","Generative AI","Chatbots","Natural Language Processing"],"draft":false,"id":"claude-3-haiku","context":200000,"input":2.5e-7,"output":0.00000125,"img":0.0004,"request":0,"last_updated":"2024-10-24T11:54:59.000Z","slug":"models/claude-3-haiku"},"content":"\nClaude 3 Haiku ÊòØ Anthropic ÂèçÂ∫îÈÄüÂ∫¶ÊúÄÂø´„ÄÅ‰ΩìÁßØÊúÄÂ∞èÁöÑÊ®°ÂûãÔºåËÉΩÂ§üÂÆûÁé∞Ëøë‰πéÂç≥Êó∂ÁöÑÂìçÂ∫î„ÄÇÂø´ÈÄü‰∏îÂáÜÁ°ÆÁöÑÂÆöÂêëÊÄßËÉΩ„ÄÇ\n\nÊü•ÁúãÂèëÂ∏ÉÂÖ¨ÂëäÂíåÂü∫ÂáÜÊµãËØïÁªìÊûú [ËøôÈáå](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/claude-3-opus","frontmatter":{"title":"Anthropic: Claude 3 Opus","meta_title":"Anthropic: Claude 3 Opus","description":"Anthropic: Claude 3 Opus","date":"2024-03-05T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"claude-3-opus","context":200000,"input":0.000015,"output":0.000075,"img":0.024,"request":0,"last_updated":"2024-11-07T09:45:35.000Z","slug":"models/claude-3-opus"},"content":"\nClaude 3 Opus ÊòØ Anthropic ÈíàÂØπÈ´òÂ∫¶Â§çÊùÇ‰ªªÂä°ÁöÑÊúÄÂº∫Â§ßÊ®°Âûã„ÄÇÂÆÉÊã•ÊúâÈ°∂Á∫ßÁöÑÊÄßËÉΩ„ÄÅÊô∫ËÉΩ„ÄÅÊµÅÁïÖÊÄßÂíåÁêÜËß£ËÉΩÂäõ„ÄÇ\n\nÊü•ÁúãÂèëÂ∏ÉÂÖ¨ÂëäÂíåÂü∫ÂáÜÊµãËØïÁªìÊûú [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/claude-3-sonnet","frontmatter":{"title":"Anthropic: Claude 3 Sonnet","meta_title":"Anthropic: Claude 3 Sonnet","description":"Anthropic: Claude 3 Sonnet","date":"2024-03-05T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Technology","Machine Learning","Data Science","Chatbots"],"draft":false,"is_recommended":true,"id":"claude-3-sonnet","context":200000,"input":0.000003,"output":0.000015,"img":0.0048,"request":0,"last_updated":"2024-11-14T04:05:16.000Z","slug":"models/claude-3-sonnet"},"content":"\nClaude 3 Sonnet ÊòØ‰ºÅ‰∏öÂ∑•‰ΩúË¥üËΩΩÁöÑÁêÜÊÉ≥Êô∫ËÉΩ‰∏éÈÄüÂ∫¶Âπ≥Ë°°„ÄÇ‰ª•Êõ¥‰ΩéÁöÑ‰ª∑Ê†ºÊèê‰æõÊúÄÂ§ßÊïàÁî®ÔºåÂèØÈù†ÔºåÈÄÇÂêàÂ§ßËßÑÊ®°ÈÉ®ÁΩ≤ÁöÑÂπ≥Ë°°„ÄÇ\n\nÊü•ÁúãÂèëÂ∏ÉÂÖ¨ÂëäÂíåÂü∫ÂáÜÊµãËØïÁªìÊûú [ËøôÈáå](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/claude-35-haiku","frontmatter":{"title":"Anthropic: Claude 3.5 Haiku","meta_title":"Anthropic: Claude 3.5 Haiku","description":"Anthropic: Claude 3.5 Haiku","date":"2024-11-04T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text 2 text"],"author":"anthropic","tags":["Programming","Chatbots","Data Science","Machine Learning","Natural Language Processing"],"draft":false,"id":"claude-3.5-haiku","context":200000,"input":0.000001,"output":0.000005,"img":0,"request":0,"last_updated":"2024-11-07T09:46:02.000Z","slug":"models/claude-35-haiku"},"content":"\nClaude 3.5 Haiku ÁâπÊÄßÊèê‰æõ‰∫ÜÊõ¥È´òÁöÑÈÄüÂ∫¶„ÄÅÁºñÁ†ÅÂáÜÁ°ÆÊÄßÂíåÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõ„ÄÇÊó®Âú®Âú®ÂÆûÊó∂Â∫îÁî®‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂÆÉÊèê‰æõ‰∫ÜÂø´ÈÄüÁöÑÂìçÂ∫îÊó∂Èó¥ÔºåËøôÂØπ‰∫éÂä®ÊÄÅ‰ªªÂä°ÔºàÂ¶ÇËÅäÂ§©‰∫íÂä®ÂíåÂç≥Êó∂ÁºñÁ†ÅÂª∫ËÆÆÔºâËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n\nËøô‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÈÄüÂ∫¶ÂíåÁ≤æÂ∫¶ÁöÑÁéØÂ¢ÉÔºå‰æãÂ¶ÇËΩØ‰ª∂ÂºÄÂèë„ÄÅÂÆ¢Êà∑ÊúçÂä°Êú∫Âô®‰∫∫ÂíåÊï∞ÊçÆÁÆ°ÁêÜÁ≥ªÁªü„ÄÇ\n\nÊ≠§Ê®°ÂûãÂΩìÂâçÊåáÂêë [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).\n\n"},{"lang":"zh","group":"models","slug":"models/claude-35-sonnet","frontmatter":{"title":"Anthropic: Claude 3.5 Sonnet","meta_title":"Anthropic: Claude 3.5 Sonnet","description":"Anthropic: Claude 3.5 Sonnet","date":"2024-06-20T00:00:00.000Z","image":"https://img.rifx.online/logo/anthropic.svg","categories":["text image 2 text"],"author":"anthropic","tags":["Programming","Data Science","Computer Vision","Chatbots","Autonomous Systems"],"draft":false,"id":"claude-3.5-sonnet","context":200000,"input":0.000003,"output":0.000015,"img":0.0048,"request":0,"last_updated":"2024-10-24T11:45:46.000Z","slug":"models/claude-35-sonnet"},"content":"\nClaude 3.5 Sonnet Êèê‰æõ‰ºò‰∫é Opus ÁöÑËÉΩÂäõÔºå‰ª•Âø´‰∫é Sonnet ÁöÑÈÄüÂ∫¶Ôºå‰∏î‰ª∑Ê†º‰∏é Sonnet Áõ∏Âêå„ÄÇSonnet Âú®‰ª•‰∏ãÊñπÈù¢Ë°®Áé∞Â∞§‰∏∫Âá∫Ëâ≤Ôºö\n\n- ÁºñÁ®ãÔºöËá™‰∏ªÁºñÂÜô„ÄÅÁºñËæëÂíåËøêË°å‰ª£Á†ÅÔºåÂÖ∑Â§áÊé®ÁêÜÂíåÊïÖÈöúÊéíÈô§ËÉΩÂäõ\n- Êï∞ÊçÆÁßëÂ≠¶ÔºöÂ¢ûÂº∫‰∫∫Á±ªÊï∞ÊçÆÁßëÂ≠¶‰∏ì‰∏öÁü•ËØÜÔºõÂú®‰ΩøÁî®Â§öÁßçÂ∑•ÂÖ∑Ëé∑ÂèñÊ¥ûÂØüÁöÑÂêåÊó∂ÔºåÂ§ÑÁêÜÈùûÁªìÊûÑÂåñÊï∞ÊçÆ\n- ËßÜËßâÂ§ÑÁêÜÔºöÊìÖÈïøËß£ËØªÂõæË°®„ÄÅÂõæÂΩ¢ÂíåÂõæÂÉèÔºåÂáÜÁ°ÆËΩ¨ÂΩïÊñáÊú¨‰ª•Ëé∑ÂæóË∂ÖË∂äÊñáÊú¨Êú¨Ë∫´ÁöÑÊ¥ûÂØü\n- ‰ª£ÁêÜ‰ªªÂä°ÔºöÂá∫Ëâ≤ÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõÔºå‰ΩøÂÖ∂Âú®‰ª£ÁêÜ‰ªªÂä°ÔºàÂç≥ÈúÄË¶Å‰∏éÂÖ∂‰ªñÁ≥ªÁªü‰∫íÂä®ÁöÑÂ§çÊùÇÂ§öÊ≠•È™§ÈóÆÈ¢òËß£ÂÜ≥‰ªªÂä°Ôºâ‰∏≠Ë°®Áé∞Âá∫Ëâ≤\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/command-r-plus","frontmatter":{"title":"Cohere: Command R+ (08-2024)","meta_title":"Cohere: Command R+ (08-2024)","description":"Cohere: Command R+ (08-2024)","date":"2024-08-30T00:00:00.000Z","image":"https://img.rifx.online/logo/cohere.svg","categories":["text 2 text"],"author":"cohere","tags":["Technology","Programming","Machine Learning","Generative AI","Ethics"],"draft":false,"id":"command-r-plus","context":128000,"input":0.000002375,"output":0.0000095,"img":0,"request":0,"last_updated":"2024-11-07T09:33:44.000Z","slug":"models/command-r-plus"},"content":"\ncommand-r-plus-08-2024 ÊòØ [Command R+](/cohere/command-r-plus) ÁöÑÊõ¥Êñ∞Ôºå‰∏é‰πãÂâçÁöÑ Command R+ ÁâàÊú¨Áõ∏ÊØîÔºåÂêûÂêêÈáèÊèêÈ´ò‰∫ÜÂ§ßÁ∫¶ 50%ÔºåÂª∂ËøüÈôç‰Ωé‰∫Ü 25%ÔºåÂêåÊó∂‰øùÊåÅÁõ∏ÂêåÁöÑÁ°¨‰ª∂Âç†Áî®„ÄÇ\n\nÂú® [ËøôÈáå](https://docs.cohere.com/changelog/command-gets-refreshed) ÈòÖËØªÂèëÂ∏ÉÂ∏ñÂ≠ê„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™ Cohere ÁöÑ [ÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://docs.cohere.com/docs/c4ai-acceptable-use-policy)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/command-r","frontmatter":{"title":"Cohere: Command R (08-2024)","meta_title":"Cohere: Command R (08-2024)","description":"Cohere: Command R (08-2024)","date":"2024-08-30T00:00:00.000Z","image":"https://img.rifx.online/logo/cohere.svg","categories":["text 2 text"],"author":"cohere","tags":["Programming","Natural Language Processing","Generative AI","Machine Learning","Data Science"],"draft":false,"id":"command-r","context":128000,"input":1.425e-7,"output":5.7e-7,"img":0,"request":0,"last_updated":"2024-11-07T09:33:55.000Z","slug":"models/command-r"},"content":"\ncommand-r-08-2024 ÊòØ [Command R](/cohere/command-r) ÁöÑÊõ¥Êñ∞ÔºåÊèêÂçá‰∫ÜÂ§öËØ≠Ë®ÄÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) ÂíåÂ∑•ÂÖ∑‰ΩøÁî®ÁöÑÊÄßËÉΩ„ÄÇÊõ¥ÂπøÊ≥õÂú∞ËØ¥ÔºåÂÆÉÂú®Êï∞Â≠¶„ÄÅ‰ª£Á†ÅÂíåÊé®ÁêÜÊñπÈù¢Ë°®Áé∞Êõ¥‰Ω≥ÔºåÂπ∂‰∏î‰∏é‰πãÂâçÁöÑÊõ¥Â§ßÁâàÊú¨ Command R+ Ê®°ÂûãÂÖ∑ÊúâÁ´û‰∫âÂäõ„ÄÇ\n\nÈòÖËØªÂèëÂ∏ÉÂ∏ñÂ≠ê [ËøôÈáå](https://docs.cohere.com/changelog/command-gets-refreshed)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™ Cohere ÁöÑ [ÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://docs.cohere.com/docs/c4ai-acceptable-use-policy)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/deepseek-chat","frontmatter":{"title":"DeepSeek V2.5","meta_title":"DeepSeek V2.5","description":"DeepSeek V2.5","date":"2024-05-14T00:00:00.000Z","image":"https://img.rifx.online/logo/deepseek.svg","categories":["text 2 text"],"author":"deepseek","tags":["Programming","Natural Language Processing","Machine Learning","Data Science","Chatbots"],"draft":false,"id":"deepseek-chat","context":128000,"input":1.4e-7,"output":2.8e-7,"img":0,"request":0,"last_updated":"2024-11-01T04:19:11.000Z","slug":"models/deepseek-chat"},"content":"\nDeepSeek-V2.5 ÊòØ‰∏Ä‰∏™ÂçáÁ∫ßÁâàÊú¨ÔºåÁªìÂêà‰∫Ü DeepSeek-V2-Chat Âíå DeepSeek-Coder-V2-Instruct„ÄÇÊñ∞Ê®°ÂûãÊï¥Âêà‰∫ÜÂâç‰∏§‰∏™ÁâàÊú¨ÁöÑÈÄöÁî®ËÉΩÂäõÂíåÁºñÁ†ÅËÉΩÂäõ„ÄÇ\n\nDeepSeek-V2 Chat ÊòØ DeepSeek-V2 ÁöÑÂØπËØùÂæÆË∞ÉÁâàÊú¨ÔºåÂ±û‰∫éÊ∑∑Âêà‰∏ìÂÆ∂ÔºàMoEÔºâËØ≠Ë®ÄÊ®°Âûã„ÄÇÂÆÉÊÄªÂÖ±ÂåÖÂê´ 236B ‰∏™ÂèÇÊï∞ÔºåÂÖ∂‰∏≠ÊØè‰∏™ token ÊøÄÊ¥ª 21B„ÄÇ\n\n‰∏é DeepSeek 67B Áõ∏ÊØîÔºåDeepSeek-V2 ÁöÑÊÄßËÉΩÊõ¥Âº∫ÔºåÂêåÊó∂ËäÇÁúÅ‰∫Ü 42.5% ÁöÑËÆ≠ÁªÉÊàêÊú¨ÔºåÂáèÂ∞ë‰∫Ü 93.3% ÁöÑ KV ÁºìÂ≠òÔºåÂπ∂Â∞ÜÊúÄÂ§ßÁîüÊàêÂêûÂêêÈáèÊèêÂçáËá≥ 5.76 ÂÄç„ÄÇ\n\nDeepSeek-V2 Âú®Ê†áÂáÜÂü∫ÂáÜÊµãËØïÂíåÂºÄÊîæÂºèÁîüÊàêËØÑ‰º∞‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/dolphin-mixtral-8x22b","frontmatter":{"title":"Dolphin 2.9.2 Mixtral 8x22B üê¨","meta_title":"Dolphin 2.9.2 Mixtral 8x22B üê¨","description":"Dolphin 2.9.2 Mixtral 8x22B üê¨","date":"2024-06-08T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"cognitivecomputations","tags":["Natural Language Processing","Generative AI","Chatbots","Roleplay","Ethics"],"draft":false,"id":"dolphin-mixtral-8x22b","context":65536,"input":9e-7,"output":9e-7,"img":0,"request":0,"last_updated":"2024-11-04T12:49:50.000Z","slug":"models/dolphin-mixtral-8x22b"},"content":"\nDolphin 2.9 Êó®Âú®ËøõË°åÊåá‰ª§Ë∑üÈöè„ÄÅÂØπËØùÂíåÁºñÁ†Å„ÄÇËØ•Ê®°ÂûãÊòØ [Mixtral 8x22B Instruct](/mistralai/mixtral-8x22b-instruct) ÁöÑÂæÆË∞ÉÁâàÊú¨„ÄÇÂÆÉÂÖ∑Êúâ 64k ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåÂπ∂‰ΩøÁî® ChatML Ê®°ÊùøËøõË°å‰∫Ü 16k Â∫èÂàóÈïøÂ∫¶ÁöÑÂæÆË∞É„ÄÇ\n\nËØ•Ê®°ÂûãÊòØ [Dolphin Mixtral 8x7B](/cognitivecomputations/dolphin-mixtral-8x7b) ÁöÑÁªß‰ªªËÄÖ„ÄÇ\n\nËØ•Ê®°ÂûãÊú™ÁªèËøáÂÆ°Êü•ÔºåÂπ∂ÂéªÈô§‰∫ÜÂØπÈΩêÂíåÂÅèËßÅ„ÄÇÂÆÉÈúÄË¶ÅÂ§ñÈÉ®ÂØπÈΩêÂ±Ç‰ª•Á°Æ‰øù‰º¶ÁêÜ‰ΩøÁî®„ÄÇÁî®Êà∑Ë¢´Ë≠¶ÂëäË¶ÅË¥üË¥£‰ªªÂú∞‰ΩøÁî®Ëøô‰∏™È´òÂ∫¶ÂêàËßÑÁöÑÊ®°ÂûãÔºåËØ¶ÁªÜ‰ø°ÊÅØËØ∑ÂèÇËßÅÂÖ≥‰∫éÊú™ÂÆ°Êü•Ê®°ÂûãÁöÑÂçöÂÆ¢ÊñáÁ´† [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models)„ÄÇ\n\n#moe #uncensored\n\n"},{"lang":"zh","group":"models","slug":"models/dolphin-mixtral-8x7b","frontmatter":{"title":"Dolphin 2.6 Mixtral 8x7B üê¨","meta_title":"Dolphin 2.6 Mixtral 8x7B üê¨","description":"Dolphin 2.6 Mixtral 8x7B üê¨","date":"2023-12-21T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"cognitivecomputations","tags":["Programming","Natural Language Processing","Generative AI","Ethics","Chatbots"],"draft":false,"id":"dolphin-mixtral-8x7b","context":32768,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-04T12:52:28.000Z","slug":"models/dolphin-mixtral-8x7b"},"content":"\nËøôÊòØÂØπ [Mixtral-8x7b](/mistralai/mixtral-8x7b) ÁöÑ 16k ‰∏ä‰∏ãÊñáÂæÆË∞É„ÄÇÁî±‰∫éÂ§ßÈáè‰ΩøÁî®ÁºñÁ†ÅÊï∞ÊçÆËøõË°åËÆ≠ÁªÉÔºåÂÆÉÂú®ÁºñÁ†Å‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂπ∂‰ª•ÂÖ∂Êúç‰ªéÊÄßËÄåÈóªÂêçÔºåÂ∞ΩÁÆ°Áº∫‰πè DPO Ë∞É‰ºò„ÄÇ\n\nËØ•Ê®°ÂûãÊú™ÁªèËøáÂÆ°Êü•ÔºåÂπ∂‰∏îÂéªÈô§‰∫ÜÂØπÈΩêÂíåÂÅèËßÅ„ÄÇÂÆÉÈúÄË¶Å‰∏Ä‰∏™Â§ñÈÉ®ÂØπÈΩêÂ±Ç‰ª•Á°Æ‰øù‰º¶ÁêÜ‰ΩøÁî®„ÄÇÁî®Êà∑Ë¢´ÊèêÈÜíË¶ÅË¥üË¥£‰ªªÂú∞‰ΩøÁî®Ëøô‰∏™È´òÂ∫¶ÂêàËßÑÁöÑÊ®°ÂûãÔºåÂÖ∑‰ΩìÁªÜËäÇÂèØÂèÇËßÅÂÖ≥‰∫éÊú™ÂÆ°Êü•Ê®°ÂûãÁöÑÂçöÂÆ¢ÊñáÁ´† [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models)„ÄÇ\n\n#moe #uncensored\n\n"},{"lang":"zh","group":"models","slug":"models/eva-qwen-25-14b","frontmatter":{"title":"EVA Qwen2.5 14B","meta_title":"EVA Qwen2.5 14B","description":"EVA Qwen2.5 14B","date":"2024-09-30T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"eva-unit-01","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"is_recommended":false,"id":"eva-qwen-2.5-14b","context":32768,"input":2.5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:18:57.000Z","slug":"models/eva-qwen-25-14b"},"content":"\n‰∏Ä‰∏™‰∏ìÊ≥®‰∫éËßíËâ≤ÊâÆÊºîÂíåÂàõÊÑèÂÜô‰ΩúÁöÑÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂü∫‰∫é Qwen2.5-14BÔºåÁªèËøáÂêàÊàêÊï∞ÊçÆÂíåËá™ÁÑ∂Êï∞ÊçÆÁöÑÊ∑∑ÂêàÂæÆË∞É„ÄÇ\n\nÂÆÉÂú® 1.5M ‰ª§ÁâåÁöÑËßíËâ≤ÊâÆÊºîÊï∞ÊçÆ‰∏äËøõË°åËÆ≠ÁªÉÔºåÂπ∂Âú® 1.5M ‰ª§ÁâåÁöÑÂêàÊàêÊï∞ÊçÆ‰∏äËøõË°åÂæÆË∞É„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/eva-qwen-25-32b","frontmatter":{"title":"Eva Qwen2.5 32B","meta_title":"Eva Qwen2.5 32B","description":"Eva Qwen2.5 32B","date":"2024-11-08T22:27:27.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"eva-unit-01","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"is_recommended":true,"id":"eva-qwen-2.5-32b","context":32000,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:18:50.000Z","slug":"models/eva-qwen-25-32b"},"content":"\n‰∏Ä‰∏™ËßíËâ≤ÊâÆÊºî/ÊïÖ‰∫ãÂàõ‰Ωú‰∏ìÁî®Ê®°ÂûãÔºåÈíàÂØπÂêàÊàêÊï∞ÊçÆÂíåËá™ÁÑ∂Êï∞ÊçÆÁöÑÊ∑∑ÂêàËøõË°åÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÁöÑQwen2.5-32B„ÄÇ\n\nÂÆÉ‰ΩøÁî®Celeste 70B 0.1Êï∞ÊçÆÊ∑∑ÂêàÔºåÊûÅÂ§ßÂú∞Êâ©Â±ï‰∫ÜÊï∞ÊçÆÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂ§öÊ†∑ÊÄß„ÄÅÂàõÈÄ†ÂäõÂíå‚ÄúÈ£éÂë≥‚Äù„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/gemini-flash-15-8b-exp","frontmatter":{"title":"Google: Gemini Flash 8B 1.5 Experimental","meta_title":"Google: Gemini Flash 8B 1.5 Experimental","description":"Google: Gemini Flash 8B 1.5 Experimental","date":"2024-08-28T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Technology","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"gemini-flash-1.5-8b-exp","context":1000000,"input":0,"output":0,"img":0,"request":0,"last_updated":"2024-11-11T03:14:22.000Z","slug":"models/gemini-flash-15-8b-exp"},"content":"\nGemini 1.5 Flash 8B Experimental ÊòØ [Gemini 1.5 Flash](/google/gemini-flash-1.5) Ê®°ÂûãÁöÑÂÆûÈ™åÊÄß 8B ÂèÇÊï∞ÁâàÊú¨„ÄÇ\n\n‰ΩøÁî® Gemini ÈúÄÈÅµÂæ™ Google ÁöÑ [Gemini ‰ΩøÁî®Êù°Ê¨æ](https://ai.google.dev/terms)„ÄÇ\n\n#multimodal\n\nÊ≥®ÊÑèÔºöËØ•Ê®°ÂûãÁõÆÂâçÂ§Ñ‰∫éÂÆûÈ™åÈò∂ÊÆµÔºå‰∏çÈÄÇÂêàÁîü‰∫ß‰ΩøÁî®Ê°à‰æãÔºåÂèØËÉΩ‰ºöÂèóÂà∞‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/gemini-flash-15-8b","frontmatter":{"title":"Google: Gemini 1.5 Flash-8B","meta_title":"Google: Gemini 1.5 Flash-8B","description":"Google: Gemini 1.5 Flash-8B","date":"2024-10-03T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Natural Language Processing","Chatbots","Translation","Technology/Web"],"draft":false,"id":"gemini-flash-1.5-8b","context":1000000,"input":3.75e-8,"output":1.5e-7,"img":0,"request":0,"last_updated":"2024-10-03T00:00:00.000Z","slug":"models/gemini-flash-15-8b"},"content":"\nGemini 1.5 Flash-8B ÈíàÂØπÈÄüÂ∫¶ÂíåÊïàÁéáËøõË°å‰∫Ü‰ºòÂåñÔºåÂú®ËÅäÂ§©„ÄÅËΩ¨ÂΩïÂíåÁøªËØëÁ≠âÂ∞èÊèêÁ§∫‰ªªÂä°‰∏≠Êèê‰æõ‰∫ÜÂ¢ûÂº∫ÁöÑÊÄßËÉΩ„ÄÇÈÄöËøáÂáèÂ∞ëÂª∂ËøüÔºåÂÆÉÂú®ÂÆûÊó∂ÂíåÂ§ßËßÑÊ®°Êìç‰Ωú‰∏≠ÈùûÂ∏∏ÊúâÊïà„ÄÇËØ•Ê®°Âûã‰∏ìÊ≥®‰∫éÊàêÊú¨ÊïàÁõäËß£ÂÜ≥ÊñπÊ°àÔºåÂêåÊó∂‰øùÊåÅÈ´òË¥®ÈáèÁöÑÁªìÊûú„ÄÇ\n\n[ÁÇπÂáªÊ≠§Â§Ñ‰∫ÜËß£Êõ¥Â§öÂÖ≥‰∫éÊ≠§Ê®°ÂûãÁöÑ‰ø°ÊÅØ](https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/)„ÄÇ\n\n‰ΩøÁî® Gemini ÂèóÈôê‰∫é Google's [Gemini ‰ΩøÁî®Êù°Ê¨æ](https://ai.google.dev/terms)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/gemini-flash-15","frontmatter":{"title":"Google: Gemini Flash 1.5","meta_title":"Google: Gemini Flash 1.5","description":"Google: Gemini Flash 1.5","date":"2024-05-14T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Machine Learning","Natural Language Processing","Computer Vision","Chatbots"],"draft":false,"is_recommended":true,"id":"gemini-flash-1.5","context":1000000,"input":7.5e-8,"output":3e-7,"img":0.00004,"request":0,"last_updated":"2024-11-14T08:23:12.000Z","slug":"models/gemini-flash-15"},"content":"\nGemini 1.5 Flash ÊòØ‰∏Ä‰∏™Âü∫Á°ÄÊ®°ÂûãÔºåÂú®ËßÜËßâÁêÜËß£„ÄÅÂàÜÁ±ª„ÄÅÊëòË¶Å‰ª•Âèä‰ªéÂõæÂÉè„ÄÅÈü≥È¢ëÂíåËßÜÈ¢ëÂàõÂª∫ÂÜÖÂÆπÁ≠âÂ§öÁßçÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂÆÉÊìÖÈïøÂ§ÑÁêÜËßÜËßâÂíåÊñáÊú¨ËæìÂÖ•Ôºå‰æãÂ¶ÇÁÖßÁâá„ÄÅÊñáÊ°£„ÄÅ‰ø°ÊÅØÂõæÂíåÊà™Âõæ„ÄÇ\n\nGemini 1.5 Flash Êó®Âú®Â§ÑÁêÜÈ´òÂÆπÈáè„ÄÅÈ´òÈ¢ëÁéáÁöÑ‰ªªÂä°ÔºåÂÖ∂‰∏≠ÊàêÊú¨ÂíåÂª∂ËøüËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®Â§ßÂ§öÊï∞Â∏∏ËßÅ‰ªªÂä°‰∏≠ÔºåFlash ÁöÑË¥®Èáè‰∏éÂÖ∂‰ªñ Gemini Pro Ê®°ÂûãÁõ∏ÂΩìÔºå‰ΩÜÊàêÊú¨ÊòæËëóÈôç‰Ωé„ÄÇFlash ÈùûÂ∏∏ÈÄÇÂêàÁî®‰∫éËÅäÂ§©Âä©ÊâãÂíåÊåâÈúÄÂÜÖÂÆπÁîüÊàêÁ≠âÂØπÈÄüÂ∫¶ÂíåËßÑÊ®°ÊúâË¶ÅÊ±ÇÁöÑÂ∫îÁî®„ÄÇ\n\n‰ΩøÁî® Gemini ÂèóÂà∂‰∫é Google ÁöÑ [Gemini ‰ΩøÁî®Êù°Ê¨æ](https://ai.google.dev/terms)„ÄÇ\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/gemini-pro-15","frontmatter":{"title":"Google: Gemini Pro 1.5","meta_title":"Google: Gemini Pro 1.5","description":"Google: Gemini Pro 1.5","date":"2024-04-09T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Chatbots"],"draft":false,"id":"gemini-pro-1.5","context":2000000,"input":0.00000125,"output":0.000005,"img":0.00263,"request":0,"last_updated":"2024-04-09T00:00:00.000Z","slug":"models/gemini-pro-15"},"content":"\nË∞∑Ê≠åÊúÄÊñ∞ÁöÑÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊîØÊåÅÂú®ÊñáÊú¨ÊàñËÅäÂ§©ÊèêÁ§∫‰∏≠‰ΩøÁî®ÂõæÂÉèÂíåËßÜÈ¢ë„ÄÇ\n\nÈíàÂØπ‰ª•‰∏ãËØ≠Ë®Ä‰ªªÂä°ËøõË°å‰∫Ü‰ºòÂåñÔºö\n\n- ‰ª£Á†ÅÁîüÊàê\n- ÊñáÊú¨ÁîüÊàê\n- ÊñáÊú¨ÁºñËæë\n- ÈóÆÈ¢òËß£ÂÜ≥\n- Êé®Ëçê\n- ‰ø°ÊÅØÊèêÂèñ\n- Êï∞ÊçÆÊèêÂèñÊàñÁîüÊàê\n- AI‰ª£ÁêÜ\n\nGeminiÁöÑ‰ΩøÁî®ÂèóÈôê‰∫éË∞∑Ê≠åÁöÑ[Gemini‰ΩøÁî®Êù°Ê¨æ](https://ai.google.dev/terms)„ÄÇ\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/gemini-pro-vision","frontmatter":{"title":"Google: Gemini Pro Vision 1.0","meta_title":"Google: Gemini Pro Vision 1.0","description":"Google: Gemini Pro Vision 1.0","date":"2023-12-13T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text image 2 text"],"author":"google","tags":["Programming","Machine Learning","Natural Language Processing","Computer Vision","Generative AI"],"draft":false,"id":"gemini-pro-vision","context":16384,"input":5e-7,"output":0.0000015,"img":0.0025,"request":0,"last_updated":"2024-11-11T03:15:08.000Z","slug":"models/gemini-pro-vision"},"content":"\nË∞∑Ê≠åÁöÑÊóóËà∞Â§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊîØÊåÅÂú®ÊñáÊú¨ÊàñËÅäÂ§©ÊèêÁ§∫‰∏≠‰ΩøÁî®ÂõæÂÉèÂíåËßÜÈ¢ëÔºå‰ª•Ëé∑ÂæóÊñáÊú¨Êàñ‰ª£Á†ÅÂìçÂ∫î„ÄÇ\n\nËØ∑ÂèÇÈòÖÊù•Ëá™ [Deepmind](https://deepmind.google/technologies/gemini/) ÁöÑÂü∫ÂáÜÂíåÊèêÁ§∫ÊåáÂçó„ÄÇ\n\n‰ΩøÁî® Gemini ÈúÄÈÅµÂæ™Ë∞∑Ê≠åÁöÑ [Gemini ‰ΩøÁî®Êù°Ê¨æ](https://ai.google.dev/terms)„ÄÇ\n\n#multimodal\n\n"},{"lang":"zh","group":"models","slug":"models/gemma-2-27b-it","frontmatter":{"title":"Google: Gemma 2 27B","meta_title":"Google: Gemma 2 27B","description":"Google: Gemma 2 27B","date":"2024-07-13T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"gemma-2-27b-it","context":8192,"input":2.7e-7,"output":2.7e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:14:49.000Z","slug":"models/gemma-2-27b-it"},"content":"\nGemma 2 27B Áî± Google ÂºÄÂèëÔºåÊòØ‰∏Ä‰∏™ÂºÄÊîæÊ®°ÂûãÔºåÂü∫‰∫éÂàõÂª∫ [Gemini Ê®°Âûã](/models?q=gemini) ÊâÄ‰ΩøÁî®ÁöÑÁõ∏ÂêåÁ†îÁ©∂ÂíåÊäÄÊúØ„ÄÇ\n\nGemma Ê®°ÂûãÈùûÂ∏∏ÈÄÇÂêàÂ§öÁßçÊñáÊú¨ÁîüÊàê‰ªªÂä°ÔºåÂåÖÊã¨ÈóÆÁ≠î„ÄÅÊëòË¶ÅÂíåÊé®ÁêÜ„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ [ÂèëÂ∏ÉÂÖ¨Âëä](https://blog.google/technology/developers/google-gemma-2/)„ÄÇ‰ΩøÁî® Gemma ÈúÄÈÅµÂæ™ Google ÁöÑ [Gemma ‰ΩøÁî®Êù°Ê¨æ](https://ai.google.dev/gemma/terms)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/gemma-2-9b-it","frontmatter":{"title":"Google: Gemma 2 9B","meta_title":"Google: Gemma 2 9B","description":"Google: Gemma 2 9B","date":"2024-06-28T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Programming","Natural Language Processing","Machine Learning","Data Science","Open Source"],"draft":false,"id":"gemma-2-9b-it","context":8192,"input":6e-8,"output":6e-8,"img":0,"request":0,"last_updated":"2024-11-11T03:14:49.000Z","slug":"models/gemma-2-9b-it"},"content":"\nGemma 2 9B by Google ÊòØ‰∏Ä‰∏™ÂÖàËøõÁöÑÂºÄÊ∫êËØ≠Ë®ÄÊ®°ÂûãÔºåÂú®ÂÖ∂Â∞∫ÂØ∏Á±ªÂà´‰∏≠ËÆæÂÆö‰∫ÜÊïàÁéáÂíåÊÄßËÉΩÁöÑÊñ∞Ê†áÂáÜ„ÄÇ\n\nÂÆÉÊó®Âú®ÊîØÊåÅÂêÑÁßç‰ªªÂä°Ôºå‰ΩøÂºÄÂèëËÄÖÂíåÁ†îÁ©∂‰∫∫ÂëòËÉΩÂ§üÊûÑÂª∫ÂàõÊñ∞Â∫îÁî®ÔºåÂêåÊó∂‰øùÊåÅÂèØËÆøÈóÆÊÄß„ÄÅÂÆâÂÖ®ÊÄßÂíåÁªèÊµéÊÄß„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅ [launch announcement](https://blog.google/technology/developers/google-gemma-2/)„ÄÇ‰ΩøÁî® Gemma ÈúÄÈÅµÂæ™ Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4-air","frontmatter":{"title":"GLM-4 Air","meta_title":"GLM-4 Air","description":"GLM-4 Air","date":"2024-11-14T10:21:13.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-air","tags":["Programming","Technology","Machine Learning","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"glm-4-air","context":128000,"input":1.4e-7,"output":1.4e-7,"img":0,"request":0,"last_updated":"2024-11-14T12:36:34.000Z","slug":"models/glm-4-air"},"content":"\n\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4-airx","frontmatter":{"title":"GLM-4 AirX","meta_title":"GLM-4 AirX","description":"GLM-4 AirX","date":"2024-11-15T13:12:54.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-airx","tags":["Technology","Machine Learning","Generative AI","Data Science","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4-airx","context":8000,"input":0.0000014,"output":0.0000014,"img":0,"request":0,"last_updated":"2024-11-15T23:49:16.000Z","slug":"models/glm-4-airx"},"content":"\n## Âü∫Êú¨‰ø°ÊÅØ\n\n‚ÄúGLM-4-AIRX‚ÄùÊòØÁî±‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑ‰∏ìÂÆ∂ÂºÄÂèëÁöÑÂÖàËøõÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã„ÄÇÂÆÉÂõ†ÂÖ∂Âº∫Â§ßÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËÉΩÂäõËÄåÈóªÂêçÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊúâÊïàÁêÜËß£ÂíåÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÊñáÊú¨„ÄÇËØ•Ê®°ÂûãÂà©Áî®Ê∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÔºåÁâπÂà´ÊòØÂπøÊ≥õÁî®‰∫éNLPÔºàËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºâÈ¢ÜÂüüÁöÑTransformerÊû∂ÊûÑ„ÄÇ\n\n## ÊäÄÊúØÁâπÁÇπ\n\n### 1. Âü∫‰∫éTransformerÊû∂ÊûÑ\n\nËØ•Ê®°ÂûãÁöÑÊ†∏ÂøÉÂü∫‰∫éTransformerÊû∂ÊûÑÔºåËøôÊòØ‰∏ÄÁßçÈááÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÁªìÊûÑ„ÄÇÈÄöËøáËøô‰∏ÄÊú∫Âà∂Ôºå‚ÄúGLM-4-AIRX‚ÄùËÉΩÂ§üÊçïÊçâËæìÂÖ•Â∫èÂàó‰∏≠‰ªªÊÑè‰∏§‰∏™‰ΩçÁΩÆ‰πãÈó¥ÁöÑÂ§çÊùÇ‰æùËµñÂÖ≥Á≥ªÔºåÊó†ËÆ∫ÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÂ¶Ç‰ΩïÔºå‰ªéËÄåÊèêÈ´òÂ§ÑÁêÜËØ≠Ë®Ä‰ªªÂä°Êó∂ÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ\n\n### 2. È¢ÑËÆ≠ÁªÉ‰∏éÂæÆË∞É\n\nÊ®°ÂûãÂºÄÂèëÂåÖÊã¨È¢ÑËÆ≠ÁªÉÂíåÂæÆË∞É‰∏§‰∏™Èò∂ÊÆµ„ÄÇÂú®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºåÂÆÉÂú®ÂπøÊ≥õÂ§öÊ†∑ÁöÑÊñáÊú¨Êï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉÔºå‰ª•ÊéåÊè°Âü∫Êú¨ÁöÑËØ≠Ë®ÄÊ®°Âºè„ÄÇÂú®ÂæÆË∞ÉÈò∂ÊÆµÔºåÊ†πÊçÆÁâπÂÆö‰ªªÂä°Ë∞ÉÊï¥ÂèÇÊï∞Ôºå‰ª•ÊèêÈ´òÂú®ÁâπÂÆöÂ∫îÁî®‰∏äÁöÑÊÄßËÉΩ„ÄÇ\n\n### 3. Â§öËØ≠Ë®ÄÊîØÊåÅ\n\n‚ÄúGLM-4-AIRX‚ÄùÂÖ∑Â§áÂ§öËØ≠Ë®ÄËÉΩÂäõÔºåÈÄöËøáÂú®ÂåÖÂê´Â§öÁßçËØ≠Ë®ÄÁöÑËØ≠ÊñôÂ∫ì‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÂÆûÁé∞„ÄÇËøô‰ΩøÂÖ∂ËÉΩÂ§üÁêÜËß£ÂíåÁîüÊàêÂ§öÁßçËØ≠Ë®ÄÁöÑÊñáÊú¨ÔºåÊª°Ë∂≥ÂÖ®ÁêÉÁî®Êà∑ÈúÄÊ±ÇÔºåÂπ∂‰øÉËøõË∑®ÊñáÂåñ‰∫§ÊµÅ„ÄÇ\n\n### 4. ÂèØÊâ©Â±ïÊÄß\n\nËØ•Ê®°ÂûãÂú®ËÆæËÆ°Êó∂ËÄÉËôë‰∫ÜÂèØÊâ©Â±ïÊÄßÔºåËÉΩÂ§üÁÅµÊ¥ªË∞ÉÊï¥‰ª•Â§ÑÁêÜÊõ¥Â§ßÊï∞ÊçÆÈõÜÊàñÊõ¥Â§çÊùÇÁöÑ‰ªªÂä°ÈúÄÊ±Ç„ÄÇÊ≠§ÁâπÊÄß‰ΩøÂÖ∂ËÉΩÂ§üÂπøÊ≥õÂ∫îÁî®‰∫é‰∏çÊñ≠ÂèòÂåñÂíåÊâ©Â±ïÁöÑÊï∞ÊçÆÁéØÂ¢É‰∏≠„ÄÇ\n\n## Â∫îÁî®Âú∫ÊôØ\n\n‚ÄúGLM-4-AIRX‚ÄùÂú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºö\n\n- **ÊñáÊú¨ÁîüÊàê**ÔºöËá™Âä®ÂàõÂª∫ÊñáÁ´†„ÄÅÊïÖ‰∫ãÊàñËØóÊ≠å„ÄÇ\n- **ÊñáÊú¨ÂàÜÁ±ª**Ôºö‰æãÂ¶ÇÊÉÖÊÑüÂàÜÊûêÊàñ‰∏ªÈ¢òÂàÜÁ±ª„ÄÇ\n- **Êú∫Âô®ÁøªËØë**ÔºöÊèê‰æõÈ´òÊïàÂáÜÁ°ÆÁöÑË∑®ËØ≠Ë®ÄÁøªËØë„ÄÇ\n- **ÈóÆÁ≠îÁ≥ªÁªü**ÔºöÁî®‰∫éÊûÑÂª∫Êô∫ËÉΩÂπ≥Âè∞ÔºåÁõ¥Êé•ÂìçÂ∫îÁî®Êà∑Êü•ËØ¢„ÄÇ\n- **ÊñáÊú¨ÊëòË¶Å**ÔºöËá™Âä®‰ªéÊñáÊ°£‰∏≠ÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØÂπ∂ÁîüÊàêÁÆÄÊòéÊëòË¶Å„ÄÇ\n\n## ‰∏éÁ±ª‰ººÊ®°ÂûãÁöÑÊØîËæÉ\n\n‰∏éÂÖ∂‰ªñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁõ∏ÊØîÔºå‚ÄúGLM-4-AIRX‚ÄùÊèê‰æõ‰∫ÜÂá†‰∏™‰ºòÂäøÔºö\n\n- **ÂçìË∂äÁöÑÊÄßËÉΩ**ÔºöÂú®ÊñáÊú¨ÁîüÊàêÂíåÁêÜËß£Á≠âÂ§ö‰∏™NLP‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n- **È´òÂ§ÑÁêÜÊïàÁéá**Ôºö‰ºòÂåñÁöÑÊû∂ÊûÑËÆæËÆ°‰ΩøËµÑÊ∫ê‰ΩøÁî®ÂíåÈÄüÂ∫¶Êõ¥‰∏∫È´òÊïà„ÄÇ\n- **Âº∫Â§ßÁöÑÁÅµÊ¥ªÊÄß**ÔºöÊîØÊåÅÂ§öÁßçËØ≠Ë®ÄÔºåÂπ∂ËÉΩÂ§üÈÄöËøáÊâ©Â±ïÂäüËÉΩÈÄÇÂ∫î‰∏çÂêåÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇ\n- **‰ªªÂä°ÈÄÇÂ∫îÊÄß**ÔºöÈÄöËøáÂæÆË∞ÉÂÆûÁé∞ÁâπÂÆö‰ªªÂä°ÈúÄÊ±ÇÁöÑ‰ºòÂåñÔºåÂ¢ûÂº∫ÂÆûÈôÖ‰ª∑ÂÄº„ÄÇ\n\nÊÄª‰πãÔºå‚ÄúGLM-4-AIRX‚ÄùÊòØ‰∏Ä‰∏™ÂÖ®Èù¢‰∏îÁÅµÊ¥ªÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂÖ∑ÊúâÂú®ÂΩì‰ªäÂø´ÈÄüÂèëÂ±ïÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÈ¢ÜÂüü‰∏≠ÊåÅÁª≠Â¢ûÈïøÂíåÂàõÊñ∞ÁöÑÊΩúÂäõ„ÄÇ\n\nÊ≠§ÂìçÂ∫î‰ΩøÁî®‰∫ÜÂÖ≥‰∫éGLMÊ®°ÂûãÁöÑÂÆûÊó∂Êï∞ÊçÆÔºåÊîØÊåÅÁ≥ªÁªüÊèêÁ§∫„ÄÅÂáΩÊï∞Ë∞ÉÁî®„ÄÅÊ£ÄÁ¥¢„ÄÅÁΩëÁªúÊêúÁ¥¢Á≠âÊñ∞ÂäüËÉΩÔºå‰ª•ÂèäÂÖ≥‰∫éNLPËøõÂ±ï‰∏≠Â∏∏ËßÅÁöÑÂü∫‰∫éTransformerÁöÑÊû∂ÊûÑÁöÑ‰∏ÄËà¨Áü•ËØÜ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4-flash","frontmatter":{"title":"glm-4-flash","meta_title":"glm-4-flash","description":"glm-4-flash","date":"2024-11-15T12:53:10.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-flash","tags":["Generative AI","Machine Learning","Natural Language Processing","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4-flash","context":128000,"input":1e-8,"output":1e-8,"img":0,"request":0,"last_updated":"2024-11-15T23:22:37.000Z","slug":"models/glm-4-flash"},"content":"\n# Êô∫Ë∞±Âø´ÈÄüÁâà\n\n## ÂäüËÉΩÁâπÊÄß\n\n- Âø´ÈÄüÁîüÊàêÊä•Âëä\n- ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÊ†ºÂºè\n- Áõ¥ËßÇÁöÑÁî®Êà∑ÁïåÈù¢\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n1. ÂÆâË£Ö‰æùËµñ\n   ```bash\n   npm install\n   ```\n2. ÂêØÂä®Â∫îÁî®\n   ```bash\n   npm start\n   ```\n\n## Ê≥®ÊÑè‰∫ãÈ°π\n\n- ËØ∑Á°Æ‰øùÊÇ®‰ΩøÁî®ÁöÑÊòØÊúÄÊñ∞ÁâàÊú¨ÁöÑ Node.js\n- Êï∞ÊçÆÊ∫êÂøÖÈ°ªÁ¨¶ÂêàÊåáÂÆöÊ†ºÂºè\n\n## Á§∫‰æã‰ª£Á†Å\n\n```python\ndef hello_world():\n    print(\"Hello, World!\")\n```\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4-long","frontmatter":{"title":"glm-4-long","meta_title":"glm-4-long","description":"glm-4-long","date":"2024-11-15T12:53:01.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-long","tags":["Technology","Machine Learning","Natural Language Processing","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"glm-4-long","context":1000000,"input":1.4e-7,"output":1.4e-7,"img":0,"request":0,"last_updated":"2024-11-15T23:22:49.000Z","slug":"models/glm-4-long"},"content":"\n# Êô∫Ë∞±Áôæ‰∏á‰∏ä‰∏ãÊñá\n\n## ÁÆÄ‰ªã\n\nÊô∫Ë∞±Áôæ‰∏á‰∏ä‰∏ãÊñáÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑÂ∑•ÂÖ∑ÔºåÊó®Âú®Â∏ÆÂä©Áî®Êà∑Âú®Êµ∑ÈáèÊï∞ÊçÆ‰∏≠ÊèêÂèñÊúâ‰ª∑ÂÄºÁöÑ‰ø°ÊÅØ„ÄÇ\n\n## ÁâπÊÄß\n\n- È´òÊïàÁöÑÊï∞ÊçÆÂ§ÑÁêÜËÉΩÂäõ\n- ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÊ†ºÂºè\n- Áõ¥ËßÇÁöÑÁî®Êà∑ÁïåÈù¢\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n```python\nimport zhipu\n\n# ÂàùÂßãÂåñÊô∫Ë∞±Áôæ‰∏á‰∏ä‰∏ãÊñá\ncontext = zhipu.Context()\n\n# Ê∑ªÂä†Êï∞ÊçÆ\ncontext.add_data(\"‰Ω†ÁöÑÊï∞ÊçÆ\")\n\n# Ëé∑ÂèñÁªìÊûú\nresult = context.get_results()\n```\n\n## ÁªìËÆ∫\n\nÊô∫Ë∞±Áôæ‰∏á‰∏ä‰∏ãÊñá‰∏∫Áî®Êà∑Êèê‰æõ‰∫Ü‰∏Ä‰∏™È´òÊïà„ÄÅ‰æøÊç∑ÁöÑÊï∞ÊçÆÂàÜÊûêËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4-plus","frontmatter":{"title":"glm-4-plus","meta_title":"glm-4-plus","description":"glm-4-plus","date":"2024-11-15T12:53:05.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4-plus","tags":["Generative AI","Machine Learning","Natural Language Processing","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4-plus","context":128000,"input":0.000007,"output":0.000007,"img":0,"request":0,"last_updated":"2024-11-15T23:22:43.000Z","slug":"models/glm-4-plus"},"content":"\n# Êô∫Ë∞±ÊóóËà∞Áâà\n\n## ÂäüËÉΩÁâπÁÇπ\n\n- È´òÁ∫ßÊï∞ÊçÆÂàÜÊûê\n- ÂÆûÊó∂ÁõëÊéß\n- Ëá™ÂÆö‰πâÊä•ÂëäÁîüÊàê\n\n## ÂÆâË£ÖÊåáÂçó\n\nËØ∑ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§ÂÆâË£ÖÊô∫Ë∞±ÊóóËà∞ÁâàÔºö\n\n1. ‰∏ãËΩΩÂÆâË£ÖÂåÖ\n2. ÂèåÂáªËøêË°åÂÆâË£ÖÁ®ãÂ∫è\n3. ÊåâÁÖßÊèêÁ§∫ÂÆåÊàêÂÆâË£Ö\n\n```bash\n# ËøôÊòØ‰∏Ä‰∏™Á§∫‰æã‰ª£Á†ÅÂùó\necho \"Hello, World!\"\n```\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4","frontmatter":{"title":"GLM-4","meta_title":"GLM-4","description":"GLM-4","date":"2024-11-15T13:12:41.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4","tags":["Generative AI","Machine Learning","Natural Language Processing","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"glm-4","context":128000,"input":0.000014,"output":0.000014,"img":0,"request":0,"last_updated":"2024-11-15T23:23:43.000Z","slug":"models/glm-4"},"content":"\n# Êô∫Ë∞±ÊúÄÂº∫Áâà\n\n## ÁâπÊÄß\n\n- È´òÊïàËÉΩ\n- ÂÖºÂÆπÊÄßÂº∫\n- ÈÄÇÂ∫îÊÄßÂπø\n\n## ÂÆâË£Ö\n\n```bash\npip install zhipu\n```\n\n## ‰ΩøÁî®Á§∫‰æã\n\n```python\nimport zhupu\n\n# ÂàùÂßãÂåñ\nzhupu.init()\n\n# Ëé∑ÂèñÊï∞ÊçÆ\ndata = zhupu.get_data()\n```\n\n"},{"lang":"zh","group":"models","slug":"models/glm-4v-plus","frontmatter":{"title":"glm-4v-plus","meta_title":"glm-4v-plus","description":"glm-4v-plus","date":"2024-11-15T12:53:06.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"glm-4v-plus","tags":["Computer Vision","Technology","Machine Learning","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"glm-4v-plus","context":32000,"input":0.0000014,"output":0.0000014,"img":0,"request":0,"last_updated":"2024-11-15T23:22:53.000Z","slug":"models/glm-4v-plus"},"content":"\n# Êô∫Ë∞±ÊúÄÊñ∞ÂõæÂÉèËØÜÂà´\n\n## ÁâπÊÄß\n\n- È´òÁ≤æÂ∫¶\n- Âø´ÈÄüÂ§ÑÁêÜ\n- Â§öÁßçÂ∫îÁî®Âú∫ÊôØ\n\n## ‰ΩøÁî®Á§∫‰æã\n\n```python\nimport image_recognition\n\nresult = image_recognition.detect_objects(\"image.jpg\")\nprint(result)\n```\n\n"},{"lang":"zh","group":"models","slug":"models/gpt-35-turbo-instruct","frontmatter":{"title":"OpenAI: GPT-3.5 Turbo Instruct","meta_title":"OpenAI: GPT-3.5 Turbo Instruct","description":"OpenAI: GPT-3.5 Turbo Instruct","date":"2023-09-28T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"openai","tags":["Programming","Natural Language Processing","Generative AI","Chatbots","Technology/Web"],"draft":false,"id":"gpt-3.5-turbo-instruct","context":4095,"input":0.0000015,"output":0.000002,"img":0,"request":0,"last_updated":"2023-09-28T00:00:00.000Z","slug":"models/gpt-35-turbo-instruct"},"content":"\nËØ•Ê®°ÂûãÊòØGPT-3.5 TurboÁöÑ‰∏Ä‰∏™Âèò‰ΩìÔºåÈíàÂØπÊïôÂ≠¶ÊèêÁ§∫ËøõË°å‰∫ÜË∞ÉÊï¥ÔºåÂπ∂ÁúÅÁï•‰∫Ü‰∏éËÅäÂ§©Áõ∏ÂÖ≥ÁöÑ‰ºòÂåñ„ÄÇËÆ≠ÁªÉÊï∞ÊçÆÔºöÊà™Ëá≥2021Âπ¥9Êúà„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/gpt-4o-mini","frontmatter":{"title":"OpenAI: GPT-4o-mini","meta_title":"OpenAI: GPT-4o-mini","description":"OpenAI: GPT-4o-mini","date":"2024-07-18T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text image 2 text"],"author":"openai","tags":["Programming","Technology","Programming/Scripting","Technology/Web"],"draft":false,"is_recommended":true,"id":"gpt-4o-mini","context":128000,"input":1.5e-7,"output":6e-7,"img":0.007225,"request":0,"last_updated":"2024-11-14T05:09:26.000Z","slug":"models/gpt-4o-mini"},"content":"\nGPT-4o mini ÊòØ OpenAI Âú® [GPT-4 Omni](/openai/gpt-4o) ‰πãÂêéÊé®Âá∫ÁöÑÊúÄÊñ∞Ê®°ÂûãÔºåÊîØÊåÅÊñáÊú¨ÂíåÂõæÂÉèËæìÂÖ•ÔºåÂπ∂ÁîüÊàêÊñáÊú¨ËæìÂá∫„ÄÇ\n\n‰Ωú‰∏∫‰ªñ‰ª¨ÊúÄÂÖàËøõÁöÑÂ∞èÂûãÊ®°ÂûãÔºåÂÆÉÁöÑ‰ª∑Ê†ºÊØîÂÖ∂‰ªñÊúÄËøëÁöÑÂâçÊ≤øÊ®°Âûã‰æøÂÆú‰∫ÜËÆ∏Â§öÔºå‰∏îÊØî [GPT-3.5 Turbo](/openai/gpt-3.5-turbo) ‰æøÂÆúË∂ÖËøá 60%„ÄÇÂÆÉ‰øùÊåÅ‰∫Ü SOTA Êô∫ËÉΩÔºåÂêåÊó∂Âú®ÊàêÊú¨ÊïàÁõä‰∏äÊòæËëóÊèêÈ´ò„ÄÇ\n\nGPT-4o mini Âú® MMLU ‰∏äËé∑Âæó‰∫Ü 82% ÁöÑÂàÜÊï∞ÔºåÁõÆÂâçÂú®ËÅäÂ§©ÂÅèÂ•Ω [Â∏∏ËßÅÊéíË°åÊ¶ú](https://arena.lmsys.org/) ‰∏äÁöÑÊéíÂêçÈ´ò‰∫é GPT-4„ÄÇ\n\nÊü•Áúã [ÂèëÂ∏ÉÂÖ¨Âëä](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) ‰ª•‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/gpt-4o","frontmatter":{"title":"OpenAI: GPT-4o","meta_title":"OpenAI: GPT-4o","description":"OpenAI: GPT-4o","date":"2024-05-13T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text image 2 text"],"author":"openai","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Computer Vision"],"draft":false,"id":"gpt-4o","context":128000,"input":0.0000025,"output":0.00001,"img":0.0036125,"request":0,"last_updated":"2024-05-13T00:00:00.000Z","slug":"models/gpt-4o"},"content":"\nGPT-4oÔºà‚Äúo‚Äù‰ª£Ë°®‚ÄúÂÖ®ËÉΩ‚ÄùÔºâÊòØOpenAIÊúÄÊñ∞ÁöÑAIÊ®°ÂûãÔºåÊîØÊåÅÊñáÊú¨ÂíåÂõæÂÉèËæìÂÖ•ÔºåÂπ∂ÁîüÊàêÊñáÊú¨ËæìÂá∫„ÄÇÂÆÉ‰øùÊåÅ‰∫Ü[GPT-4 Turbo](/openai/gpt-4-turbo)ÁöÑÊô∫ËÉΩÊ∞¥Âπ≥ÔºåÂêåÊó∂ÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü‰∏§ÂÄçÔºåÊàêÊú¨ÊïàÁõäÊèêÈ´ò‰∫Ü50%„ÄÇGPT-4oËøòÂú®Â§ÑÁêÜÈùûËã±ËØ≠ËØ≠Ë®ÄÂíåÂ¢ûÂº∫ËßÜËßâËÉΩÂäõÊñπÈù¢Êèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ\n\n‰∏∫‰∫Ü‰∏éÂÖ∂‰ªñÊ®°ÂûãËøõË°åÂü∫ÂáÜÊµãËØïÔºåÂÆÉÊõæË¢´ÊöÇÊó∂Áß∞‰∏∫[\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n"},{"lang":"zh","group":"models","slug":"models/grok-beta","frontmatter":{"title":"xAI: Grok Beta","meta_title":"xAI: Grok Beta","description":"xAI: Grok Beta","date":"2024-10-20T00:00:00.000Z","image":"https://img.rifx.online/logo/xai.svg","categories":["text 2 text"],"author":"x-ai","tags":["Natural Language Processing","Machine Learning","Generative AI","Chatbots","Data Science"],"draft":false,"id":"grok-beta","context":131072,"input":0.000005,"output":0.000015,"img":0,"request":0,"last_updated":"2024-11-07T09:32:49.000Z","slug":"models/grok-beta"},"content":"\nGrok Beta ÊòØ xAI ÁöÑÂÆûÈ™åÊÄßËØ≠Ë®ÄÊ®°ÂûãÔºåÂÖ∑ÊúâÊúÄÂÖàËøõÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊúÄÈÄÇÂêàÂ§çÊùÇÂíåÂ§öÊ≠•È™§ÁöÑÁî®‰æã„ÄÇ\n\nÂÆÉÊòØ [Grok 2](https://x.ai/blog/grok-2) ÁöÑÁªß‰ªªËÄÖÔºåÂÖ∑ÊúâÂ¢ûÂº∫ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/hermes-3-llama-31-405b","frontmatter":{"title":"Nous: Hermes 3 405B Instruct","meta_title":"Nous: Hermes 3 405B Instruct","description":"Nous: Hermes 3 405B Instruct","date":"2024-08-16T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"nousresearch","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Chatbots"],"draft":false,"id":"hermes-3-llama-3.1-405b","context":131072,"input":0.00000179,"output":0.00000249,"img":0,"request":0,"last_updated":"2024-11-11T03:16:40.000Z","slug":"models/hermes-3-llama-31-405b"},"content":"\nHermes 3 ÊòØ‰∏Ä‰∏™ÈÄöÁî®ËØ≠Ë®ÄÊ®°ÂûãÔºåÁõ∏ËæÉ‰∫é Hermes 2 ÊúâËÆ∏Â§öÊîπËøõÔºåÂåÖÊã¨ÂÖàËøõÁöÑ‰ª£ÁêÜËÉΩÂäõ„ÄÅÊòæËëóÊõ¥Â•ΩÁöÑËßíËâ≤ÊâÆÊºî„ÄÅÊé®ÁêÜ„ÄÅÂ§öËΩÆÂØπËØù„ÄÅÈïø‰∏ä‰∏ãÊñá‰∏ÄËá¥ÊÄß‰ª•ÂèäÂêÑÊñπÈù¢ÁöÑÊèêÂçá„ÄÇ\n\nHermes 3 405B ÊòØ Llama-3.1 405B Âü∫Á°ÄÊ®°ÂûãÁöÑÂâçÊ≤øÁ∫ßÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºå‰∏ìÊ≥®‰∫éÂ∞Ü LLM ‰∏éÁî®Êà∑ÂØπÈΩêÔºåËµã‰∫àÁªàÁ´ØÁî®Êà∑Âº∫Â§ßÁöÑÂºïÂØºËÉΩÂäõÂíåÊéßÂà∂ÊùÉ„ÄÇ\n\nHermes 3 Á≥ªÂàóÂú® Hermes 2 ÁöÑËÉΩÂäõÂü∫Á°Ä‰∏äËøõË°åÊûÑÂª∫ÂíåÊâ©Â±ïÔºåÂåÖÊã¨Êõ¥Âº∫Â§ßÂíåÂèØÈù†ÁöÑÂáΩÊï∞Ë∞ÉÁî®ÂíåÁªìÊûÑÂåñËæìÂá∫ËÉΩÂäõ„ÄÅÈÄöÁî®Âä©ÊâãËÉΩÂäõ‰ª•ÂèäÊîπËøõÁöÑ‰ª£Á†ÅÁîüÊàêÊäÄËÉΩ„ÄÇ\n\nÂú®ÈÄöÁî®ËÉΩÂäõÊñπÈù¢ÔºåHermes 3 ‰∏é Llama-3.1 Êåá‰ª§Ê®°ÂûãÂÖ∑ÊúâÁ´û‰∫âÂäõÔºåÁîöËá≥Âú®Êüê‰∫õÊñπÈù¢ÂèØËÉΩÊõ¥‰ºòÔºå‰∏§ËÄÖ‰πãÈó¥ÁöÑ‰ºòÁº∫ÁÇπÂêÑÊúâ‰∏çÂêå„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/hermes-3-llama-31-70b","frontmatter":{"title":"Nous: Hermes 3 70B Instruct","meta_title":"Nous: Hermes 3 70B Instruct","description":"Nous: Hermes 3 70B Instruct","date":"2024-08-18T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"nousresearch","tags":["Natural Language Processing","Machine Learning","Generative AI","Chatbots","Programming"],"draft":false,"id":"hermes-3-llama-3.1-70b","context":131072,"input":4e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:16:38.000Z","slug":"models/hermes-3-llama-31-70b"},"content":"\nHermes 3 ÊòØ‰∏Ä‰∏™ÈÄöÁî®ËØ≠Ë®ÄÊ®°ÂûãÔºåÁõ∏ËæÉ‰∫é [Hermes 2](/nousresearch/nous-hermes-2-mistral-7b-dpo) ÊúâËÆ∏Â§öÊîπËøõÔºåÂåÖÊã¨ÂÖàËøõÁöÑ‰ª£ÁêÜËÉΩÂäõÔºåÊõ¥Â•ΩÁöÑËßíËâ≤ÊâÆÊºîÔºåÊé®ÁêÜÔºåÂ§öËΩÆÂØπËØùÔºåÈïø‰∏ä‰∏ãÊñáËøûË¥ØÊÄßÔºå‰ª•ÂèäÂêÑÊñπÈù¢ÁöÑÊîπËøõ„ÄÇ\n\nHermes 3 70B ÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÂæÆË∞ÉÁâàÊú¨ÔºåÁîöËá≥ÂèØ‰ª•ËØ¥ÊòØ [Llama-3.1 70B Âü∫Á°ÄÊ®°Âûã](/meta-llama/llama-3.1-70b-instruct) ÁöÑ‰ºòË∂äÁâàÊú¨Ôºå‰∏ìÊ≥®‰∫éÂ∞Ü LLM ‰∏éÁî®Êà∑ÂØπÈΩêÔºåËµã‰∫àÊúÄÁªàÁî®Êà∑Âº∫Â§ßÁöÑÂºïÂØºËÉΩÂäõÂíåÊéßÂà∂ÊùÉ„ÄÇ\n\nHermes 3 Á≥ªÂàóÂú® Hermes 2 ÁöÑËÉΩÂäõÂü∫Á°Ä‰∏äËøõË°åÊûÑÂª∫ÂíåÊâ©Â±ïÔºåÂåÖÊã¨Êõ¥Âº∫Â§ßÂíåÂèØÈù†ÁöÑÂáΩÊï∞Ë∞ÉÁî®ÂíåÁªìÊûÑÂåñËæìÂá∫ËÉΩÂäõÔºåÈÄöÁî®Âä©ÊâãËÉΩÂäõÔºå‰ª•ÂèäÊîπËøõÁöÑ‰ª£Á†ÅÁîüÊàêÊäÄËÉΩ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/inflection-3-pi","frontmatter":{"title":"Inflection: Inflection 3 Pi","meta_title":"Inflection: Inflection 3 Pi","description":"Inflection: Inflection 3 Pi","date":"2024-10-11T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"inflection","tags":["Chatbots","Roleplay","Emotional Intelligence","Customer Support","Safety"],"draft":false,"id":"inflection-3-pi","context":8000,"input":0.0000025,"output":0.00001,"img":0,"request":0,"last_updated":"2024-11-07T10:11:48.000Z","slug":"models/inflection-3-pi"},"content":"\nInflection 3 Pi ÁöÑ [Pi](https://pi.ai) ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂåÖÂê´ËÉåÊôØÊïÖ‰∫ã„ÄÅÊÉÖÊÑüÊô∫ËÉΩ„ÄÅÁîü‰∫ßÂäõÂíåÂÆâÂÖ®ÊÄß„ÄÇÂÆÉÂú®ÂÆ¢Êà∑ÊîØÊåÅ„ÄÅËßíËâ≤ÊâÆÊºîÂíåÊÉÖÊÑüÊô∫ËÉΩÁ≠âÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/inflection-3-productivity","frontmatter":{"title":"Inflection: Inflection 3 Productivity","meta_title":"Inflection: Inflection 3 Productivity","description":"Inflection: Inflection 3 Productivity","date":"2024-10-11T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"inflection","tags":["Programming","Technology","Chatbots","Generative AI","Data Science"],"draft":false,"id":"inflection-3-productivity","context":8000,"input":0.0000025,"output":0.00001,"img":0,"request":0,"last_updated":"2024-11-07T10:11:56.000Z","slug":"models/inflection-3-productivity"},"content":"\nInflection 3 ÁöÑÁîü‰∫ßÂäõÁªèËøá‰ºòÂåñÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞ÈÅµÂæ™Êåá‰ª§„ÄÇÂÆÉÊõ¥ÈÄÇÂêàÈúÄË¶Å JSON ËæìÂá∫ÊàñÁ≤æÁ°ÆÈÅµÂæ™Êèê‰æõÁöÑÊåáÂØºÊñπÈíàÁöÑ‰ªªÂä°„ÄÇ\n\nÊúâÂÖ≥Á±ª‰ºº‰∫é Pi ÁöÑÊÉÖÊÑüÊô∫ËÉΩÔºåËØ∑ÂèÇËßÅ [Inflect 3 Pi](/inflection/inflection-3-pi)„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅ [Inflection ÁöÑÂÖ¨Âëä](https://inflection.ai/blog/enterprise)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/jamba-1-5-large","frontmatter":{"title":"AI21: Jamba 1.5 Large","meta_title":"AI21: Jamba 1.5 Large","description":"AI21: Jamba 1.5 Large","date":"2024-08-23T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"ai21","tags":["Programming","Technology","Machine Learning","Data Science","Generative AI"],"draft":false,"id":"jamba-1-5-large","context":256000,"input":0.000002,"output":0.000008,"img":0,"request":0,"last_updated":"2024-11-11T03:11:21.000Z","slug":"models/jamba-1-5-large"},"content":"\nJamba 1.5 Large ÊòØ AI21 Êñ∞‰∏Ä‰ª£ÂºÄÊîæÊ®°ÂûãÂÆ∂ÊóèÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊèê‰æõÂçìË∂äÁöÑÈÄüÂ∫¶„ÄÅÊïàÁéáÂíåË¥®Èáè„ÄÇ\n\nÂÆÉÂÖ∑Êúâ 256K ÁöÑÊúâÊïà‰∏ä‰∏ãÊñáÁ™óÂè£ÔºåÊòØÂºÄÊîæÊ®°Âûã‰∏≠ÊúÄÈïøÁöÑÔºåËÉΩÂ§üÂú®ÊñáÊ°£ÊëòË¶ÅÂíåÂàÜÊûêÁ≠â‰ªªÂä°‰∏äÊèêÂçáÊÄßËÉΩ„ÄÇ\n\nÂü∫‰∫éÊñ∞È¢ñÁöÑ SSM-Transformer Êû∂ÊûÑÔºåÂÆÉÂú®Âü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫ÜÊõ¥Â§ßÁöÑÊ®°ÂûãÔºåÂ¶Ç Llama 3.1 70BÔºåÂêåÊó∂‰øùÊåÅËµÑÊ∫êÊïàÁéá„ÄÇ\n\nÈòÖËØª‰ªñ‰ª¨ÁöÑ [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) ‰ª•‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/jamba-1-5-mini","frontmatter":{"title":"AI21: Jamba 1.5 Mini","meta_title":"AI21: Jamba 1.5 Mini","description":"AI21: Jamba 1.5 Mini","date":"2024-08-23T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"ai21","tags":["Programming","Technology","Machine Learning","Natural Language Processing","Data Science"],"draft":false,"id":"jamba-1-5-mini","context":256000,"input":2e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:11:12.000Z","slug":"models/jamba-1-5-mini"},"content":"\nJamba 1.5 Mini ÊòØ‰∏ñÁïå‰∏äÈ¶ñ‰∏™Áîü‰∫ßÁ∫ß Mamba Âü∫Á°ÄÊ®°ÂûãÔºåÁªìÂêà‰∫Ü SSM Âíå Transformer Êû∂ÊûÑÔºåÂÖ∑Êúâ 256K ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÂíåÈ´òÊïàÁéá„ÄÇ\n\nÂÆÉÊîØÊåÅ 9 ÁßçËØ≠Ë®ÄÔºåÂπ∂ËÉΩÂ§üÂ§ÑÁêÜÂêÑÁßçÂÜô‰ΩúÂíåÂàÜÊûê‰ªªÂä°ÔºåÊïàÊûú‰∏éÁ±ª‰ººÁöÑÂ∞èÊ®°ÂûãÁõ∏ÂΩìÊàñÊõ¥Â•Ω„ÄÇ\n\nËØ•Ê®°ÂûãÊØî‰ª•ÂâçÁöÑËÆæËÆ°‰ΩøÁî®Êõ¥Â∞ëÁöÑËÆ°ÁÆóÊú∫ÂÜÖÂ≠òÔºåÂπ∂‰∏îÂú®Â§ÑÁêÜËæÉÈïøÊñáÊú¨Êó∂ÈÄüÂ∫¶Êõ¥Âø´„ÄÇ\n\nÈòÖËØª‰ªñ‰ª¨ÁöÑ [ÂÖ¨Âëä](https://www.ai21.com/blog/announcing-jamba-model-family) ‰ª•‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/l3-lunaris-8b","frontmatter":{"title":"Llama 3 8B Lunaris","meta_title":"Llama 3 8B Lunaris","description":"Llama 3 8B Lunaris","date":"2024-08-13T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"sao10k","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Chatbots"],"draft":false,"id":"l3-lunaris-8b","context":8192,"input":0.000002,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:12:13.000Z","slug":"models/l3-lunaris-8b"},"content":"\nLunaris 8B ÊòØ‰∏Ä‰∏™Â§öÂäüËÉΩÁöÑÈÄöÁî®ÂíåËßíËâ≤ÊâÆÊºîÊ®°ÂûãÔºåÂü∫‰∫é Llama 3„ÄÇÂÆÉÊòØÂ§ö‰∏™Ê®°ÂûãÁöÑÊàòÁï•ÂêàÂπ∂ÔºåÊó®Âú®Âπ≥Ë°°ÂàõÈÄ†Âäõ‰∏éÊîπËøõÁöÑÈÄªËæëÂíå‰∏ÄËà¨Áü•ËØÜ„ÄÇ\n\nÁî± [Sao10k](https://huggingface.co/Sao10k) ÂàõÂª∫ÔºåËØ•Ê®°ÂûãÊó®Âú®Êèê‰æõÊØî Stheno v3.2 Êõ¥Â•ΩÁöÑ‰ΩìÈ™åÔºåÂÖ∑ÊúâÂ¢ûÂº∫ÁöÑÂàõÈÄ†ÂäõÂíåÈÄªËæëÊé®ÁêÜËÉΩÂäõ„ÄÇ\n\n‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÊïàÊûúÔºåËØ∑‰ΩøÁî® Llama 3 Instruct ‰∏ä‰∏ãÊñáÊ®°ÊùøÔºåÊ∏©Â∫¶ 1.4Ôºåmin_p 0.1„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/l31-euryale-70b","frontmatter":{"title":"Llama 3.1 Euryale 70B v2.2","meta_title":"Llama 3.1 Euryale 70B v2.2","description":"Llama 3.1 Euryale 70B v2.2","date":"2024-08-28T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"sao10k","tags":["Roleplay","Generative AI","Chatbots","Natural Language Processing","Technology/Web"],"draft":false,"id":"l3.1-euryale-70b","context":8192,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:12:50.000Z","slug":"models/l31-euryale-70b"},"content":"\nEuryale L3.1 70B v2.2 ÊòØ‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÂàõÊÑèËßíËâ≤ÊâÆÊºîÁöÑÊ®°ÂûãÔºåÊù•Ëá™ [Sao10k](https://ko-fi.com/sao10k)„ÄÇÂÆÉÊòØ [Euryale L3 70B v2.1](/sao10k/l3-euryale-70b) ÁöÑÁªß‰ªªËÄÖ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/lfm-40b","frontmatter":{"title":"Liquid: LFM 40B MoE","meta_title":"Liquid: LFM 40B MoE","description":"Liquid: LFM 40B MoE","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"liquid","tags":["Machine Learning","Natural Language Processing","Data Science","Generative AI","Computer Vision"],"draft":false,"is_recommended":true,"id":"lfm-40b","context":32768,"input":0.000001,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-14T05:10:16.000Z","slug":"models/lfm-40b"},"content":"\nLiquidÁöÑ40.3B‰∏ìÂÆ∂Ê∑∑ÂêàÔºàMoEÔºâÊ®°Âûã„ÄÇLiquidÂü∫Á°ÄÊ®°ÂûãÔºàLFMsÔºâÊòØÂü∫‰∫éÂä®ÊÄÅÁ≥ªÁªüÊûÑÂª∫ÁöÑÂ§ßÂûãÁ•ûÁªèÁΩëÁªú„ÄÇ\n\nLFMsÊòØÈÄöÁî®ÁöÑAIÊ®°ÂûãÔºåÂèØ‰ª•Áî®‰∫éÂª∫Ê®°‰ªª‰ΩïÁ±ªÂûãÁöÑÂ∫èÂàóÊï∞ÊçÆÔºåÂåÖÊã¨ËßÜÈ¢ë„ÄÅÈü≥È¢ë„ÄÅÊñáÊú¨„ÄÅÊó∂Èó¥Â∫èÂàóÂíå‰ø°Âè∑„ÄÇ\n\nÊúâÂÖ≥Âü∫ÂáÜÂíåÊõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅ[ÂèëÂ∏ÉÂÖ¨Âëä](https://www.liquid.ai/liquid-foundation-models)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/liquid-lfm-40b:free","frontmatter":{"title":"Liquid: LFM 40B MoE (free)","meta_title":"Liquid: LFM 40B MoE (free)","description":"Liquid: LFM 40B MoE (free)","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"liquid","tags":["Generative AI","Machine Learning","Natural Language Processing","Data Science","Technology/Web"],"draft":false,"id":"liquid/lfm-40b:free","context":8192,"input":0,"output":0,"img":0,"request":0,"last_updated":"2024-11-07T00:17:57.000Z","slug":"models/liquid-lfm-40b:free"},"content":"\nLiquidÁöÑ40.3B‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºàMoEÔºâ„ÄÇLiquidÂü∫Á°ÄÊ®°ÂûãÔºàLFMsÔºâÊòØÂü∫‰∫éÂä®ÊÄÅÁ≥ªÁªüÊûÑÂª∫ÁöÑÂ§ßÂûãÁ•ûÁªèÁΩëÁªú„ÄÇ\n\nLFMsÊòØÈÄöÁî®ÁöÑAIÊ®°ÂûãÔºåÂèØ‰ª•Áî®‰∫éÂª∫Ê®°‰ªª‰ΩïÁ±ªÂûãÁöÑÂ∫èÂàóÊï∞ÊçÆÔºåÂåÖÊã¨ËßÜÈ¢ë„ÄÅÈü≥È¢ë„ÄÅÊñáÊú¨„ÄÅÊó∂Èó¥Â∫èÂàóÂíå‰ø°Âè∑„ÄÇ\n\nÊúâÂÖ≥Âü∫ÂáÜÊµãËØïÂíåÊõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇËßÅ[ÂèëÂ∏ÉÂÖ¨Âëä](https://www.liquid.ai/liquid-foundation-models)„ÄÇ\n\n_Ëøô‰∫õÊòØ[LFM 40B MoE](/liquid/lfm-40b)ÁöÑÂÖçË¥πÈôêÊµÅÁ´ØÁÇπ„ÄÇËæìÂá∫ÂèØËÉΩ‰ºöË¢´ÁºìÂ≠ò„ÄÇÊúâÂÖ≥ÈÄüÁéáÈôêÂà∂ÁöÑ‰ø°ÊÅØÔºåËØ∑[Âú®ËøôÈáå](/docs/limits)ÈòÖËØª„ÄÇ_\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-70b-instruct","frontmatter":{"title":"Meta: Llama 3.1 70B Instruct","meta_title":"Meta: Llama 3.1 70B Instruct","description":"Meta: Llama 3.1 70B Instruct","date":"2024-07-23T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Programming","Machine Learning","Natural Language Processing","Chatbots","Ethics"],"draft":false,"id":"llama-3.1-70b-instruct","context":131072,"input":3e-7,"output":3e-7,"img":0,"request":0,"last_updated":"2024-10-28T13:38:49.000Z","slug":"models/llama-31-70b-instruct"},"content":"\nMetaÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÊ®°ÂûãÁ±ªÂà´ÔºàLlama 3.1ÔºâÊé®Âá∫‰∫ÜÂ§öÁßçÂ∞∫ÂØ∏ÂíåÁâàÊú¨„ÄÇËøô‰∏™70BÁöÑÊåá‰ª§Ë∞É‰ºòÁâàÊú¨ÈíàÂØπÈ´òË¥®ÈáèÂØπËØùÁî®‰æãËøõË°å‰∫Ü‰ºòÂåñ„ÄÇ\n\nÂú®‰∫∫Â∑•ËØÑ‰º∞‰∏≠ÔºåÂÆÉ‰∏éÈ¢ÜÂÖàÁöÑÈó≠Ê∫êÊ®°ÂûãÁõ∏ÊØîË°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n‰ΩøÁî®ËØ•Ê®°ÂûãÈúÄÈÅµÂæ™[MetaÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://www.llama.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-8b-instruct","frontmatter":{"title":"Meta: Llama 3.1 8B Instruct","meta_title":"Meta: Llama 3.1 8B Instruct","description":"Meta: Llama 3.1 8B Instruct","date":"2024-07-23T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Ethics"],"draft":false,"id":"llama-3.1-8b-instruct","context":131072,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-10-31T23:27:09.000Z","slug":"models/llama-31-8b-instruct"},"content":"\nMetaÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÊ®°ÂûãÁ≥ªÂàóÔºàLlama 3.1ÔºâÊé®Âá∫‰∫ÜÂ§öÁßçÂ∞∫ÂØ∏ÂíåÁâàÊú¨„ÄÇËøô‰∏™8BÊåá‰ª§Ë∞É‰ºòÁâàÊú¨Âø´ÈÄü‰∏îÈ´òÊïà„ÄÇ\n\n‰∏éÈ¢ÜÂÖàÁöÑÈó≠Ê∫êÊ®°ÂûãÁõ∏ÊØîÔºåÂÆÉÂú®‰∫∫Â∑•ËØÑ‰º∞‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈúÄÈÅµÂæ™[MetaÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://www.llama.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-lumimaid-70b","frontmatter":{"title":"Lumimaid v0.2 70B","meta_title":"Lumimaid v0.2 70B","description":"Lumimaid v0.2 70B","date":"2024-10-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"neversleep","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Ethics"],"draft":false,"id":"llama-3.1-lumimaid-70b","context":131072,"input":0.000003375,"output":0.0000045,"img":0,"request":0,"last_updated":"2024-11-11T03:03:31.000Z","slug":"models/llama-31-lumimaid-70b"},"content":"\nLumimaid v0.2 70B ÊòØÂØπ [Llama 3.1 70B](/meta-llama/llama-3.1-70b-instruct) ÁöÑÂæÆË∞ÉÔºå‰∏é Lumimaid v0.1 Áõ∏ÊØîÔºåÂú®Êï∞ÊçÆÈõÜÊñπÈù¢Êúâ‰∫Ü‚ÄúÂ∑®Â§ßÁöÑÊèêÂçá‚Äù„ÄÇ‰∏çÂêàÊ†ºÁöÑËÅäÂ§©ËæìÂá∫Â∑≤Ë¢´Ê∏ÖÈô§„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™ [Meta ÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://llama.meta.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-lumimaid-8b","frontmatter":{"title":"Lumimaid v0.2 8B","meta_title":"Lumimaid v0.2 8B","description":"Lumimaid v0.2 8B","date":"2024-09-15T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"neversleep","tags":["Programming","Machine Learning","Natural Language Processing","Chatbots","Ethics"],"draft":false,"id":"llama-3.1-lumimaid-8b","context":131072,"input":1.875e-7,"output":0.000001125,"img":0,"request":0,"last_updated":"2024-11-11T03:10:19.000Z","slug":"models/llama-31-lumimaid-8b"},"content":"\nLumimaid v0.2 8B ÊòØÂØπ [Llama 3.1 8B](/meta-llama/llama-3.1-8b-instruct) ÁöÑÂæÆË∞ÉÔºåÁõ∏ËæÉ‰∫é Lumimaid v0.1ÔºåÊï∞ÊçÆÈõÜÊúâ‰∫Ü‚ÄúÂ∑®Â§ßÁöÑÊèêÂçá‚Äù„ÄÇ‰∏çÂΩìÁöÑËÅäÂ§©ËæìÂá∫Â∑≤Ë¢´Ê∏ÖÈô§„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™ [Meta ÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://llama.meta.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-nemotron-70b-instruct","frontmatter":{"title":"Nvidia: Llama 3.1 Nemotron 70B Instruct","meta_title":"Nvidia: Llama 3.1 Nemotron 70B Instruct","description":"Nvidia: Llama 3.1 Nemotron 70B Instruct","date":"2024-10-15T00:00:00.000Z","image":"https://img.rifx.online/logo/nvidia.svg","categories":["text 2 text"],"author":"nvidia","tags":["Programming","Natural Language Processing","Machine Learning","Generative AI","Ethics"],"draft":false,"id":"llama-3.1-nemotron-70b-instruct","context":131072,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-10-15T00:00:00.000Z","slug":"models/llama-31-nemotron-70b-instruct"},"content":"\nNVIDIAÁöÑLlama 3.1 Nemotron 70BÊòØ‰∏Ä‰∏™Êó®Âú®ÁîüÊàêÁ≤æÁ°ÆÂíåÊúâÁî®ÂìçÂ∫îÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇÂà©Áî®[Llama 3.1 70B](/models/meta-llama/llama-3.1-70b-instruct)Êû∂ÊûÑÂíåÂü∫‰∫é‰∫∫Á±ªÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π†ÔºàRLHFÔºâÔºåÂÆÉÂú®Ëá™Âä®ÂØπÈΩêÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇËØ•Ê®°Âûã‰∏ì‰∏∫ÈúÄË¶ÅÈ´òÂáÜÁ°ÆÊÄß‰ª•Êèê‰æõÂ∏ÆÂä©ÂíåÁîüÊàêÂìçÂ∫îÁöÑÂ∫îÁî®ËÄåËÆæËÆ°ÔºåÈÄÇÂêàÂ§ÑÁêÜÂ§ö‰∏™È¢ÜÂüüÁöÑÂ§öÊ†∑Áî®Êà∑Êü•ËØ¢„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™[MetaÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://www.llama.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-sonar-huge-128k-online","frontmatter":{"title":"Perplexity: Llama 3.1 Sonar 405B Online","meta_title":"Perplexity: Llama 3.1 Sonar 405B Online","description":"Perplexity: Llama 3.1 Sonar 405B Online","date":"2024-08-14T00:00:00.000Z","image":"https://img.rifx.online/logo/perplexity.svg","categories":["text 2 text"],"author":"perplexity","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"llama-3.1-sonar-huge-128k-online","context":127072,"input":0.000005,"output":0.000005,"img":0,"request":0.005,"last_updated":"2024-11-07T09:36:38.000Z","slug":"models/llama-31-sonar-huge-128k-online"},"content":"\nLlama 3.1 Sonar ÊòØ Perplexity ÊúÄÊñ∞ÁöÑÊ®°ÂûãÁ≥ªÂàó„ÄÇÂÆÉÂú®ÊàêÊú¨ÊïàÁõä„ÄÅÈÄüÂ∫¶ÂíåÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫Ü‰ªñ‰ª¨Êó©ÊúüÁöÑ Sonar Ê®°Âûã„ÄÇËØ•Ê®°ÂûãÂü∫‰∫é Llama 3.1 405BÔºåÂπ∂ÂÖ∑Êúâ‰∫íËÅîÁΩëËÆøÈóÆÂäüËÉΩ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-sonar-large-128k-online","frontmatter":{"title":"Perplexity: Llama 3.1 Sonar 70B Online","meta_title":"Perplexity: Llama 3.1 Sonar 70B Online","description":"Perplexity: Llama 3.1 Sonar 70B Online","date":"2024-08-01T00:00:00.000Z","image":"https://img.rifx.online/logo/perplexity.svg","categories":["text 2 text"],"author":"perplexity","tags":["Programming","Machine Learning","Natural Language Processing","Chatbots","Generative AI"],"draft":false,"id":"llama-3.1-sonar-large-128k-online","context":127072,"input":0.000001,"output":0.000001,"img":0,"request":0.005,"last_updated":"2024-11-07T09:37:21.000Z","slug":"models/llama-31-sonar-large-128k-online"},"content":"\nLlama 3.1 Sonar ÊòØ Perplexity ÊúÄÊñ∞ÁöÑÊ®°ÂûãÁ≥ªÂàó„ÄÇÂÆÉÂú®ÊàêÊú¨ÊïàÁõä„ÄÅÈÄüÂ∫¶ÂíåÊÄßËÉΩÊñπÈù¢Ë∂ÖË∂ä‰∫Ü‰ªñ‰ª¨Êó©ÊúüÁöÑ Sonar Ê®°Âûã„ÄÇ\n\nËøôÊòØ [Á¶ªÁ∫øËÅäÂ§©Ê®°Âûã](/perplexity/llama-3.1-sonar-large-128k-chat) ÁöÑÂú®Á∫øÁâàÊú¨„ÄÇÂÆÉ‰∏ìÊ≥®‰∫éÊèê‰æõÊúâÂ∏ÆÂä©„ÄÅÊúÄÊñ∞ÂíåÁúüÂÆûÁöÑÂìçÂ∫î„ÄÇ #online\n\n"},{"lang":"zh","group":"models","slug":"models/llama-31-sonar-small-128k-online","frontmatter":{"title":"Perplexity: Llama 3.1 Sonar 8B Online","meta_title":"Perplexity: Llama 3.1 Sonar 8B Online","description":"Perplexity: Llama 3.1 Sonar 8B Online","date":"2024-08-01T00:00:00.000Z","image":"https://img.rifx.online/logo/perplexity.svg","categories":["text 2 text"],"author":"perplexity","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"llama-3.1-sonar-small-128k-online","context":127072,"input":2e-7,"output":2e-7,"img":0,"request":0.005,"last_updated":"2024-11-07T09:38:09.000Z","slug":"models/llama-31-sonar-small-128k-online"},"content":"\nLlama 3.1 Sonar ÊòØ Perplexity ÊúÄÊñ∞ÁöÑÊ®°ÂûãÁ≥ªÂàó„ÄÇÂÆÉÂú®ÊàêÊú¨ÊïàÁéá„ÄÅÈÄüÂ∫¶ÂíåÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫Ü‰ªñ‰ª¨Êó©ÊúüÁöÑ Sonar Ê®°Âûã„ÄÇ\n\nËøôÊòØ [Á¶ªÁ∫øËÅäÂ§©Ê®°Âûã](/perplexity/llama-3.1-sonar-small-128k-chat) ÁöÑÂú®Á∫øÁâàÊú¨„ÄÇÂÆÉ‰∏ìÊ≥®‰∫éÊèê‰æõÊúâÁî®„ÄÅÊúÄÊñ∞ÂíåÁúüÂÆûÁöÑÂìçÂ∫î„ÄÇ #online\n\n"},{"lang":"zh","group":"models","slug":"models/llama-32-11b-vision-instruct","frontmatter":{"title":"Meta: Llama 3.2 11B Vision Instruct","meta_title":"Meta: Llama 3.2 11B Vision Instruct","description":"Meta: Llama 3.2 11B Vision Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text image 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Computer Vision","Machine Learning","Generative AI","Data Science"],"draft":false,"is_recommended":true,"id":"llama-3.2-11b-vision-instruct","context":131072,"input":5.5e-8,"output":5.5e-8,"img":0.000079475,"request":0,"last_updated":"2024-11-14T05:10:41.000Z","slug":"models/llama-32-11b-vision-instruct"},"content":"\nLlama 3.2 11B Vision ÊòØ‰∏Ä‰∏™ÂÖ∑Êúâ 110 ‰∫øÂèÇÊï∞ÁöÑÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊó®Âú®Â§ÑÁêÜÁªìÂêàËßÜËßâÂíåÊñáÊú¨Êï∞ÊçÆÁöÑ‰ªªÂä°„ÄÇÂÆÉÂú®ÂõæÂÉèÊèèËø∞ÂíåËßÜËßâÈóÆÁ≠îÁ≠â‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂº•Âêà‰∫ÜËØ≠Ë®ÄÁîüÊàê‰∏éËßÜËßâÊé®ÁêÜ‰πãÈó¥ÁöÑÈ∏øÊ≤ü„ÄÇËØ•Ê®°ÂûãÂú®Â§ßÈáèÂõæÂÉè-ÊñáÊú¨ÂØπÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÈ¢ÑËÆ≠ÁªÉÔºåËÉΩÂ§üÂú®Â§çÊùÇÁöÑÈ´òÁ≤æÂ∫¶ÂõæÂÉèÂàÜÊûê‰∏≠Ë°®Áé∞ËâØÂ•Ω„ÄÇ\n\nÂÆÉÂ∞ÜËßÜËßâÁêÜËß£‰∏éËØ≠Ë®ÄÂ§ÑÁêÜÁõ∏ÁªìÂêàÁöÑËÉΩÂäõÔºå‰ΩøÂÖ∂Êàê‰∏∫ÈúÄË¶ÅÂÖ®Èù¢ËßÜËßâËØ≠Ë®Ä AI Â∫îÁî®ÁöÑË°å‰∏öÁöÑÁêÜÊÉ≥Ëß£ÂÜ≥ÊñπÊ°àÔºå‰æãÂ¶ÇÂÜÖÂÆπÂàõ‰Ωú„ÄÅAI È©±Âä®ÁöÑÂÆ¢Êà∑ÊúçÂä°ÂíåÁ†îÁ©∂„ÄÇ\n\nÁÇπÂáªÊ≠§Â§ÑÊü•Áúã [ÂéüÂßãÊ®°ÂûãÂç°](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈúÄÈÅµÂÆà [Meta ÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://www.llama.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-32-1b-instruct","frontmatter":{"title":"Meta: Llama 3.2 1B Instruct","meta_title":"Meta: Llama 3.2 1B Instruct","description":"Meta: Llama 3.2 1B Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Programming","Technology","Machine Learning","Generative AI"],"draft":false,"id":"llama-3.2-1b-instruct","context":131072,"input":1e-8,"output":2e-8,"img":0,"request":0,"last_updated":"2024-09-25T00:00:00.000Z","slug":"models/llama-32-1b-instruct"},"content":"\nLlama 3.2 1B ÊòØ‰∏Ä‰∏™Êã•Êúâ10‰∫øÂèÇÊï∞ÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºå‰∏ìÊ≥®‰∫éÈ´òÊïàÊâßË°åËá™ÁÑ∂ËØ≠Ë®Ä‰ªªÂä°ÔºåÂ¶ÇÊëòË¶Å„ÄÅÂØπËØùÂíåÂ§öËØ≠Ë®ÄÊñáÊú¨ÂàÜÊûê„ÄÇÂÖ∂ËæÉÂ∞èÁöÑËßÑÊ®°‰ΩøÂÖ∂ËÉΩÂ§üÂú®‰ΩéËµÑÊ∫êÁéØÂ¢É‰∏≠È´òÊïàËøêË°åÔºåÂêåÊó∂‰øùÊåÅÂº∫Â§ßÁöÑ‰ªªÂä°ÊÄßËÉΩ„ÄÇ\n\nÊîØÊåÅÂÖ´ÁßçÊ†∏ÂøÉËØ≠Ë®ÄÔºåÂπ∂ÂèØÈíàÂØπÊõ¥Â§öËØ≠Ë®ÄËøõË°åÂæÆË∞ÉÔºåLlama 1.3B ÈùûÂ∏∏ÈÄÇÂêàÂØªÊ±ÇËΩªÈáèÁ∫ß‰ΩÜÂº∫Â§ßÁöÑ AI Ëß£ÂÜ≥ÊñπÊ°àÁöÑ‰ºÅ‰∏öÊàñÂºÄÂèëËÄÖÔºåËøô‰∫õËß£ÂÜ≥ÊñπÊ°àËÉΩÂ§üÂú®Â§öÊ†∑ÂåñÁöÑÂ§öËØ≠Ë®ÄÁéØÂ¢É‰∏≠ËøêË°åÔºåËÄå‰∏çÈúÄË¶ÅÂ§ßÂûãÊ®°ÂûãÁöÑÈ´òËÆ°ÁÆóÈúÄÊ±Ç„ÄÇ\n\nÁÇπÂáªÊ≠§Â§ÑÊü•Áúã [ÂéüÂßãÊ®°ÂûãÂç°](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈúÄÈÅµÂæ™ [Meta ÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://www.llama.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/llama-32-3b-instruct","frontmatter":{"title":"Meta: Llama 3.2 3B Instruct","meta_title":"Meta: Llama 3.2 3B Instruct","description":"Meta: Llama 3.2 3B Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Machine Learning","Generative AI","Chatbots","Multilingual"],"draft":false,"id":"llama-3.2-3b-instruct","context":131072,"input":3e-8,"output":5e-8,"img":0,"request":0,"last_updated":"2024-11-11T03:09:59.000Z","slug":"models/llama-32-3b-instruct"},"content":"\nLlama 3.2 3B ÊòØ‰∏Ä‰∏™Êã•Êúâ 30 ‰∫øÂèÇÊï∞ÁöÑÂ§öËØ≠Ë®ÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÈíàÂØπÂØπËØùÁîüÊàê„ÄÅÊé®ÁêÜÂíåÊëòË¶ÅÁ≠âÈ´òÁ∫ßËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°ËøõË°å‰∫Ü‰ºòÂåñ„ÄÇÂÆÉÈááÁî®ÊúÄÊñ∞ÁöÑ transformer Êû∂ÊûÑÔºåÊîØÊåÅÂåÖÊã¨Ëã±ËØ≠„ÄÅË•øÁè≠ÁâôËØ≠ÂíåÂç∞Âú∞ËØ≠Âú®ÂÜÖÁöÑÂÖ´ÁßçËØ≠Ë®ÄÔºåÂπ∂‰∏îÂèØ‰ª•ÈÄÇÂ∫îÂÖ∂‰ªñËØ≠Ë®Ä„ÄÇ\n\nLlama 3.2B Ê®°ÂûãÂú® 9 ‰∏á‰∫ø‰∏™Ê†áËÆ∞‰∏äËøõË°åËÆ≠ÁªÉÔºåÊìÖÈïøÈÅµÂæ™Êåá‰ª§„ÄÅÂ§çÊùÇÊé®ÁêÜÂíåÂ∑•ÂÖ∑‰ΩøÁî®„ÄÇÂÖ∂Âπ≥Ë°°ÁöÑÊÄßËÉΩ‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÂú®Â§öËØ≠Ë®ÄÁéØÂ¢É‰∏≠ËøõË°åÊñáÊú¨ÁîüÊàêÊó∂ÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÁöÑÂ∫îÁî®„ÄÇ\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n"},{"lang":"zh","group":"models","slug":"models/llama-32-90b-vision-instruct","frontmatter":{"title":"Meta: Llama 3.2 90B Vision Instruct","meta_title":"Meta: Llama 3.2 90B Vision Instruct","description":"Meta: Llama 3.2 90B Vision Instruct","date":"2024-09-25T00:00:00.000Z","image":"https://img.rifx.online/logo/meta.svg","categories":["text image 2 text"],"author":"meta-llama","tags":["Natural Language Processing","Computer Vision","Machine Learning","Data Science","Generative AI"],"draft":false,"id":"llama-3.2-90b-vision-instruct","context":131072,"input":3.5e-7,"output":4e-7,"img":0.00050575,"request":0,"last_updated":"2024-09-25T00:00:00.000Z","slug":"models/llama-32-90b-vision-instruct"},"content":"\nLlama 90B VisionÊ®°ÂûãÊòØ‰∏ÄÊ¨æÈ°∂Á∫ßÁöÑ90‰∫øÂèÇÊï∞Â§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊó®Âú®Â∫îÂØπÊúÄÂÖ∑ÊåëÊàòÊÄßÁöÑËßÜËßâÊé®ÁêÜÂíåËØ≠Ë®Ä‰ªªÂä°„ÄÇÂÆÉÂú®ÂõæÂÉèÊèèËø∞„ÄÅËßÜËßâÈóÆÁ≠îÂíåÈ´òÁ∫ßÂõæÂÉè-ÊñáÊú¨ÁêÜËß£ÊñπÈù¢Êèê‰æõÊó†‰∏é‰º¶ÊØîÁöÑÂáÜÁ°ÆÊÄß„ÄÇËØ•Ê®°ÂûãÂú®Â∫ûÂ§ßÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂ÈÄöËøá‰∫∫Á±ªÂèçÈ¶àËøõË°åÂæÆË∞ÉÔºå‰∏ì‰∏∫Â§ÑÁêÜÊúÄËãõÂàªÁöÑÂü∫‰∫éÂõæÂÉèÁöÑAI‰ªªÂä°ËÄåËÆæËÆ°„ÄÇ\n\nÊ≠§Ê®°ÂûãÈùûÂ∏∏ÈÄÇÂêàÈúÄË¶ÅÂ∞ñÁ´ØÂ§öÊ®°ÊÄÅAIËÉΩÂäõÁöÑË°å‰∏öÔºåÂ∞§ÂÖ∂ÊòØÈÇ£‰∫õÂ§ÑÁêÜÂ§çÊùÇÂÆûÊó∂ËßÜËßâÂíåÊñáÊú¨ÂàÜÊûêÁöÑË°å‰∏ö„ÄÇ\n\nÁÇπÂáªÊ≠§Â§ÑÊü•Áúã[ÂéüÂßãÊ®°ÂûãÂç°Áâá](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈúÄÈÅµÂÆà[MetaÁöÑÂèØÊé•Âèó‰ΩøÁî®ÊîøÁ≠ñ](https://www.llama.com/llama3/use-policy/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/lzlv-70b-fp16-hf","frontmatter":{"title":"lzlv 70B","meta_title":"lzlv 70B","description":"lzlv 70B","date":"2023-11-12T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"lizpreciatior","tags":["Roleplay","Programming","Machine Learning","Generative AI","Chatbots"],"draft":false,"id":"lzlv-70b-fp16-hf","context":4096,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-11-04T12:50:34.000Z","slug":"models/lzlv-70b-fp16-hf"},"content":"\nA Mythomax/MLewd_13BÈ£éÊ†ºÁöÑÈÄâÂÆö70BÊ®°ÂûãÂêàÂπ∂„ÄÇ\n‰∏Ä‰∏™Â§öÊ®°ÂûãÂêàÂπ∂ÔºåÁªìÂêà‰∫ÜÂ§ö‰∏™LLaMA2 70BÂæÆË∞ÉÊ®°ÂûãÔºåÁî®‰∫éËßíËâ≤ÊâÆÊºîÂíåÂàõÊÑèÂ∑•‰Ωú„ÄÇÁõÆÊ†áÊòØÂàõÂª∫‰∏Ä‰∏™Â∞ÜÂàõÈÄ†Âäõ‰∏éÊô∫ËÉΩÁõ∏ÁªìÂêàÁöÑÊ®°ÂûãÔºå‰ª•ÊèêÂçá‰ΩìÈ™å„ÄÇ\n\n#merge #uncensored\n\n"},{"lang":"zh","group":"models","slug":"models/magnum-v2-72b","frontmatter":{"title":"Magnum v2 72B","meta_title":"Magnum v2 72B","description":"Magnum v2 72B","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"anthracite-org","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"id":"magnum-v2-72b","context":32768,"input":0.00000375,"output":0.0000045,"img":0,"request":0,"last_updated":"2024-11-11T03:09:19.000Z","slug":"models/magnum-v2-72b"},"content":"\nÊù•Ëá™[Goliath](https://openrouter.ai/alpindale/goliath-120b)ÁöÑÂà∂ÈÄ†ÂïÜÔºåMagnum 72BÊòØÁ¨¨‰∏É‰∏™Êó®Âú®ËææÂà∞Claude 3Ê®°ÂûãÁöÑÊï£ÊñáË¥®ÈáèÁöÑÊ®°ÂûãÁ≥ªÂàóÔºåÁâπÂà´ÊòØOpusÂíåSonnet„ÄÇ\n\nËØ•Ê®°ÂûãÂü∫‰∫é[Qwen2 72B](https://openrouter.ai/qwen/qwen-2-72b-instruct)ÔºåÂπ∂‰ΩøÁî®5500‰∏á‰∏™È´òÂ∫¶Á≠ñÂàíÁöÑËßíËâ≤ÊâÆÊºî(RP)Êï∞ÊçÆËøõË°åËÆ≠ÁªÉ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/magnum-v4-72b","frontmatter":{"title":"Magnum v4 72B","meta_title":"Magnum v4 72B","description":"Magnum v4 72B","date":"2024-10-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"anthracite-org","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"magnum-v4-72b","context":32768,"input":0.000001875,"output":0.00000225,"img":0,"request":0,"last_updated":"2024-11-04T12:39:55.000Z","slug":"models/magnum-v4-72b"},"content":"\nËøôÊòØ‰∏Ä‰∏™Á≥ªÂàóÊ®°ÂûãÔºåÊó®Âú®Â§çÂà∂Claude 3Ê®°ÂûãÁöÑÊï£ÊñáË¥®ÈáèÔºåÁâπÂà´ÊòØSonnetÂíåOpus„ÄÇ\n\nËØ•Ê®°ÂûãÊòØÂú®[Qwen2.5 72B]sÁöÑÂü∫Á°Ä‰∏äËøõË°åÂæÆË∞ÉÁöÑ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/ministral-3b","frontmatter":{"title":"Ministral 3B","meta_title":"Ministral 3B","description":"Ministral 3B","date":"2024-10-17T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Natural Language Processing","Data Science","Generative AI"],"draft":false,"id":"ministral-3b","context":128000,"input":4e-8,"output":4e-8,"img":0,"request":0,"last_updated":"2024-11-07T00:24:37.000Z","slug":"models/ministral-3b"},"content":"\nMinistral 3B ÊòØ‰∏Ä‰∏™ÈíàÂØπËÆæÂ§áÂíåËæπÁºòËÆ°ÁÆó‰ºòÂåñÁöÑ 3B ÂèÇÊï∞Ê®°Âûã„ÄÇÂÆÉÂú®Áü•ËØÜ„ÄÅÂ∏∏ËØÜÊé®ÁêÜÂíåÂáΩÊï∞Ë∞ÉÁî®ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåÂú®Â§ßÂ§öÊï∞Âü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫ÜÂÉè Mistral 7B ËøôÊ†∑ÁöÑÊõ¥Â§ßÊ®°Âûã„ÄÇÊîØÊåÅÊúÄÈïø 128k ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåÈùûÂ∏∏ÈÄÇÂêàÈ´òÊïàÊé®ÁêÜÁöÑ‰ª£ÁêÜÂ∑•‰ΩúÊµÅÂíå‰∏ì‰∏ö‰ªªÂä°ÁöÑÂçèË∞É„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/ministral-8b","frontmatter":{"title":"Ministral 8B","meta_title":"Ministral 8B","description":"Ministral 8B","date":"2024-10-17T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Technology","Machine Learning","Data Science","Generative AI","Ethics"],"draft":false,"id":"ministral-8b","context":128000,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-10-19T04:54:11.000Z","slug":"models/ministral-8b"},"content":"\nMinistral 8B ÊòØ‰∏Ä‰∏™ÂÖ∑Êúâ 8B ÂèÇÊï∞ÁöÑÊ®°ÂûãÔºåÈááÁî®Áã¨ÁâπÁöÑ‰∫§ÈîôÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõÊ®°ÂºèÔºå‰ª•ÂÆûÁé∞Êõ¥Âø´„ÄÅÊõ¥ËäÇÁúÅÂÜÖÂ≠òÁöÑÊé®ÁêÜ„ÄÇËØ•Ê®°Âûã‰∏ì‰∏∫ËæπÁºò‰ΩøÁî®Ê°à‰æãËÆæËÆ°ÔºåÊîØÊåÅÊúÄÈïø 128k ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåÂπ∂Âú®Áü•ËØÜÂíåÊé®ÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂÆÉÂú®‰Ωé‰∫é 10B ÁöÑÁ±ªÂà´‰∏≠‰ºò‰∫éÂêåÁ±ª‰∫ßÂìÅÔºåÈùûÂ∏∏ÈÄÇÂêà‰ΩéÂª∂Ëøü„ÄÅÊ≥®ÈáçÈöêÁßÅÁöÑÂ∫îÁî®„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/mistral-7b-instruct","frontmatter":{"title":"Mistral: Mistral 7B Instruct","meta_title":"Mistral: Mistral 7B Instruct","description":"Mistral: Mistral 7B Instruct","date":"2024-05-27T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"mistral-7b-instruct","context":32768,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-10-31T23:13:12.000Z","slug":"models/mistral-7b-instruct"},"content":"\n‰∏Ä‰∏™È´òÊÄßËÉΩ„ÄÅË°å‰∏öÊ†áÂáÜÁöÑ7.3BÂèÇÊï∞Ê®°ÂûãÔºåÈíàÂØπÈÄüÂ∫¶Âíå‰∏ä‰∏ãÊñáÈïøÂ∫¶ËøõË°å‰∫Ü‰ºòÂåñ„ÄÇ\n\n*Mistral 7B InstructÊúâÂ§ö‰∏™ÁâàÊú¨Âèò‰ΩìÔºåÊú¨ÊñáÊó®Âú®‰ªãÁªçÊúÄÊñ∞ÁâàÊú¨„ÄÇ*\n\n"},{"lang":"zh","group":"models","slug":"models/mistral-nemo","frontmatter":{"title":"Mistral: Mistral Nemo","meta_title":"Mistral: Mistral Nemo","description":"Mistral: Mistral Nemo","date":"2024-07-19T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Data Science"],"draft":false,"id":"mistral-nemo","context":128000,"input":1.3e-7,"output":1.3e-7,"img":0,"request":0,"last_updated":"2024-10-31T23:10:58.000Z","slug":"models/mistral-nemo"},"content":"\nÁî±Mistral‰∏éNVIDIAÂêà‰ΩúÊûÑÂª∫ÁöÑ12BÂèÇÊï∞Ê®°ÂûãÔºåÂÖ∑Êúâ128kÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶„ÄÇ\n\nËØ•Ê®°ÂûãÊòØÂ§öËØ≠Ë®ÄÁöÑÔºåÊîØÊåÅËã±ËØ≠„ÄÅÊ≥ïËØ≠„ÄÅÂæ∑ËØ≠„ÄÅË•øÁè≠ÁâôËØ≠„ÄÅÊÑèÂ§ßÂà©ËØ≠„ÄÅËë°ËêÑÁâôËØ≠„ÄÅ‰∏≠Êñá„ÄÅÊó•ËØ≠„ÄÅÈü©ËØ≠„ÄÅÈòøÊãâ‰ºØËØ≠ÂíåÂç∞Âú∞ËØ≠„ÄÇ\n\nÂÆÉÊîØÊåÅÂáΩÊï∞Ë∞ÉÁî®ÔºåÂπ∂Âú®Apache 2.0ËÆ∏ÂèØËØÅ‰∏ãÂèëÂ∏É„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/mistral-tiny","frontmatter":{"title":"Mistral Tiny","meta_title":"Mistral Tiny","description":"Mistral Tiny","date":"2024-01-10T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Machine Learning","Data Science","Generative AI","Chatbots"],"draft":false,"id":"mistral-tiny","context":32000,"input":2.5e-7,"output":2.5e-7,"img":0,"request":0,"last_updated":"2024-10-31T23:12:22.000Z","slug":"models/mistral-tiny"},"content":"\nËØ•Ê®°ÂûãÁõÆÂâçÁî± Mistral-7B-v0.2 È©±Âä®ÔºåÂπ∂ÁªìÂêà‰∫ÜÊØî [Mistral 7B](/mistralai/mistral-7b-instruct-v0.1) Êõ¥‚Äú‰ºòË∂ä‚ÄùÁöÑÂæÆË∞ÉÔºåÁÅµÊÑüÊù•Ëá™Á§æÂå∫ÁöÑÂ∑•‰Ωú„ÄÇÂÆÉÊúÄÈÄÇÂêàÁî®‰∫éÂ§ßÊâπÈáèÂ§ÑÁêÜ‰ªªÂä°ÔºåÂú®Ëøô‰∫õ‰ªªÂä°‰∏≠ÔºåÊàêÊú¨ÊòØ‰∏Ä‰∏™ÈáçË¶ÅÂõ†Á¥†Ôºå‰ΩÜÊé®ÁêÜËÉΩÂäõÂπ∂‰∏çÊòØÂÖ≥ÈîÆ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/mixtral-8x22b-instruct","frontmatter":{"title":"Mistral: Mixtral 8x22B Instruct","meta_title":"Mistral: Mixtral 8x22B Instruct","description":"Mistral: Mixtral 8x22B Instruct","date":"2024-04-17T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Programming","Natural Language Processing","Machine Learning","Data Science","Generative AI"],"draft":false,"is_recommended":false,"id":"mixtral-8x22b-instruct","context":65536,"input":9e-7,"output":9e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:21:32.000Z","slug":"models/mixtral-8x22b-instruct"},"content":"\nMistralÁöÑÂÆòÊñπÊåá‰ª§ÂæÆË∞ÉÁâàÊú¨[Mixtral 8x22B](/mistralai/mixtral-8x22b)„ÄÇÂÆÉ‰ΩøÁî®141B‰∏≠ÁöÑ39BÊ¥ªË∑ÉÂèÇÊï∞Ôºå‰∏∫ÂÖ∂ËßÑÊ®°Êèê‰æõÊó†‰∏é‰º¶ÊØîÁöÑÊàêÊú¨ÊïàÁõä„ÄÇÂÆÉÁöÑ‰ºòÁÇπÂåÖÊã¨Ôºö\n- Âº∫Â§ßÁöÑÊï∞Â≠¶„ÄÅÁºñÁ†ÅÂíåÊé®ÁêÜËÉΩÂäõ\n- Â§ß‰∏ä‰∏ãÊñáÈïøÂ∫¶Ôºà64kÔºâ\n- ÊµÅÂà©ÁöÑËã±ËØ≠„ÄÅÊ≥ïËØ≠„ÄÅÊÑèÂ§ßÂà©ËØ≠„ÄÅÂæ∑ËØ≠ÂíåË•øÁè≠ÁâôËØ≠\n\nÂú®ÂèëÂ∏ÉÂÖ¨Âëä‰∏≠Êü•ÁúãÂü∫ÂáÜÊµãËØï[ËøôÈáå](https://mistral.ai/news/mixtral-8x22b/)„ÄÇ\n#moe\n\n"},{"lang":"zh","group":"models","slug":"models/mixtral-8x7b","frontmatter":{"title":"Mixtral 8x7B (base)","meta_title":"Mixtral 8x7B (base)","description":"Mixtral 8x7B (base)","date":"2023-12-10T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text 2 text"],"author":"mistralai","tags":["Generative AI","Machine Learning","Data Science","Programming","Technology/Web"],"draft":false,"is_recommended":true,"id":"mixtral-8x7b","context":32768,"input":5.4e-7,"output":5.4e-7,"img":0,"request":0,"last_updated":"2024-11-14T08:22:09.000Z","slug":"models/mixtral-8x7b"},"content":"\n‰∏Ä‰∏™Áî±Mistral AIÂºÄÂèëÁöÑÈ¢ÑËÆ≠ÁªÉÁîüÊàêÁ®ÄÁñè‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºåÂåÖÂê´8‰∏™‰∏ìÂÆ∂ÔºàÂâçÈ¶àÁΩëÁªúÔºâÔºåÊÄªËÆ°47BÂèÇÊï∞„ÄÇÂü∫Á°ÄÊ®°ÂûãÔºàÊú™ÈíàÂØπÊåá‰ª§ËøõË°åÂæÆË∞ÉÔºâ - ËØ∑ÂèÇËßÅ[Mixtral 8x7B Instruct](/mistralai/mixtral-8x7b-instruct)‰ª•Ëé∑ÂèñÁªèËøáÊåá‰ª§ÂæÆË∞ÉÁöÑÊ®°Âûã„ÄÇ\n\n#moe\n\n"},{"lang":"zh","group":"models","slug":"models/mn-inferor-12b","frontmatter":{"title":"Mistral Nemo Inferor 12B","meta_title":"Mistral Nemo Inferor 12B","description":"Mistral Nemo Inferor 12B","date":"2024-11-13T02:20:28.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"infermatic","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"id":"mn-inferor-12b","context":32000,"input":2.5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T02:10:35.000Z","slug":"models/mn-inferor-12b"},"content":"\nInferor ÊòØÈ°∂Á∫ßËßíËâ≤ÊâÆÊºîÊ®°ÂûãÁöÑÂêàÂπ∂‰ΩìÔºå‰∏ìÊ≥®‰∫éÊ≤âÊµ∏ÂºèÂèô‰∫ãÂíåÊïÖ‰∫ãËÆ≤Ëø∞„ÄÇ\n\nËØ•Ê®°Âûã‰ΩøÁî® [Model Stock](https://arxiv.org/abs/2403.19522) ÂêàÂπ∂ÊñπÊ≥ïÔºåÂü∫‰∫é [anthracite-org/magnum-v4-12b](https://openrouter.ai/anthracite-org/magnum-v4-72b) ËøõË°åÂêàÂπ∂„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/mn-starcannon-12b","frontmatter":{"title":"Mistral Nemo 12B Starcannon","meta_title":"Mistral Nemo 12B Starcannon","description":"Mistral Nemo 12B Starcannon","date":"2024-08-13T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"aetherwiing","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"mn-starcannon-12b","context":12000,"input":0.000002,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:16:53.000Z","slug":"models/mn-starcannon-12b"},"content":"\nStarcannon 12B ÊòØ‰∏Ä‰∏™ÂàõÊÑèËßíËâ≤ÊâÆÊºîÂíåÊïÖ‰∫ãÂÜô‰ΩúÊ®°ÂûãÔºåÂü∫‰∫é [nothingiisreal/mn-celeste-12b](https://openrouter.ai/nothingiisreal/mn-celeste-12b) Âπ∂‰ΩøÁî® [intervitens/mini-magnum-12b-v1.1](https://huggingface.co/intervitens/mini-magnum-12b-v1.1) ÂêàÂπ∂ÔºåÈááÁî® [TIES](https://arxiv.org/abs/2306.01708) ÊñπÊ≥ï„ÄÇ\n\nËôΩÁÑ∂Êï¥‰Ωì‰∏äÊõ¥Á±ª‰ºº‰∫é MagnumÔºå‰ΩÜËØ•Ê®°Âûã‰ªçÁÑ∂ÈùûÂ∏∏ÂÖ∑ÊúâÂàõÊÑèÔºåÂÜô‰ΩúÈ£éÊ†ºÊÑâÊÇ¶„ÄÇÊé®ËçêÁªôÈÇ£‰∫õÂ∏åÊúõËé∑ÂæóÊØî Magnum Êõ¥Â§öÂèòÂåñÔºåÂêåÊó∂ÂèàÂ∏åÊúõÊØî Celeste Êõ¥ÂÜóÈïøÁöÑÊï£ÊñáÁöÑ‰∫∫„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/mythomax-l2-13b","frontmatter":{"title":"MythoMax 13B","meta_title":"MythoMax 13B","description":"MythoMax 13B","date":"2023-07-02T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"gryphe","tags":["Roleplay","Programming","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"id":"mythomax-l2-13b","context":4096,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-10-28T13:10:41.000Z","slug":"models/mythomax-l2-13b"},"content":"\nLlama 2 13B ÁöÑÊÄßËÉΩÊúÄÈ´ò‰∏îÊúÄÂèóÊ¨¢ËøéÁöÑÂæÆË∞É‰πã‰∏ÄÔºåÂÖ∑Êúâ‰∏∞ÂØåÁöÑÊèèËø∞ÂíåËßíËâ≤ÊâÆÊºî„ÄÇ #merge\n\n"},{"lang":"zh","group":"models","slug":"models/o1-mini","frontmatter":{"title":"OpenAI: o1-mini","meta_title":"OpenAI: o1-mini","description":"OpenAI: o1-mini","date":"2024-09-12T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"openai","tags":["Programming","Science","Natural Language Processing","Machine Learning","Data Science"],"draft":false,"id":"o1-mini","context":128000,"input":0.000003,"output":0.000012,"img":0,"request":0,"last_updated":"2024-09-12T00:00:00.000Z","slug":"models/o1-mini"},"content":"\nOpenAIÊúÄÊñ∞‰∏îÊúÄÂº∫Â§ßÁöÑÊ®°ÂûãÁ≥ªÂàóo1Êó®Âú®Âú®ÂìçÂ∫î‰πãÂâçËä±Êõ¥Â§öÊó∂Èó¥ÊÄùËÄÉ„ÄÇ\n\no1Ê®°ÂûãÁªèËøá‰ºòÂåñÔºåÈÄÇÁî®‰∫éÊï∞Â≠¶„ÄÅÁßëÂ≠¶„ÄÅÁºñÁ®ãÂèäÂÖ∂‰ªñSTEMÁõ∏ÂÖ≥‰ªªÂä°„ÄÇÂÆÉ‰ª¨Âú®Áâ©ÁêÜ„ÄÅÂåñÂ≠¶ÂíåÁîüÁâ©Â≠¶ÁöÑÂü∫ÂáÜÊµãËØï‰∏≠ÂßãÁªàÂ±ïÁé∞Âá∫ÂçöÂ£´Á∫ßÁöÑÂáÜÁ°ÆÊÄß„ÄÇ‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØÔºåËØ∑Êü•Áúã[ÂèëÂ∏ÉÂÖ¨Âëä](https://openai.com/o1)„ÄÇ\n\nÊ≥®ÊÑèÔºöËØ•Ê®°ÂûãÁõÆÂâçÂ§Ñ‰∫éÂÆûÈ™åÈò∂ÊÆµÔºå‰∏çÈÄÇÂêàÁîü‰∫ß‰ΩøÁî®ÔºåÂπ∂ÂèØËÉΩÂèóÂà∞‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/o1-preview","frontmatter":{"title":"OpenAI: o1-preview","meta_title":"OpenAI: o1-preview","description":"OpenAI: o1-preview","date":"2024-09-12T00:00:00.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"openai","tags":["Programming","Science","Natural Language Processing","Machine Learning","Data Science"],"draft":false,"id":"o1-preview","context":128000,"input":0.000015,"output":0.00006,"img":0,"request":0,"last_updated":"2024-09-12T00:00:00.000Z","slug":"models/o1-preview"},"content":"\nOpenAIÊúÄÊñ∞‰∏îÊúÄÂº∫Â§ßÁöÑÊ®°ÂûãÁ≥ªÂàóo1Êó®Âú®Âú®ÂìçÂ∫î‰πãÂâçËä±Êõ¥Â§öÊó∂Èó¥ÊÄùËÄÉ„ÄÇ\n\no1Ê®°ÂûãÁªèËøá‰ºòÂåñÔºåÈÄÇÁî®‰∫éÊï∞Â≠¶„ÄÅÁßëÂ≠¶„ÄÅÁºñÁ®ãÂíåÂÖ∂‰ªñSTEMÁõ∏ÂÖ≥‰ªªÂä°„ÄÇÂÆÉ‰ª¨Âú®Áâ©ÁêÜ„ÄÅÂåñÂ≠¶ÂíåÁîüÁâ©Â≠¶ÁöÑÂü∫ÂáÜÊµãËØï‰∏≠ÂßãÁªàË°®Áé∞Âá∫ÂçöÂ£´Á∫ßÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊúâÂÖ≥Êõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ[ÂèëÂ∏ÉÂÖ¨Âëä](https://openai.com/o1)„ÄÇ\n\nÊ≥®ÊÑèÔºöËØ•Ê®°ÂûãÁõÆÂâçÂ§Ñ‰∫éÂÆûÈ™åÈò∂ÊÆµÔºå‰∏çÈÄÇÂêàÁîü‰∫ß‰ΩøÁî®Ê°à‰æãÔºåÂπ∂‰∏îÂèØËÉΩ‰ºöÂèóÂà∞‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/openai-gpt-4o-mini","frontmatter":{"title":"OpenAI: GPT-4o-Mini Official","meta_title":"OpenAI: GPT-4o-Mini Official","description":"OpenAI: GPT-4o-Mini Official","date":"2024-10-26T09:00:07.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"gpt-4o-mini","tags":["Generative AI","Natural Language Processing","Machine Learning","Technology","Chatbots"],"draft":false,"is_recommended":false,"id":"openai/gpt-4o-mini","context":128000,"input":1.5e-7,"output":6e-7,"img":0.0036125,"request":0,"last_updated":"2024-11-14T09:46:04.000Z","slug":"models/openai-gpt-4o-mini"},"content":"\nGPT-4o mini ÊòØ OpenAI ÊúÄÊñ∞ÁöÑÊ®°ÂûãÔºåÁªß [GPT-4 Omni](/openai/gpt-4o) ‰πãÂêéÊé®Âá∫ÔºåÊîØÊåÅÊñáÊú¨ÂíåÂõæÂÉèËæìÂÖ•ÔºåÂπ∂ÁîüÊàêÊñáÊú¨ËæìÂá∫„ÄÇ\n\n‰Ωú‰∏∫‰ªñ‰ª¨ÊúÄÂÖàËøõÁöÑÂ∞èÂûãÊ®°ÂûãÔºåÂÆÉÁöÑ‰ª∑Ê†ºÊØîÂÖ∂‰ªñÊúÄËøëÁöÑÂâçÊ≤øÊ®°Âûã‰æøÂÆú‰∫ÜËÆ∏Â§öÔºå‰∏îÊØî [GPT-3.5 Turbo](/openai/gpt-3.5-turbo) ‰æøÂÆúË∂ÖËøá 60%„ÄÇÂÆÉ‰øùÊåÅ‰∫Ü SOTA Êô∫ËÉΩÔºåÂêåÊó∂Âú®ÊàêÊú¨ÊïàÁõä‰∏äÊòæËëóÊõ¥È´ò„ÄÇ\n\nGPT-4o mini Âú® MMLU ‰∏äÂèñÂæó‰∫Ü 82% ÁöÑÂàÜÊï∞ÔºåÁõÆÂâçÂú®ËÅäÂ§©ÂÅèÂ•Ω [Â∏∏ËßÅÊéíË°åÊ¶ú](https://arena.lmsys.org/) ‰∏äÁöÑÊéíÂêçÈ´ò‰∫é GPT-4„ÄÇ\n\nÊü•Áúã [ÂèëÂ∏ÉÂÖ¨Âëä](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) ‰ª•‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/openai-gpt-4o","frontmatter":{"title":"OpenAI: GPT-4o Official","meta_title":"OpenAI: GPT-4o Official","description":"OpenAI: GPT-4o Official","date":"2024-11-14T02:53:29.000Z","image":"https://img.rifx.online/logo/openai.svg","categories":["text 2 text"],"author":"gpt-4o","tags":["Generative AI","Natural Language Processing","Technology","Chatbots","Machine Learning"],"draft":false,"is_recommended":false,"id":"openai/gpt-4o","context":128000,"input":0.0000025,"output":0.00001,"img":0.0036125,"request":0,"last_updated":"2024-11-14T09:45:25.000Z","slug":"models/openai-gpt-4o"},"content":"\nGPT-4oÔºà‚Äúo‚Äù‰ª£Ë°®‚ÄúÂÖ®ËÉΩ‚ÄùÔºâÊòØOpenAIÊúÄÊñ∞ÁöÑAIÊ®°ÂûãÔºåÊîØÊåÅÊñáÊú¨ÂíåÂõæÂÉèËæìÂÖ•ÔºåÂπ∂Êèê‰æõÊñáÊú¨ËæìÂá∫„ÄÇÂÆÉ‰øùÊåÅ‰∫Ü[GPT-4 Turbo](/openai/gpt-4-turbo)ÁöÑÊô∫ËÉΩÊ∞¥Âπ≥ÔºåÂêåÊó∂ÈÄüÂ∫¶ÊòØÂÖ∂‰∏§ÂÄçÔºåÊàêÊú¨ÊïàÁõäÊèêÈ´ò‰∫Ü50%„ÄÇGPT-4oËøòÂú®Â§ÑÁêÜÈùûËã±ËØ≠ËØ≠Ë®ÄÂíåÂ¢ûÂº∫ËßÜËßâËÉΩÂäõÊñπÈù¢Êèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ\n\n‰∏∫‰∫Ü‰∏éÂÖ∂‰ªñÊ®°ÂûãËøõË°åÂü∫ÂáÜÊµãËØïÔºåÂÆÉÊõæË¢´Áß∞‰∏∫[\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n"},{"lang":"zh","group":"models","slug":"models/openchat-7b","frontmatter":{"title":"OpenChat 3.5 7B","meta_title":"OpenChat 3.5 7B","description":"OpenChat 3.5 7B","date":"2023-11-28T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"openchat","tags":["Programming","Natural Language Processing","Machine Learning","Open Source","Generative AI"],"draft":false,"id":"openchat-7b","context":8192,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-11-07T09:39:42.000Z","slug":"models/openchat-7b"},"content":"\nOpenChat 7B ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êËØ≠Ë®ÄÊ®°ÂûãÂ∫ìÔºåÈááÁî®‚ÄúC-RLFTÔºàÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÔºâ‚ÄùÁ≠ñÁï•ËøõË°å‰∫ÜÂæÆË∞ÉÔºåËØ•Á≠ñÁï•ÂèóÂà∞Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†ÁöÑÂêØÂèë„ÄÇÂÆÉÂú®Ê≤°ÊúâÂÅèÂ•ΩÊ†áÁ≠æÁöÑÊ∑∑ÂêàË¥®ÈáèÊï∞ÊçÆ‰∏äËøõË°å‰∫ÜËÆ≠ÁªÉ„ÄÇ\n\n- ÂØπ‰∫éÂú® Mistral 7B ‰∏äÂæÆË∞ÉÁöÑ OpenChatÔºåËØ∑Êü•Áúã [OpenChat 7B](/openchat/openchat-7b)„ÄÇ\n- ÂØπ‰∫éÂú® Llama 8B ‰∏äÂæÆË∞ÉÁöÑ OpenChatÔºåËØ∑Êü•Áúã [OpenChat 8B](/openchat/openchat-8b)„ÄÇ\n\n#open-source\n\n"},{"lang":"zh","group":"models","slug":"models/palm-2-chat-bison-32k","frontmatter":{"title":"Google: PaLM 2 Chat 32k","meta_title":"Google: PaLM 2 Chat 32k","description":"Google: PaLM 2 Chat 32k","date":"2023-11-03T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Natural Language Processing","Programming","Technology","Chatbots","Generative AI"],"draft":false,"id":"palm-2-chat-bison-32k","context":32760,"input":0.000001,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:15:52.000Z","slug":"models/palm-2-chat-bison-32k"},"content":"\nPaLM 2 ÊòØË∞∑Ê≠åÊé®Âá∫ÁöÑ‰∏ÄÁßçËØ≠Ë®ÄÊ®°ÂûãÔºåÂÖ∑Â§áÊõ¥Âº∫ÁöÑÂ§öËØ≠Ë®Ä„ÄÅÊé®ÁêÜÂíåÁºñÁ†ÅËÉΩÂäõ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/palm-2-codechat-bison-32k","frontmatter":{"title":"Google: PaLM 2 Code Chat 32k","meta_title":"Google: PaLM 2 Code Chat 32k","description":"Google: PaLM 2 Code Chat 32k","date":"2023-11-03T00:00:00.000Z","image":"https://img.rifx.online/logo/google.svg","categories":["text 2 text"],"author":"google","tags":["Programming","Chatbots","Natural Language Processing","Generative AI","Technology/Web"],"draft":false,"id":"palm-2-codechat-bison-32k","context":32760,"input":0.000001,"output":0.000002,"img":0,"request":0,"last_updated":"2024-11-11T03:16:01.000Z","slug":"models/palm-2-codechat-bison-32k"},"content":"\nPaLM 2 ÈíàÂØπÂ∏ÆÂä©Ëß£ÂÜ≥‰ª£Á†ÅÁõ∏ÂÖ≥ÈóÆÈ¢òÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÂØπËØùËøõË°å‰∫ÜÂæÆË∞É„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/phi-3-medium-128k-instruct","frontmatter":{"title":"Phi-3 Medium 128K Instruct","meta_title":"Phi-3 Medium 128K Instruct","description":"Phi-3 Medium 128K Instruct","date":"2024-05-24T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Natural Language Processing","Machine Learning","Programming","Data Science","Generative AI"],"draft":false,"id":"phi-3-medium-128k-instruct","context":128000,"input":0.000001,"output":0.000001,"img":0,"request":0,"last_updated":"2024-11-11T03:17:38.000Z","slug":"models/phi-3-medium-128k-instruct"},"content":"\nPhi-3 128K Medium ÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑ 140 ‰∫øÂèÇÊï∞Ê®°ÂûãÔºåÊó®Âú®ÂÆûÁé∞È´òÁ∫ßËØ≠Ë®ÄÁêÜËß£„ÄÅÊé®ÁêÜÂíåÊåá‰ª§Ë∑üÈöè„ÄÇÈÄöËøáÁõëÁù£ÂæÆË∞ÉÂíåÂÅèÂ•ΩË∞ÉÊï¥ËøõË°å‰ºòÂåñÔºåÂÆÉÂú®Ê∂âÂèäÂ∏∏ËØÜ„ÄÅÊï∞Â≠¶„ÄÅÈÄªËæëÊé®ÁêÜÂíå‰ª£Á†ÅÂ§ÑÁêÜÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\nÂú®ÂèëÂ∏ÉÊó∂ÔºåPhi-3 Medium Âú®ËΩªÈáèÁ∫ßÊ®°Âûã‰∏≠Â±ïÁ§∫‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂú® MMLU-Pro ËØÑ‰º∞‰∏≠ÔºåËØ•Ê®°ÂûãÁîöËá≥Êé•Ëøë Llama3 70B ÁöÑÊÄßËÉΩÊ∞¥Âπ≥„ÄÇ\n\nÂØπ‰∫é 4k ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåËØ∑Â∞ùËØï [Phi-3 Medium 4K](/microsoft/phi-3-medium-4k-instruct).\n\n"},{"lang":"zh","group":"models","slug":"models/phi-3-mini-128k-instruct","frontmatter":{"title":"Phi-3 Mini 128K Instruct","meta_title":"Phi-3 Mini 128K Instruct","description":"Phi-3 Mini 128K Instruct","date":"2024-05-26T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Natural Language Processing","Machine Learning","Programming","Data Science","Generative AI"],"draft":false,"id":"phi-3-mini-128k-instruct","context":128000,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:17:47.000Z","slug":"models/phi-3-mini-128k-instruct"},"content":"\nPhi-3 Mini ÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑ 3.8B ÂèÇÊï∞Ê®°ÂûãÔºåÊó®Âú®ÂÆûÁé∞È´òÁ∫ßËØ≠Ë®ÄÁêÜËß£„ÄÅÊé®ÁêÜÂíåÊåá‰ª§Ë∑üÈöè„ÄÇÈÄöËøáÁõëÁù£ÂæÆË∞ÉÂíåÂÅèÂ•ΩË∞ÉÊï¥ËøõË°å‰ºòÂåñÔºåÂÆÉÂú®Ê∂âÂèäÂ∏∏ËØÜ„ÄÅÊï∞Â≠¶„ÄÅÈÄªËæëÊé®ÁêÜÂíå‰ª£Á†ÅÂ§ÑÁêÜÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ\n\nÂú®ÂèëÂ∏ÉÊó∂ÔºåPhi-3 Medium Âú®ËΩªÈáèÁ∫ßÊ®°Âûã‰∏≠Â±ïÁ§∫‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇËØ•Ê®°ÂûãÊòØÈùôÊÄÅÁöÑÔºåËÆ≠ÁªÉ‰∫éÊà™Ê≠¢Âà∞ 2023 Âπ¥ 10 ÊúàÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÈõÜ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/phi-35-mini-128k-instruct","frontmatter":{"title":"Phi-3.5 Mini 128K Instruct","meta_title":"Phi-3.5 Mini 128K Instruct","description":"Phi-3.5 Mini 128K Instruct","date":"2024-08-21T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Programming","Machine Learning","Natural Language Processing","Data Science","Generative AI"],"draft":false,"id":"phi-3.5-mini-128k-instruct","context":128000,"input":1e-7,"output":1e-7,"img":0,"request":0,"last_updated":"2024-11-01T04:17:17.000Z","slug":"models/phi-35-mini-128k-instruct"},"content":"\nPhi-3.5 Ê®°ÂûãÊòØËΩªÈáèÁ∫ßÁöÑ„ÄÅÂÖàËøõÁöÑÂºÄÊîæÊ®°Âûã„ÄÇËøô‰∫õÊ®°Âûã‰ΩøÁî® Phi-3 Êï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉÔºåËØ•Êï∞ÊçÆÈõÜÂåÖÊã¨ÂêàÊàêÊï∞ÊçÆÂíåÁªèËøáÁ≠õÈÄâÁöÑÂÖ¨ÂÖ±ÁΩëÁ´ôÊï∞ÊçÆÔºåÈáçÁÇπÂÖ≥Ê≥®È´òË¥®ÈáèÂíåÊé®ÁêÜÂØÜÈõÜÁöÑÁâπÊÄß„ÄÇPhi-3.5 Mini ‰ΩøÁî® 3.8B ÂèÇÊï∞ÔºåÊòØ‰∏ÄÁßç‰ªÖËß£Á†ÅÁöÑÁ®†ÂØÜÂèòÊç¢Âô®Ê®°ÂûãÔºå‰ΩøÁî®‰∏é [Phi-3 Mini](/microsoft/phi-3-mini-128k-instruct) Áõ∏ÂêåÁöÑÂàÜËØçÂô®„ÄÇ\n\nËøô‰∫õÊ®°ÂûãÁªèËøá‰∏•Ê†ºÁöÑÂ¢ûÂº∫ËøáÁ®ãÔºåÁªìÂêà‰∫ÜÁõëÁù£ÂæÆË∞É„ÄÅÈÇªËøëÁ≠ñÁï•‰ºòÂåñÂíåÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºå‰ª•Á°Æ‰øùÁ≤æÁ°ÆÁöÑÊåá‰ª§ÈÅµÂæ™ÂíåÂº∫Â§ßÁöÑÂÆâÂÖ®Êé™ÊñΩ„ÄÇÂú®ÈíàÂØπÊµãËØïÂ∏∏ËØÜ„ÄÅËØ≠Ë®ÄÁêÜËß£„ÄÅÊï∞Â≠¶„ÄÅ‰ª£Á†Å„ÄÅÈïø‰∏ä‰∏ãÊñáÂíåÈÄªËæëÊé®ÁêÜÁöÑÂü∫ÂáÜËØÑ‰º∞‰∏≠ÔºåPhi-3.5 Ê®°ÂûãÂú®ÂèÇÊï∞Â∞ë‰∫é 130 ‰∫øÁöÑÊ®°Âûã‰∏≠Â±ïÁ§∫‰∫ÜÂº∫Â§ß‰∏îÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/pixtral-12b","frontmatter":{"title":"Mistral: Pixtral 12B","meta_title":"Mistral: Pixtral 12B","description":"Mistral: Pixtral 12B","date":"2024-09-10T00:00:00.000Z","image":"https://img.rifx.online/logo/mistral.png","categories":["text image 2 text"],"author":"mistralai","tags":["Natural Language Processing","Machine Learning","Technology","Generative AI","Computer Vision"],"draft":false,"id":"pixtral-12b","context":4096,"input":1e-7,"output":1e-7,"img":0.0001445,"request":0,"last_updated":"2024-11-11T03:10:29.000Z","slug":"models/pixtral-12b"},"content":"\nMistral AI ÁöÑÁ¨¨‰∏Ä‰∏™ÂõæÂÉèÂà∞ÊñáÊú¨Ê®°Âûã„ÄÇÊ†πÊçÆ‰ªñ‰ª¨ÁöÑ‰º†ÁªüÔºåÂÖ∂ÊùÉÈáçÈÄöËøá torrent ÂèëÂ∏ÉÔºö https://x.com/mistralai/status/1833758285167722836\n\n"},{"lang":"zh","group":"models","slug":"models/qwen-2-7b-instruct","frontmatter":{"title":"Qwen 2 7B Instruct","meta_title":"Qwen 2 7B Instruct","description":"Qwen 2 7B Instruct","date":"2024-07-16T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Natural Language Processing","Programming","Machine Learning","Data Science","Ethics"],"draft":false,"id":"qwen-2-7b-instruct","context":32768,"input":5.4e-8,"output":5.4e-8,"img":0,"request":0,"last_updated":"2024-07-16T00:00:00.000Z","slug":"models/qwen-2-7b-instruct"},"content":"\nQwen2 7B ÊòØ‰∏Ä‰∏™Âü∫‰∫éÂèòÊç¢Âô®ÁöÑÊ®°ÂûãÔºåÊìÖÈïøËØ≠Ë®ÄÁêÜËß£„ÄÅÂ§öËØ≠Ë®ÄËÉΩÂäõ„ÄÅÁºñÁ†Å„ÄÅÊï∞Â≠¶ÂíåÊé®ÁêÜ„ÄÇ\n\nÂÆÉÂÖ∑Êúâ SwiGLU ÊøÄÊ¥ª„ÄÅÊ≥®ÊÑèÂäõ QKV ÂÅèÁΩÆÂíåÁªÑÊü•ËØ¢Ê≥®ÊÑèÂäõ„ÄÇÂÆÉÂú®Â§ßÈáèÊï∞ÊçÆ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂ÁªèËøáÁõëÁù£ÂæÆË∞ÉÂíåÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖÊ≠§ [ÂçöÂÆ¢ÊñáÁ´†](https://qwenlm.github.io/blog/qwen2/) Âíå [GitHub ‰ªìÂ∫ì](https://github.com/QwenLM/Qwen2)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™ [Âêå‰πâÂçÉÈóÆËÆ∏ÂèØËØÅÂçèËÆÆ](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/qwen-2-vl-72b-instruct","frontmatter":{"title":"Qwen2-VL 72B Instruct","meta_title":"Qwen2-VL 72B Instruct","description":"Qwen2-VL 72B Instruct","date":"2024-09-18T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text image 2 text"],"author":"qwen","tags":["Natural Language Processing","Computer Vision","Robotics","Machine Learning"],"draft":false,"id":"qwen-2-vl-72b-instruct","context":32768,"input":4e-7,"output":4e-7,"img":0.000578,"request":0,"last_updated":"2024-09-18T00:00:00.000Z","slug":"models/qwen-2-vl-72b-instruct"},"content":"\nQwen2 VL 72B ÊòØÊù•Ëá™ Qwen Team ÁöÑÂ§öÊ®°ÊÄÅ LLMÔºåÂÖ∑Êúâ‰ª•‰∏ãÂÖ≥ÈîÆÂ¢ûÂº∫ÂäüËÉΩÔºö\n\n- ÂØπÂêÑÁßçÂàÜËæ®ÁéáÂíåÊØî‰æãÂõæÂÉèÁöÑÊúÄÂÖàËøõÁêÜËß£ÔºöQwen2-VL Âú®ËßÜËßâÁêÜËß£Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂåÖÊã¨ MathVista„ÄÅDocVQA„ÄÅRealWorldQA„ÄÅMTVQA Á≠â„ÄÇ\n\n- ÁêÜËß£Ë∂ÖËøá 20 ÂàÜÈíüÁöÑËßÜÈ¢ëÔºöQwen2-VL ÂèØ‰ª•ÁêÜËß£Ë∂ÖËøá 20 ÂàÜÈíüÁöÑËßÜÈ¢ëÔºå‰ª•ËøõË°åÈ´òË¥®ÈáèÁöÑËßÜÈ¢ëÈóÆÁ≠î„ÄÅÂØπËØù„ÄÅÂÜÖÂÆπÂàõ‰ΩúÁ≠â„ÄÇ\n\n- ËÉΩÂ§üÊìç‰ΩúÊÇ®ÁöÑÊâãÊú∫„ÄÅÊú∫Âô®‰∫∫Á≠âÁöÑÊô∫ËÉΩ‰ΩìÔºöÂá≠ÂÄüÂ§çÊùÇÊé®ÁêÜÂíåÂÜ≥Á≠ñËÉΩÂäõÔºåQwen2-VL ÂèØ‰ª•‰∏éÊâãÊú∫„ÄÅÊú∫Âô®‰∫∫Á≠âËÆæÂ§áÈõÜÊàêÔºåÂÆûÁé∞Âü∫‰∫éËßÜËßâÁéØÂ¢ÉÂíåÊñáÊú¨Êåá‰ª§ÁöÑËá™Âä®Êìç‰Ωú„ÄÇ\n\n- Â§öËØ≠Ë®ÄÊîØÊåÅÔºö‰∏∫‰∫ÜÊúçÂä°ÂÖ®ÁêÉÁî®Êà∑ÔºåÈô§‰∫ÜËã±ËØ≠Âíå‰∏≠ÊñáÔºåQwen2-VL Áé∞Âú®ËøòÊîØÊåÅÁêÜËß£ÂõæÂÉè‰∏≠‰∏çÂêåËØ≠Ë®ÄÁöÑÊñáÊú¨ÔºåÂåÖÊã¨Â§ßÂ§öÊï∞Ê¨ßÊ¥≤ËØ≠Ë®Ä„ÄÅÊó•ËØ≠„ÄÅÈü©ËØ≠„ÄÅÈòøÊãâ‰ºØËØ≠„ÄÅË∂äÂçóËØ≠Á≠â„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖÊ≠§ [ÂçöÂÆ¢ÊñáÁ´†](https://qwenlm.github.io/blog/qwen2-vl/) Âíå [GitHub ‰ªìÂ∫ì](https://github.com/QwenLM/Qwen2-VL)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÂèó [ÈÄö‰πâÂçÉÈóÆËÆ∏ÂèØÂçèËÆÆ](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE) ÁöÑÁ∫¶Êùü„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/qwen-2-vl-7b-instruct","frontmatter":{"title":"Qwen2-VL 7B Instruct","meta_title":"Qwen2-VL 7B Instruct","description":"Qwen2-VL 7B Instruct","date":"2024-08-28T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text image 2 text"],"author":"qwen","tags":["Natural Language Processing","Computer Vision","Robotics","Multimodal AI","Generative AI"],"draft":false,"id":"qwen-2-vl-7b-instruct","context":32768,"input":1e-7,"output":1e-7,"img":0.0001445,"request":0,"last_updated":"2024-11-11T03:13:01.000Z","slug":"models/qwen-2-vl-7b-instruct"},"content":"\nQwen2 VL 7B ÊòØÊù•Ëá™ Qwen Âõ¢ÈòüÁöÑÂ§öÊ®°ÊÄÅ LLMÔºåÂÖ∑Êúâ‰ª•‰∏ãÂÖ≥ÈîÆÂ¢ûÂº∫ÂäüËÉΩÔºö\n\n- ÂØπÂêÑÁßçÂàÜËæ®ÁéáÂíåÊØî‰æãÁöÑÂõæÂÉèÁöÑÊúÄÂÖàËøõÁêÜËß£ÔºöQwen2-VL Âú®ËßÜËßâÁêÜËß£Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂåÖÊã¨ MathVista„ÄÅDocVQA„ÄÅRealWorldQA„ÄÅMTVQA Á≠â„ÄÇ\n\n- ÁêÜËß£Ë∂ÖËøá 20 ÂàÜÈíüÁöÑËßÜÈ¢ëÔºöQwen2-VL ËÉΩÂ§üÁêÜËß£Ë∂ÖËøá 20 ÂàÜÈíüÁöÑËßÜÈ¢ëÔºå‰ª•‰æøËøõË°åÈ´òË¥®ÈáèÁöÑËßÜÈ¢ëÈóÆÁ≠î„ÄÅÂØπËØù„ÄÅÂÜÖÂÆπÂàõ‰ΩúÁ≠â„ÄÇ\n\n- ËÉΩÂ§üÊìç‰ΩúÊâãÊú∫„ÄÅÊú∫Âô®‰∫∫Á≠âÁöÑ‰ª£ÁêÜÔºöÂá≠ÂÄüÂ§çÊùÇÊé®ÁêÜÂíåÂÜ≥Á≠ñËÉΩÂäõÔºåQwen2-VL ÂèØ‰ª•‰∏éÊâãÊú∫„ÄÅÊú∫Âô®‰∫∫Á≠âËÆæÂ§áÈõÜÊàêÔºåÂÆûÁé∞Âü∫‰∫éËßÜËßâÁéØÂ¢ÉÂíåÊñáÊú¨Êåá‰ª§ÁöÑËá™Âä®Êìç‰Ωú„ÄÇ\n\n- Â§öËØ≠Ë®ÄÊîØÊåÅÔºö‰∏∫‰∫ÜÊúçÂä°ÂÖ®ÁêÉÁî®Êà∑ÔºåÈô§‰∫ÜËã±ËØ≠Âíå‰∏≠ÊñáÔºåQwen2-VL Áé∞Âú®ËøòÊîØÊåÅÁêÜËß£ÂõæÂÉè‰∏≠‰∏çÂêåËØ≠Ë®ÄÁöÑÊñáÊú¨ÔºåÂåÖÊã¨Â§ßÂ§öÊï∞Ê¨ßÊ¥≤ËØ≠Ë®Ä„ÄÅÊó•ËØ≠„ÄÅÈü©ËØ≠„ÄÅÈòøÊãâ‰ºØËØ≠„ÄÅË∂äÂçóËØ≠Á≠â„ÄÇ\n\nÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖÊ≠§ [ÂçöÂÆ¢ÊñáÁ´†](https://qwenlm.github.io/blog/qwen2-vl/) Âíå [GitHub ‰ªìÂ∫ì](https://github.com/QwenLM/Qwen2-VL)„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂæ™ [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/qwen-25-72b-instruct","frontmatter":{"title":"Qwen2.5 72B Instruct","meta_title":"Qwen2.5 72B Instruct","description":"Qwen2.5 72B Instruct","date":"2024-09-19T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Programming","Natural Language Processing","Chatbots","Machine Learning","Data Science"],"draft":false,"id":"qwen-2.5-72b-instruct","context":131072,"input":3.5e-7,"output":4e-7,"img":0,"request":0,"last_updated":"2024-09-19T00:00:00.000Z","slug":"models/qwen-25-72b-instruct"},"content":"\nQwen2.5 72B ÊòØ Qwen Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞Á≥ªÂàó„ÄÇQwen2.5 Âú® Qwen2 ÁöÑÂü∫Á°Ä‰∏äÂ∏¶Êù•‰∫Ü‰ª•‰∏ãÊîπËøõÔºö\n\n- Áü•ËØÜÊòæËëóÂ¢ûÂä†ÔºåÂπ∂Âú®ÁºñÁ†ÅÂíåÊï∞Â≠¶ËÉΩÂäõ‰∏äÊúâ‰∫ÜÂæàÂ§ßÊèêÂçáÔºåËøôÂæóÁõä‰∫éÊàë‰ª¨Âú®Ëøô‰∫õÈ¢ÜÂüüÁöÑ‰∏ì‰∏ö‰∏ìÂÆ∂Ê®°Âûã„ÄÇ\n\n- Âú®ÈÅµÂæ™Êåá‰ª§„ÄÅÁîüÊàêÈïøÊñáÊú¨ÔºàË∂ÖËøá 8K tokensÔºâ„ÄÅÁêÜËß£ÁªìÊûÑÂåñÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåË°®Ê†ºÔºâ‰ª•ÂèäÁîüÊàêÁªìÊûÑÂåñËæìÂá∫ÔºàÁâπÂà´ÊòØ JSONÔºâÊñπÈù¢ÊúâÊòæËëóÊîπËøõ„ÄÇÂØπÁ≥ªÁªüÊèêÁ§∫ÁöÑÂ§öÊ†∑ÊÄßÊõ¥Âä†Âº∫ÈüßÔºåÂ¢ûÂº∫‰∫ÜËßíËâ≤ÊâÆÊºîÁöÑÂÆûÁé∞ÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊù°‰ª∂ËÆæÁΩÆ„ÄÇ\n\n- ÊîØÊåÅÊúÄÈïø 128K tokens ÁöÑÈïø‰∏ä‰∏ãÊñáÔºåÂπ∂ÂèØ‰ª•ÁîüÊàêÊúÄÂ§ö 8K tokens„ÄÇ\n\n- ÊîØÊåÅË∂ÖËøá 29 ÁßçËØ≠Ë®ÄÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊ≥ïËØ≠„ÄÅË•øÁè≠ÁâôËØ≠„ÄÅËë°ËêÑÁâôËØ≠„ÄÅÂæ∑ËØ≠„ÄÅÊÑèÂ§ßÂà©ËØ≠„ÄÅ‰øÑËØ≠„ÄÅÊó•ËØ≠„ÄÅÈü©ËØ≠„ÄÅË∂äÂçóËØ≠„ÄÅÊ≥∞ËØ≠„ÄÅÈòøÊãâ‰ºØËØ≠Á≠â„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂÆà [Âêå‰πâÂçÉÈóÆËÆ∏ÂèØÂçèËÆÆ](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/qwen-25-7b-instruct","frontmatter":{"title":"Qwen2.5 7B Instruct","meta_title":"Qwen2.5 7B Instruct","description":"Qwen2.5 7B Instruct","date":"2024-10-16T00:00:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Programming","Natural Language Processing","Chatbots","Machine Learning","Data Science"],"draft":false,"id":"qwen-2.5-7b-instruct","context":131072,"input":2.7e-7,"output":2.7e-7,"img":0,"request":0,"last_updated":"2024-10-16T00:00:00.000Z","slug":"models/qwen-25-7b-instruct"},"content":"\nQwen2.5 7B ÊòØ Qwen Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞Á≥ªÂàó„ÄÇQwen2.5 Âú® Qwen2 ÁöÑÂü∫Á°Ä‰∏äÂ∏¶Êù•‰∫Ü‰ª•‰∏ãÊîπËøõÔºö\n\n- Áü•ËØÜÊòæËëóÂ¢ûÂä†ÔºåÂπ∂Âú®ÁºñÁ†ÅÂíåÊï∞Â≠¶ÊñπÈù¢ÁöÑËÉΩÂäõÂ§ßÂπÖÊèêÂçáÔºåËøôÂæóÁõä‰∫éÊàë‰ª¨Âú®Ëøô‰∫õÈ¢ÜÂüüÁöÑ‰∏ì‰∏öÊ®°Âûã„ÄÇ\n\n- Âú®ÈÅµÂæ™Êåá‰ª§„ÄÅÁîüÊàêÈïøÊñáÊú¨ÔºàË∂ÖËøá 8K tokensÔºâ„ÄÅÁêÜËß£ÁªìÊûÑÂåñÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåË°®Ê†ºÔºâ‰ª•ÂèäÁîüÊàêÁªìÊûÑÂåñËæìÂá∫ÔºåÁâπÂà´ÊòØ JSON ÊñπÈù¢ÊúâÊòæËëóÊîπËøõ„ÄÇÂØπÁ≥ªÁªüÊèêÁ§∫ÁöÑÂ§öÊ†∑ÊÄßÊõ¥ÂÖ∑ÈüßÊÄßÔºåÂ¢ûÂº∫‰∫ÜËßíËâ≤ÊâÆÊºîÁöÑÂÆûÁé∞ÂíåËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÊù°‰ª∂ËÆæÁΩÆ„ÄÇ\n\n- ÈïøÊñáÊú¨ÊîØÊåÅÈ´òËææ 128K tokensÔºåÂπ∂‰∏îÂèØ‰ª•ÁîüÊàêÊúÄÂ§ö 8K tokens„ÄÇ\n\n- ÊîØÊåÅË∂ÖËøá 29 ÁßçËØ≠Ë®ÄÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊ≥ïÊñá„ÄÅË•øÁè≠ÁâôÊñá„ÄÅËë°ËêÑÁâôÊñá„ÄÅÂæ∑Êñá„ÄÅÊÑèÂ§ßÂà©Êñá„ÄÅ‰øÑÊñá„ÄÅÊó•Êñá„ÄÅÈü©Êñá„ÄÅË∂äÂçóÊñá„ÄÅÊ≥∞Êñá„ÄÅÈòøÊãâ‰ºØÊñáÁ≠â„ÄÇ\n\n‰ΩøÁî®Ê≠§Ê®°ÂûãÈ°ªÈÅµÂÆà [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/qwen-25-coder-32b-instruct","frontmatter":{"title":"Qwen2.5 Coder 32B Instruct","meta_title":"Qwen2.5 Coder 32B Instruct","description":"Qwen2.5 Coder 32B Instruct","date":"2024-11-11T23:40:00.000Z","image":"https://img.rifx.online/logo/qwen.svg","categories":["text 2 text"],"author":"qwen","tags":["Programming","Programming/Scripting","Machine Learning","Natural Language Processing","Generative AI"],"draft":false,"is_recommended":true,"id":"qwen-2.5-coder-32b-instruct","context":32768,"input":1.8e-7,"output":1.8e-7,"img":0,"request":0,"last_updated":"2024-11-15T23:24:23.000Z","slug":"models/qwen-25-coder-32b-instruct"},"content":"\nQwen2.5-Coder ÊòØÊúÄÊñ∞‰∏ÄÁ≥ªÂàóÈíàÂØπ‰ª£Á†ÅÁöÑ Qwen Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºà‰ª•ÂâçÁß∞‰∏∫ CodeQwenÔºâ„ÄÇQwen2.5-Coder Âú® CodeQwen1.5 ÁöÑÂü∫Á°Ä‰∏äÂ∏¶Êù•‰∫Ü‰ª•‰∏ãÊîπËøõÔºö\n\n- Âú® **‰ª£Á†ÅÁîüÊàê**„ÄÅ**‰ª£Á†ÅÊé®ÁêÜ** Âíå **‰ª£Á†Å‰øÆÂ§ç** ÊñπÈù¢ÊúâÊòæËëóÊèêÂçá„ÄÇ\n- ‰∏∫Áé∞ÂÆû‰∏ñÁïåÂ∫îÁî®ÔºàÂ¶Ç **‰ª£Á†Å‰ª£ÁêÜ**ÔºâÊèê‰æõ‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑÂü∫Á°Ä„ÄÇ‰∏ç‰ªÖÂ¢ûÂº∫‰∫ÜÁºñÁ†ÅËÉΩÂäõÔºåËøò‰øùÊåÅ‰∫ÜÂÖ∂Âú®Êï∞Â≠¶Âíå‰∏ÄËà¨ËÉΩÂäõÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇ\n\nË¶Å‰∫ÜËß£Êõ¥Â§öÂÖ≥‰∫éÂÖ∂ËØÑ‰º∞ÁªìÊûúÁöÑ‰ø°ÊÅØÔºåËØ∑Êü•Áúã [Qwen 2.5 Coder ÁöÑÂçöÂÆ¢](https://qwenlm.github.io/blog/qwen2.5-coder-family/)„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/remm-slerp-l2-13b","frontmatter":{"title":"ReMM SLERP 13B","meta_title":"ReMM SLERP 13B","description":"ReMM SLERP 13B","date":"2023-07-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"undi95","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"is_recommended":true,"id":"remm-slerp-l2-13b","context":4096,"input":0.000001125,"output":0.000001125,"img":0,"request":0,"last_updated":"2024-11-14T04:06:00.000Z","slug":"models/remm-slerp-l2-13b"},"content":"\nÂéüÂßã MythoMax-L2-B13 ÁöÑÈáçÂàõÁâàÊú¨Ôºå‰ΩÜÈááÁî®‰∫ÜÊõ¥Êñ∞ÁöÑÊ®°Âûã„ÄÇ #merge\n\n"},{"lang":"zh","group":"models","slug":"models/remm-slerp-l2-13b:extended","frontmatter":{"title":"ReMM SLERP 13B (extended)","meta_title":"ReMM SLERP 13B (extended)","description":"ReMM SLERP 13B (extended)","date":"2023-07-22T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"undi95","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"remm-slerp-l2-13b:extended","context":6144,"input":0.000001125,"output":0.000001125,"img":0,"request":0,"last_updated":"2024-11-04T12:47:21.000Z","slug":"models/remm-slerp-l2-13b:extended"},"content":"\nÂéüÂßã MythoMax-L2-B13 ÁöÑÈáçÁé∞ËØïÈ™åÔºå‰ΩÜ‰ΩøÁî®‰∫ÜÊõ¥Êñ∞ÁöÑÊ®°Âûã„ÄÇ #merge\n\n_Ëøô‰∫õÊòØ [ReMM SLERP 13B](/undi95/remm-slerp-l2-13b) ÁöÑÊâ©Â±ï‰∏ä‰∏ãÊñáÁ´ØÁÇπ„ÄÇÂÆÉ‰ª¨ÂèØËÉΩÂÖ∑ÊúâÊõ¥È´òÁöÑ‰ª∑Ê†º„ÄÇ_\n\n"},{"lang":"zh","group":"models","slug":"models/rocinante-12b","frontmatter":{"title":"Rocinante 12B","meta_title":"Rocinante 12B","description":"Rocinante 12B","date":"2024-09-30T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"thedrummer","tags":["Roleplay","Programming","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"rocinante-12b","context":32768,"input":2.5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-11T03:09:37.000Z","slug":"models/rocinante-12b"},"content":"\nRocinante 12B Êó®Âú®Êèê‰æõÂºï‰∫∫ÂÖ•ËÉúÁöÑÂèô‰∫ãÂíå‰∏∞ÂØåÁöÑÊï£Êñá„ÄÇ\n\nÊó©ÊúüÊµãËØïËÄÖÊä•ÂëäÔºö\n- ËØçÊ±áÈáèÊâ©Â±ïÔºåÁã¨Áâπ‰∏îÂØåÊúâË°®Áé∞ÂäõÁöÑÁî®ËØçÈÄâÊã©\n- ÂàõÈÄ†ÂäõÂ¢ûÂº∫ÔºåËÉΩÂ§üÁîüÂä®ÂèôËø∞\n- ÂÖÖÊª°ÂÜíÈô©ÂíåÂºï‰∫∫ÂÖ•ËÉúÁöÑÊïÖ‰∫ã\n\n"},{"lang":"zh","group":"models","slug":"models/sorcererlm-8x22b","frontmatter":{"title":"Sorcererlm 8x22b","meta_title":"Sorcererlm 8x22b","description":"Sorcererlm 8x22b","date":"2024-11-08T22:31:23.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"raifle","tags":["Roleplay","Programming","Natural Language Processing","Chatbots","Generative AI"],"draft":false,"id":"sorcererlm-8x22b","context":16000,"input":0.0000045,"output":0.0000045,"img":0,"request":0,"last_updated":"2024-11-11T02:56:49.000Z","slug":"models/sorcererlm-8x22b"},"content":"\nSorcererLM ÊòØ‰∏Ä‰∏™ÂÖàËøõÁöÑ RP ÂíåÊïÖ‰∫ãËÆ≤Ëø∞Ê®°ÂûãÔºå‰Ωú‰∏∫‰∏Ä‰∏™‰ΩéÁß© 16 ‰Ωç LoRA Âú® WizardLM-2-8x22B ‰∏äËøõË°åÂæÆË∞É„ÄÇ\n\n- ÂÖàËøõÁöÑÊé®ÁêÜÂíåÊÉÖÊÑüÊô∫ËÉΩÔºåÂÆûÁé∞Âºï‰∫∫ÂÖ•ËÉúÂíåÊ≤âÊµ∏ÂºèÁöÑ‰∫íÂä®\n- ÁîüÂä®ÁöÑÂÜô‰ΩúËÉΩÂäõÔºåÂ¢ûÂº∫‰∫ÜÁ©∫Èó¥Âíå‰∏ä‰∏ãÊñáÊÑèËØÜ\n- Â¢ûÂº∫ÁöÑÂèô‰∫ãÊ∑±Â∫¶Ôºå‰øÉËøõÂàõÈÄ†ÊÄßÂíåÂä®ÊÄÅÁöÑÊïÖ‰∫ãËÆ≤Ëø∞\n\n"},{"lang":"zh","group":"models","slug":"models/toppy-m-7b","frontmatter":{"title":"Toppy M 7B","meta_title":"Toppy M 7B","description":"Toppy M 7B","date":"2023-11-10T00:00:00.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"undi95","tags":["Programming","Machine Learning","Generative AI","Chatbots","Data Science"],"draft":false,"id":"toppy-m-7b","context":4096,"input":7e-8,"output":7e-8,"img":0,"request":0,"last_updated":"2024-11-04T12:51:35.000Z","slug":"models/toppy-m-7b"},"content":"\n‰∏Ä‰∏™ÈáéÁîüÁöÑ7BÂèÇÊï∞Ê®°ÂûãÔºåÈÄöËøámergekit‰∏≠ÁöÑÊñ∞task_arithmeticÂêàÂπ∂ÊñπÊ≥ïÂêàÂπ∂‰∫ÜÂ§ö‰∏™Ê®°Âûã„ÄÇ\nÂêàÂπ∂Ê®°ÂûãÂàóË°®Ôºö\n- NousResearch/Nous-Capybara-7B-V1.9\n- [HuggingFaceH4/zephyr-7b-beta](/huggingfaceh4/zephyr-7b-beta)\n- lemonilia/AshhLimaRP-Mistral-7B\n- Vulkane/120-Days-of-Sodom-LoRA-Mistral-7b\n- Undi95/Mistral-pippa-sharegpt-7b-qlora\n\n#merge #uncensored\n\n"},{"lang":"zh","group":"models","slug":"models/unslopnemo-12b","frontmatter":{"title":"Unslopnemo 12b","meta_title":"Unslopnemo 12b","description":"Unslopnemo 12b","date":"2024-11-08T22:04:08.000Z","image":"/images/logo.svg","categories":["text 2 text"],"author":"thedrummer","tags":["Roleplay","Programming","Generative AI","Chatbots","Natural Language Processing"],"draft":false,"id":"unslopnemo-12b","context":32000,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-11-14T02:10:09.000Z","slug":"models/unslopnemo-12b"},"content":"\nUnslopNemo v4.1 ÊòØÊù•Ëá™ Rocinante Âàõ‰ΩúËÄÖÁöÑÊúÄÊñ∞‰ΩúÂìÅÔºåÊó®Âú®Áî®‰∫éÂÜíÈô©ÂÜô‰ΩúÂíåËßíËâ≤ÊâÆÊºîÂú∫ÊôØ„ÄÇ\n\n"},{"lang":"zh","group":"models","slug":"models/wizardlm-2-7b","frontmatter":{"title":"WizardLM-2 7B","meta_title":"WizardLM-2 7B","description":"WizardLM-2 7B","date":"2024-04-16T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"wizardlm-2-7b","context":32000,"input":5.5e-8,"output":5.5e-8,"img":0,"request":0,"last_updated":"2024-10-31T23:23:36.000Z","slug":"models/wizardlm-2-7b"},"content":"\nWizardLM-2 7B ÊòØÂæÆËΩØ AI ÊúÄÊñ∞ Wizard Ê®°ÂûãÁöÑËæÉÂ∞èÁâàÊú¨„ÄÇÂÆÉÊòØÊúÄÂø´ÁöÑÔºåÂπ∂‰∏îÂú®ÊÄßËÉΩ‰∏ä‰∏éÁé∞ÊúâÁöÑ 10 ÂÄçÊõ¥Â§ßÁöÑÂºÄÊ∫êÈ¢ÜÂÖàÊ®°ÂûãÁõ∏ÂΩì„ÄÇ\n\nÂÆÉÊòØÂØπ [Mistral 7B Instruct](/mistralai/mistral-7b-instruct) ÁöÑÂæÆË∞ÉÔºå‰ΩøÁî®‰∏é [WizardLM-2 8x22B](/microsoft/wizardlm-2-8x22b) Áõ∏ÂêåÁöÑÊäÄÊúØ„ÄÇ\n\nË¶Å‰∫ÜËß£Êõ¥Â§öÂÖ≥‰∫éÊ®°ÂûãÂèëÂ∏ÉÁöÑ‰ø°ÊÅØÔºå[ËØ∑ÁÇπÂáªËøôÈáå](https://wizardlm.github.io/WizardLM2/)„ÄÇ\n\n#moe\n\n"},{"lang":"zh","group":"models","slug":"models/wizardlm-2-8x22b","frontmatter":{"title":"WizardLM-2 8x22B","meta_title":"WizardLM-2 8x22B","description":"WizardLM-2 8x22B","date":"2024-04-16T00:00:00.000Z","image":"https://img.rifx.online/logo/microsoft.svg","categories":["text 2 text"],"author":"microsoft","tags":["Programming","Machine Learning","Natural Language Processing","Generative AI","Chatbots"],"draft":false,"id":"wizardlm-2-8x22b","context":65536,"input":5e-7,"output":5e-7,"img":0,"request":0,"last_updated":"2024-10-31T23:24:21.000Z","slug":"models/wizardlm-2-8x22b"},"content":"\nWizardLM-2 8x22B ÊòØÂæÆËΩØ AI ÊúÄÂÖàËøõÁöÑ Wizard Ê®°Âûã„ÄÇ‰∏éÈ¢ÜÂÖàÁöÑ‰∏ìÊúâÊ®°ÂûãÁõ∏ÊØîÔºåÂÆÉÂ±ïÁ§∫‰∫ÜÈ´òÂ∫¶Á´û‰∫âÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÂßãÁªà‰ºò‰∫éÊâÄÊúâÁé∞ÊúâÁöÑÊúÄÂÖàËøõÁöÑÂºÄÊ∫êÊ®°Âûã„ÄÇ\n\nÂÆÉÊòØ [Mixtral 8x22B](/mistralai/mixtral-8x22b) ÁöÑÊåá‰ª§ÂæÆË∞ÉÁâàÊú¨„ÄÇ\n\nË¶Å‰∫ÜËß£ÊúâÂÖ≥Ê®°ÂûãÂèëÂ∏ÉÁöÑÊõ¥Â§ö‰ø°ÊÅØÔºå[ËØ∑ÁÇπÂáªËøôÈáå](https://wizardlm.github.io/WizardLM2/)„ÄÇ\n\n#moe\n\n"}]