---
title: "Mistral Tiny"
meta_title: "Mistral Tiny"
description: "Mistral Tiny"
date: 2024-12-03T02:55:56Z
image: "https://img.rifx.online/icons/mistral-color.svg"
categories: ["text 2 text"]
author: "MistralAI"
tags: ["Generative AI", "MistralAI", "fine-tuned AI", "Machine Learning", "large-scale tasks", "cost-effective processing", "Programming", "Data Science", "mistral-tiny", "Chatbots", "batch processing model"]
model_tags: []
labels: ["mistral-tiny", "cost-effective processing", "batch processing model", "fine-tuned AI", "large-scale tasks"]
draft: False
is_recommended: False
is_active: True
discount: 1
is_free: False

id: "mistralai/mistral-tiny"
context: 32000
input: 2.5e-07
output: 2.5e-07
img: 0
request: 0
last_updated: 2024-12-03T02:55:56Z

---

This model is currently powered by Mistral-7B-v0.2, and incorporates a "better" fine-tuning than [Mistral 7B](/mistralai/mistral-7b-instruct-v0.1), inspired by community work. It's best used for large batch processing tasks where cost is a significant factor but reasoning capabilities are not crucial.

