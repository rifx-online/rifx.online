---
author: mistralai
categories:
- text 2 text
context: 128000
date: 2024-10-17 00:00:00+00:00
description: Ministral 8B
draft: false
id: ministral-8b
image: https://img.rifx.online/logo/mistral.png
img: 0
input: 1e-07
is_active: false
last_updated: 2024-10-19 04:54:11+00:00
meta_title: Ministral 8B
output: 1e-07
request: 0
tags:
- Technology
- Machine Learning
- Data Science
- Generative AI
- Ethics
title: Ministral 8B
---















Ministral 8B is an 8B parameter model featuring a unique interleaved sliding-window attention pattern for faster, memory-efficient inference. Designed for edge use cases, it supports up to 128k context length and excels in knowledge and reasoning tasks. It outperforms peers in the sub-10B category, making it perfect for low-latency, privacy-first applications.

