---
title: "AI21: Jamba 1.5 Mini"
meta_title: "AI21: Jamba 1.5 Mini"
description: "AI21: Jamba 1.5 Mini"
date: 2024-12-02T04:07:57Z
image: "https://img.rifx.online/icons/ai21.svg"
categories: ["text 2 text"]
author: "Ai21"
tags: ["Programming", "Technology", "Machine Learning", "Natural Language Processing", "Generative AI"]
draft: False
is_recommended: False
is_active: True

id: "ai21/jamba-1-5-mini"
context: 256000
input: 2e-07
output: 4e-07
img: 0
request: 0
last_updated: 2024-12-02T04:07:57Z
---

Jamba 1.5 Mini is the world's first production-grade Mamba-based model, combining SSM and Transformer architectures for a 256K context window and high efficiency.

It works with 9 languages and can handle various writing and analysis tasks as well as or better than similar small models.

This model uses less computer memory and works faster with longer texts than previous designs.

Read their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.

