---
title: "AI21: Jamba 1.5 Mini"
meta_title: "AI21: Jamba 1.5 Mini"
description: "AI21: Jamba 1.5 Mini"
date: 2024-12-02T04:07:57Z
image: "https://img.rifx.online/icons/ai21.svg"
categories: ["text 2 text"]
author: "Ai21"
tags: ["Generative AI", "Mamba-based model", "Ai21", "Machine Learning", "Natural Language Processing", "SSM Transformer", "Programming", "multilingual analysis", "Technology", "256K context window", "jamba-1-5-mini"]
model_tags: []
labels: ["jamba-1-5-mini", "Mamba-based model", "SSM Transformer", "256K context window", "multilingual analysis"]
draft: False
is_recommended: False
is_active: True
discount: 1
is_free: False

id: "ai21/jamba-1-5-mini"
context: 256000
input: 2e-07
output: 4e-07
img: 0
request: 0
last_updated: 2024-12-02T04:07:57Z

---

Jamba 1.5 Mini is the world's first production-grade Mamba-based model, combining SSM and Transformer architectures for a 256K context window and high efficiency.

It works with 9 languages and can handle various writing and analysis tasks as well as or better than similar small models.

This model uses less computer memory and works faster with longer texts than previous designs.

Read their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.

