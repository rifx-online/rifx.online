---
author: qwen
categories:
- text image 2 text
context: 32768
date: 2024-09-18 00:00:00+00:00
description: Qwen2-VL 72B Instruct
draft: false
id: qwen-2-vl-72b-instruct
image: https://img.rifx.online/logo/qwen.svg
img: 0.000578
input: 4e-07
is_active: false
last_updated: 2024-09-18 00:00:00+00:00
meta_title: Qwen2-VL 72B Instruct
output: 4e-07
request: 0
tags:
- Natural Language Processing
- Computer Vision
- Robotics
- Machine Learning
title: Qwen2-VL 72B Instruct
---






Qwen2 VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:

- SoTA understanding of images of various resolution & ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.

- Understanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.

- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.

- Multilingual Support: to serve global users, besides English and Chinese, Qwen2-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.

For more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).

Usage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).

