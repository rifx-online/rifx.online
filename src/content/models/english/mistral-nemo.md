---
title: "Mistral: Mistral Nemo"
meta_title: "Mistral: Mistral Nemo"
description: "Mistral: Mistral Nemo"
date: 2024-07-19T00:00:00Z
image: "https://img.rifx.online/logo/mistral.png"
categories: ["text 2 text"]
author: "mistralai"
tags: ["Programming", "Machine Learning", "Natural Language Processing", "Generative AI", "Data Science"]
draft: False

id: "mistral-nemo"
context: 128000
input: 1.3e-07
output: 1.3e-07
img: 0
request: 0
last_updated: 2024-10-31T23:10:58Z
---

A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.

The model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.

It supports function calling and is released under the Apache 2.0 license.

