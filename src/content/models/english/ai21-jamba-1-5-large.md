---
title: "AI21: Jamba 1.5 Large"
meta_title: "AI21: Jamba 1.5 Large"
description: "AI21: Jamba 1.5 Large"
date: 2024-08-23T00:00:00Z
image: "/images/logo.svg"
categories: ["text 2 text"]
author: "Ai21"
tags: ["Technology", "Machine Learning", "Data Science", "Generative AI", "Chatbots"]
draft: False
is_recommended: False
is_active: True

id: "ai21/jamba-1-5-large"
context: 256000
input: 2e-06
output: 8e-06
img: 0
request: 0
last_updated: 2024-12-02T04:08:59Z
---

Jamba 1.5 Large is part of AI21's new family of open models, offering superior speed, efficiency, and quality.

It features a 256K effective context window, the longest among open models, enabling improved performance on tasks like document summarization and analysis.

Built on a novel SSM-Transformer architecture, it outperforms larger models like Llama 3.1 70B on benchmarks while maintaining resource efficiency.

Read their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.

