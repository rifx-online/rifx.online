---
title: "Meta: Llama 3.2 90B Vision Instruct"
meta_title: "Meta: Llama 3.2 90B Vision Instruct"
description: "Meta: Llama 3.2 90B Vision Instruct"
date: 2024-12-02T02:30:10Z
image: "https://img.rifx.online/icons/meta-color.svg"
categories: ["text imaget 2 text"]
author: "Meta Llama"
tags: ["Natural Language Processing", "Computer Vision", "Machine Learning", "Data Science", "Generative AI"]
draft: False
is_recommended: False
is_active: True

id: "meta-llama/llama-3.2-90b-vision-instruct"
context: 131072
input: 3.5e-07
output: 4e-07
img: 0.00050575
request: 0
last_updated: 2024-12-02T02:30:10Z
---

The Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal model designed for the most challenging visual reasoning and language tasks. It offers unparalleled accuracy in image captioning, visual question answering, and advanced image-text comprehension. Pre-trained on vast multimodal datasets and fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the most demanding image-based AI tasks.

This model is perfect for industries requiring cutting-edge multimodal AI capabilities, particularly those dealing with complex, real-time visual and textual analysis.

Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).

Usage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).

