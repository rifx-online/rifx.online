---
title: "Mistral: Mistral Nemo"
meta_title: "Mistral: Mistral Nemo"
description: "Mistral: Mistral Nemo"
date: 2024-07-19T00:00:00Z
image: "/images/what-is-openai.png"
categories: ["text->text"]
author: "mistralai"
tags: ["Role", "mistralai"]
draft: false

id: "mistralai/mistral-nemo"
context: 128000
input: 1.3e-07
output: 0.00000013
img: 0
request: 0
---

A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.

The model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.

It supports function calling and is released under the Apache 2.0 license.

