---
title: "Qwen 2 7B Instruct"
meta_title: "Qwen 2 7B Instruct"
description: "Qwen 2 7B Instruct"
date: 2024-12-02T13:14:59Z
image: "https://img.rifx.online/icons/qwen-color.svg"
categories: ["text 2 text"]
author: "Qwen"
tags: ["Generative AI", "Qwen", "Machine Learning", "Natural Language Processing", "multilingual understanding", "Programming", "Data Science", "coding and reasoning", "SwiGLU activation", "qwen-2-7b", "transformer model"]
model_tags: []
labels: ["qwen-2-7b", "multilingual understanding", "transformer model", "coding and reasoning", "SwiGLU activation"]
draft: False
is_recommended: False
is_active: True
discount: 1
is_free: False

id: "qwen/qwen-2-7b-instruct"
context: 32768
input: 5.4e-08
output: 5.4e-08
img: 0
request: 0
last_updated: 2024-12-02T13:14:59Z

---

Qwen2 7B 是一个基于变换器的模型，在语言理解、多语言能力、编码、数学和推理方面表现出色。

它具有 SwiGLU 激活、注意力 QKV 偏置和组查询注意力。它在大量数据上进行了预训练，并进行了监督微调和直接偏好优化。

有关更多详细信息，请参见这篇 [博客文章](https://qwenlm.github.io/blog/qwen2/) 和 [GitHub 仓库](https://github.com/QwenLM/Qwen2)。

使用此模型须遵循 [通义千问许可协议](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE)。

