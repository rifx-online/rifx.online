---
title: "Goliath 120B"
meta_title: "Goliath 120B"
description: "Goliath 120B"
date: 2024-12-03T02:30:10Z
image: "https://img.rifx.online/icons/rifx.svg"
categories: ["text 2 text"]
author: "Alpindale"
tags: ["Generative AI", "goliath-120b", "model merging", "Machine Learning", "large language model", "Natural Language Processing", "mergekit", "Programming", "fine-tuned Llama", "Chatbots", "Alpindale"]
model_tags: []
labels: ["goliath-120b", "large language model", "model merging", "fine-tuned Llama", "mergekit"]
draft: False
is_recommended: False
is_active: True
discount: 1
is_free: False

id: "alpindale/goliath-120b"
context: 6144
input: 9.375e-06
output: 9.375e-06
img: 0
request: 0
last_updated: 2024-12-03T02:30:10Z

---

一个大型 LLM 通过将两个微调的 Llama 70B 模型合并成一个 120B 模型而创建。结合了 Xwin 和 Euryale。

致谢
- [@chargoddard](https://huggingface.co/chargoddard) 开发了用于合并模型的框架 - [mergekit](https://github.com/cg123/mergekit)。
- [@Undi95](https://huggingface.co/Undi95) 帮助确定合并比例。

#merge
```

