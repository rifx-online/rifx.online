---
title: "How to Choose Ideas for an LLM-powered Product to Thrive in a Fiercely Competitive Landscape"
meta_title: "How to Choose Ideas for an LLM-powered Product to Thrive in a Fiercely Competitive Landscape"
description: "Leveraging unobvious AI capabilities, profound domain expertise, and 9 more ways for a small novel product to gain its competitive edge"
date: 2024-11-10T03:51:17Z
image: "https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MAmCClj129C56jmkiqqhQQ.png"
categories: ["Generative AI", "Product Development", "Technology/Web"]
author: "Rifx.Online"
tags: ["LLM", "development", "experimentation", "domain", "expertise"]
draft: False

---




Welcome to the third (final) piece in my series exploring the question: â€œWhich GenAI products are worth developing?â€

1. [The first article](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50) explored this question from the perspectives of user experience (UX) and product adoption.
2. The second article, which I highly recommend reading before this one, included six examples of successful and unsuccessful product ideas, as well as my GenAI Squared strategy:

3\. This third piece continues to focus on ways to navigate the competitive landscape, as well as to optimize development costs without losing competitive advantages. While this article contains fewer examples than its predecessor, the factors discussed here are crucial for success in the GenAI product space.

These three pieces **donâ€™t** cover the technical intricacies of LLM\-based application development. Additionally, my analysis **doesnâ€™t** focus on conventional success factors for innovative products, such as ones described in [that article](https://pakodas.substack.com/p/llm-chronicles-6-how-to-build-competitive).


> *Instead, as a product manager, I analyze the **unique features of LLM** as a platform for my products. This approach offers fresh insights for leveraging unobvious AI capabilities in product development.*

Specifically, in this piece, I explore the following questions about software products:

* Why are Generative AI products more prone to becoming obsolete before generating returns?
* How can we transform these GenAI challenges into competitive advantages?
* Which LLM abilities truly enhance product competitiveness, and which ones donâ€™t make much sense?
* How can new AI products stand out when they contain very little code, and therefore a great team of programmers are NOT among the key success factors anymore?
* What skills are most vital for AI product developers in this new landscape?

These insights aim to guide product managers and founders in making their decisions.

So, which AI applications might be redundant or destined to fail ğŸš«, and which ones have high chances of success âœ…?

*Please note that the section numbers below continue the section numbering of the previous two pieces of the series. All 11 points are summarized at the end of this piece.*


## 9\. Large Applications with Extended Development Cycles and Lengthy Market Adoption Timelines Are Uncompetitive ğŸš«

Generative AI is evolving at an unprecedented rate, outpacing the growth of any previous technology. The time it takes for AI capabilities to double is roughly one year, a contrast to the two years described in the famous Mooreâ€™s Law.

Therefore, GenAI\-based products cannot afford long development cycles and extended time\-to\-market periods. This has three main consequences.


### 1\. New features should be lean and focused, capable of being developed within weeks, not months.

This approach allows for rapid refinement based on initial user feedback, potentially leading to significant functionality changes. Moreover, when a pivot becomes necessary (it certainly will), thereâ€™s less sunk cost in discarding features developed during these early weeks.

Consider, for instance, the UI of an LLM\-based MVP. It may be unnecessary to develop a custom web interface if users can achieve the same results through a Telegram bot or similar tool.

*However, the â€œproduct as a wholeâ€ can have extensive functionality if we are [incorporating LLM into existing solutions or integrating with them](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#5d06). The key here is to minimize the scope of **new** functionality only.*


### 2\. Thereâ€™s a critical need for ultra\-fast experimentation and customer feedback loops.

The speed of GenAI product build is higher, but itâ€™s not always possible to get feedback just as quickly. As a result, some GenAI product concepts may prove too risky.

Rapid experimentation is, of course, beneficial for any new product launch, as itâ€™s impossible to accurately predict market response in advance. Essentially, the market operates as a â€œblack box,â€ and its behavior can only be truly understood through hands\-on experimentation.


> *In the realm of GenAI products, we encounter an additional layer of complexity â€” **the second â€œblack boxâ€** stemming from the inherent unpredictability of LLM output. **This dual uncertainty amplifies the importance of frequent and rapid experimentation.** The ability to quickly iterate and gather insights becomes not just advantageous, but essential for success.*


### 3\. Thereâ€™s no time to â€œeducateâ€ the productâ€™s target audience, accustoming it to completely new work or leisure patterns.

Only the largest industry leaders, particularly those with their own ecosystems like Google, Apple, or Microsoft, can accustom the **majority** of potential users to novel concepts relatively quickly.

âœ… Consequently, other companies must align with **either existing goal\-achievement patterns familiar to users, or with trends established by industry leaders**.

* Consider an established pattern for the goal of increasing earnings: people purchase training courses to gather new skills. A good AI\-driven solution in this domain involves creating these courses using AI, dramatically reducing production costs and, consequently, enhancing competitiveness. **No new behavior** is required from end users who want to boost their income.
* A recent **trend** emerging in Apple devices exemplifies an innovation that Apple platform users will undoubtedly adopt: employing a local LLM for typical tasks to safeguard user data privacy. While the specific ways applications might leverage this trend remain unclear yet, I am sure that Apple will provide developers with convenient access to its LLM infrastructure, we just need to wait a bit.


## 10\. Leveraging the Less Apparent LLM Capabilities Enhances Competitiveness and Resource Efficiency âœ…

Imagine youâ€™re at the starting point with nothing more than a product concept. To expedite the journey towards a product in high demand, **which aspects of your idea should you prioritize for initial exploration?**

Clearly, you need to identify a small set of specific end\-to\-end work scenarioswithin your concept. This aligns with [popular product launch strategies](https://www.geeksforgeeks.org/a-complete-guide-to-a-successful-product-launch/#is-there-a-product-launch-formula): â€œStart with MVPâ€ (implementing just one or a few scenarios) and â€œBuild for the **whole** user experienceâ€ (ensuring scenarios are end\-to\-end). The question remains: which scenarios should you choose?


> *In my opinion, these MVP scenarios should be **closely aligned with LLM capabilities**. This approach saves resources on the product delivery, as significant product value comes from the LLM itself rather than solely from your developersâ€™ efforts. Failing to do so may lead to challenges like those outlined in [section 7 â€œOverconstraining LLMâ€](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e1ef).*

ğŸš« LLMâ€™s purported super\-powers often include its **ability to answer any question**. However, the accuracy and quality of these responses are inherently unpredictable, and it leads to problems (refer to [section 1](https://ai.gopubby.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#f973) for more on evaluation complexities and quality monitoring). Moreover, a product centered around question\-answering canâ€™t effectively compete with market leaders like ChatGPT (as discussed in [section 6](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e305)). Given these two factors, I advise against basing an MVP on this â€œsuper\-powerâ€.

**The LLMâ€™s capacity for â€œimaginative generationâ€** presents a somewhat more promising avenue. Such creativity of LLMs can inspire our fresh ideas or aid in creating creative content like poems, video scripts, or content plans. However, in my experience, LLMâ€™s creativity alone doesnâ€™t suffice for constructing end\-to\-end product scenarios. Once a user obtains â€œcreative materialâ€ from an LLM, substantial effort is still required to transform it into the desired outcome.

Furthermore, creativity represents one of the most easy\-to\-understand and widely recognized capabilities of GenAI. It is familiar to nearly anyone who has experimented with ChatGPT or Midjourney, so anyone can become your competitor.



âœ… Considering the intense competition, Iâ€™d recommend focusing on **LLMâ€™s less apparent capabilities,** such as:


### 1\. Flipped interaction

This human\-AI interaction pattern leverages LLMâ€™s ability to **ask good questions** or present lists for selecting items important for a user, thereby reducing the userâ€™s cognitive load. Flipped interaction not only helps replace some human work in certain fields (like teaching, mentoring, or coaching) but also aids in establishing the appropriate **context** for solving problems in any field (more details is available [here](https://readmedium.com/4-human-ai-interaction-patterns-for-experienced-chatgpt-users-9e49d4234013#c348)).


### 2\. Contextual comprehension

LLM excels at grasping the context of user requests and their preferences, then addressing the task within that context. This approach ensures that solutions align with even **unformulated** user needs.

a. This feature is perhaps most refined in AI copilots for developers, such as Github Copilot and Cursor. In these tools, the LLMâ€™s context encompasses the entire project codebase, whereas the user (developer) typically knows only specific portions. Consequently, developers often cannot consider the broader context when formulating their tasks for AI.

b. Nevertheless, leveraging insights from **explicitly stated** user needs within the context is also a powerful feature. The language learning platform [Memrise](https://www.memrise.com/), for instance, has effectively implemented this feature.


### 3\. Few\-shot learning

The modelâ€™s ability to â€œlearnâ€ from a **small** number of examples allows it to easily adapt to new tasks and contexts. This is why LLM\-based chatbots are now widely being implemented in sales and customer support, and chats with them are difficult to distinguish from those with human specialists. In contrast, traditional AI chatbots perform well only in large enterprises and struggle to adapt to evolving knowledge bases.


### 4\. Large\-scale information processing

LLM excels at analyzing **large** quantities of textual and tabular data, distilling it into **concise** forms. It can generalize, extract key points relevant to the task at hand, identify patterns, and perform various other analytical functions.

a. Take [Scite](https://scite.ai/), an AI tool for scientific research, as an example. It goes beyond merely locating query\-relevant sources within its billion\-citation database. Scite analyzes the context in which an article is referenced, revealing whether the citing paper supports, contradicts, or just mentions the earlier work.

b. When it comes to numerical data processing, LLM outputs donâ€™t require â€œtranslation into human languageâ€. This gives GenAI analyzers a distinct advantage over conventional statistical data processing tools.

Many potential competitors may be aware of some of these four LLM capabilities. However, I believe that deeper reflection on these abilities could lead to the development of truly innovative products. This approach could provide a competitive edge over products that solely leverage LLMâ€™s more obvious capabilities like â€œcreativityâ€ and â€œanswering any questionâ€.


## 11\. Small AI Products Grounded in Deep Domain Expertise Are Competitively Viable âœ…

LLM functions nearly as a finished product, it can interact with users â€œautonomouslyâ€. Consequently, LLM\-based applications are significantly smaller in terms of code base compared to traditional non\-LLM applications.

Moreover, any individual with some technical skills can learn to develop a feature\-rich LLM\-based application within days.

These two factors align perfectly with the rapid development and experimentation requirements outlined in section 9.


> *However, the small size of the product and the low barrier to entry in GenAI development are **significant drawbacks from a competitive standpoint**.*

For a typical software product with large code base, an exceptional team and agile development processes are crucial success elements. [Bill Grossâ€™s research](https://youtu.be/bNpx7gpSqbY?t=216) ranks this as the second most important factor out of five, surpassing even the product ideaâ€™s viability, which ranks third.

However, how can a product get its competitive edge when its software development scope is minimal, and even inexperienced programmers can develop it?

With ideas and business models easily replicable by competitorsâ€¦ Does success truly depend **solely** on the short\-term advantage of being the first to market in your niche?

1. Section 10 offers one answer to these questions: products should leverage LLMâ€™s less\-known capabilities. While this doesnâ€™t guarantee success, it increases the chances of outperforming competitors who may not fully understand LLMâ€™s unobvious abilities.
2. [My previous article](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#9f01) outlines another solution: implementing LLM within the product in innovative ways, such as the LLM2 strategy. This kind of know\-how is harder for competitors to replicate, as itâ€™s more deeply hidden inside the product.
3. The third component of my solution to this challenge is the necessity for a high level of **domain expertise**.

The importance of domain expertise in product success has been a topic of discussion for years. While I couldnâ€™t find quantitative studies correlating startup success with foundersâ€™ domain expertise, I recommend exploring some [examples](https://jamesspurway.com/2024/04/29/founder-domain-expertise-insider-tip-how-startups-benefit/) and [rationales](https://www.nvp.com/blog/domain-expertise-founder-greatest-asset/) supporting this significant correlation. [Existing studies](https://www.ensemble.vc/research/what-does-the-data-say-about-successful-startup-founders), focusing solely on unicorns, suggest that foundersâ€™ domain expertise is important, though not the primary success factor.

However, I believe that this factor gains substantially more importance in the realm of generative AI. The reasoning behind this opinion is well\-articulated in the following post:


> *For LLM\-based products, technical expertise plays a significantly reduced role (due to easier software delivery), unlike traditional digital products where itâ€™s a crucial competitive advantage. Instead, a **profound understanding of the domain** becomes paramount, as this depth of knowledge is challenging for competitors to replicate.*

From a product competitiveness standpoint, I believe itâ€™s important for domain expertise to reside **in the same mind** that designs the product and contributes to its implementation. Of course, the traditional separation of â€œtechâ€ and â€œbusinessâ€ roles in companies has its benefits, as long as they communicate effectively, as such communication results in well\-balanced, technically sophisticated and domain\-appropriate products. Nevertheless, verbal communication introduces significant overhead. It can take months for techies and businesspeople to understand each other well enough. During this time, market conditions may shift dramatically.


> *The most efficient and lossless translation of domain expertise into technical implementation occurs when both business and technical visions reside in a single mind. LLMs provide this opportunity by immensely reducing the technical expertise required for product implementation, thus **enabling individuals with strong domain knowledge to take a direct role in product delivery**.*

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dOlknP1p9xLfvy_NxLnq7Q.png)

In my view, when developing GenAI products, technical expertise isnâ€™t limited to programmers; it extends to include advanced ChatGPT users as well.

For example, my friend [Askhat Urazbaev](https://www.linkedin.com/in/urazbaev/) independently creates MVPs for his products using AI and even deploys them in the cloud with ChatGPT guidance only. He has never been a professional software developer, and it seems that his [AI Power User](https://readmedium.com/12-questions-to-consider-when-using-ai-path-to-ai-power-user-9c7e8de1f8b7#f646) skills are just as valuable as the ability to read program code.


> *Iâ€™m convinced that generative AI will soon enable domain experts to **single\-handedly** develop products within their domains. To do so, experts should have substantial AI user experience coupled with a foundational understanding of business principles and product design.*

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kk0SUvuajHZp7UMbSEonmQ.png)

Nevertheless, it is not yet clear which specific tools will help us create comprehensive products single\-handedly. The concept of an â€œ**LLM\-driven one\-person company**â€ will be the focus of research in one of my upcoming articles.


## Summary: Success and Failure Factors for LLM\-driven Products

Letâ€™s put together all the ideas from the 3 pieces of this series.

1. [Applications With High Quality Standards or Costly Quality Monitoring May Fail ğŸš«](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#f973)
2. [Specialized Copilots Are in Demand âœ…](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#031b)
3. [Marginal Effort\-Saving Apps Donâ€™t Cut It ğŸš«](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#e88a)
4. [Applications â€œSmartlyâ€ Integrating LLMs into Familiar Workflows Can Cross the Chasm âœ…](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#5d06)
5. [New GenAI Products Are Better Suited to B2B and B2B2C than B2C](https://readmedium.com/what-llm-powered-products-are-worth-developing-ux-and-adoption-perspectives-d9efcf444d50#bdfa)
6. [Short Lifespan of Applications Enhancing LLM Capabilities ğŸš«](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e305)
7. [Overconstraining LLM: A Recipe for Uncompetitive Applications ğŸš«](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#e1ef)
8. [â€œGenAI Squaredâ€ Products: Unlocking Unfair Competitive Advantage âœ…](https://readmedium.com/genai-squared-how-can-a-product-avoid-the-downfall-of-most-llm-driven-startups-183619ab7883#9f01)
9. Large Applications with Extended Development Cycles and Lengthy Market Adoption Timelines Are Uncompetitive ğŸš«
10. Leveraging the Less Apparent LLM Capabilities Enhances Competitiveness and Resource Efficiency âœ…
11. Small AI Products Grounded in Deep Domain Expertise Are Competitively Viable âœ…

Except for factor \#4, the remaining 10 success / failure factors can be applied to **new** products / to startups.

Below, you can find a scheme illustrating the relations between these 10 factors, LLM capabilities and some features of LLM technology market.

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*f6E4WmRBw3H7eCNbTGJHUQ.png)

Certainly, only product experimentation can validate such considerations as shown on the scheme. Nevertheless, they can help us be **faster** by limiting the scope of our experiments. As explained in section 9, there are 2 reasons why high speed of discovery and delivery is even more important for GenAI products than for digital products of other types.

Naturally, no list of success factors can be all\-encompassing. Maybe you have encountered other categories of novel LLM\-driven products that are not mentioned above but you believe hold potential for success. Please share such product types or features in the comments ğŸ™


