---
title: "My 5 AI Predictions for 2025"
meta_title: "My 5 AI Predictions for 2025"
description: "The article presents five predictions for AI advancements by 2025, emphasizing that these developments are based on existing technologies evolving into mainstream applications. Key predictions include the mainstream adoption of self-driving robotaxis, the rise of industry-specific AI applications over general chatbots, increased reliability fostering trust in AI systems, and the emergence of AI agents in various personal and professional contexts. Additionally, the author dismisses overly optimistic predictions such as the arrival of Artificial General Intelligence and conscious AI by 2025, asserting that significant challenges remain in the current AI landscape."
date: 2024-12-26T04:30:18Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ty3_l3TVtv7QPd5N"
categories: ["Autonomous Systems", "Chatbots", "Predictive Analytics"]
author: "Rifx.Online"
tags: ["robotaxis", "chatbots", "reliability", "agents", "consciousness"]
draft: False

---




And a few non\-predictions



Predicting (correctly) the future is challenging.

Ask about it — to bring a widely known pop culture icon — Hanna and Barbera, the creators of the Jetsons, who imagined a future with flying cars and robotic maids but didn’t figure the Internet or the smartphone in our future.

In AI, in particular, many failed overoptimistic predictions also caused disillusionment and, in the end, the so\-called “AI Winters,” periods when AI funding dried up. The whole field retreated from public attention to obscure research labs, where few of us stubbornly continued our research day in and day out (yes, I started working on AI during one of its Winters).

For instance, the “Encyclopedia of Everything” ([Cyc project](https://en.wikipedia.org/wiki/Cyc)) led by [Doug Lenat](https://en.wikipedia.org/wiki/Douglas_Lenat) in the 80s failed miserably. So did Japan’s “[5th generation of computing](https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Systems)” based on Logic. So did [Expert Systems](https://www.britannica.com/technology/expert-system), which, after an initial success, ended up being utterly forgotten. So did the whole subfield of “[Program Synthesis](https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm),” where I carried out my PhD research (it still stings).

All those projects looked promising at the time.

This makes some of us who are not young anymore ask ourselves, every time we see promising technologies, whether or not this will stick in the long run or burst like a bubble after the initial hype vanishes.

However, we can also get wrong at the other end of the spectrum; we fail to recognize that a particular technology is legit and will indeed make a big impact on the world. For instance, most of us were taken off\-guard by the Internet’s emergence on the first day of 1983 and even more its life\-changing impact.

So, we need to strike a balance between being too optimistic and too pessimistic and, if possible, to have evidence supporting our position.

To have objective evidence for the following prediction, I’ll abstain from predicting anything completely new (for instance, I’d love my [“silent voice” invention](https://readmedium.com/i-invented-a-way-to-speak-to-an-ai-keeping-your-privacy-ddbca5f24e4a?sk=d944e6fd6036602e691e5f471ae20530) to become a hit, but that’s not likely to happen).

This implies that, in a way, everything I predict already exists in some embryonary form and will only become mainstream. Most technologies take around 15 years from basic research to mainstream commercialization, give or take.

A final note before getting started with the enumeration is that I’ll only consider trends and technologies, not products, and not principles or discoveries. A technology is a set of tools and methods to solve a big problem by applying knowledge and innovation, so it’s more specific than a trend.

Now, without further ado, let’s take a look at the trends and technologies that will make 2025, well, a memorable year in AI. I’ll present them in increasing impact order.


## 5\. Self\-driving robotaxis become mainstream

After enduring very challenging times in 2023–2024, when most self\-driving companies [shut down due to fatal crashes](https://www.cnbc.com/2023/10/26/cruise-pauses-all-driverless-operations-after-collisions-suspensions.html) and [running over pedestrians](https://www.nbcnews.com/tech/tech-news/driver-hits-pedestrian-pushing-path-self-driving-car-san-francisco-rcna118603), now apparently, Alphabet’s [Waymo](https://waymo.com/) has reached a level of reliability that makes its robotaxis a popular option. Starting as a public beta in San Francisco, now it’s widely offered in Phoenix, Los Angeles, and soon in Austin and Miami, making it a national\-level option with a fast\-growing market share.

I just have two issues with this apparently successful self\-driving service.

First, we don’t know the internals of their self\-driving algorithms; they’re proprietary and secret. How can we “trust” a service if nobody but them sees how it works? We are left only with the Waymo robotaxis track record, which currently looks very good. But what if (God forbid) next week there is a nasty fatal accident? In that case–let’s hope it doesn’t happen–trust would crumble overnight.

The second problem is that Waymo’s cars are too expensive, costing around $150,000 apiece (they are Jaguar I\-PACEs with costly equipment added, not counting the R\&D expenses). Thus, this won’t be profitable unless Waymo finds a way to mass\-produce cheaper units.

Anyway, self\-driving cars are now close to becoming mainstream, even boring. In 2025, robotaxis will become an option for everybody… living in big cities.


## 4\. Products and industry\-specific AI will win over general chatbots

I remember a year ago when many AI enthusiasts found use cases for ChatGPT every other day, like becoming a language teacher, creating silly poetry, roleplaying for interview preparation, generating business ideas, planning events, etc.

Though some of these prompt\-guided applications could be fun, like silly poetry, in most other cases, a general chatbot will just fall short for several reasons:

* It lacks training data on the specific use case,
* It doesn’t have access to applications where it can operate.

For most real\-world, non\-casual applications, we need specialized software that excels at solving a specific customer’s problem.

Take, for instance, text writing correction. If we compare ChatGPT with an embedded professional application like [Grammarly](https://www.grammarly.com/) (I’m not affiliated in any way with it), we can see a vast difference compared to ChatGPT:

* Grammarly can run inside Microsoft Word or Google Docs (as I’m doing now) instead of copying and pasting to ChatGPT and back.
* Grammarly underlines every change it makes to your text so you can see exactly what it is doing.
* Grammarly seems to me way better than ChatGPT at correcting my writing.

That’s just one example, but I think 2025 will be the year specialized AI applications appear like mushrooms. They are already appearing, as we can see in the following examples:

* [OpenSpace](https://www.openspace.ai/) is a tool for capturing and analyzing construction site images to monitor progress and compliance.
* I found new AI products in customer service that differed in their approach. While [Ada](https://www.ada.cx/) is a customer\-facing question\-answering bot, [Forethought](https://forethought.ai/) helps agents find answers quickly and resolve tickets faster.
* [Luminar Neo](https://skylum.com/luminar?srsltid=AfmBOoo4GJH0yoyhQDLS9tBXXL_X-NIR9Mr4kzZik6jhHRDcolcY-VHf) is used for image edits like sky replacement, automatic relighting, background removal, and skin retouching for photographers and creatives who need quick yet professional edits (of course, Adobe Photoshop is a competitor here).
* [Runway](https://runwayml.com/) is a leader in ext\-to\-video generation, background removal, object tracking, and frame interpolation.

The list grows daily, with application fields from medical diagnosis to literature. We can only expect this trend to solidify in 2025\.


## 3\. Higher reliability brings trust

2024 brought significant progress in technical aspects of LLMs that apparently are not related to reliability, like the size of the context window (all the information given as input to the chatbot that includes the prompt, but also additional information). But when the context window is used to provide “grounding” information that contains reliable facts, then reliability can be (it is, in fact) greatly improved. Methods like RAG ([Retrieval\-Augmented Generation](https://cloud.google.com/use-cases/retrieval-augmented-generation)) systematize this approach, taking as grounding information either a “[Knowledge Graph](https://www.ibm.com/topics/knowledge-graph#:~:text=A%20knowledge%20graph%2C%20also%20known,illustrates%20the%20relationship%20between%20them.)” (curated bases of factual information, like the huge one built by Google) or just a web search to gather before answering the prompt, the main facts that can be found on the internet).

Other recent AI advances may not be Earth\-shattering, but they contribute to increasing the reliability of AI systems to a certain degree. These include [Model Distillation](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.) (which simplifies complex models into smaller ones), Data Quality improvement techniques (garbage in leads to garbage out, so improving data quality for training translates to better reliability), [Data augmentation](https://www.datacamp.com/tutorial/complete-guide-data-augmentation) (for generating synthetic data) and [Adversarial Training](https://datascientest.com/en/adversarial-training-what-you-didnt-know-yet) (which exposes models to carefully crafted inputs designed to mislead them).

Sundar Pichai declared that in 2025, “the focus will be on improving reasoning capabilities and reliability in AI models.”

Increased reliability will lead to trust: once you see that an AI system gave you correct answers in 100 cases in a row, you tend to take response no. 101 at face value. The problem is that while AI reliability will improve significantly, it will not be a complete assurance in the foreseeable future. This could translate into a lack of human checking and, ultimately, costly mistakes.

We all have heard the story of a lawyer who, during ChatGPT’s early days, was in a hurry to prepare the file for a trial involving Avianca Airline. The problem was that all the prior trial cases mentioned by ChatGPT were utterly made up, something the judge caught, making the lawyer an instant celebrity (in a bad way).


## 2\. Pure scaling is done

Google CEO: Al development is finally slowing down — ‘the low\-hanging fruit is gone” said the CEO of Google at The New York Times DealBook Summit.

Yes, the data available on the Internet has mostly already been used, and there is no “other Internet” to use. So, the approach of improving Generative AI systems mainly by making them bigger, with more parameters and input data, can no longer be the key to making further AI advancements.

Further, Pichai said, “The hill is steeper” and that “progress would require deeper breakthroughs” to tackle more complex challenges.

We must accept that purely scaling up is no longer a valid recipe for improving Generative AI systems.

But some “pundits” (like Gary Marcus) have been taking this to the extreme of deeming AI to have “hit a wall,” beyond which no further progress is possible. I think Marcus is wrong because he underestimates (or ignores?) the value of small algorithmic improvements that are always being proposed by research labs worldwide.

I fully agree with Pichar on this: the hill is steeper, but AI will continue to make incremental progress and no longer rely on scaling.


## 1\. AI Agents will be everywhere

The terms “AI Agents” and “Agentic AI” are overused right now. When I detect hype all over the place, it lightens a red alert light bulb, making me skeptical about the whole thing.

But in the case of Intelligent Agents, I’m stepping on known grounds: I taught the “Multiagent Systems” course for graduate students at my university for over ten years. To me, agents are not just the next shiny thing marketers present.

There are two kinds of agent systems: personal assistants and multiagent systems. The latter involves many agents communicating with each other and cooperating or competing, but I don’t think this is relevant to 2025, so I’ll focus on personal agents.

Personal agents are not new. In 1995, [Nicholas Negroponte](https://en.wikipedia.org/wiki/Nicholas_Negroponte) published the book “[Being Digital](https://en.wikipedia.org/wiki/Being_Digital),” in which he proposed replacing how people had always worked with computers. He called “point\-and\-click” the old paradigm, in which the user chooses something on the screen and an action to take (Wait! Don’t we still use computers this way?).

Negroponte proposed to use a new paradigm called “delegation,” where the human user gives high\-level tasks to the assistant to take responsibility. For instance, the user could charge the assistant to “answer every phone call and say I’m not reachable until noon, except if it’s my mother–then you’d forward the call to me.”

Nice, isn’t it?

In 1995, technology was nowhere close to achieving this vision, so Negroponte’s delegation proposal waited for better times. A few years before, in 1987, a video produced by Apple during the time of the loathed John Sculley at the company's helm presented a futuristic concept for personal assistants.

The video “[The Knowledge Navigator](https://youtu.be/umJsITGzXd0?si=59vcrKiEtXVtR3YO)” depicted the verbal interaction of a professor with an unbelievable assistant who wore a bow tie in a butler style. The butler was capable of answering phone calls and taking messages, combining several information sources, and making summaries and graphs, all of which were tasks delegated by the professor.

Some aspects of the Knowledge Navigator have already been achieved, like verbal interaction, information combination, and making summaries and graphs, but some are not, like taking care of the phone for long periods of time, giving messages to people depending on who they are, and more.

So the question is: how much of the personal agent will be a reality in 2025? I see the following coming:

* AI capable of flexible verbal interaction: Incredible progress has been made in this area, and some of the [Advanced Voice Mode of OpenAI](https://help.openai.com/en/articles/8400625-voice-mode-faq) sound even more human than several humans I know. This could be considered as achieved.
* AI capable of taking action: “Action” could be a very simple thing like setting an alarm, which is partially a reality in platforms like [Apple Intelligence](https://www.apple.com/apple-intelligence/) because Apple owns the whole platform, so they can make use of all apps even more so the ones developed by them, like the clock. But I haven’t seen in Apple Intelligence capabilities like “*when my wife calls me, wait 15 minutes and then call her mother to invite her to the party on Sunday. If she doesn’t take the call, keep calling until she does*.”
* Handling web\-based forms and applications for consulting, registering, modifying, and deleting information linked to a human user’s account. For instance, the AI should be able to purchase concert tickets entirely, fill out all the form fields correctly, and even use the user’s credentials until the operation is done. Perhaps the human could be asked to confirm the final “purchase” button. I’ve seen prototypes of this kind of system already being polished, like Google’s “[Project Mariner](https://deepmind.google/technologies/project-mariner/),” OpenAI’s “[AutoGPT](https://en.wikipedia.org/wiki/AutoGPT),” Hugging Face’s “[HuggingGPT](https://arxiv.org/abs/2303.17580),” Microsoft’s [Copilot](https://support.microsoft.com/en-us/topic/introducing-copilot-agents-943e563d-602d-40fa-bdd1-dbc83f582466), and Anthropic’s “[Computer Use](https://docs.anthropic.com/en/docs/build-with-claude/computer-use).” It’s precisely the abundance of such prototypes that convinces me this is about to become mainstream.

Believe me, agents will be everywhere in 2025!

But don’t expect to have polished agentic apps in 2025 just yet; 2025 will be the year of the “agentic explosion,” but most products will be in beta or worse, and like in the [Cambrian explosion](https://evolution.berkeley.edu/the-cambrian-explosion/), most of them will die out.


## Honorable mentions

These trends or technologies are close to making it to the main list but are not specific to 2025\. I’d include:

* Edge AI and On\-Device Intelligence
* Energy\-Efficient AI Models, AI for Sustainability
* AI regulation for threat mitigation


## Non\-predictions

Now, I’ll turn my attention to the predictions of others that, in my opinion, just won’t happen. In some cases, they are just fantasy; in others, they are overly optimistic thinking; in other instances, it’s mostly fear.


## We won’t have anything like AGI (Artificial General Intelligence) in 2025

Sensationalistic [YouTube videos](https://www.youtube.com/watch?v=awCnd0mDvTM) and even some AI pundits claim that “AGI is near!” Sam Altman gives a “1000 days” timeline, and Elon Musk sees AGI even closer (though, given his track record on promises, it is not very informative).

But the truth is that the problems I mentioned above (reliability, reasoning, product development, self\-driving in the real world) are way more pressing than AGI.

We can also see how the goalposts concerning AGI are being moved: I recently read that AGI is “an AI that can be used across many areas.” Sorry, but it’s not the same “multipurpose AI” as AGI.

When it arrives, AGI will be a big deal from an economic point of view because it won’t have to be trained for each new domain it encounters. AGI’s generalization abilities will allow it to adjust to previously unseen situations, making it almost immediately applicable, which is way cheaper than having to train the AI for each and every domain.

It seems to me that AGI won’t even be in the predictions for 2026…


## AI won’t become conscious in 2025

Some AI enthusiasts pretend that, given AI is advancing at such a fast pace, the next step is to make it “conscious.” They are misled for the following reasons:

First, AI is not about consciousness but about reasoning\-related cognitive abilities. It doesn’t even aim to create sentient creatures.

However, the main argument is that, throughout the collection of methods and technologies developed during the history of AI, none of them is related to consciousness. From intelligent search and alpha\-beta pruning to expert systems to classification or regression, nothing at all relates to consciousness.

Frankly, I think that most people who expect conscious AI are misinterpreting the sometimes expressive — even emotive — prose of Generative AI as “close to consciousness” when it’s not. There is simply “not a soul” there.


## AI won’t wipe us all in 2025

Finally, AI won’t take over in a Terminator\-like apocalypse!

In early 2023, fears about AI going rogue were all over the place, but after several [signed calls](https://readmedium.com/why-i-signed-the-pause-giant-ai-experiments-petition-e9711f672d18?sk=7bc497782d2cf474d970768632d9222c) for stopping AI development before it was too late, 2023 came and went, same (almost) for 2024, and now those calls sound like Aesop’s “The Boy Who Cried Wolf.”

Perhaps my prediction is that in 2025, very few will call for stopping AI before it becomes conscious and goes rogue. More pressing issues about AI, like its effect on the labor market, the mitigation of biases, the remuneration of human work used for AI training, and the limitation of misuse, such as political misinformation, will be finally taken seriously.

There you have it. What are YOUR AI predictions? Post in the comments!

— *Subscribe to my curated AI news insights and technology explainers through my free newsletter, “The Skeptic AI Enthusiast.” Gain a critical perspective on today’s tech landscape from an AI veteran at <https://rafebrena.substack.com/>.*


