---
title: "åˆ©ç”¨ CrewAI æ„å»ºè‡ªä¸»å¤šä»£ç†ç³»ç»Ÿ"
meta_title: "åˆ©ç”¨ CrewAI æ„å»ºè‡ªä¸»å¤šä»£ç†ç³»ç»Ÿ"
description: "æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨CrewAIå’ŒLangChainæ„å»ºè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚æ–‡ç« é¦–å…ˆé˜è¿°äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¦‚å¿µï¼Œå¼ºè°ƒä»£ç†ã€å·¥å…·å’Œä»»åŠ¡çš„åä½œå…³ç³»ã€‚æ¥ç€ï¼Œè¯¦ç»†æè¿°äº†CrewAIæ¡†æ¶çš„ä¼˜åŠ¿å’Œé¡¹ç›®ç»“æ„ï¼ŒåŒ…æ‹¬å¦‚ä½•åˆ›å»ºä»£ç†ã€å®šä¹‰ä»»åŠ¡å’Œä½¿ç”¨å·¥å…·ã€‚é€šè¿‡ä¸€ä¸ªè®ºæ–‡å†™ä½œé¡¹ç›®ç¤ºä¾‹ï¼Œå±•ç¤ºäº†ä»£ç†å¦‚ä½•æ”¶é›†ä¿¡æ¯ã€æ’°å†™å’Œç¼–è¾‘å†…å®¹ã€‚æœ€åï¼Œä½¿ç”¨Streamlitæ¡†æ¶å°†åº”ç”¨ç¨‹åºéƒ¨ç½²ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä¸ç³»ç»Ÿè¿›è¡Œäº¤äº’ã€‚æ•´ä½“ä¸Šï¼Œæ–‡ç« å¼ºè°ƒäº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨æé«˜ä»»åŠ¡æ•ˆç‡å’Œåä½œæ–¹é¢çš„æ½œåŠ›ã€‚"
date: 2024-11-14T03:29:09Z
image: "https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*72Cy_QqOie7G2NAiWr13Kw.jpeg"
categories: ["Autonomous Systems", "Programming", "Data Science"]
author: "Rifx.Online"
tags: ["CrewAI", "LangChain", "multi-agent", "Streamlit", "essay-writing"]
draft: False

---

### ä»€ä¹ˆæ˜¯å¤šæ™ºèƒ½ä½“è‡ªä¸»ç³»ç»Ÿä»¥åŠå¦‚ä½•ä½¿ç”¨CrewAIå’ŒLangChainæ„å»ºä¸€ä¸ªï¼Ÿ



## åŠ¨æœº

å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯¹è¿™äº›æ¦‚å¿µå¹¶ä¸é™Œç”Ÿï¼›æˆ‘ä»¬ä»ç”µå½±ä¸­äº†è§£åˆ°å®ƒä»¬ã€‚ä¸€ä¸ªäººæŒ‡æŒ¥ä»–ä»¬çš„AIï¼Œè€ŒAIé€šè¿‡ä½¿ç”¨å„ç§å·¥å…·æ¥æ‰§è¡Œè¿™äº›å‘½ä»¤ã€‚è¿™å°±æ˜¯æˆ‘ä»¬ä»Šå¤©åœ¨AIç³»ç»Ÿå´›èµ·çš„é“è·¯ä¸Šæ‰€èµ°çš„æ–¹å‘ã€‚æ—¶ä»£æ­£åœ¨é€æ¸å˜åŒ–ã€‚åœ¨è¿‡å»ï¼Œäººä»¬æ— æ³•ç‹¬è‡ªå®Œæˆä¸€é¡¹ä»»åŠ¡ï¼Œéœ€è¦ä¸€ä¸ªå›¢é˜Ÿã€‚æ²¡æœ‰å›¢é˜Ÿï¼Œä»–ä»¬è¦ä¹ˆåœ¨ä¸€æ®µæ—¶é—´åç²¾ç–²åŠ›ç«­ï¼Œè¦ä¹ˆè¾¾åˆ°èƒ½åŠ›çš„æé™ã€‚æœ€ç»ˆï¼ŒæˆåŠŸçš„é¡¹ç›®æ¥è‡ªäºç”±å…·æœ‰ä¸åŒæŠ€èƒ½çš„ä¸ªäººç»„æˆçš„å›¢é˜Ÿã€‚

> å›¢é˜Ÿåˆä½œä½¿æ¢¦æƒ³æˆçœŸã€‚

ç„¶è€Œï¼Œå¦‚ä»Šä¸€ç§æ–°æŠ€æœ¯å¼€å§‹å´­éœ²å¤´è§’ã€‚æˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸ºAGIä¹‹å‰çš„AIä¸‹ä¸€ä¸ªé˜¶æ®µï¼šâ€œä»£ç†â€ã€‚é‚£ä¹ˆï¼Œè¿™äº›ä»£ç†æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿåœ¨æ·±å…¥ä»£ç ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆè°ˆè°ˆå¤šä»£ç†ç³»ç»Ÿçš„ç»“æ„ã€‚

## å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

ç®€å•æ¥è¯´ï¼Œè¿™ä¸ªæ–¹ç¨‹å¼å¯ä»¥è¡¨ç¤ºä¸ºï¼š`Multi Agent Systems = AGENTs + TOOLs + TASKs` è¿™æ˜¯ä¸€ä¸ªå¤šä¸ªä»£ç†é…å¤‡äº†å„ç§ä»»åŠ¡å’Œå·¥å…·çš„ç³»ç»Ÿã€‚

### ä»£ç†

æˆ‘ä»¬ç†Ÿæ‚‰è§’è‰²æ‰®æ¼”æ¸¸æˆï¼Œåœ¨è¿™äº›æ¸¸æˆä¸­ï¼Œä½ çš„è§’è‰²æœ‰ä¸€ä¸ªè§’è‰²ï¼Œæ¯”å¦‚æˆ˜å£«ã€‚ä¾‹å¦‚ã€‚åœ¨æ¸¸æˆä¸­ï¼Œä½ å°†è‡ªå·±ç½®äºä»–ä»¬çš„ä½ç½®ï¼Œæ—¨åœ¨é€šè¿‡å®Œæˆå¡‘é€ ä»–ä»¬èƒŒæ™¯æ•…äº‹çš„ä»»åŠ¡ï¼Œä»ä¸€æ¬¡å†’é™©åˆ°ä¸‹ä¸€æ¬¡å†’é™©æ¥å®Œæˆæ¸¸æˆã€‚ç±»ä¼¼åœ°ï¼Œç ”ç©¶äººå‘˜å‘ç°ï¼Œå½“ç»™å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) è§’è‰²ã€èƒŒæ™¯æ•…äº‹å’Œç›®æ ‡æ—¶ï¼Œå®ƒä»¬å¯ä»¥è¢«æ¿€åŠ±ä»¥æœ€ä½³æ–¹å¼æ‰§è¡Œä»»åŠ¡ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡å‡ ä¸ªç®€å•çš„æç¤ºæ¥æ¿€åŠ± LLM æ‰§è¡Œå„ç§ä»»åŠ¡ã€‚

ä»£ç†æœ¬è´¨ä¸Šå°†åˆ†é…çš„ä»»åŠ¡åˆ†è§£ä¸ºç®€å•çš„æ­¥éª¤ï¼Œç„¶åé€šè¿‡â€œæ€è€ƒâ€â€”â€”æ˜¯çš„ï¼Œæ€è€ƒâ€”â€”æŒ‰é¡ºåºæ‰§è¡Œè¿™äº›æ­¥éª¤ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ›å»ºä¸€ä¸ªä¸ä»…èƒ½æ·±æ€ç†Ÿè™‘åœ°æ‰§è¡Œæ­¥éª¤çš„ä»£ç†ï¼Œè¿˜èƒ½å’¨è¯¢å…¶ä»–å…·æœ‰ä¸åŒä¸“ä¸šé¢†åŸŸçš„ä»£ç†ï¼Œè€Œä¸æ˜¯ä¾èµ–å•ä¸ª LLM è¾“å…¥æç¤ºå¹¶æ¥æ”¶è¾“å‡ºã€‚

### å·¥å…·

äººç±»æœ€ä¼Ÿå¤§çš„èƒ½åŠ›ä¹‹ä¸€æ— ç–‘æ˜¯æˆ‘ä»¬ä½¿ç”¨å·¥å…·çš„æŠ€èƒ½ã€‚è¿™ç§èƒ½åŠ›é€šè¿‡è¿›åŒ–å’Œæ–‡åŒ–è¿‡ç¨‹ä¸æ–­æ¼”å˜å’Œå‘å±•ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ›é€ å‡ºä»Šå¤©æ‰€ä½¿ç”¨çš„å…ˆè¿›æŠ€æœ¯ã€‚åŒæ ·ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹éšç€è®­ç»ƒåœ¨æ›´å¤§æ•°æ®é›†ä¸Šçš„èƒ½åŠ›ä¹Ÿåœ¨ä¸æ–­å¢å¼ºã€‚ç°åœ¨ï¼Œå½“å·¥å…·çš„åŠŸèƒ½åŠå…¶ä½¿ç”¨æ–¹å¼è¢«æ¸…æ™°è§£é‡Šæ—¶ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿåœ¨é€‚å½“æ¡ä»¶ä¸‹è‡ªä¸»ä½¿ç”¨å·¥å…·ï¼Œå®Œå…¨è‡ªåŠ¨æ‰§è¡Œï¼Œå¹¶æ ¹æ®è¾“å‡ºè§„åˆ’ä¸‹ä¸€æ­¥ï¼Œè€Œæ— éœ€ç­‰å¾…è¿›ä¸€æ­¥çš„å‘½ä»¤ã€‚

å› æ­¤ï¼Œå·¥å…·çš„ä½¿ç”¨ä¹Ÿå¯ä»¥è¢«è§†ä¸ºå®ƒä»¬è¿›åŒ–ä¸­æœ€é‡è¦çš„éƒ¨åˆ†ä¹‹ä¸€ã€‚å°¤å…¶æ˜¯é€šè¿‡äº’è”ç½‘æµè§ˆå·¥å…·ï¼Œä»£ç†å¯ä»¥æŒ‰ç…§æŒ‡å®šåŠŸèƒ½çš„æ­¥éª¤è®¿é—®å¿…è¦çš„èµ„æºï¼Œæ— è®ºæ˜¯é€šè¿‡ç½‘ç»œçˆ¬è™«è¿˜æ˜¯ä½¿ç”¨æŒ‡å®šç½‘ç«™çš„æœç´¢å¼•æ“ã€‚

æ‚¨å·¥å…·çš„åŠŸèƒ½å’Œç›®çš„å®Œå…¨å–å†³äºæ‚¨çš„æƒ³è±¡åŠ›ã€‚ç„¶è€Œï¼Œå¦‚æœæ‚¨å¸Œæœ›å°†é¢„æ„å»ºçš„å·¥å…·é›†æˆåˆ°æ‚¨çš„ä»£ç†ä¸­ï¼ŒCrewAI å’Œ LangChain åº“éƒ½æä¾›äº†å¹¿æ³›çš„å†…ç½®å·¥å…·ä¾›æ‚¨ä½¿ç”¨ã€‚åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹åˆ›å»ºæˆ‘ä»¬è‡ªå·±çš„è‡ªå®šä¹‰å·¥å…·ã€‚

### ä»»åŠ¡

å°±åƒæˆ‘ä»¬åˆ›å»ºä»£ç†ä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿåˆ›å»ºä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½éœ€è¦å„ç§å·¥å…·ã€‚ä¸¾ä¸€ä¸ªäººç±»è¡Œä¸ºçš„ä¾‹å­ï¼Œå½“æˆ‘ä»¬éœ€è¦ç ”ç©¶æŸä¸ªäº‹æƒ…æ—¶ï¼Œæˆ‘ä»¬ä¼šåšä»€ä¹ˆï¼Ÿ

1\- æˆ‘ä»¬åœ¨äº’è”ç½‘ä¸Šæœç´¢ã€‚

2\- æˆ‘ä»¬è¿›è¡Œæ·±å…¥çš„æ¥æºç ”ç©¶ã€‚

3\- æˆ‘ä»¬å¯¹æˆ‘ä»¬çš„å‘ç°è¿›è¡Œç¬”è®°ã€‚

ä»¥åŒæ ·çš„æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡ä»»åŠ¡æ¥éµå¾ªè¿™äº›æ­¥éª¤ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä»£ç è®¨è®ºå®ƒä»¬æ˜¯å¦‚ä½•è®¾è®¡çš„ã€‚

## ä»€ä¹ˆæ˜¯ CrewAIï¼Ÿ

CrewAI æ˜¯ä¸€ä¸ªå¼€æºçš„ Python æ¡†æ¶ï¼Œç”¨äºåè°ƒè§’è‰²æ‰®æ¼”çš„è‡ªä¸» AI ä»£ç†ï¼Œå…·æœ‰ Crewã€Taskã€Agentã€Process ç­‰æ–¹æ³•ï¼Œå¹¶æ”¯æŒå¤šç§ LLMï¼ŒåŒ…æ‹¬æœ¬åœ°æ¨¡å‹ã€‚

å¦‚æœæˆ‘ä»¬çœ‹çœ‹è¯¥æ¡†æ¶æä¾›çš„ä¸»è¦ä¼˜åŠ¿ï¼š

* åŸºäºè§’è‰²çš„ä»£ç†è®¾è®¡ã€‚
* è‡ªä¸»çš„ä»£ç†é—´å§”æ´¾ã€‚
* çµæ´»çš„ä»»åŠ¡ç®¡ç†ã€‚
* åŸºäºæµç¨‹çš„æ‰§è¡Œã€‚
* è¾“å‡ºä¿å­˜ä¸º .markdown æ–‡ä»¶ç­‰æ ¼å¼ã€‚
* ä¸å¼€æºå’Œä¸“æœ‰æ¨¡å‹ï¼ˆå¦‚ OpenAIï¼‰å…¼å®¹ã€‚

## æ„å»ºå¤šæ™ºèƒ½ä½“

ä»…ä»…é€šè¿‡æè¿°æ€§çš„è§£é‡Šå¯èƒ½ä¸è¶³ä»¥å®Œå…¨ç†è§£ä¸€ä¸ªæ¦‚å¿µï¼Œå› æ­¤è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå°å‹çš„è®ºæ–‡å†™ä½œé¡¹ç›®ï¼Œä»¥æ›´å¥½åœ°æŒæ¡å¤šæ™ºèƒ½ä½“æ–¹æ³•ã€‚åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†ç»“åˆ LangChain å’Œ CrewAI æ¡†æ¶ã€‚è¦è¿è¡Œè¯¥é¡¹ç›®ï¼Œæ‚¨éœ€è¦ä¸€ä¸ª OpenAI API å¯†é’¥ï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¿é—® [https://proxy.rifx.online/https://platform.openai.com/signup](https://proxy.rifx.online/https://platform.openai.com/signup) æ¥è·å–ã€‚

æˆ‘ä»¬é¡¹ç›®çš„ç»“æ„ç”±å‡ ä¸ªä¸åŒçš„ Python è„šæœ¬ç»„æˆï¼š

* `crew.py`ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„æ™ºèƒ½ä½“åŠå…¶ä»»åŠ¡ã€‚
* `graph.py`ï¼Œæ„å»º LangGraph ç»“æ„ã€‚
* `extra_tools.py`ï¼ŒåŒ…å«æˆ‘ä»¬çš„æ™ºèƒ½ä½“å°†ä½¿ç”¨çš„å·¥å…·ã€‚
* `pdf_writer.py`ï¼Œè´Ÿè´£å°†è®ºæ–‡è½¬æ¢ä¸º PDFã€‚
* `app.py`ï¼Œä¸ºæˆ‘ä»¬çš„åº”ç”¨ç¨‹åºæä¾› Streamlit ç•Œé¢ã€‚

```python
## é¡¹ç›®ç»“æ„
Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer
â”œâ”€â”€ app.py              # ä¸»è¦çš„ streamlit åº”ç”¨ç¨‹åº
â”œâ”€â”€ crew.py             # CrewAI æ™ºèƒ½ä½“å’Œä»»åŠ¡å¤„ç†
â”œâ”€â”€ extra_tools.py      # æ™ºèƒ½ä½“å·¥å…·çš„åŠŸèƒ½
â”œâ”€â”€ graph.py            # LangGraph å’Œé¡¹ç›®å·¥ä½œæµç¨‹
â”œâ”€â”€ pdf_writer.py       # å¤„ç† PDF è¾“å‡ºç”Ÿæˆ
â”œâ”€â”€ requirements.txt    # æ‰€éœ€åº“åˆ—è¡¨
â”œâ”€â”€ media
â”‚   â””â”€â”€ cover.jpg       # é¡¹ç›®å°é¢å›¾åƒ
â””â”€â”€ README.md        
```

è¯¥é¡¹ç›®æ‰€éœ€çš„åº“åˆ—åœ¨ `requirements.txt` æ–‡ä»¶ä¸­ã€‚æ­¤å¤–ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£… Python 3\.12 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚åœ¨è¿è¡Œé¡¹ç›®ä¹‹å‰ï¼Œè¯·ä¸è¦å¿˜è®°å®‰è£…ä¾èµ–é¡¹ã€‚æˆ‘ä»¬ä½¿ç”¨çš„åº“åŒ…æ‹¬ï¼š

```python
langchain-core
langchain-openai
langgraph
streamlit
wikipedia
reportlab
crewai[tools]
pysqlite3-binary
bs4
```

### å·¥ä½œæµç¨‹

åœ¨æˆ‘ä»¬çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸ºä»£ç†åˆ†é…å„ç§è§’è‰²ã€‚ä¾‹å¦‚ï¼Œå½“ä¸€ä¸ªä»£ç†ç­‰å¾…å¦ä¸€ä¸ªä»£ç†å®Œæˆå…¶åœ¨äº’è”ç½‘ä¸Šç ”ç©¶çš„ä»»åŠ¡æ—¶ï¼Œå¦ä¸€ä¸ªä»£ç†å°†ç‹¬ç«‹è¿›è¡Œç»´åŸºç™¾ç§‘çš„ç ”ç©¶ã€‚ä¸€æ—¦ä¸¤ä¸ªä»£ç†éƒ½å®Œæˆäº†ä»–ä»¬çš„ä»»åŠ¡ï¼Œç­‰å¾…ä¿¡æ¯çš„ä»£ç†å°†ç»§ç»­è¿›è¡Œå†™ä½œï¼Œè¿™æ˜¯ä»–ä»¬è¢«åˆ†é…çš„ä»»åŠ¡ã€‚

å¦‚æœæˆ‘ä»¬è¦å°†å…¶å¯è§†åŒ–ï¼š

![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Emb37H_8OAKp1s1ChLLVQg.png)

* ç”¨æˆ·æŸ¥è¯¢æœ€åˆå‘é€åˆ°è·¯ç”±å™¨ã€‚
* è·¯ç”±å™¨è¯»å–æŸ¥è¯¢å¹¶ç¡®å®šç”¨æˆ·æ˜¯æƒ³å†™ä¸€ç¯‡æ–°æ–‡ç« ã€ç¼–è¾‘ä¹‹å‰çš„æ–‡ç« ï¼Œè¿˜æ˜¯ä»…ä»…ä¼ è¾¾ä¸€ä¸ªè®¨è®ºä¸»é¢˜ã€‚å¦‚æœç”¨æˆ·å¸Œæœ›å†™ä¸€ç¯‡æ–°æ–‡ç« ï¼Œè¯·æ±‚å°†è½¬å‘ç»™å°ç»„ã€‚
* å‘é€åˆ°å°ç»„çš„è¯·æ±‚é¦–å…ˆå‘é€ç»™ç ”ç©¶ä»£ç†ã€‚
* ç ”ç©¶ä»£ç†ä½¿ç”¨åˆ†é…ç»™ä»–çš„å·¥å…·æœç´¢ä¸ç”¨æˆ·æƒ³è¦å†™çš„ä¸»é¢˜ç›¸å…³çš„äº’è”ç½‘èµ„æºã€‚
* ä¸€æ—¦èµ„æºæ”¶é›†è¿‡ç¨‹å®Œæˆï¼Œæ”¶é›†åˆ°çš„ä¿¡æ¯å°†è½¬å‘ç»™å†™ä½œä»£ç†ã€‚
* å½“å†™ä½œä»£ç†èµ·è‰æ–‡ç« æ—¶ï¼Œç¼–è¾‘ä»£ç†è¿›è¡Œæœ€ç»ˆè°ƒæ•´ï¼Œçº æ­£è¯­æ³•é”™è¯¯ï¼Œå¹¶å°†è‰ç¨¿ä½œä¸ºJSONæ–‡ä»¶è¿”å›ç»™LangGraphã€‚
* JSONæ–‡ä»¶å°†å‘é€åˆ°å°†åœ¨æœ€ç»ˆèŠ‚ç‚¹åˆ›å»ºæˆ‘ä»¬æ–‡ç« çš„PDFæ–‡ä»¶çš„åŠŸèƒ½ã€‚

### æ„å»º LangGraph

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å»ºç«‹æˆ‘ä»¬æ¶æ„çš„æ¡†æ¶ã€‚ä¸€æ—¦æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå·¥ä½œæµç¨‹ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨éœ€è¦æ—¶ä¸æˆ‘ä»¬çš„ä»£ç†è¿›è¡Œè”ç³»ï¼Œå‰©ä¸‹çš„å°±æ˜¯å†³å®šåœ¨å·¥ä½œæµç¨‹çš„å“ªäº›é˜¶æ®µæˆ‘ä»¬å°†å‘æˆ‘ä»¬çš„ä»£ç†å‘é€è¯·æ±‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨ LangChain åˆ›å»ºä¸€ä¸ªç®€å•çš„å·¥ä½œæµç¨‹ã€‚

![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iHQzJymxAstrW40THoRxwA.png)

```python
#LangGraph workflow

builder = StateGraph(GraphState)

builder.add_node("answer", self.answer)
builder.add_node("write_essay", self.write_essay)
builder.add_node("edit_essay", self.edit_essay)


builder.set_conditional_entry_point(self.router_query,
                              {"write_essay": "write_essay",
                                        "answer": "answer",
                                        "edit_essay": "edit_essay"})
builder.add_edge("write_essay", END)
builder.add_edge("edit_essay", END)
builder.add_edge("answer", END)

self.graph = builder.compile()
```

**è·¯ç”±èŠ‚ç‚¹**ï¼šæ­£å¦‚æˆ‘ä»¬åœ¨å·¥ä½œæµç¨‹æè¿°ä¸­æåˆ°çš„ï¼Œæˆ‘ä»¬çš„è·¯ç”±å™¨æ ¹æ®ä¼ å…¥è¯·æ±‚å°†ä»»åŠ¡åˆ†é…ç»™å„ä¸ªèŠ‚ç‚¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæœ‰æ•ˆçš„æç¤ºï¼Œæ¶µç›–ç”¨æˆ·æä¾›çš„ä¸»é¢˜å¹¶ç»“åˆè¿‡å»çš„å¯¹è¯ã€‚æ¯•ç«Ÿï¼Œæˆ‘ä»¬æ­£åœ¨å¼€å‘ä¸€ä¸ªå¤šä»£ç†çš„ä½œæ–‡å†™ä½œèŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥è®°ä½å¹¶å›å¿†ä¹‹å‰çš„è®¨è®ºã€‚

è®©æˆ‘ä»¬èµ·è‰ä¸€ä¸ªç®€å•çš„æç¤ºå’Œç›¸åº”çš„èŠ‚ç‚¹æ¥åˆ©ç”¨è¿™ä¸ªæç¤ºã€‚åœ¨æç¤ºä¸­ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨ Pydantic åº“å®šä¹‰ä¸€ä¸ª `BaseModel`ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„è·¯ç”±å™¨é€‰æ‹©ä¸‰ç§æ½œåœ¨å“åº”ç­–ç•¥ä¸­çš„ä¸€ç§ã€‚è¿™äº›ç­–ç•¥å°†æŒ‡å¯¼èŠå¤©æœºå™¨äººæœ‰æ•ˆåœ°åˆ¶å®šå…¶å“åº”ã€‚

åœ¨èŠ‚ç‚¹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Langchain çš„ `PromptTemplate` æ–¹æ³•å®ç°è¿™ä¸ªæç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è°ƒç”¨ LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ï¼Œå°†ç”¨æˆ·æŸ¥è¯¢å’Œå¯¹è¯å†å²ä¸€èµ·ä¼ å…¥ï¼Œä»¥ç¡®ä¿å“åº”åœ¨ä¸Šä¸‹æ–‡ä¸Šç›¸å…³å¹¶ç¬¦åˆç”¨æˆ·çš„éœ€æ±‚ã€‚

1. **å®šä¹‰ Pydantic æ¨¡å‹**ï¼šåˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼ŒæŒ‡å®šæ‰€éœ€çš„å“åº”ç­–ç•¥ã€‚
2. **æ„å»ºæç¤º**ï¼šç¼–å†™ä¸€ä¸ªæ¸…æ™°æ¦‚è¿°ä¸‰ç§ç­–ç•¥çš„æç¤ºã€‚
3. **è®¾ç½®èŠ‚ç‚¹**ï¼šä½¿ç”¨ Langchain çš„ `PromptTemplate` åŠ¨æ€æ ¼å¼åŒ–æç¤ºã€‚
4. **è°ƒç”¨ LLM**ï¼šä½¿ç”¨æ ¼å¼åŒ–çš„æç¤ºã€ç”¨æˆ·æŸ¥è¯¢å’Œå¯¹è¯å†å²è°ƒç”¨ LLMã€‚

é€šè¿‡éµå¾ªè¿™äº›æ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿èŠå¤©æœºå™¨äººå‡†ç¡®å“åº”å¹¶ä¿æŒä¹‹å‰äº’åŠ¨çš„ä¸Šä¸‹æ–‡ã€‚

```python
#Router Prompt and Router Node
class RouteQuery(BaseModel):
    """å°†ç”¨æˆ·æŸ¥è¯¢è·¯ç”±åˆ°ç›´æ¥å›ç­”æˆ–ç ”ç©¶ã€‚"""

    way: Literal["edit_essay","write_essay", "answer"] = Field(
        ...,
        description="æ ¹æ®ç”¨æˆ·é—®é¢˜é€‰æ‹©å°†å…¶è·¯ç”±åˆ° write_essayã€edit_essay æˆ– answer",
    )

self.router_prompt = 
    """
    ä½ æ˜¯ä¸€ä¸ªè·¯ç”±å™¨ï¼Œä½ çš„èŒè´£æ˜¯å°†ç”¨æˆ·å¼•å¯¼åˆ°æ­£ç¡®çš„ä¸“å®¶ã€‚
    å§‹ç»ˆæ£€æŸ¥å¯¹è¯å†å²ï¼Œå¹¶æ ¹æ®å…¶è€ƒè™‘ä½ çš„è¡ŒåŠ¨ã€‚
    å¦‚æœä¸»é¢˜æ˜¯å…³äºè®°å¿†æˆ–æ—¥å¸¸è°ˆè¯ï¼Œå°†ç”¨æˆ·å¼•å¯¼åˆ°å›ç­”ä¸“å®¶ã€‚
    å¦‚æœä¸»é¢˜ä»¥â€œä½ èƒ½å†™...â€å¼€å¤´ï¼Œæˆ–è€…ç”¨æˆ·è¯·æ±‚ä½ å†™ä¸€ç¯‡æ–‡ç« æˆ–è®ºæ–‡ï¼Œå°†ç”¨æˆ·å¼•å¯¼åˆ°å†™ä½œä¸“å®¶ã€‚
    å¦‚æœä¸»é¢˜æ˜¯ç”¨æˆ·æƒ³è¦ç¼–è¾‘è®ºæ–‡ä¸­çš„ä»»ä½•å†…å®¹ï¼Œå°†ç”¨æˆ·å¼•å¯¼åˆ°ç¼–è¾‘ä¸“å®¶ã€‚
  
    \nå¯¹è¯å†å²: {memory}
    \nä¸»é¢˜: {topic}
    """

def router_query(self, state: GraphState):
    print("**ROUTER**")
    prompt = PromptTemplate.from_template(self.router_prompt)
    memory = self.memory.load_memory_variables({})

    router_query = self.model.with_structured_output(RouteQuery)
    chain = prompt | router_query
    result:  RouteQuery = chain.invoke({"topic": state["topic"],
                                       "memory": memory})

    print("Router Result: ", result.way)
    return result.way
```

**ç®€å•å›ç­”èŠ‚ç‚¹**ï¼šåœ¨å°†æˆ‘ä»¬çš„è·¯ç”±å™¨ä½œä¸ºå¼€å§‹éƒ¨åˆ†çš„èŠ‚ç‚¹åï¼Œä¸‹ä¸€æ­¥æ˜¯åˆ›å»ºå…¶ä»–ä¸‰ä¸ªèŠ‚ç‚¹ï¼š`write_essay`ã€`edit_essay` å’Œ `answer`ã€‚ä¸ºäº†é‡‡å–ç®€å•çš„æ–¹å¼ï¼Œæˆ‘ä»¬éœ€è¦ç¼–ç¨‹æˆ‘ä»¬çš„ `answer` èŠ‚ç‚¹ï¼Œä»¥ä¾¿åœ¨ç”¨æˆ·å‘é€éšæ„æ¶ˆæ¯æˆ–å‚ä¸æœ‰å…³è®ºæ–‡çš„å¯¹è¯æ—¶ç›´æ¥ä½¿ç”¨å…¶è®°å¿†ç”Ÿæˆå“åº”ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆä¸ºæ­¤ä»»åŠ¡ç¼–å†™ä¸€ä¸ªåˆé€‚çš„æç¤ºã€‚ç„¶åï¼Œåˆ©ç”¨è¿™ä¸ªæç¤ºï¼Œæˆ‘ä»¬å°†è®¾è®¡ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹ã€‚è®©æˆ‘ä»¬ç»§ç»­è¿™ä¸ªè®¾è®¡ã€‚

```python
#Simple Answer Prompt and Node

self.simple_answer_prompt = 
      """
      ä½ æ˜¯ä¸€ä¸ªä¸“å®¶ï¼Œä½ æ­£åœ¨ä¸ºç”¨æˆ·çš„é—®é¢˜æä¾›ç®€å•çš„ 
      ç­”æ¡ˆã€‚
    
      \nå¯¹è¯å†å²: {memory}
      \nä¸»é¢˜: {topic}
      """
def answer(self, state: GraphState):
    print("**ANSWER**")
    prompt = PromptTemplate.from_template(self.simple_answer_prompt)
    memory = self.memory.load_memory_variables({})
    chain = prompt | self.model | StrOutputParser()
    result = chain.invoke({"topic": state["topic"], "memory": memory})

    self.memory.save_context(inputs={"input": state["topic"]}, outputs={"output": result})
    return {"response": result}
```

**å†™ä½œèŠ‚ç‚¹**ï¼šæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦è®¾è®¡ `writing_essay` èŠ‚ç‚¹ã€‚è¯¥èŠ‚ç‚¹çš„ç›®çš„æ˜¯ä½¿ç”¨ CrewAI çš„ `kickoff` æ–¹æ³•å°†ç”¨æˆ·æ”¶åˆ°çš„æŸ¥è¯¢è½¬å‘ç»™æˆ‘ä»¬çš„ä»£ç†ï¼Œç„¶åå°†ä»£ç†è¿”å›çš„ JSON æ–‡ä»¶è½¬æ¢ä¸º PDFã€‚è‡ªç„¶ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä¸ºè¿™ä¸ªèŠ‚ç‚¹ç¼–å†™æç¤ºï¼Œå› ä¸ºæç¤ºå°†åœ¨ä»£ç†åˆ›å»ºé˜¶æ®µå®šä¹‰ã€‚è¿™ä¸ªèŠ‚ç‚¹å°†ä»…ç”¨äºè°ƒç”¨ä»£ç†å’Œåˆ©ç”¨è¿”å›çš„å€¼ã€‚

1. **è°ƒç”¨ä»£ç†**ï¼šä½¿ç”¨ CrewAI çš„ `kickoff` æ–¹æ³•å°†ç”¨æˆ·çš„æŸ¥è¯¢å‘é€ç»™ä»£ç†ã€‚
2. **å¤„ç†è¿”å›çš„ JSON**ï¼šå¤„ç†ä»ä»£ç†æ”¶åˆ°çš„ JSON å“åº”ã€‚
3. **è½¬æ¢ä¸º PDF**ï¼šå°† JSON ä¸­çš„ç›¸å…³æ•°æ®è½¬æ¢ä¸º PDF æ ¼å¼ã€‚

```python
#Write Essay Node
def write_essay(self, state: GraphState):
    print("**ESSAY COMPLETION**")

    self.essay = self.crew.kickoff({"topic": state["topic"]})

    self.memory.save_context(inputs={"input": state["topic"]},
                           outputs={"output": str(self.essay)})

    pdf_name = generate_pdf(self.essay)
    return {"response": "è¿™æ˜¯ä½ çš„è®ºæ–‡ï¼",  "pdf_name": f"{pdf_name}"}
```

**ç¼–è¾‘è®ºæ–‡èŠ‚ç‚¹**ï¼šè®©æˆ‘ä»¬ç®€è¦è®¨è®ºæˆ‘ä»¬çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ `edit_essay`ã€‚ä»£ç å¯èƒ½çœ‹èµ·æ¥æœ‰ç‚¹å†—é•¿ï¼Œå› ä¸ºæç¤ºè¢«ä¿ç•™åœ¨èŠ‚ç‚¹å†…ã€‚å¦‚æœä½ æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨ç±»å®šä¹‰æœŸé—´ç¼–å†™æç¤ºå¹¶å°†å…¶åˆ†é…ä¸ºå˜é‡ã€‚

å½“è·¯ç”±å™¨æ£€æµ‹åˆ°ç”¨æˆ·çš„ä»»ä½•è®ºæ–‡ä¿®æ”¹è¯·æ±‚æ—¶ï¼Œå°†æ¿€æ´»è¯¥èŠ‚ç‚¹ã€‚åœ¨æ­¤èŠ‚ç‚¹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸‰ä¸ªé‡è¦å€¼ï¼šå¯¹è¯å†å²ã€ç”¨æˆ·è¯·æ±‚å’Œæœ€è¿‘ç”Ÿæˆçš„è®ºæ–‡ã€‚æ­¤å¤–ï¼Œæç¤ºä¸­æœ‰ä¸€ä¸ªå˜é‡ï¼ŒLangchain å°†ç”Ÿæˆï¼Œç§°ä¸º `format_instructions`ã€‚è¿™ä¸ªå˜é‡ä½¿æˆ‘ä»¬èƒ½å¤Ÿå‘ LLM ä¼ è¾¾æˆ‘ä»¬å¸Œæœ›ä¿æŒç¼–è¾‘è®ºæ–‡ JSON æ ¼å¼çš„ç»“æ„ï¼Œå¹¶ä»¥ç›¸åŒæ ¼å¼æ¥æ”¶å“åº”ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†æŠŠè¿”å›çš„å“åº”å‘é€åˆ°æˆ‘ä»¬çš„ PDF ç”Ÿæˆå·¥å…·ã€‚

1. **æ£€æµ‹ç¼–è¾‘è¯·æ±‚**ï¼šè·¯ç”±å™¨è¯†åˆ«ç”¨æˆ·è¯·æ±‚æ˜¯å¦ä¸ºç¼–è¾‘è®ºæ–‡ã€‚
2. **æ”¶é›†å¿…è¦å€¼**ï¼šæ”¶é›†å¯¹è¯å†å²ã€ç”¨æˆ·è¯·æ±‚å’Œæœ€åç”Ÿæˆçš„è®ºæ–‡ã€‚
3. **åˆ›å»ºå¹¶ä½¿ç”¨æç¤º**ï¼šæ„å»ºä¸€ä¸ªåŒ…å« `format_instructions` çš„æç¤ºã€‚
4. **ç”Ÿæˆç¼–è¾‘åçš„è®ºæ–‡**ï¼šè°ƒç”¨ LLM è·å–ç¼–è¾‘åçš„è®ºæ–‡ï¼Œå¹¶å°†å“åº”ä¼ é€’ç»™ PDF ç”Ÿæˆå™¨ã€‚

```python
#Edit Essay Node

def edit_essay(self, state: GraphState):
    print("**ESSAY EDIT**")
    memory = self.memory.load_memory_variables({})

    user_request = state["topic"]
    parser = JsonOutputParser(pydantic_object=Essay)
    prompt = PromptTemplate(
      template=("æŒ‰ç…§ç”¨æˆ·è¯·æ±‚ç¼–è¾‘ JSON æ–‡ä»¶ï¼Œå¹¶è¿”å›æ–°çš„ JSON æ–‡ä»¶ã€‚"
                "\nè¯·æ±‚:{user_request} "
                "\nå¯¹è¯å†å²: {memory}"
                "\n JSON æ–‡ä»¶: {essay}"
                " \n{format_instructions}"),
      input_variables=["memory","user_request","essay"],
      partial_variables={"format_instructions": parser.get_format_instructions()},
  )

    chain = prompt | self.model | parser

    self.essay = chain.invoke({"user_request": user_request,
                               "memory": memory, 
                                "essay": self.essay})


    self.memory.save_context(inputs={"input": state["topic"]},
                             outputs={"output": str(self.essay)})
    pdf_name = generate_pdf(self.essay)
    return {"response": "è¿™æ˜¯ä½ çš„ç¼–è¾‘åçš„è®ºæ–‡ï¼", 
            "essay": self.essay, "pdf_name": f"{pdf_name}"}
```

## æ„å»ºä»£ç†

**å†…å®¹ç ”ç©¶å‘˜**ï¼šä¸ºäº†ä¿æŒæˆ‘ä»¬çš„é¡¹ç›®ç®€å•ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸‰ä¸ªä»£ç†ï¼Œå®ƒä»¬å°†ç›¸äº’é€šä¿¡å¹¶è¿›è¡Œäº’è”ç½‘æœç´¢ä»¥æ’°å†™æ–‡ç« ã€‚è®©æˆ‘ä»¬è®¾è®¡ç¬¬ä¸€ä¸ªä»£ç†ï¼Œç ”ç©¶å‘˜ä»£ç†ã€‚è¯¥ä»£ç†å°†å¯¹ç»´åŸºç™¾ç§‘å’Œå…¶ä»–ç½‘ç«™è¿›è¡Œç½‘é¡µæŠ“å–ï¼Œæ”¶é›†å¿…è¦çš„æ¥æºï¼Œç›´åˆ°å®ƒç¡®å®šå·²æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ã€‚å®ƒå°†è·å–ä¸ä¸»é¢˜ç›¸å…³çš„ä¸»è¦æ ‡é¢˜ã€å‰¯æ ‡é¢˜å’Œæ–‡ç« ï¼Œå¹¶å‡†å¤‡æ‘˜è¦ã€‚éšåï¼Œè¿™äº›æ–‡æ¡£å°†è¢«å­˜å‚¨ï¼Œä»¥ä¾¿å‘é€ç»™å†™ä½œä»£ç†ã€‚

åœ¨è®¾è®¡è¿™ä¸ªä»£ç†æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘å®ƒçš„è§’è‰²ã€èƒŒæ™¯æ•…äº‹å’Œç›®æ ‡ã€‚æˆ‘ä»¬å°†è¿™äº›åˆ†é…ç»™`Agent`ç±»ä¸­çš„å‚æ•°ï¼Œç±»ä¼¼äºæ„å»ºæç¤ºï¼Œä»è€Œä¸ºä»£ç†çš„æ“ä½œåšå¥½å‡†å¤‡ã€‚

```python
#Content Researcher Agent and Task

self.researcher = Agent(
    role="Content Researcher",

    goal="Research accurate content on {topic}",

    backstory="You're researching content to write 
                an essay about the topic: {topic}."
              "You collect information that helps 
                the audience learn something and make informed decisions."
              "Your work is the basis for the Content Writer to 
                write an article on this topic.",
    verbose=True
)

self.research = Task(
    description=(
        "1. Prioritize the latest trends, key players, 
            and noteworthy news on {topic}.\n"
        "2. Identify the target audience, considering their 
            interests and pain points.\n"
        "3. Research a detailed content outline including 
            an introduction, key points, and a conclusion.\n"
        "4. Include SEO keywords and relevant data or sources."
    ),
    expected_output="A comprehensive document with an outline, 
                    audience analysis, SEO keywords, and resources.",
    tools=[search_wikipedia, scrap_webpage],
    agent=self.researcher,
)
```

æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸¤ä¸ªç±»ï¼š`Agent`å’Œ`Task`ã€‚æ¯ä¸ªä»£ç†å¯ä»¥æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªåˆ†é…çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥å°†å·¥å…·åˆ†é…ç»™ä»£ç†ï¼Œæˆ–è€…æ·»åŠ ç‰¹å®šäºä»»åŠ¡çš„å·¥å…·ã€‚é€šè¿‡ä¸ºä»»åŠ¡ä¸“é—¨æ·»åŠ å·¥å…·ï¼Œæˆ‘ä»¬ç¡®ä¿è¯¥å·¥å…·ä»…åœ¨ç‰¹å®šä»»åŠ¡ä¸­ä½¿ç”¨ã€‚

### å‚æ•°

æˆ‘ä»¬çš„ `Agent` ç±»çš„å‚æ•°ï¼š

1. **è§’è‰²**ï¼šå®šä¹‰ä»£ç†åœ¨å›¢é˜Ÿä¸­çš„åŠŸèƒ½ã€‚å®ƒå†³å®šäº†ä»£ç†æœ€é€‚åˆæ‰§è¡Œçš„ä»»åŠ¡ç±»å‹ï¼Œåº”ç®€çŸ­ä¸”å…·æœ‰æè¿°æ€§ã€‚
2. **ç›®æ ‡**ï¼šè¿™æ˜¯ä»£ç†æ—¨åœ¨å®ç°çš„ä¸ªäººç›®æ ‡ã€‚å®ƒæŒ‡å¯¼ä»£ç†çš„å†³ç­–è¿‡ç¨‹ï¼Œåº”ç®€çŸ­ä¸”ç®€å•ã€‚
3. **èƒŒæ™¯æ•…äº‹**ï¼šä¸ºä»£ç†çš„è§’è‰²å’Œç›®æ ‡æä¾›èƒŒæ™¯ï¼Œä¸°å¯Œäº’åŠ¨å’Œåä½œåŠ¨æ€ã€‚åº”å°½å¯èƒ½è¯¦ç»†ã€‚
4. **è¯¦ç»†**ï¼šå°†å…¶è®¾ç½®ä¸º `True` å¯é…ç½®å†…éƒ¨è®°å½•å™¨ï¼Œæä¾›è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—ï¼Œæœ‰åŠ©äºè°ƒè¯•å’Œç›‘æ§æˆ‘ä»¬çš„ä»£ç†æ­£åœ¨è¿›è¡Œçš„æ´»åŠ¨ã€‚

æˆ‘ä»¬çš„ `Task` ç±»çš„å‚æ•°ï¼š

1. **æè¿°**ï¼šå¯¹ä»»åŠ¡å†…å®¹çš„æ¸…æ™°ç®€æ´çš„é™ˆè¿°ã€‚åº”å°½å¯èƒ½è¯¦ç»†ä»¥ç¡®ä¿æ¸…æ™°ã€‚
2. **é¢„æœŸè¾“å‡º**ï¼šå¯¹ä»»åŠ¡å®Œæˆåç»“æœçš„è¯¦ç»†æè¿°ï¼Œæœ‰åŠ©äºè®¾å®šå¯¹ç»“æœçš„æ˜ç¡®æœŸæœ›ã€‚
3. **å·¥å…·**ï¼šä»£ç†å¯ä»¥åˆ©ç”¨æ¥æ‰§è¡Œä»»åŠ¡çš„åŠŸèƒ½æˆ–èƒ½åŠ›ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦ä½¿ç”¨ LangChainã€CrewAI æˆ–è‡ªå®šä¹‰å·¥å…·ã€‚
4. **ä»£ç†**ï¼šè´Ÿè´£è¯¥ä»»åŠ¡çš„ä»£ç†ï¼Œå¯ä»¥ç›´æ¥åˆ†é…æˆ–é€šè¿‡å›¢é˜Ÿçš„æµç¨‹åˆ†é…ã€‚

![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ocQ9ZUZwFtGx7a7pPrTbuQ.png)

**å†…å®¹æ’°å†™è€…**ï¼šä¸€æ—¦æˆ‘ä»¬çš„ç ”ç©¶ä»£ç†é€šè¿‡å¤šæ¬¡è¿­ä»£æ”¶é›†äº†å¿…è¦çš„ä¿¡æ¯ï¼Œå®ƒå°†æŠŠæ”¶é›†åˆ°çš„æ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè®¤ä¸ºè‡ªå·±å·²è·å¾—è¶³å¤Ÿçš„çŸ¥è¯†ï¼Œå¹¶å°†ä»»åŠ¡ä¼ é€’ç»™æˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªä»£ç†ï¼Œå†…å®¹æ’°å†™è€…ã€‚

![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HD1Bm7twxsUIVGPiqEhHAg.png)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„å†…å®¹æ’°å†™è€…ä»£ç†åŠå…¶è§’è‰²ã€‚è¯¥ä»£ç†ä¸éœ€è¦ä½¿ç”¨ä»»ä½•å·¥å…·ï¼Œå› æ­¤åªéœ€è¯¦ç»†è¯´æ˜èƒŒæ™¯æ•…äº‹å’Œæè¿°ï¼Œç±»ä¼¼äºç ”ç©¶ä»£ç†ã€‚åœ¨èƒŒæ™¯æ•…äº‹ä¸­ï¼Œæˆ‘ä»¬å¿…é¡»è®°å¾—æŒ‡å®šå“ªä¸ªä»£ç†æä¾›äº†ä¿¡æ¯æ¥æºã€‚

### å‚æ•°

1. **è§’è‰²**ï¼šé¡¹ç›®ä¸­å†…å®¹ç¼–å†™ä»£ç†çš„åŠŸèƒ½ã€‚è¿™åº”ç®€æ´åœ°æ•æ‰ä»£ç†çš„ä½œç”¨ã€‚
2. **ç›®æ ‡**ï¼šå†…å®¹ç¼–å†™è€…æ—¨åœ¨å®ç°çš„å…·ä½“ç›®æ ‡ï¼Œä¾‹å¦‚æ ¹æ®æ”¶é›†çš„ä¿¡æ¯æ’°å†™ä¸€ç¯‡ç»“æ„è‰¯å¥½çš„æ–‡ç« ã€‚
3. **èƒŒæ™¯æ•…äº‹**ï¼šä¸ºå†…å®¹ç¼–å†™è€…çš„è§’è‰²æä¾›ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬å…³äºç ”ç©¶è€…ä»£ç†åŠå…¶æä¾›çš„ä¿¡æ¯çš„è¯¦ç»†ä¿¡æ¯ã€‚ç²¾å¿ƒåˆ¶ä½œçš„èƒŒæ™¯æ•…äº‹å¯ä»¥å¢å¼ºå™è¿°å’Œåä½œåŠ¨æ€ã€‚
4. **æè¿°**ï¼šå¯¹å†…å®¹ç¼–å†™è€…æ‰€åšå·¥ä½œçš„æ¸…æ™°ç®€æ´çš„é™ˆè¿°ï¼Œé‡ç‚¹å…³æ³¨å…¶èŒè´£å’Œä»»åŠ¡ã€‚
5. **é¢„æœŸè¾“å‡º**ï¼šå¯¹ä»»åŠ¡å®Œæˆçš„è¯¦ç»†æè¿°ï¼Œå¸®åŠ©è®¾å®šå¯¹ç»“æœçš„æ˜ç¡®æœŸæœ›ã€‚
6. **ä¸Šä¸‹æ–‡**ï¼šåœ¨æ‰§è¡Œä»»åŠ¡ä¹‹å‰ï¼Œæˆ‘ä»¬æŒ‡å®šè¦ç­‰å¾…å®Œæˆçš„ä»»åŠ¡ï¼Œå¹¶ä»è¯¥ä»»åŠ¡è¾“å‡ºä¸­è·å–å¿…è¦çš„ä¿¡æ¯ï¼Œç»“åˆä¸Šä¸‹æ–‡å‚æ•°ã€‚

```python
#Content Writer Agent and Task

self.writer = Agent(
  role="Content Writer",

  goal="æ’°å†™æœ‰å…³æä¾›ä¸»é¢˜çš„æ·±åˆ»ä¸”äº‹å®å‡†ç¡®çš„ "
       "è§‚ç‚¹æ–‡ç« ",

  backstory="æ‚¨æ­£åœ¨æ’°å†™ä¸€ç¯‡å…³äºæä¾›ä¸»é¢˜çš„æ–°è§‚ç‚¹æ–‡ç« ã€‚"
            "æ‚¨åŸºäºå†…å®¹ç ”ç©¶å‘˜çš„å·¥ä½œï¼Œè¯¥ç ”ç©¶å‘˜æä¾›äº†ä¸»é¢˜çš„æçº²å’Œç›¸å…³èƒŒæ™¯ä¿¡æ¯ã€‚"
            "æ‚¨éµå¾ªå†…å®¹ç ”ç©¶å‘˜æä¾›çš„æçº²çš„ä¸»è¦ç›®æ ‡å’Œæ–¹å‘ã€‚"
            "æ‚¨è¿˜æä¾›å®¢è§‚å’Œå…¬æ­£çš„è§è§£ï¼Œå¹¶ç”¨å†…å®¹ç ”ç©¶å‘˜æä¾›çš„ä¿¡æ¯è¿›è¡Œæ”¯æŒã€‚",
  verbose=True,
)

self.write = Task(
  description=(
      "1. ä½¿ç”¨å†…å®¹æ’°å†™ä¸€ç¯‡å¼•äººå…¥èƒœçš„æ–‡ç« ã€‚\n"
      "2. è‡ªç„¶åœ°èå…¥SEOå…³é”®è¯ã€‚\n"
      "3. å„éƒ¨åˆ†/å‰¯æ ‡é¢˜ä»¥å¼•äººå…¥èƒœçš„æ–¹å¼å‘½åã€‚\n"
      "4. ç¡®ä¿æ–‡ç« ç»“æ„åˆç†ï¼ŒåŒ…å«å¼•äººå…¥èƒœçš„å¼•è¨€ã€æ·±åˆ»çš„ä¸»ä½“å’Œæ€»ç»“æ€§çš„ç»“è®ºã€‚\n"
      "5. æ ¡å¯¹è¯­æ³•é”™è¯¯å¹¶ç¡®ä¿ä¸å“ç‰Œå£°éŸ³ä¸€è‡´ã€‚\n"
      "6. é€‰æ‹©åˆé€‚çš„æ ‡é¢˜ã€‚\n"
  ),
  expected_output="ä¸€ç¯‡ä»¥markdownæ ¼å¼æ’°å†™çš„æ–‡ç« ï¼Œ"
                  "å‡†å¤‡å‘å¸ƒï¼Œæ¯ä¸ªéƒ¨åˆ†åº”æœ‰2æˆ–3æ®µã€‚",
  context=[self.research],
  agent=self.writer,
)
```

**å†…å®¹ç¼–è¾‘å™¨**ï¼šåœ¨å®šä¹‰äº†ç¼–å†™ä»£ç†åï¼Œæˆ‘ä»¬æœ¬å¯ä»¥ç»“æŸè¿™ä¸ªè¿‡ç¨‹ï¼›ç„¶è€Œï¼Œå³ä½¿ç¼–å†™ä»£ç†è´Ÿè´£å†™ä½œï¼Œå®ƒä»å¯èƒ½å‡ºç°æ‹¼å†™é”™è¯¯å’Œç ´åå†…å®¹è¿è´¯æ€§çš„é”™è¯¯ã€‚ä¸ºé˜²æ­¢è¿™äº›é—®é¢˜å¹¶å°†æ–‡ç« è¾“å‡ºä¸ºJSONæ ¼å¼ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªæ–°çš„ä»£ç†ï¼šå†…å®¹ç¼–è¾‘å™¨ã€‚

åœ¨è¯¥ä»£ç†çš„èƒŒæ™¯æ•…äº‹ä¸­ï¼Œæˆ‘ä»¬å°†è¯´æ˜å®ƒè´Ÿè´£å®¡æŸ¥å’Œçº æ­£ä»ç¼–å†™ä»£ç†æ”¶åˆ°çš„æ–‡ç« ã€‚åœ¨ä»»åŠ¡é˜¶æ®µï¼Œæˆ‘ä»¬è¿˜å°†å®šä¹‰æ‰€éœ€çš„è¾“å‡ºæ ¼å¼ã€‚

```python
#Content Editor Agent and Task
self.editor = Agent(
    role="Content Editor",

    goal="ç¼–è¾‘ç»™å®šçš„æ–‡ç« ï¼Œä»¥ç¬¦åˆç»„ç»‡çš„å†™ä½œé£æ ¼ã€‚",

    backstory="æ‚¨æ˜¯ä¸€åç¼–è¾‘ï¼Œæ”¶åˆ°æ¥è‡ªå†…å®¹ç¼–å†™è€…çš„æ–‡ç« ã€‚"
              "æ‚¨çš„ç›®æ ‡æ˜¯å®¡æŸ¥æ–‡ç« ï¼Œä»¥ç¡®ä¿å…¶éµå¾ªæœ€ä½³å®è·µï¼Œæä¾›å¹³è¡¡çš„è§‚ç‚¹"
              "åœ¨æä¾›æ„è§æˆ–æ–­è¨€æ—¶ï¼Œå°½é‡é¿å…é‡å¤§äº‰è®®è¯é¢˜æˆ–æ„è§ã€‚",
    verbose=True
)

self.edit = Task(
    description="æ ¡å¯¹ç»™å®šæ–‡ç« çš„è¯­æ³•é”™è¯¯ï¼Œå¹¶ç¡®ä¿ä¸å“ç‰Œå£°éŸ³ä¸€è‡´ã€‚",

    expected_output="ä¸€ç¯‡ä»¥æ‰€éœ€æ ¼å¼æ’°å†™çš„æ–‡ç« ï¼Œ"
                    "å‡†å¤‡å‘å¸ƒï¼Œæ¯ä¸ªéƒ¨åˆ†åº”æœ‰2æˆ–3æ®µã€‚",
    output_json = Essay,
    context=[self.write],
    agent=self.editor
)
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çš„è¾“å‡ºæ˜¯ä¸€ä¸ªåä¸º`Essay`çš„å¯¹è±¡ï¼Œå®ƒæ˜¯é€šè¿‡Pydanticåº“ä¸­çš„`BaseModel`å’Œ`Field`ç±»åˆ›å»ºçš„ã€‚é€šè¿‡æ·»åŠ æˆ‘ä»¬çš„ä»£ç†å¯ä»¥ç†è§£çš„è§£é‡Šï¼Œæˆ‘ä»¬ç¡®ä¿ä»£ç†å°†æ•°æ®ä»¥PDFæ‰“å°åŠŸèƒ½æ‰€æœŸæœ›çš„æ ¼å¼è¾“å‡ºã€‚

```python
#Expected Pydantic Output

class Paragraph(TypedDict):
    sub_header: str
    paragraph: str

class Essay(BaseModel):
    header: str = Field(..., description="æ–‡ç« çš„æ ‡é¢˜")
    entry: str = Field(..., description="æ–‡ç« çš„å¼•è¨€")
    paragraphs: List[Paragraph] = Field(..., description="æ–‡ç« çš„æ®µè½")
    conclusion: str = Field(..., description="æ–‡ç« çš„ç»“è®º")
    seo_keywords: List[str] = Field(..., description="æ–‡ç« çš„SEOå…³é”®è¯")
```

æˆ‘ä»¬å·²ç»å®šä¹‰äº†æˆ‘ä»¬çš„ä»£ç†åŠå…¶ä»»åŠ¡ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†æˆ‘ä»¬çš„ä¸‰ä¸ªä»£ç†ç»“åˆåœ¨ä¸€èµ·ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨CrewAIåº“ä¸­çš„ä¸€ä¸ªå°è€Œå®ç”¨çš„æ–¹æ³•ï¼Œç§°ä¸º`Crew`ã€‚åœ¨æ­¤æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬åˆ—å‡ºå°†é¡ºåºæ“ä½œçš„ä»£ç†åŠå…¶å°†ä½¿ç”¨çš„å·¥å…·ã€‚å¦‚æœä»»åŠ¡éœ€è¦æŒ‰é¡ºåºæ‰§è¡Œï¼Œå¦‚åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†`process`å‚æ•°è®¾ç½®ä¸º`Process.sequential`ã€‚æˆ‘ä»¬è¿˜å°†`memory`å‚æ•°è®¾ç½®ä¸º`True`ï¼Œä»¥ä½¿ä»£ç†èƒ½å¤Ÿä½¿ç”¨çŸ­æœŸå’Œé•¿æœŸè®°å¿†è¿›è¡Œç›¸äº’é€šä¿¡ã€‚

```python
#Crew Run

def kickoff(self,*args):
    return Crew(
        agents=[self.researcher, self.writer, self.editor],
        tasks=[self.research, self.write, self.edit],
        process=Process.sequential,
        verbose=True,
        memory=True
    ).kickoff(*args)
```

æˆ‘ä»¬çš„ä»£ç†ç»“æ„å·²ç»å®Œæˆï¼Œä½†æˆ‘ä»¬è¿˜æ²¡æœ‰è®¨è®ºæˆ‘ä»¬çš„å·¥å…·ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç®€è¦è¯´æ˜ä¸€ä¸‹æˆ‘ä»¬çš„å·¥å…·ã€‚

## æ„å»ºå·¥å…·

å·¥å…·æœ¬è´¨ä¸Šæ˜¯æ¥å—å„ç§è¾“å…¥å¹¶è¿”å›å€¼ä½œä¸ºè¾“å‡ºçš„å‡½æ•°ã€‚æˆ‘ä»¬çš„ä»£ç†å°†ç®€å•åœ°æä¾›è¿™äº›å‡½æ•°æ‰€éœ€çš„è¾“å…¥ï¼Œå¹¶å¤„ç†ä»–ä»¬æ”¶åˆ°çš„è¾“å‡ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä»¥é«˜å®¹é”™æ€§è®¾è®¡æˆ‘ä»¬çš„å·¥å…·ã€‚å½“å‘ç”Ÿä½¿ç”¨é”™è¯¯æ—¶ï¼Œæˆ‘ä»¬çš„ä»£ç†åº”è¯¥èƒ½å¤Ÿè¯»å–é”™è¯¯ï¼Œå¹¶é…å¤‡ä¿¡æ¯ä»¥ä¾¿åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­æ­£ç¡®ä½¿ç”¨å·¥å…·ã€‚

åœ¨ä¸ºæˆ‘ä»¬çš„å·¥å…·å‡†å¤‡å¥½å‡½æ•°åï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨ LangChain æˆ– CrewAI çš„å·¥å…·åˆ›å»ºç±»å°†å®ƒä»¬è½¬æ¢ä¸ºå·¥å…·å¯¹è±¡ï¼Œå¹¶é™„ä¸Šå„ç§è¯´æ˜ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡ç®€å•åœ°åœ¨å‡½æ•°é¡¶éƒ¨å†™ä¸Š C**rewAI çš„å·¥å…·è£…é¥°å™¨**å°†æˆ‘ä»¬çš„å·¥å…·è½¬æ¢ä¸ºä»£ç†å¯ä»¥ä½¿ç”¨çš„å½¢å¼ã€‚

```python
from crewai_tools import tool

@tool("Wikipedia Search Tool")
def search_wikipedia(query: str) -> str:
    """Run Wikipedia search and get page summaries."""
    page_titles = wikipedia.search(query)
    summaries = []

    for page_title in page_titles[:3]:  # First 3 results
        try:
            wiki_page = wikipedia.page(title=page_title, auto_suggest=False)
            summaries.append(f"Page: {page_title}\nSummary: {wiki_page.summary}")
        except wikipedia.PageError: # Page Not Found
            pass
        except wikipedia.DisambiguationError: # Disambiguation Error
            pass

    if not summaries:
        return "No good Wikipedia Search Result was found"

    return "\n\n".join(summaries)
```

## æ„å»ºåº”ç”¨ç¨‹åº

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨æˆ‘ç»å¸¸ä½¿ç”¨å¹¶ä¸”è®¤ä¸ºæä¾›äº†ç®€å•ç•Œé¢è®¾è®¡çš„ Streamlit æ¡†æ¶æ¥å®æ—¶éƒ¨ç½²æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºã€‚Streamlit æ˜¯ä¸€ä¸ªå¼€æºçš„ Python æ¡†æ¶ï¼Œä¾›æ•°æ®ç§‘å­¦å®¶å’Œ AI/ML å·¥ç¨‹å¸ˆä½¿ç”¨ï¼Œä»…éœ€å‡ è¡Œä»£ç å³å¯äº¤ä»˜åŠ¨æ€æ•°æ®åº”ç”¨ç¨‹åºã€‚

å½“ç”¨æˆ·åœ¨ `text_input` æ¡†ä¸­è¾“å…¥ä»–ä»¬çš„ OpenAI å¯†é’¥å¹¶ç‚¹å‡»â€œåˆå§‹åŒ–ä»£ç†â€æŒ‰é’®æ—¶ï¼Œæˆ‘ä»¬çš„åº”ç”¨ç¨‹åºä¸»è¦æ¿€æ´»ã€‚å½“ç”¨æˆ·é€šè¿‡æ´»åŠ¨çš„ `chat_input` éƒ¨åˆ†å‘é€æ¶ˆæ¯æ—¶ï¼Œä»¥ä¸‹å‡½æ•°ç”¨äºå°†è¾“å…¥çš„è¯·æ±‚ä¼ é€’ç»™æˆ‘ä»¬å»ºç«‹çš„ä»£ç†ç»“æ„ï¼š

```python
def generate_response(topic):
    return app.invoke(input={"topic": topic})
```

å€ŸåŠ© Streamlit çš„ `st.chat_message` ç»„ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾å®ç°èŠå¤©æœºå™¨äººç•Œé¢ã€‚å¦‚æœç”¨æˆ·æ­£åœ¨è¿›è¡Œå¸¸è§„æ¶ˆæ¯ä¼ é€’ï¼Œå“åº”å°†æ˜¾ç¤ºæ­£å¸¸ç­”æ¡ˆã€‚å¦‚æœç”Ÿæˆäº†ä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å°†é€šè¿‡ç¼–å†™ç®€å•çš„ if-else å¾ªç¯å‘ç”¨æˆ·æä¾› PDF çš„ç›®å½•ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬å°†ä»èŠå¤©æœºå™¨äººå‘é€å’Œæ¥æ”¶çš„æ¯æ¡æ¶ˆæ¯æ·»åŠ åˆ° Streamlit çš„ `session_state` ä¸­åˆ›å»ºçš„ `messages` å˜é‡ä¸­ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±åˆ›å»ºäº†ä¸€ä¸ªå¯è§çš„èŠå¤©å±å¹•ã€‚

```python
#Streamlit App

import streamlit as st
from graph import EssayWriter
import os
import base64

st.set_page_config(page_title="Essay Writer Chat Bot", page_icon="ğŸ¤–")
st.image("./media/cover.jpg", use_column_width=True)


if "messages" not in st.session_state:
    st.session_state.messages =  [{"role": "assistant", "content": "Hello!"}]
    st.session_state.app = None
    st.session_state.chat_active = True

with st.sidebar:
    st.info(" * æ­¤åº”ç”¨ç¨‹åºä½¿ç”¨ OpenAI API ç”Ÿæˆæ–‡æœ¬ï¼Œè¯·æä¾›æ‚¨çš„ API å¯†é’¥ã€‚"
            "\n\n * æ­¤åº”ç”¨ç¨‹åºä½¿ç”¨ 'gpt-4o-mini-2024-07-18' æ¨¡å‹ã€‚æˆæœ¬æœ‰æ•ˆä¸”é«˜æ•ˆã€‚"
            "\n\n * å¦‚æœæ‚¨æ²¡æœ‰ API å¯†é’¥ï¼Œå¯ä»¥åœ¨ [è¿™é‡Œ](https://proxy.rifx.online/https://platform.openai.com/signup) è·å–ã€‚"
            "\n\n * æ‚¨è¿˜å¯ä»¥åœ¨ [è¿™é‡Œ](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) æ‰¾åˆ°æ­¤åº”ç”¨ç¨‹åºçš„æºä»£ç ã€‚"
            "\n\n * åº”ç”¨ç¨‹åºå¯†é’¥ä¸ä¼šä»¥ä»»ä½•æ–¹å¼å­˜å‚¨æˆ–ä¿å­˜ã€‚"
            "\n\n * å†™ä½œè®ºæ–‡å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚å¤§çº¦ 1-2 åˆ†é’Ÿã€‚"
    openai_key= st.text_input("OpenAI API å¯†é’¥", type="password")


def initialize_agents():
    os.environ["OPENAI_API_KEY"] = openai_key
    essay_writer = EssayWriter().graph

    if len(openai_key) < 1:
        st.error("è¯·è¾“å…¥æ‚¨çš„ OpenAI API å¯†é’¥å¹¶åˆå§‹åŒ–ä»£ç†ã€‚")

        st.session_state.chat_active = True
    else:
        st.success("ä»£ç†æˆåŠŸåˆå§‹åŒ–")
        st.session_state.chat_active = False

    return essay_writer

with st.sidebar:
    if st.button("åˆå§‹åŒ–ä»£ç†", type="primary"):
        st.session_state.app = initialize_agents()

app = st.session_state.app
def generate_response(topic):
    return app.invoke(input={"topic": topic})


for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"], unsafe_allow_html=True)

if topic:= st.chat_input(placeholder="é—®ä¸€ä¸ªé—®é¢˜", disabled=st.session_state.chat_active):
    st.chat_message("user").markdown(topic)

    st.session_state.messages.append({"role": "user", "content": topic})
    with st.spinner("æ€è€ƒä¸­..."):
        response = generate_response(topic)

    with st.chat_message("assistant"):
        if "pdf_name" in response:
            with open(f"./{response['pdf_name']}", "rb") as file:
                file_bytes = file.read()
                b64 = base64.b64encode(file_bytes).decode()
            href = f'<a href="data:application/pdf;base64,{b64}" download="{response['pdf_name']}">{response['pdf_name']}</a>'

            st.markdown(f"{response['response']}: {href}", unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": f"{response['response']}: {href}"})
        else:
            st.markdown(response["response"])
            st.session_state.messages.append({"role": "assistant", "content": response["response"]})
```

**æ­å–œ**ï¼æˆ‘ä»¬å·²ç»å®Œæˆäº†æˆ‘ä»¬çš„é¡¹ç›®ã€‚å¦‚æœæ‚¨æ„¿æ„ï¼Œå¯ä»¥è§‚çœ‹æˆ‘ä¸ºæ‚¨å½•åˆ¶çš„é¡¹ç›®å·¥ä½œæ—¥å¿—ã€‚ä¸è¦å¿˜è®°è®¿é—® GitHub [**ä»“åº“**](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) ä»¥è·å–é¡¹ç›®çš„æ‰€æœ‰ä»£ç ã€‚

è¿™å°±æ˜¯æˆ‘ä»¬åº”ç”¨ç¨‹åºçš„ä¸»é¡µåœ¨éƒ¨ç½²åå°†å‘ˆç°çš„æ ·å­ï¼

![](https://images.weserv.nl/?url=https://proxy.rifx.online/https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*8tDAluuAH6njIohDbb-UqA.png)

## ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨ CrewAI æ„å»ºè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚æˆ‘ä»¬é¦–å…ˆè®¨è®ºäº†åˆ›å»ºæ™ºèƒ½ä½“çš„åŠ¨æœºï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•ååŒå·¥ä½œä»¥æ›´é«˜æ•ˆåœ°å®Œæˆä»»åŠ¡ã€‚é€šè¿‡å°†ä»»åŠ¡ç»†åˆ†å¹¶åˆ©ç”¨å·¥å…·ï¼Œæˆ‘ä»¬ä½¿æˆ‘ä»¬çš„æ™ºèƒ½ä½“èƒ½å¤Ÿä»¥ç»“æ„åŒ–çš„æ–¹å¼æ‰§è¡Œå¤æ‚æ“ä½œã€‚

æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç®€å•çš„é¡¹ç›®ï¼Œé›†æˆäº† CrewAI å’Œ LangChain æ¡†æ¶ï¼Œå±•ç¤ºäº†å¤šä¸ªæ™ºèƒ½ä½“å¦‚ä½•åä½œæ”¶é›†ä¿¡æ¯ã€æ’°å†™è®ºæ–‡å’Œç¼–è¾‘å†…å®¹ã€‚å¼ºè°ƒäº†å·¥å…·ä½¿ç”¨å’Œä»»åŠ¡ç®¡ç†ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„æ™ºèƒ½ä½“èƒ½å¤Ÿé¡ºåˆ©æœ‰æ•ˆåœ°è¿è¡Œã€‚

æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ Streamlit éƒ¨ç½²äº†æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾ä¸ç³»ç»Ÿäº’åŠ¨ã€‚

æ‚¨å¯ä»¥åœ¨ [**è¿™é‡Œ**](https://proxy.rifx.online/https://multi-agent-essay-writer.streamlit.app/) æŸ¥çœ‹å®æ—¶é¡¹ç›®ï¼Œåœ¨æˆ‘çš„ GitHub ä»“åº“ [**è¿™é‡Œ**](https://proxy.rifx.online/https://github.com/mesutdmn/Autonomous-Multi-Agent-Systems-with-CrewAI-Essay-Writer) æŸ¥çœ‹æºä»£ç 


