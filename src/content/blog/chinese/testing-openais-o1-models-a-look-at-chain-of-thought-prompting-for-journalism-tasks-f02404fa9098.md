---
title: "测试 OpenAI 的 o1 模型：新闻任务的思维链提示概览"
meta_title: "测试 OpenAI 的 o1 模型：新闻任务的思维链提示概览"
description: "OpenAI的o1模型在新闻任务中的表现被评估，重点关注数据分析和标题选择。尽管o1在复杂问题解决方面有潜力，但在实际应用中并不总是优于GPT-4o。o1在数据分析中表现良好，但在A/B标题测试中准确率较低。链式思维提示被证明是提升模型性能的有效策略，强调了任务特定评估的重要性。整体而言，o1模型在新闻工作中的可靠性尚未超越更成熟的模型，提示策略和评估方法对模型选择至关重要。"
date: 2024-12-07T12:38:58Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*wZoDihjVRh_gB1hq"
categories: ["Natural Language Processing", "Machine Learning", "Data Science"]
author: "Rifx.Online"
tags: ["o1", "reasoning", "journalism", "prompting", "GPT-4o"]
draft: False

---



*新的大型语言模型被称为更聪明的问题解决者——但它们在数据可视化和标题选择等实际新闻任务中表现如何？*



上个月，OpenAI 发布了两个新的大型语言模型：o1-preview 和 o1-mini。这些被公司称为 [“推理模型”](https://openai.com/index/introducing-openai-o1-preview/)，与我们迄今为止看到的大型语言模型有着重要的区别。与 GPT-4o 直接生成文本以响应用户问题不同，o1 模型首先构建一个逐步计划，然后执行该计划以达到解决方案。这个过程使得 o1 能够处理更复杂的问题：根据 [基准测试](https://openai.com/index/learning-to-reason-with-llms/)，这些模型在编程、数学和其他复杂推理任务上优于 GPT-4o。

这些新模型在新闻工作者中可能何时会有用呢？与任何大型语言模型一样，将基准测试转化为实际表现是棘手的。而对于 o1 模型来说，这一点更加明显——OpenAI 的 [文档指出](https://help.openai.com/en/articles/9824965-using-openai-o1-models-and-gpt-4o-models-on-chatgpt) “GPT-4o 仍然是大多数提示的最佳选择”，但 o1 “可能有助于处理复杂的问题解决任务，涉及研究、策略、编码、数学和科学等领域。”为了弄清楚这在实践中意味着什么，识别一些常见的新闻任务对评估 o1 是有帮助的。

复杂的问题解决是新闻学许多方面的核心，但并不是所有任务都同样适合评估。根据 Charlotte Li 的 [新闻任务分类法](https://generative-ai-newsroom.com/heres-what-gpt-4-thinks-being-a-journalist-is-all-about-88028ae27a01)，我们可以将任务分为六类：信息收集、意义构建、编辑、出版与分发、生产力和新闻培训。大多数任务需要在新闻编辑部中嵌入模型以进行适当评估，这使得它们在单独评估时具有挑战性。

然而，意义构建涉及处理信息的推理密集型任务，这些任务在受控环境中是可行的评估。因此，我选择了两个核心的意义构建任务进行此次评估：**数据分析**和**标题选择**。

## 评估任务

*所有评估的提示、分析代码和模型输出都可以在[项目仓库](https://github.com/NHagar/o1-eval)中找到。*

### 数据分析

**数据分析** — 清理、处理和可视化一个不熟悉的数据集的过程 — 是报告中耗时但必不可少的一部分。这也是大语言模型（LLMs）一个有前景的应用：[Joris Veerbeek 和 Nick Diakopoulos 的研究](https://arxiv.org/abs/2409.07286)展示了 LLMs 在数据集分析中的潜力，而 OpenAI [强调](https://openai.com/index/learning-to-reason-with-llms/) 代码生成是 o1 模型的一个优势。

我想评估模型执行端到端分析任务的能力，从电子表格开始，最后以清晰的可视化结束。为此，我选择了几个来自 data.gov 的 [热门数据集](https://catalog.data.gov/dataset?q=&sort=views_recent+desc)：农业部的 [估计水果和蔬菜价格](https://catalog.data.gov/dataset/fruit-and-vegetable-prices)、华盛顿州的 [电动车注册](https://catalog.data.gov/dataset/electric-vehicle-population-data) 和纽约市的 [机动车碰撞](https://catalog.data.gov/dataset/motor-vehicle-collisions-crashes)。对于每个数据集，我提示模型生成不同类型可视化的 Python 代码。我将这些可视化任务按照复杂性逐步增加：

* **水果价格：** 一个散点图，显示零售价格与杯等价价格之间的关系，并带有最佳拟合线。
* **电动车：** 并排的直方图，显示电池电动车和插电式混合动力车的范围分布。
* **碰撞：** 纽约市各区碰撞的热图。

我根据以下标准评估每个模型的输出：

* 代码是否运行？
* 输出是否符合请求的图形？
* 是否存在数据清理错误？
* 模型完成任务需要多少行代码？

### 标题选择

许多新闻机构利用**多变量标题测试**来比较同一故事的多个标题的表现（例如，点击率），以查看哪个标题与读者的共鸣最好。正如我们的[先前研究](https://par.nsf.gov/servlets/purl/10301845)所示，预测这些测试的结果通常是困难的，需要强大的编辑判断和对受众偏好的熟悉。当评估标题时，一个推理模型可能能够很好地权衡这些因素。

为了测试这一点，我从[Upworthy研究档案](https://osf.io/jd64p/)中的探索性数据集中随机抽取了50个标题测试。该数据集包含[Upworthy](https://www.upworthy.com/)在2013年至2015年间进行的测试。我提示模型从每个测试中选择最佳标题，然后测量其与编辑选择的标题的准确性。

### 比较 LLMs

为了判断 o1 模型的相对有效性，我还评估了 GPT\-4o、GPT\-4o\-mini 和 Llama3\.1–7b，后者用于评估可以在本地运行的小型模型的性能。

这个比较很重要，因为在这些模型能够与 o1 竞争的程度上，它们代表了显著的成本节约。在撰写本文时，o1\-preview 的费用为每百万输入标记 $15 和每百万输出标记 $60。这是 GPT\-4o 的 6 倍，以及 GPT\-4o\-mini 的 100 倍（而且比您可以在笔记本电脑上运行的模型贵得多）。

除了每个任务的单步提示外，我还探索了多种提示策略，以查看这些较便宜的模型是否能够竞争。这是受到 o1 的 [“推理”能力](https://openai.com/index/learning-to-reason-with-llms/) 的启发，该能力利用了一种称为 [思维链](https://arxiv.org/pdf/2201.11903) 的技术。思维链是一种提示策略，它从 LLM 中引出中间推理步骤——模型不会立即回答请求，而是首先输出其“思维过程”。它还 [提高了](https://arxiv.org/pdf/2201.11903) LLM 在某些任务上的表现，即使对基础模型没有任何更改。虽然 o1 针对这种方法进行了优化，但您可以使用思维链与任何 LLM 一起使用（[这里](https://gist.github.com/NHagar/37dde89443f68715674840cc42802ead) 是一个使用 llama3\.1–7b 的示例）。

了解这一点后，我尝试了三种策略，以引导非 o1 模型进行更深入的“推理”：

* 一个 **思维链** 系统提示，指示模型逐步思考问题，改编自开源 [optillm](https://github.com/codelion/optillm/blob/main/optillm/cot_reflection.py#L8-L33) 库。
* 一个 **多步推理策略**，允许模型模仿 o1 的方法，改编自开源 [g1](https://github.com/bklieger-groq/g1/tree/main) 项目。
* **手工制作的多步工作流程**，以评估由人参与的推理的好处。

## 结果

### 数据分析

下表总结了每个模型是否成功完成每项分析。有关按模型和提示策略进行的性能全面分析，请参见附录 A。

在高层次上，虽然 o1 在这些分析任务中通常比其他模型更有效，但它并不是严格意义上的 *最佳*。较小的模型在更复杂的任务上表现不佳，无论提示如何 — 只有 GPT\-4o 和 o1\-preview 能够完成所有三项任务。但总体而言，使用链式思维提示的 GPT\-4o 生成的可视化效果与 o1 相当。以下是它们的碰撞热图比较：

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*upwHcaMAe10hYhcnchrbXQ.png)

Llama\-3\.1–7b 的表现最差，仅在链式思维提示下完成了最简单的任务（水果价格）。尽管如此，这表明即使是小型本地模型也能处理某些分析任务 — 这对优先考虑效率和隐私的报告工作流程来说是个好消息。

这也强调了链式思维提示的更广泛有效性。对于非 o1 模型，它在 56% 的情况下产生了最准确的结果，而单一提示为 44%，生成推理链为 33%，手工推理为 22%。虽然手工推理整体上效果较差，但在特定情况下表现出色 — 例如使用 GPT\-4o\-mini 进行的水果价格分析，它生成了最全面的数据清理，并揭示了干果价格的有趣趋势：

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*mRRYJAWYJMhFf4wy)

总体而言，虽然 o1 模型在数据分析方面通常有效，但它们并没有超越其他模型的能力到足以证明其额外成本的程度。较小的模型在复杂任务上表现不佳，但通过正确的提示 — 尤其是链式思维 — 即使是像 Llama\-3\.1–7b 这样的本地模型也能处理更简单的分析。

### A/B 标题测试

在评估模型在 A/B 测试中预测获胜标题的能力时，o1 模型的表现始终不佳：o1\-preview 和 o1\-mini 的准确率仅为 24%。相比之下，GPT\-4o 和 GPT\-4o\-mini 的准确率最高，达到了 34%，其中 GPT\-4o 的链式思维提示和 GPT\-4o\-mini 的手工推理链产生了最佳结果（有关所有提示方法的详细信息，请参见附录 B）。

这种表现差距表明，o1 的推理能力可能不适用于需要编辑判断或受众参与预测的任务。虽然所有模型在此任务中都遇到了困难，但提示也明显产生了差异。对于 GPT 模型，手工推理链的准确率提升超过了代码生成任务，表明这些工作流程在编辑环境中是有用的。链式思维提示再次提高了大多数模型的准确率，进一步证明了其作为提高推理密集型任务表现的多功能策略的价值。

## 结论

在构建这项评估时，我尝试选择那些能够从o1的推理能力中受益的任务——那些需要结合多个逻辑步骤以生成数据可视化的任务，或需要模型对新闻价值和受众参与进行推理的任务。但这里展示的结果呼应了[OpenAI的一般指导](https://help.openai.com/en/articles/9824965-using-openai-o1-models-and-gpt-4o-models-on-chatgpt)：对于大多数任务，o1不应成为你的首选模型。虽然在某些领域它与GPT-4o一样出色，但在其他方面却落后于它（而且代价[昂贵](https://openai.com/api/pricing/)）。

这项评估强调了有意的提示策略的重要性。尤其是链式思维提示，是一种强大的工具——优化你的提示可以显著提升性能，即使是对于较小的本地模型。通过引导模型逐步推理，你可以提升其处理更复杂任务的能力。

同样重要的是任务特定的评估。虽然较新的模型可能在基准测试中表现优异，但它们的表现并不总是能转化为每个任务。确定哪个模型最适合你的用例的唯一方法是开发一个系统的、针对你所面临的具体挑战量身定制的现实评估。这一要求使得从业者很难找到最适合他们需求的模型，从而为未来的工作创造了机会，以开发特定于新闻行业的基准来评估LLMs。

需要考虑的限制因素也存在。o1模型是新的，随着用户学习如何更有效地提示它们，其性能可能会改善。OpenAI也已[表示](https://www.axios.com/2024/09/19/openai-sam-altman-chatgpt-strawberry-o1) o1将迅速发展，这意味着这些发现可能会随着未来的更新而变化。而且这项评估仅涵盖了一小部分新闻任务，不同的模型可能在不同的数据集或任务中表现出色。

在当前形态下，o1模型在[某些领域](https://www.nature.com/articles/d41586-024-03169-9)显示出潜力，但尚未成为新闻任务的最可靠选择。它们的推理能力令人印象深刻，但与更成熟的模型如GPT-4o相比，常常显得不足。关键的启示是，任何模型的成功都依赖于深思熟虑的提示和全面的评估。随着o1的不断发展，重新评估其优缺点对于理解其现实应用至关重要。

## 附录 A：数据分析评估

### 水果价格散点图

### 电动汽车直方图

### NYC碰撞热图：

## 附录 B：A/B 测试评估

