---
title: "ä½¿ç”¨ LangChain + Streamlit + *o1ã€GTP-4o å’Œ Claude 3.5 ç¼–å†™ RAG LLM èŠå¤©åº”ç”¨ç¨‹åº"
meta_title: "ä½¿ç”¨ LangChain + Streamlit + *o1ã€GTP-4o å’Œ Claude 3.5 ç¼–å†™ RAG LLM èŠå¤©åº”ç”¨ç¨‹åº"
description: "æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨Pythonã€Streamlitå’ŒLangChainæ„å»ºä¸€ä¸ªæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰èŠå¤©åº”ç”¨ç¨‹åºã€‚RAGé€šè¿‡åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¹‹å‰å¼•å…¥ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæå‡äº†æ¨¡å‹å¯¹ç‰¹å®šä¸»é¢˜çš„å›ç­”å‡†ç¡®æ€§ã€‚æ–‡ç« è¯¦ç»†æè¿°äº†RAGçš„å…­ä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ã€åµŒå…¥å’Œå­˜å‚¨ï¼Œæœ€åé€šè¿‡æ£€ç´¢å’Œç”Ÿæˆé˜¶æ®µå®ç°å¢å¼ºçš„å›ç­”ã€‚ä½œè€…è¿˜æä¾›äº†åº”ç”¨çš„ä»£ç ç¤ºä¾‹ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•å°†å…¶åœ¨çº¿éƒ¨ç½²åˆ°Streamlit Cloudã€‚"
date: 2024-11-20T00:43:56Z
image: "https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*NNgzD3_oLFEHSfKp1CmmKA.png"
categories: ["Programming", "Machine Learning", "Chatbots"]
author: "Rifx.Online"
tags: ["RAG", "Streamlit", "LangChain", "embeddings", "chatbot"]
draft: False

---



å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Pythonã€Streamlit å’Œ LangChain æ„å»º RAG ç½‘ç»œåº”ç”¨ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥ä¸æ–‡æ¡£ã€ç½‘ç«™å’Œå…¶ä»–è‡ªå®šä¹‰æ•°æ®è¿›è¡ŒèŠå¤©ã€‚

GitHub ä»£ç ï¼š<https://github.com/enricd/rag_llm_app>

RAG LLM Streamlit åº”ç”¨ï¼š[https://rag\-llm\-app.streamlit.app/](https://rag-llm-app.streamlit.app/)

## ç›®å½•

1. ğŸ’ªğŸ» RAG ä»‹ç»ï¼ˆä»¥åŠä¸ºä»€ä¹ˆå®ƒæ¯”å¾®è°ƒæ›´å¥½ï¼‰
2. ğŸ¦œ LangChain ä¸­çš„ RAG åˆ†æ­¥æŒ‡å—
3. ğŸ‘¨â€ğŸ’» å°† RAG é›†æˆåˆ° LLM èŠå¤©ç½‘é¡µåº”ç”¨ä¸­
4. ğŸš€ åœ¨çº¿å…è´¹éƒ¨ç½² RAG ç½‘é¡µåº”ç”¨ï¼

## 1\. ğŸ’ªğŸ» RAGç®€ä»‹ï¼ˆä»¥åŠä¸ºä»€ä¹ˆå®ƒä¼˜äºå¾®è°ƒï¼‰

åœ¨æœ¬åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†é€æ­¥å­¦ä¹ å¦‚ä½•å¼€å‘**æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰**ç®¡é“ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨[LangChain](https://www.langchain.com/)å’Œ[Streamlit](https://streamlit.io/)å°†å…¶é›†æˆåˆ°Pythonçš„èŠå¤©Webåº”ç”¨ä¸­ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹æœ€ç»ˆç»“æœï¼š

### ä½¿ç”¨ RAG:



### Without RAG:

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*0BXPS5ekGBy7ovM6frKDmw.png)

æ­£å¦‚æ‚¨å¯èƒ½å·²ç»çŸ¥é“çš„ï¼ŒLLMs æ˜¯åœ¨å¤§é‡å…¬å…±æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œç›´åˆ°æŸä¸ªç‰¹å®šæ—¥æœŸã€‚**ä»»ä½•ä¸å…¬å¼€ã€æ›´æ–°æˆ–ç›¸å¯¹å°ä¼—çš„äº‹å®å¯¹å®ƒä»¬æ¥è¯´åŸºæœ¬ä¸Šæ˜¯æœªçŸ¥çš„**ã€‚å°½ç®¡æ›´æ–°çš„æ¨¡å‹åœ¨å›å¿†è®­ç»ƒé›†ä¸­å­˜åœ¨çš„äº‹å®æ–¹é¢å¾€å¾€æ›´å¥½ï¼Œä½†å®ƒä»¬ä»ç„¶è¿œéå®Œç¾ã€‚è¿™å¯èƒ½æ˜¯è®¸å¤šä»»åŠ¡çš„ä¸€ä¸ªé™åˆ¶å› ç´ ï¼Œè¿™äº›ä»»åŠ¡å› æŸç§åŸå› éœ€è¦ LLM éå¸¸ç²¾ç¡®åœ°äº†è§£ç‰¹å®šä¸»é¢˜ã€‚

**RAG** çš„æ ¸å¿ƒæ˜¯ä¸ºæˆ‘ä»¬çš„ LLM èŠå¤©ç®¡é“æä¾›è‡ªå®šä¹‰ä¿¡æ¯æºã€‚åœ¨å‘æ¨¡å‹å‘é€ä»»ä½•é—®é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šè‡ªåŠ¨æä¾›ä»è¯¥æ•°æ®åº“ä¸­æå–çš„æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ç‰‡æ®µï¼Œä»¥ä¾¿æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­æ‹¥æœ‰ä¸æˆ‘ä»¬çš„é—®é¢˜ç›¸é‚»çš„ç²¾ç¡®ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹éå¸¸æ¸…æ¥šæˆ‘ä»¬åœ¨è®¨è®ºä»€ä¹ˆï¼Œä¿¡æ¯æ¥è‡ªå“ªé‡Œï¼Œå¹¶ä¸”æˆ‘ä»¬å¯ä»¥å‡ ä¹æ²¡æœ‰æˆæœ¬æˆ–ä¸éœ€è¦ GPU çš„æƒ…å†µä¸‹è½»æ¾æ›´æ–°è¿™äº›ä¿¡æ¯ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•å·²å¯ç”¨çš„ LLMï¼Œä¾‹å¦‚æ¥è‡ª OpenAI API çš„ GPT\-4oï¼ˆç°åœ¨æˆ–ä¸ä¹…å°†æ¥çš„ o1 å’Œ o1\-miniï¼ï¼‰ã€æ¥è‡ª Anthropic API çš„ Claude 3\.5ï¼Œç”šè‡³æ˜¯ä»¥ç»æµé«˜æ•ˆçš„æ–¹å¼ä½¿ç”¨å…·æœ‰åŸå§‹æƒé‡çš„å¼€æºæ¨¡å‹ï¼Œæ­£å¦‚æˆ‘ä»¬å·²ç»åœ¨åšçš„é‚£æ ·ã€‚å¦‚æœæ˜å¤©å‡ºç°æ›´å¥½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å‡ ä¹ç«‹å³å°†å…¶é›†æˆåˆ°æˆ‘ä»¬çš„ RAG ç®¡é“ä¸­ï¼Œå¹¶åˆ©ç”¨å®ƒï¼Œè€Œæ— éœ€å†æ¬¡å¾®è°ƒä»»ä½• LLMã€‚

æ›´è¯¦ç»†åœ°è¯´ï¼ŒRAG ç”± 6 ä¸ªæ­¥éª¤ç»„æˆï¼Œå¯ä»¥åˆ†ä¸º 2 ä¸ªé˜¶æ®µï¼š

### 1st phase: Indexing

**1\- ğŸ“¤ åŠ è½½æ–‡æ¡£:** æˆ‘ä»¬ä»æ–‡æ¡£ä¸­æå–åŸå§‹æ–‡æœ¬ï¼Œæ— è®ºå…¶æ ¼å¼å¦‚ä½•ï¼Œä½¿ç”¨é€‚å½“çš„PythonåŒ…è¿›è¡Œå¤„ç†ã€‚

**2\- âœ‚ï¸ æ‹†åˆ†æ–‡æ¡£:** ç”±äºæŸäº›æ–‡æ¡£å¯èƒ½åŒ…å«æ•°ç™¾ç”šè‡³æ•°åƒé¡µçš„æ–‡æœ¬ï¼Œæˆ‘ä»¬çš„LLMä¸Šä¸‹æ–‡æ˜¯æœ‰é™çš„ï¼Œå¯èƒ½åªæƒ³ä»è¿™äº›æ–‡æ¡£ä¸­æå–å‡ ä¸ªç‰¹å®šçš„å°éƒ¨åˆ†ï¼Œå› æ­¤æˆ‘ä»¬å°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶åœ¨å®ƒä»¬ä¹‹é—´ä¿ç•™ä¸€äº›é‡å ã€‚

**3\- ğŸ”¢ åµŒå…¥æ‹†åˆ†:** åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåµŒå…¥LLMï¼Œå®ƒæ¥æ”¶æˆ‘ä»¬çš„æ–‡æœ¬å—å¹¶è¿”å›æ¯ä¸ªæ–‡æœ¬æ ‡è®°çš„åµŒå…¥ã€‚å› æ­¤ï¼Œç¨åæˆ‘ä»¬å°†èƒ½å¤Ÿå¿«é€Ÿæ£€ç´¢ä¸æ¯ä¸ªç»™å®šé—®é¢˜æ›´ç›¸å…³çš„æ–‡æœ¬å—ï¼Œè¿™äº›æ–‡æœ¬å—åœ¨å¤šç»´åµŒå…¥ç©ºé—´ä¸­æ›´æ¥è¿‘è¯¥é—®é¢˜ã€‚

**4\- ğŸ—ƒï¸ å°†åµŒå…¥å­˜å‚¨åœ¨å‘é‡å­˜å‚¨ä¸­ï¼ˆå³å‘é‡æ•°æ®åº“ï¼‰:** åµŒå…¥è¢«ä¿å­˜åœ¨ä¸€ä¸ªä¸“é—¨ç”¨äºåµŒå…¥çš„æ•°æ®åº“ä¸­ï¼Œè¯¥æ•°æ®åº“èƒ½å¤Ÿé«˜æ•ˆåœ°æ‰§è¡ŒåŸºæœ¬çš„å‘é‡æ“ä½œï¼Œä¾‹å¦‚åœ¨æ¯æ¬¡æ£€ç´¢è¯·æ±‚ä¸­è®¡ç®—ä¸¤ä¸ªå¥å­ä¹‹é—´çš„ç¼–ç è¯­ä¹‰è·ç¦»ã€‚

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*xUYXAKdVxqYJsdZb.png)

### 2é˜¶æ®µï¼šæ£€ç´¢ä¸ç”Ÿæˆ

**5\- ğŸ” æ£€ç´¢ï¼š** ç”¨æˆ·çš„é—®é¢˜é¦–å…ˆè¢«è½¬æ¢ä¸ºä»¤ç‰Œå’ŒåµŒå…¥ï¼Œä»¥ä¾¿å¯ä»¥å¿«é€Ÿä¸å‘é‡å­˜å‚¨ä¸­çš„æ‰€æœ‰æ–‡æ¡£å—è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œæ£€ç´¢å‡ºåœ¨æ„ä¹‰ä¸Šæ›´æ¥è¿‘æˆ–æ›´ç›¸ä¼¼çš„ N ä¸ªå—ã€‚

**6\- ğŸ§  å¢å¼ºç”Ÿæˆï¼š** åœ¨ç”¨æˆ·é—®é¢˜ä¹‹å‰ï¼Œå°† N ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£å—æ·»åŠ åˆ°æç¤ºä¸­ï¼Œå¹¶ä¸º LLM æä¾›é€‚å½“çš„æŒ‡ä»¤ï¼Œè¿™æ · LLM å°±å¯ä»¥è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œè¿™æ„å‘³ç€ç›¸å…³ä¿¡æ¯ä¸é—®é¢˜ä¸€èµ·å‡ºç°åœ¨è¯·æ±‚çš„ä¸Šä¸‹æ–‡ä¸­ï¼ˆè€Œä¸æ˜¯ç¨€é‡Šåœ¨æ¨¡å‹çš„æƒé‡ä¸­ï¼‰ï¼Œå¹¶èƒ½ä»¥æ›´å¥½çš„çŸ¥è¯†å’Œå‡†ç¡®æ€§è¿›è¡Œå›ç­”ã€‚

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*GLJD4MUcpbP5mX2b.png)

### â€œä½†æ˜¯.. å¾®è°ƒå‘¢ï¼Ÿâ€

è®¸å¤šäººå¬è¯´è¿‡**å¾®è°ƒ**çš„æ¦‚å¿µï¼Œç”šè‡³æœ‰å¯èƒ½ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªLLMã€‚è™½ç„¶ä»æŠ€æœ¯ä¸Šè®²è¿™æ˜¯å¯è¡Œçš„ï¼ˆå°¤å…¶æ˜¯ç¬¬ä¸€ä¸ªï¼‰ï¼Œä½†å®ƒä¼´éšç€è®¸å¤šè­¦å‘Šã€é™åˆ¶å’Œéšè—æˆæœ¬ï¼Œä½¿å…¶æœ€ç»ˆæˆä¸ºä¸€ä¸ªä¸å¤ªç†æƒ³çš„é€‰æ‹©ï¼š

* è¦å¾®è°ƒä¸€ä¸ªLLMï¼Œæ‚¨é¦–å…ˆ**éœ€è¦è®¿é—®å®ƒ**ï¼Œè¿™é€šå¸¸å¯ä»¥é€šè¿‡åƒHuggingFaceä¸Šçš„å¼€æºLLMï¼ˆä¾‹å¦‚Llama 3.1ï¼‰æ¥å®ç°ï¼Œä½†å¯¹äºåƒGPT-4æˆ–Claude 3.5è¿™æ ·çš„ç§æœ‰æ¨¡å‹åˆ™ä¸å¤ªå¯èƒ½ï¼ˆæœ‰ä¸€äº›ä¾‹å¤–ï¼Œæ¯”å¦‚OpenAIçš„å°å‹æ¨¡å‹å’Œå…¶ä»–ä¸€äº›ç§æœ‰é€‰é¡¹ï¼Œä½†ä¸æ˜¯æœ€å¥½çš„LLMï¼‰ï¼Œè¿™äº›æ¨¡å‹åœ¨è´¨é‡ä¸Šä»ç„¶æ¯”å¼€æºæ¨¡å‹é¢†å…ˆä¸€æ­¥ã€‚
* è¦ç”¨**æ‚¨è‡ªå·±çš„æ•°æ®å¾®è°ƒæ¨¡å‹ï¼Œæ‚¨éœ€è¦å‡†å¤‡å’Œå¤„ç†æ•°æ®**ï¼Œè¿™éœ€è¦è‡³å°‘æ•°åƒä¸ªå¤šæ ·åŒ–ã€æœ€æ–°å’Œå‡è¡¡çš„ç¤ºä¾‹ã€‚è¿™å¹¶ä¸åƒæ‹¥æœ‰ä¸€äº›PDFæˆ–æ–‡æ¡£é‚£ä¹ˆç®€å•ã€‚è¿™å¯èƒ½éœ€è¦å¤§é‡çš„äººåŠ›æ—¶é—´è¿›è¡Œé¢„å¤„ç†ã€‚
* åœ¨è¿‡å»çš„1-2å¹´ä¸­ï¼Œå¾®è°ƒæŠ€æœ¯æœ‰æ‰€è¿›å±•ï¼Œä½¿å¾—è¿™ä¸€è¿‡ç¨‹æ›´é«˜æ•ˆï¼Œå¹¶ä¸”æ‰€éœ€çš„GPUå†…å­˜æ›´å°‘ã€‚å³ä¾¿å¦‚æ­¤ï¼Œæ‚¨ä»ç„¶éœ€è¦**èŠ±è´¹æ•°åƒç¾å…ƒç”¨äºGPUèµ„æº**ï¼Œæ— è®ºæ˜¯ä½¿ç”¨è‡ªå·±çš„NVIDIAè®¾å¤‡è¿˜æ˜¯ä»ä¼ ç»Ÿæˆ–æ–°å…´çš„äº‘æœåŠ¡ç§Ÿç”¨å®ƒä»¬ã€‚
* ç„¶åï¼Œæ‚¨éœ€è¦**æœåŠ¡æ‚¨çš„æ–°è‡ªå®šä¹‰LLM**ï¼Œä½¿å…¶äº†è§£æ‚¨çš„ç”¨ä¾‹ï¼Œè¿™ä¹Ÿéœ€è¦GPUçš„æ”¯æŒï¼Œå¹¶ä¸”æˆæœ¬ä¸ä½ã€‚æ‚¨å°†æ— æ³•ä½¿ç”¨æŒ‰ä»¤ç‰Œä»˜è´¹æˆ–æŒ‰éœ€ä»˜è´¹çš„æ¨¡å‹ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹ä»…é€‚ç”¨äºæ™®é€šçš„é€šç”¨LLMã€‚ç¡®å®ï¼Œä¸€äº›å…¬å¸å¦‚OpenAIå…è®¸å¯¹å…¶ä¸€äº›è¾ƒå°å’Œè¾ƒæ—§çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒå¹¶ä¸ºæ‚¨æä¾›æœåŠ¡ï¼Œä½†åŒæ ·ï¼Œè¿™ä¹Ÿæœ‰å…¶é™åˆ¶ï¼Œè€Œè¿™äº›æ¨¡å‹ç°åœ¨å¹¶ä¸æ˜¯æœ€å¥½çš„LLMã€‚
* æ­¤å¤–ï¼Œæ‚¨çš„å¾®è°ƒæ¨¡å‹**ä¸ä¼šè‡ªåŠ¨æ›´æ–°**ï¼Œå¦‚æœæ˜å¤©å‘å¸ƒäº†æ–°çš„Llama 4æˆ–æ‚¨æ­£åœ¨ä½¿ç”¨çš„å…¶ä»–å¼€æºæ¨¡å‹ã€‚å¦‚æœæ‚¨ç”¨äºè®­ç»ƒçš„è‡ªå®šä¹‰æ•°æ®ä¸‹ä¸ªæœˆå˜å¾—è¿‡æ—¶ï¼Œæˆ–è€…æ‚¨éœ€è¦åŒ…å«æ–°æ•°æ®ï¼Œå®ƒä¹Ÿä¸ä¼šæ›´æ–°ã€‚æ‚¨éœ€è¦é‡æ–°ç»å†è¿™ä¸ªè¿‡ç¨‹ï¼š1. å‡†å¤‡æ‰€æœ‰æ•°æ®ï¼Œ2. å†æ¬¡å¾®è°ƒæ¨¡å‹ï¼Œ3. éƒ¨ç½²/æœåŠ¡/ç›‘æ§ã€‚
* å¦‚æœè¿™ä¸€åˆ‡è¿˜ä¸è¶³ä»¥è®©æ‚¨æŠŠå¾®è°ƒä½œä¸ºè®¡åˆ’Bï¼ˆæˆ–Cï¼Œæˆ–Dï¼‰ï¼Œæ‚¨éœ€è¦äº†è§£ä¸€ä¸ªå«åš**ç¾éš¾æ€§é—å¿˜**çš„æ¦‚å¿µã€‚è¿™æ˜¯æŒ‡ç¥ç»ç½‘ç»œåœ¨å­¦ä¹ æ–°ç¤ºä¾‹æ—¶å¤±å»å…ˆå‰å­¦ä¹ çš„ä¿¡æ¯çš„å€¾å‘ã€‚æ¢å¥è¯è¯´ï¼Œå½“æ‚¨ç”¨è‡ªå®šä¹‰ç¤ºä¾‹å¾®è°ƒä¸€ä¸ªé¡¶çº§LLMæ—¶ï¼Œæ‚¨ä½¿å…¶åœ¨ä¹‹å‰æ‹¥æœ‰çš„ä¸€èˆ¬çŸ¥è¯†ä¸Šå˜å¾—ä¸é‚£ä¹ˆå‡†ç¡®ã€‚ä¸ä»…å¦‚æ­¤ï¼ŒLLMé€šå¸¸ä¸ä¼š100%å‡†ç¡®åœ°å­¦ä¹ æ‚¨çš„è‡ªå®šä¹‰äº‹å®ï¼Œè€Œæ˜¯å­¦ä¹ å®ƒä»¬çš„ä¸€äº›æ¥è¿‘æ€»ç»“æˆ–ä¸å®Œç¾çš„å‰¯æœ¬ï¼Œè¿™äº›ä¿¡æ¯åœ¨ä¹‹å‰è®­ç»ƒæ¨¡å‹çš„æƒé‡å’Œåå·®ä¸­è¢«ç¨€é‡Šã€‚
* æœ€åï¼ŒLLMæœ¬èº«**æ— æ³•å‘Šè¯‰æ‚¨æä¾›çš„äº‹å®çš„ç¡®åˆ‡å¼•ç”¨æˆ–ç²¾ç¡®æ¥æº**ï¼Œå¦‚æœå®ƒä»¬èƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¾ˆå¯èƒ½æ˜¯å®ƒä»¬å¯¹è¿™äº›ä¿¡æ¯äº§ç”Ÿäº†å¹»è§‰ã€‚

å› æ­¤ï¼Œåœ¨åº”ç”¨å¾®è°ƒäºå®é™…æ¡ˆä¾‹æ—¶ï¼Œç»è¿‡è¿™ä¸€é•¿ä¸²è­¦å‘Šå’Œå¤æ‚å› ç´ åï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªæ›´å¥½çš„é€‰æ‹©ï¼Œé€‚ç”¨äº90%ä»¥ä¸Šçš„æƒ…å†µï¼š***Le RAG!***

ğŸ’¡ ç¡®ä¿å…³æ³¨æˆ‘çš„ [Medium](https://medium.com/@enricdomingo)ã€[YouTube](https://www.youtube.com/@enricd) å’Œ [GitHub](https://github.com/enricd)ï¼Œåœ¨ä¸‹ä¸€ä¸ªåšå®¢å’Œè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å°†è¿™ä¸ªåº”ç”¨éƒ¨ç½²åˆ°Azureï¼Œä½¿ç”¨GPT-4oå’ŒGPT-4o minié€šè¿‡Azure OpenAI Serviceï¼Œå¹¶åœ¨æˆ‘ä»¬çš„åº”ç”¨å‰æ·»åŠ SSOèº«ä»½éªŒè¯ï¼Œä»¥ä¾¿åªæœ‰åœ¨æˆ‘ä»¬çš„Azureè®¢é˜…ä¸‹çš„æˆæƒç”¨æˆ·ï¼ˆä¾‹å¦‚ï¼Œæ‚¨çš„å·¥ä½œåŒäº‹ï¼‰å¯ä»¥è®¿é—®æˆ‘ä»¬çš„åº”ç”¨ï¼Œå…¶ä»–äººå°†æ— æ³•ä½¿ç”¨æˆ‘ä»¬çš„èµ„æºæˆ–çªƒå–æˆ‘ä»¬çš„æ•°æ®ï¼

è®©æˆ‘ä»¬è¿›å…¥ä»£ç å§ï¼ï¼ ğŸ’ªğŸ§‘â€ğŸ’»

## 2\. ğŸ¦œ ä½¿ç”¨ LangChain çš„ RAG æ­¥éª¤è¯¦è§£

è®©æˆ‘ä»¬å¼€å§‹å®‰è£…æ‰€æœ‰éœ€è¦çš„ Python åº“ï¼ˆæˆ‘å‡è®¾æ‚¨å·²ç»å®‰è£…äº† Python â‰¥3\.9ï¼Œä½¿ç”¨ VSCode æˆ– PyCharm ç­‰ IDEï¼Œå¹¶ä¸”ä½¿ç”¨ Windowsã€Linux/Ubuntu æˆ– MacOS ç­‰æ“ä½œç³»ç»Ÿï¼‰ã€‚

```python
## åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¿›å…¥ç»ˆç«¯å¹¶ä½¿ç”¨ cd è¿›å…¥è¯¥æ–‡ä»¶å¤¹ï¼Œç„¶åï¼š

$ python -m venv venv  # å¯é€‰
$ venv/scripts/activate  # æˆ–è€…åœ¨ mac å’Œ linux ä¸Šä½¿ç”¨ source venv/bin/activateï¼Œ å¯é€‰

$ pip install python-dotenv streamlit langchain langchain-core langchain-community langchain-openai langchain-anthropic chromadb==0.5.3 langchain-chroma docx2txt pypdf bs4 ipykernel
```
åœ¨æ‚¨çš„æ–‡ä»¶å¤¹ä¸­åˆ›å»ºä¸€ä¸ªåä¸º *.env* çš„æ–‡ä»¶ï¼Œå¹¶å°†æ‚¨çš„ [OpenAI API å¯†é’¥](https://platform.openai.com/) å’Œå¯é€‰çš„ [Anthropic API å¯†é’¥](https://console.anthropic.com/) æ”¾å…¥å…¶ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆå¦‚æœæ‚¨è¿˜æ²¡æœ‰å¯†é’¥ï¼Œè¯·æŸ¥çœ‹é“¾æ¥ï¼‰ï¼š

```python
## /.env

OPENAI_API_KEY="<your-openai-api-key>"
ANTHROPIC_API_KEY="<your-anthropic-api-key>"
```
ç¡®ä¿åˆ›å»ºä¸€ä¸ª *.gitignore* æ–‡ä»¶ï¼Œå¹¶å°† *.env* æ–‡ä»¶æ·»åŠ åˆ°å…¶ä¸­ï¼š

```python
## /.gitignore

.env
venv/
__pycache__
```
ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Jupyter Notebookï¼Œçœ‹çœ‹å¦‚ä½•ä½¿ç”¨ LangChain çš„ RAG æ–¹æ³•ï¼Œæˆ‘å°†å…¶å‘½åä¸º *langchain\_rag.ipynb*ã€‚

åœ¨å…¶ä¸­ï¼Œè®©æˆ‘ä»¬åœ¨ç¬¬ä¸€ä¸ªå•å…ƒä¸­å¯¼å…¥æ‰€æœ‰éœ€è¦çš„åº“ï¼š

```python
## /langchain_rag.ipynb

import os
import dotenv
from pathlib import Path

from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.document_loaders.text import TextLoader
from langchain_community.document_loaders import (
    WebBaseLoader, 
    PyPDFLoader, 
    Docx2txtLoader,
)
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

dotenv.load_dotenv()
```
ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®ç°ä¹‹å‰çœ‹åˆ°çš„ 6 ä¸ªæ­¥éª¤ï¼šåŠ è½½ã€æ‹†åˆ†ã€åµŒå…¥ã€å­˜å‚¨ã€æ£€ç´¢å’Œå¢å¼ºç”Ÿæˆï¼š

**åŠ è½½ï¼š** æˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›æœ€å¸¸è§çš„ LangChain æ–‡æ¡£åŠ è½½æ–¹æ³•ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„æ–¹æ³•ï¼Œå¹¶ä¸ºæ‚¨çš„ç‰¹å®šç”¨ä¾‹åº”ç”¨æ›´å¤šè‡ªå®šä¹‰çš„æ–¹æ³•ï¼š[LangChain æ–‡æ¡£åŠ è½½å™¨](https://python.langchain.com/v0.2/docs/integrations/document_loaders/)ã€‚

åœ¨ä¸‹é¢çš„å•å…ƒä¸­ï¼Œæˆ‘ä»¬å°†åŠ è½½ pdfã€docxã€txt å’Œ markdown æ–‡æ¡£ï¼Œè¿˜å°†ä»å…¶ URL åŠ è½½ç½‘ç«™çš„æ–‡æœ¬å†…å®¹ã€‚åœ¨é¡¹ç›®æ–‡ä»¶å¤¹ä¸­ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ª *docs/* æ–‡ä»¶å¤¹ï¼Œå¹¶æ”¾ç½®äº†ä¸€äº› test\_rag æ–‡æ¡£ï¼Œå…¶ä¸­åŒ…å«ä¸€äº›éšæœºä¿¡æ¯ä»¥éªŒè¯å…¶ç¡®å®æœ‰æ•ˆï¼Œå¯¹äº URLï¼Œæˆ‘æ­£åœ¨æµ‹è¯• Streamlit æ–‡æ¡£çš„æ›´æ–°æ—¥å¿—ï¼Œæˆ‘å°†è¯¢é—® LLM å…³äºæœ€æ–°ç‰ˆæœ¬çš„ä¿¡æ¯ï¼š

```python
## åŠ è½½æ–‡æ¡£

doc_paths = [
    "docs/test_rag.pdf",
    "docs/test_rag.docx",
]

docs = [] 
for doc_file in doc_paths:
    file_path = Path(doc_file)

    try:
        if doc_file.endswith(".pdf"):
            loader = PyPDFLoader(file_path)
        elif doc_file.endswith(".docx"):
            loader = Docx2txtLoader(file_path)
        elif doc_file.endswith(".txt") or doc_file.name.endswith(".md"):
            loader = TextLoader(file_path)
        else:
            print(f"æ–‡æ¡£ç±»å‹ {doc_file.type} ä¸æ”¯æŒã€‚")
            continue

        docs.extend(loader.load())

    except Exception as e:
        print(f"åŠ è½½æ–‡æ¡£ {doc_file.name} æ—¶å‡ºé”™: {e}")
    
    finally:
        os.remove(file_path)


## åŠ è½½ URL

url = "https://docs.streamlit.io/develop/quick-reference/release-notes"
try:
    loader = WebBaseLoader(url)
    docs.extend(loader.load())

except Exception as e:
    print(f"ä» {url} åŠ è½½æ–‡æ¡£æ—¶å‡ºé”™: {e}")


```
**æ‹†åˆ†ï¼š** ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ *RecursiveCharacterTextSplitter* å°†æ¯ä¸ªæ–‡æ¡£æ‹†åˆ†ä¸º 5000 ä¸ªå­—ç¬¦çš„å—ï¼Œé‡å  1000 ä¸ªå­—ç¬¦ï¼Œä»¥å…å°†ä»»ä½•ä¸Šä¸‹æ–‡åˆ‡æˆä¸¤åŠã€‚

```python
## æ‹†åˆ†æ–‡æ¡£

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=5000,
    chunk_overlap=1000,
)

document_chunks = text_splitter.split_documents(docs)
```
**åµŒå…¥å’Œå­˜å‚¨ï¼š** æˆ‘ä»¬å°†ä½¿ç”¨ Chroma DB çš„å•ä¸ªæ–¹æ³•æ¥ä½¿ç”¨ OpenAI Embeddings æ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨æœ¬åœ° Chroma DB å‘é‡å­˜å‚¨ä¸­ã€‚

```python
## å¯¹æ–‡æ¡£è¿›è¡Œæ ‡è®°å¹¶åŠ è½½åˆ°å‘é‡å­˜å‚¨ä¸­

vector_db = Chroma.from_documents(
    documents=document_chunks,
    embedding=OpenAIEmbeddings(),
)
```
ç°åœ¨æˆ‘ä»¬å·²ç»å°†å‘é‡å­˜å‚¨åŠ è½½å¹¶å‡†å¤‡å¥½è¿›è¡Œæ£€ç´¢ã€‚è®©æˆ‘ä»¬åˆ›å»ºæ£€ç´¢çš„ç®¡é“ï¼š

**æ£€ç´¢ï¼š** æœ‰ä¸åŒçš„ç®—æ³•å’Œæ–¹æ³•å¯ä¾›æ£€ç´¢ï¼Œæœ‰äº›æ›´åŸºç¡€ï¼Œæœ‰äº›æ›´å¤æ‚ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ç§ä¸­ç­‰çš„æ–¹å¼ï¼Œå®ƒä¸ä»…è€ƒè™‘ç”¨æˆ·çš„æœ€åä¸€ä¸ªé—®é¢˜ï¼Œè¿˜è€ƒè™‘ä¹‹å‰çš„æ‰€æœ‰å¯¹è¯ï¼Œä»¥ä¾¿ä»å‘é‡å­˜å‚¨ä¸­è·å–ç›¸å…³ä¿¡æ¯ï¼š

```python
def _get_context_retriever_chain(vector_db, llm):
    retriever = vector_db.as_retriever()
    prompt = ChatPromptTemplate.from_messages([
        MessagesPlaceholder(variable_name="messages"),
        ("user", "{input}"),
        ("user", "æ ¹æ®ä»¥ä¸Šå¯¹è¯ï¼Œç”Ÿæˆä¸€ä¸ªæœç´¢æŸ¥è¯¢ï¼Œä»¥æŸ¥æ‰¾ä¸å¯¹è¯ç›¸å…³çš„ä¿¡æ¯ï¼Œé‡ç‚¹å…³æ³¨æœ€æ–°çš„æ¶ˆæ¯ã€‚"),
    ])
    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)

    return retriever_chain
```
æ­¤å‡½æ•°å°†ç”¨äºè·å–ç»™å®šå¯¹è¯ä¸­æœ€æœ‰ç”¨çš„ä¿¡æ¯å—ï¼Œä»¥ä¸‹æ–¹æ³•å°†ä½¿ç”¨è¿™äº›å—å‘ LLM å‘å‡ºæŸ¥è¯¢ï¼š

```python
def get_conversational_rag_chain(llm):
    retriever_chain = _get_context_retriever_chain(vector_db, llm)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
        """æ‚¨æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚æ‚¨å°†éœ€è¦å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ã€‚
        æ‚¨å°†æ‹¥æœ‰ä¸€äº›ä¸Šä¸‹æ–‡æ¥å¸®åŠ©å›ç­”ï¼Œä½†å¹¶ä¸æ€»æ˜¯å®Œå…¨ç›¸å…³æˆ–æœ‰å¸®åŠ©ã€‚
        æ‚¨è¿˜å¯ä»¥åˆ©ç”¨æ‚¨çš„çŸ¥è¯†æ¥ååŠ©å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ã€‚\n
        {context}"""),
        MessagesPlaceholder(variable_name="messages"),
        ("user", "{input}"),
    ])
    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)

    return create_retrieval_chain(retriever_chain, stuff_documents_chain)
```
**å¢å¼ºç”Ÿæˆï¼š** æœ€åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å‰é¢çš„æ–¹æ³•å‘ LLM æŸ¥è¯¢ï¼Œå¹¶åœ¨è¯·æ±‚ä¸­è‡ªåŠ¨æ·»åŠ ç›¸å…³ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬éœ€è¦åˆ›å»º LLM Chat å¯¹è±¡ï¼Œå…·æœ‰æµå¼èƒ½åŠ›ï¼Œä»¥ä¾¿ç¨åå¯ä»¥ä½¿ç”¨å®ƒä»¬æ„å»ºèŠå¤©ç½‘é¡µåº”ç”¨ç¨‹åºï¼Œä»¥åŠæ¶ˆæ¯å†å²ï¼š

```python
llm_stream_openai = ChatOpenAI(
    model="gpt-4o",  # åœ¨è¿™é‡Œï¼Œå¦‚æœæ‚¨å·²ç»å¯ä»¥è®¿é—®ï¼Œå¯ä»¥ä½¿ç”¨ "o1-preview" æˆ– "o1-mini"
    temperature=0.3,
    streaming=True,
)

llm_stream_anthropic = ChatAnthropic(
    model="claude-3-5-sonnet-20240620",
    temperature=0.3,
    streaming=True,
)

llm_stream = llm_stream_openai  # åœ¨ OpenAI å’Œ Anthropic æ¨¡å‹ä¹‹é—´é€‰æ‹©ä»¥è·å–å“åº”

messages = [
    {"role": "user", "content": "å—¨"},
    {"role": "assistant", "content": "ä½ å¥½ï¼ä»Šå¤©æˆ‘èƒ½å¸®åŠ©æ‚¨ä»€ä¹ˆï¼Ÿ"},
    {"role": "user", "content": "Streamlit çš„æœ€æ–°ç‰ˆæœ¬æ˜¯ä»€ä¹ˆï¼Ÿ"},
]
messages = [HumanMessage(content=m["content"]) if m["role"] == "user" else AIMessage(content=m["content"]) for m in messages]

conversation_rag_chain = get_conversational_rag_chain(llm_stream)
response_message = "*(RAG å“åº”)*\n"
for chunk in conversation_rag_chain.pick("answer").stream({"messages": messages[:-1], "input": messages[-1].content}):
    response_message += chunk
    print(chunk, end="", flush=True)

messages.append({"role": "assistant", "content": response_message})
```
å¦‚æœæˆ‘ä»¬ä¸€åˆ‡é¡ºåˆ©ï¼Œç°åœ¨æˆ‘ä»¬åº”è¯¥å¯ä»¥çœ‹åˆ° LLM çš„å“åº”è¢«æµå¼ä¼ è¾“ã€‚å½“ LLM è¢«è®­ç»ƒæ—¶ï¼ŒStreamlit çš„æœ€æ–°ç‰ˆæœ¬å¯èƒ½æ˜¯ 1\.34ï¼Œä½†ç°åœ¨å®ƒé€šè¿‡æˆ‘ä»¬ä¸ Streamlit æ›´æ–°å’Œæ›´æ–°æ—¥å¿—çš„ RAG è¿æ¥ï¼ŒçŸ¥é“äº†æœ€æ–°çš„ç‰ˆæœ¬ï¼ğŸ”¥ æ‚¨å¯ä»¥å¯¹ä»»ä½•å…¶ä»–è‡ªå®šä¹‰ç”¨ä¾‹åšåŒæ ·çš„äº‹æƒ…ã€‚

ä½¿ç”¨ LangChain çš„ä¸€ä¸ªå¥½å¤„æ˜¯ä¸åŒ LLM æä¾›è€…ä¹‹é—´çš„æ˜“äºäº’æ“ä½œæ€§ã€‚æˆ‘ä»¬å¯ä»¥å‡ ä¹ä¸æ›´æ”¹ä»£ç åœ°åœ¨å®ƒä»¬ä¹‹é—´åˆ‡æ¢ã€‚

è®©æˆ‘ä»¬è®©è¿™ä¸ªé¡¹ç›®æ›´å…·äº’åŠ¨æ€§å¹¶ä¾¿äºæ¯ä¸ªäººä½¿ç”¨ï¼šè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ª RAG èŠå¤©æœºå™¨äººç½‘ç«™ï¼Œéšåå°†å…¶åœ¨çº¿å‘å¸ƒï¼

## 3\. ğŸ‘¨â€ğŸ’» å°† RAG é›†æˆåˆ° LLM èŠå¤©ç½‘é¡µåº”ç”¨ä¸­

æˆ‘ä»¬å·²ç»çœ‹åˆ°å¦‚ä½•åœ¨ Streamlit ä¸­æ„å»ºä¸€ä¸ªå¤šæ¨¡æ€èŠå¤©ç½‘é¡µåº”ç”¨ï¼Œé’ˆå¯¹ï¼š

* OpenAI æ¨¡å‹ï¼Œå¦‚ GPT-4o: [åšå®¢å’Œè§†é¢‘é“¾æ¥](https://readmedium.com/code-the-omnichat-app-integrating-gpt-4o-your-python-chatgpt-d399b90d178e)
* Google DeepMind æ¨¡å‹ï¼Œå¦‚ Gemini 1.5: [åšå®¢å’Œè§†é¢‘é“¾æ¥](https://readmedium.com/how-i-add-gemini-1-5-pro-api-to-my-app-chat-with-videos-images-and-audios-f42171606143)
* Anthropic æ¨¡å‹ï¼Œå¦‚ Claude 3.5 Sonnet: [åšå®¢å’Œè§†é¢‘é“¾æ¥](https://readmedium.com/claude-sonnet-3-5-api-integrating-the-best-llm-into-our-app-7ec4623e2dac)

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è·³è¿‡ä¸€äº›æ„å»ºä»£ç çš„ç»†èŠ‚ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨è¿™äº›åšå®¢ä¸­çœ‹åˆ°è¿‡ï¼Œä½†åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª ***/rag_methods.py*** æ–‡ä»¶ï¼Œä»¥å£°æ˜æˆ‘ä»¬åœ¨ */langchain_rag.ipynb* ç¬”è®°æœ¬ä¸­åˆšåˆšå¼€å‘å’Œå®éªŒçš„æ‰€æœ‰éœ€è¦çš„ LLM å’Œ RAG æ–¹æ³•ã€‚

ç„¶åï¼Œæˆ‘ä»¬å°†åˆ›å»º */app.py* æ–‡ä»¶ï¼Œåœ¨å…¶ä¸­å¼€å‘æ‰€æœ‰ Streamlit é€»è¾‘ä»¥åˆ›å»ºç½‘ç«™ï¼Œå¯¼å…¥æ‰€æœ‰å…ˆå‰å¼€å‘çš„ RAG æ–¹æ³•ã€‚

### /rag\_methods.py

é€»è¾‘å’Œæ–¹æ³•å‡ ä¹ä¸ä¹‹å‰ç›¸åŒï¼Œä½†è¿›è¡Œäº†è°ƒæ•´ä»¥ä½¿å…¶åœ¨Streamlitä¸­å·¥ä½œï¼Œä½¿ç”¨ *st.session\_state* æ¥ç®¡ç†æ¶ˆæ¯å¯¹è¯ï¼ŒåŒæ—¶ä¸ºæ¯ä¸ªç”¨æˆ·é™„åŠ Chroma DBå‘é‡å­˜å‚¨ï¼Œå°†å…¶é™„åŠ åˆ°æ¯ä¸ªç”¨æˆ·çš„ä¼šè¯ä¸­ï¼Œä½†ä¿ç•™æœ€å¤š20ä¸ªï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šæº¢å‡ºæœ‰é™çš„æœåŠ¡å™¨å†…å­˜ã€‚æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„ç”¨ä¾‹å’Œäº‘åŸºç¡€è®¾æ–½ä¿®æ”¹è¿™äº›é™åˆ¶ã€‚

```python
import os
import dotenv
from time import time
import streamlit as st

from langchain_community.document_loaders.text import TextLoader
from langchain_community.document_loaders import (
    WebBaseLoader, 
    PyPDFLoader, 
    Docx2txtLoader,
)
## pip install docx2txt, pypdf
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

dotenv.load_dotenv()

os.environ["USER_AGENT"] = "myagent"
DB_DOCS_LIMIT = 10

## Function to stream the response of the LLM 
def stream_llm_response(llm_stream, messages):
    response_message = ""

    for chunk in llm_stream.stream(messages):
        response_message += chunk.content
        yield chunk

    st.session_state.messages.append({"role": "assistant", "content": response_message})


## --- Indexing Phase ---

def load_doc_to_db():
    # Use loader according to doc type
    if "rag_docs" in st.session_state and st.session_state.rag_docs:
        docs = [] 
        for doc_file in st.session_state.rag_docs:
            if doc_file.name not in st.session_state.rag_sources:
                if len(st.session_state.rag_sources) < DB_DOCS_LIMIT:
                    os.makedirs("source_files", exist_ok=True)
                    file_path = f"./source_files/{doc_file.name}"
                    with open(file_path, "wb") as file:
                        file.write(doc_file.read())

                    try:
                        if doc_file.type == "application/pdf":
                            loader = PyPDFLoader(file_path)
                        elif doc_file.name.endswith(".docx"):
                            loader = Docx2txtLoader(file_path)
                        elif doc_file.type in ["text/plain", "text/markdown"]:
                            loader = TextLoader(file_path)
                        else:
                            st.warning(f"Document type {doc_file.type} not supported.")
                            continue

                        docs.extend(loader.load())
                        st.session_state.rag_sources.append(doc_file.name)

                    except Exception as e:
                        st.toast(f"Error loading document {doc_file.name}: {e}", icon="âš ï¸")
                        print(f"Error loading document {doc_file.name}: {e}")
                    
                    finally:
                        os.remove(file_path)

                else:
                    st.error(F"Maximum number of documents reached ({DB_DOCS_LIMIT}).")

        if docs:
            _split_and_load_docs(docs)
            st.toast(f"Document *{str([doc_file.name for doc_file in st.session_state.rag_docs])[1:-1]}* loaded successfully.", icon="âœ…")


def load_url_to_db():
    if "rag_url" in st.session_state and st.session_state.rag_url:
        url = st.session_state.rag_url
        docs = []
        if url not in st.session_state.rag_sources:
            if len(st.session_state.rag_sources) < 10:
                try:
                    loader = WebBaseLoader(url)
                    docs.extend(loader.load())
                    st.session_state.rag_sources.append(url)

                except Exception as e:
                    st.error(f"Error loading document from {url}: {e}")

                if docs:
                    _split_and_load_docs(docs)
                    st.toast(f"Document from URL *{url}* loaded successfully.", icon="âœ…")

            else:
                st.error("Maximum number of documents reached (10).")


def initialize_vector_db(docs):
    vector_db = Chroma.from_documents(
        documents=docs,
        embedding=OpenAIEmbeddings(api_key=st.session_state.openai_api_key),
        collection_name=f"{str(time()).replace('.', '')[:14]}_" + st.session_state['session_id'],
    )

    # We need to manage the number of collections that we have in memory, we will keep the last 20
    chroma_client = vector_db._client
    collection_names = sorted([collection.name for collection in chroma_client.list_collections()])
    print("Number of collections:", len(collection_names))
    while len(collection_names) > 20:
        chroma_client.delete_collection(collection_names[0])
        collection_names.pop(0)

    return vector_db


def _split_and_load_docs(docs):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=5000,
        chunk_overlap=1000,
    )

    document_chunks = text_splitter.split_documents(docs)

    if "vector_db" not in st.session_state:
        st.session_state.vector_db = initialize_vector_db(docs)
    else:
        st.session_state.vector_db.add_documents(document_chunks)


## --- Retrieval Augmented Generation (RAG) Phase ---

def _get_context_retriever_chain(vector_db, llm):
    retriever = vector_db.as_retriever()
    prompt = ChatPromptTemplate.from_messages([
        MessagesPlaceholder(variable_name="messages"),
        ("user", "{input}"),
        ("user", "Given the above conversation, generate a search query to look up in order to get inforamtion relevant to the conversation, focusing on the most recent messages."),
    ])
    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)

    return retriever_chain


def get_conversational_rag_chain(llm):
    retriever_chain = _get_context_retriever_chain(st.session_state.vector_db, llm)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
        """You are a helpful assistant. You will have to answer to user's queries.
        You will have some context to help with your answers, but now always would be completely related or helpful.
        You can also use your knowledge to assist answering the user's queries.\n
        {context}"""),
        MessagesPlaceholder(variable_name="messages"),
        ("user", "{input}"),
    ])
    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)

    return create_retrieval_chain(retriever_chain, stuff_documents_chain)


def stream_llm_rag_response(llm_stream, messages):
    conversation_rag_chain = get_conversational_rag_chain(llm_stream)
    response_message = "*(RAG Response)*\n"
    for chunk in conversation_rag_chain.pick("answer").stream({"messages": messages[:-1], "input": messages[-1].content}):
        response_message += chunk
        yield chunk

    st.session_state.messages.append({"role": "assistant", "content": response_message})
```

### /app.py


```python
import streamlit as st
import os
import dotenv
import uuid

## check if it's linux so it works on Streamlit Cloud
if os.name == 'posix':
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
import os
import dotenv
import uuid

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain.schema import HumanMessage, AIMessage

from rag_methods import (
    load_doc_to_db, 
    load_url_to_db,
    stream_llm_response,
    stream_llm_rag_response,
)

dotenv.load_dotenv()

MODELS = [
    # "openai/o1-mini",
    "openai/gpt-4o",
    "openai/gpt-4o-mini",
    "anthropic/claude-3-5-sonnet-20240620",
]

st.set_page_config(
    page_title="RAG LLM åº”ç”¨ï¼Ÿ", 
    page_icon="ğŸ“š", 
    layout="centered", 
    initial_sidebar_state="expanded"
)


## --- Header ---
st.html("""<h2 style="text-align: center;">ğŸ“šğŸ” <i> ä½ çš„ LLM çœŸçš„ RAG å—ï¼Ÿ </i> ğŸ¤–ğŸ’¬</h2>""")


## --- Initial Setup ---
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "rag_sources" not in st.session_state:
    st.session_state.rag_sources = []

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "user", "content": "ä½ å¥½"},
        {"role": "assistant", "content": "ä½ å¥½ï¼ä»Šå¤©æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆï¼Ÿ"}
]


## --- Side Bar LLM API Tokens ---
with st.sidebar:
    default_openai_api_key = os.getenv("OPENAI_API_KEY") if os.getenv("OPENAI_API_KEY") is not None else ""  # ä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼Œå¦åˆ™åº”è¿”å› None
    with st.popover("ğŸ” OpenAI"):
        openai_api_key = st.text_input(
            "è¯·è¾“å…¥ä½ çš„ OpenAI API å¯†é’¥ (https://platform.openai.com/)", 
            value=default_openai_api_key, 
            type="password",
            key="openai_api_key",
        )

    default_anthropic_api_key = os.getenv("ANTHROPIC_API_KEY") if os.getenv("ANTHROPIC_API_KEY") is not None else ""
    with st.popover("ğŸ” Anthropic"):
        anthropic_api_key = st.text_input(
            "è¯·è¾“å…¥ä½ çš„ Anthropic API å¯†é’¥ (https://console.anthropic.com/)", 
            value=default_anthropic_api_key, 
            type="password",
            key="anthropic_api_key",
        )

## --- Main Content ---
## Checking if the user has introduced the OpenAI API Key, if not, a warning is displayed
missing_openai = openai_api_key == "" or openai_api_key is None or "sk-" not in openai_api_key
missing_anthropic = anthropic_api_key == "" or anthropic_api_key is None
if missing_openai and missing_anthropic:
    st.write("#")
    st.warning("â¬…ï¸ è¯·æä¾› API å¯†é’¥ä»¥ç»§ç»­...")

else:
    # Sidebar
    with st.sidebar:
        st.divider()
        st.selectbox(
            "ğŸ¤– é€‰æ‹©ä¸€ä¸ªæ¨¡å‹", 
            [model for model in MODELS if ("openai" in model and not missing_openai) or ("anthropic" in model and not missing_anthropic)],
            key="model",
        )

        cols0 = st.columns(2)
        with cols0[0]:
            is_vector_db_loaded = ("vector_db" in st.session_state and st.session_state.vector_db is not None)
            st.toggle(
                "ä½¿ç”¨ RAG", 
                value=is_vector_db_loaded, 
                key="use_rag", 
                disabled=not is_vector_db_loaded,
            )

        with cols0[1]:
            st.button("æ¸…é™¤èŠå¤©", on_click=lambda: st.session_state.messages.clear(), type="primary")

        st.header("RAG æ¥æº:")
            
        # File upload input for RAG with documents
        st.file_uploader(
            "ğŸ“„ ä¸Šä¼ æ–‡æ¡£", 
            type=["pdf", "txt", "docx", "md"],
            accept_multiple_files=True,
            on_change=load_doc_to_db,
            key="rag_docs",
        )

        # URL input for RAG with websites
        st.text_input(
            "ğŸŒ è¾“å…¥ä¸€ä¸ª URL", 
            placeholder="https://example.com",
            on_change=load_url_to_db,
            key="rag_url",
        )

        with st.expander(f"ğŸ“š æ•°æ®åº“ä¸­çš„æ–‡æ¡£ ({0 if not is_vector_db_loaded else len(st.session_state.rag_sources)})"):
            st.write([] if not is_vector_db_loaded else [source for source in st.session_state.rag_sources])

    
    # Main chat app
    model_provider = st.session_state.model.split("/")[0]
    if model_provider == "openai":
        llm_stream = ChatOpenAI(
            api_key=openai_api_key,
            model_name=st.session_state.model.split("/")[-1],
            temperature=0.3,
            streaming=True,
        )
    elif model_provider == "anthropic":
        llm_stream = ChatAnthropic(
            api_key=anthropic_api_key,
            model=st.session_state.model.split("/")[-1],
            temperature=0.3,
            streaming=True,
        )

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ä½ çš„æ¶ˆæ¯"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            messages = [HumanMessage(content=m["content"]) if m["role"] == "user" else AIMessage(content=m["content"]) for m in st.session_state.messages]

            if not st.session_state.use_rag:
                st.write_stream(stream_llm_response(llm_stream, messages))
            else:
                st.write_stream(stream_llm_rag_response(llm_stream, messages))


```
ç°åœ¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡è¿›å…¥ç»ˆç«¯åœ¨æœ¬åœ°è¿è¡Œç½‘ç«™ï¼š


```python
## cd åˆ°é¡¹ç›®æ–‡ä»¶å¤¹å¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

$ streamlit run app.py
```
å¦‚æœä¸€åˆ‡è®¾ç½®æ­£ç¡®ï¼Œæ‚¨åº”è¯¥åœ¨æµè§ˆå™¨çš„ localhost:8501 ä¸­çœ‹åˆ°ä»¥ä¸‹å†…å®¹ï¼š

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*lGbTqfd6J9Gq4F53nDUtNw.png)

æ‚¨å¯ä»¥å°è¯•ä¸å®ƒèŠå¤©è€Œæ— éœ€æ–‡æ¡£ï¼Œç„¶ååŠ è½½ä»»ä½•æ‚¨æƒ³å°è¯•çš„ pdfã€txtã€docx æˆ– URLï¼Œå¹¶è¯¢é—®æœ‰å…³å®ƒçš„å…·ä½“é—®é¢˜ï¼Œä»¥éªŒè¯å®ƒæ˜¯å¦çœŸçš„æœ‰æ•ˆã€‚

å¤ªå¥½äº†ï¼è®©æˆ‘ä»¬æŠŠå®ƒå‘å¸ƒåˆ°æˆ‘ä»¬çš„è®¡ç®—æœºä¹‹å¤–ï¼Œè®©æˆ‘ä»¬åœ¨ Streamlit Cloud ä¸Šå…è´¹éƒ¨ç½²è¿™ä¸ªç½‘ç«™ã€‚è¯·è®°ä½ï¼Œåœ¨ä¸‹ä¸€ä¸ªåšå®¢å’Œè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åœ¨ Azure ä¸Šéƒ¨ç½²å®ƒï¼Œä½¿ç”¨æ›´å¼ºå¤§çš„æœºå™¨ï¼Œæ›´é«˜çš„å®‰å…¨æ€§ä»¥åŠæ·»åŠ  SSO èº«ä»½éªŒè¯çš„å¯èƒ½æ€§ã€‚å¦‚æœæ‚¨æƒ³çœ‹åˆ°å¦‚ä½•åœ¨å…¶ä»–äº‘æä¾›å•†ï¼ˆå¦‚ AWSï¼‰ä¸Šéƒ¨ç½²å®ƒï¼Œè¯·åœ¨è¯„è®ºä¸­å‘Šè¯‰æˆ‘ã€‚ ğŸ¤—

## 4\. ğŸš€ å…è´¹åœ¨çº¿éƒ¨ç½² RAG ç½‘ç»œåº”ç”¨ç¨‹åºï¼

æˆ‘ä»¬åœ¨ä¹‹å‰çš„åšå®¢ä¸­å·²ç»çœ‹åˆ°å¦‚ä½•è½»æ¾åœ°å°† Streamlit ç½‘ç«™å…è´¹éƒ¨ç½²åˆ° Streamlit äº‘ä¸­ï¼Œä½†è®©æˆ‘ä»¬å†æ¬¡çœ‹çœ‹æ­¥éª¤ï¼š

* å¦‚æœä½ è¿˜æ²¡æœ‰åˆ›å»º Git ä»“åº“ï¼Œè¯·åˆ›å»ºä¸€ä¸ªï¼š

```python
## cd åˆ°ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹ï¼Œç¡®ä¿ .gitignore æ­£ç¡®è®¾ç½®

$ venv/scripts/activate  # æˆ– source venv/bin/activate

$ pip freeze > requirements.txt

## åœ¨ requirements.txt æ–‡ä»¶é¡¶éƒ¨æ·»åŠ ä»¥ä¸‹è¡Œï¼špysqlite3-binary; sys_platform == 'linux'

$ git init -b main

$ git add .

$ git commit -m "complete project"
```
* è®¿é—® [github.com](https://github.com) ï¼ˆå¦‚æœä½ è¿˜æ²¡æœ‰è´¦å·ï¼Œè¯·åˆ›å»ºä¸€ä¸ªï¼‰å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ä»“åº“ã€‚æŒ‰ç…§é‚£é‡Œæä¾›çš„æ­¥éª¤ä¸Šä¼ ï¼ˆæ¨é€ï¼‰ç°æœ‰çš„æœ¬åœ°é¡¹ç›®ã€‚
* è®¿é—® [streamlit.io](https://streamlit.io/)ï¼Œä½¿ç”¨ä½ çš„ GitHub è´¦å·æ³¨å†Œï¼Œå¹¶ä½¿ç”¨å³ä¸Šè§’çš„æŒ‰é’®åˆ›å»ºä¸€ä¸ªæ–°çš„åº”ç”¨ç¨‹åºï¼Œé€‰æ‹©ä½ å·²ç»æœ‰ä¸€ä¸ªåº”ç”¨ç¨‹åºã€‚
* ç°åœ¨ï¼Œå¦‚æœä½ æ­£ç¡®åœ°å°†ä½ çš„ GitHub è´¦å·ä¸ Streamlit å…³è”ï¼Œé€‰æ‹©ä¸‹æ‹‰èœå•ä¸­çš„åº”ç”¨ç¨‹åºä»“åº“ï¼Œé€‰æ‹©ä¸»åˆ†æ”¯ï¼Œå‘Šè¯‰å®ƒä¸»æ–‡ä»¶è·¯å¾„æ˜¯ *app.py*ï¼Œå¹¶è®°å¾—ä¸ºä½ çš„åº”ç”¨ç¨‹åºé€‰æ‹©ä¸€ä¸ªå¯ç”¨ã€ç®€çŸ­ä¸”é…·ç‚«çš„å­åŸŸåã€‚
* éƒ¨ç½²ï¼Œ1-2 åˆ†é’Ÿåä½ åº”è¯¥èƒ½çœ‹åˆ°ä½ çš„åº”ç”¨ç¨‹åºå…¬å¼€è¿è¡Œï¼ğŸš€
* å¦‚æœæœ‰ä»»ä½•é”™è¯¯æˆ–é—®é¢˜ï¼Œä½ å¯ä»¥ä»å³ä¸‹è§’çš„æŒ‰é’®è°ƒè¯•ï¼Œå®ƒä¼šæ˜¾ç¤ºæœåŠ¡å™¨æ—¥å¿—ï¼Œä»»ä½•é”™è¯¯éƒ½ä¼šæ‰“å°å‡ºæ¥ï¼Œä»¥ä¾¿ä½ æ›´å¥½åœ°ç†è§£å‡ºç°äº†ä»€ä¹ˆé—®é¢˜ã€‚

æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªå†…å®¹ï¼ŒRAG åº”ç”¨ç¨‹åºç¡®å®æ˜¯ä½¿ LLM æ›´åŠ é€‚ç”¨äºæ— æ•°å°ä¼—å’Œé«˜çº§åº”ç”¨çš„ä¸‹ä¸€æ­¥ã€‚ä½ å¯ä»¥æ ¹æ®æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„å†…å®¹é€‚åº”è®¸å¤šå…¶ä»–ç”¨ä¾‹ï¼Œåˆ©ç”¨å…¶ä»–æ›¿ä»£çš„ LangChain æ–¹æ³•ï¼Œæˆ–ä½¿ç”¨å¤–éƒ¨ Vector Store æœåŠ¡ï¼Œè¿™æ ·ä½ å°±ä¸å¿…åœ¨æœ¬åœ°è¿è¡Œ Chroma DBã€‚

ç¡®ä¿ç‚¹èµè¿™ç¯‡æ–‡ç« ï¼Œå…³æ³¨æˆ‘çš„ Medium å’Œ YouTubeï¼Œè¯„è®ºä»»ä½•é—®é¢˜å’Œåé¦ˆï¼Œæˆ‘ä»¬ä¸‹æ¬¡è§ï¼ï¼ğŸ¤— è°¢è°¢ï¼

