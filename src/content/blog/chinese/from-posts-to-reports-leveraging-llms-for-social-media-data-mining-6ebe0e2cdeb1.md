---
title: "ä»å¸–å­åˆ°æŠ¥å‘Šï¼šåˆ©ç”¨ LLM è¿›è¡Œç¤¾äº¤åª’ä½“æ•°æ®æŒ–æ˜"
meta_title: "ä»å¸–å­åˆ°æŠ¥å‘Šï¼šåˆ©ç”¨ LLM è¿›è¡Œç¤¾äº¤åª’ä½“æ•°æ®æŒ–æ˜"
description: "æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»ç¤¾äº¤åª’ä½“å¹³å°ï¼ˆå¦‚Instagramï¼‰ä¸­æå–å•†ä¸šç›¸å…³ä¿¡æ¯ã€‚é€šè¿‡ä½¿ç”¨æ•°æ®çˆ¬è™«ã€MongoDBæ•°æ®åº“å’Œæç¤ºå·¥ç¨‹ï¼Œç”¨æˆ·å¯ä»¥è‡ªåŠ¨åŒ–è·å–é¤å…çš„ç‰¹ä»·ã€æ´»åŠ¨å’Œæ–°èœå•ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–çš„æŠ¥å‘Šã€‚è¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿçš„ç½‘é¡µæŠ“å–ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¿‡æ»¤ä¿¡æ¯å™ªéŸ³ï¼Œå¹¶ä»¥CSVæˆ–Excelæ ¼å¼å­˜å‚¨æ•°æ®ï¼Œé€‚ç”¨äºå•†ä¸šåˆ†æå’Œå†³ç­–æ”¯æŒã€‚"
date: 2024-12-26T04:30:18Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AImMcgC4HcCxLtYaHnlYrA.jpeg"
categories: ["Programming", "Data Science", "Natural Language Processing"]
author: "Rifx.Online"
tags: ["LLMs", "Instagram", "Instaloader", "MongoDB", "Langchain"]
draft: False

---



### å¦‚ä½•æŒ‡å¯¼LLMsè¿‡æ»¤é¤å…å¸–å­å¹¶æå–å¯¹ä¸šåŠ¡å¢é•¿è‡³å…³é‡è¦çš„è§è§£ã€‚



### åº”ç”¨æ¦‚è¿°

æˆ‘ä»¬æ­£å¤„äºè‡ªåŠ¨åŒ–çš„é»„é‡‘æ—¶ä»£ï¼Œè¿™å¾—ç›Šäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å´›èµ·ã€‚ä»æ”¹å˜è¡Œä¸šåˆ°è§£é”æ— å°½çš„åº”ç”¨ï¼ŒLLMså½»åº•æ”¹å˜äº†æˆ‘ä»¬ä¸æ•°æ®çš„äº’åŠ¨æ–¹å¼ï¼Œä¸»è¦é€šè¿‡è‡ªç„¶è¯­è¨€ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•æŒ‡ç¤ºLLMç©¿é€ç¤¾äº¤åª’ä½“çš„å™ªéŸ³ï¼Œæå–æœ€é‡è¦çš„ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•æŒ–æ˜Instagramä¸Šçš„é¤å…å¸–å­ï¼Œä»¥æ”¶é›†æœ‰ä»·å€¼çš„æ•°æ®â€”â€”ä¾‹å¦‚ç‰¹ä»·ä¼˜æƒ ã€æŠ˜æ‰£å’Œæ´»åŠ¨â€”â€”å¹¶å°†å…¶æ±‡ç¼–æˆä¸€ä»½ç®€æ´çš„æ¯å‘¨æŠ¥å‘Šã€‚

### ä¸ºä»€ä¹ˆè¿™å¾ˆæœ‰ç”¨ï¼Ÿ

æ­£å¦‚å¤è€çš„è°šè¯­æ‰€è¯´ï¼Œ**â€œçŸ¥è¯†å°±æ˜¯åŠ›é‡ã€‚â€**

ä½¿ç”¨æœ¬æ–‡ä¸­ä»‹ç»çš„ç®—æ³•ï¼Œæ‚¨å¯ä»¥åœ¨ç‰¹å®šé¢†åŸŸè·å–æ‰€æœ‰é‡è¦æ•°æ®ï¼Œåªéœ€æŒ‰ä¸‹ä¸€ä¸ªæŒ‰é’®ï¼Œè®©LLMå®Œæˆæ‰€æœ‰å·¥ä½œï¼Œä»è€Œå°†æ‚¨å¯»æ‰¾è¿™äº›æ•°æ®çš„æ—¶é—´å‡å°‘åˆ°0ã€‚

ç¨ååœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘è¿˜å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•å°†è¿™äº›æ•°æ®ä»¥æ˜“äºé˜…è¯»çš„ç»“æ„å†™å…¥**CSV**æˆ–**EXCEL**ä¸­ï¼Œä»¥ä¾¿äºå­˜å‚¨æˆ–æ•°æ®æŸ¥è¯¢/è¿‡æ»¤ã€‚

è¿™ç§æ–¹æ³•æ¯”æ—§çš„ç½‘é¡µçˆ¬è™«/æŠ“å–æ–¹æ³•å…ˆè¿›å¾—å¤šï¼Œå› ä¸ºåœ¨LLMçš„å¸®åŠ©ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿‡æ»¤æå–çš„å†…å®¹ï¼Œåªå…³æ³¨æˆ‘ä»¬æ„Ÿå…´è¶£çš„éƒ¨åˆ†ã€‚

### ç›®å½•ï¼š

1\. æ•°æ®çˆ¬å–2\. æ•°æ®å­˜å‚¨3\. æç¤ºå·¥ç¨‹4\. LLM ä½¿ç”¨5\. å“åº”æ ¼å¼åŒ–6\. æ•´åˆæ‰€æœ‰å†…å®¹

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*3jAV-0Cy_VrJvyD1nNnJhw.jpeg)

## 1\. æ•°æ®çˆ¬å–

**å…è´£å£°æ˜**ï¼šæ ¹æ®æ‚¨çš„åœ°åŒºï¼Œæ­¤å®ç°å¯èƒ½å¯¹æ‚¨æ— æ•ˆï¼Œå› ä¸ºä¸åŒçš„æ³•è§„é€‚ç”¨äºç½‘ç»œçˆ¬å–ã€‚ï¼ˆè¿™æ˜¯åœ¨ç½—é©¬å°¼äºšIPä¸‹æµ‹è¯•çš„ï¼‰

**æ•°æ®çˆ¬è™«**ï¼ˆæˆ–ç½‘ç»œçˆ¬è™«ï¼‰æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–ç¨‹åºæˆ–è„šæœ¬ï¼Œç³»ç»Ÿåœ°æµè§ˆäº’è”ç½‘ä»¥æ”¶é›†å’Œç´¢å¼•æ¥è‡ªç½‘ç«™çš„æ•°æ®ã€‚

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [**Instaloader**](https://instaloader.github.io/) **\[2],** ä¸€ä¸ªå¤„ç†çˆ¬å–æ–¹é¢çš„Pythonåº“ï¼Œå®ƒå°†ä¸ºæˆ‘ä»¬æä¾›å…³äº**å…¬å¼€**Instagramä¸ªäººèµ„æ–™çš„æ‰€æœ‰ä¿¡æ¯ã€‚


```python
class InstagramCrawler:
    def __init__(self, page_name: str, proxy=None):
        self.page_name = page_name
        self.loader = instaloader.Instaloader()
        self._until = datetime.now()
        self._since = self._until - timedelta(days=7)

    def scrap(self) -> List[Dict[str, str | Any]]:
        profile = instaloader.Profile.from_username(self.loader.context, self.page_name)
        posts = takewhile(lambda p: p.date > self._since, dropwhile(lambda p: p.date > self._until, profile.get_posts()))

        return [
            {'content': post.caption, 'date': post.date, 'link': f"https://www.instagram.com/{self.page_name}"}
            for post in posts
        ]
```
åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ `datetime.now()` è·å–è¿è¡Œæ—¶çš„ç¡®åˆ‡æ—¥æœŸï¼Œå¹¶å‡å»7å¤©ï¼Œä»¥ä¾¿åªè·å–ä¸Šå‘¨çš„å¸–å­ã€‚

æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ª **config.py** æ¨¡å—æ¥åˆ›å»ºä¸€ä¸ª **Settings** ç±»ï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬å°†ä¿ç•™æ‰€æœ‰å¸¸é‡ï¼Œå¹¶å°†ç¯å¢ƒç§˜å¯†ä¼ é€’åˆ°å…¶ä»–æ–¹æ³•ä¸­ï¼Œä»¥ä¾¿ç¨åè®¿é—®ï¼Œè€Œä¸æ˜¯åšç±»ä¼¼äºï¼š **os.getenv('SOME\_ENV\_VALUE')** çš„äº‹æƒ…ã€‚

è¿™é€šè¿‡ Pydantic çš„ **BaseSettings** ç±»æ¥å®ç°ã€‚

å¦‚æœæ‚¨ä¸çŸ¥é“ Pydantic æ˜¯ä»€ä¹ˆï¼Œæˆ‘å»ºè®®é˜…è¯»å…¶æ–‡æ¡£ã€‚Pydantic æ¨¡å‹åœ¨ Python ç¼–ç¨‹ä¸­è‡³å…³é‡è¦ï¼Œæˆ‘å°†åœ¨æœ¬æ–‡ç¨åè®¨è®ºå®ƒä»¬ã€‚


```python
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8', extra='ignore')

    # OPENAI
    OPENAI_API_KEY: str
    OPENAI_MODEl: str = "gtp-4o-mini"

    # DB
    MONGO_HOST: str = 'localhost'
    MONGO_PORT: int = 27017
    MONGO_USER: str = None
    MONGO_PASSWORD: str = None
    MONGO_DATABASE: str = 'restaurants'
    MONGO_URI: str = f"mongodb://{MONGO_USER}:{MONGO_PASSWORD}@{MONGO_HOST}:{MONGO_PORT}"

    # è¦çˆ¬å–çš„ä¸ªäººèµ„æ–™
    PROFILES_TO_SCRAP: dict = {
        "KFC": {"page_name": "kfc", "city": "Salt Lake"},
        "MC": {"page_name": "mcdonalds", "city": "San Bernardino"},
        "In-N-Out Burger": {"page_name": "innout", "city": "Baldwin Park"},
        "Taco Bell": {"page_name": "tacobell", "city": "Downey"},
        "Wendy's": {"page_name": "wendys", "city": "Columbus"},
    }


settings = Settings()
```

## 2\. æ•°æ®å­˜å‚¨

æˆ‘è¿˜æ·»åŠ äº†ä¸€ä¸ªæ•°æ®åº“ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ [**MongoDB**](https://www.mongodb.com/)**,** å› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ˜¯éç»“æ„åŒ–æ•°æ®ã€‚è¿™æ ·ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ç¨åå¯¹æå–çš„å¸–å­åšäº›ä»€ä¹ˆï¼Œå°±å¯ä»¥å­˜å‚¨å®ƒä»¬ï¼ˆå°å¿ƒæ€»æ¯”åæ‚”å¥½**ï¼‰ã€‚**


```python
from pymongo.errors import ConnectionFailure
from pymongo import MongoClient
from config import settings


class DatabaseConnection:
    _client: MongoClient = None

    @classmethod
    def connect(cls):
        if cls._client is None:
            try:
                cls._client = MongoClient(settings.MONGO_URI)
            except ConnectionFailure as exc:
                print(f'Exception while connecting to database: {exc}')
                raise

    @classmethod
    def get_database(cls, name: str):
        if cls._client is None:
            cls.connect()
        return cls._client[name]

    @classmethod
    def close(cls):
        if cls._client is not None:
            cls._client.close()


database = DatabaseConnection.get_database(settings.MONGO_DATABASE)
```
æ•°æ®åº“åœ¨æœ¬åœ°è¿è¡Œäºä¸€ä¸ª [**Docker**](https://www.docker.com/) å®¹å™¨å†…ã€‚


```python
version: '3.8'

services:
  mongodb:
    image: mongo:latest
    container_name: mongo_db
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}

volumes:
  mongo-data:
```

## 3\. æç¤ºå·¥ç¨‹

æç¤ºå·¥ç¨‹å¯ä»¥æ€»ç»“ä¸ºè®¾è®¡å’Œä¼˜åŒ–æç¤ºï¼Œä»¥æœ‰æ•ˆå¼•å¯¼è¯­è¨€æ¨¡å‹æˆ–AIç³»ç»Ÿçš„è¡Œä¸ºã€‚å®ƒæ¶‰åŠåˆ°ç²¾å¿ƒåˆ¶ä½œè¾“å…¥ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºï¼Œç¡®ä¿ç”Ÿæˆå‡†ç¡®ã€ç›¸å…³å’Œè¿è´¯çš„å“åº”ï¼Œæ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚ç®€å•æ¥è¯´ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºè°ƒæ•´è¾“å…¥ä»¥æœ€å¤§åŒ–è¾“å‡ºè´¨é‡çš„è¿‡ç¨‹ã€‚

è¿™å°±æ˜¯è¯¥åº”ç”¨ç¨‹åºä¸­é­”æ³•å‘ç”Ÿçš„åœ°æ–¹ã€‚

åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¡Œä¸ºï¼Œå¹¶æŒ‡ç¤ºå®ƒå¯»æ‰¾å’Œæå–å“ªäº›ä¿¡æ¯ã€‚

æˆ‘ä»¬è¿˜é€šè¿‡è®¾ç½®ç¬¬äºŒä¸ªæç¤ºæ¥é¿å…å¹»è§‰ï¼Œä»¥ç²¾ç‚¼å“åº”ã€‚è¯¥ç»„ä»¶ä½äº **templates.py** æ¨¡å—ä¸­ã€‚

```python
PROFILES_REPORT_TEMPLATE = (
    "You're a Restaurnat specialist. Analyze social media posts from various restaurant pages and create a concise report extracting the following information:\n"
    "1. Giveaways\n"
    "2. Events (including dates)\n"
    "3. Deals and discounts (e.g., price reductions, 1+1 offers)\n"
    "4. New menu items\n"
    "For each item, include:\n"
    "- Restaurant page name"
    "- Post link"
    "- Restaurant location (city)\n"
    "Only include information from the provided posts that fits these categories. Avoid descriptive posts about dishes unless they mention specific offers or discounts.\n"
    "Posts to analyze: {input_var}"

)

PROFILES_TEMPLATE_REFINE = (
    "You're a restaurant specialist who has generated a report on various restaurant social media posts.\n"
    "Previous report: {raport}\n"
    "This report needs to be more concise and follow a predefined structure:\n"
    "1. Analyze your previous report.\n"
    "2. Adapt the report to the following structure: {format_instructions}\n"
    "If there's no relevant information for a key, leave it as an empty list\n."
    "Your response should only contain the specified structure, without ```json ``` tags."
)
```
**ç¬¬ä¸€ä¸ªæç¤º**æ—¨åœ¨ä»ç¤¾äº¤åª’ä½“å¸–å­ï¼ˆå¦‚Instagramæˆ–Facebookï¼‰ä¸­æå–ç‰¹å®šç±»å‹çš„ä¿¡æ¯ï¼Œä¸“æ³¨äºç›¸å…³çš„å•†ä¸šä¿¡æ¯ã€‚

é¤å…ç»å¸¸å‘å¸ƒå…³äºæ´»åŠ¨ã€ä¿ƒé”€æˆ–æ–°é¡¹ç›®çš„å†…å®¹ï¼Œè¿™äº›å†…å®¹é€šå¸¸ä¸èœå“æè¿°æˆ–ç¾å­¦ç…§ç‰‡ç­‰æ— å…³å†…å®¹æ··åˆåœ¨ä¸€èµ·ã€‚è¯¥æç¤ºçš„ç›®æ ‡æ˜¯è¿‡æ»¤å™ªéŸ³ï¼Œæå–å…³é”®çš„å•†ä¸šç›¸å…³æ•°æ®ã€‚

**ç¬¬äºŒä¸ªæç¤º**æ˜¯ä¸€ä¸ªç²¾ç‚¼é˜¶æ®µï¼Œä»¥ç¡®ä¿åˆå§‹è¾“å‡ºç¬¦åˆé¢„å®šä¹‰ç»“æ„ï¼Œå¹¶æ›´åŠ ç®€æ´ã€‚

åœ¨åˆæ­¥æå–åï¼Œæˆ‘ä»¬ä»å¯èƒ½é‡åˆ°æ ¼å¼ä¸å®Œç¾æˆ–è¿‡äºå†—é•¿çš„æ•°æ®ã€‚è¯¥æç¤ºç¡®ä¿æ¨¡å‹é‡æ–°åˆ†æå¹¶æ­£ç¡®æ ¼å¼åŒ–æ•°æ®ï¼ŒåŒæ—¶åˆ é™¤ä¸å¿…è¦çš„ä¿¡æ¯ã€‚

## 4\. LLM ä½¿ç”¨

åœ¨è¿™ä¸€æ­¥ï¼Œå·¥ä½œé‡ä¸å¤§ã€‚æˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•æ¥åˆ›å»ºå¯¹è¯é“¾ã€‚

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®¾ç½®ä¸ LLM ç›¸å…³çš„æ‰€æœ‰å†…å®¹ï¼Œå¦‚æ¨¡å‹åç§°ã€‚æˆ‘ä»¬ä¼ é€’æç¤ºå¹¶å°†æ‰€æœ‰å¯èƒ½ä½¿ç”¨çš„å˜é‡æ³¨å…¥å…¶ä¸­ï¼Œä¾‹å¦‚åœ¨ä¸Šè¿°ç¬¬ä¸€ä¸ªæç¤ºçš„æƒ…å†µä¸‹ä»æ•°æ®åº“æå–çš„å¸–å­ã€‚

ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [**Langchain**](https://python.langchain.com/docs/introduction/) **\[3]**ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å›´ç»•å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ„å»ºåº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒæä¾›äº†ç®¡ç†æç¤ºã€å°† LLM è¿æ¥åˆ°å¤–éƒ¨æ•°æ®æºã€å¤„ç† **æ“ä½œé“¾**ï¼Œä»¥åŠå°†æ¨¡å‹é›†æˆåˆ°èŠå¤©æœºå™¨äººæˆ–é—®ç­”ç³»ç»Ÿç­‰åº”ç”¨ç¨‹åºä¸­çš„å·¥å…·ï¼Œä½¿å¼€å‘ AI é©±åŠ¨çš„åº”ç”¨ç¨‹åºå˜å¾—æ›´åŠ å®¹æ˜“ã€‚

```python
from langchain.chains.llm import LLMChain
from langchain_core.prompts import PromptTemplate


def get_chain(llm, template: str, input_variables=None, verbose=True, output_key=""):
    return LLMChain(
        llm=llm,
        prompt=PromptTemplate(
            input_variables=input_variables, template=template, verbose=verbose
        ),
        output_key=output_key,
        verbose=verbose,
    )
```
å¯¹äºè¿™ä¸ªåº”ç”¨ä¸­çš„ LLMï¼Œæˆ‘é€‰æ‹©ä½¿ç”¨ [OpenAI](https://openai.com/) æ¨¡å‹ï¼Œå› ä¸ºå®ƒä½¿ç”¨ç®€å•ï¼Œå› æ­¤è¦ä½¿ç”¨æ­¤æ–¹æ³•ï¼Œæ‚¨éœ€è¦ä¸€ä¸ª `OPENAI_API_KEY` ã€‚

å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨ OpenAIï¼Œæ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ Grok APIï¼Œå®ƒå…·æœ‰ç›¸åŒçš„ API æ¥å£ã€‚

## 5\. å“åº”æ ¼å¼åŒ–

ä½¿ç”¨ç”Ÿæˆæ€§äººå·¥æ™ºèƒ½é€šå¸¸ä¼šäº§ç”Ÿå¤šæ ·çš„å“åº”ï¼Œè¿™äº›å“åº”æœ‰æ—¶å¯èƒ½åŒ…å«ä¸å‡†ç¡®çš„ä¿¡æ¯æˆ–ç¼ºä¹ç›¸åŒçš„ç»“æ„ã€‚

å¦‚æœæˆ‘ä»¬æƒ³åœ¨ Excel æˆ– CSV ä¸­ç¼–å†™æŠ¥å‘Šï¼Œè¿™å°†æ˜¯ä¸ªåæ¶ˆæ¯ï¼Œå› ä¸ºå¦‚æœæ²¡æœ‰é¢„å®šä¹‰çš„ç»“æ„ï¼Œåœ¨å†™å…¥æ–‡ä»¶æ—¶å¯èƒ½ä¼šå‡ºç°å„ç§é”™è¯¯ã€‚

ç„¶è€Œï¼Œå¥½æ¶ˆæ¯æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ [P**ydantic**](https://docs.pydantic.dev/latest/) **\[4]**ï¼ˆå†æ¬¡ï¼‰æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®ƒå…è®¸å¼€å‘è€…ä½¿ç”¨ Python ç±»å®šä¹‰æ•°æ®æ¨¡å‹ï¼Œç¡®ä¿æ•°æ®éµå¾ªæŒ‡å®šçš„ **ç±»å‹** å’Œ **çº¦æŸ**ï¼ŒåŒæ—¶æä¾›è‡ªåŠ¨ç±»å‹è½¬æ¢å’Œè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ã€‚

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®ç°äº† 3 ä¸ª pydantic ç±»ï¼Œè¿™äº›ç±»å°†è¢«ä¼ é€’åˆ°ä¸Šé¢å‘ˆç°çš„ç¬¬äºŒä¸ªæç¤ºä¸­ï¼Œä»¥æ ¼å¼åŒ– LLM å“åº”ä¸ºå¯ä»¥ç¨åå†™å…¥ EXCEL çš„é¢„å®šä¹‰ç»“æ„ã€‚

```python
from pydantic import BaseModel, Field


class InformationProfiles(BaseModel):
    name: str = Field(description='ä¿¡æ¯æå–é¡µé¢çš„åç§°')
    information: str = Field(description='ä¸ºæŒ‡å®šé”®æå–çš„ä¿¡æ¯ã€‚')
    link: str = Field(description='ä¿¡æ¯æå–çš„å¸–å­çš„é“¾æ¥ã€‚')
    city: str = Field(description='é¤å…æ‰€åœ¨çš„åŸå¸‚ã€‚')


class FieldProfiles(BaseModel):
    name: str = Field(description='é”®çš„åç§°ã€‚å¯ç”¨é€‰é¡¹åŒ…æ‹¬ï¼šèµ å“ã€ä¼˜æƒ å’ŒæŠ˜æ‰£ã€æ´»åŠ¨ã€‚')
    keys: list[InformationProfiles] = Field(description='é¤å…åŠå…¶ç›¸å…³ä¿¡æ¯çš„åˆ—è¡¨ã€‚')


class ReportProfiles(BaseModel):
    name: str = Field(description='æŠ¥å‘Šåç§°ï¼šæŠ¥å‘Šé¤å…æ–°é—»')
    fields: list[FieldProfiles] = Field(description='æ­¤æŠ¥å‘Šçš„æ‰€æœ‰ç›¸å…³é”®çš„åˆ—è¡¨ã€‚')
```

## 6\. æ•´åˆæ‰€æœ‰å†…å®¹

æˆ‘ä»¬åªéœ€åœ¨æˆ‘ä»¬çš„ **report\_generator.py** æ¨¡å—ä¸­æ•´åˆæ‰€æœ‰å†…å®¹ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç±»æ¥å°è£…æ‰€æœ‰é€»è¾‘ï¼š


```python
import datetime
import io
import json

import pandas as pd

from typing import List, Dict, Any
from langchain_core.output_parsers import PydanticOutputParser
from langchain_openai import ChatOpenAI

from src.config import settings
from src.crawler import InstagramCrawler
from src.db import database
from src.llm import get_chain
from schemas import ReportProfiles
from templates import PROFILES_REPORT_TEMPLATE, PROFILES_TEMPLATE_REFINE


class ReportGenerator:
    def __init__(self):
        self.crawler = InstagramCrawler()
        self.database = database
        self.llm = ChatOpenAI(model_name=settings.OPENAI_MODEl, api_key=settings.OPENAI_API_KEY)

    def crawl_and_store_posts(self):
        posts = self.crawler.get_posts(settings.PROFILES_TO_SCRAP)
        posts_collection = self.database['instagram_posts']
        for post in posts:
            posts_collection.update_one(
                {'link': post['link']},
                {'$set': post},
                upsert=True
            )
        return len(posts)

    def get_posts_from_db(self) -> List[Dict[str, Any]]:
        posts_collection = self.database['instagram_posts']
        end_date = datetime.datetime.now()
        start_date = end_date - datetime.timedelta(days=7)
        return list(posts_collection.find({
            'date': {'$gte': start_date, '$lte': end_date}
        }))

    @staticmethod
    def get_posts_text(posts: List[Dict[str, Any]]) -> List[str]:
        unique_posts = set()
        for post in posts:
            post_text = post.get("content", "")
            page_text = post.get("restaurant_name", "")
            link_text = post.get("link", "")
            city_text = post.get("city", "")

            if post_text:
                unique_posts.add(f"{post_text} | {page_text} | {link_text} | {city_text}\n")

        return list(unique_posts)

    def create_report(self, posts: List[str]) -> str:
        chain_1 = get_chain(
            self.llm,
            PROFILES_REPORT_TEMPLATE,
            input_variables=["input_var"],
            output_key="report",
        )

        result_1 = chain_1.invoke({"input_var": posts})
        report = result_1["report"]

        output_parser = PydanticOutputParser(pydantic_object=ReportProfiles)
        format_output = {"format_instructions": output_parser.get_format_instructions()}

        chain_2 = get_chain(
            self.llm,
            PROFILES_TEMPLATE_REFINE,
            input_variables=["raport", "format_instructions"],
            output_key="formatted_report",
        )

        result_2 = chain_2.invoke({"raport": report, "format_instructions": format_output})

        return result_2["formatted_report"]

    @staticmethod
    def create_excel_file(data: Dict[str, Any]):
        rows = []
        excel_filename = f"Profiles_report_{datetime.datetime.now().strftime('%Y-%m-%d')}.xlsx"

        report_name = data.get("name", "æœªçŸ¥æŠ¥å‘Š")
        for field in data.get("fields", []):
            field_name = field.get("name", "æœªçŸ¥å­—æ®µ")
            for key in field.get("keys", []):
                rows.append({
                    "æŠ¥å‘Šç±»å‹": report_name,
                    "ä¿¡æ¯ç±»å‹": field_name,
                    "æ¥æº": key.get("name", "æ— åç§°"),
                    "ä¿¡æ¯": key.get("information", "æ— ä¿¡æ¯"),
                    "é“¾æ¥": key.get("link", "æ— é“¾æ¥"),
                    "åŸå¸‚": key.get("city", "æ— åŸå¸‚"),
                })

        df = pd.DataFrame(rows)
        buffer = io.BytesIO()
        df.to_excel(buffer, index=False)
        buffer.seek(0)

        return buffer, excel_filename

    def generate_report(self):
        # ç¬¬ä¸€æ­¥ï¼šæŠ“å–å¹¶å­˜å‚¨Instagramå¸–å­
        posts_count = self.crawl_and_store_posts()
        print(f"æŠ“å–å¹¶å­˜å‚¨äº† {posts_count} æ¡å¸–å­ã€‚")

        # ç¬¬äºŒæ­¥ï¼šä»æ•°æ®åº“ä¸­æ£€ç´¢å¸–å­
        db_posts = self.get_posts_from_db()
        print(f"ä»æ•°æ®åº“ä¸­æ£€ç´¢äº† {len(db_posts)} æ¡å¸–å­ã€‚")

        # ç¬¬ä¸‰æ­¥ï¼šå¤„ç†å¸–å­å¹¶åˆ›å»ºæŠ¥å‘Š
        posts_text = self.get_posts_text(db_posts)
        report_data_str = self.create_report(posts_text)
        print(f"ä»å¸–å­ç”Ÿæˆçš„æŠ¥å‘Šï¼š{report_data_str}")

        # è§£æJSONå­—ç¬¦ä¸²
        try:
            report_data = json.loads(report_data_str)
        except json.JSONDecodeError:
            print("é”™è¯¯ï¼šæ— æ³•å°†æŠ¥å‘Šæ•°æ®è§£æä¸ºJSONã€‚")
            return None

        # ç¬¬å››æ­¥ï¼šåˆ›å»ºExcelæ–‡ä»¶
        excel_buffer, excel_filename = self.create_excel_file(report_data)

        # ç¬¬äº”æ­¥ï¼šä¿å­˜Excelæ–‡ä»¶
        with open(excel_filename, 'wb') as f:
            f.write(excel_buffer.getvalue())

        print(f"Excelæ–‡ä»¶ '{excel_filename}' åˆ›å»ºæˆåŠŸã€‚")
        return excel_filename
```
`generate_report()` æ–¹æ³•æ˜¯è¿™ä¸ªåº”ç”¨ç¨‹åºçš„â€œ**å…¥å£ç‚¹**â€ï¼Œå…¶ä¸­åŒ…å«ç”Ÿæˆæ¯å‘¨æŠ¥å‘Šæ‰€éœ€çš„æ‰€æœ‰æ­¥éª¤ã€‚

ç”±äºè¿™ä¸ªç±»æ¯”è¾ƒå¤§ï¼Œæˆ‘å°†è¯¦ç»†è¯´æ˜ **generate\_report()** æ–¹æ³•ä¸­å‘ˆç°çš„æ¯ä¸ªæ­¥éª¤ï¼š

**1**. `self.crawl_and_store_posts()`ï¼š

æ­¤æ–¹æ³•ä»é€‰å®šçš„Instagramä¸ªäººèµ„æ–™ä¸­æ£€ç´¢ä¸Šå‘¨çš„å¸–å­å¹¶å°†å…¶å­˜å‚¨åœ¨æˆ‘ä»¬çš„æ•°æ®åº“ä¸­ã€‚

**2\.** `self.get_posts_from_db()` :

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå–æ‰€æœ‰å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„å¸–å­ï¼ŒåŒæ—¶æ ¹æ®æ—¥æœŸåº”ç”¨è¿‡æ»¤é€»è¾‘ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½æœ‰æ¥è‡ªå‰å‡ å‘¨çš„å¸–å­å­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œä¸æƒ³æ£€ç´¢å®ƒä»¬ã€‚

**3\.** `self.get_posts_text()` å’Œ `self.create_report()` :

ç¬¬ä¸€ä¸ªæ–¹æ³•ç”¨äºæå–æˆ‘ä»¬å°†ä½œä¸ºè¾“å…¥å˜é‡ä¼ é€’ç»™æç¤ºçš„æ‰€æœ‰ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯æ¥è‡ªè¿”å›çš„æ•°æ®åº“æ¨¡å‹ã€‚

ç„¶åæˆ‘ä»¬æœ‰ç¬¬äºŒä¸ªæ–¹æ³•ï¼ŒLLMæ¥æ”¶æç¤ºå¹¶åˆ›å»ºæŠ¥å‘Šã€‚

**4\.** `self.create_excel_file()` :

åœ¨è¿™ä¸€æ­¥ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è°ƒç”¨ `json.loads(report_data_str)`ï¼Œä»¥ä¾¿ä½¿ç”¨JSONæ ¼å¼æ¥å†™å…¥EXCELã€‚å¦‚æœæˆ‘ä»¬åœ¨è¿™é‡Œæ‰“å°ï¼ŒæŠ¥å‘Šå¯èƒ½çœ‹èµ·æ¥åƒè¿™æ ·ï¼š


```python
{
  "name": "REPORT RESTAURANTS NEWS",
  "fields": [
    {
      "name": "Giveaways",
      "keys": []
    },
    {
      "name": "Deals and Discounts",
      "keys": []
    },
    {
      "name": "Events",
      "keys": [
        {
          "name": "Taco Bell",
          "information": "Early access event for the disha hot discovery box on 9/24 & 9/25.",
          "link": "https://www.instagram.com/tacobell",
          "city": "Downey"
        }
      ]
    }
  ]
}
```
è¯¥åº”ç”¨ç¨‹åºå¯ä»¥é€šè¿‡åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é«˜æ•ˆè¿è¡Œï¼š `make setup` å’Œ `make run`ï¼Œæˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ `make help` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤çš„åˆ—è¡¨ã€‚

## ç»“è®º

æˆ‘å¸Œæœ›é€šè¿‡é˜…è¯»æœ¬æ–‡ï¼ˆæˆ–åƒæŸäº›äººé‚£æ ·è·³è¿‡ä»£ç è¡Œ ğŸ¤«ï¼‰ï¼Œæ‚¨å·²ç»å­¦ä¼šäº†å¦‚ä½•ä½¿ç”¨ LLM ä»ç¤¾äº¤åª’ä½“å¹³å°æå–ä¿¡æ¯ã€‚

æˆ‘ä¹Ÿè®¤ä¸ºï¼Œå­¦ä¹ çš„æœ€ä½³æ–¹å¼æ˜¯å°†çŸ¥è¯†ä»˜è¯¸å®è·µï¼Œæˆ‘é¼“åŠ±æ‚¨å°†æˆ‘åœ¨è¿™é‡Œå®ç°çš„å†…å®¹è¿›è¡Œå®šåˆ¶ï¼Œä»¥æ»¡è¶³æ‚¨è‡ªå·±çš„éœ€æ±‚ã€‚

æ­¤åº”ç”¨ç¨‹åºå¯ä»¥æ ¹æ®ä»»ä½•ç”¨ä¾‹è¿›è¡Œæ›´æ”¹ï¼Œå¹¶å¯ä»¥ä¸å…¶ä»–çˆ¬è™«é›†æˆï¼Œä»¥ä¾¿ä»ä¸åŒçš„ç¤¾äº¤åª’ä½“ç½‘ç«™è·å–æ•°æ®ã€‚

> *æ‚¨å¯ä»¥åœ¨ GitHub ä¸Šæ‰¾åˆ°å®Œæ•´ä»£ç  [**è¿™é‡Œ**](https://github.com/decodingml/articles-code/tree/main/articles/generative_ai/data_extraction_from_social_media_posts_using_llms) **\[1]**ã€‚*

æœ€åï¼Œæˆ‘è¦ç‰¹åˆ«æ„Ÿè°¢ Decoding ML çš„å›¢é˜Ÿï¼Œè®©æˆ‘ç¬¬ä¸€æ¬¡ä½œä¸ºå®¢åº§ä½œè€…ã€‚å¯¹æ­¤æœºä¼šä»¥åŠæˆ‘ä»ä»–ä»¬èº«ä¸Šå­¦åˆ°çš„ä¸œè¥¿ï¼Œæˆ‘éå¸¸æ„Ÿæ¿€ã€‚

æˆ‘é¼“åŠ±æ‚¨å…³æ³¨ Substack ä¸Šçš„ ***æ¯å‘¨*** ğ——ğ—²ğ—°ğ—¼ğ—±ğ—¶ğ—»ğ—´ ğ— ğ—Ÿ ğ—¡ğ—²ğ˜„ğ˜€ğ—¹ğ—²ğ˜ğ˜ğ—²ğ—¿ï¼Œè·å–æ›´å¤š *é¡¶å°–* æ–‡ç« ï¼Œæ¶µç›–ç”Ÿäº§ AI å’Œ MLOpsã€‚

## å‚è€ƒæ–‡çŒ®

\[1] [ä½¿ç”¨LLMä»ç¤¾äº¤åª’ä½“å¸–å­ä¸­æå–æ•°æ® â€” Githubä»“åº“](https://github.com/decodingml/articles-code/tree/data_extraction_from_social_media_posts) (2024\)ï¼ŒDecoding ML GitHubç»„ç»‡

\[2] [Instaloaderæ–‡æ¡£](https://instaloader.github.io/) (2024\)ï¼ŒInstaloader

\[3] [Langchainæ–‡æ¡£](https://python.langchain.com/docs/introduction/) (2024\)ï¼ŒLangchain

\[4] [Pydanticæ–‡æ¡£](https://docs.pydantic.dev/latest/) (2024\)ï¼ŒPydantic

