---
title: "ä»£ç† RAG ç³»åˆ—ï¼šæ¢ç´¢ LangGraph é«˜çº§å·¥ä½œæµç¨‹"
meta_title: "ä»£ç† RAG ç³»åˆ—ï¼šæ¢ç´¢ LangGraph é«˜çº§å·¥ä½œæµç¨‹"
description: "æœ¬æ–‡æ¢è®¨äº†**LangGraph**åœ¨æ„å»º**Agentic RAG**æ¶æ„ä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒå…¶åœ¨åè°ƒå¤æ‚å·¥ä½œæµç¨‹ä¸­çš„ä¼˜åŠ¿ã€‚LangGraphæ”¯æŒå¤šä»£ç†ç³»ç»Ÿçš„åˆ›å»ºï¼Œå…·å¤‡å·¥ä½œæµç¼–æ’ã€å·¥å…·é›†æˆå’Œçµæ´»æ€§ç­‰ç‰¹æ€§ï¼Œé€‚åˆåŠ¨æ€éœ€æ±‚ã€‚æ–‡ç« è¿˜ä»‹ç»äº†åŸºäºLangGraphçš„å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æŸ¥è¯¢å¤„ç†ã€æ–‡æ¡£æ£€ç´¢å’Œå“åº”ç”Ÿæˆï¼Œå¹¶æä¾›äº†ç›¸å…³ä»£ç ç¤ºä¾‹ï¼Œå±•ç¤ºå…¶åœ¨å¤„ç†å¤šæ¨¡æ€æ–‡æ¡£æ—¶çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚"
date: 2024-12-27T11:09:55Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*WTisqw_ypLsMp2mf"
categories: ["Programming", "Machine Learning", "Chatbots"]
author: "Rifx.Online"
tags: ["LangGraph", "RAG", "workflows", "LangChain", "scalability"]
draft: False

---



## ä»‹ç»

åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†**Agentic RAG**çš„æ¦‚å¿µï¼Œå¼ºè°ƒå®ƒå¦‚ä½•é€šè¿‡é›†æˆè‡ªä¸»ä»£ç†èƒ½åŠ›æ¥æ‰©å±•ä¼ ç»Ÿçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶ã€‚åœ¨æœ¬æœŸä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨**LangGraph**ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºåè°ƒé€»è¾‘å·¥ä½œæµç¨‹çš„åˆ›æ–°æ¡†æ¶ã€‚LangGraphä½¿å¾—åˆ›å»ºå…·æœ‰å¤æ‚æ¨ç†èƒ½åŠ›çš„å¤šä»£ç†ç³»ç»Ÿæˆä¸ºå¯èƒ½ï¼Œæ˜¯æ„å»ºAgentic RAGæ¶æ„çš„ç†æƒ³å·¥å…·ã€‚

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FdR0wG5Y9IbCZ909-G_1lQ.png)

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*q9GUYeVrR_lzBCW4uDDhUQ.png)

## ä¸ºä»€ä¹ˆé€‰æ‹© LangGraph è¿›è¡Œ Agentic RAGï¼Ÿ

**LangGraph** æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„ç¯å¢ƒï¼Œç”¨äºåˆ›å»ºæœ‰çŠ¶æ€çš„å·¥ä½œæµï¼Œä»£ç†åœ¨èŠ‚ç‚¹ã€å·¥å…·å’Œä»»åŠ¡ä¹‹é—´æ™ºèƒ½åœ°äº’åŠ¨ã€‚å®ƒä¸ **LangChain** åŠå…¶ä»–é«˜çº§ AI æ¡†æ¶çš„å…¼å®¹æ€§ä½¿å¾—ä¸æ£€ç´¢å’Œç”Ÿæˆç®¡é“çš„æ— ç¼é›†æˆæˆä¸ºå¯èƒ½ï¼Œå®Œç¾å¥‘åˆäº† Agentic RAG çš„åŠ¨æ€éœ€æ±‚ã€‚

### ä¸»è¦ä¼˜åŠ¿ï¼š

1. **å·¥ä½œæµç¼–æ’ï¼š** å®šä¹‰å’Œç®¡ç†å…·æœ‰æ¡ä»¶é€»è¾‘å’ŒçŠ¶æ€ç®¡ç†çš„å¤šæ­¥éª¤å·¥ä½œæµã€‚
2. **å·¥å…·é›†æˆï¼š** å®¹æ˜“é›†æˆå¤–éƒ¨å·¥å…·ã€API å’Œæ£€ç´¢ç³»ç»Ÿã€‚
3. **å¯æ‰©å±•æ€§ï¼š** ä»¥æœ€å°çš„å¼€é”€å¤„ç†å¤æ‚çš„å¤šä»£ç†å·¥ä½œæµã€‚
4. **çµæ´»æ€§ï¼š** è®¾è®¡èƒ½å¤ŸåŠ¨æ€é€‚åº”ä¸Šä¸‹æ–‡å’Œè¾“å…¥çš„å·¥ä½œæµã€‚

## å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« å¹¶æƒ³è¡¨è¾¾ä¸€äº›æ”¯æŒï¼š

* **æ‹æ‰‹** 50 æ¬¡â€”â€”æ¯ä¸€æ¬¡çš„æ”¯æŒéƒ½æ¯”ä½ æƒ³è±¡çš„æ›´æœ‰å¸®åŠ©ï¼ ğŸ‘
* **å…³æ³¨** æˆ‘åœ¨ [**Medium**](https://medium.com/@mauryaanoop3)ï¼Œå…è´¹è®¢é˜…ä»¥è·å–æˆ‘çš„æœ€æ–°å¸–å­ã€‚ ğŸ«¶
* è®©æˆ‘ä»¬åœ¨ [**LinkedIn**](https://medium.com/towards-artificial-intelligence/www.linkedin.com/in/anoop-maurya-908499148) ä¸Šè¿æ¥ï¼ŒæŸ¥çœ‹æˆ‘åœ¨ [**GitHub**](https://github.com/imanoop7) ä¸Šçš„é¡¹ç›®ï¼Œå¹¶åœ¨ [**Twitter**](https://x.com/imanoop_7) ä¸Šä¿æŒè”ç³»ï¼
* å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œä¸è¦å¿˜è®°åœ¨ [**GitHub**](https://github.com/imanoop7/Agentic-RAG) ä¸Šç»™è¿™ä¸ªä»“åº“ â­ã€‚è¿™ä¹Ÿå¸®åŠ©å…¶ä»–äººæ‰¾åˆ°å®ƒï¼

## LangGraph æ¶æ„ç”¨äº Agentic RAG

ä¸€ä¸ªå…¸å‹çš„ LangGraph å·¥ä½œæµç”¨äº Agentic RAG å¯èƒ½åŒ…æ‹¬æŸ¥è¯¢é‡å†™ã€æ–‡æ¡£æ£€ç´¢ã€ç›¸å…³æ€§è¯„åˆ†å’Œç”Ÿæˆå“åº”çš„ç»„ä»¶ã€‚

### æµç¨‹å›¾ï¼šAgentic RAG ä¸­çš„ LangGraph å·¥ä½œæµç¨‹

```python
[Start Query]
   |
   v
[Agent Node: Rewrite or Process Query]
   |
   +--> [Retrieve Documents: Knowledge Sources]
   |
   +--> [Grade Relevance]
   |
   +--> [Generate Response]
   |
   v
[End]
```

* **Start Query:** æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ã€‚
* **Agent Node:** æ ¹æ®ä¸Šä¸‹æ–‡å’Œæ¡ä»¶ç¡®å®šä¸‹ä¸€æ­¥ã€‚
* **Retrieve Documents:** ä»çŸ¥è¯†åº“ä¸­è·å–ç›¸å…³æ–‡æ¡£ã€‚
* **Grade Relevance:** å¯¹æ–‡æ¡£è¿›è¡Œè¯„åˆ†ï¼Œä»¥è¯„ä¼°å…¶ä¸æŸ¥è¯¢çš„ä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚
* **Generate Response:** ä½¿ç”¨æ£€ç´¢å’Œå¤„ç†çš„æ•°æ®ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚

## ä½¿ç”¨ Agentic RAG å¯¹ LangGraph è¿›è¡ŒåŸºå‡†æµ‹è¯•

### å®éªŒè®¾ç½®

* **æ•°æ®é›†ï¼š** ç ”ç©¶è®ºæ–‡ã€æ–‡ç« å’Œå¸¸è§é—®é¢˜çš„æ··åˆã€‚
* **è¯„ä¼°æŒ‡æ ‡ï¼š** ç›¸å…³æ€§ã€å‡†ç¡®æ€§ã€å“åº”æ—¶é—´å’Œå·¥ä½œæµç¨‹æ•ˆç‡ã€‚
* **åŸºå‡†ï¼š** ä¼ ç»Ÿçš„ RAG ä¸ä½¿ç”¨ LangGraph çš„ Agentic RAGã€‚

### ç»“æœ:

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_-j98OuAf923t0i1M7H6VA.png)

## ä»£ç è¯´æ˜ï¼š

è¯¥ä»£ç å®šä¹‰äº†ä¸€ä¸ª **æ–‡æ¡£é—®ç­”åŠ©æ‰‹**ï¼Œå…è®¸ç”¨æˆ·ä¸Šä¼ PDFæ–‡ä»¶ã€æä¾›URLæˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹ï¼Œç„¶åè¯¢é—®æœ‰å…³è¿™äº›æ–‡æ¡£å†…å®¹çš„é—®é¢˜ã€‚å®ƒåˆ©ç”¨ **LangChainæ¡†æ¶**ã€**LangGraph** å’Œ **Ollama API** è¿›è¡ŒåµŒå…¥å’ŒåŸºäºèŠå¤©çš„å“åº”ã€‚è¯¥åŠ©æ‰‹ä½¿ç”¨ **Gradioåº“** æ„å»ºï¼Œæä¾›äº†ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„ç•Œé¢ï¼Œä»¥ä¾¿ä¸ç³»ç»Ÿè¿›è¡Œäº¤äº’ã€‚

### ä»£ç è§£æï¼š

### 1\. å¯¼å…¥

ä»£ç å¼€å§‹æ—¶å¯¼å…¥å¿…è¦çš„æ¨¡å—ï¼š

* **LangChain å’Œ LangGraph**ï¼šç”¨äºæ–‡æ¡£åŠ è½½ã€å‘é‡å­˜å‚¨åˆ›å»ºã€åµŒå…¥ã€æ¶ˆæ¯å¤„ç†å’ŒåŸºäºå›¾çš„å·¥ä½œæµç¨‹ã€‚
* **Gradio**ï¼šç”¨äºæ„å»ºç”¨æˆ·å‹å¥½çš„ç•Œé¢ã€‚
* **Pydantic**ï¼šå¸®åŠ©å®šä¹‰å’ŒéªŒè¯æ•°æ®ç»“æ„ã€‚
* **Validators**ï¼šç”¨äºæ£€æŸ¥ URL çš„æœ‰æ•ˆæ€§ã€‚
* **Tempfile**ï¼šåˆ›å»ºä¸´æ—¶æ–‡ä»¶ä»¥å¤„ç† PDF ä¸Šä¼ ã€‚

```python
from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.tools.retriever import create_retriever_tool
from typing import Annotated, Sequence, Literal
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, HumanMessage
from langgraph.graph.message import add_messages
from langchain import hub
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import END, StateGraph, START
from langgraph.prebuilt import ToolNode, tools_condition
from pydantic import BaseModel, Field
import gradio as gr
import tempfile
import validators
from io import StringIO
```

### 2\. æ•°æ®ç»“æ„

* **AgentState**: ä¸€ä¸ª `TypedDict`ï¼Œç”¨äºè·Ÿè¸ªä»£ç†çš„çŠ¶æ€ï¼Œç‰¹åˆ«æ˜¯ä¸€ç³»åˆ—æ¶ˆæ¯ã€‚å®ƒç”¨äºåœ¨äº¤äº’è¿‡ç¨‹ä¸­ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡ã€‚

```python
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
```

### 3\. å¤„ç†æ¥æº

* `process_sources(urls=None, pdf_files=None)`:
* æ¥å— URL å’Œ/æˆ– PDF æ–‡ä»¶ä½œä¸ºè¾“å…¥ã€‚
* å¯¹äº URLï¼š
* éªŒè¯æ ¼å¼ã€‚
* ä½¿ç”¨ `WebBaseLoader` ä»ç½‘ç»œåŠ è½½æ–‡æ¡£ã€‚
* å¯¹äº PDFï¼š
* ä¸´æ—¶ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶ã€‚
* ä½¿ç”¨ `PyPDFLoader` å°† PDF è§£æä¸ºæ–‡æ¡£ã€‚
* è¿”å›å¤„ç†åçš„æ–‡æ¡£åˆ—è¡¨ã€‚

```python
def process_sources(urls=None, pdf_files=None):
    """Process both URLs and PDF files"""
    docs_list = []
  
    # Handle URLs
    if urls and urls.strip():
        url_list = [url.strip() for url in urls.split(",")]
        for url in url_list:
            if validators.url(url):
                try:
                    url_docs = WebBaseLoader(url).load()
                    docs_list.extend(url_docs)
                except Exception as e:
                    print(f"Error loading URL {url}: {e}")
  
    # Handle PDFs
    if pdf_files:
        for pdf in pdf_files:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:
                    tmp.write(pdf.read())
                    loader = PyPDFLoader(tmp.name)
                    docs_list.extend(loader.load())
            except Exception as e:
                print(f"Error loading PDF: {e}")
```

### 4\. æ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†

* `grade_documents(state)`:
* ç¡®å®šæ–‡æ¡£æ˜¯å¦ä¸ç”¨æˆ·çš„æŸ¥è¯¢ç›¸å…³ã€‚
* ä½¿ç”¨ `ChatOllama` å’Œç‰¹å®šæç¤ºå°†æ–‡æ¡£è¯„åˆ†ä¸º `yes` æˆ– `no`ã€‚
* æç¤ºè¦æ±‚æ¨¡å‹è¯„ä¼°æ–‡æ¡£å†…å®¹æ˜¯å¦ä¸ç”¨æˆ·çš„é—®é¢˜ä¸€è‡´ã€‚

```python
def grade_documents(state) -> Literal["generate", "rewrite"]:
    print("---CHECK RELEVANCE---")
  
    class grade(BaseModel):
        binary_score: str = Field(description="ç›¸å…³æ€§è¯„åˆ† 'yes' æˆ– 'no'")
  
    model = ChatOllama(temperature=0, model="llama3.2", streaming=True)
    llm_with_tool = model.with_structured_output(grade)
  
    prompt = PromptTemplate(
        template="""You are a grader assessing relevance of a retrieved document to a user question.
        Document: {context}
        Question: {question}
        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.
        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.""",
        input_variables=["context", "question"],
    )
  
    chain = prompt | llm_with_tool
  
    messages = state["messages"]
    question = messages[0].content
    docs = messages[-1].content
  
    scored_result = chain.invoke({"question": question, "context": docs})
    return "generate" if scored_result.binary_score == "yes" else "rewrite"
```

### 5\. æ ¸å¿ƒä»£ç†åŠŸèƒ½ï¼š

`agent(state)`:

* é€šè¿‡è°ƒç”¨ä»£ç†çš„ LLM åŠŸèƒ½å’Œæä¾›çš„å·¥å…·æ¥å¤„ç†ä¸€èˆ¬æŸ¥è¯¢ã€‚

```python
def agent(state):
    print("---CALL AGENT---")
    messages = state["messages"]
    model = ChatOllama(temperature=0, streaming=True, model="llama3.2")
    model = model.bind_tools(tools)
    response = model.invoke(messages)
    return {"messages": [response]}
```

`rewrite(state)`:

* ä½¿ç”¨è¯­ä¹‰æ¨ç†é‡æ–°è¡¨è¿°ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œä»¥æé«˜ç²¾ç¡®åº¦ã€‚

```python
def rewrite(state):
    print("---TRANSFORM QUERY---")
    messages = state["messages"]
    question = messages[0].content
  
    msg = [HumanMessage(content=f"""
    Look at the input and try to reason about the underlying semantic intent / meaning.
    Initial question: {question}
    Formulate an improved question:""")]
  
    model = ChatOllama(temperature=0, model="llama3.2", streaming=True)
    response = model.invoke(msg)
    return {"messages": [response]}
```

`generate(state)`:

* ä½¿ç”¨é¢„æ„å»ºçš„ RAGï¼ˆæ£€ç´¢ä¸ç”Ÿæˆï¼‰æç¤ºæ¥å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œåˆ©ç”¨ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚

```python
def generate(state):
    print("---GENERATE---")
    messages = state["messages"]
    question = messages[0].content
    docs = messages[-1].content
  
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOllama(temperature=0, streaming=True, model="llama3.2")
    rag_chain = prompt | llm | StrOutputParser()
  
    response = rag_chain.invoke({"context": docs, "question": question})
    return {"messages": [HumanMessage(content=response)]}
```

### 6\. æŸ¥è¯¢å¤„ç†å·¥ä½œæµç¨‹

`process_query(urls, pdf_files, query)`:

* é¦–å…ˆï¼Œå°†æä¾›çš„URLså’ŒPDFå¤„ç†æˆæ–‡æ¡£åˆ—è¡¨ã€‚
* ä½¿ç”¨`RecursiveCharacterTextSplitter`å°†è¿™äº›æ–‡æ¡£æ‹†åˆ†æˆæ›´å°çš„å—ã€‚
* ä½¿ç”¨`OllamaEmbeddings`å¯¹è¿™äº›å—è¿›è¡ŒåµŒå…¥ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨**Chromaå‘é‡å­˜å‚¨**ä¸­ã€‚
* åˆ›å»ºä¸€ä¸ªæ£€ç´¢å·¥å…·ä»¥åœ¨å‘é‡å­˜å‚¨ä¸­è¿›è¡Œæœç´¢ã€‚
* å®šä¹‰ä¸€ä¸ªåŸºäº**LangGraph**çš„å·¥ä½œæµç¨‹ï¼ŒåŒ…å«èŠ‚ç‚¹ï¼š
* `agent`: ç®¡ç†å¯¹è¯æµç¨‹ã€‚
* `retrieve`: æœç´¢ç›¸å…³æ–‡æ¡£ã€‚
* `rewrite`: é‡æ–°è¡¨è¿°æŸ¥è¯¢ã€‚
* `generate`: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
* å·¥ä½œæµç¨‹è¾¹ç¼˜æ ¹æ®æ¡ä»¶å®šä¹‰è¿™äº›èŠ‚ç‚¹ä¹‹é—´çš„è½¬æ¢ã€‚
* æ‰§è¡Œå›¾å½¢ä»¥å‘ç”¨æˆ·æä¾›æŸ¥è¯¢çš„å“åº”ã€‚

```python
def process_query(urls, pdf_files, query):
    docs_list = process_sources(urls, pdf_files)
    if not docs_list:
        return "No valid documents provided. Please input URLs or upload PDFs."
  
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)
    doc_splits = text_splitter.split_documents(docs_list)
  
    vectorstore = Chroma.from_documents(
        documents=doc_splits,
        collection_name="rag-chroma",
        embedding=OllamaEmbeddings(model="nomic-embed-text"),
    )
    retriever = vectorstore.as_retriever()
  
    global tools
    tools = [create_retriever_tool(
        retriever,
        "retrieve_documents",
        "Search and return information from the provided documents."
    )]
  
    workflow = StateGraph(AgentState)
    workflow.add_node("agent", agent)
    workflow.add_node("retrieve", ToolNode(tools))
    workflow.add_node("rewrite", rewrite)
    workflow.add_node("generate", generate)
  
    workflow.add_edge(START, "agent")
    workflow.add_conditional_edges(
        "agent",
        tools_condition,
        {"tools": "retrieve", END: END},
    )
    workflow.add_conditional_edges(
        "retrieve",
        grade_documents,
        {"generate": "generate", "rewrite": "rewrite"},
    )
    workflow.add_edge("generate", END)
    workflow.add_edge("rewrite", "agent")
  
    graph = workflow.compile()
  
    inputs = {"messages": [HumanMessage(content=query)]}
    response = ""
    for output in graph.stream(inputs):
        for key, value in output.items():
            if value.get("messages"):
                response = value["messages"][-1].content
  
    return response
```

### 7\. Gradio ç•Œé¢

`create_interface()`:

* æ„å»ºä¸€ä¸ªå¸¦æœ‰ä¸¤ä¸ªæ ‡ç­¾çš„ Gradio ç•Œé¢ï¼š

**ä¸Šä¼ æ–‡æ¡£**ï¼š

* è¾“å…¥æ¡†ç”¨äºè¾“å…¥ URLã€‚
* æ–‡ä»¶ä¸Šä¼ å™¨ç”¨äºä¸Šä¼  PDF æ–‡ä»¶ã€‚
* å¤„ç†æ–‡æ¡£çš„æŒ‰é’®ã€‚
* çŠ¶æ€æ¡†æ˜¾ç¤ºå¤„ç†ç»“æœã€‚

**èŠå¤©**ï¼š

* ç”¨æˆ·æŸ¥è¯¢çš„è¾“å…¥æ¡†ã€‚
* å¯åŠ¨æŸ¥è¯¢çš„æŒ‰é’®ã€‚
* æ˜¾ç¤ºå“åº”çš„è¾“å…¥æ¡†ã€‚

```python
def create_interface():
    with gr.Blocks(title="Document Q&A Assistant") as interface:
        gr.Markdown("# Document Q&A Assistant")
        gr.Markdown("*You can provide URLs, PDF files, or both*")
      
        with gr.Tab("Upload Documents"):
            urls = gr.Textbox(label="Enter URLs (comma separated)", placeholder="https://example1.com, https://example2.com")
            pdfs = gr.File(file_count="multiple", label="Upload PDF files", file_types=[".pdf"])
            upload_btn = gr.Button("Process Documents")
            upload_status = gr.Textbox(label="Upload Status")
          
            def handle_upload(urls, pdfs):
                if not urls and not pdfs:
                    return "Please provide either URLs, PDF files, or both"
                docs = process_sources(urls, pdfs)
                if docs:
                    return "Documents processed successfully!"
                return "No valid documents provided. Please input valid URLs or PDF files"
          
            upload_btn.click(
                fn=handle_upload,
                inputs=[urls, pdfs],
                outputs=upload_status
            )
      
        with gr.Tab("Chat"):
            query = gr.Textbox(label="Ask a question about the documents")
            chat_btn = gr.Button("Ask")
            response = gr.Textbox(label="Response")
          
            chat_btn.click(
                fn=process_query,
                inputs=[urls, pdfs, query],
                outputs=response
            )
          
    return interface
```

### 8\. åº”ç”¨ç¨‹åºå¯åŠ¨

* å½“è„šæœ¬è¢«æ‰§è¡Œæ—¶ï¼ŒGradio ç•Œé¢è¢«å¯åŠ¨ã€‚

```python
interface = create_interface()

if __name__ == "__main__":
    interface.launch()
```

## å…³é”®ç‰¹æ€§äº®ç‚¹ï¼š

**å¤šæ¨¡æ€æ–‡æ¡£æ”¯æŒ**ï¼š

* åŒæ—¶æ”¯æŒ URLs å’Œ PDFsã€‚

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vah5AK1CD8BREdcNCcEggw.png)

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*j7dpCN5gRDHBXrMq9VszqQ.png)

**ç›¸å…³æ€§è¯„åˆ†**ï¼š

* ç¡®ä¿å“åº”åŸºäºæœ€ç›¸å…³çš„æ–‡æ¡£ã€‚

**å·¥ä½œæµå›¾**ï¼š

* åˆ©ç”¨ `StateGraph` åŠ¨æ€å†³å®šè¡ŒåŠ¨ï¼ˆä¾‹å¦‚ï¼Œé‡å†™ã€æ£€ç´¢ã€ç”Ÿæˆï¼‰ã€‚

**åµŒå…¥å’Œå‘é‡æœç´¢**ï¼š

* ä½¿ç”¨ `OllamaEmbeddings` å’Œ **Chroma å‘é‡å­˜å‚¨** è¿›è¡Œé«˜æ•ˆçš„æ–‡æ¡£æ£€ç´¢ã€‚

**äº¤äº’å¼ç”¨æˆ·ç•Œé¢**ï¼š

* ä½¿ç”¨ **Gradio** æä¾›å¯è®¿é—®çš„æ— ä»£ç ç•Œé¢ã€‚

## ç»“è®º

LangGraph æ˜¯æ¨åŠ¨ Agentic RAG å‘å±•çš„å…³é”®å·¥å…·ï¼Œé€šè¿‡æ”¯æŒåŠ¨æ€çš„å¤šä»£ç†å·¥ä½œæµç¨‹ï¼Œèƒ½å¤Ÿé€‚åº”å¤æ‚åœºæ™¯ã€‚å®ƒä¸ LangChainã€Chroma å’Œ ChatOllama ç­‰å·¥å…·çš„æ— ç¼é›†æˆç¡®ä¿å¼€å‘è€…èƒ½å¤Ÿé«˜æ•ˆæ„å»ºå¯æ‰©å±•çš„æ™ºèƒ½æ£€ç´¢å¢å¼ºç³»ç»Ÿã€‚

åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ **AutoGen** åŠå…¶åœ¨ Agentic RAG æ¡†æ¶ä¸­è‡ªåŠ¨åŒ–ä»£ç†æ¨ç†çš„ä½œç”¨ã€‚

## å…¶ä»–èµ„æºï¼š

**å®Œæ•´ä»£ç :** [https://github.com/imanoop7/Agentic\-RAG](https://github.com/imanoop7/Agentic-RAG) **Ollama å®˜æ–¹ç½‘ç«™:** [https://ollama.com/](https://ollama.com/) **Ollama GitHub:** [https://github.com/ollama/ollama?tab\=readme\-ov\-file](https://github.com/ollama/ollama?tab=readme-ov-file) **å¤‡å¿˜å•:** [https://cheatsheet.md/llm\-leaderboard/ollama.en](https://cheatsheet.md/llm-leaderboard/ollama.en) **Langgraph:** [https://langchain\-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/) **æˆ‘çš„ GitHub:** [https://github.com/imanoop7](https://github.com/imanoop7) **LinkedIn:** [www.linkedin.com/in/anoop\-maurya\-908499148](http://www.linkedin.com/in/anoop-maurya-908499148) **X:** [https://x.com/imanoop_7](https://x.com/imanoop_7)


