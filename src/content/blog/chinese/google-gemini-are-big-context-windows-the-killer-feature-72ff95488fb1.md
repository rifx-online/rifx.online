---
title: "Google Gemini：大上下文窗口是杀手级功能吗？"
meta_title: "Google Gemini：大上下文窗口是杀手级功能吗？"
description: "Goggle 即将推出的法学硕士学位课程有了重大进展"
date: 2024-11-10T22:36:54Z
image: "https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MteQrQSTXLuJcd86RbjQrg.png"
categories: ["Machine Learning", "Natural Language Processing", "Data Science"]
author: "Rifx.Online"
tags: ["Gemini", "tokens", "context", "LLM", "evolution"]
draft: False

---

### 谷歌即将推出的 LLM 迈出了重大一步



就在八个月前，一封泄露的谷歌电子邮件透露该公司在努力超越其 AI 竞争对手方面遇到了困难。他们的 AI 产品周围不仅没有[护城河](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)——换句话说，没有建立起商业优势——谷歌也没有[秘密武器](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)可以改变局面。即使在他们努力解决这个问题时，他们也看到私募资助的 AI 项目与开源 AI 模型之间的差距以“惊人的”速度缩小。

现在还为时已晚，无法知道这个故事的结局。也许开源 AI 将继续在早期成功的基础上发展，或者它将被谷歌、微软和苹果等极其富有的竞争对手及其令人难以置信的数据量所压制。现在，这场冲突仍在展开，各个组织快速推出一系列 AI 进展。最近，谷歌在这个领域中成为焦点，宣布了其最新 LLM 的预览版——[Gemini 1.5 Pro](https://deepmind.google/technologies/gemini/)。又是一天，又一个大型语言模型——或者说似乎如此，直到谷歌描述了一个惊人的变化。

Gemini 1.5 Pro 扩展了 *上下文窗口*——本质上是衡量 LLM 一次可以跟踪多少数据的指标。在过去的版本中，Gemini 的上下文窗口最大为 128,000 个标记，就像 GPT-4 一样。但 Gemini 的新上下文窗口可以容纳 **100 万** 个标记，这一变化的影响是巨大的。

但在我们讨论上下文窗口对 LLM 能力的影响之前，我们需要回顾一下上下文窗口的工作原理。

## 上下文窗口（简而言之）

简单来说，上下文窗口设置了 LLM 在交互过程中能够记住多少信息。例如，如果您正在使用 ChatGPT，上下文窗口包括您给它的当前提示、您之前在该对话中输入的所有内容，以及 ChatGPT 向您发送的每个回复。对话时间长了，旧的对话部分将会从上下文窗口中滑出，ChatGPT 将突然忘记那些细节。

128,000 个令牌的上下文窗口听起来很大，但这个数字具有误导性。首先，考虑到一个平均单词在为 LLM 分解时实际上是 1 到 3 个令牌。（经验法则是 4 个令牌对应 3 个单词，但随着语言变得更加复杂或在专业领域（如法律或医学）中，这个数字会增加。）当您查看长文档、进行持续交互和 AI 驱动的应用程序时，您会很快发现您无法将所有希望 LLM 知道的内容都放入其上下文窗口中。

因此，我们开发了一些巧妙的方法来解决上下文窗口的限制。例如：

* **分块。** 您可以将大量数据分解，让 LLM 一次查看一部分。这对于某些任务（总结长文档）效果很好，但如果您需要分析跨整个文档的概念，则效果不佳。
* **微调。** 您可以用特定的数据训练 LLM。除了时间和费用之外，关键问题是您的新数据很容易被 LLM 已经吸收的更大规模的通用训练数据所淹没。通常，它就是无法保留。此外，许多 LLM 根本不支持微调——包括 GPT-4 和 Gemini。
* **检索增强生成 (RAG)。** 首先，您将文本内容转换为一种特殊表示，称为 *嵌入*。（嵌入是 LLM 工作的重要部分。基本上，它们是捕捉内容含义的数值表示。）一旦您有了嵌入，您就将它们放入向量数据库中。现在，您可以使用 *语义搜索* 的魔力查看提示，并在数据库中找到与之概念相关的内容片段，然后将其输入 LLM。换句话说，您只给它提供重要的内容。

最后一点是今天最常见的方法。RAG 高效且可预测。如果您拥有大量松散相关的文档，它效果非常好。例如，想象一下您正在创建一个技术支持聊天机器人，它从您公司的知识库文章中获取信息。使用 RAG，您找到相关数据，并将其与您的提示一起提供给 LLM。基本上，您是在告诉 LLM 在回答提示时该去哪里查找。

但 RAG 并不完美。它迫使您花费更多时间准备数据。它不容易让您跳入一个全新的数据集。如果您确实需要一次考虑大量信息——例如，您在寻找小说中的整体主题或代码库中的特征——那么它就不够有效。但尽管有其局限性，RAG 今天仍然接近最佳实践。

至少，在 Gemini 1.5 Pro 翻转剧本之前是这样的。

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EEHKDSH0wXa-J6veK5etZA.png)

## 惊艳时刻

尽管 Gemini 1\.5 Pro 尚未发布，但它已经在一个严格限制的试用中可用。结果令人瞩目。

一些最令人印象深刻的例子展示了 Gemini 创建的分析，涵盖了大量知识。谷歌的演示一如既往地令人印象深刻，但他们过去曾被指控进行演示操控和选择性展示。我更感兴趣的是独立测试者，他们报告的结果同样引人注目。

例如，Conor Grennan [向 Gemini 提供了一部 300 页的小说](https://www.youtube.com/watch?v=-MKGsijn5tI)，并要求它描述主要角色、找出情节转折，并识别角色感受特定情绪的例子。Gemini 在整部书的范围内发展细致的论点毫无困难。YouTube 上流行的 [Fireship 频道](https://www.youtube.com/c/fireship) 的创作者 Jeff Delaney 向 Gemini 提供了一个包含数千个文件的完整代码库，并要求它添加新功能。Gemini 不仅写出了正确的代码，还遵循了现有项目的风格，使用了已经建立的组件、库和约定。其他演示展示了 Gemini 识别应用程序中的问题、提取关键示例并编写 API 文档。

如果你想要其他内容来填充 Gemini 巨大的上下文窗口，还有另一个新功能——视频。视频的标记方式与文字不同，占用的空间要大得多。但即便如此，1 百万标记的上下文窗口可以容纳大约一个小时的视频——足够浏览一部电影并回答有关其内容的复杂问题。这就是谷歌所做的，当它要求 Gemini [查找具体细节](https://www.youtube.com/watch?v=wa0MT8OwHuk) 在一部巴斯特·基顿的电影中，比如在他们未识别的一个场景中，纸片上写的字。

## 未来的LLM

大上下文窗口是未来的方向吗？到目前为止，普遍的看法是，大上下文窗口充其量只是一个部分解决方案。我们担心它们在计算时间上会过于昂贵。[一项研究](https://www.voiceflow.com/blog/the-context-window-paradox-why-bigger-might-not-be-better)发现，LLM在长上下文窗口中找到信息的能力并不好，反而在细节出现在开头或结尾时表现更佳。所有这些因素支持了同样的结论：将你的内容强行塞入上下文窗口是天真的且成本高昂的。将所有数据一次性发送请求绝不是与LLM对话的正确方式。

现在，未来似乎突然发生了变化。大上下文窗口即将来临，它们可能使LLM对广泛知识集有更强大、整体的理解。去年用文本无法完成的任务现在即将在*视频*中变得可能。而谷歌研究正在尝试一种扩展上下文窗口到惊人的1000万标记的Gemini变体。

两个事实是明确的。首先，在LLM战争中选择赢家是一场愚蠢的游戏。其次，变化的速度没有放缓——反而在加速。


