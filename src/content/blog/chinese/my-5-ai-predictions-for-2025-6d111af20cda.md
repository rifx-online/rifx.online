---
title: "我对 2025 年人工智能的五大预测"
meta_title: "我对 2025 年人工智能的五大预测"
description: "文章对2025年的人工智能（AI）发展进行了五个主要预测，包括自驾机器人出租车的普及、行业特定AI的崛起、AI可靠性的提高、扩展的局限性以及AI代理的广泛应用。同时，作者指出一些不会发生的情况，如通用人工智能（AGI）的出现、AI意识的产生和AI对人类的威胁。文章强调需要在对AI的乐观与悲观之间找到平衡，并关注技术的实际进展与应用。"
date: 2024-12-26T01:15:04Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*ty3_l3TVtv7QPd5N"
categories: ["Autonomous Systems", "Chatbots", "Predictive Analytics"]
author: "Rifx.Online"
tags: ["robotaxis", "chatbots", "reliability", "agents", "consciousness"]
draft: False

---



以及一些非预测



正确预测未来是具有挑战性的。

问一下——以一个广为人知的流行文化偶像为例——汉娜和巴贝拉，杰森一家（The Jetsons）的创作者，他们想象了一个有飞行汽车和机器人女佣的未来，但没有想到互联网或智能手机会出现在我们的未来。

特别是在AI领域，许多失败的过于乐观的预测也导致了失望，最终出现了所谓的“AI寒冬”，即AI资金枯竭的时期。整个领域从公众视野中退回到不为人知的研究实验室，少数人顽强地日复一日继续我们的研究（是的，我是在其中一个寒冬期间开始从事AI工作的）。

例如，80年代由[道格·莱纳特](https://en.wikipedia.org/wiki/Douglas_Lenat)领导的“万象百科全书”（[Cyc项目](https://en.wikipedia.org/wiki/Cyc)）惨遭失败。日本的“[第五代计算](https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Systems)”基于逻辑也同样失败。还有[专家系统](https://www.britannica.com/technology/expert-system)，在初期成功后，最终被彻底遗忘。还有我进行博士研究的整个子领域“[程序合成](https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm)”，这仍然让我感到痛心。

当时所有这些项目看起来都很有前途。

这使得一些不再年轻的人在每次看到有前景的技术时都在问自己，这项技术是否能够在长期内坚持下来，或者在初期炒作消失后像泡沫一样破裂。

然而，我们也可能在光谱的另一端出错；我们未能认识到某项技术是合法的，并且确实会对世界产生重大影响。例如，大多数人在1983年第一天互联网的出现时感到意外，甚至更多的是它改变生活的影响。

因此，我们需要在过于乐观和过于悲观之间找到平衡，并在可能的情况下，有证据支持我们的立场。

为了对以下预测有客观证据，我将避免预测任何完全新的事物（例如，我希望我的[“无声声音”发明](https://readmedium.com/i-invented-a-way-to-speak-to-an-ai-keeping-your-privacy-ddbca5f24e4a?sk=d944e6fd6036602e691e5f471ae20530)能成为热门，但这不太可能发生）。

这意味着，从某种意义上说，我预测的一切在某种胚胎形式中已经存在，并将只会成为主流。大多数技术从基础研究到主流商业化大约需要15年，或多或少。

在开始列举之前的最后一点是，我只会考虑趋势和技术，而不是产品，也不是原则或发现。技术是一组工具和方法，通过应用知识和创新来解决一个大问题，因此它比趋势更具体。

现在，废话不多说，让我们来看看将使2025年成为AI值得纪念的一年趋势和技术。我将按影响力递增的顺序呈现它们。

## 5\. 自驾机器人出租车成为主流

在经历了2023-2024年非常艰难的时期后，当时大多数自驾公司因[致命事故](https://www.cnbc.com/2023/10/26/cruise-pauses-all-driverless-operations-after-collisions-suspensions.html)和[撞倒行人](https://www.nbcnews.com/tech/tech-news/driver-hits-pedestrian-pushing-path-self-driving-car-san-francisco-rcna118603)而关闭，现在显然，Alphabet的[Waymo](https://waymo.com/)已经达到了一个可靠性水平，使其机器人出租车成为一个受欢迎的选择。最初在旧金山作为公共测试版推出，现在它在凤凰城、洛杉矶广泛提供，并很快将在奥斯丁和迈阿密推出，使其成为一个国家级的选择，市场份额快速增长。

我对这个显然成功的自驾服务有两个问题。

首先，我们不知道他们自驾算法的内部机制；这些都是专有和秘密的。如果没有其他人看到它是如何工作的，我们怎么能“信任”这一服务呢？我们只能依赖Waymo机器人出租车的过往记录，目前看起来非常好。但如果（上天保佑）下周发生一起严重的致命事故呢？在那种情况下——希望不会发生——信任将会在一夜之间崩溃。

第二个问题是Waymo的汽车太贵了，每辆大约需要$150,000（它们是加装了昂贵设备的捷豹I-PACE，不包括研发费用）。因此，除非Waymo找到一种方法来大规模生产更便宜的车型，否则这将无法盈利。

无论如何，自驾车现在接近成为主流，甚至变得无聊。在2025年，机器人出租车将成为每个居住在大城市的人的选择……

## 4\. 行业特定的人工智能将胜过通用聊天机器人

我记得一年前，当许多人工智能爱好者每天都在寻找 ChatGPT 的用例，比如成为语言老师、创作搞笑诗歌、角色扮演以准备面试、生成商业创意、策划活动等。

尽管其中一些以提示为导向的应用可能很有趣，比如搞笑诗歌，但在大多数其他情况下，通用聊天机器人会因为几个原因而显得不足：

* 它缺乏特定用例的训练数据，
* 它无法访问可以操作的应用程序。

对于大多数现实世界中的非休闲应用，我们需要能够出色解决特定客户问题的专业软件。

以文本写作纠正为例。如果我们将 ChatGPT 与像 [Grammarly](https://www.grammarly.com/) 这样的嵌入式专业应用进行比较（我与它没有任何关联），我们可以看到与 ChatGPT 之间的巨大差异：

* Grammarly 可以在 Microsoft Word 或 Google Docs 中运行（就像我现在所做的那样），而不是复制粘贴到 ChatGPT 再返回。
* Grammarly 会在您文本中所做的每个更改下划线，以便您可以准确看到它在做什么。
* 在纠正我的写作方面，Grammarly 对我来说似乎比 ChatGPT 更好。

这只是一个例子，但我认为 2025 年将是专业人工智能应用如雨后春笋般涌现的一年。它们已经开始出现，正如我们在以下例子中所看到的：

* [OpenSpace](https://www.openspace.ai/) 是一个用于捕捉和分析建筑工地图像以监控进度和合规性的工具。
* 我发现了一些在客户服务领域的新人工智能产品，它们在方法上有所不同。虽然 [Ada](https://www.ada.cx/) 是一个面向客户的问答机器人，但 [Forethought](https://forethought.ai/) 帮助代理快速找到答案并更快地解决工单。
* [Luminar Neo](https://skylum.com/luminar?srsltid=AfmBOoo4GJH0yoyhQDLS9tBXXL_X-NIR9Mr4kzZik6jhHRDcolcY-VHf) 用于图像编辑，如天空替换、自动重光、背景去除和皮肤修饰，适合需要快速但专业编辑的摄影师和创意人士（当然，Adobe Photoshop 在这里是一个竞争对手）。
* [Runway](https://runwayml.com/) 是视频生成、背景去除、物体跟踪和帧插值的领导者。

这个列表每天都在增长，应用领域从医疗诊断到文学。我们只能期待这一趋势在 2025 年得到巩固。

## 3\. 更高的可靠性带来信任

2024年在大型语言模型（LLMs）的技术方面取得了显著进展，这些进展显然与可靠性无关，例如上下文窗口的大小（所有作为输入提供给聊天机器人的信息，包括提示以及其他额外信息）。但是，当上下文窗口用于提供包含可靠事实的“基础”信息时，可靠性可以（实际上是）大大提高。像RAG（[检索增强生成](https://cloud.google.com/use-cases/retrieval-augmented-generation)）的方法系统化了这种方法，将“基础”信息视为“[知识图谱](https://www.ibm.com/topics/knowledge-graph#:~:text=A%20knowledge%20graph%2C%20also%20known,illustrates%20the%20relationship%20between%20them.)”（经过整理的事实信息库，例如谷歌构建的庞大知识图谱）或仅仅是进行网络搜索，以在回答提示之前收集互联网上可以找到的主要事实。

其他近期的人工智能进展可能并不震撼，但在一定程度上有助于提高人工智能系统的可靠性。这些包括[模型蒸馏](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.)（将复杂模型简化为更小的模型）、数据质量改进技术（垃圾进垃圾出，因此提高训练数据的质量转化为更好的可靠性）、[数据增强](https://www.datacamp.com/tutorial/complete-guide-data-augmentation)（用于生成合成数据）和[对抗训练](https://datascientest.com/en/adversarial-training-what-you-didnt-know-yet)（让模型接触到精心设计的输入，以误导它们）。

Sundar Pichai 宣布在2025年，“重点将放在提高人工智能模型的推理能力和可靠性上。”

可靠性的提高将导致信任：一旦你看到一个人工智能系统连续100次给出正确答案，你就倾向于将第101次的回答视为可信。问题是，尽管人工智能的可靠性将显著提高，但在可预见的未来，它不会是完全的保证。这可能导致缺乏人工检查，最终造成代价高昂的错误。

我们都听说过一个律师的故事，在ChatGPT的早期阶段，他急于准备涉及Avianca航空公司的审判文件。问题是，ChatGPT提到的所有之前的审判案例都是完全虚构的，这一点被法官发现，使得律师瞬间成名（以一种糟糕的方式）。

## 2\. 纯粹的扩展已经完成

谷歌首席执行官：人工智能的发展终于放缓——“低垂的果实已经摘完”，谷歌首席执行官在《纽约时报》DealBook峰会上说道。

是的，互联网上可用的数据大部分已经被利用，没有“其他互联网”可以使用。因此，主要通过增大参数和输入数据来提升生成式AI系统的方式，已不再是推动进一步AI进步的关键。

此外，皮查伊表示，“山更陡峭”，并且“进步需要更深层次的突破”来应对更复杂的挑战。

我们必须接受，单纯的扩展已不再是提升生成式AI系统的有效方法。

但一些“专家”（如加里·马库斯）将这一观点推向极端，认为人工智能已经“碰壁”，在此之后不可能有进一步的进展。我认为马库斯是错的，因为他低估了（或忽视了？）全球研究实验室始终提出的小算法改进的价值。

我完全同意皮查伊的观点：山更陡峭，但人工智能将继续实现渐进式进步，而不再依赖于扩展。

## 1\. AI代理将无处不在

“AI代理”和“代理AI”这两个术语现在被过度使用。当我发现到处都是炒作时，我的警觉性会被激发，让我对整个事情产生怀疑。

但在智能代理的情况下，我是在熟悉的领域：我在大学教授“多代理系统”课程已经超过十年。对我来说，代理不仅仅是市场营销人员展示的下一个亮眼事物。

代理系统有两种类型：个人助手和多代理系统。后者涉及多个代理相互沟通并合作或竞争，但我认为这与2025无关，因此我将重点放在个人代理上。

个人代理并不新鲜。在1995年，[尼古拉斯·尼葛洛庞帝](https://en.wikipedia.org/wiki/Nicholas_Negroponte)出版了《数字化生存》一书，提出了替代人们一直以来与计算机工作的方式。他称“点按”是旧的范式，在这种范式中，用户选择屏幕上的某个内容并采取行动（等等！难道我们现在还不是这样使用计算机吗？）。

尼葛洛庞帝提出使用一种新的范式，称为“委托”，即人类用户将高级任务交给助手来负责。例如，用户可以指示助手“接听每一个电话，并说我在中午之前无法接听，除非是我母亲——那时你可以把电话转给我。”

不错吧？

在1995年，技术距离实现这个愿景还相去甚远，因此尼葛洛庞帝的委托提议等待着更好的时机。在此之前的几年，1987年，苹果公司在当时备受厌恶的约翰·斯库利领导下制作了一段视频，展示了个人助手的未来概念。

视频《知识导航员》描绘了一位教授与一位穿着蝴蝶结的不可思议助手的口头互动。这个管家能够接听电话和留言，结合多个信息来源，并制作摘要和图表，所有这些都是教授委托的任务。

知识导航员的一些方面已经实现，例如口头互动、信息组合以及制作摘要和图表，但有些方面尚未实现，例如长时间处理电话、根据不同人提供消息等。

那么问题是：到2025年，个人代理将有多少成为现实？我认为以下几点将会出现：

* 能够灵活进行口头互动的AI：在这一领域取得了令人难以置信的进展，一些[OpenAI的高级语音模式](https://help.openai.com/en/articles/8400625-voice-mode-faq)听起来甚至比我认识的几个人还要人性化。这可以被视为已实现。
* 能够采取行动的AI：“行动”可以是非常简单的事情，比如设置闹钟，这在像[Apple Intelligence](https://www.apple.com/apple-intelligence/)这样的平台上部分实现，因为苹果拥有整个平台，因此他们可以更好地利用所有应用程序，尤其是他们自己开发的应用程序，如时钟。但我还没有在Apple Intelligence中看到像“*当我妻子打电话给我时，等15分钟，然后打电话给她母亲，邀请她周日参加聚会。如果她不接电话，就继续拨打，直到她接听*”这样的功能。
* 处理与人类用户账户相关的信息的网络表单和应用程序的咨询、注册、修改和删除。例如，AI应该能够完全购买音乐会门票，正确填写所有表单字段，甚至在操作完成之前使用用户的凭证。也许可以要求人类确认最终的“购买”按钮。我已经看到这种系统的原型正在被打磨，例如谷歌的“[Project Mariner](https://deepmind.google/technologies/project-mariner/)”、OpenAI的“[AutoGPT](https://en.wikipedia.org/wiki/AutoGPT)”、Hugging Face的“[HuggingGPT](https://arxiv.org/abs/2303.17580)”、微软的[Copilot](https://support.microsoft.com/en-us/topic/introducing-copilot-agents-943e563d-602d-40fa-bdd1-dbc83f582466)和Anthropic的“[计算机使用](https://docs.anthropic.com/en/docs/build-with-claude/computer-use)”。正是这些原型的丰富性让我相信这即将成为主流。

相信我，代理将在2025年无处不在！

但不要指望在2025年就会有完善的代理应用；2025年将是“代理爆炸”的一年，但大多数产品将处于测试阶段，甚至更糟，就像[寒武纪大爆发](https://evolution.berkeley.edu/the-cambrian-explosion/)一样，其中大多数将会消亡。

## 荣誉提名

这些趋势或技术接近进入主列表，但并不特定于2025年。我会包括：

* Edge AI 和设备内智能
* 节能型 AI 模型，AI 可持续性
* AI 监管以减轻威胁

## 非预测

现在，我将关注我认为不会发生的其他人的预测。在某些情况下，它们只是幻想；在其他情况下，它们是过于乐观的想法；在其他情况下，这主要是出于恐惧。

## 我们在2025年不会有类似AGI（通用人工智能）的东西

耸人听闻的[YouTube视频](https://www.youtube.com/watch?v=awCnd0mDvTM)甚至一些AI专家声称“AGI就在眼前！”萨姆·阿尔特曼给出了“1000天”的时间表，而埃隆·马斯克则认为AGI更近（尽管考虑到他在承诺方面的记录，这并没有太多信息价值）。

但事实是，我上面提到的问题（可靠性、推理、产品开发、现实世界中的自动驾驶）远比AGI更为紧迫。

我们也可以看到关于AGI的目标不断被调整：我最近读到AGI是“可以在多个领域使用的AI。”抱歉，这并不是与AGI相同的“多功能AI”。

一旦到来，AGI从经济角度来看将是一个大事件，因为它不需要为每个新领域进行训练。AGI的泛化能力将使其能够适应以前未见过的情况，使其几乎可以立即应用，这比为每个领域训练AI便宜得多。

在我看来，AGI甚至不会出现在2026年的预测中……

## AI 不会在 2025 年变得有意识

一些 AI 爱好者假装，由于 AI 发展如此迅速，下一步是让它“有意识”。他们被误导的原因如下：

首先，AI 不是关于意识，而是关于推理相关的认知能力。它甚至不旨在创造有知觉的生物。

然而，主要论点是，在 AI 历史上开发的各种方法和技术中，没有一种与意识相关。从智能搜索和 alpha-beta 剪枝到专家系统，再到分类或回归，完全没有与意识相关的内容。

坦率地说，我认为大多数期待有意识 AI 的人误解了生成式 AI 有时富有表现力——甚至情感化的——散文，把它视为“接近意识”，但实际上并非如此。那里根本“没有灵魂”。

## AI不会在2025年消灭我们

最终，AI不会在类似《终结者》的末日中接管一切！

在2023年初，关于AI失控的恐惧充斥着各个角落，但在几次[签署的呼吁](https://readmedium.com/why-i-signed-the-pause-giant-ai-experiments-petition-e9711f672d18?sk=7bc497782d2cf474d970768632d9222c)要求在为时已晚之前停止AI开发后，2023年过去了，2024年几乎也是如此，而现在那些呼声听起来像是伊索寓言中的“喊狼来了的小男孩”。

也许我的预测是，在2025年，几乎没有人会呼吁在AI变得有意识并失控之前停止它。关于AI的更紧迫问题，比如它对劳动市场的影响、偏见的缓解、用于AI训练的人类工作的报酬以及限制误用（如政治虚假信息）等问题，最终将被认真对待。

你看到了。你对AI的预测是什么？请在评论中发表！

— *通过我的免费通讯“The Skeptic AI Enthusiast”订阅我精心策划的AI新闻见解和技术解释。从一位AI老兵的角度获得对当今科技格局的批判性看法，网址为<https://rafebrena.substack.com/>.*

