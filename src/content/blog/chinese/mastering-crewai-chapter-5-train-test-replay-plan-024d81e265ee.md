---
title: "æŒæ¡ CrewAIï¼šç¬¬ 5 ç« --è®­ç»ƒã€æµ‹è¯•ã€å›æ”¾å’Œè®¡åˆ’ | ä½œè€…ï¼šOkan YenigÃ¼n | 2025å¹´1æœˆ | äººå·¥æ™ºèƒ½æµ…æ"
meta_title: "æŒæ¡ CrewAIï¼šç¬¬ 5 ç« --è®­ç»ƒã€æµ‹è¯•ã€å›æ”¾å’Œè®¡åˆ’ | ä½œè€…ï¼šOkan YenigÃ¼n | 2025å¹´1æœˆ | äººå·¥æ™ºèƒ½æµ…æ"
description: "æœ¬ç« ä»‹ç»äº†CrewAIçš„è®­ç»ƒã€æµ‹è¯•ã€é‡æ”¾å’Œè®¡åˆ’åŠŸèƒ½ã€‚è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨äººæœºåä½œï¼Œåˆ©ç”¨åé¦ˆä¸æ–­ä¼˜åŒ–ç»“æœï¼Œå¹¶å°†æ‰€æœ‰å…ƒæ•°æ®å­˜å‚¨åœ¨pickleæ–‡ä»¶ä¸­ã€‚æµ‹è¯•é˜¶æ®µä½¿ç”¨LLMè¯„ä¼°ä»»åŠ¡æ€§èƒ½ï¼Œè€Œé‡æ”¾åŠŸèƒ½å…è®¸ç”¨æˆ·ä»æœ€è¿‘çš„å›¢é˜Ÿå¯åŠ¨ä¸­é‡è¯•ç‰¹å®šä»»åŠ¡ã€‚è®¡åˆ’åŠŸèƒ½åˆ™é€šè¿‡AgentPlanneråœ¨æ¯æ¬¡è¿­ä»£å‰åˆ›å»ºä»»åŠ¡è®¡åˆ’ï¼Œç¡®ä¿ä»»åŠ¡æ‰§è¡Œçš„ç³»ç»Ÿæ€§å’Œé«˜æ•ˆæ€§ã€‚è¿™äº›åŠŸèƒ½çš„ç»“åˆæ˜¾è‘—æå‡äº†AI LLMsçš„åº”ç”¨æ•ˆç‡å’Œè´¨é‡ã€‚"
date: 2025-01-08T23:00:24Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uIQSaKcgiUjifJtGE_Yh4g.jpeg"
categories: ["Programming", "Machine Learning", "Data Science"]
author: "Rifx.Online"
tags: ["training", "testing", "replay", "planning", "feedback"]
draft: False

---



### è®­ç»ƒã€æµ‹è¯•ã€é‡æ”¾ä¸è®¡åˆ’



åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨CrewAIçš„è®­ç»ƒã€æµ‹è¯•ã€é‡æ”¾å’Œè®¡åˆ’åŠŸèƒ½ã€‚

ä¸Šä¸€ç« ï¼š

è®©æˆ‘ä»¬ä¸ºè¿™ç¯‡æ–‡ç« åˆ›å»ºä¸€ä¸ªæ–°é¡¹ç›®ã€‚

```python
crewai create crew train_test_example
```  
è¿™å°†åˆ›å»ºä¸€ä¸ªæ¨¡æ¿é¡¹ç›®ã€‚

### è®­ç»ƒ

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äººæœºåä½œæŠ€æœ¯ã€‚å›¢é˜Ÿç”Ÿæˆç»“æœï¼Œæˆ‘ä»¬å¯¹å…¶æä¾›åé¦ˆã€‚é€šè¿‡è¿­ä»£åé¦ˆï¼Œç»“æœéšç€æ—¶é—´çš„æ¨ç§»è€Œæ”¹å–„ã€‚ä¸æ­¤è®­ç»ƒç›¸å…³çš„æ‰€æœ‰å…ƒæ•°æ®éƒ½å­˜å‚¨åœ¨ä¸€ä¸ª pickle æ–‡ä»¶ä¸­ã€‚

åœ¨ `main.py` ä¸­ï¼Œæœ‰ä¸€ä¸ª `train` æ–¹æ³•å¤„ç†è®­ç»ƒè¿‡ç¨‹ã€‚è¯¥æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°ï¼š`n_iterations`ï¼ŒæŒ‡å®šè¿­ä»£æ¬¡æ•°ï¼Œä»¥åŠ `filename`ï¼Œå³å­˜å‚¨è®­ç»ƒæ•°æ®çš„æ–‡ä»¶åã€‚


```python
def train():
    """
    Train the crew for a given number of iterations.
    """
    inputs = {
        "topic": "AI LLMs"
    }
    try:
        TrainTestExample().crew().train(n_iterations=int(sys.argv[1]), filename=sys.argv[2], inputs=inputs)

    except Exception as e:
        raise Exception(f"An error occurred while training the crew: {e}")
```
`train` æ–¹æ³•çš„å‚æ•°å¯ä»¥æ˜¯ç¡¬ç¼–ç çš„ï¼Œä¹Ÿå¯ä»¥ä½œä¸ºå‘½ä»¤è¡Œï¼ˆCLIï¼‰å‚æ•°ä¼ é€’ã€‚


```python
 crewai train -n 2 -f train_data.pkl 
```
`-n 2` è®¾ç½® `n_iterations=2`ï¼Œè€Œ `-f train_data.pkl` æŒ‡å®š `filename=train_data.pkl`ã€‚

è¿™æ˜¯ä»£ç†çš„ç¬¬ä¸€æ¬¡è¿­ä»£è¾“å‡ºï¼š


```python
## Agent: AI LLMs Senior Data Researcher
### Task: Conduct a thorough research about AI LLMs Make sure you find any interesting and relevant information given the current year is 2024.



## Agent: AI LLMs Senior Data Researcher
### Final Answer: 
Here is a list of the most relevant information about AI LLMs as of 2024:

1. **Model Scaling**: Large Language Models (LLMs) are being further scaled, with models such as GPT-4 scaling to hundreds of billions of parameters, improving their understanding and generation of human-like text.

2. **Multimodal Capabilities**: The integration of multimodal inputs (text, images, audio, etc.) into LLMs is becoming standard, allowing AI to process and generate contextually relevant responses across various formats, exemplified by models like DALL-E and CLIP.

3. **Fine-tuning and Customization**: Organizations are increasingly adopting methods to fine-tune LLMs on specific datasets, resulting in specialized versions of models that are optimized for particular industries, such as healthcare, finance, and legal sectors.

4. **AI Ethics and Bias Mitigation**: There is a growing emphasis on addressing ethical concerns and reducing biases in LLMs, with researchers developing frameworks and auditing processes to ensure models are fair, transparent, and accountable.

5. **Energy Efficiency**: Innovations in model training and architecture, including the use of more efficient algorithms and hardware, are being actively pursued to reduce the significant energy consumption associated with training large models.

6. **AI-driven Code Generation**: Tools like Codex have revolutionized software development by enabling LLMs to assist in coding tasks, generating code snippets, suggesting optimizations, and providing documentation, thus improving productivity for developers.

7. **Conversational AI Advances**: Enhanced capabilities in conversational AI have emerged, making interactions with LLMs more natural and contextually aware, leading to improvements in customer support bots and virtual assistants.

8. **Regulatory Frameworks**: Governments and international bodies are working towards creating regulatory frameworks to govern the use of AI LLMs, focusing on safety, privacy, and ethical implications as these technologies become more prevalent.

9. **Integration into Enterprises**: Businesses are increasingly integrating LLMs into their operations, utilizing them for tasks such as content creation, data analysis, and employee training, resulting in enhanced operational efficiency and decision-making.

10. **Community Contribution and Open Models**: The rise of open-source LLM initiatives, such as EleutherAI and Hugging Faceâ€™s Transformers, has fostered a collaborative environment for researchers and developers, allowing for innovation and accessibility in AI development.

These developments highlight the rapid advancement and integration of AI LLMs into various sectors, indicating a transformative impact on technology and society in 2024.


 ## Final Result: Here is a list of the most relevant information about AI LLMs as of 2024:

1. **Model Scaling**: Large Language Models (LLMs) are being further scaled, with models such as GPT-4 scaling to hundreds of billions of parameters, improving their understanding and generation of human-like text.

2. **Multimodal Capabilities**: The integration of multimodal inputs (text, images, audio, etc.) into LLMs is becoming standard, allowing AI to process and generate contextually relevant responses across various formats, exemplified by models like DALL-E and CLIP.

3. **Fine-tuning and Customization**: Organizations are increasingly adopting methods to fine-tune LLMs on specific datasets, resulting in specialized versions of models that are optimized for particular industries, such as healthcare, finance, and legal sectors.

4. **AI Ethics and Bias Mitigation**: There is a growing emphasis on addressing ethical concerns and reducing biases in LLMs, with researchers developing frameworks and auditing processes to ensure models are fair, transparent, and accountable.

5. **Energy Efficiency**: Innovations in model training and architecture, including the use of more efficient algorithms and hardware, are being actively pursued to reduce the significant energy consumption associated with training large models.

6. **AI-driven Code Generation**: Tools like Codex have revolutionized software development by enabling LLMs to assist in coding tasks, generating code snippets, suggesting optimizations, and providing documentation, thus improving productivity for developers.

7. **Conversational AI Advances**: Enhanced capabilities in conversational AI have emerged, making interactions with LLMs more natural and contextually aware, leading to improvements in customer support bots and virtual assistants.

8. **Regulatory Frameworks**: Governments and international bodies are working towards creating regulatory frameworks to govern the use of AI LLMs, focusing on safety, privacy, and ethical implications as these technologies become more prevalent.

9. **Integration into Enterprises**: Businesses are increasingly integrating LLMs into their operations, utilizing them for tasks such as content creation, data analysis, and employee training, resulting in enhanced operational efficiency and decision-making.

10. **Community Contribution and Open Models**: The rise of open-source LLM initiatives, such as EleutherAI and Hugging Faceâ€™s Transformers, has fostered a collaborative environment for researchers and developers, allowing for innovation and accessibility in AI development.

These developments highlight the rapid advancement and integration of AI LLMs into various sectors, indicating a transformative impact on technology and society in 2024.
```
åœ¨ä»£ç†ç”Ÿæˆç»“æœåï¼Œå®ƒè¯·æ±‚æˆ‘ä»¬çš„åé¦ˆï¼š


```python
=====
### Please provide feedback on the Final Result and the Agent's actions. Respond with 'looks good' or a similar phrase when you're satisfied.
=====
```
è¿™æ˜¯æˆ‘çš„åé¦ˆï¼š


```python
Use only two source and give 2 highlights only at the end.
```
ç°åœ¨ï¼Œåœ¨ç¬¬äºŒæ¬¡è¿­ä»£ä¸­ï¼Œä»£ç†å·²ç»æ”¹è¿›å¹¶ä½¿ç”¨äº† 2 ä¸ªé¡¹ç›®ã€‚


```python
Human feedback:  Use only two source and give 2 highlights only at the end.

## Agent: AI LLMs Senior Data Researcher
### Final Answer: 
Here is a list of the most relevant information about AI LLMs as of 2024, based on two selected sources:

1. **Model Scaling**: LLMs are being further enhanced with massive scaling, reaching up to trillions of parameters, resulting in improved context understanding and more nuanced responses. (Source: OpenAI Blog)

2. **Ethical Considerations**: There is increasing focus on ethical AI developments regarding bias reduction and transparency in LLM deployment, pushing organizations to adopt responsible AI principles. (Source: AI Ethics Journal)

**Highlights**:
- LLMs continue to grow in complexity, reaching unprecedented parameter sizes that allow for deeper contextual comprehension.
- Ethical guidelines are being actively developed to ensure LLMs are deployed responsibly, addressing bias and fostering transparency.


 ## Final Result: Here is a list of the most relevant information about AI LLMs as of 2024, based on two selected sources:

1. **Model Scaling**: LLMs are being further enhanced with massive scaling, reaching up to trillions of parameters, resulting in improved context understanding and more nuanced responses. (Source: OpenAI Blog)

2. **Ethical Considerations**: There is increasing focus on ethical AI developments regarding bias reduction and transparency in LLM deployment, pushing organizations to adopt responsible AI principles. (Source: AI Ethics Journal)

**Highlights**:
- LLMs continue to grow in complexity, reaching unprecedented parameter sizes that allow for deeper contextual comprehension.
- Ethical guidelines are being actively developed to ensure LLMs are deployed responsibly, addressing bias and fostering transparency.

=====
### Please provide feedback on the Final Result and the Agent's actions. Respond with 'looks good' or a similar phrase when you're satisfied.
=====
```
è¯¥è¿‡ç¨‹ä¼šæŒç»­è¿­ä»£ï¼Œç›´åˆ°æˆ‘ä»¬å†³å®šåœæ­¢ã€‚æ‰€æœ‰è¿™äº›è¿­ä»£çš„å…ƒæ•°æ®éƒ½å­˜å‚¨åœ¨ pickle æ–‡ä»¶ä¸­ã€‚

### æµ‹è¯•

åœ¨æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ LLM æ¥è¯„ä¼°ä»»åŠ¡æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼ŒLLM ç”¨äºåœ¨å¤šä¸ªè¿­ä»£åè¯„ä¼°ä»£ç†çš„è¾“å‡ºã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä½¿ç”¨åŸºäºæç¤ºçš„è¯„ä¼°æŠ€æœ¯ï¼Œä½†ä¹Ÿå¯ä»¥é€šè¿‡ RAGAS æˆ–å…¶ä»–æŠ€æœ¯è¿›è¡Œè‡ªå®šä¹‰ã€‚

åœ¨ `main.py` æ–‡ä»¶ä¸­ï¼Œæœ‰ä¸€ä¸ª `test` å‡½æ•°å¤„ç†æµ‹è¯•è¿‡ç¨‹ã€‚

```python
def test():
    """
    Test the crew execution and returns the results.
    """
    inputs = {
        "topic": "AI LLMs"
    }
    try:
        TrainTestExample().crew().test(n_iterations=int(sys.argv[1]), openai_model_name=sys.argv[2], inputs=inputs)

    except Exception as e:
        raise Exception(f"An error occurred while replaying the crew: {e}")
```
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæµ‹è¯•ï¼š

```python
crewai test
```
ç»è¿‡å¤šæ¬¡è¿­ä»£åï¼Œæˆ‘ä»¬çœ‹åˆ°ä¸€ä¸ªä»»åŠ¡å¾—åˆ†è¡¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BrQ3WeAx7J09_0KJIoJTEA.png)

### é‡æ”¾

CrewAI å…è®¸æ‚¨ä»æœ€è¿‘çš„å›¢é˜Ÿå¯åŠ¨ä¸­é‡æ”¾ä»»åŠ¡ã€‚æ­¤åŠŸèƒ½å°¤å…¶æœ‰ç”¨ï¼Œå¦‚æœæ‚¨å·²å®Œæˆå¯åŠ¨ä½†æƒ³è¦é‡è¯•ç‰¹å®šä»»åŠ¡æˆ–é¿å…é‡æ–°è·å–æ•°æ®ã€‚ç”±äºä»£ç†å·²ç»ä¿ç•™äº†å¯åŠ¨æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ï¼Œæ‚¨å¯ä»¥ç®€å•åœ°é‡æ”¾æ‰€éœ€çš„ä»»åŠ¡ã€‚

`main.py` æ–‡ä»¶ä¸­çš„ `replay` å‡½æ•°ç®¡ç†æ­¤è¿‡ç¨‹ã€‚

```python
def replay():
    """
    Replay the crew execution from a specific task.
    """
    try:
        TrainTestExample().crew().replay(task_id=sys.argv[1])

    except Exception as e:
        raise Exception(f"An error occurred while replaying the crew: {e}")
```
è¦æŸ¥çœ‹æœ€æ–°å¯åŠ¨çš„ä»»åŠ¡ IDï¼Œè¯·ä½¿ç”¨ï¼š

```python
crewai log-tasks-outputs
```
æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ä»»åŠ¡åŠå…¶å¯¹åº”çš„ä»»åŠ¡ IDã€‚

```python
Task 1: 8d1fd0fa-3e6d-4d48-b919-d2a1c6474efc
Description: A list with 10 bullet points of the most relevant information about AI LLMs

------
Task 2: 115acd30-7142-4e8e-841b-cf8dda38400b
Description: A fully fledge reports with the mains topics, each with a full section of information. Formatted as markdown without '```'
```
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»åŠ¡ 2 çš„ä»»åŠ¡ ID ä½œä¸ºæ£€æŸ¥ç‚¹ï¼Œè€Œä¸æ˜¯è¿è¡Œæ•´ä¸ªå›¢é˜Ÿï¼Œä»é‚£é‡Œå¼€å§‹å›¢é˜Ÿã€‚

```python
crewai replay -t 115acd30-7142-4e8e-841b-cf8dda38400b
```
è¾“å‡ºï¼š

```python

## ä»£ç†ï¼šAI LLMs æŠ¥å‘Šåˆ†æå¸ˆ

### ä»»åŠ¡ï¼šå®¡æŸ¥æ‚¨è·å¾—çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶å°†æ¯ä¸ªä¸»é¢˜æ‰©å±•ä¸ºæŠ¥å‘Šçš„å®Œæ•´éƒ¨åˆ†ã€‚ç¡®ä¿æŠ¥å‘Šè¯¦ç»†ä¸”åŒ…å«æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

## ä»£ç†ï¼šAI LLMs æŠ¥å‘Šåˆ†æå¸ˆ

### æœ€ç»ˆç­”æ¡ˆï¼š

## å…³äºäººå·¥æ™ºèƒ½å¤§è¯­è¨€æ¨¡å‹è¿‘æœŸå‘å±•çš„ç»¼åˆæŠ¥å‘Š

### Transformers Advancements
æœ€è¿‘åœ¨å˜å‹å™¨æ¶æ„æ–¹é¢çš„è¿›å±•æ˜¾è‘—æé«˜äº†å®ƒä»¬çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚å…³é”®ç ”ç©¶äººå‘˜ä¸“æ³¨äºåŠ¨æ€å’Œè‡ªé€‚åº”è®¡ç®—ç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥æ ¹æ®è¾“å…¥æ•°æ®çš„å¤æ‚æ€§è°ƒæ•´æ¨¡å‹çš„æ“ä½œã€‚è¿™äº›ç­–ç•¥ä½¿æ¨¡å‹èƒ½å¤Ÿæ™ºèƒ½åœ°åˆ†é…è®¡ç®—èµ„æºï¼Œå‡å°‘ä¸å¿…è¦çš„å¼€é”€ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æé«˜æ•´ä½“å‡†ç¡®æ€§ã€‚å±‚å½’ä¸€åŒ–æ–¹æ³•å’Œæ³¨æ„åŠ›æœºåˆ¶çš„æŒç»­åˆ›æ–°ä¹Ÿå¢å¼ºäº†è¿™äº›æ¶æ„çš„ç¨³å¥æ€§ï¼Œä½¿å…¶æ›´å¥½åœ°å¤„ç†æ•°æ®ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚å› æ­¤ï¼Œè¿™äº›å‘å±•ä½¿å¾—äººå·¥æ™ºèƒ½å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§åº”ç”¨ä¸­æä¾›æ›´å¿«çš„å“åº”å’Œæ›´å¥½çš„ä¸Šä¸‹æ–‡ç†è§£ã€‚

### å¤šæ¨¡æ€èƒ½åŠ›
AI LLMs æ­£åœ¨è¶Šæ¥è¶Šå¤šåœ°ä½“ç°å¤šæ¨¡æ€èƒ½åŠ›ï¼Œä¿ƒè¿›æ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘çš„æ•´åˆï¼Œä»¥å®ç°æ›´å…¨é¢çš„å¤„ç†æ–¹æ³•ã€‚åƒ GPT-4 å’Œ CLIP è¿™æ ·çš„æ¨¡å‹ exemplify è¿™ä¸€è¶‹åŠ¿ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿåœ¨ä¸åŒåª’ä½“ä¹‹é—´æå–æ„ä¹‰å’Œç”Ÿæˆå†…å®¹ã€‚è¿™ç§æ•´åˆå…è®¸æ›´ä¸°å¯Œå’Œæ›´ç»†è‡´çš„äº’åŠ¨ï¼Œæ”¹å–„ AI ç³»ç»Ÿå¯¹ä¸Šä¸‹æ–‡çš„ç†è§£å¹¶æå‡ç”¨æˆ·å‚ä¸åº¦ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥æ¶‰åŠè§†è§‰å’Œæ–‡æœ¬å…ƒç´ çš„æŸ¥è¯¢ï¼Œä¿ƒä½¿æ¨¡å‹ä»¥è€ƒè™‘è¾“å…¥æ¨¡æ€å…¨è°±çš„æ–¹å¼ä½œå‡ºå“åº”ï¼Œä»è€Œå¢å¼ºç”Ÿæˆå“åº”çš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ã€‚

### é«˜æ•ˆçš„å¾®è°ƒæŠ€æœ¯
æœ€è¿‘åœ¨æ¨¡å‹å¾®è°ƒæ–¹é¢çš„æˆåŠŸå®è·µå¼ºè°ƒäº†æ•ˆç‡å’Œèµ„æºç®¡ç†ã€‚åƒä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å’Œæç¤ºå¾®è°ƒè¿™æ ·çš„æŠ€æœ¯å·²æˆä¸ºæµè¡Œçš„æ–¹æ³•è®ºï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿä»¥é€šå¸¸æ‰€éœ€è®¡ç®—å¼€é”€çš„ä¸€å°éƒ¨åˆ†æ¥è°ƒæ•´å¤§å‹æ¨¡å‹ä»¥é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚LoRAä¸“æ³¨äºå¼•å…¥ä½ç§©çŸ©é˜µæ¥ä¿®æ”¹å˜æ¢å™¨å‚æ•°ï¼Œä»è€Œåœ¨ä¸å¦¥åæ€§èƒ½çš„æƒ…å†µä¸‹èŠ‚çœæ¨¡å‹å¤§å°ã€‚åŒæ ·ï¼Œæç¤ºå¾®è°ƒåˆ©ç”¨ç‰¹å®šä»»åŠ¡çš„æç¤ºæ¥å¼•å¯¼æ¨¡å‹è¾“å‡ºï¼Œæ‰€éœ€çš„è®­ç»ƒæ•°æ®æå°‘ã€‚è¿™äº›è¿›å±•æœ‰æœ›é™ä½ç»„ç»‡åœ¨å°†AI LLMsè°ƒæ•´åˆ°å…¶ç‹¬ç‰¹éœ€æ±‚æ—¶çš„éšœç¢ï¼Œä¿ƒè¿›å„ä¸ªè¡Œä¸šçš„æ›´å¿«é‡‡ç”¨ã€‚

### ä¼¦ç†ä¸å®‰å…¨
å›´ç»•äººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¼¦ç†è€ƒè™‘å·²è¾¾åˆ°å…³é”®ç‚¹ï¼Œä¿ƒä½¿ç»„ç»‡åœ¨è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½æ¡†æ¶ä¸Šè¿›è¡Œå¤§é‡æŠ•èµ„ã€‚å½“å‰æ­£åœ¨ç§¯æè®¨è®ºï¼Œä»¥è§£å†³è®­ç»ƒæ•°æ®ä¸­æ™®éå­˜åœ¨çš„åè§åŠäººå·¥æ™ºèƒ½å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºæ‰€å¸¦æ¥çš„é—®é¢˜ã€‚å„æœºæ„é‡‡å–ä¸»åŠ¨æªæ–½ï¼Œé€šè¿‡å»ºç«‹å¥å…¨çš„å®‰å…¨æªæ–½å’Œä¸æ–­å®Œå–„ä¼¦ç†æŒ‡å—æ¥é™ä½è¿™äº›é£é™©ã€‚å€¡è®®åŒ…æ‹¬åè§æ£€æµ‹ç ”ç©¶ã€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„é€æ˜åº¦ä»¥åŠç”¨æˆ·åé¦ˆæœºåˆ¶ï¼Œä»¥æ„å»ºä¸€ä¸ªæ›´åŠ å…¬å¹³å’Œå®‰å…¨çš„äººå·¥æ™ºèƒ½ç¯å¢ƒã€‚è¿™ä¸ªä¸æ–­å‘å±•çš„æ¡†æ¶æ—¨åœ¨ç¡®ä¿äººå·¥æ™ºèƒ½æŠ€æœ¯æƒ åŠç¤¾ä¼šï¼ŒåŒæ—¶å°½é‡å‡å°‘æ½œåœ¨çš„å±å®³ã€‚

### OpenAI API æ‰©å±•
OpenAI åœ¨æ‰©å±•å…¶ API äº§å“ä»¥æ”¯æŒå¤šæ ·åŒ–çš„ä¸šåŠ¡éœ€æ±‚æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚é€šè¿‡é›†æˆå¯å®šåˆ¶é€‰é¡¹ï¼Œå¼€å‘è€…ç°åœ¨å¯ä»¥æ›´è½»æ¾åœ°è®¿é—®é«˜çº§åŠŸèƒ½å’Œèƒ½åŠ›ï¼Œå¦‚é‡èº«å®šåˆ¶çš„æ¨¡å‹è¾“å‡ºå’Œçµæ´»çš„æŸ¥è¯¢å¤„ç†ã€‚è¿™ä¸€æ‰©å±•ä½¿ä¼ä¸šèƒ½å¤Ÿé€šè¿‡å°†æœ€å…ˆè¿›çš„ AI åŠŸèƒ½åµŒå…¥å…¶åº”ç”¨ç¨‹åºä¸­æ¥æå‡ç”¨æˆ·ä½“éªŒï¼Œä»è€Œä¿ƒè¿›å„è¡Œä¸šçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚éšç€è¶Šæ¥è¶Šå¤šçš„ç»„ç»‡é‡‡ç”¨è¿™äº›å·¥å…·ï¼Œå®ƒä»¬ä¸ä»…ç®€åŒ–äº†æ“ä½œå·¥ä½œæµç¨‹ï¼Œè¿˜é€šè¿‡ä¸°å¯Œçš„ä¸ AI ç³»ç»Ÿçš„äº’åŠ¨æ¥å¢å¼ºç”¨æˆ·ä½“éªŒã€‚

### Few-Shot å’Œ Zero-Shot å­¦ä¹ 
AI LLM åœ¨å°‘é‡æ ·æœ¬å­¦ä¹ å’Œé›¶æ ·æœ¬å­¦ä¹ æ–¹é¢çš„èƒ½åŠ›å·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿä»¥æœ€å°‘çš„è®­ç»ƒç¤ºä¾‹æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚å°‘é‡æ ·æœ¬å­¦ä¹ å…è®¸æ¨¡å‹ä»…ä»å°‘æ•°å®ä¾‹ä¸­è¿›è¡Œæ¦‚æ‹¬ï¼Œè€Œé›¶æ ·æœ¬å­¦ä¹ ä½¿å®ƒä»¬èƒ½å¤Ÿåœ¨æ²¡æœ‰å…ˆå‰ç¤ºä¾‹çš„æƒ…å†µä¸‹å¤„ç†å…¨æ–°çš„ä»»åŠ¡ã€‚è¿™ä¸€èŒƒå¼è½¬å˜å¤§å¤§å‡å°‘äº†å¯¹å¹¿æ³›æ ‡è®°æ•°æ®é›†çš„éœ€æ±‚ï¼Œè€Œè¿™åœ¨ä¼ ç»Ÿä¸Šæ˜¯è®­ç»ƒ AI ç³»ç»Ÿçš„ä¸€å¤§æŒ‘æˆ˜ã€‚é€šè¿‡å±•ç¤ºåœ¨ä»…æ ¹æ®ä¸Šä¸‹æ–‡æç¤ºç†è§£å’Œæ‰§è¡Œæ–°ä»»åŠ¡æ–¹é¢çš„å‡ºè‰²é€‚åº”èƒ½åŠ›ï¼ŒAI LLM æ­£åœ¨æˆä¸ºæ›´é€šç”¨çš„å·¥å…·ï¼Œé€‚ç”¨äºç°å®ä¸–ç•Œåœºæ™¯ã€‚

### è¿è¡Œæ—¶ä¼˜åŒ–
ä¸ºäº†æé«˜åœ¨èµ„æºå—é™ç¯å¢ƒä¸­ä½¿ç”¨LLMsçš„å¯ç”¨æ€§ï¼Œå·²ç»å¼€å‘äº†å„ç§è¿è¡Œæ—¶ä¼˜åŒ–æŠ€æœ¯ã€‚æ¨¡å‹å‰ªæï¼Œå³æ¶ˆé™¤ä¸å¤ªé‡è¦çš„å‚æ•°ï¼Œä»¥åŠé‡åŒ–ï¼Œå³é™ä½æ¨¡å‹æ•°å€¼è¡¨ç¤ºçš„ç²¾åº¦ï¼Œæ˜¯æ­£åœ¨å®æ–½çš„å…³é”®ç­–ç•¥ã€‚è¿™äº›æŠ€æœ¯æœ‰æ•ˆåœ°å‡å°‘äº†æ•´ä½“æ¨¡å‹å¤§å°å’Œè®¡ç®—éœ€æ±‚ï¼Œä½¿å¼ºå¤§çš„AIæ¨¡å‹èƒ½å¤Ÿåœ¨å…·æœ‰æœ‰é™GPUæˆ–CPUèµ„æºçš„è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚è¿™ç§ä¼˜åŒ–ä¸ä»…ä½¿å…ˆè¿›çš„AIèƒ½åŠ›èƒ½å¤Ÿåœ¨æ›´å¹¿æ³›çš„è®¾å¤‡ä¸Šè·å¾—ï¼Œè¿˜ä¸ºç§»åŠ¨æˆ–è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­çš„æ–°åº”ç”¨æ‰“å¼€äº†å¯èƒ½æ€§ã€‚

### å¼€æºè¿åŠ¨
å¼€æºè¿åŠ¨åœ¨äººå·¥æ™ºèƒ½å¼€å‘ä¸­çš„å¤å…´æ˜¾è‘—æ”¹å˜äº†ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…çš„ç¯å¢ƒã€‚ç»„ç»‡ä»¬å‘å¸ƒäº†å¼ºå¤§çš„æ¨¡å‹ï¼Œå¦‚ LLaMA å’Œ Falconï¼Œä½¿å°–ç«¯ AI LLM çš„è®¿é—®å˜å¾—æ›´åŠ æ°‘ä¸»åŒ–ã€‚è¿™ä¸€è½¬å˜ä½¿å¾—è¾ƒå°çš„å®ä½“å’Œç‹¬ç«‹ç ”ç©¶äººå‘˜èƒ½å¤Ÿåœ¨æ²¡æœ‰ä¸ä¸“æœ‰ç³»ç»Ÿç›¸å…³çš„è´¢åŠ¡é™åˆ¶çš„æƒ…å†µä¸‹ï¼Œå°è¯•å¤æ‚çš„å·¥å…·ã€‚è¿™äº›å€¡è®®çš„ç¤¾åŒºé©±åŠ¨ç‰¹æ€§ä¿ƒè¿›äº†åˆ›æ–°å’Œåˆä½œï¼ŒåŠ©åŠ›äºä¸€ä¸ªæ›´åŠ ç”Ÿæœºå‹ƒå‹ƒçš„ç”Ÿæ€ç³»ç»Ÿï¼Œåœ¨è¿™é‡Œå¤šæ ·åŒ–çš„åº”ç”¨ã€åˆ›æ–°å’Œæ–¹æ³•è®ºå¾—ä»¥è“¬å‹ƒå‘å±•ã€‚

### å®æ—¶å¯¹è¯å¼äººå·¥æ™ºèƒ½
AI LLMs æ­£åœ¨è¶Šæ¥è¶Šå¤šåœ°ç”¨äºå®æ—¶å¯¹è¯åº”ç”¨ä¸­ï¼Œæ”¹å˜å®¢æˆ·æœåŠ¡ä½“éªŒå¹¶å¢å¼ºè™šæ‹ŸåŠ©æ‰‹çš„åŠŸèƒ½ã€‚éšç€ä¸Šä¸‹æ–‡æ„è¯†å’Œå“åº”èƒ½åŠ›çš„æ˜¾è‘—æå‡ï¼Œè¿™äº› AI ç³»ç»Ÿèƒ½å¤Ÿå¤„ç†å¤æ‚æŸ¥è¯¢ï¼Œå¹¶ä¸ç”¨æˆ·è¿›è¡Œæ›´æœ‰æ„ä¹‰çš„å¯¹è¯ã€‚LLMs çš„å®æ—¶åº”ç”¨ä½¿ä¼ä¸šèƒ½å¤Ÿæä¾›åŠæ—¶çš„å¸®åŠ©ï¼Œå¿«é€Ÿè§£å†³é—®é¢˜ï¼Œå¹¶æä¾›ä¸ªæ€§åŒ–ä½“éªŒï¼Œçªæ˜¾äº† AI åœ¨å„ä¸ªè¡Œä¸šä¸­å½»åº•æ”¹å˜äº’åŠ¨ç­–ç•¥çš„æ½œåŠ›ã€‚

### åŸ¹è®­æ–¹æ³•çš„åˆ›æ–°
åŸ¹è®­æ–¹æ³•çš„åˆ›æ–°æ­£åœ¨é‡å¡‘AI LLMså¦‚ä½•ä»äº’åŠ¨ä¸­å­¦ä¹ å¹¶æé«˜è¾“å‡ºè´¨é‡ã€‚è‡ªæˆ‘ç›‘ç£å­¦ä¹ ç­‰æŠ€æœ¯ä½¿æ¨¡å‹èƒ½å¤Ÿä»å¤§é‡æœªæ ‡è®°çš„æ•°æ®ä¸­å­¦ä¹ ï¼Œè€ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰åˆ™åˆ©ç”¨äººç±»è¯„ä¼°æ¥ä¼˜åŒ–æ¨¡å‹å“åº”ï¼Œè¿™äº›éƒ½æ˜¯æ¨åŠ¨è¿™ä¸€è¿›ç¨‹çš„å…³é”®ã€‚è¿™äº›æ–¹æ³•å¢å¼ºäº†åŸ¹è®­è¿‡ç¨‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´é«˜æ•ˆã€æ›´æœ‰æ•ˆåœ°è·å–çŸ¥è¯†ã€‚é€šè¿‡æ”¹å–„å‚ä¸åº¦å’Œäº’åŠ¨è´¨é‡ï¼Œè¿™äº›åŸ¹è®­æ–¹æ³•åœ¨ä½¿LLMsé€‚åº”ç”¨æˆ·éœ€æ±‚å’Œåå¥½æ–¹é¢è‡³å…³é‡è¦ï¼Œç¡®ä¿AIèƒ½åŠ›çš„æŒç»­å­¦ä¹ å’Œæ¼”è¿›ã€‚

è¿™äº›è¯¦ç»†çš„éƒ¨åˆ†æ¦‚è¿°äº†æˆªè‡³2024å¹´AI LLMsæœ€ç›¸å…³çš„å‘å±•å’Œè¶‹åŠ¿ï¼Œå±•ç¤ºäº†è¿™ä¸€æŠ€æœ¯çš„å¿«é€Ÿæ¼”å˜åŠå…¶å¯¹å„ä¸ªé¢†åŸŸçš„å½±å“ã€‚
```

### è®¡åˆ’

CrewAIä¸­çš„è§„åˆ’åŠŸèƒ½ä½¿æ‚¨èƒ½å¤Ÿå°†è§„åˆ’èƒ½åŠ›çº³å…¥æ‚¨çš„å›¢é˜Ÿã€‚å½“æ¿€æ´»æ—¶ï¼Œåœ¨æ¯æ¬¡å›¢é˜Ÿè¿­ä»£ä¹‹å‰ï¼Œæ‰€æœ‰å›¢é˜Ÿä¿¡æ¯å°†è¢«å‘é€åˆ°`AgentPlanner`ï¼Œè¯¥å·¥å…·åˆ›å»ºé€æ­¥çš„ä»»åŠ¡è®¡åˆ’ã€‚ç„¶åå°†æ­¤è®¡åˆ’é™„åŠ åˆ°æ¯ä¸ªä»»åŠ¡æè¿°ä¸­ã€‚


```python
@crew
 def crew(self) -> Crew:
  """Creates the TrainTestExample crew"""
  # To learn how to add knowledge sources to your crew, check out the documentation:
  # https://docs.crewai.com/concepts/knowledge#what-is-knowledge

  return Crew(
   agents=self.agents, # Automatically created by the @agent decorator
   tasks=self.tasks, # Automatically created by the @task decorator
   process=Process.sequential,
   verbose=True,
   planning=True,
   # process=Process.hierarchical, # In case you wanna use that instead https://docs.crewai.com/how-to/Hierarchical/
  )
```
è®©æˆ‘ä»¬è¿è¡ŒCrewï¼š


```python
crewai run
```
è¿™æ¬¡ï¼Œåœ¨ä»£ç†æ‰§è¡Œä»»åŠ¡ä¹‹å‰ï¼Œ`AgentPlanner`å°†è´Ÿè´£å¹¶æ¦‚è¿°ä»»åŠ¡çš„æ‰§è¡Œè¿‡ç¨‹ã€‚


```python
[2025-01-04 23:06:26][INFO]: Planning the crew execution

## ä»£ç†ï¼šAI LLMsé«˜çº§æ•°æ®ç ”ç©¶å‘˜

### ä»»åŠ¡ï¼šå¯¹AI LLMsè¿›è¡Œå…¨é¢ç ”ç©¶ ç¡®ä¿æ‚¨æ‰¾åˆ°ä»»ä½•æœ‰è¶£å’Œç›¸å…³çš„ä¿¡æ¯ï¼Œè€ƒè™‘åˆ°å½“å‰å¹´ä»½æ˜¯2024å¹´ã€‚
1. ç¡®å®šä¸AI LLMsç›¸å…³çš„å…³é”®ä¸»é¢˜å’Œè¯é¢˜ï¼Œè¿™äº›ä¸»é¢˜å’Œè¯é¢˜åœ¨2024å¹´å‡ºç°ï¼Œä¾‹å¦‚æ¶æ„çš„è¿›å±•ã€ä¼¦ç†è€ƒè™‘ã€åº”ç”¨å’ŒæŒ‘æˆ˜ã€‚ 
2. åˆ©ç”¨å­¦æœ¯æ•°æ®åº“ã€è¡Œä¸šæœŸåˆŠå’Œä¿¡èª‰è‰¯å¥½çš„åœ¨çº¿èµ„æºè·å–å…³äºAI LLMsçš„æœ€æ–°ç ”ç©¶æ–‡ç« ã€ç™½çš®ä¹¦å’Œæ¡ˆä¾‹ç ”ç©¶ã€‚ 
3. ç¼–åˆ¶ä¸€ä»½2024å¹´ä¸“æ³¨äºAI LLMsçš„ç›¸å…³ä¼šè®®ã€ç½‘ç»œç ”è®¨ä¼šå’Œåä½œå¹³å°çš„æ¸…å•ï¼Œæ³¨æ„ä»»ä½•ä¸»é¢˜æ¼”è®²è€…æˆ–é‡å¤§å…¬å‘Šã€‚ 
4. é€šè¿‡è®¿è°ˆã€åšå®¢å’Œæ’­å®¢æœç´¢é¢†åŸŸå†…æ€æƒ³é¢†è¢–å’Œä»ä¸šè€…çš„ä¸“å®¶æ„è§ã€‚ 
5. æ”¶é›†æœ‰å…³æœ€æ–°AI LLMæ€§èƒ½æŒ‡æ ‡çš„æ•°æ®ï¼ŒåŒ…æ‹¬åŸºå‡†å’Œæ¯”è¾ƒåˆ†æï¼Œä»¥äº†è§£å…¶æ”¹è¿›æƒ…å†µã€‚ 
6. å®¡æŸ¥çªå‡ºAI LLMåœ¨åŒ»ç–—ã€é‡‘èå’Œæ•™è‚²ç­‰å„ä¸ªé¢†åŸŸåˆ›æ–°åº”ç”¨çš„æ¡ˆä¾‹ç ”ç©¶ã€‚ 
7. æ£€æŸ¥éšç€LLMéƒ¨ç½²å¢åŠ è€Œäº§ç”Ÿçš„å®‰å…¨å’Œéšç§é—®é¢˜ã€‚ 
8. åˆ†æAI LLMå¯¹åŠ³åŠ¨åŠ›çš„å½±å“åŠæ½œåœ¨çš„å·¥ä½œç½®æ¢é—®é¢˜ã€‚ 
9. å°†å‘ç°æ€»ç»“ä¸º10ä¸ªè¦ç‚¹ï¼Œçªå‡º2024å¹´AI LLMsçŠ¶æ€çš„æœ€ç›¸å…³å’Œå¼•äººæ³¨ç›®çš„ä¿¡æ¯ã€‚ 
10. ç¡®ä¿æ‰€æœ‰å‘ç°éƒ½å‡†ç¡®å¼•ç”¨ï¼Œå¹¶ä¸”æ²¡æœ‰é—æ¼è¯¥é¢†åŸŸç»å†çš„é‡å¤§è¿›å±•ã€‚

```
Next:


### Read More


### Sources

<https://docs.crewai.com/concepts/training>

<https://docs.crewai.com/concepts/planning>


## Thank you for being a part of the community

*Before you go:*

* Be sure to **clap** and **follow** the writer ï¸ğŸ‘**ï¸ï¸**
* Follow us: [**X**](https://x.com/inPlainEngHQ) \| [**LinkedIn**](https://www.linkedin.com/company/inplainenglish/) \| [**YouTube**](https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw) \| [**Newsletter**](https://newsletter.plainenglish.io/) \| [**Podcast**](https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0)
* [**Check out CoFeed, the smart way to stay up\-to\-date with the latest in tech**](https://cofeed.app/) **ğŸ§ª**
* [**Start your own free AI\-powered blog on Differ**](https://differ.blog/) ğŸš€
* [**Join our content creators community on Discord**](https://discord.gg/in-plain-english-709094664682340443) ğŸ§‘ğŸ»â€ğŸ’»
* For more content, visit [**plainenglish.io**](https://plainenglish.io/) \+ [**stackademic.com**](https://stackademic.com/)```

