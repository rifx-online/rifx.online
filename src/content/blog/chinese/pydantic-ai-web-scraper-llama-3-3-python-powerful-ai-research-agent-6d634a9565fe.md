---
title: "Pydantic AI + Web Scraper + Llama 3.3 Python = å¼ºå¤§çš„äººå·¥æ™ºèƒ½ç ”ç©¶ä»£ç†"
meta_title: "Pydantic AI + Web Scraper + Llama 3.3 Python = å¼ºå¤§çš„äººå·¥æ™ºèƒ½ç ”ç©¶ä»£ç†"
description: "æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ Pydantic AIã€Web Scraper å’Œ Llama 3.3 æ„å»ºä¸€ä¸ªå¤šä»£ç†èŠå¤©æœºå™¨äººï¼Œä»¥æ”¯æŒä¸šåŠ¡æˆ–ä¸ªäººéœ€æ±‚ã€‚Pydantic AI æ˜¯ä¸€ä¸ªåŸºäº Pydantic çš„æ¡†æ¶ï¼Œä¸“æ³¨äºæ•°æ®éªŒè¯å’Œç»“æ„åŒ–å“åº”ï¼Œç®€åŒ–äº† AI åº”ç”¨å¼€å‘ã€‚Llama 3.3 æ˜¯ Meta æœ€æ–°å‘å¸ƒçš„ç”Ÿæˆ AI æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„æ€§èƒ½ã€‚æ–‡ç« è¿˜æ¯”è¾ƒäº† Pydantic AI ä¸ LangChain å’Œ LlamaIndex çš„ä¸åŒç‰¹ç‚¹ï¼Œå¹¶æä¾›äº†ä»£ç ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªå®æ—¶èŠå¤©æœºå™¨äººä»¥æ£€ç´¢å’Œæ€»ç»“æœ€æ–°çš„è¯­è¨€æ¨¡å‹æ–°é—»ã€‚"
date: 2024-12-15T01:10:27Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*XIO4G9hmnfITx91eM1FmKA.png"
categories: ["Programming", "Chatbots", "Generative AI"]
author: "Rifx.Online"
tags: ["Pydantic", "Llama", "WebScraper", "Validation", "Generative"]
draft: False

---





åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘å°†å¿«é€Ÿæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Pydantic AIã€Web Scraper å’Œ Llama 3\.3 åˆ›å»ºä¸€ä¸ªå¤šä»£ç†èŠå¤©æœºå™¨äººï¼Œä»¥ä¾¿ä¸ºæ‚¨çš„ä¸šåŠ¡æˆ–ä¸ªäººä½¿ç”¨æ„å»ºä¸€ä¸ªå¼ºå¤§çš„ä»£ç†èŠå¤©æœºå™¨äººã€‚

åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥ä½œæµä¸­ï¼Œç»“æ„åŒ–è¾“å‡ºæé«˜äº†å‡†ç¡®æ€§å’Œæ¸…æ™°åº¦ï¼Œä½¿æ•°æ®æ›´æ˜“äºç†è§£ã€‚

æˆ‘ä»¬è®¸å¤šäººéƒ½çŸ¥é“éªŒè¯æˆ–è½¬æ¢æ•°æ®ä¸ºæ­£ç¡®æ ¼å¼æ˜¯å¤šä¹ˆä»¤äººæ²®ä¸§ã€‚å½“å¤„ç†æ¥å£æ•°æ®æ—¶ï¼Œæ‚¨ä¼šé¢å¯¹å¤æ‚çš„æ•°æ®æ ¼å¼ã€‚å¦‚æœä¸å°å¿ƒï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°å¾ˆéš¾å‘ç°çš„é”™è¯¯ã€‚

è¿™å°±æ˜¯ Pydantic å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚å®ƒæ˜¯ä¸€ä¸ªçŸ¥åçš„æ•°æ®éªŒè¯å·¥å…·ï¼Œå¹¶åœ¨å¹•åå‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚OpenAIã€Anthropicã€LangChain å’Œ LlamaIndex éƒ½å°† Pydantic ä½œä¸ºæ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£æ•°æ®éªŒè¯ç­‰é‡è¦åŠŸèƒ½ã€‚

ä¸ä¹…å‰ï¼ŒPydantic å›¢é˜Ÿæ¨å‡ºäº† **PydanticAI**ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº Pydantic çš„ AI ä»£ç†æ¡†æ¶ã€‚å®ƒæ—¨åœ¨ç®€åŒ– AI åº”ç”¨å¼€å‘çš„å¤æ‚æ€§ï¼Œå¹¶è§£å†³ AI ä»£ç†å¼€å‘ä¸­çš„å„ç§ç—›ç‚¹ã€‚

åœ¨ä¸œéƒ¨æ—¶é—´ 12 æœˆ 6 æ—¥æ˜ŸæœŸäº”ï¼ŒMeta å®£å¸ƒæ¨å‡ºæ–°çš„ Llama ç³»åˆ—ç”Ÿæˆ AI æ¨¡å‹ï¼šLlama 3\.3ï¼Œæ‹¥æœ‰ 70 äº¿ä¸ªå‚æ•°ï¼Œä¹Ÿç§°ä¸º Llama 3\.3 70Bã€‚é¦–å¸­æ‰§è¡Œå®˜æ‰å…‹ä¼¯æ ¼åœ¨å…¶ç¤¾äº¤åª’ä½“ Instagram ä¸Šè¡¨ç¤ºï¼Œè¿™æ˜¯ä»Šå¹´æœ€åä¸€æ¬¡é‡å¤§ AI æ¨¡å‹æ›´æ–°ï¼Œä¸‹ä¸€æ­¥å°†æ˜¯æ˜å¹´ Llama 4 çš„é¦–æ¬¡äº®ç›¸ã€‚

Llama 3\.3 ç°åœ¨å¯ä»¥ä»åœ¨çº¿æ¥æºä¸‹è½½ï¼Œä¾‹å¦‚ oLlama å®˜æ–¹ç½‘ç«™å’Œ AI å¼€å‘å¹³å° Hugging Faceã€‚

Llama 3\.3 åœ¨è¡Œä¸šåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†è°·æ­Œçš„ Gemini 1\.5 Proã€OpenAI çš„ GPT\-4o å’Œäºšé©¬é€Šæœ¬å‘¨æ—©äº›æ—¶å€™å‘å¸ƒçš„ Nova Proã€‚æ‰å…‹ä¼¯æ ¼è¡¨ç¤ºï¼Œè¿™æ˜¯ä»Šå¹´æœ€åä¸€æ¬¡é‡å¤§ AI æ¨¡å‹æ›´æ–°ï¼Œä¸‹ä¸€æ­¥å°†æ˜¯æ˜å¹´ Llama 4 çš„å‡ºç°ã€‚

é‚£ä¹ˆï¼Œè®©æˆ‘ç»™æ‚¨å¿«é€Ÿæ¼”ç¤ºä¸€ä¸ªå®æ—¶èŠå¤©æœºå™¨äººï¼Œå‘æ‚¨å±•ç¤ºæˆ‘çš„æ„æ€ã€‚

è®©æˆ‘ä»¬é—®ä¸€ä¸ªç®€å•çš„é—®é¢˜ï¼šä»Šå¹´å‘å¸ƒçš„æœ€æ–° LLM æ˜¯ä»€ä¹ˆï¼Ÿå¦‚æœæ‚¨æŸ¥çœ‹ Pydantic AI ç”Ÿæˆè¾“å‡ºçš„æ–¹å¼ï¼Œæ‚¨ä¼šçœ‹åˆ°å½“æˆ‘æå‡ºé—®é¢˜å¹¶ç‚¹å‡»æœç´¢æŒ‰é’®æ—¶ï¼Œæ£€ç´¢åŠŸèƒ½ä¼šè·å–å½“å‰æ—¥æœŸï¼Œå°†æŸ¥è¯¢å’Œæ—¥æœŸä¼ é€’ç»™ AI ä»£ç†ï¼ˆ`search_agent`ï¼‰ï¼Œå¹¶ä½¿ç”¨ Tavily å®¢æˆ·ç«¯è·å–æœç´¢ç»“æœã€‚AI ä»£ç†å¤„ç†è¿™äº›ç»“æœå¹¶å°†å…¶ç»„ç»‡æˆç»“æ„åŒ–å­—æ®µï¼ˆ`ResearchResult`ï¼‰ï¼Œå¹¶è¿”å›æ€»ç»“å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€ä¸»è¦æ–‡ç« å’Œè¦ç‚¹ã€‚è¿™ä¸ªç®€åŒ–çš„ç³»ç»Ÿå°† AI èƒ½åŠ›ä¸ç”¨æˆ·å‹å¥½çš„ç•Œé¢ç›¸ç»“åˆï¼Œä»¥æä¾›ç®€æ˜ä¸”è§†è§‰ä¸Šå¸å¼•äººçš„ä¿¡æ¯æ£€ç´¢å’Œæ€»ç»“ã€‚

åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºä»€ä¹ˆæ˜¯ Pydantic AIï¼ŒPydantic AI çš„ç‰¹ç‚¹ï¼ŒLangchainã€llamaindex å’Œ Pydantic AI ä¹‹é—´çš„åŒºåˆ«ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ Pydantic AI åˆ›å»ºä¸€ä¸ªè¶…çº§ AI ä»£ç†ã€‚

## åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼ğŸ¦¸ğŸ»â€â™€ï¸

å¦‚æœä½ å–œæ¬¢è¿™ä¸ªä¸»é¢˜å¹¶æƒ³æ”¯æŒæˆ‘ï¼š

1. **ä¸º**æˆ‘çš„æ–‡ç« é¼“æŒ 50 æ¬¡ï¼›è¿™å¯¹æˆ‘çœŸçš„å¾ˆæœ‰å¸®åŠ©ã€‚ğŸ‘
2. [**å…³æ³¨**](https://medium.com/@mr.tarik098)æˆ‘åœ¨ Medium ä¸Šï¼Œå¹¶è®¢é˜…ä»¥å…è´¹è·å–æˆ‘çš„æœ€æ–°æ–‡ç« ğŸ«¶
3. åŠ å…¥è¿™ä¸ªå¤§å®¶åº­ â€” è®¢é˜… [**YouTube é¢‘é“**](https://www.youtube.com/channel/UC6P5WCWjqhhXVFBqbJHNxyw)

## ä»€ä¹ˆæ˜¯ Pydantic AI

PydanticAI æå€¡ç±»å‹å®‰å…¨æ“ä½œã€ç»“æ„åŒ–å“åº”éªŒè¯ä»¥åŠä¸€ç§æ–°é¢–çš„ä¾èµ–æ³¨å…¥ç³»ç»Ÿï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨ç†Ÿæ‚‰çš„ Python æœ€ä½³å®è·µé¢†åŸŸå†…è¿›è¡Œã€‚è¿™ä½¿å…¶æˆä¸ºå¼€å‘äººå‘˜åœ¨ä¸ç‰ºç‰²ä»£ç è´¨é‡æˆ–å®‰å…¨æ€§çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨ç”Ÿæˆæ€§ AI åŠ›é‡çš„å®è´µå·¥å…·ã€‚PydanticAI å€¼å¾—æ¢ç´¢ï¼Œç‰¹åˆ«æ˜¯å®ƒä¸ Logfire çš„é›†æˆï¼Œä»¥å¢å¼ºè°ƒè¯•å’Œç›‘æ§èƒ½åŠ›ã€‚

## åŠŸèƒ½

PydanticAI æ˜¯ç”± Pydantic å›¢é˜Ÿå¼€å‘çš„ Python ä»£ç†æ¡†æ¶ï¼Œç”¨äºæ„å»ºç”Ÿäº§çº§åº”ç”¨ç¨‹åºï¼Œåˆ©ç”¨ç”Ÿæˆå¼ AIã€‚å®ƒæä¾›æ¨¡å‹æ— å…³çš„æ”¯æŒã€ç±»å‹å®‰å…¨çš„éªŒè¯ã€ç»“æ„åŒ–å“åº”å¤„ç†ï¼Œå¹¶ä¸å„ç§ LLM æä¾›å•†æ— ç¼é›†æˆã€‚è¯¥æ¡†æ¶å¼ºè°ƒç®€å•æ€§å’Œå¯é æ€§ï¼ŒåŒæ—¶æä¾›å¼ºå¤§çš„åŠŸèƒ½ï¼Œå¦‚ä¾èµ–æ³¨å…¥ã€æµå¼å“åº”å’Œé€šè¿‡ Logfire é›†æˆçš„å…¨é¢ç›‘æ§ã€‚

**ç±»å‹å®‰å…¨çš„å“åº”éªŒè¯ï¼š** åˆ©ç”¨ Pydantic ç¡®ä¿ LLM è¾“å‡ºç¬¦åˆé¢„æœŸçš„æ•°æ®ç»“æ„ï¼Œä¸ºç”Ÿäº§åº”ç”¨æä¾›å¼ºæœ‰åŠ›çš„éªŒè¯

**ä¾èµ–æ³¨å…¥ç³»ç»Ÿï¼š** ä¸€ç§æ–°é¢–çš„ç±»å‹å®‰å…¨ç³»ç»Ÿï¼Œå…è®¸å®šåˆ¶ä»£ç†è¡Œä¸ºï¼Œå¹¶ä¿ƒè¿›æµ‹è¯•å’Œè¯„ä¼°é©±åŠ¨çš„å¼€å‘

**æ¨¡å‹æ— å…³æ¶æ„ï¼š** æ”¯æŒå¤šä¸ª LLM æä¾›å•†ï¼ˆOpenAIã€Geminiã€Groqï¼‰ï¼Œå¹¶ä¸ºé¢å¤–æ¨¡å‹æ”¯æŒæä¾›ç®€å•æ¥å£

**æµå¼å“åº”å¤„ç†ï¼š** èƒ½å¤Ÿå®æ—¶å¤„ç†å’ŒéªŒè¯æµå¼å“åº”ï¼ŒåŒ…æ‹¬åœ¨æµå¼ä¼ è¾“æœŸé—´çš„ç»“æ„åŒ–æ•°æ®éªŒè¯

## Langchain ä¸ Llamaindex ä¸ Pydantic AI

è¿™äº›æ¡†æ¶ä¹‹é—´çš„å·®å¼‚ä½“ç°åœ¨å®ƒä»¬çš„æŠ€æœ¯ç‰¹æ€§ã€å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘çš„ä¸åŒç†è§£å’Œå®è·µæ–¹å‘ä¸Šã€‚

PydanticAI ä¼˜å…ˆè€ƒè™‘å·¥ç¨‹å®è·µå’Œç”Ÿäº§å¯é æ€§ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸¥æ ¼çš„ç±»å‹ç³»ç»Ÿå’Œæ ‡å‡†åŒ–çš„å¼€å‘æ¨¡å‹ã€‚

LangChain ä¸ºå¼€å‘è€…æä¾›äº†ä¸€ç§æ–¹ä¾¿çš„æ–¹å¼ï¼Œé€šè¿‡çµæ´»çš„ç»„ä»¶è®¾è®¡å’Œä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿå¿«é€Ÿæ„å»ºåº”ç”¨ç¨‹åºã€‚

LlamaIndex ä¸“æ³¨äºæ–‡æ¡£å¤„ç†å’ŒçŸ¥è¯†æ£€ç´¢ï¼Œåœ¨æ•°æ®å¤„ç†å’Œç´¢å¼•ä¼˜åŒ–æ–¹é¢å½¢æˆäº†ç‹¬ç‰¹çš„ä¼˜åŠ¿ã€‚

## å¼€å§‹ç¼–ç 

åœ¨æˆ‘ä»¬æ·±å…¥åº”ç”¨ç¨‹åºä¹‹å‰ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç†æƒ³çš„ç¯å¢ƒä»¥ä½¿ä»£ç æ­£å¸¸å·¥ä½œã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…å¿…è¦çš„ Python åº“ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†å¼€å§‹å®‰è£…æ”¯æŒæ¨¡å‹çš„åº“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å¯¹ä¸‹é¢çš„åº“è¿›è¡Œ pip å®‰è£…ã€‚

```python
pip install -r requirements.txt
```
å®‰è£…å®Œæˆåï¼Œæˆ‘ä»¬å¯¼å…¥ Pydantic AIã€dataclassesã€tavilyã€streamlit å’Œ devtoolsã€‚

```python
import os
import asyncio
import datetime
from typing import Any
from dataclasses import dataclass

import nest_asyncio
nest_asyncio.apply()
from openai import  AsyncOpenAI
from pydantic_ai.models.openai import OpenAIModel
import streamlit as st
from pydantic_ai import Agent, RunContext
from pydantic import BaseModel, Field
from tavily import AsyncTavilyClient
from dotenv import load_dotenv
```
ä¸ºæ‚¨çš„ LLM æä¾›è€…è®¾ç½® API ä»¤ç‰Œã€‚Pydantic ç›´æ¥ä¸ OpenAIã€Groq å’Œ VertexAI é…åˆä½¿ç”¨ã€‚

ä½†åœ¨æœ¬è§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Ollamaï¼Œå®ƒç°åœ¨ä¸ OpenAI [Chat Completions API](https://github.com/ollama/ollama/blob/main/docs/openai.md) å†…ç½®å…¼å®¹ï¼Œä½¿å¾—å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨æ›´å¤šå·¥å…·å’Œåº”ç”¨ç¨‹åºã€‚

```python
client = AsyncOpenAI(
    base_url='http://localhost:11434/v1',
    api_key='your-api-key',
)

model = OpenAIModel('llama3.3:latest', openai_client=client)
```
æˆ‘ä»¬å°†ä½¿ç”¨ tavily æ¥æŠ“å–æµè§ˆå™¨ã€è¿‡æ»¤å’Œèšåˆæ•°æ®ã€‚

```python
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
if not TAVILY_API_KEY:
    raise ValueError("Please set TAVILY_API_KEY environment variable.")

tavily_client = AsyncTavilyClient(api_key=TAVILY_API_KEY)
```
æˆ‘ä»¬å®šä¹‰äº†ä¸‰ä¸ªç±»ã€‚ç¬¬ä¸€ä¸ª `SearchDataclass` æ˜¯ä¸€ä¸ªæ•°æ®ç±»ï¼Œç”¨äºå­˜å‚¨ä¸æœç´¢ç›¸å…³çš„ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯æœ€å¤§ç»“æœæ•° (`max_results`) å’Œä»Šå¤©çš„æ—¥æœŸ (`todays_date`)ã€‚

ç¬¬äºŒä¸ªç±» `ResearchDependencies` æ˜¯å¦ä¸€ä¸ªæ•°æ®ç±»ï¼Œä»…å­˜å‚¨ä»Šå¤©çš„æ—¥æœŸã€‚

ç¬¬ä¸‰ä¸ªç±» `ResearchResult` ç»§æ‰¿è‡ª `BaseModel`ï¼Œè¡¨ç¤ºä¸€ç¯‡ç ”ç©¶æ–‡ç« ï¼ŒåŒ…å«æ–‡ç« æ ‡é¢˜ (`research_title`)ã€ä¸»è¦å†…å®¹ (`research_main`) å’Œä¸€ç»„æ€»ç»“è¦ç‚¹çš„é¡¹ç›®ç¬¦å· (`research_bullets`)ã€‚

`Field` å‡½æ•°ç”¨äºä¸ºæ¯ä¸ªå±æ€§æ·»åŠ æè¿°ï¼Œæœ‰åŠ©äºéªŒè¯å’Œæ–‡æ¡£ã€‚

```python
@dataclass
class SearchDataclass:
    max_results: int
    todays_date: str

@dataclass
class ResearchDependencies:
    todays_date: str

class ResearchResult(BaseModel):
    research_title: str = Field(description='Markdown heading describing the article topic, prefixed with #')
    research_main: str = Field(description='A main section that provides a detailed news article')
    research_bullets: str = Field(description='A set of bullet points summarizing key points')
```
æˆ‘åˆ›å»ºäº†ä¸€ä¸ª `Agent` LLama3.3 ç”¨äºç ”ç©¶ä»»åŠ¡ã€‚å®ƒä½¿ç”¨ `ResearchDependencies` æ•°æ®ç±»ä½œä¸ºè¾“å…¥ï¼Œä½¿ç”¨ `ResearchResult` ç±»ä½œä¸ºè¾“å‡ºã€‚æ¥ç€ï¼Œæˆ‘ä»¬ç¼–å†™ä¸€ä¸ª **ç³»ç»Ÿæç¤º**ï¼ŒæŒ‡ç¤ºå®ƒä»æŸ¥è¯¢ä¸­è¯†åˆ«å…³é”®è¯ï¼Œæ‰§è¡Œå¤šæ¬¡æœç´¢ï¼Œç„¶åå°†è¿™äº›ç»“æœåˆå¹¶æˆè¯¦ç»†å“åº”ã€‚

```python
## Create the agent
search_agent = Agent(
    model,
    deps_type=ResearchDependencies,
    result_type=ResearchResult,
    system_prompt='You are a helpful research assistant, you are an expert in research. '
                  'When given a query, you will identify strong keywords to do 3-5 searches using the provided search tool. '
                  'Then combine results into a detailed response.'
)
```
æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª add\_current\_date å‡½æ•°ï¼Œä»¥æŒ‡ç¤ºä»£ç†ä»ç»™å®šé—®é¢˜ä¸­è¯†åˆ«å¼ºå…³é”®è¯ï¼Œä½¿ç”¨è¿™äº›å…³é”®è¯è¿›è¡Œ 3-5 æ¬¡æœç´¢ï¼Œå¹¶å°†ç»“æœåˆå¹¶æˆè¯¦ç»†å“åº”ï¼ŒåŒæ—¶ç¡®ä¿ä¿¡æ¯å‡†ç¡®ä¸”æœ€æ–°ã€‚

```python
@search_agent.system_prompt
async def add_current_date(ctx: RunContext[ResearchDependencies]) -> str:
    todays_date = ctx.deps.todays_date
    system_prompt = (
        f"You're a helpful research assistant and an expert in research. "
        f"When given a question, write strong keywords to do 3-5 searches in total "
        f"(each with a query_number) and then combine the results. "
        f"If you need today's date it is {todays_date}. "
        f"Focus on providing accurate and current information."
    )
    return system_prompt
```
æˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªå¼‚æ­¥å‡½æ•°ï¼š`get_search` å’Œ `do_search`ã€‚

* `get_search` æ˜¯ `search_agent` ç”¨äºæ‰§è¡Œæœç´¢çš„å·¥å…·ã€‚å®ƒæ¥å—æœç´¢æŸ¥è¯¢å’Œæœç´¢ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬æœ€å¤§ç»“æœæ•°ï¼‰ï¼Œå¹¶ä½¿ç”¨ `tavily_client` æ¥æ£€ç´¢æœç´¢ç»“æœï¼Œå°†å…¶ä½œä¸ºå­—å…¸è¿”å›ã€‚
* `do_search` é€šè¿‡åˆ›å»º `SearchDataclass` çš„å®ä¾‹ï¼ˆåŒ…æ‹¬å½“å‰æ—¥æœŸå’Œæœ€å¤§ç»“æœæ•°ï¼‰æ¥å‡†å¤‡å¿…è¦çš„ä¾èµ–é¡¹ã€‚ç„¶åå®ƒä½¿ç”¨è¿™äº›ä¾èµ–é¡¹å’ŒæŸ¥è¯¢è¿è¡Œ `search_agent`ï¼Œç­‰å¾…ç»“æœã€‚

```python
@search_agent.tool
async def get_search(search_data: RunContext[SearchDataclass], query: str, query_number: int) -> dict[str, Any]:
    """Perform a search using the Tavily client."""
    max_results = search_data.deps.max_results
    results = await tavily_client.get_search_context(query=query, max_results=max_results)
    return results

async def do_search(query: str, max_results: int):
    # Prepare dependencies
    current_date = datetime.date.today()
    date_string = current_date.strftime("%Y-%m-%d")
    deps = SearchDataclass(max_results=max_results, todays_date=date_string)
    result = await search_agent.run(query, deps=deps)
```
è®©æˆ‘ä»¬è®¾ç½®ä¸€ä¸ª Streamlit åº”ç”¨ç¨‹åºï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥æŸ¥è¯¢å¹¶æŒ‡å®šè¦æ£€ç´¢çš„æœç´¢ç»“æœæ•°é‡ã€‚åœ¨æˆ‘ä»¬ç‚¹å‡»æŒ‰é’®ä»¥å¯åŠ¨æœç´¢åï¼Œåº”ç”¨ç¨‹åºå°†è·å–ç›¸å…³çš„ç ”ç©¶æ•°æ®ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€ä¸»è¦æ–‡ç« å’Œå…³é”®è¦ç‚¹ï¼‰ï¼Œå¹¶ä»¥ç»„ç»‡è‰¯å¥½çš„æ ¼å¼æ˜¾ç¤ºã€‚

```python
st.set_page_config(page_title="AI News Researcher", layout="centered")

st.title("Large Language Model News Researcher")
st.write("Stay updated on the latest trends and developments in Large Language Model.")

## User input section
st.sidebar.title("Search Parameters")
query = st.sidebar.text_input("Enter your query:", value="latest Large Language Model news")
max_results = st.sidebar.slider("Number of search results:", min_value=3, max_value=10, value=5)

st.write("Use the sidebar to adjust search parameters.")

if st.button("Get Latest Large Language Model News"):
    with st.spinner("Researching, please wait..."):
        result_data = asyncio.run(do_search(query, max_results))

    st.markdown(result_data.research_title)
    # A bit of styling for the main article
    st.markdown(f"<div style='line-height:1.6;'>{result_data.research_main}</div>", unsafe_allow_html=True)

    st.markdown("### Key Takeaways")
    st.markdown(result_data.research_bullets)
```

## ç»“è®ºï¼š

Pydantic AI æ˜¯ä¸€ä¸ªå‡ºè‰²çš„åº“ï¼Œä½†æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥å®ç°ç›¸åŒçš„åŠŸèƒ½ã€‚æˆ‘èŠ±äº†å¾ˆå¤šç²¾åŠ›æ¥ç†è§£å’Œä½¿ç”¨æˆ‘åœ¨è¿™é‡Œå±•ç¤ºçš„ç¤ºä¾‹ã€‚å¸Œæœ›ä½ èƒ½åˆ©ç”¨è¿™äº›ç¤ºä¾‹æ›´å¿«ã€æ›´è½»æ¾åœ°æŒæ¡ Pydanticã€‚

æ— è®ºæ˜¯æ„å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººè¿˜æ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿï¼ŒPydanticAI æä¾›çš„åŠŸèƒ½ä½¿å¼€å‘è¿‡ç¨‹æ›´åŠ é¡ºç•…ï¼Œæœ€ç»ˆäº§å“æ›´åŠ å¯é ã€‚

> ***ğŸ§™â€â™‚ï¸ æˆ‘æ˜¯ä¸€å AI ç”Ÿæˆä¸“å®¶ï¼å¦‚æœä½ æƒ³åœ¨é¡¹ç›®ä¸Šåˆä½œï¼Œè¯·åœ¨è¿™é‡Œæäº¤ [å’¨è¯¢](https://docs.google.com/forms/d/e/1FAIpQLSelxGSNOdTXULOG0HbhM21lIW_mTgq7NsDbUTbx4qw-xLEkMQ/viewform) æˆ–ä¸æˆ‘é¢„çº¦ [ä¸€å¯¹ä¸€å’¨è¯¢](https://calendly.com/gao-dalie/ai-consulting-call) ç”µè¯ã€‚***

*ğŸ“šæ¬¢è¿æŸ¥çœ‹æˆ‘çš„å…¶ä»–æ–‡ç« :*

