---
title: "ä½¿ç”¨ Llama 3 æ„å»º AI ä»£ç†"
meta_title: "ä½¿ç”¨ Llama 3 æ„å»º AI ä»£ç†"
description: "ä½¿ç”¨ Llama 3 å‡½æ•°è°ƒç”¨åŠŸèƒ½æ„å»º AI ä»£ç†çš„ç»¼åˆæŒ‡å—ã€‚"
date: 2024-11-10T03:51:17Z
image: "https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EWGo-7t4Kl6l82rB2-ZK9Q.png"
categories: ["Programming", "Generative AI", "Chatbots"]
author: "Rifx.Online"
tags: ["Llama", "Gradio", "RAG", "metadata", "indexing"]
draft: False

---



### æ„å»ºå…·æœ‰ Llama 3 å‡½æ•°è°ƒç”¨èƒ½åŠ›çš„ AI ä»£ç†çš„ç»¼åˆæŒ‡å—



### å¼•è¨€

æƒ³è±¡ä¸€ä¸‹ä½ æƒ³ä¹°ä¸€äº›ä¸œè¥¿ã€‚ä½ è®¿é—®ä¸€ä¸ªç”µå­å•†åŠ¡ç½‘ç«™ï¼Œä½¿ç”¨æœç´¢é€‰é¡¹æ‰¾åˆ°ä½ æƒ³è¦çš„ä¸œè¥¿ã€‚ä¹Ÿè®¸ä½ æœ‰å¤šä¸ªç‰©å“è¦è´­ä¹°ï¼Œå› æ­¤è¿™ä¸ªè¿‡ç¨‹å¹¶ä¸æ˜¯å¾ˆé«˜æ•ˆã€‚ç°åœ¨è€ƒè™‘è¿™ä¸ªåœºæ™¯ï¼šæ‰“å¼€ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œç”¨ç®€å•çš„è‹±è¯­æè¿°ä½ æƒ³è¦çš„ä¸œè¥¿ï¼Œç„¶åæŒ‰ä¸‹å›è½¦ã€‚ä½ ä¸å¿…æ‹…å¿ƒæœç´¢å’Œä»·æ ¼æ¯”è¾ƒï¼Œå› ä¸ºåº”ç”¨ç¨‹åºä¼šè‡ªåŠ¨ä¸ºä½ å¤„ç†è¿™äº›äº‹æƒ…ã€‚å¾ˆé…·ï¼Œå¯¹å§ï¼Ÿè¿™æ­£æ˜¯æˆ‘ä»¬å°†åœ¨æœ¬æ•™ç¨‹ä¸­æ„å»ºçš„å†…å®¹ã€‚

è®©æˆ‘ä»¬å…ˆçœ‹ä¸€äº›ä¾‹å­ã€‚

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ikbr1ozv37PIB2meVfCCfA.png)

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AZPn3_KCDRV0pAszd3vLmA.png)

å¥½çš„ï¼Œè®©æˆ‘ä»¬ä¸ºè¿™ä¸ªåº”ç”¨ç¨‹åºæ³¨å…¥æ´»åŠ›ã€‚æˆ‘ä»¬å°†ä½¿ç”¨Metaçš„Llama 3æ¨¡å‹ï¼Œå…·æœ‰å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚ä¸è¿‡ï¼Œè¿™ä¹Ÿå¯ä»¥ä½¿ç”¨3.1æ¨¡å‹æ¥å®ç°ã€‚æ ¹æ®[Metaçš„å…¬å‘Š](https://ai.meta.com/blog/meta-llama-3-1/)ï¼Œ3.1æ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°ä½¿ç”¨å·¥å…·å’Œå‡½æ•°ã€‚

> è¿™äº›æ˜¯å¤šè¯­è¨€çš„ï¼Œå…·æœ‰æ˜¾è‘—æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦128Kï¼Œæœ€å…ˆè¿›çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œä»¥åŠæ•´ä½“æ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€‚

æˆ‘å°†ä½¿ç”¨Groq Cloudï¼Œç‰¹åˆ«æ˜¯ä»–ä»¬çš„æ¨¡å‹æ¥æ’°å†™æœ¬æ–‡ã€‚è¿™ä¸ªåº”ç”¨ç¨‹åºçš„åˆå§‹å·¥ä½œæµç¨‹åº”ç”±ä¸€ä¸ªåµŒå…¥æ¨¡å‹ã€ä¸€ä¸ªæ£€ç´¢å™¨å’Œä¸¤ä¸ªä¸»è¦å·¥å…·ç»„æˆï¼Œç”¨äºå¤„ç†ç”¨æˆ·çš„è´­ä¹°å…´è¶£å’Œä¸æˆæœ¬ç›¸å…³çš„å…³æ³¨ã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›ç±»ä¼¼äºä¸‹é¢å›¾è¡¨ä¸­æè¿°çš„å†…å®¹ã€‚

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*EZVySX3GD2O07fzEPwLcbQ.png)

ç°åœ¨æˆ‘ä»¬éœ€è¦ä½¿ç”¨LLMç¼–æ’æ¡†æ¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘é€‰æ‹©æˆ‘ä¸€ç›´ä»¥æ¥æœ€å–œæ¬¢çš„[Haystack](https://haystack.deepset.ai/)ã€‚

å¥½çš„ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æˆ‘ä»¬éœ€è¦çš„ä¸œè¥¿ã€‚è®©æˆ‘ä»¬è·³å…¥å®é™…å·¥ä½œå§ï¼

### åŠ è½½å’Œç´¢å¼•æ•°æ®

ç”±äºæˆ‘ä»¬æœ‰ä¸€ä¸ª RAG æµæ°´çº¿ï¼Œåº”è¯¥å°†æ„å»ºæ–‡æ¡£ç´¢å¼•æœåŠ¡ä½œä¸ºç¬¬ä¸€æ­¥ã€‚å¯¹äºè¿™ä¸ªæ¼”ç¤ºï¼Œæˆ‘å°†ä½¿ç”¨ Haystack æä¾›çš„å†…å­˜å‘é‡æ•°æ®åº“ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬çš„å‘é‡æ•°æ®åº“ä¸­çš„æ¯ä¸ªæ–‡æ¡£åŒ…å«ï¼š

* å†…å®¹ â€” æˆ‘ä»¬ç”¨å®ƒæ¥æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
* Id â€” å”¯ä¸€æ ‡è¯†ç¬¦
* ä»·æ ¼ â€” äº§å“ä»·æ ¼
* URL â€” äº§å“ URL

å½“æˆ‘ä»¬çš„ RAG æµæ°´çº¿è¢«è°ƒç”¨æ—¶ï¼Œå†…å®¹å­—æ®µç”¨äºå‘é‡æœç´¢ã€‚æ‰€æœ‰å…¶ä»–å­—æ®µä½œä¸ºå…ƒæ•°æ®åŒ…å«ã€‚ä¿ç•™è¿™äº›å…ƒæ•°æ®è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒå¯¹å‰ç«¯å‘ˆç°ç»™ç”¨æˆ·æ˜¯å¿…ä¸å¯å°‘çš„ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å®ç°è¿™ä¸€ç‚¹ã€‚

```python
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.writers import DocumentWriter
from haystack.components.embedders import SentenceTransformersDocumentEmbedder
from haystack.components.generators import OpenAIGenerator
from haystack.utils import Secret
from haystack.components.generators.chat import OpenAIChatGenerator
from haystack.components.builders import PromptBuilder
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.dataclasses import ChatMessage
import pandas as pd

## Load product data from CSV
df = pd.read_csv("product_sample.csv")

## Initialize an in-memory document store
document_store = InMemoryDocumentStore()

## Convert the product data into Haystack Document objects
documents = [
    Document(
        content=item.product_name, 
        meta={
            "id": item.uniq_id, 
            "price": item.selling_price, 
            "url": item.product_url
        }
    ) for item in df.itertuples()
]

## Create a pipeline for indexing the documents
indexing_pipeline = Pipeline()

## Add a document embedder to the pipeline using Sentence Transformers model
indexing_pipeline.add_component(
    instance=SentenceTransformersDocumentEmbedder(model="sentence-transformers/all-MiniLM-L6-v2"), name="doc_embedder"
)

## Add a document writer to the pipeline to store documents in the document store
indexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name="doc_writer")

## Connect the embedder's output to the writer's input
indexing_pipeline.connect("doc_embedder.documents", "doc_writer.documents")

## Run the indexing pipeline to process and store the documents
indexing_pipeline.run({"doc_embedder": {"documents": documents}})
```
å¾ˆå¥½ï¼Œæˆ‘ä»¬å·²å®Œæˆ AI ä»£ç†åº”ç”¨ç¨‹åºçš„ç¬¬ä¸€æ­¥ã€‚ç°åœ¨æ˜¯æ—¶å€™æ„å»ºäº§å“è¯†åˆ«å·¥å…·äº†ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£äº§å“è¯†åˆ«å™¨çš„ä¸»è¦ä»»åŠ¡ï¼Œè®©æˆ‘ä»¬è€ƒè™‘ä¸‹é¢çš„ç¤ºä¾‹ã€‚

> ç”¨æˆ·æŸ¥è¯¢ï¼šæˆ‘æƒ³ä¹°ä¸€åŒéœ²è¥é´ã€ä¸€å°ç‚­çƒ¤ç‚‰å’Œä¸€ä¸ª Google Pixel 9 çš„æ‰‹æœºå£³ã€‚è®©æˆ‘ä»¬ç†è§£äº§å“è¯†åˆ«åŠŸèƒ½çš„ç†æƒ³å·¥ä½œæµç¨‹ã€‚

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*kXGYjlMi4pQcqIKpmUZLRQ.png)

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªå·¥å…·æ¥åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶è¯†åˆ«ç”¨æˆ·æ„Ÿå…´è¶£çš„äº§å“ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ„å»ºè¿™æ ·çš„å·¥å…·ã€‚

### æ„å»ºç”¨æˆ·æŸ¥è¯¢åˆ†æå™¨


```python
template = """
Understand the user query and list of products the user is interested in and return product names as list.
You should always return a Python list. Do not return any explanation.

Examples:
Question: I am interested in camping boots, charcoal and disposable rain jacket.
Answer: ["camping_boots","charcoal","disposable_rain_jacket"]

Question: Need a laptop, wireless mouse, and noise-cancelling headphones for work.
Answer: ["laptop","wireless_mouse","noise_cancelling_headphones"]

Question: {{ question }}
Answer:
"""

product_identifier = Pipeline()

product_identifier.add_component("prompt_builder", PromptBuilder(template=template))
product_identifier.add_component("llm", generator())

product_identifier.connect("prompt_builder", "llm")
```
å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº†ç¬¬ä¸€ä¸ªå‡½æ•°çš„ä¸€åŠï¼Œç°åœ¨æ˜¯æ—¶å€™é€šè¿‡æ·»åŠ RAGç®¡é“æ¥å®Œæˆè¿™ä¸ªå‡½æ•°ã€‚ 

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*JyxINdc8Wz-qAg_PCAkLbA.png)

### åˆ›å»º RAG ç®¡é“


```python
template = """
Return product name, price, and url as a python dictionary. 
You should always return a Python dictionary with keys price, name and url for single product.
You should always return a Python list of dictionaries with keys price, name and url for multiple products.
Do not return any explanation.

Legitimate Response Schema:
{"price": "float", "name": "string", "url": "string"}
Legitimate Response Schema for multiple products:
[{"price": "float", "name": "string", "url": "string"},{"price": "float", "name": "string", "url": "string"}]

Context:
{% for document in documents %}
    product_price: {{ document.meta['price'] }}
    product_url: {{ document.meta['url'] }}
    product_id: {{ document.meta['id'] }}
    product_name: {{ document.content }}
{% endfor %}
Question: {{ question }}
Answer:
"""

rag_pipe = Pipeline()
rag_pipe.add_component("embedder", SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2"))
rag_pipe.add_component("retriever", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))
rag_pipe.add_component("prompt_builder", PromptBuilder(template=template))
rag_pipe.add_component("llm", generator())

rag_pipe.connect("embedder.embedding", "retriever.query_embedding")
rag_pipe.connect("retriever", "prompt_builder.documents")
rag_pipe.connect("prompt_builder", "llm")
```
åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº† RAG å’ŒæŸ¥è¯¢åˆ†æå™¨ç®¡é“ã€‚ç°åœ¨æ˜¯æ—¶å€™å°†å…¶è½¬æ¢ä¸ºå·¥å…·äº†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¸¸è§„çš„å‡½æ•°å£°æ˜ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚ä¸ºä»£ç†åˆ›å»ºå·¥å…·å°±åƒåˆ›å»ºä¸€ä¸ª Python å‡½æ•°ã€‚å¦‚æœä½ æœ‰è¿™æ ·çš„é—®é¢˜


> ä»£ç†å¦‚ä½•è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Ÿ

è§£å†³æ–¹æ¡ˆå¾ˆç®€å•ï¼šé€šè¿‡åˆ©ç”¨ç‰¹å®šæ¨¡å‹çš„å·¥å…·æ¶æ„ï¼Œæˆ‘ä»¬è®¡åˆ’åœ¨æœªæ¥çš„æ­¥éª¤ä¸­çº³å…¥ã€‚ç›®å‰ï¼Œæ˜¯æ—¶å€™åˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°ï¼Œæ—¢ä½¿ç”¨æŸ¥è¯¢åˆ†æå™¨åˆä½¿ç”¨ RAG ç®¡é“ã€‚

è®©æˆ‘ä»¬æ˜ç¡®è¿™ä¸ªå‡½æ•°çš„ç›®æ ‡ã€‚

**ç›®æ ‡ 1ï¼š** ç¡®å®šç”¨æˆ·æ„Ÿå…´è¶£çš„æ‰€æœ‰äº§å“ï¼Œå¹¶å°†å®ƒä»¬ä½œä¸ºåˆ—è¡¨è¿”å›ã€‚ **ç›®æ ‡ 2ï¼š** å¯¹äºæ¯ä¸ªè¯†åˆ«çš„äº§å“ï¼Œä»æ•°æ®åº“ä¸­æ£€ç´¢æœ€å¤šäº”ä¸ªäº§å“åŠå…¶å…ƒæ•°æ®ã€‚

### å®Œæˆäº§å“è¯†åˆ«åŠŸèƒ½


```python
def product_identifier_func(query: str):
    """
    æ ¹æ®ç»™å®šçš„æŸ¥è¯¢è¯†åˆ«äº§å“å¹¶æ£€ç´¢æ¯ä¸ªè¯†åˆ«äº§å“çš„ç›¸å…³ç»†èŠ‚ã€‚

    å‚æ•°ï¼š
    query (str): ç”¨äºè¯†åˆ«äº§å“çš„æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚

    è¿”å›ï¼š
    dict: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºäº§å“åç§°ï¼Œå€¼ä¸ºæ¯ä¸ªäº§å“çš„è¯¦ç»†ä¿¡æ¯ã€‚å¦‚æœæœªæ‰¾åˆ°äº§å“ï¼Œåˆ™è¿”å›â€œNo product foundâ€ã€‚
    """
    product_understanding = product_identifier.run({"prompt_builder": {"question": query}})

    try:
        product_list = literal_eval(product_understanding["llm"]["replies"][0])
    except:
        return "No product found"

    results = {}

    for product in product_list:
        response = rag_pipe.run({"embedder": {"text": product}, "prompt_builder": {"question": product}})
        try:
            results[product] = literal_eval(response["llm"]["replies"][0])
        except:
            results[product] = {}
    
    return results
```
![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HWRTdWvvcw2MZP4uoaQdeQ.png)

è‡³æ­¤ï¼Œæˆ‘ä»¬å®Œæˆäº†ä»£ç†çš„ç¬¬ä¸€ä¸ªå·¥å…·ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œã€‚


```python
query = "I want crossbow and woodstock puzzle"
#execute function
product_identifier_func(query)

## {'crossbow': {'name': 'DB Longboards CoreFlex Crossbow 41" Bamboo Fiberglass '
##                        'Longboard Complete',
##                'price': 237.68,
##                'url': 'https://www.amazon.com/DB-Longboards-CoreFlex-Fiberglass-Longboard/dp/B07KMVJJK7'},
##  'woodstock_puzzle': {'name': 'Woodstock- Collage 500 pc Puzzle',
##                       'price': 17.49,
##                       'url': 'https://www.amazon.com/Woodstock-Collage-500-pc-Puzzle/dp/B07MX21WWX'}}
```
å®ƒå·¥ä½œäº†ï¼ï¼ç„¶è€Œï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯è¿”å›è¾“å‡ºçš„ç»“æ„ã€‚æ‚¨å¯ä»¥åœ¨ä¸‹é¢çœ‹åˆ°ä¸€èˆ¬çš„ç»“æ„ã€‚


```python
{
    "product_key": {
        "name": "string",
        "price": "float",
        "url": "string"
    }
}
```
è¿™æ­£æ˜¯æˆ‘ä»¬åœ¨RAGç®¡é“ä¸­å»ºè®®æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ã€‚ä¸‹ä¸€æ­¥ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªåä¸º`find_budget_friendly_option`çš„å¯é€‰å·¥å…·ã€‚


```python
def find_budget_friendly_option(selected_product_details):
    """
    ä¸ºæ¯ä¸ªäº§å“ç±»åˆ«æ‰¾åˆ°æœ€å…·é¢„ç®—å‹å¥½çš„é€‰é¡¹ã€‚

    å‚æ•°ï¼š
    selected_product_details (dict): ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºäº§å“ç±»åˆ«ï¼Œå€¼ä¸ºäº§å“è¯¦ç»†ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªäº§å“è¯¦ç»†ä¿¡æ¯åº”ä¸ºåŒ…å«â€œpriceâ€é”®çš„å­—å…¸ã€‚

    è¿”å›ï¼š
    dict: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºäº§å“ç±»åˆ«ï¼Œå€¼ä¸ºæ¯ä¸ªç±»åˆ«æœ€å…·é¢„ç®—å‹å¥½çš„äº§å“è¯¦ç»†ä¿¡æ¯ã€‚
    """
    budget_friendly_options = {}
    
    for category, items in selected_product_details.items():
        if isinstance(items, list):
            lowest_price_item = min(items, key=lambda x: x['price'])
        else:
            lowest_price_item = items
        
        budget_friendly_options[category] = lowest_price_item
    
    return budget_friendly_options
```
å¥½çš„ï¼Œè®©æˆ‘ä»¬ä¸“æ³¨äºè¿™ä¸ªåº”ç”¨ç¨‹åºæœ€å…³é”®çš„æ–¹é¢ï¼Œå³ä½¿ä»£ç†æ ¹æ®éœ€è¦ä½¿ç”¨è¿™äº›åŠŸèƒ½ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è®¨è®ºçš„ï¼Œè¿™å¯ä»¥é€šè¿‡æ¨¡å‹ç‰¹å®šçš„å·¥å…·æ¶æ„æ¥å®ç°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ç‰¹å®šäºæ‰€é€‰æ¨¡å‹çš„å·¥å…·æ¶æ„ã€‚å¹¸è¿çš„æ˜¯ï¼Œå®ƒåœ¨æ¨¡å‹å¡ä¸­æåˆ° [è¿™é‡Œ](https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use)ã€‚æˆ‘ä»¬éœ€è¦è°ƒæ•´å®ƒä»¥é€‚åº”æˆ‘ä»¬çš„ç”¨ä¾‹ã€‚

### å®ŒæˆèŠå¤©æ¨¡æ¿


```python
chat_template = '''<|start_header_id|>system<|end_header_id|>

You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:
<tool_call>
{"name": <function-name>,"arguments": <args-dict>}
</tool_call>

Here are the available tools:
<tools>
    {
        "name": "product_identifier_func",
        "description": "To understand user interested products and its details",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The query to use in the search. Infer this from the user's message. It should be a question or a statement"
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "find_budget_friendly_option",
        "description": "Get the most cost-friendly option. If selected_product_details has morethan one key this should return most cost-friendly options",
        "parameters": {
            "type": "object",
            "properties": {
                "selected_product_details": {
                    "type": "dict",
                    "description": "Input data is a dictionary where each key is a category name, and its value is either a single dictionary with 'price', 'name', and 'url' keys or a list of such dictionaries; example: {'category1': [{'price': 10.5, 'name': 'item1', 'url': 'http://example.com/item1'}, {'price': 8.99, 'name': 'item2', 'url': 'http://example.com/item2'}], 'category2': {'price': 15.0, 'name': 'item3', 'url': 'http://example.com/item3'}}"
                }
            },
            "required": ["selected_product_details"]
        }
    }
</tools><|eot_id|><|start_header_id|>user<|end_header_id|>

I need to buy a crossbow<|eot_id|><|start_header_id|>assistant<|end_header_id|>

<tool_call>
{"id":"call_deok","name":"product_identifier_func","arguments":{"query":"I need to buy a crossbow"}}
</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>

<tool_response>
{"id":"call_deok","result":{'crossbow': {'price': 237.68,'name': 'crossbow','url': 'https://www.amazon.com/crossbow/dp/B07KMVJJK7'}}}
</tool_response><|eot_id|><|start_header_id|>assistant<|end_header_id|>
'''
ç°åœ¨åªå‰©ä¸‹å‡ ä¸ªæ­¥éª¤ã€‚åœ¨åšä»»ä½•äº‹æƒ…ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„ä»£ç†ã€‚


```python
### æµ‹è¯•ä»£ç†
messages = [
    ChatMessage.from_system(
        chat_template
    ),
    ChatMessage.from_user("I need to buy a crossbow for my child and PokÃ©mon for myself."),
]

chat_generator = get_chat_generator()
response = chat_generator.run(messages=messages)
pprint(response)

### response
{'replies': [ChatMessage(content='<tool_call>\n'
                                 '{"id": 0, "name": "product_identifier_func", '
                                 '"arguments": {"query": "I need to buy a '
                                 'crossbow for my child"}}\n'
                                 '</tool_call>\n'
                                 '<tool_call>\n'
                                 '{"id": 1, "name": "product_identifier_func", '
                                 '"arguments": {"query": "I need to buy a '
                                 'Pokemon for myself"}}\n'
                                 '</tool_call>',
                         role=<ChatRole.ASSISTANT: 'assistant'>,
                         name=None,
                         meta={'finish_reason': 'stop',
                               'index': 0,
                               'model': 'llama3-groq-70b-8192-tool-use-preview',
                               'usage': {'completion_time': 0.217823967,
                                         'completion_tokens': 70,
                                         'prompt_time': 0.041348261,
                                         'prompt_tokens': 561,
                                         'total_time': 0.259172228,
                                         'total_tokens': 631}})]}
```
åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†å¤§çº¦90%çš„å·¥ä½œã€‚

![](https://images.weserv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nYVXcgpm3RZ3g5h5d4UK_A.png)

åœ¨ä¸Šé¢çš„å“åº”ä¸­ï¼Œæ‚¨å¯èƒ½æ³¨æ„åˆ°XMLæ ‡ç­¾`<tool_call>`å°é—­äº†å·¥å…·è°ƒç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å¼€å‘ä¸€ç§æœºåˆ¶æ¥æå–tool_callå¯¹è±¡ã€‚


```python
def extract_tool_calls(tool_calls_str):
    json_objects = re.findall(r'<tool_call>(.*?)</tool_call>', tool_calls_str, re.DOTALL)
    
    result_list = [json.loads(obj) for obj in json_objects]
    
    return result_list

available_functions = {
    "product_identifier_func": product_identifier_func, 
    "find_budget_friendly_option": find_budget_friendly_option
    }
```
å®Œæˆè¿™ä¸€æ­¥åï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è®¿é—®ä»£ç†çš„å“åº”ï¼Œå½“å®ƒè°ƒç”¨ä¸€ä¸ªå·¥å…·æ—¶ã€‚ç°åœ¨å”¯ä¸€å¾…åšçš„å°±æ˜¯è·å–å·¥å…·è°ƒç”¨å¯¹è±¡å¹¶ç›¸åº”åœ°æ‰§è¡Œå‡½æ•°ã€‚è®©æˆ‘ä»¬å®Œæˆé‚£éƒ¨åˆ†ã€‚


```python
messages.append(ChatMessage.from_user(message))
response = chat_generator.run(messages=messages)

if response and "<tool_call>" in response["replies"][0].content:
    function_calls = extract_tool_calls(response["replies"][0].content)
    for function_call in function_calls:
        # Parse function calling information
        function_name = function_call["name"]
        function_args = function_call["arguments"]

        # Find the corresponding function and call it with the given arguments
        function_to_call = available_functions[function_name]
        function_response = function_to_call(**function_args)

        # Append function response to the messages list using `ChatMessage.from_function`
        messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))
        response = chat_generator.run(messages=messages)
```
ç°åœ¨æ˜¯æ—¶å€™å°†æ¯ä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ï¼Œæ„å»ºä¸€ä¸ªåˆé€‚çš„èŠå¤©åº”ç”¨ç¨‹åºã€‚æˆ‘å°†ä½¿ç”¨Gradioæ¥å®ç°è¿™ä¸ªç›®çš„ã€‚


```python
import gradio as gr

messages = [ChatMessage.from_system(chat_template)]
chat_generator = get_chat_generator()

def chatbot_with_fc(message, messages):
    messages.append(ChatMessage.from_user(message))
    response = chat_generator.run(messages=messages)

    while True:
        if response and "<tool_call>" in response["replies"][0].content:
            function_calls = extract_tool_calls(response["replies"][0].content)
            for function_call in function_calls:
                # Parse function calling information
                function_name = function_call["name"]
                function_args = function_call["arguments"]

                # Find the corresponding function and call it with the given arguments
                function_to_call = available_functions[function_name]
                function_response = function_to_call(**function_args)

                # Append function response to the messages list using `ChatMessage.from_function`
                messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))
                response = chat_generator.run(messages=messages)

        # Regular Conversation
        else:
            messages.append(response["replies"][0])
            break
    return response["replies"][0].content


def chatbot_interface(user_input, state):
    response_content = chatbot_with_fc(user_input, state)
    return response_content, state

with gr.Blocks() as demo:
    gr.Markdown("# AI è´­ä¹°åŠ©æ‰‹")
    gr.Markdown("é—®æˆ‘å…³äºæ‚¨æƒ³è´­ä¹°çš„äº§å“ï¼")
    
    state = gr.State(value=messages)
    
    with gr.Row():
        user_input = gr.Textbox(label="æ‚¨çš„æ¶ˆæ¯ï¼š")
        response_output = gr.Markdown(label="å›å¤ï¼š")
    
    user_input.submit(chatbot_interface, [user_input, state], [response_output, state])
    gr.Button("å‘é€").click(chatbot_interface, [user_input, state], [response_output, state])


demo.launch()
```
å°±è¿™æ ·ï¼æˆ‘ä»¬æ„å»ºäº†åŸºäºLlama 3çš„AIä»£ç†ğŸ¤–ï¼Œå…·å¤‡å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚æ‚¨å¯ä»¥ä»è¿™ä¸ª[GitHubä»“åº“](https://github.com/Ransaka/ai-agents-with-llama3)è®¿é—®å®Œæ•´ä»£ç ã€‚æ„Ÿè°¢æ‚¨çš„é˜…è¯»ã€‚

é€šè¿‡[è¿™ä¸ª](https://www.kaggle.com/datasets/promptcloud/amazon-product-dataset-2020)Kaggleé“¾æ¥ï¼ˆåœ¨CC0ï¼šå…¬å…±é¢†åŸŸä¸‹ï¼‰å¯ä»¥è®¿é—®æœ¬æ–‡ä½¿ç”¨çš„æ•°æ®é›†ã€‚

### ç»“è®º

åœ¨æ„å»ºåŸºäºAIä»£ç†çš„ç³»ç»Ÿæ—¶ï¼Œè€ƒè™‘å®Œæˆä»»åŠ¡æ‰€éœ€çš„æ—¶é—´å’Œæ¯ä¸ªä»»åŠ¡ä½¿ç”¨çš„APIè°ƒç”¨ï¼ˆä»¤ç‰Œï¼‰æ•°é‡éå¸¸é‡è¦ã€‚ä¸€ä¸ªä¸»è¦çš„æŒ‘æˆ˜æ˜¯å‡å°‘ç³»ç»Ÿä¸­çš„å¹»è§‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚å› æ­¤ï¼Œæ„å»ºLLMå’Œä»£ç†ç³»ç»Ÿæ²¡æœ‰å›ºå®šçš„è§„åˆ™ã€‚å¿…é¡»è€å¿ƒè€Œæœ‰ç­–ç•¥åœ°å·¥ä½œï¼Œä»¥ç¡®ä¿AIä»£ç†ï¼Œå³LLMï¼Œæ­£å¸¸è¿è¡Œã€‚

*é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›ã€‚*

### å‚è€ƒï¼š

[https://docs.together.ai/docs/llama\-3\-function\-calling](https://docs.together.ai/docs/llama-3-function-calling)

