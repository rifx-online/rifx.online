---
title: "ä»é›¶åˆ°è‹±é›„ï¼šä½¿ç”¨ LangGraph å¿«é€Ÿæ„å»ºæ™ºèƒ½èŠå¤©æœºå™¨äºº"
meta_title: "ä»é›¶åˆ°è‹±é›„ï¼šä½¿ç”¨ LangGraph å¿«é€Ÿæ„å»ºæ™ºèƒ½èŠå¤©æœºå™¨äºº"
description: "æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨LangGraphæ„å»ºä¸€ä¸ªæ™ºèƒ½èŠå¤©æœºå™¨äººï¼Œæ¶µç›–äº†ä»åŸºç¡€æ„å»ºåˆ°å¢å¼ºåŠŸèƒ½çš„å¤šä¸ªæ­¥éª¤ã€‚é¦–å…ˆï¼Œåˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººï¼Œéšåé›†æˆäº†ç½‘ç»œæœç´¢å·¥å…·ä»¥æå‡å›ç­”èƒ½åŠ›ï¼Œå¹¶å®ç°äº†è®°å¿†ç®¡ç†ä»¥ä¿æŒå¯¹è¯çŠ¶æ€ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ¢è®¨äº†äººæœºåä½œçš„å®ç°ï¼Œé€šè¿‡äººå·¥ç›‘ç£å’Œè‡ªå®šä¹‰çŠ¶æ€æ›´æ–°æ¥å¢å¼ºæœºå™¨äººçš„çµæ´»æ€§å’Œå“åº”èƒ½åŠ›ã€‚æ•´ä¸ªè¿‡ç¨‹å±•ç¤ºäº†LangGraphåœ¨æ„å»ºå¤æ‚æœ‰çŠ¶æ€AIåº”ç”¨ä¸­çš„å¼ºå¤§åŠŸèƒ½å’Œçµæ´»æ€§ã€‚"
date: 2024-11-25T15:00:22Z
image: "https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*80g4sqbcGGL9p3qEK852iA.jpeg"
categories: ["Chatbots", "Programming", "Machine Learning"]
author: "Rifx.Online"
tags: ["LangGraph", "chatbot", "state", "memory", "tools"]
draft: False

---





åœ¨è¿™ä¸ªå…¨é¢çš„å¿«é€Ÿå…¥é—¨æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ LangGraph æ„å»ºä¸€ä¸ªæ”¯æŒèŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥ï¼š

* **é€šè¿‡æœç´¢ç½‘ç»œå›ç­”å¸¸è§é—®é¢˜**
* **åœ¨è°ƒç”¨ä¹‹é—´ä¿æŒå¯¹è¯çŠ¶æ€**
* **å°†å¤æ‚æŸ¥è¯¢è·¯ç”±åˆ°äººå·¥è¿›è¡Œå®¡æŸ¥**
* **ä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€æ¥æ§åˆ¶å…¶è¡Œä¸º**
* **å›æº¯å¹¶æ¢ç´¢æ›¿ä»£å¯¹è¯è·¯å¾„**

æˆ‘ä»¬å°†ä»ä¸€ä¸ªåŸºæœ¬çš„èŠå¤©æœºå™¨äººå¼€å§‹ï¼Œé€æ­¥æ·»åŠ æ›´å¤æ‚çš„åŠŸèƒ½ï¼ŒåŒæ—¶ä»‹ç»å…³é”®çš„ LangGraph æ¦‚å¿µã€‚

## è®¾ç½®

é¦–å…ˆï¼Œå®‰è£…æ‰€éœ€çš„åŒ…ï¼š

```python
%pip install -U langgraph langsmith langchain_anthropic
```
æ¥ä¸‹æ¥ï¼Œè®¾ç½®æ‚¨çš„ API å¯†é’¥ï¼š

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
_set_env("ANTHROPIC_API_KEY")
```
ä¸º LangGraph å¼€å‘è®¾ç½® **LangSmith**ã€‚æ³¨å†Œ LangSmith ä»¥å¿«é€Ÿå‘ç°é—®é¢˜å¹¶æé«˜æ‚¨çš„ LangGraph é¡¹ç›®çš„æ€§èƒ½ã€‚LangSmith å…è®¸æ‚¨ä½¿ç”¨è·Ÿè¸ªæ•°æ®æ¥è°ƒè¯•ã€æµ‹è¯•å’Œç›‘æ§ä½¿ç”¨ LangGraph æ„å»ºçš„ LLM åº”ç”¨ç¨‹åºã€‚

## ç¬¬1éƒ¨åˆ†ï¼šæ„å»ºä¸€ä¸ªåŸºæœ¬çš„èŠå¤©æœºå™¨äºº

æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨ LangGraph åˆ›å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººã€‚è¿™ä¸ªèŠå¤©æœºå™¨äººå°†ç›´æ¥å¯¹ç”¨æˆ·æ¶ˆæ¯åšå‡ºå›åº”ã€‚å°½ç®¡ç®€å•ï¼Œå®ƒå°†é˜æ˜ä½¿ç”¨ LangGraph æ„å»ºçš„æ ¸å¿ƒæ¦‚å¿µã€‚åœ¨æœ¬èŠ‚ç»“æŸæ—¶ï¼Œæ‚¨å°†æ„å»ºä¸€ä¸ªåˆæ­¥çš„èŠå¤©æœºå™¨äººã€‚

## å®šä¹‰çŠ¶æ€å›¾

é¦–å…ˆåˆ›å»ºä¸€ä¸ª `StateGraph`ã€‚`StateGraph` å¯¹è±¡å®šä¹‰äº†æˆ‘ä»¬èŠå¤©æœºå™¨äººçš„ç»“æ„ï¼Œä½œä¸ºä¸€ä¸ª **çŠ¶æ€æœº**ã€‚æˆ‘ä»¬å°†æ·»åŠ èŠ‚ç‚¹æ¥è¡¨ç¤º LLM å’Œæˆ‘ä»¬çš„èŠå¤©æœºå™¨äººå¯ä»¥è°ƒç”¨çš„å‡½æ•°ï¼Œå¹¶æ·»åŠ è¾¹æ¥æŒ‡å®šæœºå™¨äººå¦‚ä½•åœ¨è¿™äº›å‡½æ•°ä¹‹é—´è½¬æ¢ã€‚

```python
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


class State(TypedDict):
    # æ¶ˆæ¯çš„ç±»å‹æ˜¯ "list"ã€‚`add_messages` å‡½æ•°
    # åœ¨æ³¨é‡Šä¸­å®šä¹‰äº†å¦‚ä½•æ›´æ–°æ­¤çŠ¶æ€é”®
    # ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå°†æ¶ˆæ¯é™„åŠ åˆ°åˆ—è¡¨ä¸­ï¼Œè€Œä¸æ˜¯è¦†ç›–å®ƒä»¬ï¼‰
    messages: Annotated[list, add_messages]
graph_builder = StateGraph(State)
```
**æ³¨æ„ï¼š**

* **çŠ¶æ€å®šä¹‰**ï¼š`State` åŒ…å«å›¾çš„æ¶æ„ä»¥åŠæŒ‡å®šå¦‚ä½•å°†æ›´æ–°åº”ç”¨äºçŠ¶æ€çš„ reducer å‡½æ•°ã€‚
* **æ³¨é‡Šæ¶ˆæ¯**ï¼š`messages` é”®è¢«æ³¨é‡Šä¸º `add_messages` reducer å‡½æ•°ï¼Œè¿™å‘Šè¯‰ LangGraph å°†æ–°æ¶ˆæ¯é™„åŠ åˆ°ç°æœ‰åˆ—è¡¨ä¸­ï¼Œè€Œä¸æ˜¯è¦†ç›–å®ƒã€‚

## æ·»åŠ èŠå¤©æœºå™¨äººèŠ‚ç‚¹

æ¥ä¸‹æ¥ï¼Œæ·»åŠ ä¸€ä¸ª `chatbot` èŠ‚ç‚¹ã€‚èŠ‚ç‚¹ä»£è¡¨å·¥ä½œå•å…ƒï¼Œé€šå¸¸æ˜¯å¸¸è§„çš„ Python å‡½æ•°ã€‚

```python
from langchain_anthropic import ChatAnthropic
llm = ChatAnthropic(model="claude-2")

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}
## The first argument is the unique node name
## The second argument is the function or object that will be called whenever
## the node is used.
graph_builder.add_node("chatbot", chatbot)
```
* **å‡½æ•°è¯´æ˜**ï¼š`chatbot` å‡½æ•°ä»¥å½“å‰ `State` ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå­—å…¸ä¸­åŒ…å«ä¸€ä¸ªæ›´æ–°åçš„ `messages` åˆ—è¡¨ï¼Œé”®ä¸º `"messages"`ã€‚

## å®šä¹‰å…¥å£å’Œå‡ºå£

ä¸ºå›¾å½¢æ·»åŠ ä¸€ä¸ªå…¥å£ç‚¹å’Œä¸€ä¸ªç»“æŸç‚¹ã€‚


```python
graph_builder.add_edge(START, "chatbot")
graph_builder.add_edge("chatbot", END)
```
* **å…¥å£ç‚¹**ï¼šå‘Šè¯‰å›¾å½¢æ¯æ¬¡è¿è¡Œæ—¶ä»å“ªé‡Œå¼€å§‹å·¥ä½œã€‚
* **ç»“æŸç‚¹**ï¼šæŒ‡ç¤ºå›¾å½¢åœ¨ `chatbot` èŠ‚ç‚¹ä¹‹åé€€å‡ºã€‚

## ç¼–è¯‘å›¾å½¢

ç¼–è¯‘å›¾å½¢ä»¥åˆ›å»ºä¸€ä¸ª `CompiledGraph`ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„çŠ¶æ€ä¸Šè°ƒç”¨å®ƒã€‚

```python
graph = graph_builder.compile()
```

## å¯è§†åŒ–å›¾å½¢ï¼ˆå¯é€‰ï¼‰

æ‚¨å¯ä»¥ä½¿ç”¨ `get_graph` æ–¹æ³•å’Œå…¶ä¸­ä¸€ç§ç»˜å›¾æ–¹æ³•æ¥å¯è§†åŒ–å›¾å½¢ã€‚

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    pass  # Visualization is optional
```

### è¾“å‡º:

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*87erCrk12EGGU0GGGMsb4Q.jpeg)

## è¿è¡ŒèŠå¤©æœºå™¨äºº

ç°åœ¨è®©æˆ‘ä»¬è¿è¡ŒèŠå¤©æœºå™¨äººï¼


```python
def stream_graph_updates(user_input: str):
    for event in graph.stream({"messages": [("user", user_input)]}):
        for value in event.values():
            print("Assistant:", value["messages"][-1].content)

while True:
    try:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye!")
            break
        stream_graph_updates(user_input)
    except:
        # Fallback if input() is not available
        user_input = "What do you know about LangGraph?"
        print("User: " + user_input)
        stream_graph_updates(user_input)
        break
```
**ç¤ºä¾‹äº’åŠ¨ï¼š**


```python
User: What is LangGraph?
Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions.
Goodbye!
```
**æ­å–œï¼** ä½ å·²ç»ä½¿ç”¨ LangGraph æ„å»ºäº†ç¬¬ä¸€ä¸ªèŠå¤©æœºå™¨äººã€‚è¿™ä¸ªæœºå™¨äººå¯ä»¥é€šè¿‡è·å–ç”¨æˆ·è¾“å…¥å¹¶ä½¿ç”¨ LLM ç”Ÿæˆå“åº”æ¥è¿›è¡ŒåŸºæœ¬å¯¹è¯ã€‚

## Part 2: ä½¿ç”¨å·¥å…·å¢å¼ºèŠå¤©æœºå™¨äºº

ä¸ºäº†å¤„ç†æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººæ— æ³•é€šè¿‡è®°å¿†å›ç­”çš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†é›†æˆä¸€ä¸ªç½‘ç»œæœç´¢å·¥å…·ã€‚æˆ‘ä»¬çš„æœºå™¨äººå¯ä»¥ä½¿ç”¨æ­¤å·¥å…·æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯å¹¶æä¾›æ›´å¥½çš„å›åº”ã€‚

## éœ€æ±‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…å¿…è¦çš„è½¯ä»¶åŒ…å¹¶è®¾ç½®äº† API å¯†é’¥ã€‚

**å®‰è£… Tavily æœç´¢å¼•æ“ï¼š**


```python
%pip install -U tavily-python langchain_community
```
è®¾ç½®æ‚¨çš„ `TAVILY_API_KEY`ï¼š


```python
_set_env("TAVILY_API_KEY")
```

## å®šä¹‰å·¥å…·


```python
from langchain_community.tools.tavily_search import TavilySearchResults

tool = TavilySearchResults(max_results=2)
tools = [tool]
```

## ä¿®æ”¹å›¾å½¢

æˆ‘ä»¬å°†å¼€å§‹å®šä¹‰æˆ‘ä»¬çš„å›¾å½¢ã€‚ä»¥ä¸‹å†…å®¹ä¸ç¬¬ä¸€éƒ¨åˆ†ç±»ä¼¼ï¼Œä½†æˆ‘ä»¬åœ¨æˆ‘ä»¬çš„ LLM ä¸­æ·»åŠ äº† `bind_tools`ã€‚


```python
from typing import Annotated
from langchain_anthropic import ChatAnthropic
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


class State(TypedDict):
    messages: Annotated[list, add_messages]
graph_builder = StateGraph(State)
llm = ChatAnthropic(model="claude-2")
llm_with_tools = llm.bind_tools(tools)
def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}
graph_builder.add_node("chatbot", chatbot)
```

## æ·»åŠ å·¥å…·èŠ‚ç‚¹

åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è¿è¡Œè¢«è°ƒç”¨çš„å·¥å…·ã€‚

```python
import json
from langchain_core.messages import ToolMessage

class BasicToolNode:
    """ä¸€ä¸ªè¿è¡Œåœ¨æœ€åä¸€ä¸ªAIMessageä¸­è¯·æ±‚çš„å·¥å…·çš„èŠ‚ç‚¹ã€‚"""
    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}
    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("è¾“å…¥ä¸­æœªæ‰¾åˆ°æ¶ˆæ¯")
        outputs = []
        for tool_call in message.tool_calls:
            tool_result = self.tools_by_name[tool_call["name"]].invoke(
                tool_call["args"]
            )
            outputs.append(
                ToolMessage(
                    content=json.dumps(tool_result),
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}
tool_node = BasicToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)
```

## å®šä¹‰æ¡ä»¶è¾¹

è¾¹ç¼˜å°†æ§åˆ¶æµä»ä¸€ä¸ªèŠ‚ç‚¹è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚æ¡ä»¶è¾¹é€šå¸¸åŒ…å«â€œifâ€è¯­å¥ï¼Œä»¥æ ¹æ®å½“å‰å›¾çŠ¶æ€è·¯ç”±åˆ°ä¸åŒçš„èŠ‚ç‚¹ã€‚

```python
from typing import Literal

def route_tools(state: State):
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END
graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph = graph_builder.compile()
```

## å¯è§†åŒ–å¢å¼ºå›¾

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    pass
```

### è¾“å‡º:

![](https://wsrv.nl/?url=https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*InvKcUBqDcXMLHUusmp30A.jpeg)

## è¿è¡Œå¢å¼ºå‹èŠå¤©æœºå™¨äºº


```python
while True:
    try:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye!")
            break
        stream_graph_updates(user_input)
    except:
        user_input = "What do you know about LangGraph?"
        print("User: " + user_input)
        stream_graph_updates(user_input)
        break
```
**ç¤ºä¾‹äº’åŠ¨:**


```python
User: What's a 'node' in LangGraph?
Assistant: Based on the search results, a 'node' in LangGraph represents a function or computation step. Each node performs a specific task and can be connected to other nodes to form a workflow.
Goodbye!
```
**æ­å–œï¼** æ‚¨å·²ç»åœ¨ LangGraph ä¸­åˆ›å»ºäº†ä¸€ä¸ªå¯ä»¥åœ¨éœ€è¦æ—¶ä½¿ç”¨æœç´¢å¼•æ“æ£€ç´¢æ›´æ–°ä¿¡æ¯çš„å¯¹è¯ä»£ç†ã€‚

## ç¬¬3éƒ¨åˆ†ï¼šä¸ºèŠå¤©æœºå™¨äººæ·»åŠ è®°å¿†

æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººç°åœ¨å¯ä»¥ä½¿ç”¨å·¥å…·æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä½†å®ƒå¹¶ä¸è®°å¾—ä¹‹å‰äº¤äº’çš„ä¸Šä¸‹æ–‡ã€‚è¿™é™åˆ¶äº†å®ƒè¿›è¡Œè¿è´¯çš„å¤šè½®å¯¹è¯çš„èƒ½åŠ›ã€‚

## ä½¿ç”¨æ£€æŸ¥ç‚¹æŠ€æœ¯è¿›è¡Œå†…å­˜ç®¡ç†

LangGraphé€šè¿‡æŒä¹…æ€§æ£€æŸ¥ç‚¹è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœåœ¨ç¼–è¯‘å›¾æ—¶æä¾›ä¸€ä¸ªæ£€æŸ¥ç‚¹å™¨ï¼Œå¹¶åœ¨è°ƒç”¨å›¾æ—¶æä¾›ä¸€ä¸ª`thread_id`ï¼ŒLangGraphä¼šåœ¨æ¯ä¸€æ­¥åè‡ªåŠ¨ä¿å­˜çŠ¶æ€ã€‚

**åˆ›å»ºä¸€ä¸ª MemorySaver æ£€æŸ¥ç‚¹å™¨ï¼š**


```python
from langgraph.checkpoint.memory import MemorySaver
memory = MemorySaver()
```

## æ›´æ–°å›¾è¡¨

æˆ‘ä»¬å°†ä½¿ç”¨ LangGraph çš„é¢„æ„å»º `ToolNode` å’Œ `tools_condition` æ¥ç®€åŒ–æ“ä½œã€‚

```python
from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

class State(TypedDict):
    messages: Annotated[list, add_messages]
graph_builder = StateGraph(State)
tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-2")
llm_with_tools = llm.bind_tools(tools)
def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}
graph_builder.add_node("chatbot", chatbot)
tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)
graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph = graph_builder.compile(checkpointer=memory)
```

## ä¸å…·æœ‰è®°å¿†çš„èŠå¤©æœºå™¨äººäº’åŠ¨

**è®¾ç½®çº¿ç¨‹ IDï¼š**


```python
config = {"configurable": {"thread_id": "1"}}
```
**ç¬¬ä¸€æ¬¡äº’åŠ¨ï¼š**


```python
user_input = "Hi there! My name is Alice."
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    event["messages"][-1].pretty_print()
```
**ç¬¬äºŒæ¬¡äº’åŠ¨ï¼š**


```python
user_input = "Remember my name?"
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    event["messages"][-1].pretty_print()
```
**ç¤ºä¾‹è¾“å‡ºï¼š**


```python
mathematica
```

```python
Assistant: Of course, I remember your name, Alice. How can I assist you today?
```
**æ­å–œï¼** ç”±äº LangGraph çš„æ£€æŸ¥ç‚¹ç³»ç»Ÿï¼Œæ‚¨çš„èŠå¤©æœºå™¨äººç°åœ¨å¯ä»¥åœ¨ä¼šè¯ä¹‹é—´ä¿æŒå¯¹è¯çŠ¶æ€ã€‚

## ç¬¬4éƒ¨åˆ†ï¼šäººæœºåä½œ

ä»£ç†å¯èƒ½ä¸å¯é ï¼Œå¯èƒ½éœ€è¦äººç±»çš„è¾“å…¥æ‰èƒ½æˆåŠŸå®Œæˆä»»åŠ¡ã€‚åŒæ ·ï¼Œå¯¹äºæŸäº›æ“ä½œï¼Œæ‚¨å¯èƒ½å¸Œæœ›åœ¨è¿è¡Œä¹‹å‰è¦æ±‚äººç±»æ‰¹å‡†ï¼Œä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸè¿›è¡Œã€‚

## æ·»åŠ äººå·¥ç›‘ç£

æˆ‘ä»¬å°†ä½¿ç”¨ LangGraph çš„ `interrupt_before` åŠŸèƒ½æ¥å§‹ç»ˆä¸­æ–­å·¥å…·èŠ‚ç‚¹ã€‚

**ç¼–è¯‘å¸¦ä¸­æ–­çš„å›¾ï¼š**


```python
graph = graph_builder.compile(
    checkpointer=memory,
    interrupt_before=["tools"],
)
```

## ä¸äººç±»å‚ä¸è€…çš„äº¤äº’

**ç”¨æˆ·è¾“å…¥ï¼š**


```python
user_input = "I'm learning LangGraph. Could you do some research on it for me?"
config = {"configurable": {"thread_id": "1"}}
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```
**æ£€æŸ¥çŠ¶æ€ï¼š**


```python
snapshot = graph.get_state(config)
existing_message = snapshot.values["messages"][-1]
existing_message.tool_calls
```
**ç»§ç»­å›¾å½¢ï¼š**


```python
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```
**æ­å–œï¼** æ‚¨å·²ä½¿ç”¨ä¸­æ–­ä¸ºæ‚¨çš„èŠå¤©æœºå™¨äººæ·»åŠ äº†äººç±»å‚ä¸è€…æ‰§è¡Œï¼Œä½¿å…¶åœ¨éœ€è¦æ—¶èƒ½å¤Ÿè¿›è¡Œäººå·¥ç›‘ç£å’Œå¹²é¢„ã€‚

## ç¬¬5éƒ¨åˆ†ï¼šæ‰‹åŠ¨æ›´æ–°çŠ¶æ€

LangGraph å…è®¸æ‚¨æ‰‹åŠ¨æ›´æ–°çŠ¶æ€ï¼Œä½¿æ‚¨èƒ½å¤Ÿé€šè¿‡ä¿®æ”¹ä»£ç†çš„è¡Œä¸ºæ¥æ§åˆ¶å…¶è½¨è¿¹ã€‚

## æ›´æ–°çŠ¶æ€

**å¼€å§‹ä¸€ä¸ªæ–°çº¿ç¨‹ï¼š**


```python
user_input = "I'm learning LangGraph. Could you do some research on it for me?"
config = {"configurable": {"thread_id": "2"}}
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```
**ä¿®æ”¹å·¥å…·è°ƒç”¨ï¼š**


```python
from langchain_core.messages import AIMessage

snapshot = graph.get_state(config)
existing_message = snapshot.values["messages"][-1]
new_tool_call = existing_message.tool_calls[0].copy()
new_tool_call["args"]["query"] = "LangGraph human-in-the-loop workflow"
new_message = AIMessage(
    content=existing_message.content,
    tool_calls=[new_tool_call],
    id=existing_message.id,
)
graph.update_state(config, {"messages": [new_message]})
```
**æ¢å¤å›¾å½¢ï¼š**


```python
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```
**æ­å–œï¼** ä½ å·²ç»ä½¿ç”¨ `interrupt_before` å’Œ `update_state` æ‰‹åŠ¨ä¿®æ”¹çŠ¶æ€ï¼Œä½œä¸ºäººæœºåä½œå·¥ä½œæµçš„ä¸€éƒ¨åˆ†ã€‚

## ç¬¬6éƒ¨åˆ†ï¼šè‡ªå®šä¹‰çŠ¶æ€

æˆ‘ä»¬å°†é€šè¿‡æ·»åŠ ä¸€ä¸ªæ–°èŠ‚ç‚¹æ¥æ‰©å±•æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººï¼Œä»¥è¯´æ˜å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€æ›´æ–°æ¥å®šåˆ¶æœºå™¨äººçš„è¡Œä¸ºã€‚

## å®šä¹‰æ‰©å±•çŠ¶æ€


```python
from typing import Annotated
from langchain_anthropic import ChatAnthropic
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]
    ask_human: bool  # è¿™ä¸ªæ ‡å¿—æ˜¯æ–°çš„
```

## å®šä¹‰äººç±»è¾…åŠ©æ¨¡å¼


```python
from pydantic import BaseModel

class RequestAssistance(BaseModel):
    """Escalate the conversation to an expert."""
    request: str
```

## æ›´æ–°èŠå¤©æœºå™¨äººèŠ‚ç‚¹


```python
tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-2")
llm_with_tools = llm.bind_tools(tools + [RequestAssistance])

def chatbot(state: State):
    response = llm_with_tools.invoke(state["messages"])
    ask_human = False
    if (
        response.tool_calls
        and response.tool_calls[0]["name"] == RequestAssistance.__name__
    ):
        ask_human = True
    return {"messages": [response], "ask_human": ask_human}
```

## æ·»åŠ äººç±»èŠ‚ç‚¹


```python
from langchain_core.messages import AIMessage, ToolMessage

def create_response(response: str, ai_message: AIMessage):
    return ToolMessage(
        content=response,
        tool_call_id=ai_message.tool_calls[0]["id"],
    )
def human_node(state: State):
    new_messages = []
    if not isinstance(state["messages"][-1], ToolMessage):
        new_messages.append(
            create_response("No response from human.", state["messages"][-1])
        )
    return {
        "messages": new_messages,
        "ask_human": False,
    }
graph_builder.add_node("human", human_node)
```

## å®šä¹‰æ¡ä»¶é€»è¾‘


```python
def select_next_node(state: State):
    if state["ask_human"]:
        return "human"
    return tools_condition(state)


graph_builder.add_conditional_edges(
    "chatbot",
    select_next_node,
    {"human": "human", "tools": "tools", END: END},
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge("human", "chatbot")
graph_builder.add_edge(START, "chatbot")
memory = MemorySaver()
graph = graph_builder.compile(
    checkpointer=memory,
    interrupt_before=["human"],
)
```

## ä¸å®šåˆ¶èŠå¤©æœºå™¨äººäº’åŠ¨

**ç”¨æˆ·è¾“å…¥ï¼š**


```python
user_input = "I need some expert guidance for building this AI agent. Could you request assistance for me?"
config = {"configurable": {"thread_id": "1"}}
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```
**ä½œä¸ºäººç±»çš„å›åº”ï¼š**


```python
ai_message = snapshot.values["messages"][-1]
human_response = (
    "We, the experts, recommend you check out LangGraph to build your agent."
)
tool_message = create_response(human_response, ai_message)
graph.update_state(config, {"messages": [tool_message]})
```
**æ¢å¤å›¾å½¢ï¼š**


```python
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```
**æ­å–œï¼** æ‚¨å·²å‘åŠ©æ‰‹å›¾æ·»åŠ äº†ä¸€ä¸ªé¢å¤–èŠ‚ç‚¹ï¼Œè®©èŠå¤©æœºå™¨äººè‡ªè¡Œå†³å®šæ˜¯å¦éœ€è¦ä¸­æ–­æ‰§è¡Œã€‚

## ç»“è®º

åœ¨æœ¬ç»¼åˆæŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ LangGraph æ„å»ºäº†ä¸€ä¸ªå…·æœ‰é€æ­¥å¢å¼ºåŠŸèƒ½çš„æ”¯æŒèŠå¤©æœºå™¨äººï¼š

* **åŸºæœ¬èŠå¤©æœºå™¨äºº**ï¼šç›´æ¥å“åº”ç”¨æˆ·æ¶ˆæ¯ã€‚
* **å¢å¼ºå·¥å…·**ï¼šä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·å›ç­”é—®é¢˜ã€‚
* **å¢åŠ è®°å¿†**ï¼šåœ¨è°ƒç”¨ä¹‹é—´ç»´æŠ¤å¯¹è¯çŠ¶æ€ã€‚
* **äººç±»å‚ä¸**ï¼šå…è®¸äººç±»ç›‘ç£å’Œå¹²é¢„ã€‚
* **è‡ªå®šä¹‰çŠ¶æ€**ï¼šé€šè¿‡è‡ªå®šä¹‰çŠ¶æ€æ›´æ–°æ§åˆ¶è¡Œä¸ºã€‚

LangGraph çš„çµæ´»æ€§å’Œå¼ºå¤§åŠŸèƒ½ä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿè½»æ¾åˆ›å»ºå¤æ‚çš„ã€æœ‰çŠ¶æ€çš„ AI åº”ç”¨ç¨‹åºã€‚é€šè¿‡æŒæ¡è¿™äº›æ¦‚å¿µï¼Œæ‚¨åœ¨æ„å»ºé«˜çº§å¯¹è¯ä»£ç†å’Œæ¢ç´¢ AI å¼€å‘çš„å¹¿é˜”å¯èƒ½æ€§æ–¹é¢å·²ç»èµ°ä¸Šäº†è‰¯å¥½çš„é“è·¯ã€‚

**ç¥ç¼–ç æ„‰å¿«ï¼**

***å‚è€ƒæ–‡çŒ®ï¼š***

[ä»‹ç» \| ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/introduction/)

[https://python.langchain.com/v0\.2/docs/how\_to/migrate\_agent/](https://python.langchain.com/v0.2/docs/how_to/migrate_agent/)

[https://langchain\-ai.github.io/langgraph/tutorials/introduction](https://langchain-ai.github.io/langgraph/tutorials/introduction)

